{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICSI corpus and AMI corpus\n",
    "\n",
    "## Defined Training, Dev, and Test Dataset \n",
    "Go through the list of files and extract passage and the summaries, using the DialogueActs as intermediary\n",
    "Uses the following mappings:\n",
    "\n",
    "__1__) meeting id -> ordered dict of word id: word\n",
    "\n",
    "__2__) meeting id -> ordered dict of dialog id -> list of (start, end) word ids that form a dialog. \n",
    "\n",
    "__3__) summary_starts, summary_ends -> sets of start and end dialog ids that belong to extractive summaries\n",
    "\n",
    "\n",
    "function `get_words(meeting, meetingtype, start_word=None, end_word=None)` # goes through the meeting and returns words from start to end if provided. Else prints everything; `meetingtype` is either \"AMI\" or \"ICSI\"\n",
    "\n",
    "function `extract_dialogues(meeting, meetingtype)` # goes through the meeting and returns list of  (dialogue, SummaryFlag) for the meeting, `meetingtype` is either \"AMI\" or \"ICSI\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref:\n",
    "* http://groups.inf.ed.ac.uk/ami/corpus/annotation.shtml\n",
    "* http://groups.inf.ed.ac.uk/ami/icsi/\n",
    "* https://www.groundai.com/project/end-to-end-abstractive-summarization-for-meetings/1\n",
    "* https://bitbucket.org/dascim/offline_meeting_summarization/src/master/\n",
    "* https://github.com/gcunhase/AMICorpusXML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Please download the related ICSI corpus and AMI corpus from the websites, and change the root directory below to point to them each.* The saving will also require a file directory as:\n",
    "\n",
    "* `data/ICSI_plus_NXT/Full_doc/Dev`, \n",
    "* `data/ICSI_plus_NXT/Full_doc/Train`, \n",
    "* `data/ICSI_plus_NXT/Full_doc/Test`,\n",
    "* `data/AMI_manual/Full_doc/Dev`,\n",
    "* `data/AMI_manual/Full_doc/Test`,\n",
    "* `data/AMI_manual/Full_doc/Train`\n",
    "\n",
    "\n",
    "The dataset is split on the speaker (turn) level, meaning for each hour of the meeting (e.g.ES2004a), the saving will have ES2004a.A, ES2004a.B, etc. The abstractive summary is on the meeting level (e.g. ES2004a)\n",
    "\n",
    "**During Model Training, do separate ROUGE evaluation on AMI and ICSI datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "#import xml.etree.ElementTree as et\n",
    "from lxml import etree as et\n",
    "from collections import OrderedDict, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import operator\n",
    "from nltk import PerceptronTagger\n",
    "\n",
    "ROOT_DIR_ICSI = \"/Users/haileywu/Desktop/W266_project/data/ICSI_plus_NXT/ICSIplus\"\n",
    "ROOT_DIR_AMI = \"/Users/haileywu/Desktop/W266_project/data/AMI_manual/ami_public\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Dev, Test Split\n",
    "\n",
    "based on https://bitbucket.org/dascim/acl2018_abssumm/src/master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ami_test_set = [\n",
    "    'ES2004a',\n",
    "    'ES2004b',\n",
    "    'ES2004c',\n",
    "    'ES2004d',\n",
    "    'ES2014a',\n",
    "    'ES2014b',\n",
    "    'ES2014c',\n",
    "    'ES2014d',\n",
    "    'IS1009a',\n",
    "    'IS1009b',\n",
    "    'IS1009c',\n",
    "    'IS1009d',\n",
    "    'TS3003a',\n",
    "    'TS3003b',\n",
    "    'TS3003c',\n",
    "    'TS3003d',\n",
    "    'TS3007a',\n",
    "    'TS3007b',\n",
    "    'TS3007c',\n",
    "    'TS3007d'\n",
    "]\n",
    "\n",
    "ami_development_set = [\n",
    "    'ES2005b',\n",
    "    'ES2005d',\n",
    "    'ES2007b',\n",
    "    'ES2008a',\n",
    "    'ES2008d',\n",
    "    'ES2015d',\n",
    "    'IS1003c',\n",
    "    'IS1004c',\n",
    "    'IS1006b',\n",
    "    'IS1006d',\n",
    "    'TS3004c',\n",
    "    'TS3005d',\n",
    "    'TS3006c',\n",
    "    'TS3008b',\n",
    "    'TS3011a',\n",
    "\n",
    "    'ES2005a',\n",
    "    'ES2005c',\n",
    "    'ES2007a',\n",
    "    'ES2007c',\n",
    "    'ES2007d',\n",
    "    'ES2008b',\n",
    "    'ES2008c',\n",
    "    'ES2015a',\n",
    "    'ES2015b',\n",
    "    'ES2015c',\n",
    "    'IS1003a',\n",
    "#    'IS1003b',\n",
    "    'IS1003d',\n",
    "    'IS1004a',\n",
    "    'IS1004b',\n",
    "    'IS1004d',\n",
    "    'IS1006a',\n",
    "    'IS1006c',\n",
    "    'TS3004a',\n",
    "    'TS3004b',\n",
    "    'TS3004d',\n",
    "    'TS3005a',\n",
    "    'TS3005b',\n",
    "    'TS3005c',\n",
    "    'TS3006a',\n",
    "    'TS3006b',\n",
    "    'TS3006d',\n",
    "    'TS3008a',\n",
    "    'TS3008c',\n",
    "    'TS3008d',\n",
    "    'TS3011b',\n",
    "    'TS3011c',\n",
    "    'TS3011d'\n",
    "]\n",
    "\n",
    "icsi_test_set = [\n",
    "    'Bed004',\n",
    "    'Bed009',\n",
    "    'Bed016',\n",
    "    'Bmr005',\n",
    "    'Bmr019',\n",
    "    'Bro018'\n",
    "]\n",
    "\n",
    "icsi_development_set = [\n",
    "    'Bed003',\n",
    "    'Bed006',\n",
    "    'Bed011',\n",
    "    'Bed014',\n",
    "    'Bed015',\n",
    "    'Bed017',\n",
    "    'Bmr013',\n",
    "    'Bmr014',\n",
    "    'Bmr015',\n",
    "    'Bmr020',\n",
    "    'Bro023',\n",
    "    'Bro024',\n",
    "    'Bro025',\n",
    "    'Bro026',\n",
    "    'Bro027',\n",
    "\n",
    "    'Bed002',\n",
    "    'Bed005',\n",
    "    'Bed008',\n",
    "    'Bed010',\n",
    "    'Bed012',\n",
    "    'Bed013',\n",
    "    'Bmr003',\n",
    "    'Bmr006',\n",
    "    'Bmr007',\n",
    "    'Bmr018',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract words\n",
    "\n",
    "__1__) meeting id -> ordered dict of word id: word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "meeting_dict_ICSI = dict() # key = meeting, value = ordered dict of word id: word\n",
    "cur_word = None\n",
    "for word_f in sorted(glob.glob(ROOT_DIR_ICSI+\"/Words/*xml\")):\n",
    "    m = word_f.split(\"/\")[-1].split(\".\")\n",
    "    meeting_name = m[0]+\".\"+m[1]\n",
    "    root = et.parse(word_f).getroot()\n",
    "    nodes = root.findall('*')\n",
    "    meet_words = OrderedDict()\n",
    "\n",
    "    for node in nodes:\n",
    "        if node.tag=='w':\n",
    "            meet_words[node.attrib['{http://nite.sourceforge.net/}id']] = node.text\n",
    "            cur_word = node.text\n",
    "        for w in node.values():\n",
    "            if \"disfmarker\" in w or \"pause\" in w or \"vocalsound\" in w:\n",
    "                meet_words [node.attrib['{http://nite.sourceforge.net/}id']] = None\n",
    "    meeting_dict_ICSI[meeting_name] = meet_words\n",
    "    \n",
    "#meeting_dict_ICSI['Bdb001.D']['Bdb001.w.2,391']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meeting_dict_ICSI['Bdb001.D']['Bdb001.w.2,391']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meeting_dict_AMI = dict() # key = meeting, value = ordered dict of word id: word\n",
    "cur_word = None\n",
    "for word_f in sorted(glob.glob(ROOT_DIR_AMI+\"/words/*xml\")):\n",
    "    m = word_f.split(\"/\")[-1].split(\".\")\n",
    "    meeting_name = m[0]+\".\"+m[1]\n",
    "    root = et.parse(word_f).getroot()\n",
    "    nodes = root.findall('*')\n",
    "    meet_words = OrderedDict()\n",
    "\n",
    "    for node in nodes:\n",
    "        if node.tag=='w':\n",
    "            meet_words[node.attrib['{http://nite.sourceforge.net/}id']] = node.text\n",
    "            cur_word = node.text\n",
    "        else:\n",
    "            meet_words [node.attrib['{http://nite.sourceforge.net/}id']] = None\n",
    "               \n",
    "    meeting_dict_AMI[meeting_name] = meet_words\n",
    "    \n",
    "#meeting_dict_AMI['EN2001a.A']['EN2001a.A.words0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meeting_dict_AMI['EN2001a.A']['EN2001a.A.words0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(meeting, meetingtype, start=None, end=None):\n",
    "    ret = \"\"\n",
    "    include = False\n",
    "    if start is None:\n",
    "        include = True\n",
    "    if meetingtype == \"AMI\":\n",
    "        for meet_word in meeting_dict_AMI[meeting].keys():\n",
    "\n",
    "            if start is not None and meet_word == start:\n",
    "                include = True\n",
    "            if include:\n",
    "                if meeting_dict_AMI[meeting][meet_word] is not None:\n",
    "                    ret += meeting_dict_AMI[meeting][meet_word] + \" \"\n",
    "            if end is not None and meet_word == end:\n",
    "                include = False\n",
    "        return ret\n",
    "    elif meetingtype == \"ICSI\":\n",
    "        for meet_word in meeting_dict_ICSI[meeting].keys():\n",
    "\n",
    "            if start is not None and meet_word == start:\n",
    "                include = True\n",
    "            if include:\n",
    "                if meeting_dict_ICSI[meeting][meet_word] is not None:\n",
    "                    ret += meeting_dict_ICSI[meeting][meet_word] + \" \"\n",
    "            if end is not None and meet_word == end:\n",
    "                include = False\n",
    "        return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"So you 're essentially defining a lattice . Yeah . How - how Oh , that 's \""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_words('Bdb001.A', \"ICSI\", \"Bdb001.w.915\", \"Bdb001.disfmarker.49\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay . '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_words('EN2001a.A',\"AMI\",'EN2001a.A.words0','EN2001a.A.words1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Dialogues\n",
    "\n",
    "__2__) meeting id -> ordered dict of dialog id -> tuple of (start, end) word ids that form a dialog. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "meeting_dialogues_ICSI = dict() # key = meeting name, value = ordered dict of dialog id -> List of (start, end, SummaryFlag) word ids that form a dialog. \n",
    "for dialog_f in sorted(glob.glob(ROOT_DIR_ICSI+\"/DialogueActs/*acts.xml\")):\n",
    "    m = dialog_f.split(\"/\")[-1].split(\".\")\n",
    "    meeting_name = m[0]+\".\"+m[1]\n",
    "    root = et.parse(dialog_f).getroot()\n",
    "    dlist = root.findall('dialogueact')\n",
    "    for dl in dlist:\n",
    "        nodes = dl.findall(\"{http://nite.sourceforge.net/}child\")\n",
    "        dialog_id = dl.attrib['{http://nite.sourceforge.net/}id']\n",
    "\n",
    "        for dl_c in nodes:\n",
    "            words = dl_c.attrib['href']\n",
    "            words = words.split(\"#\")[1]\n",
    "            try:\n",
    "                start, end = words.split(\"..\")\n",
    "                start, end = start.replace(\"id\", \"\"), end.replace(\"id\", \"\")\n",
    "                start, end = start.replace(\"(\", \"\"), end.replace(\"(\", \"\")\n",
    "                start, end = start.replace(\")\", \"\"), end.replace(\")\", \"\")\n",
    "            except:\n",
    "                start = end = words.replace(\"id\", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "            if meeting_name not in meeting_dialogues_ICSI:\n",
    "                meeting_dialogues_ICSI[meeting_name] = OrderedDict()\n",
    "            meeting_dialogues_ICSI[meeting_name][dialog_id] = [start, end, None]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bdb001.w.691', 'Bdb001.w.700', None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meeting_dialogues_ICSI['Bdb001.A']['Bdb001.A.dialogueact74']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "meeting_dialogues_AMI = dict() # key = meeting name, value = ordered dict of dialog id -> List of (start, end, SummaryFlag) word ids that form a dialog. \n",
    "for dialog_f in sorted(glob.glob(ROOT_DIR_AMI+\"/DialogueActs/*act.xml\")):\n",
    "    m = dialog_f.split(\"/\")[-1].split(\".\")\n",
    "    meeting_name = m[0]+\".\"+m[1]\n",
    "    root = et.parse(dialog_f).getroot()\n",
    "    dlist = root.findall('dact')\n",
    "    for dl in dlist:\n",
    "        nodes = dl.findall(\"{http://nite.sourceforge.net/}child\")\n",
    "        dialog_id = dl.attrib['{http://nite.sourceforge.net/}id']\n",
    "\n",
    "        for dl_c in nodes:\n",
    "            words = dl_c.attrib['href']\n",
    "            words = words.split(\"#\")[1]\n",
    "            try:\n",
    "                start, end = words.split(\"..\")\n",
    "                start, end = start.replace(\"id\", \"\"), end.replace(\"id\", \"\")\n",
    "                start, end = start.replace(\"(\", \"\"), end.replace(\"(\", \"\")\n",
    "                start, end = start.replace(\")\", \"\"), end.replace(\")\", \"\")\n",
    "            except:\n",
    "                start = end = words.replace(\"id\", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "            if meeting_name not in meeting_dialogues_AMI:\n",
    "                meeting_dialogues_AMI[meeting_name] = OrderedDict()\n",
    "            meeting_dialogues_AMI[meeting_name][dialog_id] = [start, end, None]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ES2002a.A.words0', 'ES2002a.A.words12', None]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meeting_dialogues_AMI['ES2002a.A']['ES2002a.A.dialog-act.dharshi.1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extractive summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3__) meeting id -> set of dialog ids that belong to extractive summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_starts_ICSI, summary_ends_ICSI = set(),set() # key = meeting name, list (2) of set of Dialogue starts and ends\n",
    "\n",
    "for dialog_f in sorted(glob.glob(ROOT_DIR_ICSI+\"/Contributions/Summarization/extractive/*extsumm.xml\")):\n",
    "    m = dialog_f.split(\"/\")[-1].split(\".\")\n",
    "    meeting_name = m[0]+\".\"+m[1]\n",
    "    root = et.parse(dialog_f).getroot()\n",
    "    dlist = root.findall('extsumm/{http://nite.sourceforge.net/}child')\n",
    "    for dl in dlist:\n",
    "        dialogs = dl.attrib['href']\n",
    "        dialogs = dialogs.split(\"#\")[1]\n",
    "        start = end = None\n",
    "        try:\n",
    "            start, end = dialogs.split(\"..\")\n",
    "            start, end = start.replace(\"id\", \"\"), end.replace(\"id\", \"\")\n",
    "            start, end = start.replace(\"(\", \"\"), end.replace(\"(\", \"\")\n",
    "            start, end = start.replace(\")\", \"\"), end.replace(\")\", \"\")\n",
    "        except:\n",
    "            start = end = dialogs.replace(\"id\", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        summary_starts_ICSI.add(start)\n",
    "        summary_ends_ICSI.add(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_starts_AMI, summary_ends_AMI = set(),set() # key = meeting name, list (2) of set of Dialogue starts and ends\n",
    "\n",
    "for dialog_f in sorted(glob.glob(ROOT_DIR_AMI+\"/extractive/*extsumm.xml\")):\n",
    "    m = dialog_f.split(\"/\")[-1].split(\".\")\n",
    "    meeting_name = m[0]+\".\"+m[1]\n",
    "    root = et.parse(dialog_f).getroot()\n",
    "    dlist = root.findall('extsumm/{http://nite.sourceforge.net/}child')\n",
    "    for dl in dlist:\n",
    "        dialogs = dl.attrib['href']\n",
    "        dialogs = dialogs.split(\"#\")[1]\n",
    "        start = end = None\n",
    "        try:\n",
    "            start, end = dialogs.split(\"..\")\n",
    "            start, end = start.replace(\"id\", \"\"), end.replace(\"id\", \"\")\n",
    "            start, end = start.replace(\"(\", \"\"), end.replace(\"(\", \"\")\n",
    "            start, end = start.replace(\")\", \"\"), end.replace(\")\", \"\")\n",
    "        except:\n",
    "            start = end = dialogs.replace(\"id\", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        summary_starts_AMI.add(start)\n",
    "        summary_ends_AMI.add(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def extract_dialogues(meeting, meetingtype):\n",
    "    # loop through all the meetings and (optionally) return only the ones that fall in range of starts/ends\n",
    "    ret = []\n",
    "    include = False\n",
    "    if meetingtype == \"AMI\":\n",
    "        dialogues = meeting_dialogues_AMI[meeting]\n",
    "        for dialog, (start_w, end_w, _) in dialogues.items():\n",
    "            if dialog in summary_starts_AMI:\n",
    "                include = True\n",
    "            if include:\n",
    "                ret.append((dialog, start_w, end_w, get_words(meeting, meetingtype, start_w, end_w), True))\n",
    "                meeting_dialogues_AMI[meeting][dialog][2] = True\n",
    "            else:\n",
    "                ret.append((dialog, start_w, end_w, get_words(meeting, meetingtype, start_w, end_w), False))\n",
    "                meeting_dialogues_AMI[meeting][dialog][2] = False\n",
    "            if dialog in summary_ends_AMI:\n",
    "                include = False\n",
    "        return ret\n",
    "\n",
    "    elif meetingtype == \"ICSI\":\n",
    "        dialogues = meeting_dialogues_ICSI[meeting]\n",
    "        for dialog, (start_w, end_w, _) in dialogues.items():\n",
    "            if dialog in summary_starts_ICSI:\n",
    "                include = True\n",
    "            if include:\n",
    "                ret.append((dialog, start_w, end_w, get_words(meeting, meetingtype, start_w, end_w), True))\n",
    "                meeting_dialogues_ICSI[meeting][dialog][2] = True\n",
    "            else:\n",
    "                ret.append((dialog, start_w, end_w, get_words(meeting, meetingtype, start_w, end_w), False))\n",
    "                meeting_dialogues_ICSI[meeting][dialog][2] = False\n",
    "            if dialog in summary_ends_ICSI:\n",
    "                include = False\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bed009.G.dialogueact1133',\n",
       "  'Bed009.w.9,951',\n",
       "  'Bed009.w.9,955',\n",
       "  'Is it i in , ',\n",
       "  False),\n",
       " ('Bed009.G.dialogueact1134',\n",
       "  'Bed009.w.9,956',\n",
       "  'Bed009.w.9,966',\n",
       "  'then , your place , in five five - A ? ',\n",
       "  False)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_dialogues('Bed009.G',\"ICSI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ES2004a.A.dialog-act.s9553330.1',\n",
       "  'ES2004a.A.words0',\n",
       "  'ES2004a.A.words3',\n",
       "  'Hmm hmm hmm . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.2',\n",
       "  'ES2004a.A.words4',\n",
       "  'ES2004a.A.words5',\n",
       "  'Yeah . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.3',\n",
       "  'ES2004a.A.words6',\n",
       "  'ES2004a.A.words12',\n",
       "  'Okay . Yep , yep . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.4',\n",
       "  'ES2004a.A.words13',\n",
       "  'ES2004a.A.words14',\n",
       "  'Okay . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.5',\n",
       "  'ES2004a.A.words15',\n",
       "  'ES2004a.A.words18',\n",
       "  'Tu tu tu tu ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.6',\n",
       "  'ES2004a.A.words19',\n",
       "  'ES2004a.A.words23',\n",
       "  'Hi , good morning . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.7',\n",
       "  'ES2004a.A.words24',\n",
       "  'ES2004a.A.words25',\n",
       "  \"'Kay . \",\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.8',\n",
       "  'ES2004a.A.words26',\n",
       "  'ES2004a.A.words26',\n",
       "  '',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.9',\n",
       "  'ES2004a.A.words27',\n",
       "  'ES2004a.A.words28',\n",
       "  'Oops . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.10',\n",
       "  'ES2004a.A.words29',\n",
       "  'ES2004a.A.words30',\n",
       "  'Mm . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.11',\n",
       "  'ES2004a.A.words31',\n",
       "  'ES2004a.A.words33',\n",
       "  'Oh sorry . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.12',\n",
       "  'ES2004a.A.words34',\n",
       "  'ES2004a.A.words35',\n",
       "  'Mm-hmm . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.13',\n",
       "  'ES2004a.A.words36',\n",
       "  'ES2004a.A.words39',\n",
       "  'Yeah , me . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.14',\n",
       "  'ES2004a.A.words40',\n",
       "  'ES2004a.A.words42',\n",
       "  'Cat . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.15',\n",
       "  'ES2004a.A.words43',\n",
       "  'ES2004a.A.words48',\n",
       "  'Where did this come from ? ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.16',\n",
       "  'ES2004a.A.words49',\n",
       "  'ES2004a.A.words52',\n",
       "  'Uh , yep . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.17',\n",
       "  'ES2004a.A.words53',\n",
       "  'ES2004a.A.words55',\n",
       "  'Thank you . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.18',\n",
       "  'ES2004a.A.words56',\n",
       "  'ES2004a.A.words67',\n",
       "  \"Uh , maybe you can guess what I'm trying to make ? \",\n",
       "  True),\n",
       " ('ES2004a.A.dialog-act.s9553330.19',\n",
       "  'ES2004a.A.words68',\n",
       "  'ES2004a.A.words69',\n",
       "  'Yep . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.20',\n",
       "  'ES2004a.A.words70',\n",
       "  'ES2004a.A.words75',\n",
       "  \"It's actually sitting , so \",\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.21',\n",
       "  'ES2004a.A.words76',\n",
       "  'ES2004a.A.words82',\n",
       "  \"it's sitting , it's not standing . \",\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.22',\n",
       "  'ES2004a.A.words83',\n",
       "  'ES2004a.A.words94',\n",
       "  \"Okay , I see it as one thing it's very supportive . \",\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.23',\n",
       "  'ES2004a.A.words95',\n",
       "  'ES2004a.A.words98',\n",
       "  \"It's your best friend \",\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.24',\n",
       "  'ES2004a.A.words99',\n",
       "  'ES2004a.A.words108',\n",
       "  'and your you can talk to a dog , ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.25',\n",
       "  'ES2004a.A.words109',\n",
       "  'ES2004a.A.words115',\n",
       "  'it can be your best friend , ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.26',\n",
       "  'ES2004a.A.words116',\n",
       "  'ES2004a.A.words127',\n",
       "  \"it doesn't discriminate between you , based on what you are . \",\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.27',\n",
       "  'ES2004a.A.words128',\n",
       "  'ES2004a.A.words130',\n",
       "  \"Second it's loyal \",\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.28',\n",
       "  'ES2004a.A.words131',\n",
       "  'ES2004a.A.words137',\n",
       "  \"and third thing it's got intuition . \",\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.29',\n",
       "  'ES2004a.A.words138',\n",
       "  'ES2004a.A.words151',\n",
       "  'dogs can som sometimes can make out between a thief and a person ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.30',\n",
       "  'ES2004a.A.words152',\n",
       "  'ES2004a.A.words166',\n",
       "  'so basically these are the three unique features I think belong to a dog . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.31',\n",
       "  'ES2004a.A.words167',\n",
       "  'ES2004a.A.words169',\n",
       "  'Thank you . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.32',\n",
       "  'ES2004a.A.words170',\n",
       "  'ES2004a.A.words171',\n",
       "  'Okay . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.33',\n",
       "  'ES2004a.A.words172',\n",
       "  'ES2004a.A.words173',\n",
       "  'Sorry . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.34',\n",
       "  'ES2004a.A.words174',\n",
       "  'ES2004a.A.words182',\n",
       "  'Does it look like a dog actually ? ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.35',\n",
       "  'ES2004a.A.words183',\n",
       "  'ES2004a.A.words184',\n",
       "  'Mm . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.36',\n",
       "  'ES2004a.A.words185',\n",
       "  'ES2004a.A.words185',\n",
       "  '',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.37',\n",
       "  'ES2004a.A.words186',\n",
       "  'ES2004a.A.words189',\n",
       "  'Eagle , okay . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.38',\n",
       "  'ES2004a.A.words190',\n",
       "  'ES2004a.A.words197',\n",
       "  'One point four or something like that . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.39',\n",
       "  'ES2004a.A.words198',\n",
       "  'ES2004a.A.words210',\n",
       "  'One point four Euro would make a Pound or something like that . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.40',\n",
       "  'ES2004a.A.words211',\n",
       "  'ES2004a.A.words212',\n",
       "  'Yeah . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.41',\n",
       "  'ES2004a.A.words213',\n",
       "  'ES2004a.A.words214',\n",
       "  'Okay , ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.42',\n",
       "  'ES2004a.A.words215',\n",
       "  'ES2004a.A.words218',\n",
       "  'pretty huge margin . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.43',\n",
       "  'ES2004a.A.words219',\n",
       "  'ES2004a.A.words221',\n",
       "  'So then ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.44',\n",
       "  'ES2004a.A.words222',\n",
       "  'ES2004a.A.words223',\n",
       "  'Mm-hmm . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.45',\n",
       "  'ES2004a.A.words224',\n",
       "  'ES2004a.A.words225',\n",
       "  'Yeah , ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.46',\n",
       "  'ES2004a.A.words226',\n",
       "  'ES2004a.A.words227',\n",
       "  'that c ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.47',\n",
       "  'ES2004a.A.words228',\n",
       "  'ES2004a.A.words229',\n",
       "  'Okay , ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.48',\n",
       "  'ES2004a.A.words230',\n",
       "  'ES2004a.A.words237',\n",
       "  'you wanna integrate everything into one like ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.49',\n",
       "  'ES2004a.A.words238',\n",
       "  'ES2004a.A.words239',\n",
       "  'Okay . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.50',\n",
       "  'ES2004a.A.words240',\n",
       "  'ES2004a.A.words248',\n",
       "  'So simplification of symbols you could think of . ',\n",
       "  True),\n",
       " ('ES2004a.A.dialog-act.s9553330.52',\n",
       "  'ES2004a.A.words249',\n",
       "  'ES2004a.A.words250',\n",
       "  'Mm-hmm . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.51',\n",
       "  'ES2004a.A.words251',\n",
       "  'ES2004a.A.words254',\n",
       "  'Menu , alright . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.53',\n",
       "  'ES2004a.A.words255',\n",
       "  'ES2004a.A.words257',\n",
       "  'Uh uh ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.54',\n",
       "  'ES2004a.A.words258',\n",
       "  'ES2004a.A.words259',\n",
       "  'Right , ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.55',\n",
       "  'ES2004a.A.words260',\n",
       "  'ES2004a.A.words268',\n",
       "  'I was thinking on the same lines you , ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.56',\n",
       "  'ES2004a.A.words269',\n",
       "  'ES2004a.A.words296',\n",
       "  'instead of having too many b buttons and make it complicated for the user , may h maybe have an L_C_D_ di display or something like that , ',\n",
       "  True),\n",
       " ('ES2004a.A.dialog-act.s9553330.57',\n",
       "  'ES2004a.A.words297',\n",
       "  'ES2004a.A.words305',\n",
       "  'like a mobile , yeah and with menus . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.58',\n",
       "  'ES2004a.A.words306',\n",
       "  'ES2004a.A.words331',\n",
       "  \"And if it's s somewhat similar to what you have on mobile phone , people might find it easier to browse and navigate also maybe . \",\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.59',\n",
       "  'ES2004a.A.words332',\n",
       "  'ES2004a.A.words340',\n",
       "  'You mean to save it lesser number . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.60',\n",
       "  'ES2004a.A.words341',\n",
       "  'ES2004a.A.words342',\n",
       "  'Right . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.61',\n",
       "  'ES2004a.A.words343',\n",
       "  'ES2004a.A.words344',\n",
       "  'Mm-hmm . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.62',\n",
       "  'ES2004a.A.words345',\n",
       "  'ES2004a.A.words346',\n",
       "  'Okay . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.65',\n",
       "  'ES2004a.A.words347',\n",
       "  'ES2004a.A.words350',\n",
       "  'Mm , okay . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.64',\n",
       "  'ES2004a.A.words351',\n",
       "  'ES2004a.A.words351',\n",
       "  'S ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.63',\n",
       "  'ES2004a.A.words352',\n",
       "  'ES2004a.A.words353',\n",
       "  'It might ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.66',\n",
       "  'ES2004a.A.words354',\n",
       "  'ES2004a.A.words362',\n",
       "  'it might save a b bit of space , ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.67',\n",
       "  'ES2004a.A.words363',\n",
       "  'ES2004a.A.words374',\n",
       "  \"it's i instead of looking bulky , it might look small . \",\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.68',\n",
       "  'ES2004a.A.words375',\n",
       "  'ES2004a.A.words382',\n",
       "  'But it might have its cost implications . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.69',\n",
       "  'ES2004a.A.words383',\n",
       "  'ES2004a.A.words384',\n",
       "  'Right . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.70',\n",
       "  'ES2004a.A.words385',\n",
       "  'ES2004a.A.words386',\n",
       "  'Okay . ',\n",
       "  False),\n",
       " ('ES2004a.A.dialog-act.s9553330.71',\n",
       "  'ES2004a.A.words387',\n",
       "  'ES2004a.A.words390',\n",
       "  'Mm , yeah . ',\n",
       "  False)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_dialogues('ES2004a.A', \"AMI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstractive Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the dictionary abstractive_summary[sentenceid]\n",
    "as_dict_ICSI = dict()\n",
    "for sum_f in sorted(glob.glob(ROOT_DIR_ICSI+\"/Contributions/Summarization/abstractive/*abssumm.xml\")):\n",
    "    m = sum_f.split(\"/\")[-1].split(\".\")\n",
    "    meeting_name = m[0]\n",
    "    root = et.parse(sum_f).getroot()\n",
    "    dlist = root.findall('abstract/sentence')\n",
    "    # getting the abstractive summary sentences only in the abstractive summary\n",
    "    # excluding question and progress part\n",
    "    for dl in dlist:\n",
    "        sentenceid = dl.attrib[\"{http://nite.sourceforge.net/}id\"]\n",
    "        if meeting_name not in as_dict_ICSI:\n",
    "            as_dict_ICSI[meeting_name]= OrderedDict()\n",
    "        as_dict_ICSI[meeting_name][sentenceid] = dl.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the dictionary abstractive_summary[sentenceid]\n",
    "as_dict_AMI = dict()\n",
    "for sum_f in sorted(glob.glob(ROOT_DIR_AMI+\"/abstractive/*abssumm.xml\")):\n",
    "    m = sum_f.split(\"/\")[-1].split(\".\")\n",
    "    meeting_name = m[0]\n",
    "    root = et.parse(sum_f).getroot()\n",
    "    dlist = root.findall('abstract/sentence')\n",
    "    # getting the abstractive summary sentences only in the abstractive summary\n",
    "    # excluding question and progress part\n",
    "    for dl in dlist:\n",
    "        sentenceid = dl.attrib[\"{http://nite.sourceforge.net/}id\"]\n",
    "        if meeting_name not in as_dict_AMI:\n",
    "            as_dict_AMI[meeting_name]= OrderedDict()\n",
    "        as_dict_AMI[meeting_name][sentenceid] = dl.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstractive Summary and Extractive Summary Link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ICSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the relationship between extractive and abstractive \n",
    "# summary_links[extractive_sentence_id] = abstractive_sentence_id\n",
    "summary_links_ICSI = dict()\n",
    "for summary_link in sorted(glob.glob(ROOT_DIR_ICSI+\"/Contributions/Summarization/extractive/*summlink.xml\")):\n",
    "    m = summary_link.split(\"/\")[-1].split(\".\")\n",
    "    meeting_name = m[0]\n",
    "    root = et.parse(summary_link).getroot()\n",
    "    dlist = root.findall('summlink')\n",
    "    for dl in dlist:\n",
    "        #d = dl.findall('{http://nite.sourceforge.net/}pointer')\n",
    "        for d in dl: \n",
    "            if d.attrib['role'] == 'abstractive':\n",
    "                abstractive_sentence_id = d.attrib['href'].split(\"(\")[1].split(\")\")[0]\n",
    "                #abstractive_meeting_id = abstractive_sentence_id.split(\".\")[0]\n",
    "            elif d.attrib['role']=='extractive': \n",
    "                extractive_sentence_id = d.attrib['href'].split(\"(\")[1].split(\")\")[0]\n",
    "                #extractive_meeting_id = extractive_sentence_id.split(\".\")[0] + \".\" + extractive_sentence_id.split(\".\")[1]  \n",
    "        if meeting_name not in summary_links_ICSI:\n",
    "            summary_links_ICSI[meeting_name]= defaultdict(set)\n",
    "        summary_links_ICSI[meeting_name][extractive_sentence_id].add(abstractive_sentence_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two main options were discussed as to the organisation of the collected data.\n"
     ]
    }
   ],
   "source": [
    "s1 = summary_links_ICSI['Bdb001']['Bdb001.F.dialogueact37']\n",
    "for i in s1:\n",
    "    print(as_dict_ICSI['Bdb001'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the relationship between extractive and abstractive \n",
    "# summary_links[extractive_sentence_id] = abstractive_sentence_id\n",
    "summary_links_AMI = dict()\n",
    "for summary_link in sorted(glob.glob(ROOT_DIR_AMI+\"/extractive/*summlink.xml\")):\n",
    "    m = summary_link.split(\"/\")[-1].split(\".\")\n",
    "    meeting_name = m[0]\n",
    "    root = et.parse(summary_link).getroot()\n",
    "    dlist = root.findall('summlink')\n",
    "    for dl in dlist:\n",
    "        #d = dl.findall('{http://nite.sourceforge.net/}pointer')\n",
    "        for d in dl: \n",
    "            if d.attrib['role'] == 'abstractive':\n",
    "                abstractive_sentence_id = d.attrib['href'].split(\"(\")[1].split(\")\")[0]\n",
    "                #abstractive_meeting_id = abstractive_sentence_id.split(\".\")[0]\n",
    "            elif d.attrib['role']=='extractive': \n",
    "                extractive_sentence_id = d.attrib['href'].split(\"(\")[1].split(\")\")[0]\n",
    "                #extractive_meeting_id = extractive_sentence_id.split(\".\")[0] + \".\" + extractive_sentence_id.split(\".\")[1]  \n",
    "        if meeting_name not in summary_links_AMI:\n",
    "            summary_links_AMI[meeting_name]= defaultdict(set)\n",
    "        summary_links_AMI[meeting_name][extractive_sentence_id].add(abstractive_sentence_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text(text, stopwords, remove_stopwords=True, pos_filtering=False, stemming=True, lower_case=True):\n",
    "#     if lower_case:\n",
    "#         # convert to lower case\n",
    "#         text = text.lower()\n",
    "#     # strip extra white space\n",
    "#     text = re.sub(' +', ' ', text)\n",
    "#     # strip leading and trailing white space\n",
    "#     text = text.strip()\n",
    "#     # tokenize (split based on whitespace)\n",
    "#     tokens = text.split(' ')\n",
    "\n",
    "#     # remove punctuation\n",
    "#     tokens = [t for t in tokens if t not in string.punctuation]\n",
    "\n",
    "#     if pos_filtering:\n",
    "#         tagger = PerceptronTagger()\n",
    "#         # apply POS-tagging\n",
    "#         tagged_tokens = tagger.tag(tokens)\n",
    "#         # retain only nouns and adjectives\n",
    "#         tokens = [item[0] for item in tagged_tokens if item[1] in ['NN', 'NNS', 'NNP', 'NNPS', 'JJ', 'JJS', 'JJR', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']]\n",
    "#     if remove_stopwords:\n",
    "#         # remove stopwords\n",
    "#         tokens = [token for token in tokens if token.lower() not in stopwords]\n",
    "#     if stemming:\n",
    "#         # http://people.scs.carleton.ca/~armyunis/projects/KAPI/porter.pdf\n",
    "#         stemmer = nltk.stem.PorterStemmer()\n",
    "#         # apply Porter's stemmer\n",
    "#         tokens_stemmed = list()\n",
    "#         for token in tokens:\n",
    "#             tokens_stemmed.append(stemmer.stem(token))\n",
    "#         tokens = tokens_stemmed\n",
    "\n",
    "#     return (tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopwords(path):\n",
    "    stopwords = set([])\n",
    "\n",
    "    for line in codecs.open(path, 'r', 'utf-8'):\n",
    "        if not re.search('^#', line) and len(line.strip()) > 0:\n",
    "            stopwords.add(line.strip().lower())  # lowercase\n",
    "\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filler_words(path):\n",
    "    with open(path, 'r+') as f:\n",
    "        filler = f.read().splitlines()\n",
    "\n",
    "    return filler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_utterance(utterance, filler_words):\n",
    "    utt = utterance\n",
    "    # replace consecutive unigrams with a single instance\n",
    "    utt = re.sub('\\\\b(\\\\w+)\\\\s+\\\\1\\\\b', '\\\\1', utt)\n",
    "    # same for bigrams\n",
    "    utt = re.sub('(\\\\b.+?\\\\b)\\\\1\\\\b', '\\\\1', utt)\n",
    "    # strip extra white space\n",
    "    utt = re.sub(' +', ' ', utt)\n",
    "    # strip leading and trailing white space\n",
    "    utt = utt.strip()\n",
    "\n",
    "    # remove filler words # highly time-consuming\n",
    "    utt = ' ' + utt + ' '\n",
    "    for filler_word in filler_words:\n",
    "        utt = re.sub(' ' + filler_word + ' '+ '.'+ ' ', ' ', utt)\n",
    "        utt = re.sub(' ' + filler_word + ' '+ ','+ ' ', ' ', utt)\n",
    "        utt = re.sub(' ' + filler_word + ' '+ '?'+ ' ', ' ', utt)\n",
    "        utt = re.sub(' ' + filler_word + ' ', ' ', utt) \n",
    "        #utt = re.sub(' ' + filler_word.capitalize() + ' ', ' ', utt)\n",
    "\n",
    "    return utt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_ami_icsi(diag, filler_words):\n",
    "#     asr_output = pd.read_csv(\n",
    "#         path,\n",
    "#         sep='\\t',\n",
    "#         header=None,\n",
    "#         names=['ID', 'start', 'end', 'letter', 'role', 'A', 'B', 'C', 'utt']\n",
    "#     )\n",
    "    utt = diag\n",
    "    utterances = []\n",
    "#     for tmp in zip(asr_output['role'].tolist(), asr_output['utt'].tolist()):\n",
    "#         role, utt = tmp\n",
    "#         # lower case\n",
    "    utt = str(utt).lower()\n",
    "\n",
    "    # remove special tag\n",
    "    for ch in ['{nonvocalsound}','{vocalsound}', '{gap}', '{disfmarker}', '{comment}', '{pause}', '@reject@']:\n",
    "        utt = re.sub(ch, '', utt)\n",
    "\n",
    "    utt = re.sub(\"'Kay\", 'okay', utt)\n",
    "    utt = re.sub(\"'kay\", 'okay', utt)\n",
    "    utt = re.sub('\"Okay\"', 'okay', utt)\n",
    "    utt = re.sub(\"'cause\", 'cause', utt)\n",
    "    utt = re.sub(\"'Cause\", 'cause', utt)\n",
    "    utt = re.sub('\"cause\"', 'cause', utt)\n",
    "    utt = re.sub('\"\\'em\"', 'them', utt)\n",
    "    utt = re.sub('\"\\'til\"', 'until', utt)\n",
    "    utt = re.sub('\"\\'s\"', 's', utt)\n",
    "    utt = re.sub('\"\\\"', \"\" , utt)\n",
    "    utt = re.sub(\"-\", ' ', utt)\n",
    "    # l. c. d. -> lcd\n",
    "    # t. v. -> tv\n",
    "    utt = re.sub('h. t. m. l.', 'html', utt)\n",
    "    utt = re.sub(r\"(\\w)\\. (\\w)\\. (\\w)\\.\", r\"\\1\\2\\3\", utt)\n",
    "    utt = re.sub(r\"(\\w)\\. (\\w)\\.\", r\"\\1\\2\", utt)\n",
    "    utt = re.sub(r\"(\\w)\\.\", r\"\\1\", utt)\n",
    "\n",
    "    # clean_utterance, remove filler_words\n",
    "    utt = clean_utterance(utt, filler_words=filler_words)\n",
    "\n",
    "    # strip extra white space\n",
    "    utt = re.sub(' +', ' ', utt)\n",
    "    # strip leading and trailing white space\n",
    "    utt = utt.strip()\n",
    "\n",
    "    if not re.match(r'^[_\\W]+$', utt) and utt != '':\n",
    "    #if utt != '' and utt != '.' and utt != ' ' and utt!= \"?\" and utt!= \",\" and :\n",
    "        utterances.append(utt)\n",
    "    if len(utterances)>0:\n",
    "    # remove duplicate utterances per speaker\n",
    "        utterances = sorted(set(utterances), key=utterances.index)[0]\n",
    "        result = str(utterances)\n",
    "    else:\n",
    "        result = \"\"\n",
    "    #utterances_indexed = list(zip(range(len(utterances)), list(zip(*utterances))[0], list(zip(*utterances))[1]))\n",
    "    #list(zip(*utterances))[1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR_UTILS = \"/Users/haileywu/Desktop/W266_project/data/utils/\"\n",
    "filler_words = load_filler_words(ROOT_DIR_UTILS+\"filler_words.less.txt\")\n",
    "#stopwords = load_stopwords(ROOT_DIR_UTILS+\"stopwords.en.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comma(utterance_indexed):\n",
    "    #utterances_processed = []\n",
    "#    for utterance_indexed in rst:\n",
    "        # remove the comma at the beginning\n",
    "    if len(utterance_indexed) >0:\n",
    "        if utterance_indexed[0] == \",\" or utterance_indexed[0] == \".\" :\n",
    "            utt_cleaned = utterance_indexed[2:]  \n",
    "        else:\n",
    "            utt_cleaned = utterance_indexed\n",
    "        #print(utt_cleaned)\n",
    "        #utterances_processed.append(utt_cleaned)\n",
    "    else:\n",
    "        utt_cleaned = \"\"\n",
    "    return utt_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_words = 3\n",
    "# utterances_processed =[]\n",
    "# for utterance_indexed in list(rst):\n",
    "#     index,role,utt = utterance_indexed\n",
    "#     utt_cleaned = clean_text(\n",
    "#         utt,\n",
    "#         stopwords=stopwords,\n",
    "#         remove_stopwords=True,\n",
    "#         pos_filtering=False,\n",
    "#         stemming=False,\n",
    "#         # clustering based on lowercase form.\n",
    "#         lower_case=True\n",
    "#     )\n",
    "#     if len(utt_cleaned) >= min_words:\n",
    "#         utterances_processed.append((index, role, ' '.join(utt_cleaned)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Okay . Yep , yep . Okay . Tu tu tu tu Hi , good morning . 'Kay . Oops . Mm . Oh sorry . Mm-hmm . Yeah , me . Cat . Where did this come from ? Uh , yep . Thank you . Uh , maybe you can guess what I'm trying to make ? Yep . It's actually sitting , so it's sitting , it's not standing . Okay , I see it as one thing it's very supportive . It's your best friend and your you can talk to a dog , it can be your best friend , it doesn't discriminate between you , based on what you are . Second it's loyal and third thing it's got intuition . dogs can som sometimes can make out between a thief and a person so basically these are the three unique features I think belong to a dog . Thank you . Okay . Sorry . Does it look like a dog actually ? Mm . Eagle , okay . One point four or something like that . One point four Euro would make a Pound or something like that . Yeah . Okay , pretty huge margin . So then Mm-hmm . Yeah , that c Okay , you wanna integrate everything into one like Okay . So simplification of symbols you could think of . Mm-hmm . Menu , alright . Uh uh Right , I was thinking on the same lines you , instead of having too many b buttons and make it complicated for the user , may h maybe have an L_C_D_ di display or something like that , like a mobile , yeah and with menus . And if it's s somewhat similar to what you have on mobile phone , people might find it easier to browse and navigate also maybe . You mean to save it lesser number . Right . Mm-hmm . Okay . Mm , okay . S It might it might save a b bit of space , it's i instead of looking bulky , it might look small . But it might have its cost implications . Right . Okay . Mm , yeah . \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Okay . Yep , yep . Okay . Tu tu tu tu Hi , good morning . 'Kay . Oops . Mm . Oh sorry . Mm-hmm . Yeah , me . Cat . Where did this come from ? Uh , yep . Thank you . Uh , maybe you can guess what I'm trying to make ? Yep . It's actually sitting , so it's sitting , it's not standing . Okay , I see it as one thing it's very supportive . It's your best friend and your you can talk to a dog , it can be your best friend , it doesn't discriminate between you , based on what you are . Second it's loyal and third thing it's got intuition . dogs can som sometimes can make out between a thief and a person so basically these are the three unique features I think belong to a dog . Thank you . Okay . Sorry . Does it look like a dog actually ? Mm . Eagle , okay . One point four or something like that . One point four Euro would make a Pound or something like that . Yeah . Okay , pretty huge margin . So then Mm-hmm . Yeah , that c Okay , you wanna integrate everything into one like Okay . So simplification of symbols you could think of . Mm-hmm . Menu , alright . Uh uh Right , I was thinking on the same lines you , instead of having too many b buttons and make it complicated for the user , may h maybe have an L_C_D_ di display or something like that , like a mobile , yeah and with menus . And if it's s somewhat similar to what you have on mobile phone , people might find it easier to browse and navigate also maybe . You mean to save it lesser number . Right . Mm-hmm . Okay . Mm , okay . S It might it might save a b bit of space , it's i instead of looking bulky , it might look small . But it might have its cost implications . Right . Okay . Mm , yeah .  \n"
     ]
    }
   ],
   "source": [
    "print(\" \"+test+\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"tu hi , good morning . me . cat . where did this come from ? you can guess what i'm trying to make ? it's actually sitting , it's sitting , it's not standing . i see it as one thing it's very supportive . it's your best friend and your you can talk to a dog , it can be your best friend , it doesn't discriminate between you , based on what you are . second it's loyal and third thing it's got intuition . dogs can som sometimes can make out between a thief and a person these are the three unique features belong to a dog . does it look like a dog actually ? eagle , one point four like that . one point four euro would make a pound like that . pretty huge margin . then that c you wanna integrate everything into one like simplification of symbols you could think of . menu , alright . right , i was thinking on the same lines you , instead of having too many b buttons and make it complicated for the user , may h have an l_c_d_ di display like that , like a mobile , and with menus . and if it's somewhat similar to what you have on mobile phone , people might find it easier to browse and navigate also to save it lesser number . right . s it might save a b bit of space , it's i instead of looking bulky , it might look small . but it might have its cost implications . right .\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = read_ami_icsi(test, filler_words)\n",
    "clean_comma(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Documents\n",
    "\n",
    "The saving will also require a file directory as:\n",
    "\n",
    "* `data/ICSI_plus_NXT/Full_doc/Dev`, \n",
    "* `data/ICSI_plus_NXT/Full_doc/Train`, \n",
    "* `data/ICSI_plus_NXT/Full_doc/Test`,\n",
    "* `data/AMI_manual/Full_doc/Dev`,\n",
    "* `data/AMI_manual/Full_doc/Test`,\n",
    "* `data/AMI_manual/Full_doc/Train`\n",
    "\n",
    "\n",
    "The dataset is split on the speaker (turn) level, meaning for each hour of the meeting (e.g.ES2004a), the saving will have ES2004a.A, ES2004a.B, etc. The abstractive summary is on the meeting level (e.g. ES2004a)\n",
    "\n",
    "If you would like to have another format, e.g. two columns in csv file, use the dictionaries created previously to build your output.\n",
    "\n",
    "Dictionary List:\n",
    "\n",
    "* `meeting_dialogues_ICSI[meeting_name][dialog_id] = [start, end, T/F]`\n",
    "* `meeting_dialogues_AMI[meeting_name][dialog_id] = [start, end, T/F]`\n",
    "\n",
    "* `as_dict_ICSI[meeting_name][sentenceid] = abstractive_summary_sentence`\n",
    "* `as_dict_AMI[meeting_name][sentenceid] = abstractive_summary_sentence`\n",
    "\n",
    "* `summary_links_ICSI[meeting_name][extractive_sentence_id] = abstractive_sentence_id`\n",
    "* `summary_links_AMI[meeting_name][extractive_sentence_id] = abstractive_sentence_id`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save less stop words, common words \n",
    "\n",
    "same format as the next chunk, but with cleaning of the data itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ICSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "with open(\"../data/ICSI_plus_NXT/data_cleansing/ICSI_1024_test_cleaned.csv\", mode='w') as csv_file:\n",
    "    # ctext is the orginal text, while text is the extractive summary\n",
    "    fieldnames = ['meeting','original','extractive','abstractive']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for meeting in meeting_dialogues_ICSI.keys():\n",
    "        meetingid = meeting.split(\".\")[0] \n",
    "        #Bdb001\n",
    "        if meetingid in icsi_test_set:\n",
    "            original_text = \"\"\n",
    "            extractive_summary = \"\"\n",
    "            abstractive_summary = \"\"\n",
    "            # make sure each abstractive sentence appears only once\n",
    "            abstractive_existing = set()\n",
    "            links = summary_links_ICSI.get(meetingid,{})\n",
    "            this_as_dict = as_dict_ICSI.get(meetingid,{})\n",
    "            paragraph_count = 0\n",
    "            for diag_id, _, _, diag, summ_flag in extract_dialogues(meeting, \"ICSI\"):\n",
    "                # cleaning words \n",
    "                #print(diag)\n",
    "                diag = read_ami_icsi(diag, filler_words)\n",
    "                diag = clean_comma(diag)\n",
    "                #print(diag)\n",
    "                # if the count of original text words are more than x, then write the row and move to the next\n",
    "                diag_word_count = len(diag.split())\n",
    "                if diag_word_count + paragraph_count > 1024:\n",
    "                    writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})\n",
    "                    original_text = \"\"\n",
    "                    extractive_summary = \"\"\n",
    "                    abstractive_summary = \"\"\n",
    "                    abstractive_existing = set()  # uniqueness of abstractive sentences per row\n",
    "                    paragraph_count = 0\n",
    "\n",
    "                # add extractive summary\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "\n",
    "                # add abstractive summary\n",
    "                if diag_id in links.keys():\n",
    "                    abstractive_id=links[diag_id]\n",
    "                    for ai in abstractive_id:\n",
    "                        if ai not in abstractive_existing and ai in this_as_dict.keys():\n",
    "                            abstractive_summary += as_dict_ICSI[meetingid][ai] + \" \"\n",
    "                            abstractive_existing.add(ai)\n",
    "\n",
    "                # add the original text\n",
    "                original_text+=diag + \" \"\n",
    "                # increase the original text word counts\n",
    "                paragraph_count += diag_word_count\n",
    "\n",
    "            # write to the row when one meeting ends \n",
    "            writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "with open(\"../data/ICSI_plus_NXT/data_cleansing/ICSI_1024_dev_cleaned.csv\", mode='w') as csv_file:\n",
    "    # ctext is the orginal text, while text is the extractive summary\n",
    "    fieldnames = ['meeting','original','extractive','abstractive']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for meeting in meeting_dialogues_ICSI.keys():\n",
    "        meetingid = meeting.split(\".\")[0] \n",
    "        #Bdb001\n",
    "        if meetingid in icsi_development_set:\n",
    "            original_text = \"\"\n",
    "            extractive_summary = \"\"\n",
    "            abstractive_summary = \"\"\n",
    "            # make sure each abstractive sentence appears only once\n",
    "            abstractive_existing = set()\n",
    "            links = summary_links_ICSI.get(meetingid,{})\n",
    "            this_as_dict = as_dict_ICSI.get(meetingid,{})\n",
    "            paragraph_count = 0\n",
    "            for diag_id, _, _, diag, summ_flag in extract_dialogues(meeting, \"ICSI\"):\n",
    "                diag = read_ami_icsi(diag, filler_words)\n",
    "                diag = clean_comma(diag)\n",
    "                # if the count of original text words are more than x, then write the row and move to the next\n",
    "                diag_word_count = len(diag.split())\n",
    "                if diag_word_count + paragraph_count > 1024:\n",
    "                    writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})\n",
    "                    original_text = \"\"\n",
    "                    extractive_summary = \"\"\n",
    "                    abstractive_summary = \"\"\n",
    "                    abstractive_existing = set()  # uniqueness of abstractive sentences per row\n",
    "                    paragraph_count = 0\n",
    "\n",
    "                # add extractive summary\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "\n",
    "                # add abstractive summary\n",
    "                if diag_id in links.keys():\n",
    "                    abstractive_id=links[diag_id]\n",
    "                    for ai in abstractive_id:\n",
    "                        if ai not in abstractive_existing and ai in this_as_dict.keys():\n",
    "                            abstractive_summary += as_dict_ICSI[meetingid][ai] + \" \"\n",
    "                            abstractive_existing.add(ai)\n",
    "\n",
    "                # add the original text\n",
    "                original_text+=diag + \" \"\n",
    "                # increase the original text word counts\n",
    "                paragraph_count += diag_word_count\n",
    "\n",
    "            # write to the row when one meeting ends \n",
    "            writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "with open(\"../data/ICSI_plus_NXT/data_cleansing/ICSI_512_train_cleaned.csv\", mode='w') as csv_file:\n",
    "    # ctext is the orginal text, while text is the extractive summary\n",
    "    fieldnames = ['meeting','original','extractive','abstractive']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for meeting in meeting_dialogues_ICSI.keys():\n",
    "        meetingid = meeting.split(\".\")[0] \n",
    "        #Bdb001\n",
    "        if meetingid not in icsi_development_set and meetingid not in icsi_test_set:\n",
    "            original_text = \"\"\n",
    "            extractive_summary = \"\"\n",
    "            abstractive_summary = \"\"\n",
    "            # make sure each abstractive sentence appears only once\n",
    "            abstractive_existing = set()\n",
    "            links = summary_links_ICSI.get(meetingid,{})\n",
    "            this_as_dict = as_dict_ICSI.get(meetingid,{})\n",
    "            paragraph_count = 0\n",
    "            for diag_id, _, _, diag, summ_flag in extract_dialogues(meeting, \"ICSI\"):\n",
    "                diag = read_ami_icsi(diag, filler_words)\n",
    "                diag = clean_comma(diag)\n",
    "                # if the count of original text words are more than 512, then write the row and move to the next\n",
    "                diag_word_count = len(diag.split())\n",
    "                if diag_word_count + paragraph_count > 512:\n",
    "                    writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})\n",
    "                    original_text = \"\"\n",
    "                    extractive_summary = \"\"\n",
    "                    abstractive_summary = \"\"\n",
    "                    abstractive_existing = set()  # uniqueness of abstractive sentences per row\n",
    "                    paragraph_count = 0\n",
    "\n",
    "                # add extractive summary\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "\n",
    "                # add abstractive summary\n",
    "                if diag_id in links.keys():\n",
    "                    abstractive_id=links[diag_id]\n",
    "                    for ai in abstractive_id:\n",
    "                        if ai not in abstractive_existing and ai in this_as_dict.keys():\n",
    "                            abstractive_summary += as_dict_ICSI[meetingid][ai] + \" \"\n",
    "                            abstractive_existing.add(ai)\n",
    "\n",
    "                # add the original text\n",
    "                original_text+=diag + \" \"\n",
    "                # increase the original text word counts\n",
    "                paragraph_count += diag_word_count\n",
    "\n",
    "            # write to the row when one meeting ends \n",
    "            writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "with open(\"../data/AMI_manual/data_cleansing/AMI_1024_test_cleaned.csv\", mode='w') as csv_file:\n",
    "    # ctext is the orginal text, while text is the extractive summary\n",
    "    fieldnames = ['meeting','original','extractive','abstractive']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for meeting in meeting_dialogues_AMI.keys():\n",
    "        meetingid = meeting.split(\".\")[0] \n",
    "        #Bdb001\n",
    "        if meetingid in ami_test_set:\n",
    "            original_text = \"\"\n",
    "            extractive_summary = \"\"\n",
    "            abstractive_summary = \"\"\n",
    "            # make sure each abstractive sentence appears only once\n",
    "            abstractive_existing = set()\n",
    "            links = summary_links_AMI.get(meetingid,{})\n",
    "            this_as_dict = as_dict_AMI.get(meetingid,{})\n",
    "            paragraph_count = 0\n",
    "            for diag_id, _, _, diag, summ_flag in extract_dialogues(meeting, \"AMI\"):\n",
    "                diag = read_ami_icsi(diag, filler_words)\n",
    "                diag = clean_comma(diag)\n",
    "                # if the count of original text words are more than x, then write the row and move to the next\n",
    "                diag_word_count = len(diag.split())\n",
    "                if diag_word_count + paragraph_count > 1024:\n",
    "                    writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})\n",
    "                    original_text = \"\"\n",
    "                    extractive_summary = \"\"\n",
    "                    abstractive_summary = \"\"\n",
    "                    abstractive_existing = set()  # uniqueness of abstractive sentences per row\n",
    "                    paragraph_count = 0\n",
    "\n",
    "                # add extractive summary\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "\n",
    "                # add abstractive summary\n",
    "                if diag_id in links.keys():\n",
    "                    abstractive_id=links[diag_id]\n",
    "                    for ai in abstractive_id:\n",
    "                        if ai not in abstractive_existing and ai in this_as_dict.keys():\n",
    "                            abstractive_summary += as_dict_AMI[meetingid][ai] + \" \"\n",
    "                            abstractive_existing.add(ai)\n",
    "\n",
    "                # add the original text\n",
    "                original_text+=diag + \" \"\n",
    "                # increase the original text word counts\n",
    "                paragraph_count += diag_word_count\n",
    "\n",
    "            # write to the row when one meeting ends \n",
    "            writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      242\n",
       "1      538\n",
       "2      540\n",
       "3      158\n",
       "4       93\n",
       "      ... \n",
       "744    536\n",
       "745    426\n",
       "746    547\n",
       "747    578\n",
       "749    601\n",
       "Name: original, Length: 670, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/AMI_manual/data_cleansing/AMI_512_train_cleaned.csv\")\n",
    "print(len(df))\n",
    "\n",
    "df[df['abstractive'].notna()]['original'].apply(lambda x: x.split(\" \")).map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"inbetween now and then , as the industrial designer , you're gonna be working on the actual working design of it what you're doing there . for user interface , technical functions , that's like what we've been talking about , what it'll actually do . and marketing executive , you'll be just thinking about what it actually what , what requirements it has to fulfil and you'll all get instructions emailed to you ,  it's th the functional design stage is next ,  and and that's the end of the meeting . got that little message a lot sooner than would ,   th  just very quickly this we're supposed to finish now . guess that's up to us , you probably want some unique selling point of it ,      right , we'll that's the end of the meeting , then .  all for coming . \""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['original'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        533\n",
       "2         94\n",
       "3         66\n",
       "4       1474\n",
       "5        179\n",
       "        ... \n",
       "9298     517\n",
       "9326      98\n",
       "9333      21\n",
       "9337      47\n",
       "9359      17\n",
       "Name: original, Length: 2846, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"../data/AMI_manual/T5_csv/AMI_512_train.csv\")\n",
    "df2[df2['abstractive'].notna()]['original'].apply(lambda x: x.split(\" \")).map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"so we're designing a new remote control and um Oh I have to record who's here actually . So that's David , Andrew and Craig , isn't it ? And you all arrived on time . Um yeah so des uh design a new remote control . Um , as you can see it's supposed to be original , trendy and user friendly . Um so that's kind of our our brief , as it were . Um and so there are three different stages to the design . Um I'm not really sure what what you guys have already received um in your emails . What did you get ? Mm-hmm . Is that what everybody got ? Okay . Um . So we're gonna have like individual work and then a meeting about it . And repeat that process three times . Um and at this point we get try out the whiteboard over there . Um . So uh you get to draw your favourite animal and sum up your favourite characteristics of it . So who would like to go first ? Very good . Mm-hmm . Yeah . Yeah . Right . Lovely . Right . You can take as long over this as you like , because we haven't got an awful lot to discuss . Ok oh we do we do . Don't feel like you're in a rush , anyway . Ach why not We might have to get you up again then . I don't know what mine is . I'm gonna have to think on the spot now . Is that a whale ? Ah . Okay . God , I still don't know what I'm gonna write about . Um . I was gonna choose a dog as well . But I'll just draw a different kind of dog . M my favourite animal is my own dog at home . Um That doesn't really look like him , actually . He looks more like a pig , actually . Ah well . Do you ? Oh that's very good of you . Uh . Um he's a mixture of uh various things . Um and what do I like about him , um That's just to suggest that his tail wags . Um he's very friendly and cheery and always pleased to see you , and very kind of affectionate and um uh and he's quite quite wee as well so you know he can doesn't take up too much space . Um and uh And he does a funny thing where he chases his tail as well , which is quite amusing , so It is . I think it is . He only does it after he's had his dinner and um he'll just all of a sudden just get up and start chasing his tail 'round the living room . Yeah , so uh Yeah , maybe . Maybe . Right , um where did you find this ? Just down here ? Yeah . Okay . Um what are we doing next ? Uh um . Okay , uh we now need to discuss the project finance . Um so according to the brief um we're gonna be selling this remote control for twenty five Euro , um and we're aiming to make fifty million Euro . Um so we're gonna be selling this on an international scale . And uh we don't want it to cost any more than uh twelve fifty Euros , so fifty percent of the selling price . Sure . All together . Um I dunno . I imagine That's a good question . I imagine it probably is our sale actually because it's probably up to the the um the retailer to uh sell it for whatever price they want . Um . But I I don't know , I mean do you think the fact that it's going to be sold internationally will have a bearing on how we design it at all ? Think it will ? Um . Hmm . Oh yeah , regions and stuff , yeah . Yeah . Okay . Yeah . Well for a remote control , do you think that will be I suppose it's depends on how complicated our remote control is . Yeah , yeah . Okay . What , just like in terms of like the wealth of the country ? Like how much money people have to spend on things like ? Aye , I see what you mean , yeah . Marketing . Good marketing thoughts . Oh gosh , I should be writing all this down . Um . Mm . Yeah . Yeah , yeah . Like how much does , you know , a remote control cost . Well twenty five Euro , I mean that's um that's about like eighteen pounds or something , isn't it ? Or no , is it as much as that ? Sixteen seventeen eighteen pounds . Um , I dunno , I've never bought a remote control , so I don't know how how good a remote control that would get you . Um . But yeah , I suppose it has to look kind of cool and gimmicky . Um right , okay . Let me just scoot on ahead here . Okay . Um well d Does anybody have anything to add to uh to the finance issue at all ? Thin No , actually . That would be useful , though , wouldn't it , if you knew like what your money would get you now . Mm-hmm . Yeah , yeah . Oh . Five minutes to end of meeting . Oh , okay . We're a bit behind . Yeah . Right , so do you think that should be like a main design aim of our remote control d you know , do your your satellite and your regular telly and your V_C_R_ and everything ? Mm-hmm . Yeah . Or even like , you know , notes about um what you wanna watch . Like you might put in there oh I want to watch such and such and look a Oh that's a good idea . So extra functionalities . Mm-hmm . Hmm . Um okay , uh I'd wel we're gonna have to wrap up pretty quickly in the next couple of minutes . Um I'll just check we've nothing else . Okay . Um so anything else anybody wants to add about what they don't like about remote controls they've used , what they would really like to be part of this new one at all ? You keep losing them . Okay . Yeah . W You get those ones where you can , if you like , whistle or make a really high pitched noise they beep . There I mean is that something we'd want to include , do you think ? Dunno . Okay maybe . My goodness . Still feels quite primitive . Maybe like a touch screen or something ? Okay . Uh-huh , okay . Well I guess that's up to our industrial designer . It looks better . Yeah . Okay . Okay . Right , well um so just to wrap up , the next meeting's gonna be in thirty minutes . So that's about um about ten to twelve by my watch . Um so inbetween now and then , um as the industrial designer , you're gonna be working on you know the actual working design of it so y you know what you're doing there . Um for user interface , technical functions , I guess that's you know like what we've been talking about , what it'll actually do . Um and uh marketing executive , you'll be just thinking about what it actually what , you know , what requirements it has to has to fulfil and you'll all get instructions emailed to you , I guess . Um . Yeah , so it's th the functional design stage is next , I guess . And uh and that's the end of the meeting . So I got that little message a lot sooner than I thought I would , so Mm-hmm . Uh-huh , yeah . Th Okay , well just very quickly 'cause this we're supposed to finish now . Um I guess that's up to us , I mean you probably want some kind of unique selling point of it , so um , you know Yeah . Mm-hmm . Yeah . Okay . Right , okay , we'll that's that's the end of the meeting , then . Um . So , uh thank you all for coming .  \""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['original'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "with open(\"../data/AMI_manual/data_cleansing/AMI_1024_dev_cleaned.csv\", mode='w') as csv_file:\n",
    "    # ctext is the orginal text, while text is the extractive summary\n",
    "    fieldnames = ['meeting','original','extractive','abstractive']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for meeting in meeting_dialogues_AMI.keys():\n",
    "        meetingid = meeting.split(\".\")[0] \n",
    "        #Bdb001\n",
    "        if meetingid in ami_development_set:\n",
    "            original_text = \"\"\n",
    "            extractive_summary = \"\"\n",
    "            abstractive_summary = \"\"\n",
    "            # make sure each abstractive sentence appears only once\n",
    "            abstractive_existing = set()\n",
    "            links = summary_links_AMI.get(meetingid,{})\n",
    "            this_as_dict = as_dict_AMI.get(meetingid,{})\n",
    "            paragraph_count = 0\n",
    "            for diag_id, _, _, diag, summ_flag in extract_dialogues(meeting, \"AMI\"):\n",
    "                diag = read_ami_icsi(diag, filler_words)\n",
    "                diag = clean_comma(diag)\n",
    "                # if the count of original text words are more than 512, then write the row and move to the next\n",
    "                diag_word_count = len(diag.split())\n",
    "                if diag_word_count + paragraph_count > 1024:\n",
    "                    writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})\n",
    "                    original_text = \"\"\n",
    "                    extractive_summary = \"\"\n",
    "                    abstractive_summary = \"\"\n",
    "                    abstractive_existing = set()  # uniqueness of abstractive sentences per row\n",
    "                    paragraph_count = 0\n",
    "\n",
    "                # add extractive summary\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "\n",
    "                # add abstractive summary\n",
    "                if diag_id in links.keys():\n",
    "                    abstractive_id=links[diag_id]\n",
    "                    for ai in abstractive_id:\n",
    "                        if ai not in abstractive_existing and ai in this_as_dict.keys():\n",
    "                            abstractive_summary += as_dict_AMI[meetingid][ai] + \" \"\n",
    "                            abstractive_existing.add(ai)\n",
    "\n",
    "                # add the original text\n",
    "                original_text+=diag + \" \"\n",
    "                # increase the original text word counts\n",
    "                paragraph_count += diag_word_count\n",
    "\n",
    "            # write to the row when one meeting ends \n",
    "            writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "with open(\"../data/AMI_manual/data_cleansing/AMI_1024_train_cleaned.csv\", mode='w') as csv_file:\n",
    "    # ctext is the orginal text, while text is the extractive summary\n",
    "    fieldnames = ['meeting','original','extractive','abstractive']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for meeting in meeting_dialogues_AMI.keys():\n",
    "        meetingid = meeting.split(\".\")[0] \n",
    "        #Bdb001\n",
    "        if meetingid not in ami_development_set and meetingid not in ami_test_set:\n",
    "            original_text = \"\"\n",
    "            extractive_summary = \"\"\n",
    "            abstractive_summary = \"\"\n",
    "            # make sure each abstractive sentence appears only once\n",
    "            abstractive_existing = set()\n",
    "            links = summary_links_AMI.get(meetingid,{})\n",
    "            this_as_dict = as_dict_AMI.get(meetingid,{})\n",
    "            paragraph_count = 0\n",
    "            for diag_id, _, _, diag, summ_flag in extract_dialogues(meeting, \"AMI\"):\n",
    "                diag = read_ami_icsi(diag, filler_words)\n",
    "                diag = clean_comma(diag)\n",
    "                # if the count of original text words are more than 1024, then write the row and move to the next\n",
    "                diag_word_count = len(diag.split())\n",
    "                if diag_word_count + paragraph_count > 1024:\n",
    "                    writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})\n",
    "                    original_text = \"\"\n",
    "                    extractive_summary = \"\"\n",
    "                    abstractive_summary = \"\"\n",
    "                    abstractive_existing = set()  # uniqueness of abstractive sentences per row\n",
    "                    paragraph_count = 0\n",
    "\n",
    "                # add extractive summary\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "\n",
    "                # add abstractive summary\n",
    "                if diag_id in links.keys():\n",
    "                    abstractive_id=links[diag_id]\n",
    "                    for ai in abstractive_id:\n",
    "                        if ai not in abstractive_existing and ai in this_as_dict.keys():\n",
    "                            abstractive_summary += as_dict_AMI[meetingid][ai] + \" \"\n",
    "                            abstractive_existing.add(ai)\n",
    "\n",
    "                # add the original text\n",
    "                original_text+=diag + \" \"\n",
    "                # increase the original text word counts\n",
    "                paragraph_count += diag_word_count\n",
    "\n",
    "            # write to the row when one meeting ends \n",
    "            writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Original, Extractive, Abstractive in X tokens\n",
    "\n",
    "* *ICSI_512_train.csv*\n",
    "* *ICSI_512_dev.csv*\n",
    "* *ICSI_512_test.csv*\n",
    "\n",
    "* *AMI_512_train.csv*\n",
    "* *AMI_512_dev.csv*\n",
    "* *AMI_512_test.csv*\n",
    "\n",
    "* *ICSI_1024_train.csv*\n",
    "* *ICSI_1024_dev.csv*\n",
    "* *ICSI_1024_test.csv*\n",
    "\n",
    "* *AMI_1024_train.csv*\n",
    "* *AMI_1024_dev.csv*\n",
    "* *AMI_1024_test.csv*\n",
    "\n",
    "Columns: 'meeting','original','extractive','abstractive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ICSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "with open(\"../data/ICSI_plus_NXT/T5_csv/ICSI_1024_test.csv\", mode='w') as csv_file:\n",
    "    # ctext is the orginal text, while text is the extractive summary\n",
    "    fieldnames = ['meeting','original','extractive','abstractive']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for meeting in meeting_dialogues_ICSI.keys():\n",
    "        meetingid = meeting.split(\".\")[0] \n",
    "        #Bdb001\n",
    "        if meetingid in icsi_test_set:\n",
    "            original_text = \"\"\n",
    "            extractive_summary = \"\"\n",
    "            abstractive_summary = \"\"\n",
    "            # make sure each abstractive sentence appears only once\n",
    "            abstractive_existing = set()\n",
    "            links = summary_links_ICSI.get(meetingid,{})\n",
    "            this_as_dict = as_dict_ICSI.get(meetingid,{})\n",
    "            paragraph_count = 0\n",
    "            for diag_id, _, _, diag, summ_flag in extract_dialogues(meeting, \"ICSI\"):\n",
    "\n",
    "                # if the count of original text words are more than x, then write the row and move to the next\n",
    "                diag_word_count = len(diag.split())\n",
    "                if diag_word_count + paragraph_count > 1024:\n",
    "                    writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})\n",
    "                    original_text = \"\"\n",
    "                    extractive_summary = \"\"\n",
    "                    abstractive_summary = \"\"\n",
    "                    abstractive_existing = set()  # uniqueness of abstractive sentences per row\n",
    "                    paragraph_count = 0\n",
    "\n",
    "                # add extractive summary\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "\n",
    "                # add abstractive summary\n",
    "                if diag_id in links.keys():\n",
    "                    abstractive_id=links[diag_id]\n",
    "                    for ai in abstractive_id:\n",
    "                        if ai not in abstractive_existing and ai in this_as_dict.keys():\n",
    "                            abstractive_summary += as_dict_ICSI[meetingid][ai] + \" \"\n",
    "                            abstractive_existing.add(ai)\n",
    "\n",
    "                # add the original text\n",
    "                original_text+=diag + \" \"\n",
    "                # increase the original text word counts\n",
    "                paragraph_count += diag_word_count\n",
    "\n",
    "            # write to the row when one meeting ends \n",
    "            writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bed004.A\n",
      "It is not a working net yet, but identifying clusters of features that define the output mode provides a visual aid for further work. \n",
      "So , what I did for this this is uh , a pedagogical belief - net  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/ICSI_plus_NXT/T5_csv/ICSI_512_test.csv\")\n",
    "print(df.meeting[0])\n",
    "#print(df.original[0])\n",
    "print(df.abstractive[0])\n",
    "print(df.extractive[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'Bro027.B.dialogueact18': {'Bro027.s.14'},\n",
       "             'Bro027.B.dialogueact25': {'Bro027.s.14'},\n",
       "             'Bro027.B.dialogueact26': {'Bro027.s.14'},\n",
       "             'Bro027.B.dialogueact39': {'Bro027.s.4'},\n",
       "             'Bro027.B.dialogueact40': {'Bro027.s.4'},\n",
       "             'Bro027.B.dialogueact42': {'Bro027.s.4'},\n",
       "             'Bro027.B.dialogueact95': {'Bro027.s.4'},\n",
       "             'Bro027.B.dialogueact96': {'Bro027.s.4'},\n",
       "             'Bro027.B.dialogueact185': {'Bro027.s.4'},\n",
       "             'Bro027.A.dialogueact243': {'Bro027.s.15'},\n",
       "             'Bro027.A.dialogueact245': {'Bro027.s.15'},\n",
       "             'Bro027.A.dialogueact247': {'Bro027.s.15'},\n",
       "             'Bro027.A.dialogueact248': {'Bro027.s.15'},\n",
       "             'Bro027.A.dialogueact251': {'Bro027.s.15'},\n",
       "             'Bro027.A.dialogueact252': {'Bro027.s.15'},\n",
       "             'Bro027.A.dialogueact253': {'Bro027.s.15'},\n",
       "             'Bro027.A.dialogueact256': {'Bro027.s.15'},\n",
       "             'Bro027.A.dialogueact257': {'Bro027.s.15'},\n",
       "             'Bro027.B.dialogueact280': {'Bro027.s.6', 'Bro027.s.8'},\n",
       "             'Bro027.A.dialogueact283': {'Bro027.s.6'},\n",
       "             'Bro027.A.dialogueact288': {'Bro027.s.6'},\n",
       "             'Bro027.B.dialogueact292': {'Bro027.s.6', 'Bro027.s.8'},\n",
       "             'Bro027.D.dialogueact300': {'Bro027.s.8'},\n",
       "             'Bro027.D.dialogueact303': {'Bro027.s.8'},\n",
       "             'Bro027.B.dialogueact333': {'Bro027.s.8'},\n",
       "             'Bro027.B.dialogueact338': {'Bro027.s.8'},\n",
       "             'Bro027.C.dialogueact417': {'Bro027.s.12', 'Bro027.s.2'},\n",
       "             'Bro027.C.dialogueact418': {'Bro027.s.12', 'Bro027.s.2'},\n",
       "             'Bro027.C.dialogueact419': {'Bro027.s.12'},\n",
       "             'Bro027.C.dialogueact423': {'Bro027.s.12'},\n",
       "             'Bro027.D.dialogueact428': {'Bro027.s.12'},\n",
       "             'Bro027.C.dialogueact460': {'Bro027.s.12'},\n",
       "             'Bro027.C.dialogueact465': {'Bro027.s.12'},\n",
       "             'Bro027.B.dialogueact466': {'Bro027.s.12'},\n",
       "             'Bro027.C.dialogueact472': {'Bro027.s.9'},\n",
       "             'Bro027.C.dialogueact476': {'Bro027.s.9'},\n",
       "             'Bro027.C.dialogueact603': {'Bro027.s.3'},\n",
       "             'Bro027.A.dialogueact605': {'Bro027.s.3'},\n",
       "             'Bro027.A.dialogueact608': {'Bro027.s.3'},\n",
       "             'Bro027.B.dialogueact615': {'Bro027.s.3'},\n",
       "             'Bro027.B.dialogueact618': {'Bro027.s.3'},\n",
       "             'Bro027.C.dialogueact623': {'Bro027.s.3'},\n",
       "             'Bro027.A.dialogueact641': {'Bro027.s.9'},\n",
       "             'Bro027.B.dialogueact643': {'Bro027.s.9'},\n",
       "             'Bro027.B.dialogueact644': {'Bro027.s.9'},\n",
       "             'Bro027.B.dialogueact647': {'Bro027.s.9'},\n",
       "             'Bro027.B.dialogueact648': {'Bro027.s.9'},\n",
       "             'Bro027.A.dialogueact649': {'Bro027.s.9'},\n",
       "             'Bro027.B.dialogueact652': {'Bro027.s.9'},\n",
       "             'Bro027.B.dialogueact657': {'Bro027.s.9'},\n",
       "             'Bro027.B.dialogueact711': {'Bro027.s.3'},\n",
       "             'Bro027.B.dialogueact713': {'Bro027.s.3'},\n",
       "             'Bro027.A.dialogueact720': {'Bro027.s.12'},\n",
       "             'Bro027.B.dialogueact721': {'Bro027.s.12'},\n",
       "             'Bro027.C.dialogueact724': {'Bro027.s.12'},\n",
       "             'Bro027.C.dialogueact823': {'Bro027.s.13'},\n",
       "             'Bro027.C.dialogueact825': {'Bro027.s.13'},\n",
       "             'Bro027.C.dialogueact828': {'Bro027.s.13'},\n",
       "             'Bro027.C.dialogueact831': {'Bro027.s.13'},\n",
       "             'Bro027.C.dialogueact857': {'Bro027.s.13'},\n",
       "             'Bro027.C.dialogueact858': {'Bro027.s.13'},\n",
       "             'Bro027.B.dialogueact866': {'Bro027.s.10', 'Bro027.s.13'},\n",
       "             'Bro027.C.dialogueact873': {'Bro027.s.10'},\n",
       "             'Bro027.B.dialogueact875': {'Bro027.s.10'},\n",
       "             'Bro027.B.dialogueact877': {'Bro027.s.10'},\n",
       "             'Bro027.C.dialogueact883': {'Bro027.s.10'},\n",
       "             'Bro027.A.dialogueact884': {'Bro027.s.10'},\n",
       "             'Bro027.C.dialogueact900': {'Bro027.s.10'},\n",
       "             'Bro027.C.dialogueact906': {'Bro027.s.10'},\n",
       "             'Bro027.C.dialogueact907': {'Bro027.s.10'},\n",
       "             'Bro027.C.dialogueact911': {'Bro027.s.10'},\n",
       "             'Bro027.B.dialogueact949': {'Bro027.s.3'},\n",
       "             'Bro027.C.dialogueact952': {'Bro027.s.3'},\n",
       "             'Bro027.C.dialogueact953': {'Bro027.s.3'},\n",
       "             'Bro027.B.dialogueact962': {'Bro027.s.3'},\n",
       "             'Bro027.B.dialogueact966': {'Bro027.s.3'},\n",
       "             'Bro027.B.dialogueact971': {'Bro027.s.3', 'Bro027.s.7'},\n",
       "             'Bro027.B.dialogueact973': {'Bro027.s.3', 'Bro027.s.7'},\n",
       "             'Bro027.B.dialogueact1042': {'Bro027.s.10'},\n",
       "             'Bro027.B.dialogueact1043': {'Bro027.s.10'},\n",
       "             'Bro027.B.dialogueact1049': {'Bro027.s.10'},\n",
       "             'Bro027.C.dialogueact1227': {'Bro027.s.11'},\n",
       "             'Bro027.C.dialogueact1228': {'Bro027.s.11'},\n",
       "             'Bro027.C.dialogueact1230': {'Bro027.s.11'},\n",
       "             'Bro027.C.dialogueact1231': {'Bro027.s.11'},\n",
       "             'Bro027.B.dialogueact1234': {'Bro027.s.11'},\n",
       "             'Bro027.A.dialogueact1236': {'Bro027.s.11'},\n",
       "             'Bro027.C.dialogueact1238': {'Bro027.s.11'},\n",
       "             'Bro027.B.dialogueact1245': {'Bro027.s.11'},\n",
       "             'Bro027.C.dialogueact1248': {'Bro027.s.11'},\n",
       "             'Bro027.B.dialogueact1249': {'Bro027.s.11'},\n",
       "             'Bro027.B.dialogueact1303': {'Bro027.s.7'},\n",
       "             'Bro027.C.dialogueact1307': {'Bro027.s.7'},\n",
       "             'Bro027.B.dialogueact1312': {'Bro027.s.7'},\n",
       "             'Bro027.C.dialogueact1315': {'Bro027.s.7'},\n",
       "             'Bro027.C.dialogueact1321': {'Bro027.s.7'},\n",
       "             'Bro027.B.dialogueact1323': {'Bro027.s.7'},\n",
       "             'Bro027.B.dialogueact1326': {'Bro027.s.7'},\n",
       "             'Bro027.B.dialogueact1327': {'Bro027.s.7'},\n",
       "             'Bro027.B.dialogueact1330': {'Bro027.s.7'},\n",
       "             'Bro027.B.dialogueact1332': {'Bro027.s.7'},\n",
       "             'Bro027.A.dialogueact1370': {'Bro027.s.3'},\n",
       "             'Bro027.A.dialogueact1371': {'Bro027.s.3'},\n",
       "             'Bro027.D.dialogueact1376': {'Bro027.s.3'},\n",
       "             'Bro027.D.dialogueact1377': {'Bro027.s.3'},\n",
       "             'Bro027.D.dialogueact1380': {'Bro027.s.3'},\n",
       "             'Bro027.D.dialogueact1387': {'Bro027.s.3'},\n",
       "             'Bro027.D.dialogueact1388': {'Bro027.s.3'},\n",
       "             'Bro027.D.dialogueact1391': {'Bro027.s.3'},\n",
       "             'Bro027.A.dialogueact1396': {'Bro027.s.3'},\n",
       "             'Bro027.C.dialogueact1404': {'Bro027.s.3'},\n",
       "             'Bro027.A.dialogueact1412': {'Bro027.s.3'},\n",
       "             'Bro027.A.dialogueact1420': {'Bro027.s.3'},\n",
       "             'Bro027.C.dialogueact1424': {'Bro027.s.3'},\n",
       "             'Bro027.C.dialogueact1427': {'Bro027.s.3'},\n",
       "             'Bro027.D.dialogueact1678': {'Bro027.s.3'},\n",
       "             'Bro027.D.dialogueact1679': {'Bro027.s.3'},\n",
       "             'Bro027.D.dialogueact1685': {'Bro027.s.3'},\n",
       "             'Bro027.D.dialogueact1687': {'Bro027.s.3'},\n",
       "             'Bro027.D.dialogueact1691': {'Bro027.s.3'},\n",
       "             'Bro027.D.dialogueact1693': {'Bro027.s.3'},\n",
       "             'Bro027.D.dialogueact1706': {'Bro027.s.3'},\n",
       "             'Bro027.A.dialogueact1720': {'Bro027.s.3'},\n",
       "             'Bro027.D.dialogueact1722': {'Bro027.s.3'},\n",
       "             'Bro027.B.dialogueact1728': {'Bro027.s.3'},\n",
       "             'Bro027.B.dialogueact1783': {'Bro027.s.11'},\n",
       "             'Bro027.B.dialogueact1784': {'Bro027.s.11'},\n",
       "             'Bro027.C.dialogueact1787': {'Bro027.s.11'},\n",
       "             'Bro027.C.dialogueact1788': {'Bro027.s.11'},\n",
       "             'Bro027.C.dialogueact1791': {'Bro027.s.11'},\n",
       "             'Bro027.B.dialogueact1960': {'Bro027.s.5'},\n",
       "             'Bro027.B.dialogueact1963': {'Bro027.s.5'},\n",
       "             'Bro027.B.dialogueact1975': {'Bro027.s.5'},\n",
       "             'Bro027.B.dialogueact1987': {'Bro027.s.5'},\n",
       "             'Bro027.B.dialogueact1988': {'Bro027.s.5'},\n",
       "             'Bro027.B.dialogueact1989': {'Bro027.s.5'},\n",
       "             'Bro027.B.dialogueact1991': {'Bro027.s.5'},\n",
       "             'Bro027.B.dialogueact2003': {'Bro027.s.5'},\n",
       "             'Bro027.B.dialogueact2010': {'Bro027.s.5'}})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_links_ICSI['Bro027']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The group discussed possible further investigations that arose from these areas, including better linking the two.\n"
     ]
    }
   ],
   "source": [
    "print(as_dict_ICSI['Bro027']['Bro027.s.3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "with open(\"../data/ICSI_plus_NXT/T5_csv/ICSI_1024_dev.csv\", mode='w') as csv_file:\n",
    "    # ctext is the orginal text, while text is the extractive summary\n",
    "    fieldnames = ['meeting','original','extractive','abstractive']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for meeting in meeting_dialogues_ICSI.keys():\n",
    "        meetingid = meeting.split(\".\")[0] \n",
    "        #Bdb001\n",
    "        if meetingid in icsi_development_set:\n",
    "            original_text = \"\"\n",
    "            extractive_summary = \"\"\n",
    "            abstractive_summary = \"\"\n",
    "            # make sure each abstractive sentence appears only once\n",
    "            abstractive_existing = set()\n",
    "            links = summary_links_ICSI.get(meetingid,{})\n",
    "            this_as_dict = as_dict_ICSI.get(meetingid,{})\n",
    "            paragraph_count = 0\n",
    "            for diag_id, _, _, diag, summ_flag in extract_dialogues(meeting, \"ICSI\"):\n",
    "\n",
    "                # if the count of original text words are more than x, then write the row and move to the next\n",
    "                diag_word_count = len(diag.split())\n",
    "                if diag_word_count + paragraph_count > 1024:\n",
    "                    writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})\n",
    "                    original_text = \"\"\n",
    "                    extractive_summary = \"\"\n",
    "                    abstractive_summary = \"\"\n",
    "                    abstractive_existing = set()  # uniqueness of abstractive sentences per row\n",
    "                    paragraph_count = 0\n",
    "\n",
    "                # add extractive summary\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "\n",
    "                # add abstractive summary\n",
    "                if diag_id in links.keys():\n",
    "                    abstractive_id=links[diag_id]\n",
    "                    for ai in abstractive_id:\n",
    "                        if ai not in abstractive_existing and ai in this_as_dict.keys():\n",
    "                            abstractive_summary += as_dict_ICSI[meetingid][ai] + \" \"\n",
    "                            abstractive_existing.add(ai)\n",
    "\n",
    "                # add the original text\n",
    "                original_text+=diag + \" \"\n",
    "                # increase the original text word counts\n",
    "                paragraph_count += diag_word_count\n",
    "\n",
    "            # write to the row when one meeting ends \n",
    "            writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "with open(\"../data/ICSI_plus_NXT/T5_csv/ICSI_1024_train.csv\", mode='w') as csv_file:\n",
    "    # ctext is the orginal text, while text is the extractive summary\n",
    "    fieldnames = ['meeting','original','extractive','abstractive']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for meeting in meeting_dialogues_ICSI.keys():\n",
    "        meetingid = meeting.split(\".\")[0] \n",
    "        #Bdb001\n",
    "        if meetingid not in icsi_development_set and meetingid not in icsi_test_set:\n",
    "            original_text = \"\"\n",
    "            extractive_summary = \"\"\n",
    "            abstractive_summary = \"\"\n",
    "            # make sure each abstractive sentence appears only once\n",
    "            abstractive_existing = set()\n",
    "            links = summary_links_ICSI.get(meetingid,{})\n",
    "            this_as_dict = as_dict_ICSI.get(meetingid,{})\n",
    "            paragraph_count = 0\n",
    "            for diag_id, _, _, diag, summ_flag in extract_dialogues(meeting, \"ICSI\"):\n",
    "\n",
    "                # if the count of original text words are more than 512, then write the row and move to the next\n",
    "                diag_word_count = len(diag.split())\n",
    "                if diag_word_count + paragraph_count > 1024:\n",
    "                    writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})\n",
    "                    original_text = \"\"\n",
    "                    extractive_summary = \"\"\n",
    "                    abstractive_summary = \"\"\n",
    "                    abstractive_existing = set()  # uniqueness of abstractive sentences per row\n",
    "                    paragraph_count = 0\n",
    "\n",
    "                # add extractive summary\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "\n",
    "                # add abstractive summary\n",
    "                if diag_id in links.keys():\n",
    "                    abstractive_id=links[diag_id]\n",
    "                    for ai in abstractive_id:\n",
    "                        if ai not in abstractive_existing and ai in this_as_dict.keys():\n",
    "                            abstractive_summary += as_dict_ICSI[meetingid][ai] + \" \"\n",
    "                            abstractive_existing.add(ai)\n",
    "\n",
    "                # add the original text\n",
    "                original_text+=diag + \" \"\n",
    "                # increase the original text word counts\n",
    "                paragraph_count += diag_word_count\n",
    "\n",
    "            # write to the row when one meeting ends \n",
    "            writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/ICSI_plus_NXT/T5_csv/ICSI_1024_train.csv\")\n",
    "#print(df.meeting[0])\n",
    "#print(df.original[0])\n",
    "#print(df.abstractive[0])\n",
    "#print(df.extractive[0])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1149\n",
       "1      1120\n",
       "2       301\n",
       "3        63\n",
       "4      1133\n",
       "       ... \n",
       "692    1156\n",
       "693      28\n",
       "694    1135\n",
       "695    1154\n",
       "696    1037\n",
       "Name: original, Length: 697, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['original'].notna()]['original'].apply(lambda x: x.split(\" \")).map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      244\n",
       "1      150\n",
       "4      305\n",
       "5      501\n",
       "6      366\n",
       "      ... \n",
       "691    171\n",
       "692    146\n",
       "694    203\n",
       "695    178\n",
       "696    210\n",
       "Name: extractive, Length: 364, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['extractive'].notna()]['extractive'].apply(lambda x: x.split(\" \")).map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4       55\n",
       "5      125\n",
       "6       56\n",
       "7       37\n",
       "11      39\n",
       "      ... \n",
       "690     16\n",
       "692     42\n",
       "694     16\n",
       "695     17\n",
       "696     24\n",
       "Name: abstractive, Length: 222, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['abstractive'].notna()]['abstractive'].apply(lambda x: x.split(\" \")).map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "with open(\"../data/AMI_manual/T5_csv/AMI_512_test_new.csv\", mode='w') as csv_file:\n",
    "    # ctext is the orginal text, while text is the extractive summary\n",
    "    fieldnames = ['meeting','original','extractive','abstractive']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for meeting in meeting_dialogues_AMI.keys():\n",
    "        meetingid = meeting.split(\".\")[0] \n",
    "        #Bdb001\n",
    "        if meetingid in ami_test_set:\n",
    "            original_text = \"\"\n",
    "            extractive_summary = \"\"\n",
    "            abstractive_summary = \"\"\n",
    "            # make sure each abstractive sentence appears only once\n",
    "            abstractive_existing = set()\n",
    "            links = summary_links_AMI.get(meetingid,{})\n",
    "            this_as_dict = as_dict_AMI.get(meetingid,{})\n",
    "            paragraph_count = 0\n",
    "            for diag_id, _, _, diag, summ_flag in extract_dialogues(meeting, \"AMI\"):\n",
    "\n",
    "                # if the count of original text words are more than x, then write the row and move to the next\n",
    "                diag_word_count = len(diag.split())\n",
    "                if diag_word_count + paragraph_count > 512:\n",
    "                    writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})\n",
    "                    original_text = \"\"\n",
    "                    extractive_summary = \"\"\n",
    "                    abstractive_summary = \"\"\n",
    "                    abstractive_existing = set()  # uniqueness of abstractive sentences per row\n",
    "                    paragraph_count = 0\n",
    "\n",
    "                # add extractive summary\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "\n",
    "                # add abstractive summary\n",
    "                if diag_id in links.keys():\n",
    "                    abstractive_id=links[diag_id]\n",
    "                    for ai in abstractive_id:\n",
    "                        if ai not in abstractive_existing and ai in this_as_dict.keys():\n",
    "                            abstractive_summary += as_dict_AMI[meetingid][ai] + \" \"\n",
    "                            abstractive_existing.add(ai)\n",
    "\n",
    "                # add the original text\n",
    "                original_text+=diag + \" \"\n",
    "                # increase the original text word counts\n",
    "                paragraph_count += diag_word_count\n",
    "\n",
    "            # write to the row when one meeting ends \n",
    "            writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "with open(\"../data/AMI_manual/T5_csv/AMI_512_dev_new.csv\", mode='w') as csv_file:\n",
    "    # ctext is the orginal text, while text is the extractive summary\n",
    "    fieldnames = ['meeting','original','extractive','abstractive']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for meeting in meeting_dialogues_AMI.keys():\n",
    "        meetingid = meeting.split(\".\")[0] \n",
    "        #Bdb001\n",
    "        if meetingid in ami_development_set:\n",
    "            original_text = \"\"\n",
    "            extractive_summary = \"\"\n",
    "            abstractive_summary = \"\"\n",
    "            # make sure each abstractive sentence appears only once\n",
    "            abstractive_existing = set()\n",
    "            links = summary_links_AMI.get(meetingid,{})\n",
    "            this_as_dict = as_dict_AMI.get(meetingid,{})\n",
    "            paragraph_count = 0\n",
    "            for diag_id, _, _, diag, summ_flag in extract_dialogues(meeting, \"AMI\"):\n",
    "\n",
    "                # if the count of original text words are more than 512, then write the row and move to the next\n",
    "                diag_word_count = len(diag.split())\n",
    "                if diag_word_count + paragraph_count > 512:\n",
    "                    writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})\n",
    "                    original_text = \"\"\n",
    "                    extractive_summary = \"\"\n",
    "                    abstractive_summary = \"\"\n",
    "                    abstractive_existing = set()  # uniqueness of abstractive sentences per row\n",
    "                    paragraph_count = 0\n",
    "\n",
    "                # add extractive summary\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "\n",
    "                # add abstractive summary\n",
    "                if diag_id in links.keys():\n",
    "                    abstractive_id=links[diag_id]\n",
    "                    for ai in abstractive_id:\n",
    "                        if ai not in abstractive_existing and ai in this_as_dict.keys():\n",
    "                            abstractive_summary += as_dict_AMI[meetingid][ai] + \" \"\n",
    "                            abstractive_existing.add(ai)\n",
    "\n",
    "                # add the original text\n",
    "                original_text+=diag + \" \"\n",
    "                # increase the original text word counts\n",
    "                paragraph_count += diag_word_count\n",
    "\n",
    "            # write to the row when one meeting ends \n",
    "            writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "with open(\"../data/AMI_manual/T5_csv/AMI_512_train_new.csv\", mode='w') as csv_file:\n",
    "    # ctext is the orginal text, while text is the extractive summary\n",
    "    fieldnames = ['meeting','original','extractive','abstractive']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for meeting in meeting_dialogues_AMI.keys():\n",
    "        meetingid = meeting.split(\".\")[0] \n",
    "        #Bdb001\n",
    "        if meetingid not in ami_development_set and meetingid not in ami_test_set:\n",
    "            original_text = \"\"\n",
    "            extractive_summary = \"\"\n",
    "            abstractive_summary = \"\"\n",
    "            # make sure each abstractive sentence appears only once\n",
    "            abstractive_existing = set()\n",
    "            links = summary_links_AMI.get(meetingid,{})\n",
    "            this_as_dict = as_dict_AMI.get(meetingid,{})\n",
    "            paragraph_count = 0\n",
    "            for diag_id, _, _, diag, summ_flag in extract_dialogues(meeting, \"AMI\"):\n",
    "\n",
    "                # if the count of original text words are more than 1024, then write the row and move to the next\n",
    "                diag_word_count = len(diag.split())\n",
    "                if diag_word_count + paragraph_count > 512:\n",
    "                    writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})\n",
    "                    original_text = \"\"\n",
    "                    extractive_summary = \"\"\n",
    "                    abstractive_summary = \"\"\n",
    "                    abstractive_existing = set()  # uniqueness of abstractive sentences per row\n",
    "                    paragraph_count = 0\n",
    "\n",
    "                # add extractive summary\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "\n",
    "                # add abstractive summary\n",
    "                if diag_id in links.keys():\n",
    "                    abstractive_id=links[diag_id]\n",
    "                    for ai in abstractive_id:\n",
    "                        if ai not in abstractive_existing and ai in this_as_dict.keys():\n",
    "                            abstractive_summary += as_dict_AMI[meetingid][ai] + \" \"\n",
    "                            abstractive_existing.add(ai)\n",
    "\n",
    "                # add the original text\n",
    "                original_text+=diag + \" \"\n",
    "                # increase the original text word counts\n",
    "                paragraph_count += diag_word_count\n",
    "\n",
    "            # write to the row when one meeting ends \n",
    "            writer.writerow({'meeting':meeting,'original': original_text, 'extractive': extractive_summary, 'abstractive': abstractive_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES2002a.B\n",
      "6755\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/AMI_manual/T5_csv/AMI_1024_train.csv\")\n",
    "print(df.meeting[4])\n",
    "#print(df.original[4])\n",
    "#print(df.abstractive[4])\n",
    "#print(df.extractive[4])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        925\n",
       "1         66\n",
       "2       1474\n",
       "3        179\n",
       "4       1288\n",
       "        ... \n",
       "6750     997\n",
       "6751     887\n",
       "6752     822\n",
       "6753     970\n",
       "6754     591\n",
       "Name: original, Length: 6748, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['original'].notna()]['original'].apply(lambda x: x.split(\" \")).map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        197\n",
       "1          2\n",
       "2       1474\n",
       "3         56\n",
       "11        13\n",
       "        ... \n",
       "6727      34\n",
       "6730      18\n",
       "6732       7\n",
       "6738      12\n",
       "6743       5\n",
       "Name: extractive, Length: 2832, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['extractive'].notna()]['extractive'].apply(lambda x: x.split(\" \")).map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       48\n",
       "1       36\n",
       "2       36\n",
       "3       36\n",
       "11      36\n",
       "        ..\n",
       "6726    15\n",
       "6727    46\n",
       "6730    32\n",
       "6732    32\n",
       "6743    32\n",
       "Name: abstractive, Length: 2446, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['abstractive'].notna()]['abstractive'].apply(lambda x: x.split(\" \")).map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Original Dialogue\n",
    "\n",
    "*meeting_da.txt*\n",
    "\n",
    "e.g. ES2004a.B_da.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ICSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "for meeting in meeting_dialogues_ICSI.keys():\n",
    "    meetingid = meeting.split(\".\")[0]    \n",
    "    original_text = \"\"\n",
    "    if meetingid in icsi_test_set:\n",
    "        with open(\"../data/ICSI_plus_NXT/Full_doc/Test/\"+meeting+\"_da.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,_ in extract_dialogues(meeting,\"ICSI\"):\n",
    "                original_text+=diag + \" \"\n",
    "            f.write(original_text)\n",
    "            f.write(\"\\n\")\n",
    "    elif meetingid in icsi_development_set:\n",
    "        with open(\"../data/ICSI_plus_NXT/Full_doc/Dev/\"+meeting+\"_da.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,_ in extract_dialogues(meeting,\"ICSI\"):\n",
    "                original_text+=diag + \" \"\n",
    "            f.write(original_text)\n",
    "            f.write(\"\\n\")\n",
    "    else:\n",
    "        with open(\"../data/ICSI_plus_NXT/Full_doc/Train/\"+meeting+\"_da.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,_ in extract_dialogues(meeting,\"ICSI\"):\n",
    "                original_text+=diag + \" \"\n",
    "            f.write(original_text)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "for meeting in meeting_dialogues_AMI.keys():\n",
    "    meetingid = meeting.split(\".\")[0]        \n",
    "    original_text = \"\"\n",
    "    if meetingid in ami_test_set:\n",
    "        with open(\"../data/AMI_manual/Full_doc/Test/\"+meeting+\"_da.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,_ in extract_dialogues(meeting,\"AMI\"):\n",
    "                original_text+=diag + \" \"\n",
    "            f.write(original_text)\n",
    "            f.write(\"\\n\")\n",
    "    elif meetingid in ami_development_set:\n",
    "        with open(\"../data/AMI_manual/Full_doc/Dev/\"+meeting+\"_da.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,_ in extract_dialogues(meeting,\"AMI\"):\n",
    "                original_text+=diag + \" \"\n",
    "            f.write(original_text)\n",
    "            f.write(\"\\n\")\n",
    "    else:\n",
    "        with open(\"../data/AMI_manual/Full_doc/Train/\"+meeting+\"_da.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,_ in extract_dialogues(meeting,\"AMI\"):\n",
    "                original_text+=diag + \" \"\n",
    "            f.write(original_text)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Cleaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ICSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "for meeting in meeting_dialogues_ICSI.keys():\n",
    "    meetingid = meeting.split(\".\")[0]    \n",
    "    original_text = \"\"\n",
    "    if meetingid in icsi_test_set:\n",
    "        with open(\"../data/ICSI_plus_NXT/Full_doc/Test/\"+meeting+\"_dac.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,_ in extract_dialogues(meeting,\"ICSI\"):\n",
    "                diag = read_ami_icsi(diag, filler_words)\n",
    "                diag = clean_comma(diag)\n",
    "                original_text+=diag + \" \"\n",
    "            f.write(original_text)\n",
    "            f.write(\"\\n\")\n",
    "    elif meetingid in icsi_development_set:\n",
    "        with open(\"../data/ICSI_plus_NXT/Full_doc/Dev/\"+meeting+\"_dac.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,_ in extract_dialogues(meeting,\"ICSI\"):\n",
    "                diag = read_ami_icsi(diag, filler_words)\n",
    "                diag = clean_comma(diag)\n",
    "                original_text+=diag + \" \"\n",
    "            f.write(original_text)\n",
    "            f.write(\"\\n\")\n",
    "    else:\n",
    "        with open(\"../data/ICSI_plus_NXT/Full_doc/Train/\"+meeting+\"_dac.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,_ in extract_dialogues(meeting,\"ICSI\"):\n",
    "                diag = read_ami_icsi(diag, filler_words)\n",
    "                diag = clean_comma(diag)\n",
    "                original_text+=diag + \" \"\n",
    "            f.write(original_text)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "for meeting in meeting_dialogues_AMI.keys():\n",
    "    meetingid = meeting.split(\".\")[0]        \n",
    "    original_text = \"\"\n",
    "    if meetingid in ami_test_set:\n",
    "        with open(\"../data/AMI_manual/Full_doc/Test/\"+meeting+\"_dac.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,_ in extract_dialogues(meeting,\"AMI\"):\n",
    "                diag = read_ami_icsi(diag, filler_words)\n",
    "                diag = clean_comma(diag)\n",
    "                original_text+=diag + \" \"\n",
    "            f.write(original_text)\n",
    "            f.write(\"\\n\")\n",
    "    elif meetingid in ami_development_set:\n",
    "        with open(\"../data/AMI_manual/Full_doc/Dev/\"+meeting+\"_dac.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,_ in extract_dialogues(meeting,\"AMI\"):\n",
    "                diag = read_ami_icsi(diag, filler_words)\n",
    "                diag = clean_comma(diag)\n",
    "                original_text+=diag + \" \"\n",
    "            f.write(original_text)\n",
    "            f.write(\"\\n\")\n",
    "    else:\n",
    "        with open(\"../data/AMI_manual/Full_doc/Train/\"+meeting+\"_dac.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,_ in extract_dialogues(meeting,\"AMI\"):\n",
    "                diag = read_ami_icsi(diag, filler_words)\n",
    "                diag = clean_comma(diag)\n",
    "                original_text+=diag + \" \"\n",
    "            f.write(original_text)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Extractive Summary\n",
    "\n",
    "*meeting_es.txt*\n",
    "\n",
    "e.g. ES2004a.A_es.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ICSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "for meeting in meeting_dialogues_ICSI.keys():\n",
    "    meetingid = meeting.split(\".\")[0]   \n",
    "    extractive_summary = \"\"\n",
    "    \n",
    "    if meetingid in icsi_test_set:\n",
    "        with open(\"../data/ICSI_plus_NXT/Full_doc/Test/\"+meeting+\"_es.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,summ_flag in extract_dialogues(meeting,\"ICSI\"):\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "            f.write(extractive_summary)\n",
    "            f.write(\"\\n\")\n",
    "    elif meetingid in icsi_development_set:\n",
    "        with open(\"../data/ICSI_plus_NXT/Full_doc/Dev/\"+meeting+\"_es.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,summ_flag in extract_dialogues(meeting,\"ICSI\"):\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "            f.write(extractive_summary)\n",
    "            f.write(\"\\n\")\n",
    "    else:\n",
    "        with open(\"../data/ICSI_plus_NXT/Full_doc/Train/\"+meeting+\"_es.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,summ_flag in extract_dialogues(meeting,\"ICSI\"):\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "            f.write(extractive_summary)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "for meeting in meeting_dialogues_AMI.keys():\n",
    "    meetingid = meeting.split(\".\")[0]   \n",
    "    extractive_summary = \"\"\n",
    "    \n",
    "    if meetingid in ami_test_set:\n",
    "        with open(\"../data/AMI_manual/Full_doc/Test/\"+meeting+\"_es.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,summ_flag in extract_dialogues(meeting,\"AMI\"):\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "            f.write(extractive_summary)\n",
    "            f.write(\"\\n\")\n",
    "    elif meetingid in ami_development_set:\n",
    "        with open(\"../data/AMI_manual/Full_doc/Dev/\"+meeting+\"_es.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,summ_flag in extract_dialogues(meeting,\"AMI\"):\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "            f.write(extractive_summary)\n",
    "            f.write(\"\\n\")\n",
    "    else:\n",
    "        with open(\"../data/AMI_manual/Full_doc/Train/\"+meeting+\"_es.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,summ_flag in extract_dialogues(meeting,\"AMI\"):\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "            f.write(extractive_summary)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save cleaned extractive summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "for meeting in meeting_dialogues_ICSI.keys():\n",
    "    meetingid = meeting.split(\".\")[0]   \n",
    "    extractive_summary = \"\"\n",
    "    \n",
    "    if meetingid in icsi_test_set:\n",
    "        with open(\"../data/ICSI_plus_NXT/Full_doc/Test/\"+meeting+\"_esc.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,summ_flag in extract_dialogues(meeting,\"ICSI\"):\n",
    "                if summ_flag == 1: \n",
    "                    diag = read_ami_icsi(diag, filler_words)\n",
    "                    diag = clean_comma(diag)\n",
    "                    extractive_summary+= diag + \" \"\n",
    "            f.write(extractive_summary)\n",
    "            f.write(\"\\n\")\n",
    "    elif meetingid in icsi_development_set:\n",
    "        with open(\"../data/ICSI_plus_NXT/Full_doc/Dev/\"+meeting+\"_esc.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,summ_flag in extract_dialogues(meeting,\"ICSI\"):\n",
    "                if summ_flag == 1: \n",
    "                    diag = read_ami_icsi(diag, filler_words)\n",
    "                    diag = clean_comma(diag)\n",
    "                    extractive_summary+= diag + \" \"\n",
    "            f.write(extractive_summary)\n",
    "            f.write(\"\\n\")\n",
    "    else:\n",
    "        with open(\"../data/ICSI_plus_NXT/Full_doc/Train/\"+meeting+\"_esc.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,summ_flag in extract_dialogues(meeting,\"ICSI\"):\n",
    "                if summ_flag == 1: \n",
    "                    diag = read_ami_icsi(diag, filler_words)\n",
    "                    diag = clean_comma(diag)\n",
    "                    extractive_summary+= diag + \" \"\n",
    "            f.write(extractive_summary)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "for meeting in meeting_dialogues_AMI.keys():\n",
    "    meetingid = meeting.split(\".\")[0]   \n",
    "    extractive_summary = \"\"\n",
    "    \n",
    "    if meetingid in ami_test_set:\n",
    "        with open(\"../data/AMI_manual/Full_doc/Test/\"+meeting+\"_esc.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,summ_flag in extract_dialogues(meeting,\"AMI\"):\n",
    "                if summ_flag == 1: \n",
    "                    diag = read_ami_icsi(diag, filler_words)\n",
    "                    diag = clean_comma(diag)\n",
    "                    extractive_summary+= diag + \" \"\n",
    "            f.write(extractive_summary)\n",
    "            f.write(\"\\n\")\n",
    "    elif meetingid in ami_development_set:\n",
    "        with open(\"../data/AMI_manual/Full_doc/Dev/\"+meeting+\"_esc.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,summ_flag in extract_dialogues(meeting,\"AMI\"):\n",
    "                if summ_flag == 1: \n",
    "                    diag = read_ami_icsi(diag, filler_words)\n",
    "                    diag = clean_comma(diag)\n",
    "                    extractive_summary+= diag + \" \"\n",
    "            f.write(extractive_summary)\n",
    "            f.write(\"\\n\")\n",
    "    else:\n",
    "        with open(\"../data/AMI_manual/Full_doc/Train/\"+meeting+\"_esc.txt\", mode='w') as f:\n",
    "            for _, _, _, diag,summ_flag in extract_dialogues(meeting,\"AMI\"):\n",
    "                if summ_flag == 1: \n",
    "                    diag = read_ami_icsi(diag, filler_words)\n",
    "                    diag = clean_comma(diag)\n",
    "                    extractive_summary+= diag + \" \"\n",
    "            f.write(extractive_summary)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Abstractive Summary\n",
    "\n",
    "*meeting_as.txt*\n",
    "\n",
    "e.g. Bed002_as.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ICSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "for meeting, sentencedict in as_dict_ICSI.items():\n",
    "    meetingid = meeting\n",
    "    abstractive_summary = \"\"\n",
    "    \n",
    "    if meetingid in icsi_test_set:\n",
    "        with open(\"../data/ICSI_plus_NXT/Full_doc/Test/\"+meeting+\"_as.txt\", mode='w') as f:\n",
    "            for s,v in sentencedict.items():\n",
    "                abstractive_summary+= v + \" \"\n",
    "            f.write(abstractive_summary)\n",
    "            f.write(\"\\n\")\n",
    "    elif meetingid in icsi_development_set:\n",
    "        with open(\"../data/ICSI_plus_NXT/Full_doc/Dev/\"+meeting+\"_as.txt\", mode='w') as f:\n",
    "            for s,v in sentencedict.items():\n",
    "                abstractive_summary+= v + \" \"\n",
    "            f.write(abstractive_summary)\n",
    "            f.write(\"\\n\")\n",
    "    else:\n",
    "        with open(\"../data/ICSI_plus_NXT/Full_doc/Train/\"+meeting+\"_as.txt\", mode='w') as f:\n",
    "            for s,v in sentencedict.items():\n",
    "                abstractive_summary+= v + \" \"\n",
    "            f.write(abstractive_summary)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "with open(\"../data/ICSI_plus_NXT/T5_csv/goldsummary_ICSI_as_test.csv\", mode='w') as csv_file:\n",
    "    # ctext is the orginal text, while text is the extractive summary\n",
    "    fieldnames = ['meeting','abstractive']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for meeting, sentencedict in as_dict_ICSI.items():\n",
    "        meetingid = meeting\n",
    "        #Bdb001\n",
    "        if meetingid in icsi_test_set:\n",
    "            abstractive_summary = \"\"\n",
    "            for s,v in sentencedict.items():\n",
    "                abstractive_summary+= v + \" \"\n",
    "            # write to the row when one meeting ends \n",
    "            writer.writerow({'meeting':meeting,'abstractive': abstractive_summary})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "for meeting, sentencedict in as_dict_AMI.items():\n",
    "    meetingid = meeting\n",
    "    abstractive_summary = \"\"\n",
    "    \n",
    "    if meetingid in ami_test_set:\n",
    "        with open(\"../data/AMI_manual/Full_doc/Test/\"+meeting+\"_as.txt\", mode='w') as f:\n",
    "            for s,v in sentencedict.items():\n",
    "                abstractive_summary+= v + \" \"\n",
    "            f.write(abstractive_summary)\n",
    "            f.write(\"\\n\")\n",
    "    elif meetingid in ami_development_set:\n",
    "        with open(\"../data/AMI_manual/Full_doc/Dev/\"+meeting+\"_as.txt\", mode='w') as f:\n",
    "            for s,v in sentencedict.items():\n",
    "                abstractive_summary+= v + \" \"\n",
    "            f.write(abstractive_summary)\n",
    "            f.write(\"\\n\")\n",
    "    else:\n",
    "        with open(\"../data/AMI_manual/Full_doc/Train/\"+meeting+\"_as.txt\", mode='w') as f:\n",
    "            for s,v in sentencedict.items():\n",
    "                abstractive_summary+= v + \" \"\n",
    "            f.write(abstractive_summary)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "with open(\"../data/AMI_manual/T5_csv/goldsummary_AMI_as_test.csv\", mode='w') as csv_file:\n",
    "    # ctext is the orginal text, while text is the extractive summary\n",
    "    fieldnames = ['meeting','abstractive']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for meeting, sentencedict in as_dict_AMI.items():\n",
    "        meetingid = meeting\n",
    "        #Bdb001\n",
    "        if meetingid in ami_test_set:\n",
    "            abstractive_summary = \"\"\n",
    "            for s,v in sentencedict.items():\n",
    "                abstractive_summary+= v + \" \"\n",
    "            # write to the row when one meeting ends \n",
    "            writer.writerow({'meeting':meeting,'abstractive': abstractive_summary})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extractive Summary and Abstractive Summary with Links\n",
    "\n",
    "*meeting_esas.csv*\n",
    "\n",
    "e.g.Bed002.A_esas.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "fieldnames = ['meeting','abstractive', 'extractive']\n",
    "\n",
    "for meeting in meeting_dialogues_ICSI.keys():\n",
    "    meetingid = meeting.split(\".\")[0] \n",
    "    #Bdb001\n",
    "    extractive_summary = \"\"\n",
    "    abstractive_summary = \"\"\n",
    "    # make sure each abstractive sentence appears only once\n",
    "    abstractive_existing = set()\n",
    "    links = summary_links_ICSI.get(meetingid,{})\n",
    "    this_as_dict = as_dict_ICSI.get(meetingid,{})\n",
    "    \n",
    "    if meetingid in icsi_test_set:\n",
    "        with open(\"../data/ICSI_plus_NXT/Full_doc/Test/\"+meeting+\"_esas.csv\", mode='w') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for diag_id, _, _, diag,summ_flag in extract_dialogues(meeting,\"ICSI\"):\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "                if diag_id in links.keys():\n",
    "                    abstractive_id=links[diag_id]\n",
    "                    if abstractive_id not in abstractive_existing and abstractive_id in this_as_dict.keys():\n",
    "                        abstractive_summary += as_dict_ICSI[meetingid][abstractive_id] + \" \"\n",
    "                        abstractive_existing.add(abstractive_id)\n",
    "            writer.writerow({'meeting':meeting,'abstractive': abstractive_summary, 'extractive': extractive_summary})\n",
    "            \n",
    "    elif meetingid in icsi_development_set:\n",
    "        with open(\"../data/ICSI_plus_NXT/Full_doc/Dev/\"+meeting+\"_esas.csv\", mode='w') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for diag_id, _, _, diag,summ_flag in extract_dialogues(meeting,\"ICSI\"):\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "                if diag_id in links.keys():\n",
    "                    abstractive_id=links[diag_id]\n",
    "                    if abstractive_id not in abstractive_existing and abstractive_id in this_as_dict.keys():\n",
    "                        abstractive_summary += as_dict_ICSI[meetingid][abstractive_id] + \" \"\n",
    "                        abstractive_existing.add(abstractive_id)\n",
    "            writer.writerow({'meeting':meeting,'abstractive': abstractive_summary, 'extractive': extractive_summary})\n",
    "            \n",
    "    else:\n",
    "        with open(\"../data/ICSI_plus_NXT/Full_doc/Train/\"+meeting+\"_esas.csv\", mode='w') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for diag_id, _, _, diag,summ_flag in extract_dialogues(meeting,\"ICSI\"):\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "                if diag_id in links.keys():\n",
    "                    abstractive_id=links[diag_id]\n",
    "                    if abstractive_id not in abstractive_existing and abstractive_id in this_as_dict.keys():\n",
    "                        abstractive_summary += as_dict_ICSI[meetingid][abstractive_id] + \" \"\n",
    "                        abstractive_existing.add(abstractive_id)\n",
    "            writer.writerow({'meeting':meeting,'abstractive': abstractive_summary, 'extractive': extractive_summary})\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all meetings and write out dialogues to files\n",
    "fieldnames = ['meeting','abstractive', 'extractive']\n",
    "\n",
    "for meeting in meeting_dialogues_AMI.keys():\n",
    "    meetingid = meeting.split(\".\")[0] \n",
    "    #Bdb001\n",
    "    extractive_summary = \"\"\n",
    "    abstractive_summary = \"\"\n",
    "    # make sure each abstractive sentence appears only once\n",
    "    abstractive_existing = set()\n",
    "    links = summary_links_AMI.get(meetingid,{})\n",
    "    this_as_dict = as_dict_AMI.get(meetingid,{})\n",
    "    \n",
    "    if meetingid in ami_test_set:\n",
    "        with open(\"../data/AMI_manual/Full_doc/Test/\"+meeting+\"_esas.csv\", mode='w') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for diag_id, _, _, diag,summ_flag in extract_dialogues(meeting,\"AMI\"):\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "                if diag_id in links.keys():\n",
    "                    abstractive_id=links[diag_id]\n",
    "                    if abstractive_id not in abstractive_existing and abstractive_id in this_as_dict.keys():\n",
    "                        abstractive_summary += as_dict_AMI[meetingid][abstractive_id] + \" \"\n",
    "                        abstractive_existing.add(abstractive_id)\n",
    "            writer.writerow({'meeting':meeting,'abstractive': abstractive_summary, 'extractive': extractive_summary})\n",
    "            \n",
    "    elif meetingid in ami_development_set:\n",
    "        with open(\"../data/AMI_manual/Full_doc/Dev/\"+meeting+\"_esas.csv\", mode='w') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for diag_id, _, _, diag,summ_flag in extract_dialogues(meeting,\"AMI\"):\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "                if diag_id in links.keys():\n",
    "                    abstractive_id=links[diag_id]\n",
    "                    if abstractive_id not in abstractive_existing and abstractive_id in this_as_dict.keys():\n",
    "                        abstractive_summary += as_dict_AMI[meetingid][abstractive_id] + \" \"\n",
    "                        abstractive_existing.add(abstractive_id)\n",
    "            writer.writerow({'meeting':meeting,'abstractive': abstractive_summary, 'extractive': extractive_summary})\n",
    "            \n",
    "    else:\n",
    "        with open(\"../data/AMI_manual/Full_doc/Train/\"+meeting+\"_esas.csv\", mode='w') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for diag_id, _, _, diag,summ_flag in extract_dialogues(meeting,\"AMI\"):\n",
    "                if summ_flag == 1: \n",
    "                    extractive_summary+= diag + \" \"\n",
    "                if diag_id in links.keys():\n",
    "                    abstractive_id=links[diag_id]\n",
    "                    if abstractive_id not in abstractive_existing and abstractive_id in this_as_dict.keys():\n",
    "                        abstractive_summary += as_dict_AMI[meetingid][abstractive_id] + \" \"\n",
    "                        abstractive_existing.add(abstractive_id)\n",
    "            writer.writerow({'meeting':meeting,'abstractive': abstractive_summary, 'extractive': extractive_summary})\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
