meeting,original,extractive,abstractive
Bed002.A,"we 're on . just make that th your wireless mike is on , if you 're wearing a wireless . and you should be able to see which one you 're on by , watching the little bars change .  actually , if you guys wanna go ahead and read digits now , as long as you 've signed the consent form , that 's alright . no . no . each individually . we 're talking about doing all at the same time but cognitively that would be really difficult . to try to read them while everyone else is . when you 're reading the digit strings , the first thing to do is just say which transcript you 're on . the first thing you 'd wanna do is just say which transcript you 're on .  you can see the transcript ? there 's two large number strings on the digits ? you would just read that one . and then you read each line with a small pause between the lines . and the pause is just the person transcribing it can tell where one line ends and the other begins . and i 'll give i 'll read the digit strings first , can see how that goes .  again , i 'm not how much i should talk about before everyone 's here .  why don't i go ahead and read digit strings and then we can go on from there .  just also a note on wearing the microphones . all of you look like you 're doing it reasonably correctly , but you want it about two thumb widths away from your mouth , and then , at the corner . and that 's that you minimize breath sounds , that when you 're breathing , you don't breathe into the mike .  that 's good . and everyone needs to fill out , only once , the speaker form and the consent form . and the short form you should read the consent form , but the thing to notice is that we will give you an opportunity to edit a all the transcripts . if you say things and you don't want them to be released to the general public , which , these will be available at some point to anyone who wants them , you 'll be given an opportunity by email , to bleep out any portions you don't like .  on the speaker form just fill out as much of the information as you can . if you 're not exactly about the region , we 're not exactly either . don't worry too much about it . the it 's just self rating .  and that 's about it . should i do you want me to talk about why we 're doing this and what this project is ? or ? what we 're gonna we 'll anonymize it in the transcript . but not in the audio . the right , if i said , "" hi jerry , how are you ? "" , we 're not gonna go through and cancel out the "" jerry ""s . we will go through and , in the speaker id tags there 'll be , m one o seven , m one o eight . but it w i don't know a good way of doing it on the audio , and still have people who are doing discourse research be able to use the data .  right . whatever you wanna do is fine , but we find that we want the meeting to be as natural as possible . we 're trying to do real meetings . and we don't wanna have to do aliases and we don't want people to be editing what they say . think that it 's better just as a pro post process to edit out every time you bash microsoft .   th this is the project is called meeting recorder and there are lots of different aspects of the project . my particular interest is in the pda of the future . this is a mock up of one . yes , we do believe the pda of the future will be made of wood . the idea is that you 'd be able to put a pda at the table at an impromptu meeting , and record it , and then be able to do querying and retrieval later on , on the meeting . that 's my particular interest , is a portable device to do m information retrieval on meetings . other people are interested in other aspects of meetings . the first step on that , in any of these , is to collect some data . and what we wanted is a room that 's instrumented with both the table top microphones , and these are very high quality pressure zone mikes , as as the close talking mikes . what the close talk ng talking mikes gives us is some ground truth , gives us , high quality audio , especially for people who aren't interested in the acoustic parts of this corpus . for people who are more interested in language , we didn't want to penalize them by having only the far field mikes available . and then also , it 's a very , very hard task in terms of speech recognition . and on the far field mikes we can expect very low recognition results . we wanted the near field mikes to at least isolate the difference between the two . that 's why we 're recording in parallel with the close talking and the far field at the same time . and then , all these channels are recorded simultaneously and framed synchronously that you can also do things like , beam forming on all the microphones and do research like that . our intention is to release this data to the public , probably through f through a body like the ldc . ",,
Bed002.A,"and , just make it as a generally available corpus . there 's other work going on in meeting recording . we 're working with sri , with uw , nist has started an effort which will include video . we 're not including video , and and then also , a small amount of assistance from ibm . is also involved . and the digit strings , this is just a more constrained task . because the general environment is challenging , we decided to do at least one set of digit strings to give ourselves something easier . and it 's exactly the same digit strings as in ti digits , which is a common connected digits corpus . we 'll have some , comparison to be able to be made . anything else ? when the l last person comes in , just have them wear a wireless . it should be on already .  either one of those . and read the digit strings and fill out the forms . the most important form is the consent form , just be s be everyone signs that , if they consent .  right . and just give me a call , which , my number 's up there when your meeting is over . and i 'm going to leave the mike here but it 's n but i 'm not gonna be on don't have them use this one . it 'll just be sitting here . ",,
Bed002.B,"which is my bar ? mah ! number one . for our  i sent an email . we can make up aliases for each of us . right .  i 'm it 's pretty usual for meetings that people come late , you will have to leave what you set . input ?  there we go .  i got it . wel we i it 's really simple though . this is the idea .  we could pursue , if we thought it 's worth it but , we will agree on that , to come up with a very , very first crude prototype , and do some implementation work , and do some research , and some modeling . the idea is if you want to go somewhere , and focus on that object down actually walk with this . this is down here . that 's the powder tower . now , we found in our , data and from experiments , that there 's three things you can do . you can walk this way , and come really , really close to it . and touch it . but you cannot enter or do anything else . unless you 're interested in rock climbing , it won't do you no good standing there . it 's just a dark alley . but you can touch it . if you want to actually go up or into the tower , you have to go this way , and then through some buildings and up some stairs and forth . if you actually want to see the tower , and that 's what actually most people want to do , is just have a good look of it , take a picture for the family , you have to go this way , and go up here . and there you have a vre really view it exploded , the during the thirty years war . really interesting sight . and these these lines are , paths , or that 's ab er , i the street network of our geographic information system . and you can tell that we deliberately cut out this part . because otherwise we couldn't get our gis system to take to lead people this way . it would always use the closest point to the object , and then the tourists would be faced , in front of a wall , but it would do them no good . what we found interesting is , first of all , intentions differ . you want to enter a building . you want to see it , take a picture of it . or you actually want to come as close as possible to the building . for whatever reason that may be . r red limestone . you would want to touch it .  i this , these intentions , we w we could , if we want to , call it the vista mode , where we just want to get the overview or look at it , the enter mode , and the , tango mode . i always come up with silly names . this "" tango "" means , literally translated , "" to touch "" . but sometimes the tango mode is really relevant in the sense that , if you want to , if you don't have the intention of entering your building , but that something is really close to it , and you just want to approach it , or get to that building . consider , the post office in chicago , a building large that it has its own zip code . the entrance could be miles away from the closest point . sometimes it m makes sense to d to distinguish there . i 've looked , through twenty some i didn't look through all the data . and there 's a lot more different ways in people the ways people phrase how to g get if they want to get to a certain place . and sometimes here it 's b it 's a little bit more obvious should go back a couple of steps and go through the you need to sign some and read some digits . o or later . they are uncomfortable .   but that was our idea . is  that was the idea . people , when they w when they want to go to a building , sometimes they just want to look at it . sometimes they want to enter it . and sometimes they want to get really close to it . that 's something we found . it 's just a truism . and the places where you will lead them for these intentions are sometimes ex in incredibly different . i gave an example where the point where you end up if you want to look at it is completely different from where if you want to enter it . this is how people may , may phrase those requests to a mock up system at least that 's the way they did it . and we get tons of these "" how do i get to "" , "" i want to go to "" , but also , "" give me directions to "" , and "" i would like to see "" . and what we can do , if we look closer a closer at the data that was the wrong one . we can look at some factors that may make a difference . first of all , very important , and that i 've completely forgot that when we talked . this is crucial factor , "" what type of object is it ? "" some buildings you just don't want to take pictures of . or very rarely . but you usually want to enter them . some objects are more picturesque , and you more f more highly photographed . then the actual phrases may give us some idea of what the person wants . ","the street network of our geographic information system . it would always use the closest point to the object , what we found interesting is , first of all , intentions differ . you want to enter a building . you want to see it , take a picture of it . or you actually want to come as close as possible to the building . if you don't have the intention of entering your building , but that something is really close to it , and you just want to approach it , or get to that building . and the places where you will lead them for these intentions are sometimes ex in incredibly different . and we get tons of these "" how do i get to "" , "" i want to go to "" , we can look at some factors that may make a difference . this is crucial factor , "" what type of object is it ? "" then the actual phrases may give us some idea of what the person wants . ","In the navigational paradigm used for the task, these intentions are to ""see"" to ""enter"" or to ""get to the closest point of"" a building. However, the starting point is, through the use of existing data, to determine possible linguistic, discourse or situation features that define intentionality. These may include the type of building, time of day, particular phrases used or whether the user is a tourist or a native. "
Bed002.B,"sometimes i found in the looking at the data , in a superficial way , i found some s modifiers that m may also give us a hint , "" i 'm trying to get to "" nuh ? "" i need to get to "" . hints to the fact that you 're not really sightseeing and just f there for pleasure and forth and on . and this leads us straight to the context which also should be considered . that whatever it is you 're doing at the moment may also inter influence the interpretation of a phrase . this is , really  my suggestion is really simple . we start with , now , let me , say one more thing . what we do know , is that the parser we use in the smartkom system will never differentiate between any of these . all of these things will result in the same xml m three l structure . action "" go "" , and then an object .  and a source . it 's it 's way too crude to d capture those differences in intentions .  for a deep understanding task , that 's a playground or first little thing . "" where we can start it and n look "" we need , we gonna get those m three l structures . the crude , undifferentiated parse . interpreted input . we may need additional part of speech , or just some information on the verb , and modifiers , auxiliaries . we 'll see . and i will try to come up with a list of factors that we need to get out of there , and we want to get a g switch for the context . this is not something which we can actually monitor , now , but just is something we can set . and then you can all imagine constrained satisfaction program , depending on what , comes out . we want to have an a structure resulting if we feed it through a belief net along those lines . we 'd get an inferred intention , we produce a structure that differentiates between the vista , the enter , and the , tango mode . which we want to ignore . but . that 's my idea . it 's up for discussion . we can change all of it , any bit of it . throw it all away . as i a as i get ideas ,  discourse about that . that needs to go in there .   people won't want to enter it . s b but that 's a false state of the system , that it 's too close to call .   i have one more point to bhaskara 's question . also the deep understanding part of it is going to be in there to the extent that we want it in terms of our modeling . we can start , basic from human beings , model that , its motions , going , walking , seeing , we can mem model all of that and then compose whatever inferences o we make out of these really conceptual primitives . that will be extremely deep in the in my understanding . the parser output ? "" analyzed speech "" it 's what they call it , really , oder o th no , actually , intention lattices is what we 're gonna get . in a intention lattice k hypothesis . they call it intention hypotheses . they keep it . we have to request it . nuh ? but it 's not in there .  or i th the there is a p a point there if i understand you . correct ?  because sometimes people just say things this you find very often . "" where is the city hall ? "" and this do they don't wanna sh see it on a map , or they don't wanna know it 's five hundred yards away from you , or that it 's to the your north . they wanna go there . that 's what they say , is , "" where is it ? "" . where is that damn thing ? that 's a question mark . sh a lot of parsers , just , that 's way beyond their scope , is of interpreting that .  but still outcome w the outcome will be some form of structure , with the town hall and saying it 's a wh focus on the town hall . but to interpret it ,  somebody else has to do that job later . it will probably tell you how far away it is , at least that 's even what deep map does . it tells you how far away it is , and shows it to you on a map . because i we can not differentiate , at the moment , between , the intention of wanting to go there or the intention of just know wanting to know where it is .  it 's a granularity factor , because where people ask you , "" where is new york ? "" , you will tell them it 's on the east coast . y you won't tell them how to get there , ft take that bus to the airport and blah blah . but if it 's the post office , you will tell them how to get there . th they have done some interesting experiments on that in hamburg as  w this is "" onto "" is knowledge about buildings , their opening times , and then t coupled with time of day , this should   nuh . history . discourse history .   we need a different , engine . machine ,  but , only w muh . no . but  not from that data . ","sometimes i found in the looking at the data , in a superficial way , i found some s modifiers that m may also give us a hint , and this leads us straight to the context which also should be considered . what we do know , is that the parser we use in the smartkom system will never differentiate between any of these . it 's it 's way too crude to d capture those differences in intentions . for a deep understanding task , that 's a playground or first little thing . "" "" we need , we gonna get those m three l structures . and i will try to come up with a list of factors that we need to get out of there , and we want to get a g switch for the context . if we feed it through a belief net along those lines . we 'd get an inferred intention , we produce a structure that differentiates between the vista , the enter , and the , tango mode . a lot of parsers , that 's way beyond their scope , is of interpreting that . because i we can not differentiate , at the moment , between , the intention of wanting to go there or the intention of just know wanting to know where it is . not from that data . ","However, the starting point is, through the use of existing data, to determine possible linguistic, discourse or situation features that define intentionality. Consequently, they will be fed into a belief-net -implemented on a software package like JavaBayes- and the conditional probability of each intention calculated. "
Bed002.B,"but , since we are designing a an , compared to this , even bigger data collection effort , we will definitely take care to put it in there , in some shape , way , form over the other , to see whether we can , then , get empirically validated data . from this , we can sometimes , an and that 's that but that isn't that what we need for a belief net anyhow ? is s sometimes when people want to just see it , they phrase it more like this ? but it doesn't exclude anybody from phrasing it differently , even if they still  but then other factors may come into play that change the outcome of their belief net . this is exactly what because y you can never be and i 'm even i the most , deliberate data collection experiment will never give you data that say , "" if it 's phrased like that , the intention is this . "" because then , you we  that 's what we 're doing . but we will still get the phrasing all over the place . i 'm that ,  no , no . no .  n no , no not i it was mobile but not with a w a real wizard system . there were never answers .   but it was never th the goal of that data collection to serve for sat for such a purpose . that 's why the tasks were not differentiated by intentionality , there was n there was no label , intention a , intention b , intention c . or task a , b , c .  i 'm we can produce some if we need it , that will help us along those lines . but , you gotta leave something for other people to model . to finding out what , situational con what the contextual factors of the situation really are , is an interesting s interesting thing . u 'm , at the moment , curious and i 'm s w want to approach it from the end where we can s start with this toy system that we can play around with , that we get a clearer notion of what input we need for that , what suffices and what doesn't . and then we can start worrying about where to get this input , what do we need , ultimately once we are all experts in changing that parser , there 's just a couple three things we need to do and then we get more whatever , part of speech and more construction type like out of it . it 's a m pragmatic approach , at the moment .  imagine you 're the subject . you 're gonna be in here , and somebody and you see , either th the three d model , or a quicktime animation of standing u in a square in heidelberg . you actually see that . the first thing is you have to read a text about heidelberg . just off a textbook , tourist guide , to familiarize , yourself with that odd sounding german street names , like fischergasse and forth . that 's part one . part two is , you 're told that this huge new , wonderful computer system exists , that can y tell you everything you want to know , and it understands you completely . and you 're gonna pick up that phone , dial a number , and you get a certain amount of tasks that you have to solve . first you have to know find out how to get to that place , with the intention of buying stamps in there . the next task is to get to a certain place and take a picture for your grandchild . the third one is to get information on the history of an object . the fourth one and then the g system breaks down . it crashes , and after the third task . and then or after the fourth . some find @ @ forget that for now . and then , a human operator comes on , and exp apologizes that the system has crashed , but , urges you to continue , now with a human operator . and you have the same tasks again , just with different objects , and you go through it again , and that was it . and one little bit w and the computer you are being told the computer system knows exactly where you are , via gps . when the human operator comes on , that person does not know . the gps is crashed as the person first has to ask you "" where are you ? "" . and you have to do some s tell the person where you are , depending on what you see there . this is a a bit that i d i don't think we did we discuss that bit ? squeezed that in now . but it 's something , that would provide some very interesting data for some people i know .   a additionally , y you have a map type display . two d . n two d .  b y you don't that 's i don't know . i but y i don't think you really move ,   that would be an enormous technical effort , unless we would we can show it walks to , we can have movies of walking , you walking through heidelberg , and u ultimately arriving there . we wanna do that .  the map was intended to you want to go to that place . and it 's there . and you see the label of the name we get those names , pronunciation and forth , and we can change that . we 'll see what people do . and we will record both sides . we will record the wi the wizard ","but , since we are designing a an , compared to this , even bigger data collection effort , we will definitely take care to put it in there , and i 'm even i the most , deliberate data collection experiment will never give you data that say , "" if it 's phrased like that , the intention is this . "" but it was never th the goal of that data collection to serve for sat for such a purpose . that 's why the tasks were not differentiated by intentionality , i 'm we can produce some if we need it , that will help us along those lines . u 'm , at the moment , curious and i 'm s w want to approach it from the end where we can s start with this toy system that we can play around with , that we get a clearer notion of what input we need for that , and then we can start worrying about where to get this input , and you see , either th the three d model , or a quicktime animation of standing u in a square in heidelberg . just off a textbook , tourist guide , to familiarize , yourself with that odd sounding german street names , like fischergasse and forth . part two is , you 're told that this huge new , wonderful computer system exists , that can y tell you everything you want to know , and you get a certain amount of tasks that you have to solve . first you have to know find out how to get to that place , and then the g system breaks down . and then , a human operator comes on , and exp apologizes that the system has crashed , and you have the same tasks again , just with different objects , ",There will be purpose-designed experiments carried out. A prototype system will be put together to test hypotheses regarding both the exact nature of the features and how intentions are derived from them. 
Bed002.B,"in both cases it 's gonna be a human , in the computer , and in the operator case . and we will re there will be some dialogue , you first have to do this , and that , and see wh what they say . we can ins instruct the , wizard in how expressive and talkative he should be . but the what you 're suggesting is what you 're suggesting that it might be too poor , the data , if we limit it to this ping pong one t task results in a question and then there 's an answer and that 's the end of the task ? you wanna m have it more steps ,    n no one is , at the moment . to come as close as possible to it . s to "" waltz "" it ? an nuh . and it may serve as a platform for a person , me , or whoever , who is interested in doing some linguistic analysis . w we have the for framenet group here , and we can see what they have found out about those concepts already , that are contained in the data , to come up with a little set of features and even means of s extracting them . and that altogether could also be become a paper that 's going to be published somewhere , if we sit down and write it . and when you said javabayes belief net you were talking about ones that run on coffee ? or that are in the program language java ?     but i but since we all probably are pretty that , the this th the dialogue history is producing xml documents . m three l is xml . and the ontology that the student is constructing for me back in eml is in oil and that 's also in xml . and that 's where a lot of knowledge about bakeries , about hotels , about castles and is gonna come from . if it has that io capability and if it 's a java package , it will definitely be able we can couple . who isn't , nuh ?  i like , the what you said about the getting input from just files about where you h where you have the data , have specified the features and forth . that 's , easy also to do with , xml .   the lib m three l library does that . it 's also no , u y the what i what came to my mind i is was the notion of an idea that if there are l nets that can actually lear try to set their own , probability factors based on input which is in file format , if we , get really w wild on this , we may actually want to use some corpora that other people made and , if they are in mate , then we get x m l documents with discourse annotations , t t from the discourse act down to the phonetic level . michael has a project where recognizing discourse acts and he does it all in mate , and they 're actually annotating data and data . if we w if we think it 's worth it one of these days , not with this first prototype but with a second , and we have the possibility of taking input that 's generated elsewhere and learn from that , that 'd be no , just for nuh . just a back door that we should devote m two days ? two , three days ? no . i t  i was actually more joking . with the two or three days . this was a usual jo it will take as long as y yo you guys need for that . but it might be interesting if the two of you can agree on who 's gonna be the speaker next monday , to tell us something about the net you picked , and what it does , and how it does that . or you can split it up . y that will be the assignment for next week , is to for slides and whatever net you picked and what it can do and how far you 've gotten . pppt !  this is whi while you were doing this , i received two lovely emails . the full nt and the full linux version are there . i 've downloaded them both , and i started to unpack the linux one the nt one worked fine . and i started unta pack the linux one , it told me that i can't really unpack it because it contains a future date . this is the time difference between germany . i had to until one o ' clock this afternoon before i was able to unpack it . now , then it will be my job to get this whole thing running both on swede and on this machine . and that we have it . and then hopefully that hoping that my urgent message will now come through to ralph and tilman that it will send some more documentation along , we i control p that 's what i will do next monday is show the state and show the system and show that . but but the this point is really very , very valid that ultimately we hope that both will merge into a harmonious and , wonderful , state where we can not only do the bare necessities , ie , changing the table it does exactly in english what it does in german , but also that we can have the system where we can say , "" this is what it usually does , and now we add this little thing to it "" ,  whatever , johno 's and bhaskara 's great belief net , and we plug it in , and then for these certain tasks , ","this th the dialogue history is producing xml documents . and the ontology that the student is constructing for me back in eml is in oil and that 's also in xml . and that 's where a lot of knowledge about bakeries , about hotels , about castles and is gonna come from . if we , get really w wild on this , we may actually want to use some corpora that other people made and , if they are in mate , then we get x m l documents with discourse annotations , t that 's what i will do next monday is show the state and show the system and show that . but but the this point is really very , very valid that ultimately we hope that both will merge into a harmonious and , wonderful , state where we can not only do the bare necessities , ie , changing the table it does exactly in english what it does in german , but also that we can have the system where we can say , "" this is what it usually does , and now we add this little thing to it "" , johno 's and bhaskara 's great belief net , and then for these certain tasks , ",
Bed002.B,"and we know that navigational tasks are gonna be a core domain of the new system , it all of a sudden it does much better . nuh ? because it can produce better answers , tell the person , as i s showed you on this map , n produce either a red line that goes to the vista point or a red line that goes to the tango point or red line that goes to the door , which would be great . not only can you show that something sensible but ultimately , if you produce a system like this , it takes the person where it wants to go . rather than taking him always to the geometric center of a building , which is what they do now . and we even had to take out a bit . nancy , you missed that part . we had to take out a bit of the road work . that it doesn't take you to the wall every time .  this was actually an actual problem that we encountered , which nobody have has because car navigation systems don't really care . they get you to the beginning of the street , some now do the house number . but even that is problematic . if you go d if you wanna drive to the sap in waldorf , i 'm the same is true of microsoft , it takes you to the address , whatever , street number blah blah , you are miles away from the entrance . because the s postal address is mailbox somewhere . nuh ? but the entrance where you actually wanna go is somewhere completely different . unless you 're a mail person you really don't wanna go there . probably neither e not even that . do you wanna see a picture ? have to reboot for that though . there 's more than i showed , but this is in part my job to look at that and to see whether there are features in there that can be extracted , and to come up with some features that are not empirically based on a real experiment or on reality but on your intuition of "" aha ! this is sign for that , and this is sign for this . "" talk features .  they had they used the ammunition they stored the ammunition in that tower . and that 's why , when it was hit by a cannon ball , it exploded . ahh .  ","and we know that navigational tasks are gonna be a core domain of the new system , it all of a sudden it does much better . not only can you show that something sensible but ultimately , if you produce a system like this , it takes the person where it wants to go . rather than taking him always to the geometric center of a building , ",
Bed002.C,"other way . we m we may wind up with ver we may need versions of all this garbage .    we have one more coming .  we can start doing it .  no . there was let 's see .  she got an emai she was notified . whether she knows is another question .  are the people going to be identified by name ? right .  then in terms of people worrying about , excising things from the transcript , it 's unlikely . since it does isn't attributed . i see , but the a but the   right . right .   no , i wasn't complaining , wanted to understand .  right .  right . right . right . why don't you tell us briefly your give your e normal schpiel .  no .  adam , we will be using the , screen as   organization . you guys who got email about this friday about what we 're up to . this was about inferring intentions from features in context , and the words , like "" s go to see "" , or "" visit "" , or some you didn't get it ? these g have got better filters . cuz i sent it to everybody . you just blew it off .  no , come in , sit down . if you grab yourself a microphone . you can sign afterwards . afterwards . and it it also has to be switched on , nance . it 's on ? good . what ?  not important . what is important is that we understand what the proposed task is . and , the i robert and i talked about this some on friday . and we think it 's formed . we think it 's a formed , starter task for this , deeper understanding in the tourist domain . it 's the it 's always all of it . in general it 's always going to be , the answer is , everywhere . the notion is that , this isn't real deep . but it 's deep enough that you can distinguish between these th three quite different kinds of , going to see some tourist thing . and , that 's the quote "" deep "" that we 're trying to get at . and , robert 's point is that the current front end doesn't give you any way to not only doesn't it do it , but it also doesn't give you enough information to do it . it isn't like , if you just took what the front end gives you , and used some clever inference algorithm on it , you would be able to figure out which of these is going on .  and this is bu i in general it 's gonna be true of any deep understanding , there 's gonna be contextual things , there 're gonna be linguistic things , there 're gonna be discourse things , and they gotta be combined . and , my idea on how to combine them is with a belief net , although it may turn out that t some different thing is gonna work better . the idea would be that you , take your you 're editing your slide ?  i 'm this is minutes taking minutes as we go , in his own way . but the p the anyway . i d naively speaking , you 've got a for this little task , a belief net , which is going to have as output , the conditional pr probability of one of three things , that the person wants to to view it , to enter it , or to tango with it .  that the output of the belief net is pretty formed . and , then the inputs are going to be these kinds of things . and , then the question is there are two questions is , one , where do you get this i information from , and two , what 's the structure of the belief net ? what are the conditional probabilities of this , that , and the other , given these things ? and you probably need intermediate nodes . i we don't they are yet . it may be that , that , knowing whether another thing you want is some information abou about the time of day . now , they may wanna call that part of context . but the time of day matters a lot . and , if things are closed , then , you pe people don't wanna enter them . and , if it 's not obvious , you may want to actually point out to people that it 's closed what they 're g going to is closed and they don't have the option of entering it . another thing that can come up , and will come up as soon as you get serious about this is , that another option is to have a more of a dialogue . if someone says something you could ask them .  and now , one thing you could do is always ask them , but that 's boring . and it also w it also be a pain for the person using it . one thing you could do is build a little system that , said , "" whenever you got a question like that i 've got one of three answers . ask them which one you want . ""  but that 's , not what we 're gonna do .  you want the ability to a you want the ability to ask , but what you don't wanna do is onl build a system that always asks every time , and i that 's not getting at the scientific problem , and it 's in general you 're it 's gonna be much more complex than that . a this is purposely a really simple case .   ","this was about inferring intentions from features in context , and the words , like "" s go to see "" , or "" visit "" , or some we think it 's a formed , starter task for this , deeper understanding in the tourist domain . there 's gonna be contextual things , there 're gonna be linguistic things , there 're gonna be discourse things , and they gotta be combined . and , my idea on how to combine them is with a belief net , which is going to have as output , the conditional pr probability of one of three things , there are two questions is , one , where do you get this i information from , and two , what 's the structure of the belief net ? what are the conditional probabilities of this , that , and the other , given these things ? and you probably need intermediate nodes . i we don't they are yet . another thing you want is some information abou about the time of day . one thing you could do is build a little system that , said , "" whenever you got a question like that i 've got one of three answers . you want the ability to a you want the ability to ask , but what you don't wanna do is onl build a system that always asks every time , that 's not getting at the scientific problem , ","The initial task of the EDU group is to work on inferring intentions through context. These may include the type of building, time of day, particular phrases used or whether the user is a tourist or a native. However, the starting point is, through the use of existing data, to determine possible linguistic, discourse or situation features that define intentionality. Consequently, they will be fed into a belief-net -implemented on a software package like JavaBayes- and the conditional probability of each intention calculated. A prototype system will be put together to test hypotheses regarding both the exact nature of the features and how intentions are derived from them. "
Bed002.C,"s the way that might come up , if you wanna suppose you wanted to do that , you might say , "" as an intermediate step in your belief net , is there a source path goal schema involved ? ""  and if is there a focus on the goal ? or is there a focus on the path ?  and that could be , one of the conditiona th the in some piece of the belief net , that could be the appropriate thing to enter . no . no . see , the m three l is not gonna give th what he was saying is , the m three l does not have any of that . all it has is some really crude saying , "" a person wants to go to a place . "" right . m three m three l itself refers to multimedia mark up language . we have th w we have to have a better w way of referring to   the   is i but they c they call it intention lattice , but tha anyway . right . th they 're gonna give us some cr or we can assume that y you get this crude information . about intention , and that 's all they 're going to provide . and they don't give you the object , they don't give you any discourse history , if you want to keep that you have to keep it somewhere else . right . they kee they keep it by their lights . it may or may not be what we want .  if i if if it got as simple as that , but it wouldn't .   but i go back to the th that slide . think we ought to d a as we have all along , d we 've been distu distinguishing between situational context , which is what you have as context , and discourse context , which you have as dh , i don't the h means .  whatever . we can work out terminology later . they 're quite distinct . you need them both , but they 're quite distinct . and , what we were talking about doing , a as a first shot , is not doing any of the linguistics . except to find out what seems to be useful . the reason the belief net is in blue , is the notion would be this may be a bad dis bad idea , but the idea is to take as a first goal , see if we could actually build a belief net that would make this three way distinction in a plausible way , given these we have all these transcripts and we 're able to , by hand , extract the features to put in the belief net . saying , "" aha ! here 're the things which , if you get them out of the language and discourse , and put them into the belief net , it would tell you which of these three intentions is most likely . "" and if to actually do that , build it , run it y run it on the data where you hand transcribe the parameters . and see how that goes . if that goes then we can start worrying about how we would extract them . where would you get this information ? and , expand it to other things like this . but if we can't do that , then we 're in trouble . th i if you can't do this task ,   it i if it 's the belief nets , we 'll switch to logic or some terrible thing , but i don't think that 's gonna be the case . that , if we can get the information , a belief net is a perfectly good way of doing the inferential combination of it . the real issue is , do what are the factors involved in determining this ? and i don't know . hold on a s hold on a second . i know . is it clear what 's going on here ? take them into account . but you don't worry about h how to extract them . f let 's find out which ones we need first , and no . let 's go back to th let 's go back to the slide of data .    from that task , you all know this , but we are going to actually use this little room and start recording subjects probably within a month this is not any lo any of you guys ' worry , except that we may want to push that effort to get information we need . our job is to figure out how to solve these problems . if it turns out that we need data of a certain sort , then the data collection branch can be , asked to do that . and one of the reasons why we 're recording the meeting for these guys is cuz we want their help when we d we start doing recording of subjects . you 're right , though . no , you will not have , and there it is , and , but y the , but to some extent this is a different discussion .  we have to have this discussion of th the experiment , and the data collection , and all that sorta and we do have , a student who is a candidate for wizard . she 's gonna get in touch with me . it 's a student of eve 's . fey , fey ? spelled fey . do you do you her ?  sh is sh she 's graduated .   anyway , she 's looking for some more part time work w while she 's waiting actually for graduate school . and she 'll be in touch . we may have someone , to do this , ","s the way that might come up , if you wanna suppose you wanted to do that , you might say , "" as an intermediate step in your belief net , is there a source path goal schema involved ? "" and if is there a focus on the goal ? what he was saying is , the m three l does not have any of that . right . th they 're gonna give us some cr or we can assume that y you get this crude information . about intention , and they don't give you the object , think we ought to d a as we have all along , d we 've been distu distinguishing between situational context , which is what you have as context , and discourse context , but the idea is to take as a first goal , see if we could actually build a belief net that would make this three way distinction in a plausible way , these we have all these transcripts and we 're able to , by hand , extract the features to put in the belief net . here 're the things which , if you get them out of the language and discourse , and put them into the belief net , it would tell you which of these three intentions is most likely . "" and if to actually do that , build it , run it y run it on the data where you hand transcribe the parameters . if that goes then we can start worrying about how we would extract them . and , expand it to other things like this . but if we can't do that , then we 're in trouble . that , if we can get the information , a belief net is a perfectly good way of doing the inferential combination of it . the real issue is , do what are the factors involved in determining this ? you all know this , but we are going to actually use this little room and start recording subjects probably within a month we have to have this discussion of th the experiment , and the data collection , and all that sorta ","Consequently, they will be fed into a belief-net -implemented on a software package like JavaBayes- and the conditional probability of each intention calculated. Initially, these features will be hand-coded, but the goal is to find ways of extracting them automatically from the XML data. "
Bed002.C,"and she 's got some background in all this and is a linguist st and , that 's nancy , we 'll have an at some point we 'll have another discussion on exactly wha t how that 's gonna go . and jane , but also , liz have offered to help us do this , data collection and design and when we get to that we 'll have some people doing it that they 're doing . we that 's part of what we 'll have to figure out . but , the problem that i was tr gonna try to focus on today was , let 's suppose by magic you could collect dialogues in which , one way or the other , you were able to , figure out both the intention , and set the context , and language was used . let 's suppose that we can get that data .  the issue is , can we find a way to , featurize it that we get some discrete number of features that , when we know the values to all those features , or as many as possible , we can w come up with the best estimate of which of the , in this case three little intentions , are most likely . th the terminology we 're using is to go back . to v to view it .  to enter it . now those it seems to me those are cl you c you have no trouble with those being distinct . "" take a picture of it "" you might want to be a really rather different place than entering it . and , for an object that 's big , getting to the nearest part of it could be quite different than either of those . just  anyway .  right . right . is there a construction , or the object , or w anything else that 's in the si it 's either in the s the discourse itself or in the context . if it turns out that , whatever it is , you want to know whether the person 's a tourist or not , that becomes a feature . now , how you determine that is another issue . but fo for the current problem , it would just be , "" if you can be that it 's a tourist , versus a businessman , versus a native , "" that would give you a lot of discriminatory power and then just have a little section in your belief net that said , "" pppt ! "" though sin f in the short run , you 'd set them , and see ho how it worked , and then in the longer run , you would figure out how you could derive them . from previous discourse or w any anything else you knew . first of all is , do e either of you guys , you got a favorite belief net that you 've , played with ? javabayes  anyway . f get one . one of th one of the things we wanna do is actually , pick a package , doesn't matter which one , presumably one that 's got good interactive abilities , cuz a lot of what we 're gonna be d we don't need the one that 'll solve massive , belief nets quickly . d w these are not gonna get big in the foreseeable future . but we do want one in which it 's easy to interact with and , modify . because i that 's a lot of what it 's gonna be , is , playing with this . and probably one in which it 's easy to have , what amounts to transcript files . that if we have all these cases  we make up cases that have these features , and then you 'd like to be able to say , "" here 's a bunch of cases "" there 're even ones tha that you can do learning you have all their cases and their results and you have a algorithms to go through and run around trying to set the probabilities for you .  probably that 's not worth it . my guess is we aren't gonna have enough data that 's good enough to make the these data fitting ones worth it , but i don't know . would say you guy the first task for you two guys is to pick a package . and you wanna it s the standard things you want it stable , you want it  and , as soon as we have one , we can start trying to , make a first cut at what 's going on . but it what i like about it is it 's very concrete . we have a we the outcomes are gonna be , and we have some data that 's loose , we can use our own intuition , and see how hard it is , and , importantly , what intermediate nodes we think we need . it if it turns out that just , thinking about the problem , you come up with things you really need to this is the thing that is , an intermediate little piece in your belief net . that 'd be really interesting . no , th it turns out that there is a , the new end of java libraries . and it turns out one called which is one that fair people around here use a fair amount . i have no idea whether that 's the obvious advantage of that is that you can then , relatively easily , get all the other java packages for guis or whatever else you might want to do . that i that 's why a lot of people doing research use that . but it may not be i have no idea whether that 's the best choice ","we that 's part of what we 'll have to figure out . the problem that i was tr gonna try to focus on today was , let 's suppose by magic you could collect dialogues in which , one way or the other , you were able to , figure out both the intention , and set the context , and language was used . the issue is , can we find a way to , featurize it that we get some discrete number of features that , when we know the values to all those features , or as many as possible , we can w come up with the best estimate of which of the , in this case three little intentions , are most likely . is there a construction , or the object , or w anything else that 's in the si it 's either in the s the discourse itself or in the context . if it turns out that , whatever it is , you want to know whether the person 's a tourist or not , that becomes a feature . now , how you determine that is another issue . though sin f in the short run , you 'd set them , and then in the longer run , you would figure out how you could derive them . from previous discourse or w any anything else you knew . do e either of you guys , you got a favorite belief net that you 've , played with ? javabayes one of th one of the things we wanna do is actually , pick a package , we don't need the one that 'll solve massive , belief nets quickly . but we do want one in which it 's easy to interact with and , modify . and probably one in which it 's easy to have , what amounts to transcript files . you want it stable , you want it and , as soon as we have one , we can start trying to , make a first cut at what 's going on . we have a we the outcomes are gonna be , and we have some data that 's loose , we can use our own intuition , it if it turns out that just , thinking about the problem , you come up with things you really need to this is the thing that is , an intermediate little piece in your belief net . that 'd be really interesting . ","However, the starting point is, through the use of existing data, to determine possible linguistic, discourse or situation features that define intentionality. These may include the type of building, time of day, particular phrases used or whether the user is a tourist or a native. A prototype system will be put together to test hypotheses regarding both the exact nature of the features and how intentions are derived from them. Consequently, they will be fed into a belief-net -implemented on a software package like JavaBayes- and the conditional probability of each intention calculated. "
Bed002.C,"an and there 're plenty of people around , students in the department who , live and breathe bayes nets .  right . it 's kevin would be a good person to start with . nancy knows him i don't know whether you guys have met kevin yet or not , but ,     we 're committed to xml as the interchange . but that 's , not a big deal . in terms of interchanging in and out of any module we build , it 'll be xml . and if you 're going off to queries to the ontology , you 'll have to deal with its interface . but that 's fine an and all of these things have been built with much bigger projects than this in mind . they have worked very hard . it 's blackboards and multi wave blackboards and ways of interchanging and registering your a and forth .  that i don't think is even worth us worrying about just yet . if we can get the core of the thing to work , in a way that we 're comfortable with , then we ca we can get in and out of it with , xml , little descriptors . i believe . i don't see you could have an x you could make and xml format for that . that  feature value xml format is probably as good a way as any . it 's als it 's also worth , while you 're poking around , poke around for xml packages that do things you 'd like .  and the question is , d you c you 'll have to l we 'll have to l that should be ay we should be able to look at that  it 'd be but i do i don't wanna count on it . you can't run your project based on the speculation that the data will come , and you don't have to actually design the nets . could happen . in terms of the , the what the smartkom gives us for m three l packages , it could be that they 're fine , or it could be eeh . you don't you don't really like it . we 're not abs we 're not required to use their packages . we are required at the end to give them in their format , but hey .  it 's , it doesn't control what you do in internally .  bu w i 'd like that this y this week , to ha to n to have y guys , pick the y belief net package and tell us what it is , and give us a pointer we can play with it and , then as soon as we have it , we should start trying to populate it for this problem . make a first cut at , what 's going on , and probably the ea easiest way to do that is some on line way . you can f figure out whether you wanna make it a web site or how i wasn't .  right . y or both of them speak . we don't care . i 'd like to also , though , ha have a first cut at what the belief net looks like . even if it 's really crude .  here a here are right . and , as i said , what i 'd like to do is , what would be really great is you bring it in if we could , in the meeting , say , "" here 's the package , here 's the current one we have , "" "" what other ideas do you have ? "" and then we can think about this idea of making up the data file . of , get a t a p tentative format for it , let 's say xml , that says , l "" these are the various scenarios we 've experienced . "" we can just add to that and there 'll be this file of them and when you think you 've got a better belief net , you just run it against this , this data file . unt until we know more .  the answer , johno , is that these are , at the moment , separate . what one hopes is that when we understand how the analyzer works , we can both worry about converting it to english and worry about how it could ex extract the parameters we need for the belief net . i don't know . n none of this is i n neither of these projects has got a real tight time line , in the sense that over the next month there 's a deliverable .  s it 's opportu in that sense it 's opportunistic . if if we don't get any information for these guys f for several weeks then we aren't gonna sit around , wasting time , trying to do the problem or guess what they just pppt ! go on and do other things .  probably not then , cuz y you probably can't drop the mail there anyway .  clear ? they use the sample data . we can end the meeting and call adam , and then we wanna s look at some filthy pictures of heidelberg . we can do that as is that alright .  ni ","an and there 're plenty of people around , students in the department who , live and breathe bayes nets . we 're committed to xml as the interchange . it 'd be but i do i don't wanna count on it . in terms of the , the what the smartkom gives us for m three l packages , it could be that they 're fine , or it could be eeh . we 're not abs we 're not required to use their packages . we are required at the end to give them in their format , bu w i 'd like that this y this week , to ha to n to have y guys , pick the y belief net package and , then as soon as we have it , we should start trying to populate it for this problem . i 'd like to also , though , ha have a first cut at what the belief net looks like . even if it 's really crude . unt until we know more . what one hopes is that when we understand how the analyzer works , we can both worry about converting it to english and worry about how it could ex extract the parameters we need for the belief net . n none of this is i n neither of these projects has got a real tight time line , in the sense that over the next month there 's a deliverable . ",A prototype system will be put together to test hypotheses regarding both the exact nature of the features and how intentions are derived from them. 
Bed002.D,"afterwards is fine . really small ? i see .   it 's on .   people no might not be able to infer that either , right ? like the fact like , i could imagine if someone came up to me and asked , "" where 's the city hall ? "" , i might say , g ar "" are you trying to get there ? "" because how i describe t its location p probably depend on whether should give them , directions now , or say , whatever , "" it 's half a mile away "" like that .  exactly . right . right .  right .  right . right . that context was like , their presumed purpose context , i like business or travel , as as the utterance context i 'm now standing at this place at this time "" . i missed the beginning , but ,  could you back to the slide , the previous one ? is it that it 's , these are all factors that a these are the ones that you said that we are going to ignore now ? or that we want to take into account ? you were saying n take the linguistic factors too . how to extract these features .  got it .  and it 's clear from the data , sorta the correct answer in each case . but l  that 's the thing i 'm curious ab like do we know from the data wh which      right .  right . right . right .  u the only way you could get that is if you were to give th the x subjects a task . right ? where you have where your , current goal is to that 's what you want ?  you will know .  the no , that 's fine . it 's just knowing the intention from the experimental subject . and the other concern that has come up before , too , is if it 's  i don't know if this was collected what situation this data was collected in . was it is it the one that you showed in your talk ? like people but  was this someone actually mobile , like s using a device ?   but , is it don't know the situation of collecting th the data of , like here you could imagine them being walking around the city . as like one situation . and then you have all sorts of other c situational context factors that would influence w how to interpret , like you said , the scope and things like that . if they 're doing it in a "" i 'm sitting here with a map and asking questions "" , i would imagine that the data would be really different . it 's just   right .        a at the third ? right then ?  in the display you can you said that you cou you might have a display that shows the a w your perspective ? and as you two d .  as you move through it that 's they just track it on the for themselves there .    i was just trying to figure out how ambitious the system is .    your tasks don't require you to yo you 're told when your task is , i don't know , "" go buy stamps "" like that ? do you have to respond ? or does your what are you ste what are you supposed to be telling the system ? like , w what you 're doing now ? or there 's no it 's just like , "" let 's figure out what they would say under the circumstances "" .     i don't know how much direction is given to the subject about what their interaction th they 're unfamiliar w with interacting with the system . all they know is it 's this great system that could do s right ?   fey parrill .   she started taking the class last year and then didn't didn't continue . i g she 's a g is she an undergradua she is a graduate , i m i know her very , very briefly . i know she was inter interested in aspect and like that .     the reason i was asking about the the de the details of this thing is that , it 's one thing to collect data for , i don't know , speech recognition or various other tasks that have pretty c clear correct answers , but with intention as you point out , there 's a lot of di other factors and i 'm not really how e the question of how to make it a t appropriate toy version of that it 's ju it 's just hard . it 's a it is , if they have these tasks that they 're supposed to to give   right . right . right .  w what are the t three intentions ? is it to go there , to see it , and it 's @ @ .       now i understand the referent of tango mode . i didn't get that before . how close are you gonna be ? like , tango 's really close . there 's the m tool kit that kevin murphy has developed , which might be useful too . and it 's available matlab code . really ?    right , i was wondering .    you two , who 'll be working on this , li are you gl will you be doing are you supposed to just do it by thinking about the situation ? can you use the sample data ? is it like ho is there more than is there a lot s of sample data that is beyond what you have there ?  right .    that 's right , ","and it 's clear from the data , sorta the correct answer in each case . it 's just like , "" let 's figure out what they would say under the circumstances "" . the reason i was asking about the the de the details of this thing is that , it 's one thing to collect data for , i don't know , speech recognition or various other tasks that have pretty c clear correct answers , but with intention as you point out , there 's a lot of di other factors and i 'm not really how e the question of how to make it a t appropriate toy version of that it 's ju it 's just hard . ",
Bed002.E," check one . check one . sibilance . sibilance . are we supposed to read digits at the same time ?  everyone would need extreme focus . does nancy know that we 're meeting in here ? she got an e  no . what was the nature of the email ? i don't did .   what 's it made out of ? you would wanna touch it . you have to al also have to read some digits . no , that one 's already on , he said .   still , i have no recollection whatsoever of the email . i 'll have to go back and check .  the m three l is the old smartkom output ?  it 's just a language . right , if someone says , "" i wanna touch the side of the powder tower "" , that would we need to pop up tango mode and the directions ?   but that doesn't necessarily but we 'd have to infer a source path goal to some degree for touching the side , right ? and the parser would output i 'm just trying to figure out what the smartkom system would output , depending on these things . how exactly does the data collection work ? do they have a map , and then you give them a scenario of some sort ? actually that was my question . is the intention implicit in the scenario that 's given ? like , do the wasn't to what level of detail the task was .  see , i would have thought it was more of a waltz . cuz a tango   what 's the time frame for this ? we 're supposed to @ @ about features and whatnot , and and what 's the relation to this with changing the table that the system works in english ? my question was more about time frame . we 're gonna do belief nets this week , and then   the powder tower is made of red limestone .   it exploded . that 's why they call it the powder tower .  i first thought it had something to do with the material that it w that 's why i asked . ",the m three l is the old smartkom output ? how exactly does the data collection work ? what 's the time frame for this ? ,
Bed002.F," no . now @ @ this email that you sent , actually . now i remember the email . where exactly is the , deeper understanding being done ? like s is it before the bayes net ? is it , where would we extract that information from ? from the m three l ? right .  all these the question is how what features can like , do you wanna try to extract from , say , the parse or whatever ? like , the presence of a word or the presence of a certain stem , or certain construction or whatever .  right . how should what 's the plan ? like , how should we go about figuring out these  no , not really . right . i know him . doesn't does smartkom system have such packages ?  right . right .     we 'll be like , hand , doing all the probabilities .   sounds good .  later this week we should get together , and start thinking about that , hopefully . ","we 'll be like , hand , doing all the probabilities . ","Initially, these features will be hand-coded, but the goal is to find ways of extracting them automatically from the XML data. "
Bed003.A,"to handle . i 'm in control here . but if you really want to find out what it 's about you have to click on the little light bulb . it opens the assistant that tells you that the font type is too small . do you wanna try ?  continue . why are you doing this in this mode and not in the presentation mode ?     no , it 's it 's it 'll work .  appreciate it .  the  there is a term that 's often used . that 's "" saliency "" , or the "" salience "" of an object . and i was just wondering whether that 's the same as what you describe as "" landmark iness "" . but it 's really not . an object can be very salient but not a landmark    or it can be als  no one knows it .   they 're are a couple of more things . would actually suggest we go through this one more time we all agree on what the meaning of these things is at the moment and what changes we   why is the landmark  the landmark is facing to the tourists . that 's because we 're talking about landmarks as touristic landmarks not as possible navigational landmarks   then   whatever granularity .    that 's very  the the context is a switch between tourist or non tourist ? or also unknown ?  the middle layer is also binary ? no . it  but all those things without question marks are also binary . right ? walls ?    i gotcha . we can either be in a hurry or not , but we cannot be in a medium hurry at the moment ?      the the landmark is the object right ? the argument in a sense ? that 's always warping on something some entity , and at this stage we will we do want to get modifiers in there because they may also tell us whether the person is in a hurry or not what 's the fastest way no , then it wouldn't be a demo i was just gonna s  but it however it the purpose was not really , at this stage , to come up with meaningful probabilities but to get thinking about that hidden middle layer . and th and  is it if you run out of cash as a tourist , and you need to go to the at  "" how do i get to the bank ? "" we what set the they set the context to "" unknown "" ?  and if we now do leave everything else as is the results should be the same , right ? the same ?   why don't we can we , how long would it take to add another node on the observatory and , play around with it ? let 's just say make it really simple . if we create something that would be th some things can be landmarks in your sense but they can never be entered ? a statue .  we wanna have "" landmark "" meaning now "" enterable landmark "" versus , something that 's simply just a vista point ,  a statue or if we include that ,  accessibility  "" is it can it be entered ? "" then this is binary as and then there 's also the question whether it may be entered . in the sense that , if it 's tom the house of tom cruise , it 's enterable but you may not enter it .  you 're not allowed to . unless you are , whatever , his divorce lawyer  and and these are very observable from the ontology things . y if you 're running an errand you more likely to be able to enter places that are usually not al w you 're not usually not allowed to let 's get this clearer . s it 's matrix between if it 's not enterable , period .  exactly . this is   right .  we would have what does it mean , then , that we have to we have an object type statue . that really is an object type . there is there 's gonna be a bunch of statues . and then we have , an object type , that 's a hotel . how about hotels ? the most famous building in heidelberg is actually a hotel . it 's the hotel zum ritter , which is the only renaissance building in heidelberg that was left after the big destruction and for the thirty years war , blah blah . it has wonderful walls . and lots of detail , c and carvings , engravings and forth ,  but , it 's still an unlikely candidate for the tango mode i must say . but . if you are a d it 's very tricky . guess your question is far i have no really arg no real argument why to differentiate between statues as statues and houses of celebrities , from that point of view .   let 's do a can we add , just can see how it 's done , a "" has door "" property or ? it might affect actually it 's it wouldn't affect any of our nodes , right ? it 's it affects th the "" doing business "" is certainly not . it should , inhibit that , right ?  just dis dismiss everything . close it and load up the old state it doesn't screw that up . you can read in ? command line . what is the c code ? can w can we see that ? how do you write the code or do you actually never have to write any code there ? n go right mouse . open with .  through the old notepad . that 's my favorite editor . wordpad ? i    this is lisp y ? no .  and that might do . do you have the true source files ","the middle layer is also binary ? and at this stage we will we do want to get modifiers in there because they may also tell us whether the person is in a hurry or not however it the purpose was not really , at this stage , to come up with meaningful probabilities but to get thinking about that hidden middle layer . how long would it take to add another node on the observatory and , play around with it ? and then there 's also the question whether it may be entered . guess your question is far i have no really arg no real argument why to differentiate between statues as statues and houses of celebrities , from that point of view . can we add , just can see how it 's done , a "" has door "" property command line . ",
Bed003.A,"or just the class ?  but if th if there is an xml file that or format that it can also read it just reads this , right ? when it starts .  wonderful . you got more slides ?  good . the it 's like yawning . and this announcement was in stereo .  this means  we general strategy here this is excellent because it gets you thinking along these terms is that we ob we could observe a couple of discourse phenomena such as the admission fee , and something else and something else , that happened in the discourse before . and let 's make those four . and there are two this could be separate region of the net , which has two has it 's own middle layer . this , has some funky thing that di if this and this may influence these hidden nodes of the discourse which is something that is a more general version of the actual phenomenon that you can observe . things that point towards pay a visit ""   exactly .  and then there are some discourse acts if they happened before , it 's more for cue that the person actually wants to get somewhere else and that you are in a in a route proceeding past these things , this would be just something that where you want to pass it .  is that it ? however these are then the nodes , the observed nodes , for your middle layer . this again points to "" final destination "" , "" doing business "" , "" tourist hurry "" and forth .  and then we can say , "" we have a whole region "" in a e exactly . and this is just then just one . because at the end the more we add , the more spider web ish it 's going to become in the middle and the more of hand editing . it 's going to get very ugly . but with this way we could say "" these are the discourse phenomena . they ra may have there own hidden layer that points to some of the real hidden layer , or the general hidden layer . and the same we will be able to do for syntactic information , the verbs used , the object types used , modifiers . and there 's a hidden layer for that . and forth and forth . then we have context .  precisely .    and if it if you do it if you could connect it too hard you may get such phenomenon that like "" how much has it cost to enter ? "" and the answer is two hundred fifty dollars , and then the persons says want to see it . ""  meaning "" it 's way out of my budget ""  nothing comes to mind . without thinking too hard .   opera premiers .  or any good old pink floyd concert .  that the h nothing beats the admission charge prices in japan . there , two hundred dollars is moderate for getting into a discotheque .  then again , everything else is free then once you 're ins in there . food and drink and forth .  but i i we can something somebody can have discussed the admission fee and u the answer is s if we still , based on that result is never going to enter that building .  because it 's just too expensive .   it works like this . the mean . the first thing we get is that already the intention is they tried to figure out the intention , right ? simply by parsing it . and this won't differentiate between all modes ,  but at least it 'll tell us "" here we have something that somebody that wants to go someplace , now it 's up for us to figure out what going there is happening , and if the discourse takes a couple of turns before everything all the information is needed , what happens is the parser parses it and then it 's handed on to the discourse history which is , one of the most elaborate modules . it 's actually the whole memory of the entire system , that knows what wh who said what , which was what was presented . it helps an anaphora resolution and it fills in all the structures that are omitted ,  because you say "" how can i get to the castle ? "" how much is it ? "" and would like to g let 's do it "" and forth . even without an a ana anaphora somebody has to make that information we had earlier on is still here . because not every module keeps a memory of everything that happened . whenever the person is not actually rejecting what happened before , as in "" no i really don't want to see that movie . i 'd rather stay home and watch tv "" what movie was selected in what cinema in what town is going to be added into the disc into the representations every di at each dialogue step , by the discourse model , that 's what it 's called . and , it does some help in the anaphora resolution and it also helps in coordinating the gesture screen issues . person pointing to something on the screen , the discourse model actually stores what was presented at what location on the s on the screen it 's a rather huge thing but we can it has a very clear interface . we can query it whether admission fees were discussed in the last turn and the turn before that or how deep we want to search which is a question . how deep do we want to sear ,  but we should try to keep in mind that , we 're doing this for research , ","but if th if there is an xml file that or format that it can also read is that we ob we could observe a couple of discourse phenomena such as the admission fee , and something else and something else , that happened in the discourse before . this could be separate region of the net , which has two has it 's own middle layer . which is something that is a more general version of the actual phenomenon that you can observe . they ra may have there own hidden layer that points to some of the real hidden layer , or the general hidden layer . and the same we will be able to do for syntactic information , something somebody can have discussed the admission fee and u the answer is s if we still , based on that result is never going to enter that building . and this won't differentiate between all modes , but at least it 'll tell us "" here we have something that somebody that wants to go someplace , what happens is the parser parses it and then it 's handed on to the discourse history which is , one of the most elaborate modules . it helps an anaphora resolution and it fills in all the structures that are omitted , the discourse model actually stores what was presented at what location on the s on the screen we can query it whether admission fees were discussed in the last turn ","The structure of the belief-net comprises, firstly, a feature layer, which includes linguistic, discourse and world knowledge information that can be gleaned from the data. It is possible for these variables to form thematic clusters( eg ""entrance"", ""type of object"", ""verb""), each one with a separate middle layer. These feed, in turn, into the main middle layer, that defines more general hidden variables, such as the tourist/business status of the user. "
Bed003.A,"we should find a limit that 's reasonable and not go , all the way back to adam and eve . did that person ever discuss admissions fee fees in his entire life ? and the dialogues are pretty concise and anyway .  the u it 's in the these plan schemas . there are some of them are extremely elaborate ,  "" what do you need to buy a ticket ? ""  and it 's fifty steps ,  just for buying a ticket at a ticket counter , and that 's helpful to look at it to look at those . it 's amazing what human beings can do . w when we talked we had the example , of you being s a person on a ticket counter working at railway station and somebody r runs up to you with a suitcase in his hands , says new york and you say track seven ,  and it 's because that person actually is following , you execute a whole plan of going through a hundred and fifty steps , without any information other than "" new york "" ,  inferring everything from the context . works . even though there is probably no train from here to new york , right ?  but it 's possible . no you probably have to transfer also somewhere else . right ? is that t san francisco , chicago ? is that possible ?   it never went all the way , right ? you always had to change trains at omaha , right ? one track ended there and the other one started at five meters away from that and  has anybody ever been on an amtrak ? their reputation is very bad .  it 's not reality . but i don't know whether it 's which ones are safer , statistically . much faster .  used amtrak quite a bit on the east coast and i was surprised . it was actually on boston new york , new york rhode island , whatever , boston .  but that 's a different issue .  that what you guys did is really nicely sketching out different tasks , and some of their conditions . one task is more likely you 're in a hurry when you do that doing business , and less in a hurry when you 're a tourist tourists may have never have final destinations , because they are eternally traveling around what happened what might happen is that we do get this task based middle layer , and then we 'll get these sub middle layers , that are more cue based . nah ? might be a dichotomy of the world . suggest w to for to proceed with this in the sense that throughout this week the three of us will talk some more about segmenting off different regions , and we make up some toy a observable "" nodes "" is that what th what 's the technical term ? for the nodes that are observable ? the "" outer layer "" ? feature ma make up some features for those identify four regions , make up some features for each region and and and middle layer for those . and then these should then connect somehow to the more plan based deep space the they will be aud ad hoc for some time to come . the day after tomorrow . wednesday .  isn't ben ? ben , then , ben .  the that will be one thing we could do . i actually have also we can start looking at the smartkom tables and i will i actually wanted to show that to you guys now but no i actually made a mistake because it fell asleep and when linux falls asleep on my machine it 's it doesn't wake up ever , had to reboot and if i reboot without a network , i will not be able to start smartkom , because i need to have a network . we 'll do that t  it looks up some that , is that is in the written by the operating system only if it if you get a dhcp request , it my computer does not know its ip address ,   unless it boots up with networking . and i don't have an ip address , they can't look up they don't know who localhost is , and forth and forth . always fun . but it 's a , simple solution . we can just go downstairs and look at this , but not today . the other thing will  i have to report data collection . we interviewed fey , she 's willing to do it , meaning be the wizard for the data collection , also transcribe a little bit , if she has to , but also recruiting subjects , organizing them , and forth . that looks good . jerry however suggested that we should have a trial run with her , see whether she can actually do all the spontaneous , eloquent and creativeness that we expect of the wizard . and i talked to liz about this and it looks as if friday afternoon will be the time when we have a first trial run for the data . pardon me ? liz also volunteered to be the first subject , which might be even better than us guys . if we do need her for the technical then one of you has to jump in .  yes w we would like to test the wizard , but if we take a subject that is completely unfamiliar with the task , or any of the set up , we get a more realistic set up as    think it 's it 's experimental setup u on the technical issue yes , except we st we still need recording device for the wizard , just a tape recorder that 's running in a room . but in terms of specifying the scenario , we 've gotten a little further ","there are some of them are extremely elaborate , what happened what might happen is that we do get this task based middle layer , suggest w to for to proceed with this in the sense that throughout this week the three of us will talk some more about segmenting off different regions , identify four regions , make up some features for each region middle layer for those . and then these should then connect somehow to the more plan based deep space also we can start looking at the smartkom tables i have to report data collection . we interviewed fey , she 's willing to do it , meaning be the wizard for the data collection , also transcribe a little bit , if she has to , but also recruiting subjects , organizing them , and forth . jerry however suggested that we should have a trial run with her , and it looks as if friday afternoon will be the time when we have a first trial run for the data . yes w we would like to test the wizard , but if we take a subject that is completely unfamiliar with the task , or any of the set up , we get a more realistic but in terms of specifying the scenario , we 've gotten a little further ","The feature layer can end up being cue-based, while the middle layers task-based. These feed, in turn, into the main middle layer, that defines more general hidden variables, such as the tourist/business status of the user. However, there has been progress in the design and organisation of experiments, that will eventually provide data more useful and appropriate for this task. "
Bed003.A,"but we wanted to until we know who is the wizard , and have the wizard partake in the ultimate definition probe . if on friday it turns out that she really likes it and we really like her , then nothing should stop us from sitting down next week and getting all the details completely figured out . and yea some . bu e i 'm even this tango , enter , vista is itself , an ad hoc scenario . the basic u idea behind the data collection was the following . the data we get from munich is very command line , simple linguistic hardly anything complicated . no metaphors whatsoever . not a rich language . we wanted just to collect data , to get that elicits more , that elicits richer language . and we actually did not want to constrain it too much ,  just see what people say . and then we 'll discover the phenomenon the phenomena that we want to solve , with whatever engine we come up with . this is a parallel track , there they hopefully meet , but since it should tell us , what phenomenon could occur , it should tell us also something about the difference between people who think they speak to a computer versus people who think they speak to a human being and the differences there . it may get us some more information on the human machine pragmatics , that no one knows anything about , as of yesterday . and nothing has changed since then ,  and secondly , now that we have started to lick blood with this , and especially since johno can't stop tango ing , we may actually include , those intentions . now we should have at least one navigational task with explicit not ex it 's implicit that the person wants to enter , and some task where it 's more or less explicit that the person wants to take a picture , or see it that we can label it . that 's how we get a corpus that we can label . whereas , if we 'd just get data we 'd never they actually wanted , we 'd get no cues .  that was that . ma we ought to switch off these things before we continue . ","but we wanted to until we know who is the wizard , and have the wizard partake in the ultimate definition probe . if on friday it turns out that she really likes it and we really like her , then nothing should stop us from sitting down next week and getting all the details completely figured out . bu e i 'm even this tango , enter , vista is itself , an ad hoc scenario . the basic u idea behind the data collection was the following . the data we get from munich is very command line , not a rich language . we wanted just to collect data , to get that elicits more , that elicits richer language . and we actually did not want to constrain it too much , this is a parallel track , it may get us some more information on the human machine pragmatics , that no one knows anything about , as of yesterday . now we should have at least one navigational task with explicit not ex it 's implicit that the person wants to enter , and some task where it 's more or less explicit that we can label it . ","However, there has been progress in the design and organisation of experiments, that will eventually provide data more useful and appropriate for this task. "
Bed003.B,"goats eat cans , to my understanding . tin cans . could i hit f seven to do that ? on the robert ? the remote will do it  cuz i 'm already up there ? you are in control . already ? i it makes it easier to do we were   let 's see . which one of these buttons will do this for me ? aha !  do i wanna go back to the first one ?   introduce . although i 've never i don't the light bulb is for . i didn't i install that into my powerpoint presentation .  i 'd prefer not to . because i 'm gonna switch to the javabayes program and then if i do that it 'll mess everything up . is that you want me to what do you want me to do ? can do that , but then i have to end the presentation in the middle can go back to open up here , let 's see if is that better ?  'll also get rid of this "" click to add notes "" .  then the features we decided or we decided we were talked about , right ? the prosody , the discourse , verb choice . we had a list of things like "" to go "" and "" to visit "" and what not . the "" landmark iness "" of i knew you 'd like that .  of a building . whether the and this i we actually have a separate feature but i decided to put it on the same line for space . "" walls "" which we can look up because if you 're gonna get real close to a building in the tango mode , right , there 's gotta be a reason for it . and it 's either because you 're in route to something else or you wanna look at the walls . the context , which in this case we 've limited to "" business person "" , "" tourist "" , or "" unknown "" , the time of day , and "" open to suggestions "" , isn't actually a feature . it 's "" we are open to suggestions . ""  they 're separate things .  i either could put "" walls "" on its own line or "" open to suggestions "" off the slide . right . or one time i was at this but see if it 's but if it 's architecturally significant you might be able to see it from like you m might be able to "" vista "" it , right ? and be able to  versus i was at this place in europe where they had little carvings of dead people on the walls i don't remember w it was a long time ago . but if you looked at it real close , you could see the in intricacy of the walls . right . exactly . robert ? right .  right . right . but  tourist y landmarks also happen to be wouldn't couldn't they also be they 're not exclusive groups , are they ? like non tourist y landmarks and direct navigational   our initial idea was not very satisfying , because our initial idea was all the features pointing to the output node .  right . and we reasons being , it 'd be a pain to set up all the probabilities for that . if we moved onto the next step and did learning of some sort , according bhaskara we 'd be handicapped . i don't know belief nets very and they wouldn't look pretty .   then our next idea was to add a middle layer , right ? the thinking behind that was we have the features that we 've drawn from the communication of some like , the someone s the person at the screen is trying to communicate some abstract idea , like "" i 'm "" the abstract idea being "" i am a tourist i want to go to this place . "" right ? we 're gonna set up features along the lines of where they want to go and what they 've said previously and whatnot . and then we have the means that they should use . right ? but the middle thing , we were thinking along the lines of trying to figure out the concept of whether they 're a tourist or whether they 're running an errand like that along those lines . or yes , we could things we couldn't extract the from the data , the hidden variables . yes , good . then the hidden variables hair variables we came up with were whether someone was on a tour , running an errand , or whether they were in a hurry , because we were thinking if they were in a hurry there 'd be less likely to like or th right . or they might be more likely to be using the place that they want to go to as a like a navigational point to go to another place . whether the destination was their final destination , whether the destination was closed . those are all and then "" let 's look at the belief net "" that means that i should switch to the other program . right now it 's still in a toy version of it , because we didn't know the probabilities of or 'll talk about it when i get the picture up .  this right what we let 's see . what happens if i maximize this ? there we go . but the mode has three different outputs . the probability whether the probability of a vista , tango , or enter . the "" context "" , we simplified . it 's just the businessman , the tourist , unknown . "" verb used "" is actually personally amusing ","then the features we decided or we decided we were talked about , the prosody , the discourse , verb choice . we had a list of things like "" to go "" and "" to visit "" and what not . the "" landmark iness "" of "" walls "" which we can look up the context , which in this case we 've limited to "" business person "" , "" tourist "" , or "" unknown "" , the time of day , our initial idea was not very satisfying , because our initial idea was all the features pointing to the output node . reasons being , it 'd be a pain to set up all the probabilities for that . if we moved onto the next step and did learning of some sort , according bhaskara we 'd be handicapped . then our next idea was to add a middle layer , but the middle thing , we were thinking along the lines of trying to figure out the concept of whether they 're a tourist or whether they 're running an errand like that yes , we could things we couldn't extract the from the data , the hidden variables . then the hidden variables hair variables we came up with were whether someone was on a tour , running an errand , or whether they were in a hurry , right now it 's still in a toy version of it , because we didn't know the probabilities of or the mode has three different outputs . the probability whether the probability of a vista , tango , or enter . the "" context "" , we simplified . it 's just the businessman , the tourist , unknown . ","The structure of the belief-net comprises, firstly, a feature layer, which includes linguistic, discourse and world knowledge information that can be gleaned from the data. These feed, in turn, into the main middle layer, that defines more general hidden variables, such as the tourist/business status of the user. The group discussed the first version of the Bayes-net used to work out a user's intentions when asking for directions from a navigation device. The latter determine the final probability of each intention in the output layer. Three intentions were identified: Vista (to view), Enter (to visit) and Tango (to approach). "
Bed003.B,"mainly because it 's just whether the verb is a tango verb , an enter verb , or a vista verb . no .  right .  why don't you mention things about this , bhaskara , that i am not that are not coming to my mind right now . it 's it 's it is because it 's because have the time of day and the close it just had the er and what time it closed . the actual parse is somewhere up around in here . right . right . there were there 'd be other things besides just the admission fee , but we didn't have that was the initial one that we found . from the discourse that  right . one , anything else you want to say bhaskara ? one thing th  one thing i 'm unsure about , is how we have the discus the "" admission fee "" thing set up . one thing that we were thinking was by doing the layers like this , we kept things from directly affecting the mode beyond the concept , but you could see perhaps discus the "" admission fee "" going directly to the mode pointing at "" enter "" , right ? versus pointing to just at "" tourist "" ,  but we just decided to keep all the things we extracted to point at the middle and then down . right . navigational landmarks ,   that would be whatever building they referred to . that 's how we have it currently set up , but it could be , based upon hour or dis we could discrete it des descret ize it . right . or un unknown ,  wi it is binary but it doesn't have question mark because it 's extracted .   i want to get to the church quickly , and right . excellent . do we have anything else to say about this ? the we could . but the demo doesn't work very observe nodes .  dat dah . what should i observe ?    i love walls ,  i 'm a big fan . and the time of day is night ? alright . they  whoops . i forgot to ach ! one thing that bugs me about javabayes is you have to click that and do this . that all you want ?  let 's see . i want to query , right ? the mode . and then on here let 's see .  if it 's night time , they have not discussed admission fee , and the n walls are  that makes sense . the reason i say the demo doesn't work very is yesterday we observed everything in favor of taking a tour , and it came up as "" tango "" , right ? over and over again . we couldn't figure out how to turn it off of "" tango "" .    that 's at spent my youth practicing the tango de la muerte . we would actually once we look at the data more we 'll get more hidden nodes , but i 'd like to see more . not because it would expedite the probabilities , cuz it wouldn't . it would actually slow that down tremendously . but . no , we should have exponentially more middle nodes than features we 've extracted . i 'm ju i 'm just jo the of "" doing business "" as more of running an errand type thing . wi th right .  right .  no . we were thi  we were th it depends on how many things it 's linked to . right . that 's true . also didn't we have a size as one ? the size of the landmark . cuz if it 's  for some reason i had that that was a thought that i had at one point but then went away . way does it actually help to distinguish between those two cases though ? whether it 's practically speaking enterable , or actually physically enterable or not ? can see why whether it 's a public building , and whether it 's actually has a door .  tom cruise 's house is not a public building but it has a door . but sh explain to me why it 's necessary to distinguish between whether something has a door and is not public . or , if something it seems like it 's equivalent to say that it doesn't have a door a and it or "" not public "" and "" not a door "" are equivalent things , it seems like in practice . right .   does it have walls ? excellent .  you could affect theoretically you could affect "" doing business "" with "" has door "" . let 's see . we have it saved . we can rel open it up again . the safety net . let 's see . this is "" has door "" true , false . that 's acceptable . and i want to edit the function going to that , right ? no . right . it was fine . added this one . this  it might be did we w yes , that 's not good . let 's see .  no it doesn't , actually . i didn't think it did learning . it did a little bit of learning , i don't remember . which is w quite positive ,  but actually it had an interface . a lot of them were like ,  the c there 's like an xml format for bayes nets . the there is one . i don't know if this uses it . but it the  yes i do actually . let me see . man , i didn't n is there an ampersand in dos ? we that 's alright . probably double cli click on it . let 's see . let 's see , come on . one of these days , it should open this , theoretically . ","mainly because it 's just whether the verb is a tango verb , an enter verb , or a vista verb . we kept things from directly affecting the mode beyond the concept , but you could see perhaps discus the "" admission fee "" going directly to the mode pointing at "" enter "" , but we just decided to keep all the things we extracted to point at the middle and then down . the reason i say the demo doesn't work very is yesterday we observed everything in favor of taking a tour , and it came up as "" tango "" , once we look at the data more we 'll get more hidden nodes , whether it 's a public building , and whether it 's actually has a door . explain to me why it 's necessary to distinguish between whether something has a door and is not public . you could affect theoretically you could affect "" doing business "" with "" has door "" . i didn't think it did learning . it did a little bit of learning , but actually it had an interface . a lot of them were like , ","This first model of the belief-net was built in JavaBayes, since it is a free package, has a graphical interface, and it can take XML files as input. "
Bed003.B,"there we go . it was just  w it was dead . to the world .  i like word pad because it has the the returns , the carriage returns on some of them . how they get "" auto fills "" or whatever you call it . it just looks like it just specifies a bunch of  it just that it 's the ordering isn't very clear on actually we could write a program that could generate this . you could . we were doing it we could manipulate the source itself ? or i don't know if he actually does he  i didn't e up one . yes , good . "" source "" . that 's quite right . know there is an i was looking on the we web page and he 's updated it for an xml version of bayes nets . there 's a bayes net spec for in xml .  th you can either you ca or you can read both . to my understanding . because at least the i could have misread the web page , i have a habit of doing that , but . do i have more slides ? yes , one more . "" future work "" . every presentation have a should have a "" future work "" slide . but it 's we already talked about all this  that 's future work . right . and if you have a presentation that doesn't have something that doesn't work then you have "" what i learned "" , as a slide . you could . my first approach failed . what i learned . think that our presentation 's finished . i like about these meetings is one person will nod , and then the next person will nod , and then it just goes all the way around the room . no i earlier i went and bhaskara went and you did it . you did it . should i pull up the net again ? yes . there we go . and actually i was cuz i got a wireless mike on . instead of single node , for like , if they said the word "" admission fee "" "" admission fee "" , or "" how much to enter ""  other cues . exactly . that would all f funnel into one node that would constitute entrance requirements like that .  one thing that 's been bugging me when i more i look at this is that the the fact that the there 's a complete separation between the observed features and in the output . it makes it cleaner , but then mean . if the discourse does the "" discourse admission fee "" node seems like it should point directly to the or increase the probability of "" enter directly "" versus "" going there via tourist "" . right .  that makes sense . there are places in germany where it costs two hundred fifty dollars to enter ? really ? i see . if you want to see "" the magic flute "" the spagos of heidelberg .   see . the discourse refers to "" admission fee "" but it just turns out that they change their mind in the middle of the discourse . right . what discourse processing is are the how much is built into smartkom and     you 'd probably have to transfer in chicago .  one time i saw a report on trains , and there is a l i don't know if there was a line that went from somewhere , it was sacramento to chicago , but there was like a california to chicago line of some sort . i could be wrong though . it was a while ago .  but i don't know if it 's still they might have blown it up . i 'm frightened by amtrak myself .  they seem to have a lot of accidents on the amtrak .  this is going to be an interesting transcript .  it 'd help it figure it out .  refined y re just refine the the features , i don't know , whatever you just refine some of the more general nodes . some of them are completely absurd too , like they want to enter , but it 's closed , it 's night time ,  there are tourists and all this weird happens at the line up and you 're like confused .  who 's talking on wednesday ? i haven't j jerry never sent out a sent out an email , did he , ever ?   right . do you want to trade ?  why does smartkom need a network ?  it 's plugged in .  one of us ,  i like how we 've you guys have successfully narrowed it down . "" is one of you going to be the subject ? "" is one of you jump in .  i know . that 's probably a good enough test of i like that . "" test the wizard . "" i want that on a t shirt . alrighty . is this the official end of the meeting now ? randomly label things . that has nothing to do with economics or anything . ","the ordering isn't very clear on know there is an i was looking on the we web page and he 's updated it for an xml version of bayes nets . th you can either you ca or you can read both . that would all f funnel into one node that would constitute entrance requirements like that . the fact that the there 's a complete separation between the observed features and in the output . the "" discourse admission fee "" node seems like it should point directly to the or increase the probability of "" enter directly "" versus "" going there via tourist "" . the discourse refers to "" admission fee "" but it just turns out that they change their mind in the middle of the discourse . what discourse processing is are the how much is built into smartkom and ","This first model of the belief-net was built in JavaBayes, since it is a free package, has a graphical interface, and it can take XML files as input. "
Bed003.C," right . i 've have never handled them .  johno , where are you ? should you go back to the first one ?  just to "" the search for the middle layer "" . it 's talks about it just refers to the fact that one of main things we had to do was to decide what the intermediate nodes were , because can you maximize the window ? can you maximize the window all that on the side isn't doesn't appear ? fine . alright .  no . we have a separate feature . like you could have a p you like you could have a post office with murals architecturally appealing from the outside .  we meant , touristic reasons .   usually , n if you have n features , then it 's two to the n or exponential in n .  they 'd all be like pointing to the one node . want to do vista , right ? because if you want to view things you wouldn't be in a hurry .  that one needs a lot of not that 's that needs a lot of work . but that would 've made the probably significantly be more complicated to enter , we decided that for the purposes of this it 'd be simpler to just have three verbs . note the four nodes down there , the the things that are not directly extracted . actually , the five things . the "" closed "" is also not directly extracted from the  actually , no ,  it is . "" closed "" is . right ,  right , but the other ones , the final destination , the whether they 're doing business , whether they 're in a hurry , and whether they 're tourists , that thing is all probabilistically depends on the other things .  and the mode , depends on all those things only .  we haven't managed like we don't have nodes for "" discourse "" and "" parse "" , although like in some sense they are parts of this belief net . but the idea is that we just extract those features from them , we don't actually have a node for the entire parse , because we 'd never do inference on it anyway ,  whether they discuss the admission fees . we looked at the data and in a lot of data people were saying things like "" can i get to this place ? "" "" what is the admission fee ? "" . that 's like a huge clue that they 're trying to enter the place rather than to tango or vista ,  that was like our example .   i m  right . let 's see . the variables . disc "" admission fee "" is a binary thing , "" time of day "" is like morning , afternoon , night . is that the deal ?       normally context will include a huge amount of information , but we are just using the particular part of the context which consists of the switch that they flick to indicate whether they 're a tourist or not ,  right , it 's not really all of context . similarly prosody is not all of prosody but simply for our purposes whether or not they appear tense or relaxed . and  unknown , right ? which is th which one ? it does . everything is probablistic , and there 's always  right . then landmark is   "" verb used "" is like , right now we only have three values , but in general they would be a probability distribution over all verbs . rather , let me rephrase that . it can take values in the set of all verbs , that they could possibly use . walls "" is binary , "" closed "" is binary "" final destination "" , again all those are binary and "" mode "" is one of three things .  anything with a question mark after it in that picture is a binary node . which things ?  "" walls "" is something that we extract from our world knowledge . a it is binary . that 's true .  i see your point . similarly "" closed "" , we to do that we would add another value for that . and that would require s updating the probability distribution for "" mode "" as because it would now have to like take that possibility into account .  right . other syntactic information    right .  correct . we can do a little demo . we can do a demo in the sense that we can just ob observe the fact that this will , do inference . we can , set some of the nodes and then try to find the probability of other nodes . just se set a few of them . you don't have to do the whole thing that we did last time . just like the fact that they use a certain verb actually forget the verb . just i don't know , say they discussed the admission fee and the place has walls and it 's night .  no  that doesn't it 's not really consistent . they don't discuss the admission fee . make that false . and it 's night . that didn't work .  yes . "" go "" and , right , "" query "" . that is the probability that they 're entering , vista ing or tango ing . and  it loves the tango . that 's just to do with our probabilities . like , we hand tuned the probabilities , right . we were like "" if the person does this and this , let 's say forty percent for this , fifty per "" like , that 's gonna happen .  it 's we have to like fit the probabilities .    not that much though . only a little early .   that 's an interesting point . ","it 's talks about it just refers to the fact that one of main things we had to do was to decide what the intermediate nodes were , if you have n features , then it 's two to the n or exponential in n . that 's that needs a lot of work . but the other ones , the final destination , the whether they 're doing business , whether they 're in a hurry , and whether they 're tourists , that thing is all probabilistically depends on the other things . like we don't have nodes for "" discourse "" and "" parse "" , although like in some sense they are parts of this belief net . but the idea is that we just extract those features from them , we don't actually have a node for the entire parse , we looked at the data and in a lot of data people were saying things like "" can i get to this place ? "" "" what is the admission fee ? "" . that 's like a huge clue that they 're trying to enter the place rather than to tango or vista , normally context will include a huge amount of information , but we are just using the particular part of the context which consists of the switch that they flick to indicate whether they 're a tourist or not , similarly prosody is not all of prosody but simply for our purposes whether or not they appear tense or relaxed .  we can do a demo in the sense that we can just ob observe the fact that this will , do inference . we can , set some of the nodes and then try to find the probability of other nodes . that 's just to do with our probabilities . like , we hand tuned the probabilities , ","These feed, in turn, into the main middle layer, that defines more general hidden variables, such as the tourist/business status of the user. At this stage, all the actual probabilities are ad-hoc and hand-coded. "
Bed003.C,"whether you 're it 's whether it 's not it 's more like "" are you are tourist ? are you in ham like heidelberg for a "" that 's a different thing . what if the context , which is not set , but still they say things like , "" i want to go see the the castle and et cetera . ""  business on the other hand is , definitely what you 're doing .  and that 'll affect whether you want to enter or you if you kinda thing .  this context node is a bit of a i don't know , like in d do we wanna have like it 's if the context were to set one way or another , that like strongly says something about whether or not they 're tourists . what 's interesting is when it 's not when it 's set to "" unknown "" . right now we haven't observed it , guess it 's averaging over all those three possibilities . but yes , you can set it to un "" unknown "" . no , because we th the way we set the probabilities might not have  it 's an it 's an issue , right ? like  it is . the issue is that in belief nets , it 's not common to do what we did of like having , a d bunch of values and then "" unknown "" as an actual value . what 's common is you just like don't observe the variable , right , and then just marginalizes but we didn't do this because we felt that there 'd we were thinking in terms of a switch that actually but don't know y what the right thing is to do for that . i 'm not i don't know if i am happy with the way it is . another node on what ? good point . it 's addressing a variable that 's "" enterable or not "" . like an "" enterable , question mark "" . what ? not when we were doing this , but at some point we did . you want to have a node for like whether or not it can be entered ?       what would it , connect to ? like , what would , it affect ? what i was thinking was if you had a like   right .  i don't know if javabayes is about that . it might be that if you add a new thing pointing to a variable , you just like it just overwrites everything . but you can check .  it 's true . that 's fine , but we have to see the function now . has it become all point fives or not ? no . this is fine , this business .  what would be if it is if it just like kept the old function for either value but . nope . didn't do it . that 's annoying .  ha have you used javabayes a lot ?  it might be worth asking around . like , we looked at page that had like a bunch of   s he 'd be the person .  cuz  in a way this is a lot of good features in java it 's cra has a gui and it 's those are the main two things . it does learning , it has what ?  right . you 're right .  right . but it 's free . but  another thing that but its interface is not the greatest .   there is actually a text file that you can edit . but it 's you don't have to do that . is it xml ? i see . no this doesn't use it . i didn't think it did . you can look at the text file . but do you have it here ? you don't . yes ,  like , there 's the nope . just s l start up a new dos . or right .  it 'll ask you what it wants what you want to open it with and see what bat , that 's  anyway , there it is .   that 's how actual probability tables are specified . as lists of numbers . theoretically you could edit that . but they 're not very friendly . you 'd have to like figure out like you have to go and     it 's not  we can write an interface th for entering probability distributions easily , something like a little script . that might be worth it . the other thing is it is in java   we do i saw directory called "" source "" , or  go up one ?  i don't know if it actually manipulate the source , though . that might be a bit complicated . it might be simpler to just have a script that , it 's friendly , it allows you enter things  he 's like this guy has ? the javabayes guy ? but , e he doesn't use it . in what sense has he updated it ? i see .  that would be awesome .  the additional thing is learning the probabilities , also . e that 's i don't know if does that 's  very future . ha .      essentially a lot of those nodes can be expanded into little bayes nets of their own .  that 's true .  or we could like add more , middle nodes . like we could add a node like do they want to enter it , which is affected by admission fee and by whether it 's closed and by whether it has a door . it 's like there are those are the two options . either like make an arrow directly or put a new node . really .  what ? why ? really ?  and there 's much more of them . they 're it 's way better  i 've done that thing . ","it 's more like "" are you are tourist ? that 's a different thing . if the context were to set one way or another , that like strongly says something about whether or not they 're tourists . the issue is that in belief nets , it 's not common to do what we did of like having , a d bunch of values and then "" unknown "" as an actual value . what 's common is you just like don't observe the variable , and then just marginalizes but we didn't do this because we felt that there 'd we were thinking in terms of a switch that actually you want to have a node for like whether or not it can be entered ? i don't know if javabayes is about that . it might be that if you add a new thing pointing to a variable , you just like it just overwrites everything . what would be if it is if it just like kept the old function for either value in a way this is a lot of good features in java it 's cra has a gui and it 's but it 's free . but its interface is not the greatest . there is actually a text file that you can edit . theoretically you could edit that . but they 're not very friendly . we can write an interface th for entering probability distributions easily , something like a little script . i don't know if it actually manipulate the source , though . that might be a bit complicated . it might be simpler to just have a script that , essentially a lot of those nodes can be expanded into little bayes nets of their own . ","This first model of the belief-net was built in JavaBayes, since it is a free package, has a graphical interface, and it can take XML files as input. "
Bed003.C,"i want to see what it does with landmark iness "" . that 's    for which ? just observable nodes , evidence nodes ?   this is like the probabilities and all are completely ad hoc . we need to look of them . but , they 're even like like , close to the end we were like , we were like really ad hoc . right ? cuz if it 's like , if it 's four things coming in , right ? and , say , some of them have like three possibilities and all that . you 're thinking like a hundred and forty four possible things numbers to enter , right ?  the only like possible interpretation is that they are like come here just to rob the museum to that effect .  another thing to do , is also to , guess to ask around people about other bayes net packages . is srini gonna be at the meeting tomorrow , do  day after tomorrow .  we can ask him about it . no . but he mentioned at the last meeting that someone was going to be talking , i forget who .   but .  but once you start sart start smartkom you can be on you don't have to be on a network anymore . is that the deal ? interesting . who would be the subject of this trial run ? who will there be a is one is you one of you gonna be the subject ? like are you just figured it has to be someone who 's , familiar enough with the data to problems for the wizard , we can , see if they 're good .  that 's what we wanna check , right ? isn't that what it is ? that would be reasonable . having an actively antagonistic ,   what 's "" economics , the fallacy "" ? really ?  ","the probabilities and all are completely ad hoc . another thing to do , is also to , guess to ask around people about other bayes net packages . just figured it has to be someone who 's , familiar enough with the data to problems for the wizard , we can , see if they 're good . ","At this stage, all the actual probabilities are ad-hoc and hand-coded. "
Bed003.D," is that good ? did we need to do these things ?   we 're all high tech here . yet another p powerpoint presentation . certainly does . i 'm  read ! i 'm kidding .  ach u it 's a needless good idea . is that the idea ?  i was wondering . it 's proceed . very perfect . coinage . right . can ask the walls part of it is that in this particular domain you said be i it could be on two different lines but are you saying that in this particular domain it happens the that landmark iness cor is correlated with their being  and by ""  walls "" is a stand in for like architecturally it , significant like that .     there 's a lot of those .  that count as counts as a wall . the  right . something you want to inspect at close range because it 's interesting .   not a landmark there 's landmark for touristic reasons and landmark for i don't know navigational reasons   but you can imagine wanting the oth both kinds of things there for different goals . right ? they 're not mutually exclusive ? right . right . definitely . a big flat structure . right ?  and are those mutually exclusive sets ? right . got it .   simple . stab at it .  from the utterance ? inferred from the other ones ?    some of the top row of things what 's what 's "" disc admission fee "" ?    i see .   there are certain cues that are very strong either lexical or topic based concept cues for one of those . and then in that second row or whatever that row of time of day through that all of those some of them come from the utterance and some of them are either world knowledge or situational things . right ? that you have no distinction between those and  "" unmark @ @ time of day ""   navigational cue . prosody .   that 's given in their input . right ?  final dest it seems like that would really help you for doing business versus tourist , but  the context being e i don't know if that question 's in general , "" are you "" the ar are do they allow business people to be doing non business things at the moment ?  then you just have some probabilities over  over which of those it is .      take a conti this will happen when we think more about the kinds of verbs that are used in each cases but you can imagine that it 's verb plus various other things that are also not in the bottom layer that would help you like it 's a conjunction of , i don't know , the verb used and some other that would determine  exactly .  usually . i don't know if that 's always the case haven't looked at the data as much as you guys have .     that would be a cue .    go ahead . it 's starting to grow on me i 'd like to do that again .  that seems redundant but .  slightly biased toward "" tango "" ing        right . the bias toward "" tango "" ing was yours , then ? the real case ?  are "" doing business "" versus "" tourist "" they refer to your current task . like current thing you want to do at this moment . and are th  that was directly given by the context switch .  i see , you may have a task . wh you have to go get money and you are doing business at that stage . i see .   the "" tourists "" node should be very consistent with the context node . right ? if you say that 's more their in general what their background is . are you assuming that or not ? like is that to be if that 's accurate then that would determine tourist node .         it seems like it would for determining whether they wanna go into it or not . cuz they  right .  you could just add it . i have before  whew ! right .  yes . really i ha i 've i haven't used it a lot and i haven't used it in the last many months  we can ask someone .   srini srini 's the one to ask i would say . he might know . and .      god !    right . the layout of the table .  you could .  i actually seem to recall srini complaining about something to do with entering probability this is probably it 's    the d the data tables .   can't you have both ? right . i missed my turn . it 's like yawning .  could you put the net up again ?  more general thing than "" discussed admission fee "" could be i 'm just wondering whether the context , the background context of the discourse might be i don't know , if there 's a way to define it or generalize it some way there might be other cues that , say , in the last few utterances there has been something that has strongly associated with say one of the particular modes i don't know if that might be and into that node would be various things that could have specifically come up .  right . exactly .  opening hours like that .  it get into plan recognition kinds of things in the discourse . that 's like the bigger version of it .  that 's a whole set of discourse related cues to your middle layer . right ?  what do by that ?    or famous restaurant . or , i don't know . there are various things that you might w not want to eat a meal there but your own table .  you have to have some notion of not just there 's a there 's change across several turns of discourse ","there 's landmark for touristic reasons and landmark for navigational reasons but you can imagine wanting the oth both kinds of things there for different goals . there are certain cues that are very strong either lexical or topic based concept cues and then in that second row or whatever that row of time of day through that all of those some of them come from the utterance and some of them are either world knowledge or situational things . this will happen when we think more about the kinds of verbs that are used in each cases but you can imagine that it 's verb plus various other things that are also not in the bottom layer that would help you are "" doing business "" versus "" tourist "" they refer to your current task . that was directly given by the context switch . the "" tourists "" node should be very consistent with the context node . it get into plan recognition kinds of things in the discourse . that 's a whole set of discourse related cues to your middle layer . ","The feature layer can end up being cue-based, while the middle layers task-based. The structure of the belief-net comprises, firstly, a feature layer, which includes linguistic, discourse and world knowledge information that can be gleaned from the data. "
Bed003.D,"don't know how if any of this was discussed but how i if it all this is going to interact with whatever general other discourse processing that might be happen .  one thing that might be helpful which is implicit in the use of "" admission fee discussion "" as a cue for entry , is thinking about the plans that various people might have . like all the different general schemas that they might be following  this person is finding out information about this thing in order to go in as a tourist or finding out how to get to this place in order to do business . because then anything that 's a cue for one of the steps would be slight evidence for that overall plan . i don't know . they 're in non in more traditional ai kinds of plan recognition things you have some idea at each turn of agent doing something , "" wha what plans is this a consistent with ? "" and then get s some more information and then you see "" here 's a sequence that this roughly fits into "" . it might be useful here too . i don't know how you 'd have to figure out what knowl what knowledge representation would work for that .     not direct . the transcontinental railroad , doesn't that ring a bell ? it has to exist somewhere . most of the way .   you seem to know better than we do i have . but not transcontinentally . it 's not like german trains . like german trains are really great  but they 're faster .    let 's all say it a few more times . just kidding . right . tha that structure that robert drew on the board was like more cue type based , right , here 's like we 're gonna segment off a bit of that comes from discourse and then some of the things we 're talking about here are more we mentioned if they talk about i don't know , entering or som like they might be more task based . don't know if there 's some m more than one way of organizing the variables into something      that feed into those ?  it 's a even distribution . like , whatever . and that 's terrible . that 's in which case you 're supposed to alert the authorities , and see appropriate action .  quite possibly .   wednesday ,   ben ? it 's ben actually ,   giving his job talk   i was just reading the screen . no .   good . reference . i haven't done it yet . plants ? e u someone who can plant difficult things . in this case it 's a p it 's a testing of the wizard rather than of the subject . it 's    that might be a little unfair .  i 'm if we you think there 's a chance we might need liz for , whatever , the technical side of things ? i 'm we can get other people around who don't know anything if we want another subject . like drag ben into it although he might problems but . is it a experimental setup for the data collection ready determined ?     the ideal task will have whatever i don't know how much the structure of the evolving bayes net will af affect like we wanna be able to collect as much of the variables that are needed for that , right ? in the course of the task ? not all of them but        in other words this data collection is more general . it could be used for not just this task .      exactly . looks like it .  switching o ","one thing that might be helpful which is implicit in the use of "" admission fee discussion "" as a cue for entry , is thinking about the plans that various people might have . they 're in non in more traditional ai kinds of plan recognition things you have some idea at each turn of agent doing something , tha that structure that robert drew on the board was like more cue type based , and then some of the things we 're talking about here are more entering or som like they might be more task based . is it a experimental setup for the data collection ready determined ? like we wanna be able to collect as much of the variables that are needed for that , ","The feature layer can end up being cue-based, while the middle layers task-based. "
Bed005.A,"got my mike on .  let 's see . doesn't , it should be the other way . now it 's on . we are all switched on ,  where are those constructors defined ? grep for it ? that function automatically generates an initialized xml structure ? it 's mystery functions . it just automatically initializes things that are common , right ? it 's just a shorthand . a "" not a number "" is a value . awesome . then , whatever takes this m three l is what actually changes the state , not the   with sugge suggested improvements and    then the scope of this is beyond approach and vis or vista .   what would   but i 'm just but the  just this xml here just has to do with source path goal type in terms of traveling through heidelberg . or travel , specifically . but this o is the domain greater than that ?    could you give me an example of a reference problem ? make it more concrete ?  or the re the restaurant where they wear lederhosen ? or is that   trying to  you can put the microphone in your pocket . i was envying you and your pocket don't have one . exactly  asymptotically . u  really , i what a noisy or seems to neural net acize "" these bayes nets ?  my point was more that we just with the neural net , right , things come in , you have a function that combines them and right . hash on object name to , the probabilities or whatever . we could just steal the classes in javabayes and then interface to them with our own code . it depends on i was j  no , but that just means there 's a protocol , right ? that you could no , but what i the you could have four different bayes nets that you 're running , and then run your own write your own function that would take the output of those four , and make your own "" g function "" , is what i was saying . then you 'd have to break all of your bayes nets into smaller bayes nets , with all the but i 'm just i was thinking we should just cough into the microphone and see if they can't th see if they can handle it . ",it 's mystery functions . ,
Bed005.B,"ami , do yours then we 'll open it and it 'll be enough .  we all switched on ? alright . anyway . before we get started with the , technical part , want to review what is happening with the our data collection . probably after today , that shouldn't come up in this meeting . th this is s should be im it isn't there 's another thing going on of gathering data , and that 's independent of this . but , want to make we 're all together on this . what we think is gonna happen is that , in parallel starting about now we 're gonna get fey to , where you 're working with me and robert , draft a note that we 're gonna send out to various cogsci c and other classes saying , "" here 's an opportunity to be a subject . contact fey . "" and then there 'll be a certain number of hours during the week which she will be available and we 'll bring in people . roughly how many , robert ? we d do we know ? we 're looking for a total of fifty people , not necessarily by any means all students but we 'll s we 'll start with that . in parallel with that , we 're gonna need to actually do the script . and , there 's a plan to have a meeting friday afternoon with jane , and liz and whoever , on actually getting the script worked out . but what i 'd like to do , if it 's o k , is to s to , as i say , start the recruiting in parallel and possibly start running subjects next week . the week after that 's spring break , and we 'll look for them some subjects next door or i then we won't do it .  that 's easy .  is that make sense to everybody ? that 's a good idea . the high school 's a great idea . and why don't you also copy jane on it ? th they 're necessary . this the permission form . there has to be one , and we 're just gonna use it as it is , and  there 's one tricky part about ,  they have the right  i the last paragraph "" if you agree to participate you have the opportunity to have anything excised which you would prefer not to have included in the data set . ""  now that , we had to be included for this other one which might have , meetings , about something . in this case , it doesn't really make sense . what i 'd like to do is also have our subjects sign a waiver saying "" i don't want to see the final transcript "" . and if they don't if they say "" no , i 'm not willing to sign that "" , then we 'll show them the final transcript . but , that , we might actually ,  s i jane may say that , "" you can't do this "" , "" on the same form , we need a separate form . "" but anyway . i 'd i 'd like to , e add an a little thi thing for them to initial , saying "" nah , do i don't want to see the final transcript . "" but other than that , that 's one 's been approved , this really is the same project , rec  and forth . think we just go with it .  which is not a lot . but  right . we can show us , right ?  you can sho you are you gonna show us the little templates ? that sounds no i  actually , it 's a little tricky , in that there 's some allowable german orders which aren't allowable english orders and forth . and it is order based . it isn't it ? it doe i it these u these optional elements , it 's actually a set , not a sequence ?  really a se  do i ? right .   capitalized as y i p  if it says "" this "" and "" see "" , it also will work in "" see "" and "" this "" ? in the other order ? with those two key words ? "" this is the one i want to see "" or whatever . it is set based . alright .  no , no . fine . flexible it is . alright .   that 'd be great . it would be a good exercise to just see whether one can get that to run .   y they also seem to affect state , some of them there were other actions that s seemed to step state variables somewhere , like the n s "" discourse status confirm "" . that 's going to be a call on the discourse and confirm that it 's that 's right . it 's actually that looks like it 's state modification .  it always just is it it go back , then , cuz it may be that all those th things , while they look like function calls , are just a way of adding exactly that to the xml .  i 'm not e i 'm not that right . right . right .  right .  good point . it 's the it 's under what sub type you 're doing it .  each is s that 's funny . you bury the s the state in the function alright .   "" i want two seats here . "" no , right , the discourse maintainer ,  i see . and it runs around looking for discourse status tags , and doing whatever it does with them . and other people ignore those tags . alright . ","what we think is gonna happen is that , in parallel starting about now we 're gonna get fey to , where you 're working with me and robert , draft a note that we 're gonna send out to various cogsci c and other classes saying , "" here 's an opportunity to be a subject . we 're looking for a total of fifty people , not necessarily by any means all students in parallel with that , we 're gonna need to actually do the script . but what i 'd like to do , if it 's o k , is to s to , as i say , start the recruiting in parallel and possibly start running subjects next week . this the permission form . and we 're just gonna use it as it is , what i 'd like to do is also have our subjects sign a waiver saying "" i don't want to see the final transcript "" . there were other actions that s seemed to step state variables somewhere , ",The data collection running in parallel with the project can start shortly with recruiting subjects. The parser's output modifies the XML used by the system to initiate actions and generate responses. 
Bed005.B,"i definitely think it 's worth the exercise of trying to actually add something that isn't there .  disc a kid understanding what 's going on . then the next thing we talked about is actually , figuring out how to add our own tags , and like that .  s these are your friends back at eml . this is not a complicated negotiation . there 's not seven committees , or anything , right ? great . this is just trying to it 's a design thing , not a political thing . once we 've we can just agree on what oughta be done . good .  let now , this is important . let , want a again , outside of m almost managerial point ,  you 're in the midst of this , better . but it seems to me it 's probably a good idea to li minimize the number of change requests we make of them . it seemed to me , what we ought to do is get our story together .  and think about it some , internally , before asking them to make changes .  does this make sense to you guys ? it you 're doing the interaction but it seemed to me that what we ought to do is come up with a something where you , and i don't know who 's mok working most closely on it . probably johno .  take what they have , send it to everybody saying "" this is what they have , this is what we think we should add "" ,  and then have a d a an iteration within our group saying ""  and get our best idea of what we should add . and then go back to them . is i or , i don't know does this make sense to you ? or  right . right . that 's right .   the problem isn't the short ra range optimization . it 's the one or two year thing . what are the thl class of things we think we might try to do in a year or two ? how would we try to characterize those and what do we want to request now that 's leave enough space to do all that right . and that re that requires some thought . and that sounds like a great thing to do as the priority item as soon as we can do it . you guys will send to the rest of us version of this , and the description   the not everyone reads german , if you 'd  tu tur change the description to , english and , then , then , with some sug s suggestions about where do we go from here ? this and this , was just the action end . at some point we 're going to have to worry about the language end . but for the moment just t for this class of things , we might want to try to encompass . and  this is everything that , we might want to do in the next couple years . we don't that 's an issue . we don't entirely . right . no . the i the idea is that it 's beyond source path goal , but we don't need to get beyond it @ @ tourists in heidelberg . it seems to me we can get all the complexity we want in actions and in language without going outside of tourists in heidelberg .  but i depending on what people are interested in , one could have , tours , one could have explanations of why something is , why was this done , or no there 's no end to the complexity you can build into the what a tourist in heidelberg might ask . at least unless somebody else wants t to suggest otherwise the general domain we don't have t to broaden . that is , tourists in heidelberg . and if there 's something somebody comes up with that can't be done that way , then , w we 'll look at that , but i 'd be s i 'd be surprised at if there 's any important issue that and , if you want to push us into reference problems , that would be great . this is his specialty is reference , and what are these things referring to ? not only anaphora , but , more generally the , this whole issue of , referring expressions , and , what is it that they 're actually dealing with in the world ? and , again , this is li in the databa this is also pretty formed because there is an ontology , and the database , and it isn't like , the evening star or like that . i it all the entities do have concrete reference . although th the to get at them from a language may not be trivial . there aren't really deep mysteries about what w what things the system knows about . all those things .  you have proper names , and descriptions . and a l and a lot and anaphora , and pronouns , and all those things . he knows .  or , the church across from city hall , or that would be fine .  or you can say "" how "" "" how do i get back ? ""  and , again , it 's just a question of which of these things , people want to dive into . what , 'm gonna try to do , and pwww ! let 's say that by the end of spring break , i 'll try to come up with some general story about , construction grammar , and what constructions we 'd use and how all this might fit together . there 's this whole framework problem that i 'm feeling really uncomfortable about . and i haven't had a chance to think about it ","i definitely think it 's worth the exercise of trying to actually add something that isn't there . these are your friends back at eml . it seemed to me , what we ought to do is get our story together . and think about it some , internally , before asking them to make changes . the problem isn't the short ra range optimization . what are the thl class of things we think we might try to do in a year or two ? and what do we want to request now that 's leave enough space to do all that this and this , was just the action end . at some point we 're going to have to worry about the language end . this is everything that , we might want to do in the next couple years . it 's beyond source path goal , it seems to me we can get all the complexity we want in actions and in language without going outside of tourists in heidelberg . at least unless somebody else wants t to suggest otherwise the general domain we don't have t to broaden . that is , tourists in heidelberg . and , again , this is li in the databa this is also pretty formed because there is an ontology , and the database , and all the entities do have concrete reference . although th the to get at them from a language may not be trivial . let 's say that by the end of spring break , i 'll try to come up with some general story about , construction grammar , and what constructions we 'd use and how all this might fit together . there 's this whole framework problem that i 'm feeling really uncomfortable about . ","As the project evolves, further enrichment of the ontology (actions, linguistic features) will be necessary. "
Bed005.B,"but i want to do that early , rather than late . and you and i will probably have to talk about this some .    i d  you will .  we could take all the standard metaphor examples and make question versions of them .  or , "" wh why is he pushing for promotion ? "" or , "" who 's pushing proof "" er , just pick any of them and just do the don't think , it 's difficult to convert them to question forms that really exist and people say all the time ,  and we don't know how to handle them , too . right ? it 's i d it we don't know how to handle the declarative forms , @ @ really , and , then , the interrogative forms ,   nancy , it looked like you were s right . yes . right . no , that 's one of things that 's interesting , is in this over arching story we worked it out for th as you say , this the storytelling scenario . and it 's really worth thinking through what it looks like . what is the simspec mean , et cetera . i don't know . that 's what we 'll do is s u e we can do anything we want with it . once we have fulfilled these requirements , and the one for next summer is just half done and then the other half is this , "" generation thing "" which we think isn't much different . once that 's done , then all the rest of it is , what we want to do for the research . and we can w we can do all sorts of things that don't fit into their framework th there 's no reason why we 're c we 're constrained to do that . if we can use all the , execution engines , then we can , really try things that would be too much pain to do ourselves . but there 's no obligation on any of this . if we want to turn it into u understan standing stories about heidelberg , we can do that . that would just be a t a  you might , right . anyway . s who 's going ?    what happened is , there 's this , robert was describing the there 's two packages there 's a , quote parser , there 's a particular piece of this big system , which , in german , takes these t sentence templates and produces xml structures . and one of our jobs was to make the english equivalent of that . that , these guys did in a day . the other thing is , at the other end , roughly at the same level , there 's something that takes , x m l structures , produces an output xml structure which is instructions for the generator .  and then there 's a language generator , and then after that a s a synthesizer that goes from an xml structure to , language generation , to actual specifications for a synthesizer . but again , there 's one module in which there 's one piece that we have to convert to english . is that  and that but as i say , this is all along was viewed as a m a minor thing , necessary , but not  and much more interesting is the fact that , as part of doing this , we are , inheriting this system that does all these other things . not precisely what we want , and that 's wh where it gets difficult . and i don't pretend to understand yet what we really ought to do .  good ! good . and what 's the other one ? that just we the d agenda is ?  i 've got a couple new wu papers as 've been in contact with wu , probably let 's put that off till i understand better , what he 's doing . it 's just a little embarrassing all this was in his thesis and i was on his thesis committee , and , i r really knew this at one time . but , i it 's not only is part of what i haven't figured out yet is how all this goes together . 'll dig up some more from dekai . and why don't we just do the , you could squealing sound ? it 's probably just as easy . i that 's why they invented "" pocket t 's "" . wri write it out for this is the heckerman paper you 're working with ? good . th the important point is w not what the g function is . the important point is that there is a general idea of shortcutting the full cpt . th c the full conditional probability table with some function .  which y w you choose appropriately for each case . depending on what your situation is , there are different functions which are most appropriate . and gave bhaskara a copy of this , ninety two "" paper . d and you got one , robert . i don't know who else has seen it . it 's short . it 's short . i u w yo you have you read it yet ? you should take a look . nancy , i 'm you read it at some point in life .  and you other guys can decide how interested anyway . the paper isn't th isn't real hard . and one of the questions just come at bhaskara is , "" how much of this does javabayes support ? "" right . right . the little handout that the little thing that i sent i sent a message saying , here is a way to take ","is in this over arching story we worked it out for th as you say , this the storytelling scenario . and it 's really worth thinking through what it looks like . what is the simspec mean , et cetera . once we have fulfilled these requirements , and we can w we can do all sorts of things that don't fit into their framework if we want to turn it into u understan standing stories about heidelberg , we can do that . the there 's two packages there 's a , quote parser , there 's a particular piece of this big system , which , in german , takes these t sentence templates and produces xml structures . and one of our jobs was to make the english equivalent of that . that , these guys did in a day . the other thing is , at the other end , roughly at the same level , there 's something that takes , x m l structures , produces an output xml structure which is instructions for the generator . and then there 's a language generator , and then after that a s a synthesizer that goes from an xml structure to , language generation , to actual specifications for a synthesizer . but again , there 's one module in which there 's one piece that we have to convert to english . this is the heckerman paper you 're working with ? the important point is that there is a general idea of shortcutting the full cpt . th c the full conditional probability table with some function . ","The parser's output modifies the XML used by the system to initiate actions and generate responses. Meanwhile, the german parser now works with english sentences. Noisy-OR's can help avoid this by simplifying the probability tables and applying a deterministic function to produce their complete version. "
Bed005.B,"one thing you could do , which is in a way , stupid , is take this deterministic function , and use it to build the cpt . if ba javabayes won't do it for you , that you can convert all that into what the cpt would be . and , what i sent out about a week ago , was an idea of how to do that , for , evidence combination . one of one function that you could use as your "" g function "" is an e evidence combining . you just take the if each of th if each of the ones has its own little table like that , then you could take the , strength of each of those , times its little table , and you 'd add up the total evidence for "" v "" , "" e "" , and "" a "" .  right . i i no , no but i 'm saying is there is a w if y if you decide what 's what is appropriate , is probablistic evidence combination , you can write a function that does it . it 's a pui it 's actually one of the examples he 's got in there . but , anyway , s skipping the question of exactly which functions now is it clear that you might like to be able to shortcut the whole conditional probability table . right . that 's one of the problems , is , w is , where would th where would it all come from ? there 's two separate things , robert . the f the bayes nets in general are quite good at saying , "" if you have no current information about this variable just take the prior for that . "" th that 's what they 're real good at . if you don't have any information about the discourse , you just use your priors of whatever the discourse  whatever w it 's probabilistically , whatever it would be . and it 's not a great estimate , but it 's the best one you have , and , forth . that , they 're good at . but the other problem is , how do you fill in all these numbers ? and that 's the one he was getting at . pretty quickly .  to some no , no . "" noisy or "" is a funny way of referring to this , because the noisy or is only one instance . that one actually isn't a noisy or . we 'll have to think of a way t whatever .   it tha that 's true . it is a is also more neural net like , although it isn't necessarily sum s sum of weights or anything like that . you could have , like the noisy or function , really is one that 's essentially says , take the max . same .  but anyway .  and , i thi that 's the standard way people get around the there are a couple other ones . there are ways of breaking this up into s to subnets and like that . but , the we definitely it 's a great idea tha to pursue that . right .   no . i is let me say something , guys , cuz there 's not there 's a pretty point about this we might as get in right now . which is the hierarchy that s comes with the ontology is just what you want for this . that if about it let 's say , a particular town hall that , it 's one that is a monument , then , that would be stored there . if you don't , you look up the hierarchy , you may or then you 'd have this little vector of , approach mode or eva mode . let 's we have the eva vector for various kinds of landmarks . if it for a specific landmark you put it there . if you don't , you just go up the hierarchy to the first place you find one .  or , link to or but in any case i view it logically as being in the ontology . it 's part of what about a an object , is its eva vector . and , if yo as i say , if about a specific object , you put it there . this is part of what dekai was doing . when we get to wu , the e we 'll see w what he says about that . and , then if you if it isn't there , it 's higher , and if you don't know anything except that it 's a b it 's a building , then up at the highest thing , you have the pr what amounts to a prior . if you don't know anything else about a building , you just take whatever your crude approximation is up at that level , which might be equal , or whatever it is . that 's a very pretty relationship between these local vectors and the ontology . and it seems to me the obvious thing to do , unless we find a reason to do something different . does this make sense to you ? bhask ?  that 's another thing we 're gonna need to do , is , to , either we 're gonna need some way to either get a p tag in the ontology , or add fields , or some way to associate or , w it may be that all we can do is , some of our own hash tables that it th the th there 's always a way to do that . it 's a just a question of i th  e right . and , i  right .  they how ar what are they gonna do with instances ? you y  ","if ba javabayes won't do it for you , the f the bayes nets in general are quite good at saying , "" if you have no current information about this variable just take the prior for that . "" if you don't have any information about the discourse , you just use your priors of whatever the discourse like the noisy or function , really is one that 's essentially says , take the max . and , i thi that 's the standard way people get around the there are ways of breaking this up into s to subnets and like that . we definitely it 's a great idea tha to pursue that . which is the hierarchy that s comes with the ontology is just what you want for this . you may or then you 'd have this little vector of , approach mode or eva mode . let 's we have the eva vector for various kinds of landmarks . if it for a specific landmark you put it there . if you don't , you just go up the hierarchy to the first place you find one . but in any case i view it logically as being in the ontology . it 's part of what about a an object , is its eva vector . that 's a very pretty relationship between these local vectors and the ontology . we 're gonna need some way to either get a p tag in the ontology , or add fields , ","Similarly, object representations will include an EVA vector. This can be incorporated in the database entry for a particular building or inherited from the ontology of the building type. "
Bed005.B,"but what i what is smartkom gonna do about that ? cuz , they have instances all the time . but smartkom 's gonna need an ontology . i understand , but is anybody doing anything about it ?  it 's a political problem . we won't worry about it .  anyway . we may have to this is with the whole thing , we may have to build another data stru conceptually , we should be done . when we see what people have done , it may turn out that the easiest thing to do is to build a separate thing that just pools i like , i it may be , that , the instance w that we have to build our own instance , things , that , with their types , and then it goes off to the ontology once you have its type . we build a little data structure and what we would do in that case , is , in our instance gadget have our e v and if we d there isn't one we 'd get the type and then have the e v as for the type . we 'd have our own little , eva tree . and then , for other , vectors that we need . we 'd have our own little things that whenever we needed one , we 'd just use the ontology to get the type , and then would hash or whatever we do to say , "" if it 's that type of thing , and we want its eva vector , pppt ! it 's that . "" we can handle that . and then but , the combination functions , and whether we can put those in java bayes , and all that is , is the bigger deal . that 's where we have to get technically clever . i me ye the it 's , e e cute . you 've been around enough to  just ? there 's this huge package which may or may not be consistent and  but , we could look at it .  it 's b it it 's an inter it it 's an interpreter and i it expects its data structures to be in a given form , and if you say , "" hey , we 're gonna make a different data structure to stick in there "" it may or may not . i don't know . that 's the question is "" to what extent does it allow us to put in these g functions ? "" and i don't know . that 's fine if it 's if it comes only at the end . but suppose you want it embedded ? that that 's a truly horrible way to do d it . one would hope you bet . but , at that point you may say , "" hey , java bayes isn't the only package in town . let 's see if there 's another package that 's , more civilized about this . "" now , srini is worth talking to on this , cuz he said that he actually did hack some combining functions into but he doesn't remember at least when i talked to him , he didn't remember whether it was an e an easy thing , a natural thing , or whether he had to do some violence to it to make it work .  but he did do it . i say that 's one way to do it , is to just convert it int into a c p t that you zip it 's blown up , and is a it 's , it 's huge , but it doesn't require any data fitting or complication . i understand . i 'm just saying tha that w that was wi that was my note . the little note i sent said that . it said , "" here 's the way you 'd take the logical f g function and turn it into a cpt . "" that the max the evidence combining function . we could do that . and that 's what we 'll do . but , don't know . i will , e before next week , @ @ p push some more on this that dekai wu did , and try to understand it . you 'll make a couple of more copies of the heckerman paper to give to people ?  and ,  you and i should talk about it . alright , great ! and , robert , for coming in under he 's been sick , robert . ","if it 's that type of thing , and we want its eva vector , pppt ! it 's that . "" and then but , the combination functions , and whether we can put those in java bayes , and all that is , is the bigger deal . that 's the question is "" to what extent does it allow us to put in these g functions ? "" you and i should talk about it . ",This can be incorporated in the database entry for a particular building or inherited from the ontology of the building type. 
Bed005.C,"fifty was our our first  also , fey will not be here during spring break .   also , f both fey and i will , do something of which i may , kindly ask you to do the same thing , which is we gonna check out our social infrastructures for possible subjects . meaning , kid children 's gymnastic classes , pre school parents and forth . they also sometimes have flexible schedules . if you happen to be in a non student social setting , and people who may be interested in being subjects we also considered using the berkeley high school and their teachers , and get them interested in and , that 's as far as our brainstorming was concerned .  but i will just make a first draft of the , note , the "" write up "" note , send it to you and fey and then and , are we have we concurred that , these forms are sufficient for us , and necessary ?  nuh . n . n . you happy with that ?   makes sense .     much for the data , except that with munich everything is fine now . they 're gonna transcribe . they 're also gonna translate the , german data from the tv and cinema for andreas .  they 're they all seem to be happy now , with that .  w c sh should we move on to the technical sides ? guess the good news of last week was the parser .  bhaskara and i started working on the parser . then bhaskara went to class and once he came back , it was finished .  it , didn't measure it , but it was about an hour and ten minutes . and , and now it 's we have a complete english parser that does everything the german parser does . the that 's not a lot . and if you , w we d the first we did is we tried to do change the "" laufen "" into "" run "" , or "" running "" , or "" runs "" . and we noticed that whatever we tried to do , it no effect . and we were puzzled . and , the reason was that the parser i c completely ignores the verb . this sentence is parses the p the same output , even if you leave out , all of this . it 's feature film and tv . that 's what you need . if you 'd add today and evening , it 'll add time or not . it i it does look at that . but all the rest is p simply frosting on the cake , and it 's optional for that parser . and we ar we can sh er show you the templates . i also have it running here , if i do this now , you can see that it parsed the wonderful english sentence , "" which films are on the cinema today evening ? "" but , do don't worry about it . it could be "" this evening , which films are on the cinema "" , or "" running in the cinema , which "" "" today evening "" , "" is anything happening in the cinema this evening ? "" ge elaborate , or , more or less , no . it is not we were i was afraid that ,  these sentences are just silly . d these were not the ones we actually did it .  what 's an idiomatic of phrasing this ? which films are showing ? playing ? i have no net here . wonderful parse , same thing .  except that we d w we don't have this , time information here now , which is ,  this are the reserve . anyways . these are the the ten different sentence types that the the parser was able to do . and it still is , now in english . and ,  and , you have already to make it a little bit more elaborate , right ?  if you want to look at the templates , they 're conveniently located in a file , "" template "" .  and this is what i had to do . i had to change , @ @ "" spielfilm "" to "" film "" , "" film "" to "" movie "" , cinem "" kino "" to "" cinema "" to "" today "" heu "" heute "" to "" today "" , evening "" abend "" to "" evening "" and ,  and that 's the next step , but we 'll get to that in a second . and this means , "" this "" and "" see "" are not optional . "" want i like "" is all in there , but may also not be in there .  should we try it ?  "" action watch "" , whatever . nothing was specialfi specified . except that it has some references to audio visual media here . where it gets that from it 's correct , but i don't know where it gets it from . "" see "" .   and "" see this "" is exactly the same thing .  i 'll tell you why . because it gives a you a score . and the value of the score is , v i assume , the more of these optional things that are actually in there , the higher the r score it is . we shouldn't belittle it too much . it 's doing something , some things , and it 's very flexible . i 've just tried to be let 's hope that the generation will not be more difficult , even though the generator is a little bit more complex . but we 'll  that means we may need two hours and twenty minutes rather than an hour ten minutes , i hope . ","which is we gonna check out our social infrastructures for possible subjects . except that with munich everything is fine now . they 're gonna transcribe . they 're also gonna translate the , german data from the tv and cinema for andreas . and , and now it 's we have a complete english parser that does everything the german parser does . and , the reason was that the parser i c completely ignores the verb . these are the the ten different sentence types that the the parser was able to do . and it still is , now in english .  and the value of the score is , v i assume , the more of these optional things that are actually in there , the higher the r score it is . let 's hope that the generation will not be more difficult , ","Meanwhile, the german parser now works with english sentences. "
Bed005.C,"and the next thing i would like to be able to do , and it seems like this would not be too difficult either , is to say , "" let 's now pretend we actually wanted to not only change the mapping of , words to the m three l but we also wanted to change add a new sentence type and make up some new m three l s "" see th  and , that 's shouldn't be too tough . what it does , it i it does something fancy . it loads  it has these style sheets and also the , schemata . what it probably does , is it takes the ,  is this where it is ? this is already the xml this is where it takes its own , syntax , and converts it somehow .  where is the where it actually produces the xml out of the , parsed no , this is not it . i can't find it now . where the act how the action "" goodbye "" maps into something nope .  this is what happens . this is what you would need to change to get the , xml changed . when it encounts encounters "" day "" , it will , activate those h classes in the xml but , i saw those actions the "" goodbye "" somewhere .  let 's do that .    we 'll find that out . whatever n this does this is , looks l to me like a function call , right ? and , whenever it encounters "" goodbye "" , which we can make it do in a second , here i   w we e e  there is a feature called "" discourse status "" , and whenever say , "" write "" , it will put this in here . h  this we 'll see , when we say , let 's test something , "" goodbye "" , causes it to c to create an "" action goodbye end action "" . which is a means of telling the system to shut down . now , if we know that "" write "" produces a "" feature discourse status confirm discourse status "" . if i now say "" write , goodbye , "" it should do that . it sho it creates this , "" confirm goodbye "" .  it d it n that 's because   sometimes it m sometimes , i when it it  this is german .  e now , this , it cannot do anymore . nothing comes out of here . it doesn't speak german anymore , but it does speak english . and there is , here , a reference this tells us that whatever is has the id "" zero "" is referenced here by @ @ the restriction seed and this is exa "" i want "" what was the sentence ? "" need two seats here . "" nuh . "" and where is it playing ? "" there should also be a reference to something , our d this is re  here , we change and we here we add something to the discourse status , that the user wants to change something that was done before and , and that , whatever is being changed has something to do with the cinema .  get a complete understanding of the whole thing .  point number two . i got the , m three l for the routes today . got some more . this is the   interesting . it 's just going up , it 's not going back down . this is what i got today is the new three l for the maps , and with some examples this is the xml and this is what it will look like later on , even though it you can't see it on this resolution . and this is what it is the structure of map requests ,  also not very interesting , and here is the more interesting for us , is the routes , route elements , and , again , as we thought it 's really simple . this is the , parameters . we have @ @ simple "" from objects "" and "" to objects "" and forth , points of interest along the way and , i asked them whether or not we could , first of all , i was little bit it seemed to me that this m way of doing it is stack a step backwards from the way we 've done it before . t it seems to me that some notions were missing . these are  who are doing this . no . no , this is very straightforward .  exactly . and , and , however , the , that you understand , it is really simple . you have a route , and you cut it up in different pieces . and every element of that e r f of that every segment we call a "" route element "" . and from a to b we cut up in three different steps , and every step has a "" from object "" where you start , a "" to object "" where y where you end , and some points of interest along the way . what w i was missing here , and it was just me being too stupid , is , i didn't get the notion of the global goal of the whole route . really , s was not straightforward visibly for me . and some other and i suggested that they should n be k kind enough to do s two things for us , is one , also allocating , some tags for our action schema enter vista approach , and and also , since you had suggested that , we figure out if we ever , for a demo reason , wanted to shortcut directly to the g gis and the planner , ","and the next thing i would like to be able to do , and it seems like this would not be too difficult either , is to say , "" let 's now pretend we actually wanted to not only change the mapping of , words to the m three l but we also wanted to change add a new sentence type and make up some new m three l s "" we 'll find that out . get a complete understanding of the whole thing . i got the , m three l for the routes today . you have a route , and you cut it up in different pieces . and every element of that e r f of that every segment we call a "" route element "" . and from a to b we cut up in three different steps , and every step has a "" from object "" where you start , a "" to object "" where y where you end , and some points of interest along the way . and i suggested that they should n be k kind enough to do s two things for us , is one , also allocating , some tags for our action schema enter vista approach , ","The XML for Map requests also comprise a route, route elements and points of interest along the way. It is at this level that Enter/Vista/Approach tags will be added as action modes. "
Bed005.C,"of how we can do it . now , what 's the state of the art of getting to entrances , what 's the syntax for that , how get getting to vista points and calculating those on the spot . and the approach mode , anyhow , is the default . that 's all they do it these days . wherever you 'll find a route planner it n does nothing but get to the closest point where the street network is at minimal distance to the geometric center .    especially if we want what i my feeling was we reserved something that has a r an label . that 's th that was my th first step . i w no matter how we want to call it , this is our playground . and if we get something in there that is a structure elaborate and and complex enough to enable a whole simulation , one of these days , that would be u the perfect goal .          nuh . now , we hav the whole unfortunately , the whole database is , in german . we have just commissioned someone to translate some bits of it , ie the e the shortest k the more general descriptions of all the objects and , persons and events . it 's a relational database with persons , events , and , objects . and it 's quite , there . but did y there will be great because the reference problem really is not trivial , even if you have such a g defined world . he you are not , throwing carrying owls to athens . how do i get to the powder tower ? we think that our bit in this problem is interesting , but , just to get from powder tower to an object i id in a database is also not really trivial . or the o or tower , or this tower , or that building , or  u u that 's what strikes me , that we the de g small something , we should address one of these days , is to that most of the work people actually always do is look at some statements , and analyze those . whether it 's abstracts or newspapers and like this . but the whole i is it really relevant that we are dealing mostly with , questions ?  and this is it seems to me that we should at least spend a session or brainstorm a little bit about whether that l this is special case in that sense .  i don't know . did we ever find m metaphorical use in questions in that sense , really ? and how soon , i don't know . "" who got kicked out of france ? "" nuh . nuh .  help you create a mental model , blah blah .  or , we need and if we ' r take a ten year perspective , we need to do that , because w e w a assuming we have this , we ta in that case we actually do have these wonderful stories , and historical anecdotes , and knights jumping out of windows , and and tons of th the database is huge , and if we want to answer a question on that , we actually have to go one step before that , and understand that . in order to e do sensible information extraction . and this has been a deep map research issue that was is part of the unresolved , and to do 's , and something for the future , is how can we run our text , our content , through a machine that will enable us , later , to retrieve or answer e questions more sensibly ?  e enough of that , but i ,  the e johno and i will take up that responsibility , and , get a first draft of that . now , we have just , two more short things . y you guys started fighting , on the bayes net "" noisy or "" front ? the wu paper ,  y e eva   s this is a fanciful way of saying "" default "" ?    in some it seems very plausible in some sense , where we will be likely to not be observe some of the cuz we don't have the a access to the information .   i if it 's a discar discourse initial phrase , we will have nothing in the discourse history . if we ever want to wonder what was mention   wha still leaves one question . it you can always see easily that i 'm not grasping everything correctly , but what seemed attractive to me in im in the last discussion we had , was that we find out a means of getting these point four , point five , point one , of c four , not because , a is a landmark or not , but we label this whatever object type , and if it 's a garden , it 's point three , point four , point two . if it 's a castle , it 's point eight , point one . if it 's , a town hall , it 's point two , point three , point five . and forth . and we don't want to write this down necessarily every time for something but , let 's see . in the beginning , we 'll write up a flat file . we know we have twenty object types and we 'll write it down in a flat file . but it 's , it strikes me as a what for if we get the mechanism , that will be the wonderful part . and then , how to make it work is the second part , ","and the approach mode , anyhow , is the default . that 's all they do it these days . wherever you 'll find a route planner it n does nothing but get to the closest point where the street network is at minimal distance to the geometric center . now , we hav the whole unfortunately , the whole database is , in german . we have just commissioned someone to translate some bits of it , it 's a relational database with persons , events , and , objects . ",
Bed005.C,"in the sense that m the guy who was doing the ontology s ap apologized that i it will take him another through two to three days because they 're having really trouble getting the upper level straight , and right now . the reason is , given the craw bet the projects that all carry their own taxonomy and , on all history , they 're really trying to build one top level ontology ft that covers all the eml projects , and that 's , tough cookie , a little bit tougher than they figured . i could have told them s  but , nevertheless , it 's going to be there by n by , next monday and i will show you what 's what some examples from that for towers , and and , what i don't think is ever going to be in the ontology , is the likelihood of , people entering r town halls , and looking at town halls , and approaching town halls , especially since we are b dealing with a case based , not an instance based ontology . there will be nothing on that town hall , or on the berkeley town hall , or on the heidelberg town hall , it 'll just be information on town halls . but what that 's hhh . that 's al different question . th the first , they had to make a design question , "" do we take ontologies that have instances ? or just one that does not , that just has the types ? "" and , since the d decision was on types , on a d simply type based , we now have to hook it up to instances . this is one but the ontology is really not a smartkom thing , in and of itself . that 's more something that i kicked loose in eml . it 's a completely eml thing . yes , u a w a lot of people are aware of that .  no , but th the r th i still think that there is enough information in there . whether th it will know about the twenty object types there are in the world . let 's assume there are only twenty object types in this world . and it will know if any of those have institutional meanings . in a sense , "" i "" used as institutions for some s in some sense or the other . which makes them enterable . right ? in a sense .     and i 'll think s through this , getting eva vectors dynamically out of ontologies one more time because i s i 'm not quite whether we all think of the same thing or not , here .   und . is this , ","the reason is , given the craw bet the projects that all carry their own taxonomy and , on all history , they 're really trying to build one top level ontology ft that covers all the eml projects , but , nevertheless , it 's going to be there by n by , next monday what i don't think is ever going to be in the ontology , is the likelihood of , people entering r town halls , and looking at town halls , and approaching town halls , especially since we are b dealing with a case based , not an instance based ontology . and , since the d decision was on types , on a d simply type based , we now have to hook it up to instances . and i 'll think s through this , getting eva vectors dynamically out of ontologies one more time ",
Bed005.D," something like that . that 's the , point . yes . we 'll show you . no . are pl playing at the cinema ?  i changed that file , actually , where it 's on my account . you want to get it ? or is di was it easy to get it ?  changed those sentences to make it , more , idiomatic . and , you can have i many variations in those sentences , they will still parse fine . in a sense it 's pretty broad . one thing i was wondering , was , those functions there , are those things that modify the m three l   av medium .  "" see "" . it 's one thing i was wondering was , those percentage signs , right ? why do we even have them ? because if you didn't have them   that 's the main purpose . alright . right . that 's fine , where are those those functions "" action "" , "" goodbye "" , and on , right ? are they actually , are they going to be called ? are they present in the code for the parser ? what are you looking for ?    no , that 's not it .  m three l dot dtd ? that 's just a specification for the xml format . each of those functions act on the current xml structure , and change it in some way , by adding a l a field to it , right . that 's not going to actually modify the tree , but it 's going to change the event .  when there 's a feature .  right there . but there is some function call , because how does it know to put goodbye in content , but , confirm in features ?  it 's not just that it 's adding that field . it 's  they 're defined somewhere , presumably .  ooo !  should , talk a little bit about that , because that might be a good , architecture to have , in general for , problems with , multiple inputs to a node .   should i is there a white board here that use ?  or shall use this ?  hey !  recall that , we want to have this structure in our bayes nets . namely , that , you have these nodes that have several bands , right ?  does they the typical example is that , these are all a bunch of cues for something , and this is a certain effect that we 'd like to conclude .  like , let 's just look at the case when , this is actually the final action , right ? this is like , touch , or    e eva , right ? enter , v view , approach , right ? this is  enter , view , approach . right . we 'd like to take all these various cues , right ? this one might be , say , let me pick a random one and say , i don't know , it could be , like this isn't the way it really is , but let me say that , suppose someone mentioned , admission fees it takes too long . try let me just say "" landmark "" . if landmark , then there 's another thing that says if if it 's closed or not , at the moment . alright , you have nodes . right ? and the , problem that we were having was that , given n nodes , there 's "" two to the n "" given n nodes , and furthermore , the fact that there 's three things here , we need to specify "" three times "" , "" two to the n "" probabilities . right ? that 's assuming these are all binary , which f they may not be . they could be "" time of day "" , in which case we could , say , "" morning , afternoon , evening , night "" . this could be more it 's a lot , anyway . and , that 's a lot of probabilities to put here , which is pain . noisy ors are a way to , deal with this .  where should i put this ? the idea is that , let 's call these , c one , c two , c three , and c four , and e , for and effect , the idea is to have these intermediate nodes . right . actually , the idea , first of all , is that each of these things has a quote unquote distinguished state , which means that this is the state in which we don't really know anything about it .  right ? if we don't really know if landmark or not , or , i if that just doesn't seem relevant , then that would be th the disting the distinguish state . it 's a really , if there is something for the person talking about the admission fee , if they didn't talk about it , that would be the distinguish state .   that 's just what they the word they used in that paper . the idea is that , you have these intermediate nodes , right ? e one , e two , e three and e four ?  the idea is that , each of these ei is represents what this would be if all the other ones were in the distinguish state . right ? suppose that the person suppose the thing that they talked about is a landmark . but none of the other cues really apply . then , this would be w the this would just represent the probability distribution of this , assuming that this cue is turned on and the other ones just didn't apply ? ","and , you can have i many variations in those sentences , they will still parse fine . one thing i was wondering , was , those functions there , are those things that modify the m three l one thing i was wondering was , those percentage signs , right ? those functions "" action "" , "" goodbye "" , and on , right ? are they present in the code for the parser ? each of those functions act on the current xml structure , and change it in some way , by adding a l a field to it , they 're defined somewhere , presumably . recall that , we want to have this structure in our bayes nets . the typical example is that , these are all a bunch of cues for something , and this is a certain effect that we 'd like to conclude . enter , v view , approach , right ? given n nodes , and furthermore , the fact that there 's three things here , we need to specify "" three times "" , "" two to the n "" probabilities . and , that 's a lot of probabilities to put here , which is pain . noisy ors are a way to , deal with this . if we don't really know if landmark or not , or , i if that just doesn't seem relevant , then that would be th the disting the distinguish state .  the idea is that , each of these ei is represents what this would be if all the other ones were in the distinguish state . right ? ",The parser's output modifies the XML used by the system to initiate actions and generate responses. These elements will constitute only a small part of the inputs of the Bayes-net that determines the action mode. The actual number of the inputs can create a combinatorial explosion when setting the probabilities. Noisy-OR's can help avoid this by simplifying the probability tables and applying a deterministic function to produce their complete version. 
Bed005.D,"if it is a landmark , and no none of the other things really ap applicable , then this would represent the probability distribution . in this case we just t k we decide that , if the thing 's a landmark and we don't know anything else , then we 're gonna conclude that , they want to view it with probability , point four . they want to enter it with probability , with probability point five and they want to approach it probability point one , say right ? we come up with these l little tables for each of those  and the final thing is that , this is a deterministic function of these , we don't need to specify any probabilities . we just have to , say what function this is , right ? we can let this be , of e one comma e two . e three , e four . right ? and our example g would be , a majority vote ? right ?  there 's  it 's heckerman and breese .  you can you should take a look at it , it 's a good question . the what we want , is javabayes to support deterministic , functions . and , in a sense it sup we can make it supported by , manually , entering , probabilities that are one and zeros , right ?  i don't think you can do this , because g is a function from that to that . right ? there 's no numbers . there 's just quadruplets of n duplets of , e vs .  is right . w would not be ab able to observe what ?  a are you saying that we 'll not be able to observe certain nodes ? that 's fine . that is orthogonal thing .  specifically in this case you have to f have this many numbers , whereas in this case you just have to have three for this , three for this . right ? you have to have just three n ? this is much smaller than that .  right . i don't know . this isn't a noisy or anymore . it 's a noisy arg max or a noisy whatever . the "" or "" . right . you 're right .    it 'll be students where else would it be stored ? that 's the question .   is the idea to put it in the ontology ?    right . right .     we are but we 're not doing the ontology , we have to get to whoever is doing the u ultimately , we have to get them to it 's right , we can just assume  right .     that requires understanding the classes in javabayes , @ @ .    i don't see why the , combining f functions have to be directly hacked into they 're used to create tables we can just make our own little functions that create tables in xml .   i don't think the fact that it blown u blows up is a huge issue in the sense that  say it blows up , right ? there 's the ten , f ten , fifteen , things . it 's gonna be like , two to the that , which isn't bad .   p   ","if it is a landmark , and no none of the other things really ap applicable , then this would represent the probability distribution . we come up with these l little tables for each of those and the final thing is that , this is a deterministic function of these , the what we want , is javabayes to support deterministic , functions . i don't see why the , combining f functions have to be directly hacked into they 're used to create tables we can just make our own little functions that create tables in xml . ",Noisy-OR's can help avoid this by simplifying the probability tables and applying a deterministic function to produce their complete version. 
Bed005.E,"what did you end up having to do ? wha was there anything interesting about it or are we gonna see that ?     interesting parser property . i see .  today  and the t and the time , right ?  true . s the former end g "" i see .   key words , e it really is key word matching ,  tonight ? this evening ?   s  it 's a match .   right uniquely . it 's just that the goals are g very different to cases we had this problem last year when we first thought about this domain , actually , was that most of the things we talked about are our story understanding . we 're gonna have a short discourse and the person talking is trying to , i don't know , give you a statement and tell you something . and here , it 's th yea and then here , y you are j the person is getting information and they or may not be following some larger plan , that we have to recognize or , infer . and th the their discourse patterns probably don't follo follow quite as many logical connec     m right . cuz for a while we were thinking , "" how can we change the , data to illicit tha illicit , actions that are more like what we are used to ? "" but we would rather , try to figure out what 's ,              it was a quick one , they have clips !  new terminology ? i haven't heard that before . i         you don't need da data enough to cover nearly as much   ","it really is key word matching , ",
Bed005.F,"right . we are all switched on . e  actually , you would say , "" which films are on tonight ? "" right . right . but  right . right . right . right . and you have both proper names and descriptions and y and you can ask for it . right .  right . right . or if you take something even more scary , "" how do i get to the third building after the tower ? the ple powder tower ? "" you need some mechanism for right . right . right . muh right . mwa  i was just going to ask ,  what is the basic thing that you are , obligated to do , by the summer before w c we can move right . right . right . right . right . right . got it . right . right . that 's great ! right . ugh .  w what was this ? it i ehhh , i ehhh .  right . like the army .   i would like a copy , y  ","what is the basic thing that you are , obligated to do , by the summer before w c we can move ",
Bed006.A," u that 's pretty good ,   you could do it about you . the idea is to try to get the actual phrasing that they might use and try to interfere as little as possible with their choice of words .  u the one experiment th that i 've read somewhere , it was they u used pictures . to actually specify the tasks . but right . right . right . right . i 'm not saying it 's necessary but you might be able to combine text and some picture and also think it will be a good idea to show them the text and chew the task and then take the test away the the text away that they are not guided by what you wrote , but can come up with their own right .  right . you have to be careful with that thing because mean many actions presuppose some almost infinitely many other actions . if you go to a bakery you have a general intention of not being hungry . you have a specific intentions to cross the traffic light to get there . you have a further specific intentions to left to lift your right foot and mean y you really have to focus on and decide the level of abstraction that you aim at it zero in on that , and more or less ignore the rest , unless there is some implications that you want to constant draw from sub tasks that are relevant mean but very difficult .  right . right . right .  i have a question about the slot of the spg action . the enter view approach the eva those are fixed slots in this particular action . every action of this kind will have a choice . or will it just  is it change right , right . mean for each particular action that you may want to characterize you would have some number of slots that define in some way what this action is all about . it can be either a , b or c . is it a fixed number or do you leave it open it could be between one and fifteen  it 's it 's flexible . ye i u i understand  but no , no . there a actually by my question is simpler than that , is you have an spg action and it has three different aspects  because you can either enter a building or view it or approach it and touch it now you define another action , it 's called g one action a different action . and this action two would have various variable possibilities of interpreting what you would like to do . and i in a way similar to either enter view approach you may want to send a letter , read a letter , or dictate a letter , let 's say . h right . s it 's automatic derived fr from the structure that is built elsewhere . right . right .    right , right . promote them ,  friday that 's fine .  it 's at friday at three ? there that 's   an and i would like to second keith 's request . an example wo would be t to have detailed example .  ","the idea is to try to get the actual phrasing that they might use and try to interfere as little as possible with their choice of words . u the one experiment th that i 've read somewhere , it was they u used pictures . you have to be careful with that thing because mean many actions presuppose some almost infinitely many other actions . ",
Bed006.B,"what day is today ? nineteenth ? right , right . i made that joke already , nancy , sadly . the "" i don't know myself "" joke . before you came in . about me .  wizardette . right . what are the days ? april twenty sixth to the may fourth ? i 'll probably be here . 'll be here working on something . guaranteed , it 's just will i be here , in  i 'll be here too actually but but it 's not like we need to be with them twenty four hours a day s for the seven days that they 're here .   e this is the the schema of the xml here , not an example like that . actions that can be categorized with or that are related to source path goal . and then those actions can be in multiple categories at the same time if necessary . one question , robert . when you point at the screen is it your shadow that i 'm supposed to look at ?  whereas i keep looking where your hand is , and it doesn't  what this is that there 's an interface between what we are doing and the action planner and right now the way the interface is "" action go "" and then they have the what the person claimed was the source and the person claimed as the goal passed on . and the problem is , is that the current system does not distinguish between goes of type "" going into "" , goes of type "" want to go to a place where take a picture of "" , et cetera . right . currently .   robert likes to be abstract and that 's what thought he was doing . which we 're abbreviating as "" rad "" . the source path goal schema in this case , i 've if i understand how we described we set this up ,  cuz we 've been arguing about it all week , but we 'll hold the in this case it will hold the the features i 'm not it 's hard for me to exactly s that will store the object that is w the source will store the object that we 're going from , the goal will store the f we 'll fill those in fill those roles in , right ? the s action schemas have extra see we those are schemas exist because in case we need extra information instead of just making it an attribute and which is just one thing we decided to make it 's own entity that we could explode it out later on in case there is some structure that we need to exploit . that 's a block ,   the  right . right , the roles will be filled in with the schema and then what actual a action is chosen is will be in the action schema section . the wa wasn't there supposed to be a link in the i don't know if this answers your question , i was just staring at this while you were talking ,  link between the action schema , a field in the s in the schema for the image schemas that would link us to which action schema we were supposed to use we could  st references from the roles in the schema the bottom schemas to the action schemas is wha 'm assuming . right .  it 's not actually a very actually , it doesn't actually the utterance was "" is there a bakery around here ? "" , not "" i want to go to a bakery . "" it   the 'd the these actions i don't know if i 'm gonna answer your question or not with this , but the categories inside of action schemas , spg action is a category . real although what we 're specifying here is this is a category where the actions "" enter , view and approach "" would fall into because they have a related source path goal schema in our tourist domain . cuz viewing in a tourist domain is going up to it and or actually going from one place to another to take a picture , in this in a derived i don't know if i u right . right . inside of enter there will be roles that can be filled if i want to go from outside to inside then you 'd have the roles that need to filled , where you 'd have a source path goal set of roles . you 'd the source would be outside and path is to the door or whatever , right ? if you wanted to have a new type of action you 'd create a new type of category . then this category would we would put it or not necessarily we would put a new action in the m in the categories that in which it has the  every action has a set of related schemas like source path goal or force , whatever , right ? we would put "" write a letter "" in the categories that in which it had it w had schemas u exactly . schemas that of that type . and then later , there the we have a communication event action where we 'd define it down there as right . this is one of things we were arguing about . no . the reason one reason we 're doing it this way is in case there 's extra structure that 's in the enter action that 's not captured by the schemas , right ? right , but only one of i 'd i 'd i 'm not if i understand your question . only one of those things are gonna be lit up when we pass this on . only enter will be if we if our module decided that enter is the case , view and approach will not be there . ","and then those actions can be in multiple categories at the same time if necessary . what this is that there 's an interface between what we are doing and the action planner and right now the way the interface is "" action go "" and then they have the what the person claimed was the source and the person claimed as the goal passed on . and the problem is , is that the current system does not distinguish between goes of type "" going into "" , goes of type "" want to go to a place where take a picture of "" , et cetera . instead of just making it an attribute and which is just one thing we decided to make it 's own entity that we could explode it out later on in case there is some structure that we need to exploit . right , the roles will be filled in with the schema and then what actual a action is chosen is will be in the action schema section . inside of enter there will be roles that can be filled if i want to go from outside to inside then you 'd have the roles that need to filled , where you 'd have a source path goal set of roles . if you wanted to have a new type of action you 'd create a new type of category . ","The model also allows for multiple action schemas to be triggered in parallel. These modes will form categories of complete XML schemas with information filled in from the language understanding in a more elaborate way than the current Object-""Go Action""-Object model. Categories and action schemas can have -in theory- any number of blocks depending on the expansion of the domain. "
Bed006.B,"in that case , we can't w if if that 's the case we our i don't think our system can handle that currently . the r the in terms of why is it 's laid out like this versus some other that 's contentious point between the two of us but this is one wa this is a way to link the way these roles are filled out to the action . because if we know that enter is a t is an spg action , right ? we know to look for an spg schema and put the appropriate fill in the appropriate roles later on . right . this is a simple way to link roles to actions . that 's the that was the intent of it , do i 'm not i b rolls  pastries is what i 'm talking about . you have class until two , right ? if we don't want him to run over here two thirty ish or three is and between now and then we will . don't worry . the other good thing about it is jerry can be on here on friday and he can weigh in as it 's an a attempt to refine it rad 's a great term . why ? it just happened to be the acronym . who doesn't like to be a  ",,
Bed006.C," wh   some in some introductions are in order .   for those who don't know everyone knows me , this is great . apart from that , the old gang , johno and bhaskara have been with us from day one and they 're engaged in various activities , some of which you will hear about today . ami is our counselor and spiritual guidance and also interested in problems concerning reference of the more complex type , and he sits in as a interested participant and helper . is that a good characterization ? i don't know .  keith is not technically one of us yet , ha . but it 's too late for him now .   officially he will be joining us in the summer . and hopefully it is by means of keith that we will be able to get a b a better formal and a better semantic idea of what a construction is and how we can make it work for us . additionally his interest surpasses english because it also entails german , an extra capability of speaking and writing and understanding and reading that language . and is there anyone who doesn't know nancy ? do nancy ?   and fey is with us as of six days ago officially ? officially , but in reality already much longer and next to some more or less bureaucratic with the data collection she 's also the wizard in the data collection  we 're sticking with the term "" wizard "" ,  and sorceress , wizard by popular vote  why don't we get started on that subject anyways . we 're about to collect data and the the following things have happened since we last met . when will we three meet again ? and what happened is that "" a "" , there was some confusion between you and jerry with the that leading to your talking to catherine snow , and he was he completely that some something confusing happened . his idea was to get the l the lists of mayors of the department , the students . it 's exactly how you interpreted it ,  ma majors , majors . "" mayors "" . majors . majors and just sending the little write up that we did on to those email lists     that is  and  wonderful . and we have a little description of asking peop subjects to contact fey for recruiting them for our thing and there was some confusion as to the consent form , which is that what you just signed and since we have one already he said we definitely "" yes "" , however there is always more people in a facul in a department than are just taking his class or anybody else 's class at the moment and one should reach out and try and get them all .      do it .  if you if now , i how however i suggest that if you look at your email carefully you may think you may find that you already have it .   w we 'll see . anyhow , the not only also we will talk about linguistics and computer science . and then , secondly , we had , you may remember , the problem with the re phrasing , that subject always re phrase the task that we gave them , and we had a meeting on friday talking about how to avoid that , and it proved finally fruitful in the sense that we came up with a new scenario for how to get the subject m to really have intentions and to act upon those , and there the idea is now that next actually we need to hire one more person to actually do that job because it 's getting more complicated . if anyone interested in what i 'm about to describe , tell that person to write a mail to me or jerry soon , fast . the idea now is to come up with a high level of abstract tasks "" go shopping "" take in batch of art ""  "" visit do some sightseeing "" blah blah , analogous to what fey has started in compiling here and already she has already gone to the trouble of anchoring it with specific entities and real world places you will find in heidelberg . and out of these f s these high level categories the subject can pick a couple , such as if there is a cop category in emptying your roll of film , the person can then decide "" i wanna do that at this place "" , make up their own itinerary a and tasks and the person is not allowed to take this h high level category list with them , but the person is able to take notes on a map that we will give him and the map will be a tourist 's schematic representation with symbols for the objects . and the person can make a mental note that "" wanted to go shopping here "" and "" i wanted to take a picture of that "" and "" eat here "" and then goes in and solves the task with the system , ie fey , and and we 're gonna try out that any questions ?  hopefully . it 's a schematic tourist map . it 'll be it 'll still require the that information and an n not really the street network . nuh .  and the map is more a means for them to have the buildings and their names and some ma major streets and their names and we want to ask them , if you have get it isolated street the , whatever , "" river street "" , and they know that they have decided that , yes , that 's where they want to do this action that they have it with them and they can actually read them or have the label for the object ","we 're about to collect data and we have a little description of asking peop subjects to contact fey for recruiting them for our thing however there is always more people in a facul in a department than are just taking his class or anybody else 's class at the moment and then , secondly , we had , you may remember , the problem with the re phrasing , that subject always re phrase the task that we gave them , there the idea is now that next actually we need to hire one more person to actually do that job the idea now is to come up with a high level of abstract tasks "" go shopping "" out of these f s these high level categories the subject can pick a couple , make up their own itinerary a and tasks the person is able to take notes on a map that we will give him and the map will be a tourist 's schematic representation with symbols for the objects . hopefully . ","Another trial run will take place, while a call to recruit subjects is being emailed to students. "
Bed006.C,"because it 's too hard to memorize all these st strange german names . and then we 're going to have another we 're gonna have w another trial run ie the first with that new setup tomorrow at two and we have a real interesting subject which is ron for who those who know him , he 's the founder of ici . he 'll he 's around seven seventy years old , and he also approached me and he offered to help our project and he was more thinking about some high level thinking tasks and i said "" we need help you can come in as a subject "" and he said "" . that 's what 's gonna happen , tomorrow , data . new set up .  which i 'll hopefully scrape together t but , to fey , we already have blueprint and work with that . questions ? comments on that ? if not , we can move on . no ? no more questions ?  are you familiar with the very rough setup of the data ? experiment ? talk to a machine and it breaks down and then the human comes on . the question is just how do we get the tasks in their head that they have an intention of doing something and have a need to ask the system for something without giving them clear wording or phrasing of the task . because what will happen then is that people repeat , or as much as they can , of that phrasing .  we will get a protocol of the prior interaction , right ? that 's where the instructor , the person we are going to hire , and the subjects sit down together with these high level things and th the q first question for the subject is , "" these are things , we thought a tourist can do . is there anything that interests you ? "" and the person can say "" sh this is something i would do . i would go shopping "" .  and then we can this s instructor can say "" then you may want to find out how to get over here because this is where the shopping district is "" . no . just what would you like to buy and then there you wanna buy a whatever cuckoos clocks and the there is a store there . the task then for that person is t finding out how to get there , right ? that 's what 's left . and we know that the intention is to enter because we know that the person wants to buy a cuckoos clock . hopefully . hopefully . yes . in a sense that 's exactly the idea , which is never possible in a s in a lab situation , nuh ?   we had exactly that on our list of possible way things we even made a silly thing how that could work , how you control you are here you want to know how to get someplace , and this is the place and it 's a museum and you want to do some and there 's a person looking at pictures . this is exactly getting someplace with the intention of entering and looking at pictures . however , not only was the common census were among all participants of friday 's meeting was it 's gonna be very laborious to make these drawings for each different things , all the different actions , if possible , and also people will get caught up in the pictures . all of a sudden we 'll get descriptions of pictures in there . and people talking about pictures and pictorial representations and i would s i would still be willing to try it .   we will  they will have no more linguistic matter in front of them when they enter this room .  then i suggest we move on to the to we have the edu project , let me make one more general remark , has two side actions , its action items that we 're do dealing with , one is modifying the smartkom parser and the other one is modifying the smartkom natural language generation module . and this is not too complicated but i 'm just mentioning it put it in the framework because this is something we will talk about now . i have some news from the generation , do you have news from the parser ? by that look i   wonderful . did you run into problems or did you run into not h having time ? that 's good . that 's better than running into problems . and do have some good news for the natural language generation however . and the good news is it 's done . meaning that tilman becker , who does the german one , actually took out some time and already did it in english for us . and the version he 's sending us is already producing the english that 's needed to get by in version one point one .  i it even though the generator is a little bit more complex and it would have been , not changing one hundred words but four hundred words , but it would have been but this is good news , and the the time and especially bhaskara and and do i have it here ? no . the time is now fixed . it 's the last week of april until the fourth of may it 's twenty sixth through fourth . that they 'll be here . it 's extremely important that the two of you are also present in this town during that time . something like that . it 's there is a d isn't finals coming up then after that ?  anyway , this is no it 's just they 're coming for us that we can bug them and ask them more questions and sit down together ","and then we 're going to have another we 're gonna have w another trial run talk to a machine and it breaks down and then the human comes on . the question is just how do we get the tasks in their head that they have an intention of doing something and have a need to ask the system for something without giving them clear wording or phrasing of the task . however , not only was the common census were among all participants of friday 's meeting was it 's gonna be very laborious to make these drawings for each different things , all of a sudden we 'll get descriptions of pictures in there . let me make one more general remark , has two side actions , its action items that we 're do dealing with , one is modifying the smartkom parser and the other one is modifying the smartkom natural language generation module . and do have some good news for the natural language generation however . meaning that tilman becker , who does the german one , actually took out some time and already did it in english for us . it 's the last week of april until the fourth of may no it 's just they 're coming for us that we can bug them and ask them more questions ","Another trial run will take place, while a call to recruit subjects is being emailed to students. "
Bed006.C,"and write sensible code and they can give some talks and but just make a not unless you really want to . not unless you really want to . and they 're both guys you may want to . that much from the parser and generator side , unless there are more questions on that . no . it just a mail that , he 's sending me the soon and i was completely flabbergasted here and i and that 's also it 's going to produce the concept to speech blah blah information for necessary for one point one in english based on the english , in english .  i was like "" we 're done ! ""  the basic requirement is fulfilled almost . when andreas stolcke and his gang , when they have changed the language model of the recognizer and the dictionary , then we can actually a put it all together and you can speak into it and ask for tv and movie information and then when if something actually happens and some answers come out , then we 're done .  then  actually th  the you don't know how the german dialogue the german the demo dialogue actually works . it works the first thing is what 's , showing on tv , and then the person is presented with what 's running on tv in germany on that day , on that evening and you take one look at it and then you say "" that 's really nothing there 's nothing for me there "" "" what 's running in the cinemas ? "" there 's something better happening there . and then you get you 're shown what movies play which films , and it 's gonna be all the heidelberg movies and what films they are actually showing . and most of them are going to be hollywood movies . "" american beauty "" is "" american beauty "" , right ?  and n but it in that sense it doesn't make in that case it doesn't really make sense to read them out loud . if you 're displaying them . but it 'll tell you that this is what 's showing in heidelberg and there you go . and the presentation agent will go "" hhh ! "" nuh ? like that the avatar . and and then you pick a movie and it show shows you the times and you pick a time and you pick seats and all of this .  pretty straightforward . but it 's this time we are at an advantage because it was a problem for the german system to incorporate all these english movie titles . nuh ? but in english , that 's not really a problem , unless we get some topical german movies that have just come out and that are in their database . the person may select "" huehner rennen "" or whatever .  then on to the modeling . right ? then modeling , there it is . this is very rough but this is what johno and i managed to come up with . the idea here is that this is not an xml this is towards an a schema , nuh ? definition . the idea is , imagine we have a library of schema such as the source path goal and then we have forced motion , we have cost action , we have a whole library of schemas . and they 're gonna be , fleshed out in their real ugly detail , source path goal , and there 's gonna be s a lot of on the goal and blah blah , that a goal can be and forth . what we think is and all the names could should be taken "" cum grano salis "" .  this is a the fact that we 're calling this "" action schema "" right now should not entail that we are going to continue calling this "" action schema "" . but what that means is we have here first of all on the in the first iteration a stupid list of source path goal actions wi to that schema and we will have forced motion and cost action actions . push may be in both push in this or this  exactly .  also , these things may or may not get their own structure in the future . this is something that , may also be a res as a result of your work in the future , we may find out that , there 're really s these subtle differences between  even within the domain of entering in the light of a source path goal schema , that we need to put in fill in additional structure up there . but it gives us a handle . with this we can slaughter the cow any anyway we want .  it is it was it gave us some headache , how do we avoid writing down that we have the enter source path goal that this but this gets the job done in that respect and it is even conceptually somewhat adequate in a sense that we 're talking about two different things . we 're talking more on the intention level , up there , and more on the this is the your basic bone schema , down there . that wouldn't have helped you this is what it looks like now , some simple "" go "" action from it from an object named "" peter 's kirche "" of the type "" church "" to an object named "" powder tower "" of the type "" tower "" . right ? currently .  no . we this is the output , of the natural language understanding , right ? the input into the action planning , as it is now . and what we are going to do , we going to and you can see here , for johno focus the shadow , we 're gon  ","and they can give some talks and the basic requirement is fulfilled almost . when andreas stolcke and his gang , when they have changed the language model of the recognizer and the dictionary , then we can actually a put it all together you can speak into it and ask for tv and movie information if something actually happens and some answers come out , then we 're done . then on to the modeling . the idea is , imagine we have a library of schema such as the source path goal and then we have forced motion , and there 's gonna be s a lot of on the goal and blah blah , that a goal can be and forth . we 're talking more on the intention level , up there , and more on the this is the your basic bone schema , down there . ","Meanwhile, the translation of the TV and cinema information system to english is almost complete. On the other hand, there was a presentation of the model that offers more elaborate action planning for SmartKom, of which Enter/View/Approach (EVA) modes are a part. These categories will, in turn, be linked with action schemas, one of which is Source-Path-Goal (SPG). Categories and action schemas can have -in theory- any number of blocks depending on the expansion of the domain. "
Bed006.C,"here you have the action and the domain object and w and on have i have no between here and here , as you can see this is on one level and we are going to add another struct "" , if you want , ie a rich action description on that level . in the future exactly . in the future though , the content of a hypothesis will not only be an object and an action and a domain object but an action , a domain object , and a rich action description , which is  no , no . source is just not spelled out here . source meaning source will be will have a name , a type , dimensionality , canonical orientation s source it will be , we 'll f we know a lot about sources we 'll put all of that in source . but it 's independent whether we are using the spg schema in an enter , view , or approach mode , right ? this is just properties of the spg schema . we can talk about paths being the fastest , the quickest , the nicest and forth , or and the trajector should be coming in there as and then g the same about goals .  yes , yes . since you bring it up now , we will worry about it . tell us more about it . what do you what do you          that 's one thing is that we can link up , think also that we can have one or m as many as we want links from the schema up to the s action description of it . but the notion i got from nancy 's idea was that we may f find concepts floating around i in the a action description of the action f "" enter "" frame up there that are , e when you talk about the real world , actually identical to the goal of the s source path goal schema , and do we have means of telling it within that a and the answer is the way we have those means that are even part of the m three l a api , meaning we can reference . meaning and this referencing thing however is of temporary nature because sooner or later the w three c will be finished with their x path , specification and then it 's going to be even much nicer . then we have real means of pointing at an individual instantiation of one of our elements here and link it to another one , and this not only within a document but also via documents , and all in a v very easy e homogenous framework . that 's but it 's soon . it 's g it 's the spec is there and it 's gonna part of the m three l ap api filed by the end of this year that this means we can start using it now . but this is a technical detail .   personally , i 'm looking even more forward to the day when we 're going to have x forms , which l is a form of notation where it allows you to say that if the spg action up there is enter , then the goal type can never be a statue .  w exactly . this , does not make sense in light of the statue of liberty , however it is these things are imaginable .    we have absolute no . we have no means of enforcing that , it would be considered valid if we have an spg action "" enter "" and no spg schema , but a forced action schema . could happen .  it it means we had nothing to say about the source path goal . what 's also and for a i for me in my mind it 's crucially necessary , is that we can have multiple schemas and multiple action schemas in parallel . and we started thinking about going through our bakery questions , when i say "" is there a bakery here ? "" do ultimately want our module to be able to first of all f tell the rest of the system "" hey this person actually wants to go there "" and "" b "" , that person actually wants to buy something to eat there . nuh ? and if these are two different schemas , ie the source path goal schema of getting there and then the buying snacks schema , nuh ? yes . ye they would both schemas would appear , what is the is there a "" buying s snacks "" schema ? what is the have the buying snack schema ?  a "" commercial event ""  we would instantiate the spg schema with a source path goal blah blah and the buying event at which however that looks like , the place f thing to buy .  now it 's technically possible that you can fit schema within schema , and schema within schemata  for me it seems that r yes . if i 'm recipient of such a message and i get a source path goal where the goal is a bakery and then i get a commercial action which takes place in a bakery , right ? and they are via identifiers , identified to be the same thing here . no , just the     we 're gonna hit a lot of interesting problems and as i prefaced it this is the result of one week of arguing about it and and it occur it occurs to me that ne should have we should have added an ano an xml example , or some xml examples and this is on a on my list of things until next week . it 's also a question of the recursiveness and a hier hierarchy in there . do we want the schemas just blump ? ","in the future though , the content of a hypothesis will not only be an object and an action and a domain object but an action , a domain object , and a rich action description , a and the answer is meaning we can reference . and link it to another one , and this not only within a document but also via documents , personally , i 'm looking even more forward to the day when we 're going to have x forms , which l is a form of notation where it allows you to say that if the spg action up there is enter , then the goal type can never be a statue .  it would be considered valid if we have an spg action "" enter "" and no spg schema , but a forced action schema . it 's crucially necessary , is that we can have multiple schemas and multiple action schemas in parallel . we 're gonna hit a lot of interesting problems should have we should have added an ano an xml example , and this is on a on my list of things until next week . it 's also a question of the recursiveness and a hier hierarchy in there . ","On the other hand, there was a presentation of the model that offers more elaborate action planning for SmartKom, of which Enter/View/Approach (EVA) modes are a part. The notation provides for linking and referencing between different schemas. The model also allows for multiple action schemas to be triggered in parallel. "
Bed006.C,"it 's if we can actually get it that we can , out of one utterance , activate more than one schema , then we 're already pretty good , right ?      there should never be a hard coded shortcut from the bakery question to the double schema thing , how and , when i have traveled with my friends we make these exactly these kinds of appointments . we o  the it depends on if you actually write down the schema then you have to say it 's either one of them or it can be none , or it can be any of them . however the it seems to be sensible to me to r to view them as mutually exclusive  even not .  and how where is the end ? that 's forced action or forced motion .       th this is this r this is more this is probably the way that th that 's the way that seemed more intuitive to johno also for a while for no , no . we have not seen the light . no get rid of the spg slash something or the sub actions category , because what does that tell us ? and i agree that this is something we need to discuss ,   and , fr it 's it came into my mind that sometimes even two could be on , and would be interesting . nevertheless l let 's not no , not but u s t the the in some sense we ex get the task done extremely because this is exactly the discussion we need . period . no more qualifiers than that .  and and i th i hope  let 's make a sharper claim . we will not end this discussion anytime soon . and it 's gonna get more and more complex the l complexer and larger our domains get . and we will have all of our points in writing pretty soon . this is about being recorded also . the the people  yes because nobod no the modules don't this is a schema that defines xml messages that are passed from one module to another , mainly meaning from the natural language understanding , or from the deep language understanding to the action planner . now the reason for not using this approach is because you always will have to go back , each module will try have to go back to look up which entity can have which entity can have which parents , and then you always need the whole body of y your model to figure out what belongs to what . or you always send it along with it , nuh ? you always send up "" here i am this person , and have these parents "" in every message . which e it may or may not be a just a pain it 's it 's i 'm completely willing to throw all of this away and completely redo it , and it after some iterations we may just do that .   we i will promise for the next time to have fleshed out n xml examples for a run through and see how this then translates , and how this can come about , nuh ? including the miracle occurs here "" part . and is there more to be said ?   in principle what that this approach does , and e whether or not we take the enter view and we all throw up the ladder wha how do how does professor peter call that ? the hhh , silence su sublimination ? throwing somebody up the stairs ? have you never read the peter 's principle anyone here ? maximum incompetence and then you can throw them up the stairs  we can promote enter view all up a bit and get rid of the blah x blah asterisk sub action item altogether . no problem with that and we w we will play around with all of them but the principal distinction between having the pure schema and their instantiations on the one hand , and adding some whatever , more intention oriented specification on parallel to that this approach seems to be workable to me . i don't know . if you all share that opinion then that made my day much happier .  i 'm never happy when he uses the word "" roles "" , i 'm  that 's all i have for today . no , there 's one more issue . bhaskara brought that one up . meeting time rescheduling .  it looks like you have not been partaking , the monday at three o ' clock time has turned out to be not good anymore . people have been thinking about an alternative time and the one we came up with is friday two thirty ? three ? what was it ? two th two thirty ish or three or friday at three around that time . how are your and i know that you have until three you 're busy ?   and you can always make it shortly after three probably . often , no , but whenever . you are more than welcome if you think that this discussion gets you anywhere in your life then you 're free to c  but you 're a linguist . you should  and how diligent do we feel ?  do feel that we have done our chores for this week or bhaskara will do the big show on friday . we will r yes . yes . i 've i 've 'm on record for promising that now .  this is it and  and if you can get that binding point also with a example that would be helpful for johno and me . give us the binding is technically no problem but it 's it for me it seems to be conceptually important that we find out if we can s if there are things in there that are general nature , we should distill them out ","and i agree that this is something we need to discuss , we will not end this discussion anytime soon . and it 's gonna get more and more complex the l complexer and larger our domains get . this is a schema that defines xml messages that are passed from one module to another , mainly meaning from the natural language understanding , or from the deep language understanding to the action planner . now the reason for not using this approach is because you always will have to go back , each module will try have to go back to look up which entity can have which entity can have which parents , you always need the whole body of y your model to figure out what belongs to what . or you always send it along with it , we i will promise for the next time to have fleshed out n xml examples for a run through and see how this then translates , but the principal distinction between having the pure schema and their instantiations on the one hand , and adding some whatever , more intention oriented specification on parallel to that this approach seems to be workable to me . meeting time rescheduling . and if you can get that binding point also with a example that would be helpful for johno and me . but it 's it for me it seems to be conceptually important that we find out if we can s if there are things in there that are general nature , we should distill them out ","However, the structure of the model is open for discussion, since its use was to elicit discussion and highlight issues. "
Bed006.C,"and put them where the schemas are . if there are things that are intention specific , then we should put them up somewhere , a  that 's wonderful .       it 's and it 's an it 's  and there will be a relatively high level of redundancy in the sense that ultimately one th that if we want to get really cocky we will say "" if you really look at it , you just need our rad . "" you can throw the rest away , right ? because you 're not gonna get anymore information out of the action a as you find it there in the domain object . but then again in this case , the domain object may contain information that we don't really care about either .  h but w we 'll see that then , and how it evolves . if people really like our rad , what might happen is that they will get rid of that action thing completely , and leave it up for us to get the parser input     ye no but i but if you if you work in th in that xml community it is a great acronym because it e evokes whatever rdf rdf is the biggest thing right ? that 's the rich resource description framework "" and and also description , having the word d term "" description "" in there is wonderful , rich "" is also great , rwww . it 's rad ,   you want audio ? or do you want transcript ? just transcript is just not available because nobody has transcribed it yet . can e 'll transcribe it though . it 's no problem .    friday , whoever wants and comes , and can . this friday . the big parser show . now you can all turn off your ",and put them where the schemas are . ,
Bed006.D,"i am fey ,  hi . a couple times that 's right ,  and you were my gsi briefly , until i dropped the class . but . officially ,  it 's very exciting . yes . yes . wizard . m majors ? majors ? mayor something i don't know about these    but  it was really carol snow who was confused , not me and not jerry . that 's good . should still do that .  and using the thing that you wrote up .   see that 's what i suggested to him , that people like jerry and george and et cetera just  or even i could could do the actual that 's generally the way it 's done . a mailing list .  that 's send it . i 'll send it ,  probab based on the web site , at the right . it 's a tourist information web site ,  eee . buying his food that 's true . bakery . bakery .  and i don't need to be here particularly deeply .  but it 's fascinating . i 'm just glad that i don't have to work it out because . i 'm just glad that don't have to work it out myself , that i 'm not involved in the working out of it because . that 's why i 'm glad that i 'm not involved in working it out . no problem ,  you don't have to use the acronym . just think of it as "" wheel "" in german . all the kids 'll love it . ","it 's a tourist information web site , ",
Bed006.E,"hi .  not yet . right . i 've got the headset on after all . yes . i know nancy . man ! wizard . the list of majors in the department ? you 're just saying like what part of town the things are in or whatever ? i 'm not understand this but i 'm not understand everything that 's being talked about but i imagine i 'll c just catch on . this is where they 're supposed to           you will be here . they 're very dependent we 're done . toll . it 's not done right . perhaps if the answers have something to do with the questions i want to see "" die dukes von hazard ""   "" chicken run "" . what 's the next thing ?    spit right here . a laser pointer would be most appropriate here  rad !   very specific role names are "" viewed thing "" , "" entered thing ""    right . snack action . see . i 'm there 's a commercial event schema in there somewhere . mean i still am not entirely that i really fully grasp the syntax of this . like what right . or the intended interpretation of this .        every spg action either is an enter or a view or an approach , right ?  this is a cate this a category structure here , right ? action schema . what are some types of action schemas ? one of the types of action schemas is source path goal action . and what are some types of that ? and an enter , a view , an approach . those are all source path goal actions .  there could be a communication event action like that and you could write it . ri you 'd like you 're saying you could practically turn this structure inside out ?  or ? list all the parent categories .   this sounds like a paper i 've read around here recently in terms of  mean but there 's a good question here . like , do you when do you need damn this headset ! when you this  that 's all recorded .  why do you i don't know . like how do i come at this question ?  don't see why you would does th who uses this this data structure ? like , do you say "" alright i 'm going to do an spg action "" . and then somebody ne either the computer or the user says "" alright , i want to do a source path goal action what are my choices among that ? "" and "" can do an enter view approach "" . it 's not like that , right ? it 's more like you say "" i want to , want to do an enter . "" and then you 're more interested in knowing what the parent categories are of that . right ? that the the representation that you were just talking about seems more relevant to the kinds of things you would have to do ?    mayb 'm not understanding where this comes from and where this goes to . what are we doing with this ? in principle . sigh . right .   in my view .      again  i would just like to ask like , if it could happen for next time , just beca cuz i 'm new and i don't really just don't to make of this and what this is for , and like that , if someone could make an example of what would actually be in it , like first of all what modules are talking to each other using this , right ? and  right . nope . alright .    you meant pastries , then ? this is the bakery example . got it . alright . help !    i could do that . mean earlier on friday is better but three mean if it were a three or a three thirty time then i would take the three or whatever , but three is fine .    already again this week ,  between now and then . promise ?  you 've got one on hand ,  it 's rad , even ! it happened to c be what it stands for . rich de "" everybody likes action . plus it 's hip . the kids 'll like it .  ","what are some types of action schemas ? one of the types of action schemas is source path goal action . and what are some types of that ? and an enter , a view , an approach . ","These categories will, in turn, be linked with action schemas, one of which is Source-Path-Goal (SPG). "
Bed006.F,"it 's the twenty nineteenth . wizardess . they 'll be given this map , which means that they won't have to like ask the system for in for like high level information about where things are ? not yes , i would really p it would be better if i talked about it on friday . if that 's  but not any time part .  take it that was similar to the what we did for the parsing ?    finals was that . actually , that 's true . you had like an action schema and a source path goal schema , right ? how does this source path goal schema fit into the action schema ? like is it one of the tags there ? right . s like are you gonna have similar schemas for fm like forced motion and caused action and like you have for spg ? and if like can are you able to enforce that if it 's spg action then you have that schema , if it 's a forced motion then you have the other schema present in the  right . people reach their level of max their level of at which they 're incompetent or whatever .    e  mean clearly there 's talk about the the parser changes on friday at least ,    ","s like are you gonna have similar schemas for fm like forced motion and caused action and like you have for spg ? mean clearly there 's talk about the the parser changes on friday at least , ",
Bed006.G,"time . are you fey ?  hi . we 've met before , like , i remember talking to you about aspect like that at some point or other .  that 's right .  no offense . like .   getting ahead of myself . yay ! "" one of us . "" me ?  what ? you did ? when ?  about me or you ?  didn't know . i didn't mean to be humor copying , but  yes , i know myself . it 's it 's a of oz . not witch like .   didn't take a vote ?  more than three of us . the department has many mayors . right . did jerry talk to you about using our class ? the students in the undergrad class that he 's teaching ? e  but th it 's that people in his class cover a different set  than the c is the cogsci department that you were talking about ? reaching out to ? cuz we have people from other areas advertise in their classes as cuz know how to contact our students , if there 's something that you 're sending out you can also s send me a copy , me or bhaskara could either of us could post it to  is it if it 's a general solicitation that is just contact you then we can pro post it to the news group   you 'll send it   you can send it to me .  don't worry , we this doesn't concern you anymore , robert . it 's fine .  already ? really ?  i don't remember getting anything .  you 'll have those say somewhere what their intention was you still have the thing about having data where what the actual intention was ? but they will there 's nothing that says these are the things you want to do "" they 'll say "" these are the things i want to do "" and right , they 'll have a little bit more natural interaction ?   it w it doesn't have like streets on it that would allow them to figure out their way   i didn't know he was the founder . that 's  using this new plan ,  what 's the s this is what you made , fey ? like it 's just based on like the materials you had about heidelberg .  there 's a web site and then you could like figure out what the cate    are you worried about being able to identify  the goals that we 've d you guys have been talking about are this these identifying which of three modes their question concerns . it 's like the enter versus view      the interaction beforehand will give them hints about how specific or how whatever though the kinds of questions that are going to ask during the actual session ?    that 's what like those tasks are all gonna be unambiguous about which of the three modes . right .  t that they 'll be here ? it doesn't really have much meaning to grad students but final projects might . that ye no sample generator output yet ?  this is being sent ,    that was like one of the first l the first task was getting it working for english . that 's over now . is that right ? the basic requirement fulfilled .   the speech recognizer also works .    if and they 're correct . and they are correct . it 's not just like anything . and they 're mostly in english .  are they is it using the database ? the german tv movie .  all the actual data might be german names ? or are they all like american tv programs ?      right . but they 're shown like on a screen . it 's a would the generator , like the english language sentence of it is "" these are the follow the following films are being shown "" like that ? s right . it 'll just display  we don't have to worry about      right .  right .   forced motion and caused action  it 's the shadow . right .  this is the what the action planner uses ? this is  and is that and tha that 's changeable ? or not ? like are we adapting to it ? or     what did you think he was doing ?  you look up here .  it 's just an additional information right ? that doesn't hurt the current way .   good .     can you go back to that one ? the fillers of the role source .  th just don't kn  this is just xml mo notational but the fact that it 's action schema and then slash action schema that 's a whole entit that 's a block , whereas source is just an attribute ? is that   could it could also be blocked out then as      guess the question is when you actually fill one of these out , it 'll be under action schema ? those are it 's gonna be one y you 'll pick one of those for these are this is just a layout of the possible that could go play that role . go it .    s one question . this was in this case it 's all clear , obvious , but you can think of the enter , view and approach as each having their roles , right ? the it 's implicit that the person that 's moving is doing entering viewing and approaching , but the usual thing is we have bindings between they 're like action specific roles and the more general source path goal specific roles . are we worrying about that or not for now ?   what 's that ? guess it i may be just reading this and interpreting it into my head in the way that i 've always viewed things and that may or may not be what you guys intended . but if it is , then the top block is like ","you 'll have those say somewhere what their intention was they 'll have a little bit more natural interaction ? but if it is , then the top block is like ","The data collection script has been slightly modified, so that it encourages more natural dialogue between the subjects and the ""wizard"". "
Bed006.G,"you have to list exactly what x schema or in this action schema , there 'll be a certain one , that has its own s structure and it has about that specific to entering or viewing or approaching , but those could include roles like the thing that you 're viewing , the thing that you 're entering , the thing that you 're whatever , that which are think of enter , view and approach as frames and they have frame specific parameters and roles and you can also describe them in a general way as source path goal schema and there 's other image schemas that you could add after this that how do they work in terms of force dynamics or how do they work in f terms of other things . all of those have either specific frame specific roles or more general frame specific roles that might have binding . the question is are how to represent when things are linked in a certain way . we know for enter that there 's container potentially involved and it 's not don't know if you wanna have in the same level as the action schema spg schema it 's somewhere in there that you need to represent that there is some container and the interior of it corresponds to some part of the source path goal goal goal in this case . is there an easy way in this notation to show when there 's identity between things and i di don't know if that 's something we need to invent or just it 's  exactly . right , right . right .  great . s great . that 's exactly what is necessary .    happen to know how what "" sooner or later "" means like in practice ? or estimated .   pointer a way to really say pointers .     right . you have constraints that are dependent on the c actual s specific filler , of some attribute .  tsk .  or the gateway arch in st . louis .  whi which is not bad , because that there 's multiple sens that particular case , there 's mult there 's a forced side of that verb as would they both be listed here in  under under action schema there 's a list that can include both things . that 's interesting . what ? oop . i d f  i see .   interesting . would you say that the like you could have a flat structure and just say these are two independent things , but there 's also this like causal , one is really facilitating the other and it 's part of a compound action of some kind , which has structure . think that 's nicer for a lot of reasons but might be a pain  there are truly times when you have two independent goals that they might express at once , but in this case it 's really like there 's a purpo means that for achieving some other purpose .   see that bothers me that they 're the same thing .  because they 're two different things one of which is l you could think of one a sub pru whatever pre condition for the second . right .   there 's like levels of granularity . there 's single event of which they are both a part . and they 're independently they are events which have very different characters as far as source path goal whatever . when you identify source path goal and whatever , there 's gonna to be a desire , whatever , eating , hunger , whatever other frames you have involved , they have to match up in ways . it seems like each of them has its own internal structure and mapping to these schemas from the other but that 's just me . like i  between you guys   that would be     mayb  right . right . m th the other thing that thought of is that you could want to go to the bakery because you 're supposed to meet your friend there or som you like being able to infer the second thing is very useful and probably often right . but having them separate their friend said they were going to meet them in a bakery around the area . and i 'm , 'm inventing contexts which are unlikely , but mean like but it 's still the case that you could override that default by giving extra information which is to me a reason why you would keep the inference of that separate from the knowledge of "" they really want to know if there 's a bakery around here "" , which is direct . right .   exactly . it 's i met someone at the bakery in the victoria station t train station london before ,  it 's like j do within the source path goal actions ? those three ?  there 's a bit a redundancy , right ? in which the things that go into a particular you have categories at the top under action schema and the things that go under a particular category are supposed to have a corresponding schema definition for that type . guess what 's the function of having it up there too ? guess i 'm wondering whether you could just have under action schema you could just say whatever it 's gonna be enter , view or approach or whatever number of things and pos partly because you need to know somewhere that those things fall into some categories . and it may be multiple categories as you say which is the reason why it gets a little messy but if it has if it 's supposed to be categorized in category x then the corresponding schema x will be among the structures that follow . that 's like   you didn't tell me to  but now you guys have seen the light .  i it 's easy to go back and forth isn't it ?  ","and it has about that specific to entering or viewing or approaching , and you can also describe them in a general way as source path goal schema all of those have either specific frame specific roles or more general frame specific roles that might have binding . it 's somewhere in there that you need to represent that there is some container and the interior of it corresponds to some part of the source path goal goal goal in this case . you could have a flat structure and just say these are two independent things , but there 's also this like causal , one is really facilitating the other and it 's part of a compound action of some kind , which has structure . there 's like levels of granularity . there 's a bit a redundancy , ",
Bed006.G,"i agree . right . right . which is why i would think you would say enter and then just say all the things that are relevant specifically to enter . and then the things that are abstract will be in the abstract things as and that 's why the bindings become useful . ye i see what by that , but i don't if i would need to have t have that . right .   i what you could say is for enter , you could say "" here , list all the kinds of schemas that on the category that  list all the parent categories "" . it 's just like a frame hierarchy , right ? like you have these blended frames . you would say enter and you 'd say my parent frames are such and such , h and then those are the ones that actually you then actually define and say how the roles bind to your specific roles which will probably be f richer and fuller and have other in there . it could be not a coincidence . like i said , i 'm 'm just hitting everything with a hammer that i developed , but it 's i 'm just telling you what you just hit the button and it 's like metacomment . "" damn this project . "" no just kidding .    "" approach and then enter . "" run like this   no , this is the useful , don't worry .  guarantee that . and you could have also indicated that by saying "" enter , what are the kinds of action i am ? "" right ? there 's just like reverse organization , right ? like unless @ @ are there reasons why one is better than the other that come from other sources ?        it 's just like a pain to have to send it . i understand .  be great .    r . that 's fine . that 's true . although roles   i was going to bread rolls ? pastry ba the bak bakery example . i see . right . 'll agree to that , then . i n didn't you say something about friday , or ?  do i .  that would be good . three is sounds good ? i 'll be free by then . "" that 's the right answer . "" and you guys will argue some more ? and have some ? probably .  and we 'll get the summary like , this the c short version , like s like have it we 'll have it in writing .  or , better , speech .     let 's they 're i have several in my head ,  always thinking about binding .  in general they 'll be bindings across both intentions and the actions .   it 's gen it 's general across all of these things it 's like shastri would say binding is like an essential cognitive process .  don't think it will be isolated to one or the two , but you can definitely figure out where sometimes things belong and actually i 'm not i would be curious to see how separate the intention part and the action part are in the system . like i know the whole thing is like intention lattice , like that , right ? is the ri right now are the ideas the rich the rad or whatever is one potential block inside intention . it 's still mainly intention hypothesis and then that 's just one way to describe the action part of it .  great not just that you want to go from here to here , it 's that the action is what you intend and this action consists of all com complicated modules and image schemas and whatever .   which is , it 's fine  right . right .    we know the things that make use of this thing that we can just change them that they make use of rad . i can't believe we 're using this term . 'm like rad ! like every time i say it , it 's horrible .  i see what is the but what is the "" why "" ? why ? that 's doesn't make it a great term . it 's just like those jokes where you have to work on both levels . do you see what like      but what if it 's not an action ? and intentions will be "" rid "" ? like ,  are the sample data that you guys showed sometime ago like the things you 're gonna run a trial tomorrow . i 'm just wondering whether the ac some the actual sentences from this domain will be available . cuz it 'd be for me to like look if i 'm thinking about examples i 'm mostly looking at child language which will have some overlap but not total with the kinds of things that you guys are getting . you showed some in this here before and you 've posted it before but where would i look if i want to see ?  no just transcript .   i take that back then . don't make it a high priority i if you just tell me like like two examples y the representational problems are i 'm will be there , like enough for me to think about .   here .  ","which is why i would think you would say enter and then just say all the things that are relevant specifically to enter . and then the things that are abstract will be in the abstract things as and that 's why the bindings become useful . it 's just like a frame hierarchy , like unless @ @ are there reasons why one is better than the other that come from other sources ? i n didn't you say something about friday , in general they 'll be bindings across both intentions and the actions . are the sample data that you guys showed sometime ago cuz it 'd be for me to like look if i 'm thinking about examples ",
Bed008.A,"alright , 'm i should read all of these numbers ?  "" go there "" . it seems that you could it seems that those things would be logically independent like you would wanna have them separate or binary , go there and then the possibilities of how to go there because because , it might be easy to figure out that this person is going to need more film eventually from their utterance but it 's much more complex to query when would be the most appropriate time .  think no , but 'm following it . far .   user thrift .    that is simple . climb , rob . the charles bridge , no , if you go to re if you go to prague or whatever one of your key points that you have to do is cross the charles bridge and doesn't really matter which way you cross which where you end up at the end but the part the good part is walking over it ,     can i ask about "" slurred "" and "" angry "" as inputs to this ? what why ?    drunk . less likely to enter .       we 're deriving this the this feature of whether the main action at this place happens inside or outside or what we 're deriving that from what activity is done there ? couldn't you have it as just a primitive feature of the entity ?  it seems like that 's much more reliable cuz you could have outdoor places that sell things and indoor places that do something else and      i 'm just thinking about how people , human beings who know about places and places to go and on would store this and it would probably you wouldn't just remember that they sell and then deduce from that it must be going on inside       user schedule . "" do i have time to go in and climb all the way to the top of the koelner dome or do have to "" "" time to take a picture of the outside ? ""        what about the grand canyon , right ? no , never mind . are there large things that you would have to pay to get up close to like , never mind , not in the current    right ,         what whoops . right . also , that node , the go there s node would just be fed by separate ones for there 's different things , the strikes and the the time of day . actually actually is this the right way to have it where go there from the user and go there from the situation just don't know about each other but they both feed the go there decision because isn't the ,    but that still allows for the possibility of the user model affecting our decision about whether a strike is the thing which is going to keep this user away from that all that decision making happens at the go there node .  if you needed it to do that . but was just thinking 'm conflating that user node with possible asking of the user  hey there 's a strike on , does that affect whether or not you wanna go or that might not come out of a user model but , directly out of interaction .      right , right .  right ,  alright .     now .     right . darn .        right .  point three . no . the function of the thing that comes out of h is very different from the function of the other inputs . it 's driving how the other four are interpreted .  vector with three zero 's and one , right ? does h have to have another input to tell it alpha , beta , whatever , or is the that 's determined by what the experts are saying , like the type of situ     it just seems that like without that outside input that you 've got a situation where , like if one says no , a low value coming out of x on or i if x one says no then ignore x one ,  that seems like that 'd be weird , right ?   alright , right . right , right .  like how thrifty the user is , or do we have access to that ?  right . good .     no .    just talking about about that general end of things is there gonna be data soon from what people say when they 're interacting with the system and on ? like , what questions are being given being asked ? cuz     fey ,   o  i 'm just wondering , because in terms of ,   the figure i was thinking about this figure that we talked about , fifty constructions or whatever that 's that 's a whole lot of constructions and one might be f fairly pleased with getting a really good analysis of five ten in a summer know we 're going for rough and ready .     i was was talking about the , if you wanted to do it really in detail and we don't really need all the detail for what we 're doing right now but anyway in terms of just narrowing that task which fifty do i do , i wanna see what people are using ,  it will inspire me . right , right .     touche . good enough . ",we 're deriving this the this feature of whether the main action at this place happens inside or outside or what we 're deriving that from what activity is done there ? and one might be f fairly pleased with getting a really good analysis of five ten in a summer know we 're going for rough and ready . ,
Bed008.B,"  i don't know whether ami 's coming or not  but we oughta just get started . don't know . anyway  there you go . anyway , my idea f for today and we can decide that isn't the right thing to do was to at spend at least part of the time trying to build the influence links , which sets of things are relevant to which decisions and actually i had specific s suggestion to start first with the path ones . the database ones being in some sense less interesting to us although probably have to be done and to do that there 's and the idea was we were gonna do two things  right ,  we were gonna do two things one of which is just lay out the influence structure of what we think influences what and then as a separate but related task particularly bhaskara and i were going to try to decide what kinds of belief nodes are needed in order to do what we need to do . once but du we should have all of the basic design of what influences what done before we decide exactly how to compute it . didn't did you get a chance to look yet ? great . let 's start with the belief nets , the general influence and then we 'll also at some point break and talk about the techy are you gonna go there or not ? one i right , true . does have to be there . and i 'm we 'll find more as we go that  there is this question about  when we 're when we 're done .  the reason it might not be true or false is that we did have this idea of when it 's , current @ @ and forth and on or not right ? and that a decision would be do we want that you could two different things you could do , you could have all those values for go there or you could have go there be binary and given that you 're going there when .  and forth . 'll let we 'll see . that 's let 's start that way . right . no you 've s have you seen this before keith , these belief net things ?  or cheapness . thrift , that 's good . great . keith w what 's behind this is actually a program that will once you fill all this in actually s solve your belief nets for you and this is not just a display , this is actually a gui to a simulator that will if we tell it all the right things we 'll wind up with a functioning belief net at the other end . doesn't matter . let 's go ahead . here 's what 's permissible is that you can arrange that the the value of that is gonna have to be updated and n it 's not a belief update , right ? it 's you took some actions , you spent money and the update of that is gonna have to be essentially external to the belief net . right ? and then what you 're going to need is for the things that it influences . let 's first of all let 's see if it does influence anything . and if it does influence anything then you 're gonna need something that converts from the number here to something that 's relevant to the decision there . it could be ra they create different ranges that are relevant for different decisions or whatever but for the moment this is just a node that is conditioned externally and might influence various things . that 's fine . anyway , go ahead . that 's a good question . and does it have a lazy mode ? i don't remember . right .  s probably does .  someone has to track that down , but i but and actually one of the we w items for the user home base should be essentially non local . i they 're only there for the day and they don't have a place that they 're staying .   it 's clear where w where we are right now . my suggestion is we just pick one , one particular one of the let 's do the first one let 's do the one that we already think we did that was the of the endpoint ? no , that 's a although that that 's no , he has he hasn't filled them in yet , is what 's true .  no no , these are ju that 's just a point , this is ju would be a f for a given segment . you y you go first go the town square that 's subtle , but true . anyway let 's just leave it three with three for now and let 's see if we can get it linked up just to get ourselves started . you 'll see it you 'll see something comes up immediately , that the reason i wanna do this . right . right . we did , but the three things w that it contributed to this the other two aren't up there . one was the ontology  and the third thing we talked about was something from the discourse . this is w right , what w i what we seem to need here , this is why it starts getting into the technical the way we had been designing this , there were three intermediate nodes which were the endpoint decision as seen from the user model as seen from the ontology and as seen from the discourse . each of those the way we had it designed , now we can change the design , but the design we had was there was a decision with the same three outcomes based on the th those three separate considerations ","we were gonna do two things one of which is just lay out the influence structure of what we think influences what but du we should have all of the basic design of what influences what done before we decide exactly how to compute it . you could have all those values for go there or you could have go there be binary and given that you 're going there when . this is actually a gui to a simulator that will if we tell it all the right things we 'll wind up with a functioning belief net at the other end . it 's you took some actions , you spent money and and if it does influence anything then you 're gonna need something that converts from the number here to something that 's relevant to the decision there . that was the of the endpoint ? the way we had been designing this , there were three intermediate nodes which were the endpoint decision as seen from the user model as seen from the ontology and as seen from the discourse . there was a decision with the same three outcomes based on the th those three separate considerations ","Its structure was discussed during the meeting. Details of how different inputs feed into them were discussed at length. There are several endpoints (User, Ontology, Discourse etc) with separate EVA (Enter/View/Approach) values. "
Bed008.B,"if we wanted to do that would have to put in three intermediate nodes and then what you and i have to talk about is , if we 're doing that and they get combined somehow how do they get combined ? but the they 're undoubtedly gonna be more things to worry about .  it was called mode , this is m mode here means the same as endpoint . why don't we ch can we change that ? alright . but that was actually , unfortunately that was a an intermediate versio that 's i don't think what we would currently do . that 's a  but that 's that seems to ,  my advice to do is get this down to what we think is actually likely to be a strong influence . but that was what he had in mind . let 's think about this question of how do we wanna handle there 're two separate things . one is at least two . one is how do we want to handle the notion of the ontology now what we talked about , and this is another technical thing bhaskara , is can we arrange that we can that the belief net itself has properties and the properties are filled in from on ontology items . the let 's take the case of the this endpoint thing , the notion was that if you had a few key properties like is this a tourist site , some landmark is it a place of business is it something you physically could enter  et cetera . that there 'd be certain properties that would fit into the decision node and then again as part of the ou outer controlling conditioning of this thing those would be set , that some somehow someone would find this word , look it up in the ontology , pull out these properties , put it into the belief net , and then the decision would flow . now right . right .   i that 's that 's completely right and think that 's good , right ? what that says is that we might be able to take and in particular the ones we talked about were exhibiting and selling no , accessibility meant  alright . let me suggest this . could you move those up about halfway . the ones that you th and selling right . here 's what it looks like to me . is that you want an intermediate structure which i is essentially the or of for this purpose of selling , f fixing , or servicing . that it that is , for certain purposes , it becomes important but for this purpose one of these places is quite like the other . does that seem right ? we di if we yes . if it may be more than endpoint decisions , the idea would be that you might wanna merge those three  ser s selling , fixing , and servicing . it i here 's where it gets a little tricky . from the belief net point of view it is from another point of view it 's interest it 's important to it 's selling or servicing and forth . for this decision it 's just true or false and in th this is a case where the or seems just what you want . that if any of those things is true then it 's the place that you are more likely to enter . you could , let 's do that . no , no to an inter no , an intermediate node . that 's the p part of the idea , is i d o open up object type and let 's see what its values are . first of all it 's not objects , we called them entities , right ? let 's say i put commercial . couldn't i do let 's do commercial landmark and  accessible is different cuz that 's tempor that varies temporally , whereas this is a i would call that a service , but i don't know . say w it 's co i would s a again for this purpose it 's commercial . someplace you want to go in to do some business . you could , that 's a choice .  the problem with it is that it putting in a feature just for one decision , now w we may wind up having to do that this i anyway , this i at a mental level that 's what we 're gonna have to sort out . what does this look like , what are intermediate things that are worth computing , what are the features we need in order to make all these decisions and what 's the best way to organize this that it 's clean and consistent and all that  anyway let me suggest you do something else . which is to get rid of that l long link between who the user and the endpoint . no , i don't want the link there because what we 're gonna want is an intermediate thing which is the endpoint decisi the endpoint decision based o on the user models , what we talked about is three separate endpoint decisions , let 's make a new node this was let 's p put it this let 's do endpoint underbar u . i endpoint , e end poi this is sa it 's the endpoint let 's say underbar u , that 's the endpoint decision as seen through the right . let 's actually lin you can link that up to the that , that 's endpoint underscore e for entity , and we may change all this , but . right . and d don't know . actually , the easiest thing would move mo move the endpoint , go ahead . just do whatever .  good . right .  and th it 's just one who is the user , i don't know , ","but the they 're undoubtedly gonna be more things to worry about . my advice to do is get this down to what we think is actually likely to be a strong influence . that the belief net itself has properties and the properties are filled in from on ontology items . that there 'd be certain properties that would fit into the decision node and then again as part of the ou outer controlling conditioning of this thing those would be set , that some somehow someone would find this word , look it up in the ontology , pull out these properties , put it into the belief net , and then the decision would flow . but for this purpose one of these places is quite like the other . the idea would be that you might wanna merge those three for this decision it 's just true or false that if any of those things is true then it 's the place that you are more likely to enter . what does this look like , what are intermediate things that are worth computing , what are the features we need in order to make all these decisions and what 's the best way to organize this that it 's clean and consistent and all that ","Ideas mentioned included grouping features of buildings like ""selling"", ""fixing"" and ""exhibiting"", as well as creating a User-compatibility node that would take different values depending on the situation and the user status. "
Bed008.B,"there 's more . never mind . anyway , this is crude . now but the now but then the question is  and we assume that some of these properties would come indirectly through an ontology , but then we had this third idea of input from the discourse .    i again , i d put in but what we 're gonna wanna do is actually somebody else has built this user model .  you cou and here let me give you two ways to handle that . alright ? one is you could ignore it . but the other thing you could do is have an and this will give you the flavor of the of what you could have a node that 's that was a measure of the match between the object 's feature , the match between the object the entity , i 'm and the user . you could have a k a "" fit "" node that would have to be computed by someone else but that that 's all .  we could .  right . that 's what we don't wanna do , see that se cuz then we get into huge combinatorics and like that an but that 's we can't do that , we 're gonna have to but this is a good discussion , we 're gonna have to somehow figure out some way to encapsulate that if there 's some general notion of the relation to the time to do this to the amount of time the guy has like that is the compatibility with his current state , that 's what you 'd have to do , you 'd have to get it down to something which was itself relatively compact , it could be compatibility with his current state which would include his money and his time and his energy it does . it there are two advantages . that 's tha there 's one technical one and the other is it gets used right . but it there 's two advantages , one is the technical one that you don't wind up with such big exponential cbt 's , the other is it can be it presumably can be used for multiple decisions . that if you have this idea of the compatibility with the requirements of an action to the state of the user one could imagine that was u not only is it sim is it cleaner to compute it separately but it could be that it 's used in multiple places . anyway th in general this is the design , this is really design problem . you 've got a signal , a d set of decisions how do we do this ? or fat user fatigue even . whatever . what 's th what we 're talking about is compatibility . i don't know , but . but that we we had some things that that don't the right not . the that 's the issue is would even if it was true in some abstract general sense it might not be true in terms of the information we actually had and can make use of . and anyway we 're gonna have to find some way to cl get this sufficiently simple to make it feasible . w but that viewing it without ent view w with our definition of view it 's free cuz you  no we have to enter the park . almost by definition paying involves entering , ge going through some right .  let me suggest we switch to another one , clearly there 's more work to be done on this but it 's gonna be more instructive to think about other decisions that we need to make in path land . and what they 're gonna look like . why , it 's worth saving this one but 'd like to keep this one cuz i wanna see if we 're gonna reuse any of this you tell me , in terms of the planner what 's a good one to do ?  the fir see the first thing is , getting back to thing we left out of the other is the actual discourse . keith this is gonna get into your world because we 're gonna want to know which constructions indicate various of these properties s and i don't yet know how to do this , we 're gonna wind up pulling out discourse properties like we have object properties and we don't they are yet . that the go there decision will have a node from discourse , and why don't we just stick a discourse thing up there to be as a placeholder for   the ontology we said we would pull these various kinds of properties from the ontology like exhibiting , selling , and forth . in some sense it 's there . but the discourse we don't have it represented yet . but if we do it 'll have the three values . it 'll have the eva values if we have it . for go there , probably is true and false , let 's say . that 's what we talked about . right .  but that doesn't change the fact that you 're you want these two values . and they 'll be a y a user go there and that 's all , i don't know . good .  right . right , that 's where it starts getting to be essentially more interesting , what bhaskara says which is completely right is if that they 're only going to view it then it doesn't matter whether it 's closed or not in terms of whether you wanna go there . there are other situational things that do matter . it can have di various values . but we you 're right it might not be enough .   i see that could be . could be .  n  ","and we assume that some of these properties would come indirectly through an ontology , but then we had this third idea of input from the discourse . you could have a node that 's that was a measure of the match between the object 's feature , the match between the object the entity , i 'm and the user . cuz then we get into huge combinatorics and like that we 're gonna have to somehow figure out some way to encapsulate that if there 's some general notion of the relation to the time to do this to the amount of time the guy has like that is the compatibility with his current state , one is the technical one that you don't wind up with such big exponential cbt 's , the other is it can be it presumably can be used for multiple decisions . anyway th in general this is the design , this is really design problem . but that we we had some things that and anyway we 're gonna have to find some way to cl get this sufficiently simple to make it feasible . clearly there 's more work to be done on this but it 's gonna be more instructive to think about other decisions that we need to make in path land . in terms of the planner what 's a good one to do ? the fir see the first thing is , getting back to thing we left out of the other is the actual discourse . because we 're gonna want to know which constructions indicate various of these properties we 're gonna wind up pulling out discourse properties like we have object properties and we don't they are yet . for go there , probably is true and false , let 's say . and they 'll be a y a user go there ","Ideas mentioned included grouping features of buildings like ""selling"", ""fixing"" and ""exhibiting"", as well as creating a User-compatibility node that would take different values depending on the situation and the user status. Similarly, a Go-there (towards a building) node can be influenced by things like the user's budget and discourse parameters amongst other things. The study of the linguistic constructions that people use in this kind of navigational domain is expected to be prove useful in that respect. The latter are still ill-defined at this stage. "
Bed008.B,"now the other thing that bhaskara pointed out is what this says is that there sh should be a link , and this is where things are gonna get very messy from the endpoint decision the t they 're final re and , the very bottom endpoint decision to the go there node . and i don't worry about layout , then we 'll go nuts but could be ,   the go there , actually the endpoint node could feed into the go there s that 's right , the endpoint node , make that up t to the go there then we 'll have to do layout at some point , but something like that . now it 's gonna be important not to have loops really important in the belief worl net world not to have loops  no it 's much worse than that . it if i loo it it 's not def i it 's not defined if you 're there are loops , you just you have to there are all sorts of ways of breaking it up that there isn't   no it 's not a loop yet , i 'm just saying we , in no , in right . anyway , that 's another decision . what 's another decision you like ? the idea is that you go there , you go comes from something about the user from something about the situation and the the discourse is a mystery . if you want . right .   and then also the discourse endpoint , endpoint sub d is if you wanna make it consistent .  s not , a right . you you i you if you needed to do that .    good point , i don't know how we 're going to t right . gu yes my curr don't that 's enough . my current idea on that would be that each of these decision nodes has questions associated with it . and the question wouldn't itself be one of these conditional things given that there 's a strike do you still wanna go ? but if you told him a bunch of then you would ask him do you wanna go ? but trying to formulate the conditional question , that sounds too much . to me . alright , but let me let 's stay with this a minute because i want to do a little bit of organization . before we get more into details . the organization is going to be that the flavor of what 's going on is going to be that as we s e going to this detail keith is going to worry about the various constructions that people might use and johno has committed himself to being the parser wizard , what 's going to happen is that eventually like by the time he graduates ,  they 'll be some system which is able to take the discourse in context and have outputs that can feed the rest of belief net . i j wa i assume everybody knows that , wanna get closure that 'll be the game then , the semantics that you 'll get out of the discourse will be of values that go into the various discourse based decision nodes . and now some of those will get fancier like mode of transportation and it isn't by any means necessarily a simple thing that you want out . if there is an and there is mode of transportation  that , we 'll have to decide how much of th where that goes . an and it 's not clear yet . it could be those are two separate things , it could be that the discourse gadget itself integrates as which would be my guess that you 'd have to do see in order to do reference and like that you 've gotta have both the current discourse and the context to say i wanna go back there , what does that mean and alright .  i don't know . it could be . this is getting into the thing i wanna talk about next , which is s if that 's true how do we wanna combine those ? o or when it 's true ?  no . it see i if it 's fou if it 's four things and each of them has four values it turns out to be a big cpt , it 's not s completely impossi it 's not beyond what the system could solve but it 's probably beyond what we could actually write down . or learn . but , it 's four to the fourth . it 's pretty big .    it 's and i don't think it 's gonna g e i don't think it 'll get worse than that le that 's a good for go there , but not f but not for the other one 's three values for endpoint already . ev it 's the eva . no . since ta they will still have three . each you 're from each point of view you 're making the same decision . from the point of view of the ob of the entity  right . those are not necessarily binary . s we 're gonna have to use some t care in the knowledge engineering to not have this explode . and it doesn't in the sense that  read it , actually with the underlying semantics and think it isn't like you have two hundred and fifty six different ways of thinking about whether this user wants to go to some place . alright . we just have to figure out what the regularities are and code them . but what i was gonna suggest next is we wanna work on this a little longer but i do want to also talk about the thing that we started into now of  it 's all fine to say all these arrows come into the si same place what rule of combination is used there . ","really important in the belief worl net world not to have loops what 's going to happen is that eventually they 'll be some system which is able to take the discourse in context and have outputs that can feed the rest of belief net . and now some of those will get fancier like mode of transportation and that you 'd have to do see in order to do reference and like that you 've gotta have both the current discourse and the context to say i wanna go back there , s we 're gonna have to use some t care in the knowledge engineering to not have this explode . we just have to figure out what the regularities are and code them . ",
Bed008.B,"th yes they these things all affect it , how do they affect it ? and belief nets have their own beliefs about what are good ways to do that . is it 's clearer n clear enough what the issue is , right ? do we wanna switch that now or we wanna do some more of this ? here he here 's one of the things that i th you sh you no , i don't know how easy it is to do this in the interface but you it would be great if you could actually just display at a given time all the things that you pick up , you click on "" endpoint "" ,  and everything else fades and you just see the links that are relevant to that . and i does anybody remember the gui on this ? the the b anyway it clear that even with this if we put in all the arrows nobody is gonna be able to read the diagram . alright , we have to figure out some display hack to do this because anyway i let me consi suggest that 's a s not a first order consideration , we have two first order considerations which is what are the influences a , a , and b how do they get combined mathematically , how do we display them is an issue , but  right . and that seems like a perfectly feasible thing to get into , but we have to we want first . why don't you tell us a little bit about decision nodes and what the choices might be for these ? put it in your ,   alright ,  is that i wanna make everybody is with us before he goes on . it 's cl e is it clear what he wants to compute ? what ? y right .  s this assumes symmetry and equal weights and all this things , which may or may not be a good assumption , that ","i don't know how easy it is to do this in the interface but you it would be great if you could actually just display at a given time all the things that you pick up , you click on "" endpoint "" , and everything else fades and you just see the links that are relevant to that . s this assumes symmetry and equal weights and all this things , which may or may not be a good assumption , ",
Bed008.C,"nancy 's still stick ? is your mike on ? yes . what 's the difference between mode and endpoint ?  would it be an endpoint if you were crossing over it ?  right . if the person talking is angry or slurs their speech they might be tired or , and , possibly some ,  basic you 're just merging those for just the sake of endpoint decision ?  what would a hotel fall under ? mean in terms of entity type ?  just as a suggestion you could "" save as "" to keep your old one and clean and you can mess with this one . not a big deal then . the isn't there a "" save as "" inside of java base ?  as related from the user model . you have to be in move mode before the user thrift , the user budget . is it seems like everything in a user model a affects  cuz if the , and if the user is tired , the user state , right , it would affect but i can't see why e anything w everything in the model wouldn't be  just seems like it 'd push the problem back a level . but sh  s we 'd be doing subgrouping ? subgrouping , into mo make it more tree like going backwards ? the question is it 's hard for me to imagine how everything wouldn't just contribute to user state again . or user compatibility . but other though the node we 're creating right now is user compatibility to the current action , right ? seems like everything in the user model would contribute to whether or not the user was compatible with something . with the way we 're defining it you can save this one as and open up the old one , right and and then everything would be clean . you could do it again .  it does matter though if there 's like a strike or riot wh two fifty six , is that what that  right . i would almost say the other way to do that would be to open u or make many belief nets and then open them every time you wanted to look at a different one vers cuz but  i don't , just don't think this has been designed to support something like that . you can technically wear that as you 're talking . x one matters more i than x two or jus just to make understand this , in this case we would still compute the average ?  it 'd be in this case the probability that y equals a would be one times or a or let 's see , one full quarter times point one   passes a vector on to the next node ? it could ? a vector of the weights as the se  it 's to tell the bottom node which one of the situations that it 's in or which one of the weighting systems w i was just , if you wanted to pay attention to more than one you could pass a w a weighting s system though too , couldn't you ?  the situations that h has , are they built into the net or they could either be hand coded or learned or  based on training data ,  you specify one of these things for every one of those possi possible situations .  you would say , based on in this dialogue that we have which one of the things that they said whether it was the entity relations or whatever was the thing that determined what mode it was , right ? that 's on the added variable , isn't it ?  in terms of java base it 's what you see is what you get in i don't  i would be surprised if it supports anything more than what we have right here . ","if the person talking is angry or slurs their speech they might be tired or , it seems like everything in a user model a affects just seems like it 'd push the problem back a level . it 's hard for me to imagine how everything wouldn't just contribute to user state again . w i was just , if you wanted to pay attention to more than one you could pass a w a weighting s system though too , the situations that h has , are they built into the net they could either be hand coded or learned or based on training data , in terms of java base it 's what you see is what you get in i would be surprised if it supports anything more than what we have right here . ","There are several approaches ranging from simply averaging the inputs to using a hidden variable in order to weight them differently depending on context. If the latter architecture is used, the net could -to an extent- be trained with the data that is currently being collected. "
Bed008.D,"that 's funny . i looked at some of that which one ?  is this like a number that represents how much money they have left to spend ? h mean how is it different from user finance ? alright .  you 've written in what seems to be required like what else is do you want ? the other thing is that every time that 's updated beliefs will have to be propagated but then the question is do you do we wanna propagate beliefs every single time it 's updated or only when we need to ?  in srini 's thing there was this option like proper inferences which suggests that doesn't happen , automatically .  is  it 's true or false ?  mode ,  mode of transportation ?  also true or false .   some of those are subsumed by approach . yes . like they 're either true or false and they see . therefore was thinking less likely to view right . what ex and either those is true f or false ?     you just wanna have them all pointing to a summary thing ? t what does the underscore t at the end of each of those things signify ?    that also points to entity type level of interest ? see , right . why is it it , it 's like a vector of five hundred one 's or zero 's ? like for each thing are we are you interested in it or not ? i see . budget .  right . right . no but , it 's more than that , like the more you break it up like because if you have everything pointing to one node it 's like exponential whereas if you like keep breaking it up more and more it 's not exponential anymore .  right . right .  situation go there , because it 's whether it 's open or not . that definitely interes but that now that what 's the word the that interacts with the eva thing if they just wanna view it then it 's fine to go there when it 's closed whereas if they want to  the time of day , right i right . right .  that 's what i said just having one situational node may not be enough because this that node by itself wouldn't distinguish see i 'm thinking that any node that begins with "" go there "" is either gonna be true or false . like situation traffic and on . the final   we could have intermediate node that just the endpoint and the go there s node fed into ? right . because that 's what we , that 's why this situation comes up . right . yes . it things don't converge ,   but the good thing is we could have loopy belief propagation which we all love .    you need actually three to the five because mean if it has four inputs and then it itself has three values  it can get big fast . no it still has three , eva . this and also , the other places where , like consider endpoint view , it has inputs coming from user budget , user thrift even right . html ?   it might soon , if this is gonna be used in a serious way like java base then it might soon be necessary to start modifying it for our purposes .   that 's it 's right , can do that . this board works fine . recall the basic problem which is that you have a belief net and you have like a lot of different nodes all contributing to one node . right ? as we discussed specifying this thing is a big pain and it 's will take a long time to write down because if these s have three possibilities each and this has three possibilities then you have two hundred and forty three possibilities which is already a lot of numbers to write down . what helps us in our situation is that these all have values in the same set , right ? these are all like saying ev or a , right ? it 's not just a generalized situation like we wanna just take a combination of we wanna view each of these as experts ea who are each of them is making a decision based on some factors and we wanna combine their decisions and create sorta weighted combination . the what decision ?   the problem is to specify the the conditional property of this given all those , right ? that 's the way belief nets are defined , like each node given its parents , right ? that 's what we want , we want of let 's call this guy y and let 's call these x one , x two xn , right . we want probability that y equals , given that these guys are i 'll just refer to this as like x hat the co like all of them ? given that the data says a , v , a , e , right ? we would like to do this combination . right . right . what we don't wanna do is to for every single combination of e and v and a and every single letter e , s give a number because that 's not desirable . what we wanna do is find some principled way of saying what each of these is and we want it to be a valid probability distribution , we want it to add up to one , right ? those are the two things that we need . what guess , what jerry suggested earlier was that we , view these guys as voting and we just take the we essentially take averages , right ? here two people have voted for a , one has voted for v , and one has voted for e , ","the other thing is that every time that 's updated beliefs will have to be propagated but then the question is do you do we wanna propagate beliefs every single time it 's updated or only when we need to ? was thinking less likely to view what ex and either those is true f or false ? no but , it 's more than that , situation go there , see i 'm thinking that any node that begins with "" go there "" is either gonna be true or false . it might soon , if this is gonna be used in a serious way like java base then it might soon be necessary to start modifying it for our purposes . recall the basic problem which is that you have a belief net and you have like a lot of different nodes all contributing to one node . as we discussed specifying this thing is a big pain what helps us in our situation is that these all have values in the same set , these are all like saying ev or a , we wanna view each of these as experts ea who are each of them is making a decision based on some factors and we wanna combine their decisions and create sorta weighted combination . the problem is to specify the the conditional property of this given all those , like each node given its parents , what guess , what jerry suggested earlier was that we , view these guys as voting and we just take the we essentially take averages , ","As each node in the tree is the decision point of the combination of its parent nodes, which rules govern this combination is an important issue. There are several endpoints (User, Ontology, Discourse etc) with separate EVA (Enter/View/Approach) values. There are several approaches ranging from simply averaging the inputs to using a hidden variable in order to weight them differently depending on context. "
Bed008.D,"we could say that the probabilities are , probability of being e is one over four , because one person voted for e out of four and similarly , probability of this is probability of e s and then probability of a given all that is two out of four and probability of v is one out of four . right ? that 's step that 's the that 's the basic thing . now is that all    step two is right . we 've assumed equal weights whereas it might turn out that some w be that what the the actual the verbal content of what the person said , like what what might be somehow more important than the right . we don't wanna like give them all equal weight currently we 've been giving them all weight one fourth we could replace this by one , w two , w three , and w four right ? and in order for this to be a valid probability distribution for each hat , we just need that the w 's sum to one . they can be you could have point one , point three , point two , and point four , say . and that 'd be one . that also seems to work fine . and you 'd compute the weighted average , the probability of e would be not one quarter , these numbers have been replaced with point one , point three , point two , and point four . you can view these as gone . probability of     alright . this is step two . the next possibility is that we 've given just a single weight to each expert , right , whereas it might be the case that in certain situations one of the experts is more reliable and in certain situations the other expert is more reliable . the way this is handled is by what 's called a mixture of experts , what you can have is you augment these diagrams like this  you have a new thing called "" h "" ,  this is a hidden variable . and what this is it gets its input from x one , x two , x three , and x four , and what it does is it decides which of the experts is to be trusted in this particular situation . right ? and then these guys all come here .  this is sightly more complicated . what 's going on is that this h node looks at these four values of those guys and it decides in given these values which of these isn't likely to be more reliable or most reliable . produces some it produces a number , either one , two , three , or four , in our situation , right ? now this guy he looks at the value of h say it 's two , and then he just selects the thing . that 's all there is to say , about it . right , you can have a mixture that right .   it could . it could  right , mean the way you desc could be things like if x two and x three say yes then i ignore x one also .   yes .  to learn them we need data , where are we gonna get data ? mean we need data with people intentions , right ? which is slightly tricky . right .  but what 's the data about like , are we able to get these nodes from the data ?  but that 's my question , like how do we how do we have data about something like endpoint sub e , or endpoint sub ?   this is what we wanna learn .  right .   i don't think , you have a can you bring up the function thing ? where is the thing that allows you to function properties , is that it ? not . that 's right .  and it either it 'll allow us to do everything which is unlikely , more likely it 'll allow us to do very few of these things and in that case we 'll have to just write up little things that allow you to create such cpu 's on your own in the java base format .   i was assuming that 's what we 'd always do because was assuming that 's what we 'd always do , it 's right .  ","step two is we don't wanna like give them all equal weight you 'd compute the weighted average , the next possibility is that we 've given just a single weight to each expert , whereas it might be the case that in certain situations one of the experts is more reliable and in certain situations the other expert is more reliable . you have a new thing called "" h "" , this is a hidden variable . and what it does is it decides which of the experts is to be trusted in this particular situation . produces some it produces a number , either one , two , three , or four , in our situation , mean we need data with people intentions , like , are we able to get these nodes from the data ? ",There are several approaches ranging from simply averaging the inputs to using a hidden variable in order to weight them differently depending on context. 
Bed008.E,"piece of paper ? i could borrow ? nancy is currently in berkeley but not here ?  think one could go there 's we can di discuss everything . first of all this i added , i knew from this has to be there right ?  given not transverse the castle , the decision is does the person want to go there or is it just and  go there in the first place or not is definitely one of the basic ones . we can start with that . interesting effect . is this true or false or we 'll get what ? m right . here we we actually get just probabilities , right for each down here .   when . how . why ,      and 've tried to come up with some initial things one could observe who is the user ? everything that has user comes from the user model everything that has situation comes from the situation model a . we should be clear . but when it comes to writing down when you do these things is it here ? you have to a write the values this can take . and here i was really in some s sometimes i was really standing in front of a wall feeling very stupid because this case it 's pretty simple , but as we will see the other ones if it 's a running budget what are the discrete values of a running budget ? my understanding there is too impoverished . how can i write here that this is something , a number that cr keeps on changing ? but thus is understandable ? here here is the we had that the user 's budget may influence the outcome of decisions . there we wanted to keep running total of things . the finance is here thought of as the financial policy a person carries out in his life , he is he cheap , average , or spendy ? and didn't come user i don't know , i didn't want to write greediness , but welcome . welcome . there it is . and it 's simple even use it . here was think of people being cheap , average , or spendy or we can even have a finer scale moderately cheap , doesn't matter . agree there but here wasn't what to write in . if that 's permissible then i 'm happy .   this is where anyways let 's forget it . and this , that accidentally  just accidentally erased this , had values here such as is he s we had in our list we had "" is he staying in our hotel ? "" , "" is he staying with friends ? "" , and forth  we 're  something down here ?  and   no no , eva . missed that one . mode was   did i or didn't i ? probably nothing done yet , just did it on the upper ones , makes sense . this was eva . we can think of more things , cross climb , emerge   we w the user was definitely more likely to enter if he 's a local more likely to view if he 's a tourist  and then we had the fact that given the fact that he 's thrifty and there will be admission then we get all these cross we 'll d what type of building is it ?  what he has mentioned before . we can load it up it very simple . this was adjusted for this one mode thing . that 's w in our in johno 's pictogram everything that could contribute to whether a person wants to enter , view , or approach something . is now this endpoint . we can just rename that , the prosody ? seems to me that we 've embedded a lot , embedded a lot of these things we had in there previously in some of the other final decisions done here , if we would know that this thing is exhibiting something if it 's exhibiting itself it is a landmark , meaning more likely to be viewed if it is exhibiting pictures or sculptures and like this , then it 's more likely to be entered . accessibility . if it 's closed one probably won't enter . or if it 's not accessible to a tourist ever the likelihood of that person actually wanting to enter it , given that he knows it , all of these if it 's fixing things selling things , or servicing things these three ?  more likely to enter .  is that the object type node ? are they the is it the object that sells , fixes , or services things ? just created it , it has none far .  and then we have the  i w i was just gonna commercial action inside where people p and where was the accessible ,   things . places that service things sell things or fix things and pe places that e exhibit things . think an entity should be regard as a vector of several possible things , it can either do s do sell things , fix things , service things , exhibit things , it can be a landmark at the same time as doing these things , it 's not either or certainly a place can be a hotel and a famous site . many come to mind . things can be generally landmark and be accessible . ie a castle or can be a landmark a or not accessible , some statue can go inside . could we just move it like this ?     the old one was not that important , but let 's do it then . but just take this copy it somewhere else . this was user something or end point ?  gotcha , should i rename this too ? it 's underscore e . shouldn't i be able to move them all ? no . or ? can i ? where ? ","go there in the first place or not is definitely one of the basic ones . everything that has user comes from the user model everything that has situation comes from the situation model a . here is the we had that the user 's budget may influence the outcome of decisions . the finance is here thought of as the financial policy a person carries out in his life , this was eva . if it 's fixing things selling things , or servicing things ","Similarly, a Go-there (towards a building) node can be influenced by things like the user's budget and discourse parameters amongst other things. Ideas mentioned included grouping features of buildings like ""selling"", ""fixing"" and ""exhibiting"", as well as creating a User-compatibility node that would take different values depending on the situation and the user status. "
Bed008.E,"what ? wasn't this possible ?    now we 're looking for user related things that if he 's usi if he 's in a car right now what was that people with harry drove the car into the cafe let 's should we finish this , but surely the user interests  here this was one of my problems we have the user interest is a vector of five hundred values ,  that 's from the user model ,  no not levels of interest but things you can be interested in . gothic churches versus baroque townhouses versus yea n is that  think    just as a mental note   and should we say that this interests affects the likelihood of entering ?  and also if it 's an expensive place to enter , this may also schedule ? bhaskara ?  what do i have under user state anyhow cuz i named that already something . that 's tired , fresh ,  should be renamed into physical state . that 's with a "" g "" ? then we can make a user state . that don't . the user interests and the user who the user is are completely apart from the fact whether he is tired broke if we look at the if we split it up again into if we look at the the endpoint again we said that for each of these things there are certain preconditions you can only enter a place if you are not too tired to do and also have the money to do if it costs something if you can afford it and perform it is preconditions . viewing usually is cheap or free . is that always true ? i don't know . and is approaching .   this might be what next ? let 's th this go there or not is a good one . is a very basic one .  what makes things more likely that  we also had discourse features for the endpoint . identified that re that 's completely correct , we have the user model , the situation model here , we don't have the discourse model here yet . much the same way as we didn't we don't have the ontology here . really .    this be specific for second year ?  and we probably will have something like a discourse for endpoint .    just for starters and here discourse  we 're looking at the little data that we have , people say how do i get to the castle and this usually means they wanna go there . this should push it in one direction however people also sometimes say how do i get there in order to find out how to get there without wanting to go there . and sometimes people say where is it because they wanna know where it is but in most cases they probably  true . this is some external thing that takes all the discourse and then says here it 's either yay , a , or nay .        i was just gonna how long does it take you to compute recursive action ? but this isn't , this is this line is just coming from over here .  these have no parents yet , but that doesn't matter . right ? this is this comes from traffic and forth , sh should we just make some  if there 's parking  who cares .  and if he has seen it already or not and forth ,   and discourse is something that should we make a keith note here ? that comes from keith . just we don't forget .  have to get used to this .  whoops .    but and it there 's a also a split if you loo if you blow this up and look at it in more detail there 's something that comes from the discourse in terms of what was actually just said what 's the utterance go giving us and then what 's the discourse history give us . that 's two things then .   but is th is this picture that 's emerging here just my wish that you have noticed already for symmetry or is it that we get for each decision on the very bottom we get the sub e , sub d , sub u and sub o "" for "" ontology "" meta node but it might just could be this but this wou would be though that , we only have at most four at the moment arrows going f to each of the bottom decisions . and four you we can handle . it 's too much ? right , true . but four didn't we decide that all of these had true or false ? is it 's four for endpoint ? no it 's sh down here , but this one only has two . want to view that ,  c sl  r we just need to in order to get some closure on this figure out how we 're gonna get this picture completely messy .   it 's probably pretty easy do it to do it in html , just  have each of these thing each of the end belief nets be a page and then you click on the thing and then li consider that it 's respective , but  rover , the rover decision . rover . all of their outputs combined to make a decision .   and that one outcome , that 's it 's x one voted for a x two voted for v and forth ?  that 's the outcome . that 's one .  ","we have the user interest is a vector of five hundred values , go there or not is a good one . ",
Bed010.A," right . are you going to p pay any attention to the relative position of the direction relative to the speaker ? there are some differences between hebrew and english . we can say park in front of the car "" as you come beh you drive behind the car . in hebrew it means "" park behind the car "" , because to follow the car is defined as it faces you . while in english , front of the car is the absolute front of the car .  right . right . i is german closer to e to e i don't think it 's related to syntax , though , it may be entirely different .   that but it wasn't was right .  right . what do "" reference frames "" ?   right  right . i 'd love to see it if you have a copy  here great . right . they doubled the end of this right . the ext the extension , right . the extension of your hand , right . the  it 's not exactly the th same thing , but s it 's getting close to that . i once i was playing with those devices that allow you to manipulate objects when it 's dangerous to get close ? you can insert your hand something and there 's a correspondence between played with it . after a while , you don't feel the difference anymore . it 's very you stop back and suddenly it goes away and you have to work again to recapture it , but  it 's possible   right i may have to go to switzerland for in june or beginning of july for between two weeks and four weeks , but after that or before that . right . be actu actually i 'm invited to do some consulting with a bank in geneva which has an affiliation with a research institute in geneva , which i forgot the name of .    great . right . great . i 'll let s i 'll send you email .   right . great ,  ",,
Bed010.B,"     am spartacus . "" verstehe .      n , n , v   alright .     i noticed that that some of the examples they had , had non english word orders and on , and then all that good  like .  i still don't really understand e like we say , i still don't exactly understand the information flow in this thing , or what the modules are and on . like just that such and such module decides that it wants to achieve the goal of greeting the user , and then magically it how does it know which syntactic structure to pull out , and all that ? r   soon .  that 's fine .  and i remember one thing that came up in the talk last wednesday . was this , he talked about the idea of like , he was talking about these lexicalized tree adjoining grammars where you for each word you , for each lexical item , the lexical entry says what all the trees are that it can appear in . and that 's not v that 's the opposite of constructional . that 's , that 's hpsg or whatever .    right . make our fit to that .    right .    right . right ,      got it .  right ,   mean , that like the meetings far that i 've been at have been been geared towards this demo , and then that 's going to go away pretty soon .  and then we 'll shift gears a fairly substantially ,     right .          right .  it 's alright .    how do you go about this process of deciding what these connections are ? i know that there 's an issue of how to weight the different things too , and right ? do you just guess and see if it  right .   alright .    that 's right . and speaking of data , are there i could swore i could swear i saw it sitting on someone 's desk at some point , but is there a transcript of any of the , initial interactions of people with the system ? cuz i 'm still itching to look at what look at the and see what people are saying .  u found the the audio of some of those , and it sounded like i didn't want to trudge through that , it was just strange , but .     wanted to , s like mention as an issue , last meeting i wasn't here because i went to a linguistics colloquium on the fictive motion and that was pretty interesting and seems to me that will fairly be of relevance to to what we 're doing here because people are likely to give descriptions like "" what 's that thing right where you start to go up the hill , "" like that , meaning a few feet up the hill or whatever from some reference point and all that mean , i 'm in terms of people trying to state locations or , all that this is gonna be very relevant .  now that was the talk was about english versus japanese , which the japanese doesn't affect us directly , except that , some of the construction he 'd what he talked about was that in english we say things like th "" your bike is parked across the street "" and we use these prepositional phrases , "" if you were to move across the street you would be at the bike "" , but in japanese the more conventionalized tendency is to use a description of "" where one has crossed to the river , there is a tree "" . and you can actually say things like , "" there 's a tree where one has crossed the river , but no one has ever crossed the river "" , like that . the idea is that this really is that 's supposed show that 's it 's really fictive and on . but but that construction is also used in english , like "" right where you start to go up the hill "" , or "" just when you get off the train "" , like that to to indicate where something is . we 'll have to think about       right , the canonical direction of motion determines where the front is .  right .    it seems to me that you can get both in english depending o in front of the car "" could like , here 's the car sideways to me in between me and the car 's in front of the car , or whatever . i could see that , but but anyway , this was a very good talk on those kinds of issues and on .  alright !    the origin .   i never heard it .     right . you can actually say things like , "" it 's behind the tree from me "" like that , in certain circumstances in english , right ? as from where i 'm standing it would appear that ""     me too .      circuits . that 's    what 's going on at the end of the tool ,  what 's going on at the end of the tool , or whatever .     that 's      alright . i   right .   be of use to someone who 's trying to do this , right ?   i see . right .  good to know .  alright . cuz i don't have to implement anything . right .     just a drive up . ca chuk ! there you go . exactly . drive through ,       in switzerland .     pretty soon .  right .   quite relevant ,     i 'm actually probably going to be in contact with her pretty soon anyway because of various of us students were going to have a reading group about precisely that thing over the summer ,   right , no faculty ! right . it 's as if we didn't tell anyone right . ","how do you go about this process of deciding what these connections are ? cuz i 'm still itching to look at what look at the and see what people are saying . because i went to a linguistics colloquium on the fictive motion seems to me that will fairly be of relevance to to what we 're doing here be of use to someone who 's trying to do this , i 'm actually probably going to be in contact with her pretty soon anyway because of various of us students were going to have a reading group about precisely that thing over the summer , ",
Bed010.C,"alright . good .  let 's get started . nancy said she 's coming and that means she will be . my suggestion is that robert and johno give us a report on last week 's adventures to start . everybody knows there were these guys f from heidelber actually from dfki part of the german smartkom project , who were here for the week and , got a lot done . it doesn't know "" i "" . alright . it might be worth , keith , you looking at this ,   i thi  it 's not worth going over in the group , but when you get free and you have the time either robert or johno or walk you through it . and you can ask all the questions about how this all fits together . it 's eee messy but once you understand it . it 's there 's nothing really complicated about it . right . right . now , we 're not committed for our research to do any of those things . we are committed for our funding .  to to n no , to just get the dem get the demos they need .  between us all we have t to get th the demos they need . if it turns out we can also give them lots more than that by , tapping into other things we do , that 's great . but i it turns out not to be in an any of the contracts and , s deliberately . the reason i 'd like you to understand what 's going on in this demo system is not because it 's important to the research . it 's just for closure . that if we come up with a question of "" could we fit this deeper in there ? "" what the hell we 're talking about fitting in . it 's just , in the sam same actually with the rest of us we just need to really understand what 's there . is there anything we can make use of ? is there anything we can give back , beyond th the minimum requirements ? but none of that has a short time fuse . th the demo requirements for this fall are taken care of as of later this week and then it 's probably fifteen months until there 's another serious demo requirement . that doesn't mean we don't think about it for fifteen months , but it means we can not think about it for six months . the plan for this summer really is to step back from the applied project , keep the d keep the context open , but actually go after the basic issues . and , the idea is there 's this other subgroup that 's worrying about formalizing the nota getting a notation . but in parallel with that , the hope is tha in particularly you will work on constructions in english ge and german for this domain , but y not worry about parsing them or fitting them into smartkom or any of the other anything lik any other constraints for the time being . it 's hard enough to get it semantically and syntactically right and then and get the constructions in their form and and , i don i don't want you f feeling that you have to somehow meet all these other constraints . and similarly with the parsing , we 're gonna worry about parsing the general case construction parser for general constructions . and , if we need a cut down version for something , or whatever , we 'll worry about that later . 'd like to , for the summer turn into science mode . and i assume that 's also , your plan as right .   but we 're swit right .    c sh we could set that up as actually an institute wide thing ? just give a talk in the big room , and peo people 's going on ? when you 're ready ? mean , that 's the thing that 's the level at which we can just li invite everybody and say "" this is a project that we 've been working on and here 's a demo version of it "" and like that .  but any that e it 's clear , then , actually , roughly starting let 's say , nex next meeting , cuz this meeting we have one other thing to tie up besides the trip report . but starting next meeting we want to flip into this mode where there are a lot of issues , what 's the ontology look like , what do the constructions look like , what 's the execution engine look like , lots of things . but , more focused on an idealized version than just getting the demo out . now before we do that , let 's get back in  but , it 's still , useful for you to understand the demo version enough , that you can see what it is that it might eventually get retro fitted into and johno 's already done that , looked at the dem the looked at the smartkom the parser , and that anyway . the trip the report on these the last we interrupted you guys telling us about what happened last week . you 're done , then . anyth any other repo visit reports stories ? we we now the landscape is like . and we just push on and do what we need to do . and one of the things we need to do is the and this is relatively tight tightly constrained , is to finish up this belief net  and i was going to switch to start talking about that unless there 're m other more general questions . here 's where we are on the belief net as far as i understand it . ","we are committed for our funding . n no , to just get the dem get the demos they need . if it turns out we can also give them lots more than that by , tapping into other things we do , that 's great . th the demo requirements for this fall are taken care of as of later this week and then it 's probably fifteen months until there 's another serious demo requirement . the idea is there 's this other subgroup that 's worrying about formalizing the nota getting a notation . but in parallel with that , the hope is tha in particularly you will work on constructions in english ge and german for this domain , but y not worry about parsing them or fitting them into smartkom or any of the other anything lik any other constraints for the time being . 'd like to , for the summer turn into science mode . c sh we could set that up as actually an institute wide thing ? there are a lot of issues , what 's the ontology look like , what do the constructions look like , what 's the execution engine look like , but , more focused on an idealized version than just getting the demo out . and one of the things we need to do is the and this is relatively tight tightly constrained , is to finish up this belief net ","This is the first of two working demos required for the project. In parallel, another team is working on formalisation and notation. Further than that, there are no restrictions on the focus of the research or its possible applications. "
Bed010.C,"going back two weeks ago robert had laid out this belief net , missing only the connections . right ? that is he 'd put all th all the dots down , and we went through this , and , more or less convinced ourselves that at least the vast majority of the nodes that we needed for the demo level we were thinking of , were in there . we may run across one or two more . but the connections weren't . bhaskara and i went off and looked at some technical questions about were certain operations legitimate belief net computations and was there some known problem with them or had someone already solved how to do this and and bhaskara tracked that down . the answer seems to be "" no , no one has done it , but yes it 's a perfectly reasonable thing to do if that 's what you set out to do "" . and , the current state of things is that , again , starting now , we 'd like to actually get a running belief net for this particular subdomain done in the next few weeks . bhaskara is switching projects as of the first of june , and he 's gonna leave us an inheritance , which is a hopefully a belief net that does these things . and there 're two aspects to it , one of which is , technical , getting the coding right , and making it run , and like that . and the other is the actual semantics . what all what are the considerations and how and what are the ways in which they relate . he doe h he doesn't need help from this group on the technical aspects or if he does we 'll do that separately . but in terms of what are the decisions and like that , that 's something that we all have to work out . is that right ? that 's both you guys ' understanding of where we are ?  mean , that 's a separate problem . we do in the long run wanna do better visualization and all that that 's separable ,   right . not at this point . right . we can p if it 's if we can pay if it 's paying a thousand dollars we can do that .  don't view free as a absolute constraint .  and you can ask kevin . hugin , that 's free . it may be free to academics . like i don't know . i have a co i have a copy that i l i downloaded . at one point it was free . but yo i noticed people do use hugin  hugin . and bhaskara can give you a pointer . then , in any case , but paying a lit if i if it 's probably for university , it 's gonna be real cheap anyway . but if it 's fifty thousand dollars we aren't gonna do it . i 'm mean , we have no need for that . no , he 's not gonna do that . doesn't matter . and this is not a crisis that you do , e everybody who 's a student should , do their work , get their c courses all in good shape and then we 'll dig d dig down on this . right . there 're two different things you do . one is you design and the other is you learn .  what we 're gonna do initially is do design , and , i if you will , guess .  that is use your best knowledge of the domain to hypothesize what the dependencies are and if it 's done right , and if you have data then , there are techniques for learning the numbers given the structure and there are even techniques for learning the structure , although that takes a lot more data , and it 's not as @ @ and forth and on .  but for the limited amount of we have for this particular exercise we 'll just design it .   make yourself a note . and , keith would like the german as as the english , whatever you guys can get . the y your native language , right ? you remember that one . he 'll get you some data .   while we 're still at this top level , anything else that we oughta talk about today ? right .   how much is that used in german ?  where is this huge project ?  that may be another thing that keith wants to look at .  no , it 's not .     great . no , i 've not seen that . that would be "" origin "" in english , right ? alright .   it sounds like it , doesn't it ,    i see this is getting into ami 's thing . he 's very interested in that .   why don't you just put it on the web page ? there 's this edu right ? or a link to it . just just put a link on .  there something that i didn't know until about a week ago or is there are separate brain areas for things within reach , and things that are out of reach . there 's all this linguistic about near and far , or yon and forth . this is all this is there 's this linguistic facts . but the here 's the way the findings go . that , they do mri , and if you 're got something within reach then there 's one of your areas lights up , and if something 's out of reach different one . but here 's the amazing result , they say . you get someone with a deficit that they have a perfectly normal ability at distance things . the s typical task is subdivision . ","and we went through this , and , more or less convinced ourselves that at least the vast majority of the nodes that we needed for the demo level we were thinking of , were in there . bhaskara and i went off and looked at some technical questions about were certain operations legitimate belief net computations and was there some known problem with them or had someone already solved how to do this and the answer seems to be "" no , no one has done it , but yes it 's a perfectly reasonable thing to do if that 's what you set out to do "" . and there 're two aspects to it , one of which is , technical , getting the coding right , and making it run , and like that . and the other is the actual semantics . what all what are the considerations and how and what are the ways in which they relate . we do in the long run wanna do better visualization and all that one is you design and the other is you learn . what we 're gonna do initially is do design , and , i if you will , guess . if it 's done right , and if you have data then , there are techniques for learning the numbers given the structure but for the limited amount of we have for this particular exercise we 'll just design it . there something that i didn't know until about a week ago or is there are separate brain areas for things within reach , and things that are out of reach . ",The majority of the nodes are already there. This leaves the dependencies between them and the rules of computation to be set. The latter is also reflected in neuro-physiological data. 
Bed010.C,"there 's a line on the wall over there , and you give them a laser pointer , and you say , "" where 's the midpoint ? "" and they do fine . if you give them the line , and they have to touch it , they can't . there 's just that part of the brain isn't functioning , they can't do that . here 's the real experiment . the same thing on the wall , you give them a laser , "" where is it ? "" , they do it . give them a stick , long stick , and say "" do it "" , they can't do it . there 's a remapping of distant space into nearby space . it 's not within reach and you use the within reach mechanism . 'll d i 'll dig you up this reference . and this doe this is , first of all , it explains something that i 've always wondered about and i 'll do this test on you guys as  how i have had an experience , not often , but a certain number of times , when , i 'm working with a tool , a screwdriver for a long time , i start feeling the tip directly . not indirectly , but you actually can feel the tip . and people who are accomplished violinists and like that , claim they also have this thing where you get a direct sensation of , physical sensation , of the end affector .   within   right . have you hav y h had this ? it feels like your as if your neurons had extended themselves out to this tool , and you 're feeling forces on it and forth and you deal directly with it . right ,   right . right , anyway , this was the first actual experimental evidence i 'd seen that was consistent with this anecdotal and it makes a lovely def story about why languages make this distinction . there are behavioral differences too . things you can reach are really quite different than things you can't . but there seems to be an actu really deep embodied neural difference . and i this is , in addition to the e exactly . in addition to e ego and allocentric which appear all over the place , you also have this proximal distal thing which is very deeply embedded . s  there 's been a lot of behavioral things o on this , but that was the first neur neuro physiological thing i saw . anyway we 'll look at this . and . all of these issues now are now starting to come up . now we 're now done with demos . we 're starting to do science , right ? and these issues about reference , and spatial reference , discourse reference , all this deixis which is part of what you were talking about , all of this is coming up essentially starting now . we gotta do all this . there 's that . and then there 's also a set of system things that come up . we 're not using their system . that means we need our system . "" right ? it follows . and in addition to the business about just getting the linguistics right , and the formalism and we 're actually gonna build something and johno is point person on the parser , analyzer , whatever that is , and we 're gonna start on that in parallel with the the grammar but to do that we 're gonna need to make some decisions like ontology , and this is another thing where we 're gonna , have to get involved and make s relatively early make some decisions on "" is there an ontology api that "" there 's a standard way of getting things from ontologies and we build the parser and around that , or is there a particular ontology that we 're gonna standardize on , and if is there something that we can use there . i does either the smartkom project or one of the projects at eml have something that we can just p pull out , for that . there are gonna be some things like that , which are not science but system . but we aren't gonna ignore those cuz we 're not only going the plan is not only to lay out this thing , but to actually build some of it . and how much we build , and forth . part of it , if it works right , is wh it looks like we 're now in a position that the construction analyzer that we want for this applied project can be the same as the construction analyzer that nancy needs for the child language modeling . it 's always been out of phase but it now seems that there 's a good shot at that . we 've talked about it , and the hope is that we can make these things the same thing , and it 's only w in both cases it 's only one piece of a bigger system . but it would be if that piece were exactly the same piece . it was just this construction analyzer . and we think we have a shot at that . the for  to come full circle on that , this formalization task ,  is trying to get the formalism into a shape where it can actually d where it actually is covers the whole range of things . and the thing that got mark into the worst trouble is he had a very ambitious thing he was trying to do , and he insisted on trying to do it with a limited set of mechanisms . it turned out , inherently not to cover the space . and it just it was just terribly frustrating for him , ","in addition to e ego and allocentric which appear all over the place , you also have this proximal distal thing which is very deeply embedded . and these issues about reference , and spatial reference , discourse reference , all this deixis which is part of what you were talking about , we gotta do all this . and then there 's also a set of system things that come up . we 're not using their system . that means we need our system . "" and in addition to the business about just getting the linguistics right , and the formalism and we 're actually gonna build something and we 're gonna start on that in parallel with the the grammar but to do that we 're gonna need to make some decisions like ontology , i does either the smartkom project or one of the projects at eml have something that we can just p pull out , for that . cuz we 're not only going the plan is not only to lay out this thing , but to actually build some of it . it looks like we 're now in a position that the construction analyzer that we want for this applied project can be the same as the construction analyzer that nancy needs for the child language modeling . to come full circle on that , this formalization task , is trying to get the formalism into a shape where it can actually ","The variety of linguistic conventions seem to develop around an ego/allo-centric and a proximal/distal paradigm. For example, issues like spatial descriptions could be investigated. Since the whole system is going to be re-designed, there are major decisions to be taken regarding the parser and the ontology, as well as what can be re-used from past EML projects. "
Bed010.C,"and he seemed fully committed to both sides of this i irreconcilable thing . and . johno is much more pragmatic .  is this is true , is it not ?  there 's deep , really deep , emotional commitment to a certain theory being complete . we it hasn't it certainly hasn't been observed , in any case . now , you do , but that 's for exactly right . exactly . right . why a actually , you do but , th the thing you have to im implement is small that within that ,  and it 's a and still , get something done . but to try to do something upscale and purist particularly if what you 're purist about doesn't actually work , is real hard .  and then the other thing is while we 're doing this robert 's gonna pick a piece of this space ,  for his absentee thesis . you all know that you can just , in germany almost just send in your thesis . right .  it costs a lot . the amount you put in your credit card and as but , but anyway , that 's also gotta be worked out , hopefully over the next few weeks , that it becomes clear what piece robert wants to jump into . and , while we 're at this level , there 's at least one new doctoral student in computer science who will be joining the project , either next week or the first of august , depending on the blandishments of microsoft . de and her name is eva . it really is . nobody believed th that  no , first year coming . she 's now out here she 's moved , and she 'll be a student as of then . and probably she 'll pick up from you on the belief net sh she 'll be chasing you down and like that .  against all traditions . and actually i talked today to a undergraduate who wants to do an honors thesis on this .  no , interestingly enough . some of th some of them , anyway , but she 's another one of these ones with a three point nine average and forth and on . i 've give i 've given her some things to read . we 'll see how this goes . there 's yet another one of the incoming first year graduate students who 's expressed interest , we 'll see how that goes .  anyway , as far as this group goes , it 's certainly worth continuing for the next few weeks to get closure on the belief net and the ideas that are involved in that , and what are th what are the concepts . we 'll see whether it 's gonna make sense to have this be separate from the other bigger effort with the formalization or not , i 'm not it partly depends on w what your thesis turns out to be and how that goes . s we 'll see . and then , ami , you can decide , how much time you wanna put into it and it 's beginning to take shap shape , and , you will find that if you want to look technically at some of the your traditional questions in this light , keith , who 's buil building constructions , will be quite happy to see what , you envision as the issues and the problems and how they might get reflected in constructions . i suspect that 's right .  fine . and , if it 's useful we can probably arrange for you to drop by and visit either at heidelberg or at the german ai center , while you 're in the neighborhood .   e o do y we 're connected to there 's a very significant connection between we 'll go through this , icsi and epfl , which is the , it 's the fr ge germany 's got two big technical institutes . there 's one in zurich , e t and then there 's one , the french speaking one , in lausanne ,  which is p f l . find out who they are associated with in geneva . probably we 're connected to them .   and anyway we c we can m undoubtedly get ami to give a talk at eml like that . while he 's in a lot of interest . actually , either place , dfki or and if there is a book , that you 'll be building up some audience for it . and you 'll get feedback from these guys . cuz they 've actually these dfki guys have done as much as anyone over the last decade in trying to build them . we 'll set that up .  unless we wanna start digging into the the belief net and the decisions now , which would be fine , it 's probably  how about if you two guys between now and next week come up with something that is partially proposal , and partially questions , saying "" here 's what we think we understand , here are the things we think we don't understand "" . and that we as a group will try to finish it . what i 'd like to do is shoot f for finishing all this next monday .  "" these are the decisions "" i don't think we 're gonna get lots more information . it 's a design problem . we  and let 's come up with a first cut at what this should look like . and then finish it up . does that make sense ?  is it a take home final ? who 's doing this ? figured . that would have been i my guess . right . but anyway , guess that 's right . right . let 's do this , and then we there 's gonna be some separate co ","and , while we 're at this level , there 's at least one new doctoral student in computer science who will be joining the project , either next week or the first of august , depending on the blandishments of microsoft . and actually i talked today to a undergraduate who wants to do an honors thesis on this . there 's yet another one of the incoming first year graduate students who 's expressed interest , as far as this group goes , it 's certainly worth continuing for the next few weeks to get closure on the belief net and the ideas that are involved in that , and what are th what are the concepts . and anyway we c we can m undoubtedly get ami to give a talk at eml like that . while he 's in a lot of interest . actually , either place , dfki or how about if you two guys between now and next week come up with something that is partially proposal , and partially questions , ","Finally, more ideas are expected to come from students and their research. From an engineering perspective, the belief-net for the AVE task should be completed within a few weeks. "
Bed010.C,"these guys are talking , we have a group on the formalization , nancy and johno and i are gonna talk about parsers . there 're various kinds of nothing gets done even in a meeting of seven people , right ? two or three people is the size in which actual work gets done . we 'll do that . great . the other thing we wanna do is catch up with ellen and see what she 's doing because the image schemas are going to be an important pa we want those , right ? and we want them formalized and like that . let me make a note to do that . right ! right right ! that 's great ! i shweta mentioned that , although she said it 's a secret . th the faculty aren't supposed to know . but i 'm sufficiently clueless that i count as a ",,
Bed010.D,"how many batteries do you go through ? "" i am sm i am smarticus "" is what it 's saying . i gue  bu i the way the the dialogue manager works is it dumps out what it wants to know , or what it wants to tell the person , to a er in xml and there 's a conversion system for different to go from xml to something else . and th the knowledge base for the system , that generates the syntasti syntactic structures for the ge generation is in a lisp like the knowledge base is in a lisp like form . and then the thing that actually builds these syntactic structures is something based on prolog . you have a a goal and it , says "" 'm gonna try to do the greet the person goal , it just starts it binds some variables and it just decides to , do some subscold . it just means "" build the tree . "" and then it passes the tree onto , the ge the generation module . we  the syntax trees are very simple . it 's like most of the sentences in one tree , and instead of , breaking down to small units and building back up , they took the sentences , and cut them in half , or into thirds like that , and made trees out of those . and tilman wrote a little tool that you could take lisp notation and generate an xml , tree . s what do ca structure from the lisp . and you just say , "" noun goes to "" , er , nah , i don't re i 've never been good at those . there 's like the vp goes to n and those things in lisp , and it will generate for you . why i had i did need to chan generate different trees than the german ones , mainly because like the gerund in german is automatically taken care of with just a regular verb , 'd have to add "" am walking , "" or i 'd have to add a little stem for the "" am "" , when i build the built the tree .  tilman s how to do it ? you should probably move the microphone closer to your face . there 's like a little the twisty thing , you can move it with . wa  to some de what part of th the smartkom  i i did look into that , in terms of , exploding the nodes out and down ag javabayes does not support that . imagine a way of hacking at the code to do that . it 'd probably take two weeks or to actually go through and do it , and i went through all the other packages on murph kevin murphy 's page , and i couldn't find the necessary mix of free and with the gui and , with this thing that we want .  then i 'll go back and look at the ones on the list that  how do you spell that ?   yes . no . no sir . nnn . this i 've i have projects , but then the my prof professor of one of my classes also wa has a final that he 's giving us . and he 's giving us five days to do it which means it going to be hard .  aikin , alex , the seventeenth will definitely be the last day , like it or not for me .  hi wednesday 's much better for me , bhaskara . ","why i had i did need to chan generate different trees than the german ones , i did look into that , in terms of , exploding the nodes out and down ag javabayes does not support that . it 'd probably take two weeks or to actually go through and do it , ",
Bed010.E,"too .  the we got to the point where we can now speak into the smartkom system , and it 'll go all the way through and then say something like "" roman numeral one , am smarticus . "" it actually says , "" roemisch einz , am smarticus , "" which means it 's just using a german sythesis module for english sentences .  the the sythesis is just a question of hopefully it 's just a question of exchanging a couple of files , once we have them . and , it 's not going to be a problem because we decided to stick to the called concept to speech approach . 'm i 'm going backwards now , synthesis "" is where you make this make these sounds , and "" concept to speech "" is feeding into this synthesis module giving it what needs to be said , and the whole syntactic structure it can pronounce things better , presumably . then , just with text to speech . and , johno learned how to write xml tags . and did write the tree adjoining grammar for some sentences . no , right ? for a couple but that that out of the twelve possible utterances that the german system can do , we 've already written the syntax trees for three or four . and because we 're sticking to that structure , the synthesis module doesn't need to be changed . all that f fancy and the texas speech version of it , which is actually the simpler version , is gonna be done in october which is much too late for us .  this way we worked around that . the , the system , can show you the system . i actually want , at least , you should be able to start it on your own . if you wanna play around with it , in th in the future . right now it 's brittle and you need to ch start it up and then make ts twenty changes on seventeen modules before they actually can stomach it , anything . and send in a couple of side queries on some dummy center set up program that it actually works because it 's designed for this seevit thing , where you have the gestural recognition running with this s siemens virtual touch screen , which we don't have here . and we 're doing it via mouse , but the whole system was designed to work with this thing and it was a lot of engineering no science in there whatsoever , but it 's working now , and that 's the good news . everything else actually did prove to be language independent except for the parsing and the generation . you have to switch it on . no . right . it 's it 's got . what is a good idea that show to anyone who 's interested , we can even make a an internal demo , and i show you what i do , i speak into it and you hear it talk , and walk f through the information . this is like in half hour or forty five minutes . just fun . and you when somebody on the streets com comes up to you and asks you what is smartkom you can , give a sensible answer .   we do wanna have all the bugs out b where you have to pipe in extra xml messages from left and right before you 're   makes sense . it was just amazing to see how instable the whole thing is , and if you just take the and i g i got the feeling that we are the only ones right now who have a running system . i don't the guys in kaiserslautern have running because e the version that is , the full version that 's on the server d does not work . and you need to do a lot of to make it work . and it 's and even tilman and ralf said "" there never was a really working version that did it without th all the shortcuts that they built in for the october @ @ version "" . we 're actually ahead of the system gruppe by now , the system the integration group . and it was , it was fun to some extent , but the the outcome that is scientific interest is that both ralf and tilman i know that they enjoyed it here , and they r they liked , a lot of the they saw here , what we have been thinking about , and they 're more than willing to cooperate , by all means . and part of my responsibility is to use our internal "" group ware "" server at eml , make that open to all of us and them , that whatever we discuss in terms of parsing and generating and constructions w we put it in there and they put what they do in there and we can even get some overlap , get some synergy out of that . and the , if i find someone at in eml that is interested in that , may even think that we could look take constructions and generate from them because the tree adjoining grammars that tilman is using is as you said nothing but a mathematical formalism . and you can just do anything with it , whether it 's syntactic trees , h p s g like or whether it 's construction . if you ever get to the generation side of constructing things and there might be something of interest there , but in the moment we 're definitely focused on the understanding , pipeline .  we had decided no , we didn't decide . we wanted to look into getting it , the visualization , a bit clearer , ","the we got to the point where we can now speak into the smartkom system , and it 'll go all the way through and then say something like "" roman numeral one , am smarticus . "" which means it 's just using a german sythesis module for english sentences . and "" concept to speech "" is feeding into this synthesis module giving it what needs to be said , and the whole syntactic structure it can pronounce things better , presumably . then , just with text to speech . and did write the tree adjoining grammar for some sentences . but that that out of the twelve possible utterances that the german system can do , we 've already written the syntax trees for three or four . right now it 's brittle and you need to ch start it up and then make ts twenty changes on seventeen modules before they actually can stomach it , anything . because it 's designed for this seevit thing , where you have the gestural recognition running with this s siemens virtual touch screen , which we don't have here . but it 's working now , we can even make a an internal demo ,  we do wanna have all the bugs out b where you have to pipe in extra xml messages from left and right before you 're it was just amazing to see how instable the whole thing is , and i g i got the feeling that we are the only ones right now who have a running system . e the version that is , the full version that 's on the server d does not work . and part of my responsibility is to use our internal "" group ware "" server at eml , make that open to all of us and them , that whatever we discuss in terms of parsing and generating and constructions w we put it in there and they put what they do in there and we can even get some overlap , get some synergy out of that . because the tree adjoining grammars that tilman is using is as you said nothing but a mathematical formalism . and you can just do anything with it , whether it 's syntactic trees , h p s g like or whether it 's construction . if you ever get to the generation side of constructing things and there might be something of interest there , ","The system is still buggy and unstable, but it will soon be ready for a demonstration. "
Bed010.E,"but if we do it , paper version of all the nodes and then the connections between them , that should suffice .  but but i also s would suggest not to d spend two weeks in changing the javabayes code . i will send you a pointer to a java applet that does that , it 's fish eye . you have a node , and you click on it , and it shows you all the connections , and then if you click on something else that moves away , that goes into the middle . and there is an easy way of interfacing those two . if that doesn't work , it 's not a problem we need to solve right now . what i 'm what my job is , i will , give you the input in terms of the internal structure . node by node , like this ? or should i collect it all and  and you 're gonna be around ? t again , always tuesdays and thursdays afternoon ish ? as usual ? or will that change ?   that 's   no , that 's good . that means i have i h spend this week doing it .  it 's  fo hopefully as time passes we 'll get more and more data from heidelberg and from people actually using it and but this is the long run . but to solve our problems ag mediocre design will do in the beginning . the german . german .   that 's important ,  we probably will not get those to describe because they were trial runs . but that 's th but we have data in english and german already .  transcribed . i will send you that .  ho how was your thingy . the wa i was on a on a different sidetrack . the deep map project which is undergoing some renovation at the moment , but this is a three language project : german , english , japanese . and we have a i have taken care that we have the japanese generation and and looked into spatial description . we can generate spatial descriptions , how to get from a to b . and information on objects , in german , english , and japanese . and there is a huge project on spatial descriptions differences in spatial descriptions . if yo if you 're interested in that , how , it does go d all the way down to the conceptual level to some extent .   it 's kleist . it 's the bielefeld generation of spatial descriptions and whatever . but we should leave japanese constructions outside of the scope for now , but definitely it 's interesting to look at cross the bordered there .  intrinsic ,    did you ever get to look at the rou paper that i sent you on the on that problem in english and german ? carroll , ninety three . i there is a study on the differences between english and german on exactly that problem . it 's they actually say "" the monkey in front of the car , where 's the monkey ? "" and , they found statistically very significant differences in english and german ,  it might be , since there are only a finite number of ways of doing it , that german might be more like hebrew in that respect . the solution they proposed was that it was due to syntactic factors . that syntactic facto factors do play a role there , wh whether you 're more likely , to develop choices that lead you towards using intrinsic versus extrinsic reference frames . also give you a pointer to a paper of mine which is the ultimate taxonomy of reference frames .  i 'm the only person in the world who actually knows how it works . not really . it 's called a it 's spatial reference frames . you actually have only if you wanna have a this is usually i should there should be an "" l "" , though . actually you have only have two choices . you can either do a two point or a three point which is you 're familiar with th with the "" origo "" ? where that 's the center "" origo "" is the center of the f frame of reference . and then you have the reference object and the object to be localized .  in some cases the origo is the same as the reference object . "" origo "" is a terminus technikus . in that sense , that 's even used in the english literature . "" origo . "" and this video tape is in front of me . i 'm the origo and i 'm also the reference object . those are two point . and three point relations is if something has an intrinsic front side like this chair then your f shoe is behind the chair . and , reference object and no , from my point of view your shoe is left of the chair .    and then here you on this scale , you have it either be ego or allocentric . and that 's it . egocentric two point , egocentric three point , or you can have allocentric . "" as seen from the church , the town hall is right of that fire station "" . aa it 's hardly ever used but it 's w   it 's or just  it 's also all on my home page at eml . it 's called "" an anatomy of a spatial description "" . but i 'll send that link .   this is more proximal distal . dan montello he does the th the cognitive map world , down in santa barbara . and he always talks about these he already i probably most likely without knowing this evidence is talking about these small scale spaces that you can manipulate versus large scale environmental spaces . ","i also s would suggest not to d spend two weeks in changing the javabayes code . i will send you a pointer to a java applet that does that , but that 's th but we have data in english and german already . transcribed . i will send you that . and there is a huge project on spatial descriptions differences in spatial descriptions . it 's kleist . carroll , ninety three . i there is a study on the differences between english and german on exactly that problem . also give you a pointer to a paper of mine which is the ultimate taxonomy of reference frames . on this scale , you have it either be ego or allocentric . it 's called "" an anatomy of a spatial description "" . ",The variety of linguistic conventions seem to develop around an ego/allo-centric and a proximal/distal paradigm. 
Bed010.E,"the th there 's a drive in thesis sh joint over in saarbruecken . document .  the one you gave here a couple of weeks ago would be of interest there , too . i tho it 's probably better if i come next week with the version o point nine of the structure . and the sem semester will be over next week but then you have projects for one more week to come ? same with you ? no .   ",,
Bed010.F,"why this was like looks a little bit like reichenbach for time . it 's a lot like it .  because it 's within reach now ?  w what does it feel like ? you don't have a hidden purist streak ?  just checking . i have a problem , then . it 's whether i do depends on whether i 'm talking to him or him probably . which meeting i 'm in . it 's to be purist within that context . yes , good . yay . it had to be a joke , of your part , like "" johno made it up , i 'm "" someone from the class ? we always get these people who are not in the class , who it 's interesting . ",,
Bed010.G,"is there like a latest version of the belief net of the proposed belief net ? like like   that should be fine .  the one that people seem to use is hugin or whatever ? how exp i don't think it 's is it free ? because i 've seen it advertised in places it seems to    just any like rough representation of the entire belief net is probably best .   like i c this week have a lot of projects and but after that i will generally be more free . yes , i might be around . and g generally if you email me also be around on other days .  is this person someone who 's in first year this year , or   right .   no , 'll be done everything by this by the end of this week .  ",the one that people seem to use is hugin or whatever ? ,
Bed011.A,"go ahead and read .   not that much you didn't .     is like "" biking there "" part of like "" driving there "" , or ? ",,
Bed011.B,"robert , do you have any way to turn off your screensaver on there that it 's not going off every it seems to have about at two minute   got it .   this is a fictional system      don't exactly understand like we 're trying to limit the detail of our ontology or types of places that someone could go , right ? but who is it that has to care about this , or what component of the system ?   we would rather just ask have a bunch of people talk about the zoo , and assume that will that the constructions that they use there will give us everything we need to know about these zoo , castle , whatever type things , these bigger places . and that way you get the speech data of people saying "" zoo "" over and over again or whatever too .     it seems that  off the top of my head it kinda seems like you would probably just want , richer data , more complex going on , people trying to do more complex sets of things . if our goal is to really be able to handle a whole bunch of different then throwing harder situations at people will get them to do more linguistic more interesting linguistic but 'm not really because i don't fully understand like what our choices are of ways to do this here yet . i started to listen to one and it was just like , depressing . 'd just listen to the beginning part and the person was just reading off her script and .      right .  it i am just today , next couple days gonna start really diving into this data . i 've looked at one of the files one of these l y you gave me those dozens of files and i looked at one of them which was about ten sentences , found fifteen , twenty different construction types that we would have to look for and on and like , "" alright , let 's start here . "" haven't really gone into the , looked of the that 's going on . don't really right , once i start doing that i 'll have more to say about this thing .   i did scan it at first and noticed that , and then looked in detail at one of them . but i noticed that , too .   rather than having zoo and castle .  good luck .   that 's right .  what 's this idea of "" next tour "" ?    or   this tour is just like th the idea of current s round of touristness or whatever ,   got it . got it .     just to be clear .  you just spend the whole time at u fleku ri keine ahnung  not that i know of actually . business is supposed to be it like professional type right , like that ?      like my father is about to travel to prague . he 'll be there for two weeks . he is going to he 's there to teach a course at the business school but he also is touring around and he may have some mixture of these things .  mean , does this capture where do you put "" exchange money "" is an errand , right ? but what about like "" go to a movie "" is now entertainment , "" dine out "" is mean right .   right .  "" tourist needs food , badly "" h how much of heidelberg can you get around by public transport ? in terms of the interesting bits . there 's lots of bits where you don't really i 've only ev was there ten years ago , for a day , don't remember , but . like the the tourist y bits is it like     i would lump it with "" walk "" because hills matter . right ?  things like that .   it seems like this would be really hard to guess . on the part of the system . it seems like it you 're talking about rather than having the user decide this you 're supposed t we 're supposed to figure it out ? overrider      right .    you could say "" some "" in there .  dinner .     money is no object .        th there 's a couple of different ways you can interpret these things right ? i want to go there and i don't care if it 's really hard . "" or if you 're an extreme sport person , "" i wanna go there and i insist on it being the hard way . "" right ? assume we 're going for the first interpretation , right ? something like i 'll go th  i 'd li  it 's different from thing to  i      d do eliciting particular constructions ? or do like what kinds of things we want to get people talking about ? semantically speaking ,  right .  from my point of view i 'm trying to care about the syntax ,    right .    got it .     is that roughly the equivalent of what i 've seen in english or is it    same that . got it . like what have i got now ? have what i 'm loo what i those files that you sent me are the user side of some interaction with fey ? is that what it is ? or ? just talking into a box and not hearing anything back .      right , right . by the end of the summer , too . right .  still , pretty formidable actually .  right , right . existence proof , set up the infrastructure ,  sometime , i have to talk to some subset of the people in this group , at least about what constructions i 'm looking for . like just again , looking at this one thing , i saw y things from as general as argument structure constructions . i have to do verb phrase . ","if our goal is to really be able to handle a whole bunch of different then throwing harder situations at people will get them to do more linguistic more interesting linguistic and i looked at one of them which was about ten sentences , found fifteen , twenty different construction types that we would have to look for and on you 're talking about rather than having the user decide this you 're supposed t we 're supposed to figure it out ? those files that you sent me are the user side of some interaction with fey ? ",
Bed011.B,"i have to do unbounded dependencies , which have a variety of constructions in instantiate that . on the other hand i have to have , there 's particular fixed expressions , or semi fixed expressions like "" get "" plus path expression for , "" how d ho how do i get there ? "" , "" how do i get in ? "" , "" how do i get away ? "" and all that there 's a variety of different sorts of constructions and it it 's like anything goes . like  er that 's what   right , exactly . now it w we talked about this before , right . and i me it would be completely out of the question to really do more than , say don't know , ten , over the summer , but but we need to get general view of what things look like ,              but in terms of the s th level of of analysis , these don't necessarily have to be more complex than like the "" out of "" construction in the bcp paper where it 's just like , half a page on each one   for the first cut , that should be fine ,        that 's about six times in this little one here ,      how much does it cost ? i haven't planned to go .  right .    ","and i me it would be completely out of the question to really do more than , say don't know , ten , over the summer , ",
Bed011.C,"now can you give me the remote t ? alright . i 've i it 's not that i didn't try . and told it to stay on forever and ever , but if it 's not plugged in it just doesn't obey my commands . it has a mind . but keep on wiggling . but we 'll just be m working on it at intensity it doesn't happen . we 'll see . should we plunge right into it ? would you like to what i 've tried to do here is list all the decision nodes that we have identified on this side . commented and what they 're about and the properties we may give them . and here are the tasks to be implemented via our data collection . all of these tasks the reading is out of these tasks more or less imply that the user wants to go there , sometime or the other . and analogously here we have our eva intention . and these are the data tasks where w we can assume the person would like to enter , view or just approach the thing . analogously the same on the object information we can see that , we have created these tasks before we came up with our decision nodes there 's a lot of things where we have no analogous tasks , and that may or may not be a problem . we can change the tasks slightly if we feel that we should have data for e for every decision node trying to im implant the intention of going to a place now , going to a place later on the same tour , or trying to plant the intention of going sometime on the next tour , or the next day or whenever . but that might be overdoing it a little . how people phrase different intentions more or less ,   it was too fast plunging in there , because j we have two updates . you can look at this if you want , these are what our subject 's going to have to fill out . any comments still be made and the changes will be put in correspondingly . let me summarize in two sentences , mainly for eva 's benefit , who probably has not heard about the data collection , or have you heard about it ? no . we were gonna put this in front of people . they give us some information on themselves . then they will read task where lots of german words are thrown in between . and and they have to read isolated proper names and these change no , this is not the release form . this is the speaker information form . the release form is over there in that box . and and then they gonna have to f choose from one of these tasks , which are listed here . they pick a couple , say three six six different things they think they would do if they were in heidelberg or traveling someplace and and they have a map . like this . very sketchy , simplified map . and they can take notes on that map . and then they call this computer system that works perfectly , and understands everything . and the comp the computer system sits right in front of you , that 's fey . and she has a way of making this machine talk . she can copy sentences into a window , or type really fast and this machine will use speech synthesis to produce that . if you ask "" how do i get to the castle "" then a m s several seconds later it 'll come out of here "" in order to get to the castle you do ""  and and then after three tasks the system breaks down . and fey comes on the phone as a human operator . and says "" the system broke down but let 's continue . "" and we get the idea what people do when they s think they speak to a machine and what people say when they think they speak to a human , or know , or assume they speak to a human . that 's the data collection . and and fey has some thirty subjects lined up ? something ? and and they 're r ready to roll . and we 're gonna start tomorrow at three ? four ? one ?  around four ish . and we 're still l looking for a room on the sixth floor because they stole away that conference room . behind our backs . but but i it 's happening . david and jane and lila are working on that as we speak .  that was the the data collection in a nutshell . and can report a did this but i also tried to do this if i click on here , isn't this wonderful ? we get to the belief net just focusing on the g go there node . analogously this would be the reason node and the timing node and forth . and what w what happened is that design wise i 'd noticed that we can we still get a lot of errors from a lot of points to one of these sub go there user go there situation nodes . came up with a couple of additional nodes here where whether the user is thrifty or not , and what his budget is currently like , is going to result in some financial state of the user . how much will he is he willing to spend ? or can spend . being the same at this just the money available , which may influence us , whether he wants to go there if it is charging tons of dollars for admission or its gonna g cost a lot of t e whatever . twenty two million to fly to international space station , ","what i 've tried to do here is list all the decision nodes that we have identified on this side . commented and what they 're about and the properties we may give them . and here are the tasks to be implemented via our data collection . and these are the data tasks where w we can assume the person would like to enter , view or just approach the thing . there 's a lot of things where we have no analogous tasks , and that may or may not be a problem . we can change the tasks slightly if we feel that we should have data for e for every decision node trying to im implant the intention of going to a place now , going to a place later on the same tour , we were gonna put this in front of people . then they will read task where lots of german words are thrown in between . and and they have to read isolated proper names and and then they gonna have to f choose from one of these tasks , which are listed here . six different things they think they would do if they were in heidelberg or traveling someplace and and they have a map . very sketchy , simplified map . and then they call this computer system that works perfectly , and understands everything . and and then after three tasks the system breaks down . and fey comes on the phone as a human operator . and and fey has some thirty subjects lined up ? and we 're still l looking for a room on the sixth floor because they stole away that conference room . behind our backs . david and jane and lila are working on that as we speak . we get to the belief net just focusing on the g go there node . and what w what happened is that design wise i 'd noticed that we can we still get a lot of errors from a lot of points to one of these sub go there user go there situation nodes . came up with a couple of additional nodes here where ","It was agreed that making subjects select from categories of tasks, such as ""big place"", ""service"", etc. could provide a better range of data. For the latter, there are already 30 subjects lined up and more are expected to be recruited off campus. "
Bed011.C,"just not all people can do that . and this actually turned out to be pretty key , because having specified these this intermediate level and noticing that everything that happens here let 's go to our favorite endpoint one is again more or less we have then the situation nodes contributing to the endpoint situation node , which contributes to the endpoint and forth . can now draw straight lines from these to here , meaning it g goes where the sub s everything that comes from situation , everything that comes from user goes with the sub u , and whatever we specify for the called "" keith node "" , or the discourse , what comes from the parser , construction parser , will contribute to the d and the ontology to the sub o node . and one just s has to watch which also final decision node it doesn't make sense t to figure out whether he wants to enter , view or approach an object if he never wants to go there in the first place . but this makes the design thing fairly simple . and now all w that 's left to do then is the cpg 's , the conditional probabilities , for the likelihood of a person having enough money , actually wanting to go a place if it costs , this or that . and and once bhaskara has finished his classwork that 's where we 're gonna end up doing . you get involved in that process too . and and for now the question is "" how much of these decisions do we want to build in explicitly into our data collection ? "" one could think of we could call the z see or people who visit the zoo we could s call it "" visit the zoo tomorrow "" , we have an intention of seeing something , but not now but later .   the reason why we did it that way , as a reminder , is no person is gonna do all of them . they 're just gonna select u according to their preferences . "" i usually visit zoos , or i usually visit castles , or i usually "" and then you pick that one . the this was these are all different activities . but i got the point and like it . we can do put them in a more hierarchical fashion . "" go to place "" and then give them a choice , either they 're the symphony type or opera type or the tourist site guide type or the nightclub disco type person and they say "" this is on that "" go to big ish place "" , this is what i would do . "" and then we have the "" fix "" thing , and then do something the other day "" thing , my question is to some extent , we should y we just have to try it out and see if it works . it would be challenging , in a sense , to try to make it complex that they even really should schedule , or to plan it , a more complex thing in terms of  they should get the feeling that there are these s six things they have to do and they sh can be done in two days . they make these decisions , "" can i go there tomorrow ? "" or influences   but this is part of the instructor 's job . and that can be done , to say , "" now we 've picked these six tasks . "" "" now you have you can call the system and you have two days . "" and th w  but th the i don't i 'm not really interested in phase planning "" capabilities . but it 's more the how do people phrase these planning requests ? are we gonna masquerade the system as this as you said simple response system , "" i have one question i get one response "" , or should we allow for a certain level of complexity . and a i w think the data would be nicer if we get temporal references . we have tested this and a y have you heard listen to the f first two or th the second person is is was faced with exactly this setup . and  that was the first subject .  it is already with this it got pretty with this setup and that particular subject it got pretty complex . suggest we make some fine tuning of these , get run through ten or subjects and then take a breather , and see whether we wanna make it more complex or not , depending on what results we 're getting . and y and always and with this we 're getting more . no question . do we wanna get going beyond more , which is the this means audio , but no transcriptions  until we reach the gigabyte thing and david johnson s ki kills me . and we 're gonna put it on the web site . no , he he has been solving all our problems or is wonderful ,  the reading task is a lot shorter . that was cut by fifty percent . and the reading , nobody 's interested in that except for the speech people .  it 's actually like five minutes dialogue . ten minutes is long .  it feels like forever when you 're doing it , but then it turns out to be three minutes and forty five seconds . it 's not and it 's fun .   i need those back that 's for and no , th the per the person don't get it . this is why we did it , because when we gave them just three tasks for w part a and three tasks for part b a exactly . this is limiting the choices , but right .  ","can now draw straight lines from these to here , meaning it g goes where the sub s everything that comes from situation , everything that comes from user goes with the sub u , and whatever we specify for the called "" keith node "" , or the discourse , what comes from the parser , construction parser , will contribute to the d and the ontology to the sub o node . and one just s has to watch which also final decision node it doesn't make sense t to figure out whether he wants to enter , view or approach an object if he never wants to go there in the first place . and and for now the question is "" how much of these decisions do we want to build in explicitly into our data collection ? "" suggest we make some fine tuning of these , get run through ten or subjects and see whether we wanna make it more complex or not , depending on what results we 're getting . this means audio , but it 's actually like five minutes dialogue . ",
Bed011.C,"but think this approach will very work , but the person was able to look at it and say "" this is what i would actually do . ""   we gotta disallow traveling to zoos and castles at the same time , but no , they 're they 're this is where tour becomes tourists bit different and , these are just places where you enter much like here . but we can  attend ,   this is where  th the function is definitely different and the getting information or g  but this is open . since people gonna still pick something , we 're not gonna get any significant amount of redundancy . and for reasons , we don't want it , really , in that sense . and we would be ultimately more interested in getting all the possible ways of people asking , for different things with or with a computer . and if you can think of any other high level tasks a tourist may do just always just m mail them to us and we 'll sneak them into the collection . we 're not gonna do much statistical with it . no . but it seems like since we are getting towards subject fifty subjects and if we can keep it up to a five four ish per week rate , we may even reach the one hundred before fey t takes off to chicago .  in terms of decision nodes ? go there is a yes or no . right ? i 'm also interested in th in this "" property "" line here , if you look at look at that timing was have these three . do we need a final differentiation there ? now , later on the same tour , sometimes on the next tour . it 's next day , you 're doing something now and you have planned to do these three four things , and you can do something immediately , you could tag it on to that tour or you can say this is something i would do s i wanna do sometime l in my life , my visit to prague there were some nights where i never went back to the hotel , whether that counts as a two day tour or not we 'll have to think . i don't know . what is the the english co cognate if you want , for "" sankt nimmerlandstag "" ? we 'll do it on when you say on that d day it means it 'll never happen . do you have an expression ? probably you sh when hell we 'll do it when hell freezes over . that should be another property in there .  the reason why do we go there in the first place ie it 's either for sightseeing , for meeting people , for running errands , or doing business . entertainment is a good one in there , i agree .  this w this is an old johno thing . he had it in there . "" who is the tour is the person ? "" it might be a tourist , it might be a business man who 's using the system , who wants to go to some    he would just meeting people , "" i want to meet someone somewhere "" , which be puts a very heavy constraint on the "" eva "" because then if you 're meeting somebody at the town hall , you 're not entering it usually , you 're just want to approach it .  that goes with the "" energy depletion "" function , blech . "" endpoint "" . "" endpoint "" is pretty clear . "" mode "" , i have found three , "" drive there "" , "" walk there "" or "" be driven "" , which means bus , taxi , bart .   this granularity would suffice , if we say the person probably , based on the utterance we on the situation we can conclude wants to drive there , walk there , or use some other form of transportation . everywhere .  we actually biking should be a separate point because we have a very strong bicycle planning component .   bicycles c should be in there , but , will we have bic is this realistic ?  we can drive    "" length "" is you wanna get this over with as fast as possible , you wanna use some part of what of the time you have . they can . but we should just make a decision whether we feel that they want to use some substantial or some fraction of their time . they wanna do it badly that they are willing to spend the necessary and plus time . and and y if we feel that they wanna do nothing but that thing then , we should point out that to the planner , that they probably want to use all the time they have . stretch out that visit for that . th the user can always s say it , but it 's just we hand over these parameters if we make if we have a feeling that they are important . and that we can actually infer them to a significant de degree , or we ask .  and if no part of the system ever comes up with the idea that this could be important , no planner is ever gonna ask for it . y and i like the idea that , jerry pushed this idea from the very beginning , that it 's part of the understanding business to make a good question of what 's important in this general picture , what you need t if you wanna simulate it , what parameters would you need for the simulation ? and , timing , length would definitely be part of it , "" costs "" , "" little money , some money , lots of money "" ? actually ,   ","go there is a yes or no . i 'm also interested in th in this "" property "" line here , timing was have these three . now , later on the same tour , sometimes on the next tour . the reason why do we go there in the first place ie it 's either for sightseeing , for meeting people , for running errands , or doing business . "" mode "" , "" drive there "" , "" walk there "" or "" be driven "" , which means bus , taxi , bart . "" length "" is you wanna get this over with as fast as possible , th the user can always s say it , but it 's just we hand over these parameters if we make if we have a feeling that they are important . and that we can actually infer them to a significant de degree , or we ask . and , timing , length would definitely be part of it , "" costs "" , "" little money , some money , lots of money "" ? ","Their values will either be inferred from the user-system interaction, or -as a last resort- requested directly from the user. "
Bed011.C,"the what my sentiment is they 're i once had to write a charter , a carter for a student organization . and they had wanted me to define what the quorum is going to be . and i looked at the other ones and they always said ten percent of the student body has to be present at their general meeting otherwise it 's not a and i wrote in there "" en enough "" people have to be there . and it was hotly debated , but people with me that everybody probably has a good feeling whether it was a farce , a joke , or whether there were enough people . and if you go to turkey , you will find when people go shopping , they will say "" how much cheese do you want ? "" and they say "" enough . "" and the this used all over the place . because the person selling the cheese knows , that person has two kids and a husband that dislikes cheese , this is enough . and the middle part is always the golden way , right ? you can s you can be really make it as cheap as possible , or you can say "" i want , er , i don't care "" money is no object , or you say "" want to spend enough "" . or the sufficient , or the appropriate amount . but , then again , this may turn out to be insufficient for our purposes . but this is my first guess , in much the same way as how d should the route be ? should it be the easiest route , even if it 's a b little bit longer ? no steep inclinations ? go the normal way ? whatever that again means , er or do you does the person wanna rough it ? this is all top of my head . no research behind that . object information "" , "" do i wanna know anything about that object ? "" is either true or false . and . if i care about it being open , accessible or not , i don't think there 's any middle ground there . either i wanna know where it is or not , i wanna know about it 's history or not , or , wanna know about what it 's good for or not . one could put scales in there , too . wanna know a l lot about it . one could put scales in there . wanna know a lot about the history , just a bit . that 's true .  that was the wrong shortcut anyhow .  what , this is the part that this is the part that needs the work . i will tell you the german tourist data . because i have not been able to dig out all the out of the m ta thirty d v if you no , not dialogues . smartkom smartkom human . wizard of oz . a little bit of data , i with nothing .   some data i collected in a couple weeks for training recognizers and email way back when . nothing to write home about . and the see this ontology node is probably something that i will try to expand . once we have the full ontology api , what can we expect to get from the ontology ? and hopefully you can also try to find out , sooner or later in the course of the summer what we can expect to get from the discourse that might , or the not the discourse , the utterance as it were , in terms of no , no , no . this is yes . no . but it 's it 's we could sit down and think of the ideal speaker utterances , and two or three that follow each other , where we can also once we have everything up and running , show the tremendous , insane inferencing capabilities of our system . as the smartkom people have . this is their standard demo dialogue , which is , what the system survives and nothing but that . we could also sor have the analogen of o our sample sentences , the ideal sentences where we have complete construction coverage and , they match nicely . the "" how do i get to x ? "" , that 's definitely gonna be a major one .  "" where is x ? "" might be another one which is not too complicated . and tell me something about x . "" and hey , that 's already covering eighty percent of the system 's functionality . no , we can w throw in an "" out of film "" construction if you want to , but  i have one bit of news . the action planner guy has wrote has written a p lengthy proposal on how he wants to do the action planning . and i responded to him , also rather lengthy , how he should do the action planning . and yes . and i tacked on a little paragraph about the fact that the whole world calls that module a dis disc dialogue manager , and wouldn't it make sense to do this here too ? and also rainer m malaka is going to be visiting us shortly , most likely in the beginning of june .  he 's just in a conference somewhere and he is just swinging through town . and making me incapable of going to naacl , for which i had funding . but . no , no pittsburg this year . when is the santa barbara ? who is going to ? should a lot of people . that 's something i will would enjoy .  there 's ","object information "" , "" do i wanna know anything about that object ? "" and . if i care about it being open , accessible or not , i don't think there 's any middle ground there . i will tell you the german tourist data . dialogues . smartkom some data i collected in a couple weeks for training recognizers and email way back when . see this ontology node is probably something that i will try to expand . and hopefully you can also try to find out , sooner or later in the course of the summer what we can expect to get from the discourse that might , or the we could sit down and think of the ideal speaker utterances , the ideal sentences where we have complete construction coverage and , they match nicely . the action planner guy has wrote has written a p lengthy proposal on how he wants to do the action planning . and i responded to him , also rather lengthy , how he should do the action planning . and i tacked on a little paragraph about the fact that the whole world calls that module a dis disc dialogue manager , and also rainer m malaka is going to be visiting us shortly , ",
Bed011.D,"eva , co could you read your numbers ?  let 's get started . hopefully nancy will come , if not , she won't .   right , right .  let me pop up a level . and make that we 're all oriented the same . what we 're gonna do today is two related things . one of them is to work on the semantics of the belief net which is going to be the main inference engine for thi the system making decisions . and decisions are going to turn out to be parameter choices for calls on other modules . the natural language understanding thing is we think gonna only have to choose parameters , but a fairly large set of parameters . to do that , we need to do two things . one of which is figure out what all the choices are , which we 've done a fair amount . then we need to figure out what influences its choices and finally we have to do some technical work on the actual belief relations and presumably estimates of the probabilities and but we aren't gonna do the probability today . technical we 'll do another day . probably next week . but we are gonna worry about all the decisions and the things that pert that contribute to them . and we 're also , in the same process , going to work with fey on what there should be in the dialogues . one of the s steps that 's coming up real soon is to actually get subjects in here , and have them actually record like this . record dialogues more or less . and depending on what fey provokes them to say , we 'll get information on different things .  fo v people with the phrase them and for , keith and people worrying about what constructions people use , we have some i we have some ways to affect that the dialogues go . what robert kindly did , is to lay out a table of the kinds of things that might come up , and , the kinds of decisions . the on the left are decision nodes , and discreet values . if we 're right , you can get by with just this middle column worth of decisions , and it 's not all that many , and it 's perfectly feasible technically to build belief nets that will do that . and he has a handout .  s i don't see a release got it . fine .  alright , fair enough . and she does know everything . there are these i see , we have to it 's tricky . we 'll let 's let we 'll do that off line ,  right . right .  let 's see i th that from one point of view , all these places are the same , that d that , in terms of the linguistics and there may be a few different kinds of places , th i it seems to me that we ought to decide what things are k are actually going to matter to us . and the zoo , and the university and the castle , et cetera . are all big ish things that have different parts to them , and one of them might be fine . and  right , no , but s th point is to y to build a system that 's got everything in it that might happen you do one thing . t to build a system that had the most data on a relatively confined set of things , you do something else . and the speech people , are gonna do better if they if things come up repeatedly . now , if everybody says exactly the same thing then it 's not interesting . all i 'm saying is i th there 's a question of what we 're trying t to accomplish . and my temptation for the data gathering would be to and each person is only gonna do it once , you don't have to worry about them being bored , if it 's one service , one luxury item , one big ish place , and forth and on , then my guess is that the data is going to be easier to handle . now you have this possible danger that somehow there 're certain constructions that people use when talking about a museum that they wouldn't talk about with a university and but 'm i my temptation is to go for simpler . less variation . but i don't other people think about this in terms of   th there are two places where it comes up . one is in the th these people who are gonna take this and try to do speech with it . lots of pronunciations of th of the same thing are going to give you better data than l a few pronunciations of lots more things . that 's one . bigger y thi this is a question for    this is a question for you , and , if we do , and we probably will , actually try to build a prototype , probably we could get by with the prototype only handling a few of them anyway .    think th   it 's easy enough to set that up if that 's your expectation . the system could say , "" we 'd like to set up your program for two days in heidelberg , let 's first think about all the things you might like to do . there th i in in i th i 'm that if that 's what you did then they would start telling you about that , and then you could get into various things about ordering , if you wanted . i 'm no , we have to help we have to decide . fey will p carry out whatever we decide . ","what we 're gonna do today is two related things . one of them is to work on the semantics of the belief net which is going to be the main inference engine for thi the system making decisions . and decisions are going to turn out to be parameter choices for calls on other modules . and we 're also , in the same process , going to work with fey on what there should be in the dialogues . but s th point is to y to build a system that 's got everything in it that might happen you do one thing . t to build a system that had the most data on a relatively confined set of things , you do something else . and the speech people , are gonna do better if they if things come up repeatedly . if it 's one service , one luxury item , one big ish place , and forth and on , then my guess is that the data is going to be easier to handle . now you have this possible danger that somehow there 're certain constructions that people use when talking about a museum that they wouldn't talk about with a university and ","The main focus of the meeting was firstly on the structure of the belief-net, its decision nodes and the parameters that influence them, and secondly, on the design of the data collection tasks. These nodes represent decisions that will function as parameters to action calls in the system. It was agreed that making subjects select from categories of tasks, such as ""big place"", ""service"", etc. could provide a better range of data. "
Bed011.D,"but we have to decide what is the appropriate scenario . that 's what we 're gonna talk about t keith , what do you think ?  first one wasn't very good .  but th but you did say something important , which is that you can probably keep yourself fairly occupied with the simple cases for quite a while . although , th that sa s does suggest that now , i have looked the data , and it 's pre it 's actually at least to an amateur , quite redundant . that it was very stylized , and quite a lot of people said more or less the same thing .  we wanna do more than that .  right .  let 's take let 's i your suggestion is good , which is we 'll do a b batch .  and , fey , how long is it gonna be till you have ten subjects ? couple days ? or thr f a week ? or i don't have a feel for th it 's up to you , j i we don't have any huge time pressure . it 's just when you have t   let 's do this . let 's plan next monday , to have a review of what we have far . and  no , we won't have the transcriptions , but what we should be able to do and i don't know if , fey , if you will have time to do this , but it would be great if you could , not transcribe it all , but pick out some we could lis just sit here and listen to it all . are you gonna have the audio on the web site ?  we could get you can buy another disk for two hundred dollars , right ? it 's not like  we 'll take care of david johnson .   alright . we 'll buy a disk . but anyway , if you can think of a way to point us to th to interesting things , as you 're doing this make your make notes that this is , something worth looking at . and other than that , guess we 'll just have to listen although it 's only ten minutes each , right ? roughly . right . no , we don't care about that i b my guess is it 's gonna be ten . people i understand , but people   could be .  i was thinking people would , hesitate and whatever . whatever it is we 'll deal with it . that 'll be on the web page . that 's great . but anyway think it 's a good idea to start with the relatively straight forward res just response system . and then if we want to get them to start doing multiple step planning with a whole bunch of things and then organize them an tell them which things are near each other and any of that "" which things would you like to do tuesday morning ? "" th that seems pretty straight forward .  i 'm fey , what ? that 's what i was suggesting for the first round , they could , but i tha they c but but you could , but i in the short run , right .    if y if you use the right verb for each in common , like at "" attend a theater , symphony or opera "" is a group , and "" tour the university , castle or zoo "" , all of these d do have this tour "" aspect about the way you would go to them . and the movie theater is probably also is a "" attend "" et cetera . it may turn out to be not many different kinds of things , and then , what one would expect is that the sentence types would their responses would tend to be grouped according to the activity , you would expect .   we don't have enough . these are all f people off campus s from campus far , right ? we we don't know how many we can get next door at the shelter for ten bucks , probably quite a few .  alright , let 's go back then , to the chart with all the decisions and and see how we 're doing . do people think that , this is gonna cover what we need , or should we be thinking about more ?   right .  probably between stops back at the hotel . if you wanted precise about it , and that 's the way tourists do organize their lives . "" we 'll go back to the hotel and then we 'll go off and "" yes . it right . for this . i w we will not ask you more .  right .    no . or both .   right .  no , i  let we 'll put it somewhere , but i would say that if "" dine out "" is a special c if you 're doing it for that purpose then it 's entertainment . and we 'll also as y as you 'll s further along we 'll get into business about "" you 're this is going over a meal time , do you wanna stop for a meal or pick up food "" and that 's different . that 's part of th that 's not a destination reason , that 's en passant , "" right . right , right .  taxis are very different than buses , but on the other hand the system doesn't have any public transport this the planner system doesn't have any public transport in it yet .  you can't get to the philosophers ' way very but , there are hikes that you can't get to , but but other things you can , if i remember right .  put it in . we can leave it out ,  skateboards right , anyway . ","let 's plan next monday , to have a review of what we have far . but it would be great if you could , not transcribe it all , but pick out some are you gonna have the audio on the web site ?  i b my guess is it 's gonna be ten . but anyway think it 's a good idea to start with the relatively straight forward res just response system . and then if we want to get them to start doing multiple step planning with a whole bunch of things and then organize them tell them which things are near each other "" which things would you like to do tuesday morning ? "" that 's what i was suggesting for the first round , like at "" attend a theater , symphony or opera "" is a group , and "" tour the university , castle or zoo "" , we we don't know how many we can get next door at the shelter ","The duration of each dialogue will probably be no more than 10 minutes. For the latter, there are already 30 subjects lined up and more are expected to be recruited off campus. "
Bed011.D,"scooters , right ? alright . ye  w  and and par and part of the system design is that if it looks to be important and you can't figure it out , then you ask . but hopefully you don't ask a all these things all the time . or but there 's th but definitely a back off position to asking .  no . there are there 're different things where you have a ch choice , this t interacts with "" do am i do are you willing to take a taxi ? "" or if you 're going to the opera are you gonna l look for the best seats or the peanut gallery or , whatever ? s think there are a variety of things in which tour tourists really do have different styles eating . another one ,   right . no , he was going for the second one ar actually . anyway , we 'll sort th we 'll sort that out . right .  now ob  i 'm go ahead , what were you gonna say ? right i w if we w right . object "" becomes "" entity "" , right ? but we don't have to do it now . and we think that 's it , interestingly enough , that th very close to it is going to be going to be enough . and alright , think the order of things is that robert will clean this up a little bit , although it looks pretty good . and  right .  right , in parallel , three things are going to happen . robert and eva and bhaskara are gonna actually build a belief net that , has cpt 's and , tries to infer this from various kinds of information . and fey is going to start collecting data , and we 're gonna start thinking a about what constructions we want to elicit . and then w go it may iterate on further data collection to elicit yes . both . and though for us , constructions are primarily semantic , right ? and that too , but if th if we in if we make that we get them talking about temporal order . that would be great and if th if they use prepositional phrases or subordinate clauses or whatever ,  w whatever form they use is fine . but that probably we 're gonna try to look at it as s what semantic constructions d do we want them to do direc "" caused motion "" , i don't know , something like that . but , this is actually a conversation you and i have to have about your thesis fantasies , and how all this fits into that . but no , no .  right . right , but we 're not expecting keith to actually build a parser .  we are expecting johno to build a parser , but that 's a no . no . he 's g he 's hoping to do this for his masters ' thesis s by a year from now .  limited . the idea is , the hope is that the parser itself is , pretty robust . but it 's not popular it 's only p only right . it 's only popula right .  right .  this is we 're gonna mainly work on with george . and hi let me f th say what is the idea is first of all i misspoke when i said we thought you should do the constructions . for a linguist that means to do completely and perfectly . what i what i meant was "" do a first cut at "" . because we do wanna get them r u perfectly but we 're gonna have to do a first cut at a lot of them to see how they interact .  right . the idea is going to be to do like nancy did in some of the er these papers where you do enough of them you can go from top to bottom you can do f f have a complete story ov of s of some piece of dialogue . and that 's gonna be much more useful than having all of the clausal constructions and nothing else , like that . that the trick is going to be t to take this and pick a some lattice of constructions , some lexical and some phrasal , and , whatever you need in order to be able to then , by hand , explain , some fraction of the utterances . and exactly which ones will partly depend on your research interests and a bunch of other things . correct .  v a half a page is what we 'd like . and if there 's something that really requires a lot more than that then it does and we have to do it , but  right . ye right , but it 's not covering eighty percent of the intellectual interest . no , no . the th there 's a lot that needs to be done to get this right . i th we done ? good . good . "" action planning "" meaning "" discourse modeling "" ? right . right .  i 'll be gone .  s probably should go . that was that 's one you should probably go to . probably we can pay for it . student rate shouldn't be very high . if we all decide it 's a good idea for you to go then you 'll we 'll pay for it . don't have a feeling one way or the other at the moment , but it probably is . great . ","or but there 's th but definitely a back off position to asking . object "" becomes "" entity "" , alright , think the order of things is that robert will clean this up a little bit , although it looks pretty good . robert and eva and bhaskara are gonna actually build a belief net that , has cpt 's and , tries to infer this from various kinds of information . and fey is going to start collecting data , and we 're gonna start thinking a about what constructions we want to elicit . we are expecting johno to build a parser , he 's g he 's hoping to do this for his masters ' thesis s by a year from now . limited . the hope is that the parser itself is , pretty robust . the idea is first of all i misspoke when i said we thought you should do the constructions . because we do wanna get them r u perfectly but we 're gonna have to do a first cut at a lot of them to see how they interact . you can do f f have a complete story ov of s of some piece of dialogue . and that 's gonna be much more useful than having all of the clausal constructions and nothing else , like that . that the trick is going to be t to take this and pick a some lattice of constructions , whatever you need in order to be able to then , by hand , explain , some fraction of the utterances . ","Their values will either be inferred from the user-system interaction, or -as a last resort- requested directly from the user. Similarly, the construction parser that is to be built within a year is expected to be relatively basic, yet robust. Finally, as to the semantic and syntactic constructions, work will start with more general and brief descriptions, before moving to exhaustive analysis of at least a subset. "
Bed011.E,"wants to conserve . m yes . i 've i understand everything . yes i do .  and more every day . tomorrow , we don't know for because we don't know whether that person is coming or not , but they 're redundant . although can s can probably schedule ten people , whenever . how long will it be ? would say two weeks . take care of him .  i 'm not how long it 's actually going to take . it feels like a long time but . but were you saying that  that w one thing we should do is go through this list and select things that are categories and then o offer only one member of that category ?  and then , they could be alternate versions of the same if you wanted data on different constructions . like one person gets the version with the zoo as a choice , and the other person gets the no , they could still choose . they just wouldn't be able to choose both zoo and say , touring the castle .  he was vicious . there they are significantly different , but .  that means that one hundred people have to be interested .    right . that 's enough . never . that 's good .  right . right . still wrong . then you can go . "," can s can probably schedule ten people , whenever . would say two weeks . that w one thing we should do is go through this list and select things that are categories and then o offer only one member of that category ? ","It was agreed that making subjects select from categories of tasks, such as ""big place"", ""service"", etc. could provide a better range of data. "
Bed011.F,"but these are two different scenarios entirely . one is a planner the other , it give you instructions on the spot but it seem that there is a difference between going to see something , and things like "" exchange money "" or "" dine out "" @ function , all tours b a tour happens only within one day ? the next tour will be tomorrow ?  right . right . what ab what do you have in mind in terms of socializing ? what activities ?  socializing , right . i must say that thi this one looks a bit strange to me . it seems like appropriate if i go to las vegas . but i decide k how much money 'm willing to lose . but a i as a tourist , i 'll just paying what 's more or less is required . the best seat or right . right , that 's true . ","but it seem that there is a difference between going to see something , and things like "" exchange money "" or "" dine out "" ",
Bed012.A,"the crown ? is that the actual name ?  yes .  yes , i have . and , i do . alright . s where are we ? i don't think it can handle french , but anyway . no . i 'm not drinking tea . what are you talking about ?  excuse me .   you should probably make them out of  the different decision nodes , d this is making the assumption . yes . but why do we if we trusted the go there node more th much more than we trusted the other ones , then we would conclude , even in this situation , that he wanted to go there . in that sense , we weight them equally right now . the final d decision is the combination of these three . again , it 's some  a decision node for every possible question ,  is   are you saying that , what happens if you try to scale this up to the situation , or are we just dealing with arbitrary language ? is that your point ? for every question ? like  i don't not necessarily , i would think . it 's not based on constructions , it 's based on things like , there 's gonna be a node for go there or not , and there 's gonna be a node for enter , view , approach .  in general we won't just have those three , right ? we 'll have , many nodes . we have to , like that it 's no longer possible to just look at the nodes themselves and figure out what the person is trying to say .   that 's true .  ge  right .  yes ,  you do need to know to have that information . right . the other thing is that when you 're asked a specific question and you don't even like , if you 're asked a where is question , you may not even look like , ask for the posterior probability of the , eva node , right ? cuz , that 's what in the bayes net you always ask for the posterior probability of a specific node .  you may not even bother to compute things you don't need . no . you can compute , the posterior probability of one subset of the nodes , given some other nodes , but ignore some other nodes , also . things you ignore get marginalized over . you have to make  yes . but i would think that 's what you want to do . right ?    i don't know if it would necessarily be that , complicated . but , it w  that 's true , in a way you would have that . why 's that ?   alright . hopefully it 's fixable . it 's there 's a  we can figure this out . they should come when they 're done their whenever that is .   jerry needs to enter marks , but i don't know if he 's gonna do that now or later . but , if he 's gonna enter marks , it 's gonna take him awhile , and he won't be here . nancy ? she was sorta finishing up the , calculation of marks and assigning of grades , but i don't know if she should be here . or , she should be free after that ,  assuming she 's coming to this meeting . i don't know if she knows about it . is she ?   four inputs . those are the bottom things are inputs , also .  alarm in the dog ?  i 'm confusing two . right .   we 'll meet next tuesday , which friday ?  is he how long is he gone for ? italy , what 's , what 's there ? pasta . right . just visiting . it 's a pretty place , in my brief , encounter with it . yes . h what ? which which ones ? what do if the go there says no , then the go there is i don't u understand . like , the go there depends on all those four things .  it depends on the situation . if the discourse is strongly indicating that i see . the d see , specifically in our situation , d and o are gonna be ,   whatever . johno ? people have the same problem with my name .  in my name ? before the a . people have the inverse problem with my name .  that 's good . i appreciate that . "" basman "" ? it 's because of the chessplayer named michael basman , who is my hero . not eva ? it doesn't matter what those nodes are , anyway , because we 'll just make the weights "" zero "" for now .     but how many constructions do could we possibly have nodes for ? no , we . like , when people do this thing .  is it considered to be like in are they considered to be like very , abstract things ? it 's like in the thousands .  s discourse level constructions . yes . how 's that ? how it can be finite , again ? but , in the practical sense , it 's impossible .  two to the power of the number of neurons . but there 's certain level of bandw you can't do better than something . ","the different decision nodes , if we trusted the go there node more th much more than we trusted the other ones , then we would conclude , even in this situation , that he wanted to go there . it 's not based on constructions , it 's based on things like , there 's gonna be a node for go there or not , and there 's gonna be a node for enter , view , approach . in general we won't just have those three , we 'll have , many nodes . we have to , like that it 's no longer possible to just look at the nodes themselves and figure out what the person is trying to say . like , if you 're asked a where is question , you may not even look like , ask for the posterior probability of the , eva node , cuz , that 's what in the bayes net you always ask for the posterior probability of a specific node . you may not even bother to compute things you don't need . we 'll meet next tuesday , but how many constructions do could we possibly have nodes for ? ","The input layer deriving information from things like the user and situation models, feeds into a set of decision nodes, such as the Enter/View/Approach (EVA) endpoint. Therefore, they will either have to be pruned a posteriori, or only a subset of the possible decision nodes will be computed in each occasion. "
Bed012.B,"guess this is more or less now just to get you up to date , johno . this is what ,  eva , bhaskara , and i did . why ? no . this is  ha ! very we thought that , we can write up an element , and for each of the situation nodes that we observed in the bayes net ?  what 's the situation like at the entity that is mentioned ? if we know anything about it ? is it under construction ? or is it on fire happening to it ? or is it stable ? and forth , going all the way f through parking , location , hotel , car , restroom , @ @ riots , fairs , strikes , or disasters . that 's just specifying the input for the w what 's just because it forces us to be specific about the values here ? and , also , this is a what the input is going to be . right ? we will , this is a schema . this is no , because if we we 're gonna interface to we 're gonna get an xml document from somewhere . right ? and that xml document will say "" we are able to we were able to observe that w the element , @ @ of the location that the car is near . "" that 's gonna be  this is just , again , a an xml schemata which defines a set of possible , permissible xml structures , which we view as input into the bayes net . right ? yea are you talking about the structure ? when you observe a node .  no , it 's certainly not this . nuh . xsl .  that 's no problem , but i even think that , once you have this as running as a module right ? what you want is you wanna say , "" give me the posterior probabilities of the go there node , when this is happening . "" right ? when the person said this , the car is there , it 's raining , and this is happening . and with this you can specify the what 's happening in the situation , and what 's happening with the user . we get after we are done , through the situation we get the user vector . this is a  and , all the possible outputs , too . we have , the , go there decision node which has two elements , going there and its posterior probability , and not going there and its posterior probability , because the output is always gonna be all the decision nodes and all the a all the posterior probabilities for all the values . yes , but it 's a little bit more complex . as , if i understand it correctly , it always gives you all the posterior probabilities for all the values of all decision nodes . when we input something , we always get the , posterior probabilities for all of these . right ? there is no way of telling it t not to tell us about the eva values . we get this whole list of , things , and the question is what to do with it , what to hand on , how to interpret it , in a sense . you said if you "" i 'm only interested in whether he wants to go there or not "" , then look at that node , look which one  look at that struct in the output , even though i wouldn't call it a "" struct "" . but .  every part of a structure is a "" struct "" .  that element or object , i would say .   and , the reason is why it 's a little bit more complex or why we can even think about it as an interesting problem in and of itself is  the , let 's look at an example . w we 'd need to prune . right ? throw things away . no exactly . the @ @ xerxes allows you to say , u "" just give me the value of that , and that . "" but , we don't really we 're interested in before we look at the complete at the overall result . the person said , "" where is x ? "" and we want to know , is does he want info ? o on this ? or know the location ? or does he want to go there ? let 's assume this is our question . nuh ?   do this in perl . we get  let 's assume this is the output .  we should con be able to conclude from that it 's always gonna give us a value of how likely we it is that he wants to go there and doesn't want to go there , or how likely it is that he wants to get information . but , we should just reverse this to make it a little bit more delicate . does he wanna know where it is ? or does he wanna go there ? right . i tend to agree . and if it 's if and i if there 's clear winner here , and , and this is pretty , indifferent , then we might conclude that he actually wants to just know where , he does want to go there . or go there . a lot of people ask that , if they actually just wanna go there . people come up to you on campus and say , "" where 's the library ? "" you 're gonna say y you 're gonna say , g "" go down that way . "" ","what 's the situation like at the entity that is mentioned ? if we know anything about it ? that 's just specifying the input for the w what 's and , also , this is a what the input is going to be . once you have this as running as a module what you want is you wanna say , "" give me the posterior probabilities of the go there node , when this is happening . ""  as , if i understand it correctly , it always gives you all the posterior probabilities for all the values of all decision nodes . and the question is what to do with it , how to interpret it , the person said , "" where is x ? "" we want to know , is does he want info ? or know the location ? or does he want to go there ? it 's always gonna give us a value of how likely we it is that he wants to go there and doesn't want to go there , or how likely it is that he wants to get information . ","The input layer deriving information from things like the user and situation models, feeds into a set of decision nodes, such as the Enter/View/Approach (EVA) endpoint. "
Bed012.B,"you 're not gonna say "" it 's five hundred yards away from you "" or "" it 's north of you "" , or "" it 's located ""  i don't know whether i understand what but . again , in this given this input , we , also in some situations , may wanna postulate an opinion whether that person wants to go there now the nicest way , use a cab , or wants to know it wants to know where it is because he wants something fixed there , because he wants to visit t it or whatever . it n all i 'm saying is , whatever our input is , we 're always gonna get the full output . and some things will always be too not significant enough .       the idea is to f to feed the output of that belief net into another belief net . but , why only those three ? why not the whol but we believe that all the decision nodes are can be relevant for the where is , and the where how do i get to or the tell me something about . yes , it is allowed .    let 's not forget we 're gonna get some very strong input from these sub dis from these discourse things , right ?  "" tell me the location of x . "" nuh ? or "" where is x located at ? "" nuh ?  it 's th called "" the crown "" .  versus "" the sony "" .  the manufacturer . you w you 're on line ? we 're discussing this .  assume we have something coming in . a person says , "" where is x ? "" , and we get a certain we have a situation vector and a user vector and everything is fine ? an and our and , let 's just assume our bayes net just has three decision nodes for the time being . these three , he wants to know something about it , he wants to know where it is , he wants to go there . but ,  no , do the timing node in here , too , and say "" ""  and , and , go there has two values , right ? , go there and not go there . let 's assume those are the posterior probabilities of that . info on has true or false and location . he wants to know something about it , and he wants to know something he wants to know where it is , has these values . and , and , in this case we would probably all agree that he wants to go there . our belief net thinks he wants to go there , right ? in the , whatever , if we have something like this here , and this like that and here also some something like that , then we would guess , "" aha ! he , our belief net , has s stronger beliefs that he wants to know where it is , than actually wants to go there . "" right ? what do by "" differently weighted "" ? they don't feed into anything really anymore .  makes sense .  but  i don't see your point . what i am thinking , or what we 're about to propose here is we 're always gonna get the whole list of values and their posterior probabilities . and now we need an expert system or belief net that interprets that , that looks the values and says , "" the winner is timing . now , go there . "" "" go there , timing , now . "" or , "" the winner is info on , function off . "" he wants to know something about it , and what it does . nuh ? regardless of the input . wh regardle based on the k what the question was , what the discourse , the ontology , the situation and the user model gave us , we came up with these values for these decisions .  look at look face yourself with this pr question . you get this you 'll have y this is what you get . and now you have to make a decision . what do we think ? what does this tell us ? and not knowing what was asked , and what happened , and whether the person was a tourist or a local , because all of these factors have presumably already gone into making these posterior probabilities . what we need is a just a mechanism that says , "" aha ! there is ""  because there are interdependencies , right ? the no . if the go there posterior possibility is high , w if it 's if it has reached a certain height , then all of this becomes irrelevant . if even if the function or the history is scoring pretty good on the true node , true value he wants to go there and know something about it ? to some extent they are . or they 're not . if he doesn't want to go there , even if the enter posterior proba  go there is no . enter is high , and info on is high .  no , there 's no . but it 's through the   i 'm also agreeing that a simple pru take the ones where we have a clear winner . forget about the ones where it 's all middle ground . prune those out and just hand over the ones where we have a winner . because that would be the easiest way . we just compose as an output an xml mes message that says . "" go there now . "" "" enter historical information . "" and not care whether that 's consistent with anything . right ? ","it n all i 'm saying is , whatever our input is , we 're always gonna get the full output . and some things will always be too not significant enough . what i am thinking , or what we 're about to propose here is we 're always gonna get the whole list of values and their posterior probabilities . and now we need an expert system or belief net that interprets that , because there are interdependencies , ","In any particular situation, most of the outputs will not be relevant to the given context. "
Bed012.B,"but in this case if we say , "" definitely he doesn't want to go there . he just wants to know where it is . "" or let 's call this "" look at h "" he wants to know something about the history of . he said , "" tell me something about the history of that . "" now , the e but for some reason the endpoint approach gets a really high score , too . we can't expect this to be at o point three , three , o point , three , three , three . right ? somebody needs to zap that .  or know there needs to be some knowledge that   it 's one of those , that 's it 's more like a decision tree , if you want . you first look o at the lowball ones , and then   aren't we always computing all ? but that 's just shifting the problem . then you would have to make a decision , "" if it 's a where is question , which decision nodes do i query ? "" that 's un   it 's it 's apples and oranges . nuh ? it does make a difference in terms of performance , computational time . either you always have it compute all the posterior possibilities for all the values for all nodes , and then prune the ones you think that are irrelevant , or you just make a p @ @ a priori estimate of what you think might be relevant and query those . are do we know whether jerry and nancy are coming ? or ?   because what where we also have decided , prior to this meeting is that we would have a rerun of the three of us sitting together sometime this week again and finish up the , values of this . we have , believe it or not , we have all the bottom ones here .  we have actually what we have is this line . right ?   four .  and we have all the top ones , all the ones to which no arrows are pointing . what we 're missing are the these , where arrows are pointing , where we 're combining top ones . we have to come up with values for this , and this , this , and forth . and just fiddle around with it a little bit more . and , and then it 's just , edges , many of edges . and , we won't meet next monday .    on friday . this friday . this friday .  two weeks . it 's a country . buildings . people .  vacation . do you guys part of what we actually want to do is schedule out what we want to surprise him with when he comes back .   you or have a finished construction parser and a working belief net , and that 's actually what i had planned , personally . i had scheduled out in my mind that you guys do a lot of work , and i do nothing . and then , i bask in your glory . but , i do you guys have any vacation plans , because i myself am going to be , gone , but this is actually not really important . just this weekend we 're going camping .  but we 're all going to be here on tuesday again ? looks like it ? then . let 's meet again next tuesday . and , finish up this bayes net . and once we have finished it , we can , and that 's going to be more just you and me , because bhaskara is doing probabilistic , recursive , structured , object oriented , reasoning machines . and ,  the whole group . and we present our results , our final , definite we should do this th the upcoming days . this week , and , ami might .  because , th once we have the belief net done we will . because then , once we have it up and running , then we can start defining the interfaces and then feed into it and get out of it , and then hook it up to some fake construction parser and  and , worry about the ontology interface and you can keith can worry about the discourse . this is pretty i hope everybody knows that these are just going to be dummy values , right ? where the s if the endpoint if the go there is yes and no , then go there discourse will just be fifty . right ?   but , what are the values of the go there discourse ? but , we have no discourse input .  this is d this , get it in here . get it in here , th we have the , sk let 's call it "" keith johno node "" . there is an h somewhere printed .  and , but , when you abbreviate yourself as the "" basman "" , you don't use any h 's .   which is f . voiced . it 's just the difference between voiced and unvoiced .  we 'll make them zero for now , because it who knows what they come up with , what 's gonna come in there .  and , then should we start on thursday ? and not meet tomorrow ?  i 'll send an email , make a time suggestion . they would still c get the closest , best fit .    or , if even something chinese ,  phoneme .  rhetorical constructions .  but , you can probably count the ways .   you can come up with new constructions .   turn off the mikes . otherwise it gets really tough for the tr ","but that 's just shifting the problem . then you would have to make a decision , "" if it 's a where is question , which decision nodes do i query ? "" it does make a difference in terms of performance , computational time . what where we also have decided , prior to this meeting is that we would have a rerun of the three of us sitting together sometime this week again and finish up the , values of this . we have , believe it or not , we have all the bottom ones here . we have to come up with values for this , and this , this , and forth . and just fiddle around with it a little bit more . and , we won't meet next monday . then . let 's meet again next tuesday . and , finish up this bayes net . and we present our results , because then , once we have it up and running , then we can start defining the interfaces and then feed into it and get out of it , and then hook it up to some fake construction parser worry about the ontology interface and you can keith can worry about the discourse . they would still c get the closest , best fit . but , you can probably count the ways . ","The latter option could could follow a binary search-tree approach and it could also be better in computational terms. The complete prototype of the Bayes-net will be presented in the next meeting. After that, it will be possible to define interfaces and a dummy construction parser, in order to test and link modules together. "
Bed012.C,"this is a meeting for me . is this is a situation are is all the things which can be happening right now ? or , what is the situation type ? i see y why are you specifying it in xml ?  don't know if this is th l what the does this is what java bayes takes ? as a bayes net spec ? this is the situational context , everything in it . is that what situation is short for , shi situational context ?  and then we can r possibly run one of them transformations ? that put it into the format that the bayes n or java bayes or whatever wants ? it when you say the input to the v java bayes , it takes a certain format , right ? which i don't think is this . although i don't know . you could just couldn't you just run a  to convert it into the java bayes for format ?  this is just a specification of all the possible inputs ?  and then we would just look at the , struct that we wanna look at in terms of if we 're only asking about one of the like , if i 'm just interested in the going there node , i would just pull that information out of the struct that gets return that would that java bayes would output ?  agree , that 's use look at that struct in the output , right ? it 's an xml structure that 's being res returned , right ? just was abbreviated it to struct in my head , and started going with that . not a c struct . that 's not what i was trying to k though w wouldn't we just take the structure that 's outputted and then run another transformation on it , that would just dump the one that we wanted out ? actually , you don't even need to do that with xml . d can't you just look at one specific  he wants to know where it is . now , y you could out of curiosity , is there a reason why we wouldn't combine these three nodes ? into one smaller subnet ? that would just be the question for we have "" where is x ? "" is the question , right ? that would just be info on or location ? based upon but the there 's you just have three decisions for the final node , that would link thes these three nodes in the net together . wha or i it 'll be tight . you won't it 'll be hard to decide . but this is another , smaller , case of reasoning in the case of an uncertainty , which makes me think bayes net should be the way to solve these things . if you had if for every construction , right ? you could say , "" there here 's the where is construction . "" and for the where is construction , we know we need to l look at this node , that merges these three things together as for th to decide the response . and since we have a finite number of constructions that we can deal with , we could have a finite number of nodes . say , if we had to y deal with arbitrary language , it wouldn't make any sense to do that , because there 'd be no way to generate the nodes for every possible sentence . but since we can only deal with a finite amount of take these three things and then put them into another belief net . d for the where is question . we 'd have a node for the where is question . you can come in if you want . as long as y you 're not wearing your h headphones . i do i see , i don't know if this is a good idea or not . i 'm just throwing it out . but it seems like we could have i mea or we could put all of the r information that could also be relevant into the where is node answer node thing  and we u i know , but the bayes net would be able to the weights on the nodes in the bayes net would be able to do all that , wouldn't it ? here 's a k  i 'll until you 're plugged in . don't sit there . sit here . how you don't like that one . it 's that 's the weird one . that 's the one that 's painful . that hurts . it hurts bad . i 'm h i 'm happy that they 're recording that . that headphone . the headphone that you have to put on backwards , with the little thing and the little foam block on it ? it 's a painful , painful microphone . the crown ? i don't see a manufacturer on it .  here it is . h this thingy . it 's "" the crown "" . the crown of pain ! are you are your mike o is your mike on ?  you 've been working with these guys ? what 's going on ? excellent ! did you just sti did you just stick the m the microphone actually in the tea ?   in terms of , these would be wha how we would answer the question where is , right ? we u this is i that 's what you s it seemed like , explained it to me earlier w we 're we wanna know how to answer the question "" where is x ? "" but in the s let 's just deal with the s the simple case of we 're not worrying about timing or anything . we just want to know how we should answer "" where is x ? "" ","y why are you specifying it in xml ? this is just a specification of all the possible inputs ? you won't it 'll be hard to decide . you could say , "" there here 's the where is construction . "" and for the where is construction , we know we need to l look at this node , that merges these three things together ","In any case, on what basis the ""winner"" output is chosen is not clear. One suggestion was discussed: the particular constructions used can determine the pertinent decision (output) nodes. "
Bed012.C,"i see why we can't do that . it that it doesn't this assume , though , that they 're evenly weighted ? like they are evenly weighted . the go there , the info on , and the location ? like or i jus le the but the k the question that i was as er wondering or robert was proposing to me is how do we d make the decision on as to which one to listen to ? bayes net . then , the question i then my question is t to you then , would be is the only r reason we can make all these smaller bayes nets , because we know we can only deal with a finite set of constructions ? cuz oth if we 're just taking arbitrary language in , we couldn't have a node for every possible question ,  i like , in the case of in the ca any piece of language , we wouldn't be able to answer it with this system , b if we just h cuz we wouldn't have the correct node . w what you 're s proposing is a n where is node , right ? and if we and if someone says , something in mandarin to the system , we 'd wouldn't know which node to look at to answer that question , right ? but if we have a finite what ? but how does the expert system know how who which one to declare the winner , if it doesn't know the question it is , and how that question should be answered ? know . but how do we weight what we get out ? as , which one i which ones are important ? my i if we were to it with a bayes net , we 'd have to have a node for every question that we knew how to deal with , that would take all of the inputs and weight them appropriately for that question . does that make sense ? yay , nay ? we no . my question is , is the reason that we can make a node f or lemme see if i 'm confused . are we going to make a node for every question ? does that make sense ? or not . every construction . wel w someone asked a question . how do we decide how to answer it ?  don't think a "" winner take all "" type of thing is the wel i don't know about that , cuz that would suggest that do they have to be mutual do they have to be mutually exclusive ? cuz i , the way you describe what they meant , they weren't mutu they didn't seem mutually exclusive to me . wel just out of the other three , though , that you had in the those three nodes . the d they didn't seem like they were mutually exclusive . th s but some some things would drop out , and some things would still be important . but what 's confusing me is , if we have a bayes net to deal w another bayes net to deal with this   is the only reason if we have a ba another bayes net to deal with this the only r reason we can design it is cuz we each question is asking ? and then , the only reason way we would question he 's asking is based upon if let 's say i had a construction parser , and i plug this in , i would each construction the communicative intent of the construction was and then i would know how to weight the nodes appropriately , in response . no matter what they said , if i could map it onto a where is construction , i could say , "" the intent , here , was where is "" , and i could look at those . we but , the bayes net that would merge realized that i had my hand in between my mouth and my micr er , my and my microphone . then , the bayes net that would merge there , that would make the decision between go there , info on , and location , would have a node to tell you which one of those three you wanted , and based upon that node , then you would look at the other it i does that make sense ? i i didn't intend to say that every possible  there was a confusion there , k i didn't intend to say every possible thing should go into the bayes net , because some of the things aren't relevant in the bayes net for a specific question . like the endpoint is not necessarily relevant in the bayes net for where is until after you 've decided whether you wanna go there or not . show us the way , bhaskara . you 'd have a decision tree query , go there . if k if that 's false , query this one . if that 's true , query that one . and just do a binary search through the ? in the case of go there , it would be . in the case cuz if you needed an if y if go there was true , you 'd wanna endpoint was . and if it was false , you 'd wanna d look at either lo income info on or history . also , i 'm somewhat boggled by that hugin software . i can't figure out how to get the probabilities into it . like , i 'd look at it 's somewha it 's boggling me . ju i d haven't figured out what the terms in hugin mean , versus what java bayes terms are . what d what do they need to do left ? and what 's nancy doing ? she 's on the email list , right ? i ","they are evenly weighted . know . but how do we weight what we get out ? as , which one i which ones are important ? my i if we were to it with a bayes net , we 'd have to have a node for every question that we knew how to deal with , that would take all of the inputs and weight them appropriately for that question . are we going to make a node for every question ? every construction . if let 's say i had a construction parser , and i plug this in , i would each construction the communicative intent of the construction was and then i would know how to weight the nodes appropriately , in response . then , the bayes net that would merge there , that would make the decision between go there , info on , and location , would have a node to tell you which one of those three you wanted , you 'd have a decision tree query , go there . if k if that 's false , query this one . if that 's true , query that one . and just do a binary search through the ? also , i 'm somewhat boggled by that hugin software . i can't figure out how to get the probabilities into it . ",One suggestion was discussed: the particular constructions used can determine the pertinent decision (output) nodes. The latter option could could follow a binary search-tree approach and it could also be better in computational terms. 
Bed012.C,"what do the , structures do ? the this location node 's got two inputs , that one you i see . that was that makes a lot more sense to me now . cuz it was like , that one in stuart 's book about , the u or the earthquake and the alarm . there 's a dog one , too , but that 's in java bayes , isn't it ? but there 's something about bowel problems with the dog . cuz of memorial day ? when 's jerry leaving for italia ? ugh . as in , four days ? or , three days ? but it 's not a conference or anything . he 's just visiting . we should disappoint him . that wouldn't be disappointing . we should do no work for the two weeks that he 's gone . that sounds good , too . i 'm wanna be this gone this weekend , too . killing machines ! killing , reasoning . what 's the difference ? when you say , "" the whole group "" , the four of us , and keith ? ami might be here , and it 's possible that nancy 'll be here ?   you 're just gonna have to explain it to me , then , on tuesday , how it 's all gonna work out .  that you will have in about nine months or  the first bad version 'll be done in nine months . there you go . does th does the h go b before the a or after the a ?  good . cuz you kn when you said people have the same problem , cuz my h goes after the the v  i always have to check , every time y i send you an email , a past email of yours , to make 'm spelling your name correctly . i worry about you . you 're a geek . it 's o k . i how do you pronou how do you pronounce your name ? eva ? what if i were to call you eva ? no , not just eva , eva . like if i u take the v and s pronounce it like it was a german v ?  it sounds like an f . there 's also an f in german , which is why i  as long as that 's o k . i might slip out and say it accidentally . that 's all i 'm saying .  it 's that we can that we have one node per construction . cuz even in people they don't you 're talking about if you 're using some strange construction . but the that 's what the construction parser would do . if you said something completely arbitrary , it would f find the closest construction , right ? but if you said something that was completel er h theoretically the construction parser would do that but if you said something for which there was no construction whatsoever , n people wouldn't have any idea what you were talking about . like "" bus dog fried egg . ""  or , something in mandarin , or cantonese , as the case may be . what do you think about that , bhaskara ? in this system , or in r when p how many constructions do people have ? i have not the slightest idea . every noun is a construction . the  any form meaning pair , to my understanding , is a construction . and form u starts at the level of noun or actually , even sounds .  and goes upwards until you get the ditransitive construction . and then , the c there can be the can there be combinations of the dit  the "" giving a speech "" construction , it 's probab i would s definitely say it 's finite . and at least in compilers , that 's all that really matters , as long as your analysis is finite . nah , i can't think of a way it would be infinite . if the if your brain was non deterministic , then perhaps there 's a way to get , infin an infinite number of constructions that you 'd have to worry about . right . cuz if we have a fixed number of neurons ? the best case scenario would be the number of constructions or , the worst case scenario is the number of constructions equals the number of neurons . right . but still finite . no , not necessarily , is it ? we can end the meeting .  can't you use different var different levels of activation ? across , lots of different neurons , to specify different values ? there 's a bandwidth issue , right ?  ","it 's that we can that we have one node per construction . cuz even in people they don't you 're talking about if you 're using some strange construction . any form meaning pair , to my understanding , is a construction . as long as your analysis is finite . ",
Bed012.D,"did you add more to it ? later ? i don't know . there were the @ @ and all that but . you said you were adding but i don't know .  what ? true . eventually , you still have to pick out which ones you look at . it 's the same problem , isn't it ?  you added a bunch of nodes , for ?  this friday ?  you 're saying , next tuesday , is it the whole group meeting , or just us three working on it , or ?  when you were saying we need to do a re run of , like what like , just working out the rest of the this week ?  i don't get it . far we have is that what the keith node is ? and you 're taking it out ? for now ? or ? all the d 's are eva .  i 'd probably still respond to it . i 've had people call me eva , but i don't know . no idea then . what ? i    that 's fine . ","eventually , you still have to pick out which ones you look at . ",
Bed013.A,"i 'm  yes . was he supposed to harass me ? he just told me that you came looking for me . figure this out . i know , i didn't understand that either !   it hurts . it does ! i 'm didn't mean to i 'm i 'm these are all the same . th this is not very on target . shoot . alright , you guys can continue talking about whatever you were talking about before . which johno mentioned to me .   what 's the part that 's not pretend ? the writing ? tha which conference is it for ? interesting . whinney . macwhinney interesting , both child language people .  wanna go . why are they speaking at it if it is it normally like , dialogue systems , or , other nlp ish things ? it 's cognitive .  and both learning and like , comprehension , production , that kinda   i don't know about it . that 's pretty soon .  th that 's the kinda thing that like , the general con like ntl ish like , whatever , the previous simulation based pers you 're talking about the same thing . a general paper about the approach here would probably be appropriate . and good to do at some point anyway .   having it is still a good thing .  it 's fun . when is it and where ? it 's in germany . i s i see . tomasello 's already in germany anyway , makes sense .  is the what are you just talking about the details of how to do it , or whether to do it , or what it would be ? or what to write about ?    how many pages ? four pages ? it 's a little thing .  four pages is really not very much space . it 's  and it 's also difficult to even if you had a lot of substance , it 's hard to demonstrate that in four pages ,  it 's still   not including figures and such ?   ascii ? look at the web page ? wha w more cues for us to find it are like , neural cons you have a link .  keith . "" keith "" . excellent . that 's a very shirt . new york ? excellent . yes ? lucky you . the idea that you and i already know about ? that you already told me ? not that   that 's what he says . i kn that 's great ! does that mean you 'll get you 'll fly us there ? hhh !   i know about that part . i know about the almond trees and not joking . name a vegetable , kiwi ? coconut . pineapple . see ? mango ? too easy ? really ? but i was trying to find something that he didn't grow on his farm .  anyway . cantaloupe . but then in the end we 're not doing like those things right yet , right ? would that be clear in the paper or not ?  it would be like , this is the idea . i didn't get that , did i ?  did i ?  i 'm i 'm i 'm . go on . parsing done right is like chicken done right .    parsing done right , interpretation done right , example . and how much to get into the cognitive neural part ? you don't have t the conference may be cognitive neural , doesn't mean that every paper has to be both . like , nlp cognitive neural . this paper wouldn't particularly deal with that side although it could reference the ntl ish approach .  the fact that the methods here are all compatible with or designed to be compatible with whatever , neurological neuro biol su four pages you could you could definitely it 's definitely possible to do it . it 's just it 'd just be small . like introducing the formalism might be not really possible in detail , but you can use an example of it .  it be like using the formalism rather than introducing it per se .   and people will figure out or ask about the bits that are implicit .  that 's th that 's definitely a good idea . no . yes ! what 'd you say ? i do remember you talking to me .  a few more bits .    that was that the question ? was that what my god , that 's amazing ! no way . someone 's gonna start making phil collins jokes .  you guys are too young . come on . i know , that was horrible . sussudio . i 'm i haven't . not on purpose . no , he 's not . really ? i didn't really listen to it , i was too young . anyway .  stop excluding me . i can't believe that 's never been thought of before . keith . what 's the middle thing ? but wh but what is it ?  is that supposed to be the international sign for interface ?  just t    that 's great . user ? what about the utterance ? discourse . that 's not like context , interesting ,  user . user . grateful for us ? did you just say grateful for us ?  anyway .    it 's not just a particular word 's the you 're looking for a few keys that are cues to a few specific cues to some intention .  just just "" where is x "" ? or any variants of that . s that it has a location like that ? or th the ontology will tell us where actually it is located ?    you 're talking about , the construction involves this entity or refers to this entity , and from the construction also that it is a location is or a thing that can be located . ","and how much to get into the cognitive neural part ? like , nlp cognitive neural . the fact that the methods here are all compatible with or designed to be compatible with whatever , neurological neuro biol su like introducing the formalism might be not really possible in detail , but you can use an example of it . what 's the middle thing ? ",
Bed013.A,"right ? ontology says this thing has a location slot . sh and that 's the thing that is being that is the content of the question that 's being queried by one interpretation of "" where is x "" . and another one is , path from current user current location to that location .  is the question it 's just that i 'm not what the is the question , for this particular construction how we specify that 's the information it provides ? or asked for ? b both sides , right ? observed when you heard the speaker say "" where is x "" , or when that 's been parsed ? these little circles you have by the d ? is that ?  is  un agree with that . i have a different kinda question , might be related , which is , implicitly everything in edu , we 're always inferring the speaker intent , right ? like , what they want either , the information that they want , or it 's always information that they want probably , of some kind . right ? or i don't know , or what 's something that they i don't   let 's see . don't know if the if th just there 's more s here that 's not shown that you it 's already like part of the system whatever , but , "" where is x "" the fact that it is , a speech act , whatever , it is a question . it 's a question that , queries on some particular thing x , and x is that location . there 's lot of structure in representing that . that seems different from just having the node "" location x "" and that goes into edu , right ? tha is that what you 're t talking about ? wh what kinds of structure we want .   in some ways in some ways in the other parallel set of mo more linguistic meetings we 've been talking about possible semantics of some construction . right ? where it was the simulation that 's , according to it that corresponds to it , and as the as discourse , whatever , conte infor in discourse information , such as the mood , and , other are we looking for a abbreviation of that , that 's tailored to this problem ? cuz that has , s it 's in progress still it 's in development still , but it definitely has various feature slots , attributes , bindings between things   for the subset of  that exactly "" where is x "" , not the choices of "" where is x "" or "" how do i get to x "" . just "" where is x "" .  do , or do not take other kinds of constructions into account ? where possible .    it seems like "" where is x "" , the fact that it might mean "" tell me how to get to x "" , like do y would you wanna say that those two are both , like those are the two interpretations , right ? the ones that are location or path . you could say that the s construction is a question asking about this location , and then you can additionally infer , if they 're asking about the location , it 's because they wanna go to that place , in which case , the you 're jumping a step and saying , "" i know where it is but i also know how to get they wanna seem they seem to wanna get there 'm gonna tell them "" . there 's like structure i do you kn that it 's like you infer the speaker intent , and then infer a plan , a larger plan from that , for which you have the additional information , you 're just being extra helpful .    and just by an additional link  right , like , with context and enough user information ,     fifty ? you 've had fifty far , or ?    ","do , or do not take other kinds of constructions into account ? it 's like you infer the speaker intent , and then infer a plan , a larger plan from that , for which you have the additional information , ",
Bed013.B,"yes . whew ! i almost forgot about the meeting . i woke up twenty minutes ago , thinking , what did i forget ? internal alarms . yes . now what are y what are you doing there ? i forgot ?  god bless america . aren't you flying on lufthansa though ? then the it 's not a big deal . once you get to the united states it 'll be a problem , but on ?   like in ai they generally do the take in , and then they also do the generation phase , like nancy 's thing . or you remember , in the hand thing in one eighty two , like not only was it able to recognize but it was also to generate based upon situations . that thing ?  then , he probably should be coming back a year from now . once the system understands things . don't think we 're probably a year away from getting the system to understand things . the basic idea would be to give allow the system to have intentions , cuz that 's what needs to be added to the system for it . we 'd have to seed that ,  it wouldn't to ask .  unless it was in a situation . we 'd have to set up a situation where , it didn't know where something was and it wanted to go there . which means that we 'd need to set up an intention inside of the system . right ? which is "" i don't know where something is and i need to go there "" . no not . excel  it will d r assign values to all the nodes . yes . i 'm just what i 'm afraid of is if we don't , set up a situation , we 'll just get a bunch of garbage out , like everything 's exactly thirty percent . that was absurdly low , in the last meeting , cuz i went and looked at it cuz i was thinking , that could not be right , and it would it was on the order of twenty output nodes and something like twenty thirty input nodes . to test every output node , would at least let 's see , it would be two to the thirty for every output node ? which is very th very large . i 'm talking about i was gonna take a drink of my water . i 'm talking about billions and billions and a number two to the thirty is like a bhaskara said , we had calculated out and bhaskara believes that it 's larger than the number of particles in the universe . and if i two to the thirty ? two to the thirty is a billion , but if we have to do it two to the twenty times , then that 's a very large number . cuz you have to query the node , for every a or query the net two to the twenty times . or not two to th excuse me , twenty times . yes . as far as that 's @ @ that 's big . actually we calculated a different number before . how did we do that ? if it takes us a second to do , for each one , and let 's say it 's twenty billion , then that 's twenty billion seconds , which is eva , do the math . hours and hours and hours . but we can do randomized testing . which probabilistically will be good enough . who ? my advisor ! i 'm gonna work on that today and tomorrow . i 'm gonna finish it today , hopefully . i wanna do one of those things where i stay here . cuz if i go home , i can't finish it . i 've tried about five times far , where i work for a while and then i 'm like , i 'm hungry . go home , and then  either that or to myself , work at home . and then i try to work at home , but i fail miserably . like i ended up at blakes last night . no . i almost got into a brawl . but i did not finish the but i 've been looking into it . i th @ @ it 's not like it 's a blank slate . i found everything that i need and stu and at the b furthermore , i told jerry that i was gonna finish it before he got back .  we 'll see him definitely on tuesday for the next or , no , the meetings are on thursday .  we 'll see him next week . i was thinking about that .  i will try to work on the smartkom and i 'll if finish it today , i 'll help you with that tomorrow , if you work on it ? i don't have a problem with us working on it though ?  and it we just it wouldn't hurt to write up a paper , cuz then , was talking with nancy and nancy said , you don't know whether you have a paper to write up until you write it up .  and since jerry 's coming back , we can run it by him too .  is this a computer science conference or is it a i really can't keep a straight face doing anything . did ben harass you ? good . yes .  no you have to put it on exactly like that , put that those things over your ears like that . see the p how the plastic things ar arch out like that ? there we go . it hurts . it hurts real bad . is your mike on ?  will i ? but that don't they need to finish the formalism ? you said it was four thousand lines ? ","the basic idea would be to give allow the system to have intentions , it will d r assign values to all the nodes . yes . let 's see , it would be two to the thirty for every output node ? which is very th very large . but we can do randomized testing . which probabilistically will be good enough . i 'm gonna finish it today , hopefully . we just it wouldn't hurt to write up a paper , is this a computer science conference ","Setting up certain inputs in the Bayes-net would imply certain intentions, which would trigger dialogues. There is potential to make a conference paper out of presenting the current work and the project aspirations within a parsing paradigm. "
Bed013.B,"is that what you s i would say that 's closer to six pages actually . four thousand lines of ascii ? how many characters are on a line ? i got an email . keith is comfortable with us calling him "" keith "" . and he 'll put us up , too . potatoes .  no , y i don't think you got it . that 's the only that 's the question mark . don't you need to reduce it if it 's a or reduce it , if it 's a cognitive neuro you might get blacklisted . remember i came in and i started asking you about how we were sor going to sort out the decision nodes ? i remember you talking to me , just not what you said . there was like we needed to or in my opinion we need to design a bayes another sub bayes net it was whether we would have a bayes net on the output and on the input , or whether the construction was gonna be in the bayes net , a and outside of it , and that was related to what we were talking about .  what ?  i 've blocked every aspect of phil collins out of my mind . what are the dots ? i don't remember what the dots were .  i 'd never seen it before either . you can dynamically look up keys , and then grep , i was just dancing ,  we i don't hhh . i don't i don't see unde how we would be able to distinguish between the two intentions just from the g utterance , though . bef or , before we don't before we cranked it through the bayes net .  we would ?  but then it 's just a for every construction we have a node in the net , right ? and we turn on that node . and then given that we know that the construction has these two things , we can set up probabilities we can s define all the tables for ev for those i d don't like having characterizing the constructions with location and path , or li characterizing them like that . cuz you don't it seems like in the general case you wouldn't know how to characterize them . or , for when . there could be an interpretation that we don't have a node for in the it just seems like @ @ has to have node for the construction and then let the chips fall where they may . versus saying , this construction either can mean location or path . and , in this cas and since it can mean either of those things , it would light both of those up . thoughts ? questions ? answers ?   i change i changed my mind actually . i am great . when do you need to start wizarding ?  ","that 's the only that 's the question mark . i don't see unde how we would be able to distinguish between the two intentions just from the g utterance , though . bef or , before we don't before we cranked it through the bayes net . ",
Bed013.C,"     and like thirty input nodes or some  i don't really know . ooo , it 's just big . can't . an like what ? discourse . ouch . ",,
Bed013.D,"it 's great how the br brain does that .  the news for me is a , my forthcoming travel plans in two weeks from today ?  more or less ? i 'll be off to sicily and germany for a couple , three days . i 'm flying to sicily to drop off simon there with his grandparents . and then i 'm flying to germany t to go to a moku treffen which is the meeting of all the module responsible people in smartkom , and , represent ici and myself there . and that 's the actual reason . and then i 'm also going up to eml for a day , and then i 'm going to meet the very big boss , wolfgang walster , in saarbruecken and the system integration people in kaiserslautern and then i 'm flying back via sicily pick up my son come back here on the fourth of july . and and i 'm all the people at the airport will be happy to work on that day .  alitalia .  and that 's that bit of news , and the other bit of news is we had i was visited by my german project manager who a , did like what we did what we 're doing here , and b , is planning to come here either three weeks in july or three weeks in august , to actually work . with us . and we sat around and we talked and he came up we came up with a pretty strange idea . and that 's what i 'm gonna lay on you now . and it might be ultimately the most interesting thing for eva because she has been known to complain about the fact that the we do here is not weird enough . this is weird it should even make you happy . imagine if you will , that we have a system that does all that understanding that we want it to do based on utterances . it should be possible to make that system produce questions . if you have the knowledge of how to interpret "" where is x ? "" under given conditions , situational , user , discourse and ontological conditions , you should also be able to make that same system ask "" where is x ? "" in a sper certain way , based on certain intentions . in instead of just being able to observe phenomenon , and , guess the intention we might be able just to give it an intention , and make it produce an utterance .  and once you 've done that what we can do is have the system ask itself . and answer , understand the answer , ask something else , and enter a dialogue with itself . the ba basic the same idea as having two chess computers play against each other . you c if you want , you can have two parallel machines asking each other . what would that give us ? would a be something completely weird and strange , and b , i if you look the factors , we will never observe people let 's say , in wheelchairs under in under all conditions , when they say "" x "" , and there is a ride at the goal , and the parking is good , we can never collect enough data . it 's it 's not possible . but one could do some learning . if you get the system to speak to itself , you may find n break downs and errors and you may be able to learn . and make it more robust , learn new things . and there 's no end of potential things one could get out of it , if that works . and he would like to actually work on that with us .  i w see the generation bit , making the system generate something , is shouldn't be too hard . if we can get it to understand one thing , like our "" where is "" run through we can also , e make it say , or ask "" where is x ? "" or not . it 's i 've done generation and language production research for fo four and a half years . and it 's you 're right , it 's not the same as the understanding . it 's in some ways easier and some ways harder . nuh ? but , it 'd be fun to look at it , or into that question . it 's a pretty strange idea . and that 's but look at th eee , even what it would be the prior intention . let 's let 's say we have this no . let 's we have to we have some top down processing , given certain setting . now we change nothing , and just say ask something . right ? what would it ask ? it shur   n do we really need to do that ? because , s it 's i know it 's strange , but look at it look at our bayes net . if we don't have let 's assume we don't have any input from the language . right ? there 's also nothing we could query the ontology , but we have a certain user setting . if you just ask , what is the likelihood of that person wanting to enter some something , it 'll give you an answer . right ? that 's just how they are . and @ @ whatever that is , it 's the generic default intention . that it would find out . which is , wanting to know where something is , nnn and wanting i don't it 's gonna be , but there 's gonna be something that you can observe some user and context and ask , what 's the posterior probabilities of all of our decision nodes . ","and the other bit of news is we had i was visited by my german project manager and b , is planning to come here either three weeks in july or three weeks in august , to actually work . and he came up we came up with a pretty strange idea . imagine if you will , that we have a system that does all that understanding that we want it to do based on utterances . it should be possible to make that system produce questions . if you have the knowledge of how to interpret "" where is x ? "" under given conditions , situational , user , discourse and ontological conditions , you should also be able to make that same system ask "" where is x ? "" but one could do some learning . if you get the system to speak to itself , you may find n break downs and errors and you may be able to learn . it 's not the same as the understanding . if we don't have let 's assume we don't have any input from the language . right ? there 's also nothing we could query the ontology , but we have a certain user setting . if you just ask , what is the likelihood of that person wanting to enter some something , it 'll give you an answer . and @ @ whatever that is , it 's the generic default intention . that it would find out . you can observe some user and context and ask , what 's the posterior probabilities of all of our decision nodes . ","An idea for future work was suggested during the visit of the german project manager: the possibility to use the same system for language generation. Having a system able to ask questions could contribute significantly to training the belief-net. Setting up certain inputs in the Bayes-net would imply certain intentions, which would trigger dialogues. "
Bed013.D,"you could even say , "" let 's take all the priors , let 's observe nothing "" , and query all the posterior probabilities . it 's gonna tell us something . right ? and yes . and come up with posterior probabilities for all the values of the decision nodes . which , if we have an algorithm that filters out whatever the best or the most consistent answer out of that , will give us the intention ex nihilo . and that is exactly what would happen if we ask it to produce an utterance , it would be b based on that extension , ex nihilo , which we don't it is , but it 's there . we wouldn't even have to t to kick start it by giving it a certain intention or observing anything on the decision node . and whatever that that would lead to "" what is the castle ? "" , or "" what is that whatever "" . no what we actually then need to do is write a little script that changes all the settings , go goes through all the permutations , which is we did a didn't we calculate that once ? it 's a that 's n that 's nothing for those neural guys . they train for millions and millions of epochs .   it be it 's an idea that one could n run past , what 's that guy 's name ? he 's usually here . tsk . j jer jerj that 's the guy . we g and this is just an idea that 's floating around and we 'll see what happens . and what other news do i have ? we fixed some more things from the smartkom system , but that 's not really of general interest ,  questions ,  i 'll ask eva about the e bayes and she 's working on that . how is the generation xml thing ? no need to do it today or tomorrow even . do it next week or  but st   who knows . that 's good .  the paper .   you would say it 's funky    what 's your input ?   it seems to me that it 's more it 's both , right ? it 's cognitive , neural , psycho , linguistic , but all for the sake of doing computer science . it 's cognitive , psycho , neural , plausibly motivated , architectures of natural language processing . it seems pretty interdisciplinary , and w the keynote speaker is tomasello and blah blah ,  w the question is what could we actually do and keep a straight face while doing it . and i my idea is , you can say we have done a little bit and that 's this , and the rest is position paper , "" we wanna also do that "" . which is not too good . might be more interesting to do something like let 's assume we 're right , we have as jerry calls it , a delusion of adequacy , and take a "" where is x "" sentence , and say , "" we will just talk about this , and how we cognitively , neurally , psycho linguistically , construction grammar ally , motivated , envision understanding that "" . we can actually show how we parse it . that should be able to we should be able to come up with , a parse . it 's on , just put it on . you don you will suffer in hell , that . this is it .  it is . we 're talking about this alleged paper that we may , just ,  and brought forth the idea that we take a sentence , "" where is the powder tower "" , and we p pretend to parse it , we pretend to understand it , and we write about it . then we pretend to write about . it 's the whatever , architectures , where there is this conference , it 's the seventh already international conference , on neu neurally , cognitively , motivated , architectures of natural language processing . and the keynote speakers are tomasello , macwhinney ? we macwhinney ,   you wanna write something too . no no no . it 's like a  even neuro . psycho . you could look at the web site . i 'll and the ad and the deadline is the fifteenth of june . hey . plenty of time . it would be to go write two papers actually . and one from your perspective , and one from our peve per   i also think that if we write about what we have done in the past six months , we could craft a little paper that if it gets rejected , which could happen , doesn't hurt because it 's something we having it is a good thing . it 's a exercise , it 's i usually enjoy writing papers . it 's not i don't re regard it as a painful thing . and we should all do more for our publication lists . and . it just never hurts . and keith and or johno will go , probably . in case of it 's on the twenty second of september , in saarbruecken germany . what to write about . what is our what 's our take home message . what do we actually because it i don't like papers where you just talk about what you plan to do . it 's obvious that we can't do any evaluation , and have no we can't write an acl type paper where we say , "" we 've done this and now we 're whatever percentage better than everybody else "" . it 's far too early for that . but we can tell them what we think . that 's never hurts to try . and ","what we actually then need to do is write a little script that changes all the settings , go goes through all the permutations , didn't we calculate that once ? it be it 's an idea that one could n run past , we fixed some more things from the smartkom system , how is the generation xml thing ? it 's cognitive , neural , psycho , linguistic , but all for the sake of doing computer science . it 's cognitive , psycho , neural , plausibly motivated , architectures of natural language processing . might be more interesting to do something like let 's assume we 're right , and take a "" where is x "" sentence , and how we cognitively , neurally , psycho linguistically , construction grammar ally , motivated , envision understanding that "" . that should be able to we should be able to come up with , a parse . i also think that if we write about what we have done in the past six months , we could craft a little paper that if it gets rejected , which could happen , doesn't hurt it 's obvious that we can't do any evaluation , and have no we can't write an acl type paper where we say , "" we 've done this and now we 're whatever percentage better than everybody else "" . ",There is potential to make a conference paper out of presenting the current work and the project aspirations within a parsing paradigm. 
Bed013.D,"even that 's the time to introduce the new formalism that you guys have cooked up . it 's just like four pages . it 's not even a h  i don't know w did you look at it ? it depends on the format . no that 's that 's actually a problem . it 's difficu it 's more difficult to write on four pages than on eight . it 's just four thousand lines . i do i don't they don't want any they don't have a tex f style @ @ guide . they just want ascii . pure ascii lines , whatever . why , for whatever reason , i don't know . i don't know . very unspecific unfortunately . we 'll just then . it 's i d don't quote me on this . this is numbers i have from looking o  let 's wh what should we discuss this over tea and all of us look at the web ? i can't . i 'm wizarding today .  look at the web page and let 's talk about it tomorrow afternoon ? johno will send you a link .  and i 'm also flying i 'm flying to sicily next in a w two weeks from now , w and a week of business in germany . i should mention that for you . and otherwise you haven't missed much , except for a really weird idea , but you 'll hear about that soon enough . no , no . that is something for the rest of the gang to g change the watchband . it 's time to walk the sheep .  did you catch that allusion ? it 's time to walk the sheep ? it 's a presumably one of the watergate codes they anyways , th  don't make any plans for spring break next year . that 's that 's the other thing . we 're gonna do an int edu internal workshop in sicily . i 've already got the funding .  no , that 's that 's what it means .  too easy . ki too easy . mangos go everywhere . do kiwi . but coconut anana pineapple , that 's tricky , you have it would be the paper ha would have , in my vision , a flow if we could say , here is th the th here is parsing if you wanna do it c right , here is understanding if you wanna do it right , and without going into technical that would be clear , we would i mailed around a little paper that i have w we could say , this is no , see this , if you if you 're not around , and don't partake in the discussions , and you don't get any email , and su we could say this is what 's state of the art today . nuh ? and say , this is bad . nuh ? and then we can say , what we do is this .  and we and you can just point to the literature , you can say that construction based       this will be documenting what we think , and documenting what we have in terms of the bayes net and since there 's never a bad idea to document things , no ? that would be my , we should sketch out the details tomorrow afternoon ish , if everyone is around . i don't know . you probably wouldn't be part of it . you want ? think about it .  you may ruin your career forever , if you appear . and the other thing , we actually have we made any progress on what we decided , last week ? i 'm you read the transcript of last week 's meeting in red sh you 're up to dated caught up . we decided t that we 're gonna take a "" where is something "" question , and pretend we have parsed it , and see what we could possibly hope to observe on the discourse side . should i introduce it as sudo square ? we have to put this in the paper . if we write it . this is my only constraint . the th  the sudo square is , "" situation "" , "" user "" , "" discourse "" , right ? "" ontology "" .  whatever . is it ?   also he 's talking about suicide , and that 's not a notion i wanna have evoked . he is . the  we have tons of little things here , and we 've  these are our , whatever , belief net decision nodes , and they all contribute to these things down here . that 's edu . e our e you . we . us . in the moment it 's a bayes net . and it has fifty not yet specified interfaces . have taken care that we actually can build little interfaces , to other modules that will tell us whether the user likes these things and , n the or these things , and he whether he 's in a wheelchair or not ,   no , this is a rme core by agent design , i don't know . there 's different situation , user , d ontology . that 's here .  this includes the current utterance plus all the previous utterances . and i s i irena gurevich is going to be here end of july . she 's a new linguist working for eml . and what she would like to do is great for us . she would like to take the ent ontolog  we have discussed in terms of the eva  think of back at the eva vector , ","even that 's the time to introduce the new formalism that you guys have cooked up . look at the web page and let 's talk about it tomorrow afternoon ? don't make any plans for spring break next year . we 're gonna do an int edu internal workshop in sicily . i 've already got the funding . we could say this is what 's state of the art today . nuh ? and say , this is bad . nuh ? and then we can say , what we do is this . and you can just point to the literature , this will be documenting what we think , and documenting what we have in terms of the bayes net the sudo square is , "" situation "" , "" user "" , "" discourse "" , right ? "" ontology "" . these are our , whatever , belief net decision nodes , and they all contribute to these things down here . in the moment it 's a bayes net . and it has fifty not yet specified interfaces . have taken care that we actually can build little interfaces , to other modules that will tell us whether the user likes these things and , n the or these things , think of back at the eva vector , ","There is potential to make a conference paper out of presenting the current work and the project aspirations within a parsing paradigm. The focus should be the Bayes-net, to which all other modules interface. Situation, User, Discourse and Ontology feed into the net to infer user intentions. "
Bed013.D,"and johno coming up with the idea that if the person discussed the admission fee , in previously , that might be a good indication that , "" how do i get to the castle ? "" , actually he wants to enter . or , "" how do i get to x ? "" discussing the admission fee in the previous utterance , is a good indication .  we don't want a hard code , a set of lexemes , or things , that person 's filter , or search the discourse history . what would be is that if we encounter concepts that are castle , tower , bank , hotel , we run it through the ontology , and the ontology tells us it has admission , opening times , it has admission fees , it has this , it has that , and then we make a thesaurus lexicon , look up , and then search dynamically through the discourse history for occurrences of these things in a given window of utterances . and that might , give us additional input to belief a versus b . or e versus a .   the idea is even more general . the idea is to say , we encounter a certain entity in a in a utterance . le let 's look up everything we the ontology gives us about that entity , what it does , what roles it has , what parts , whatever it has . functions . and , then we look in the discourse , whether any of that , or any surface structure corresponding to these roles , functions aaa has ever occurred . and then , the discourse history can t tell us , "" , or "" no "" . and then it 's up for us to decide what to do with it . t we may think that if you say "" where is the theater "" , whether or not he has talked about tickets before , then we he 's probably wanna go there to see something . or "" where is the opera in par paris ? ,  lots of people go to the opera to take pictures of it and to look at it , and lots of people go to attend a performance . and , the discourse can tell us w what 's more likely if we to look for in previous statements . and we can hard code "" for opera , look for tickets , look for this , look for that , or look for mozart , look for thi "" but the smarter way is to go via the ontology and dynamically , then look up u     e ultimately that 's also what we wanna get at . that 's the correct way . we have to keep memory of what was the last intention , and how does it fit to this , and what does it tell us , in terms of the what we 're examining . and furthermore , we can idealize that , people don't change topics , but they do . but , even th for that , there is a student of ours who 's doing a dialogue act recognition module . we 're even in a position where we can take your approach , which is much better , as to say how do these pieces  how do these pieces fit together ?  and but , nevertheless . these are issues but we what we actually decided last week , is to , and this is , again , for your benefit is to pretend we have observed and parsed an utterance such as "" where is the powder tower "" , or "" where is the zoo "" , and specify what we think the output observe , out i input nodes for our bayes nets for the sub d , for the discourse bit , should be . that and i will then come up with the ontology side bits and pieces , that we can say , we always just look at this utterance . that 's the only utterance we can do , it 's hard coded , like srini , hand parsed , hand crafted , but this is what we hope to be able to observe in general from utterances , and from ontologies , and then we can fiddle with these things to see what it actually produces , in terms of output . we need to find out what the "" where is x "" construction will give us in terms of semantics and simspec type things .   no ! look at it this way , i  what did we decide . we decided the prototypical "" where is x "" , where we don't really know , does he wanna go there , or just wanna know where it is . the difference of "" where is the railway station "" , versus where "" where is greenland "" . nuh ? we 're not videotaping any of this .  but it yea nnn actually more m more the other way around . we wanted something that represents uncertainty we in terms of going there or just wanting to know where it is , some generic information . and this is prototypically @ @ found in the "" where is something "" question , surface structure , which can be p should be maps to something that activates both . the idea is to let 's have it fit nicely with the paper . the we wouldn't . that 's exactly what we want . we want to get no . we wouldn't .  what is this gonna exactly . what is the  it should be we have  i let 's assume we call something like a loc x node and a path x node . and what we actually get if we just look at the discourse , "" where is x "" should activate or should should be both , ","and johno coming up with the idea that if the person discussed the admission fee , in previously , that might be a good indication that , "" how do i get to the castle ? "" , actually he wants to enter . what would be is that if we encounter concepts that are castle , tower , bank , hotel , we run it through the ontology , and the ontology tells us it has admission , opening times , and then search dynamically through the discourse history for occurrences of these things in a given window of utterances . and furthermore , we can idealize that , people don't change topics , but , even th for that , there is a student of ours who 's doing a dialogue act recognition module . but we what we actually decided last week , is to , and this is , again , for your benefit is to pretend we have observed and parsed an utterance such as "" where is the powder tower "" , and specify what we think the output observe , out i input nodes for our bayes nets for the sub d , for the discourse bit , should be . that and i will then come up with the ontology side bits and pieces , and then we can fiddle with these things to see what it actually produces , in terms of output . ","Someone asking where the castle is after having asked about the admission fee, indicates that -given that the castle is open to tourists- they want to go there, as opposed to knowing its whereabouts. It was suggested that they start analysing what the Discourse and Ontology would give as inputs to the Bayes-net by working on simple utterances like ""where is X?"". "
Bed013.D,"whereas where is x located "" , we find from the data , is always just asked when the person wants to know where it is , and "" how do i get to "" is always asked when the person just wants to know how to get there . right ? we want to come up with what gets input , and how inter in case of a "" where is "" question . what would the outcome of your parser look like ? and , what other discourse information from the discourse history could we hope to get , squeeze out of that utterance ? define the input into the bayes net based on what the utterance , "" where is x "" , gives us . definitely have an entity node here which is activated via the ontology , where is x "" produces something that is s stands for x , whether it 's castle , bank , restroom , toilet , whatever . and then the ontology will tell us no . not where it is located , we have , a user proximity node here somewhere , e which tells us how far the user how far away the user is in respect to that entity .   you don't need to even do that . it 's just what would be @ @ observed in in that case .  that 's exactly what we 're looking for . you wouldn't . it 's the same . it will be the same . think r in here we have "" i 'll go there "" , right ? and we have our info on . in my c my case , this would make this happy , and this would make the go there happy . what you 're saying is we have a where x question , where x node , that makes both happy . right ? that 's what you 're proposing , which is , in my mind just as fine . if we have a construction node , "" where is x "" , it 's gonna both get the po posterior probability that it 's info on up , info on is true up , and that go there is true up , as which would be exactly analogous to what i 'm proposing is , this makes makes something here true , and this makes something also something here true , and this makes this true up , and this makes this true up as because we get tons of constructions because , people have many ways of asking for the same thing , and the system doesn't massage you , no . no .  precisely . that 's that 's w exactly . we have su we have specified two . the next one would be here , just for mood . the next one would be what we can squeeze out of the i don't know , we wanna observe the the length of the words used , and , or the prosody and g a and t make conclusions about the user 's intelligence . i don't know ,     u that 's exactly r why i 'm proposing it 's too early to have to think of them of all of these discourse things that one could possibly observe , let 's just assume human beings are not allowed to ask anything but "" where is x "" . this is the only utterance in the world . what could we observe from that ? in ter just "" where is x "" . and , but do it in such a way that we know that people can also say , "" is the town hall in front of the bank "" , that we need something like a w wh focus . nuh ? should be there , that , this the whatever we get from the if you can , definitely do , where possible . right ? if i if it 's not triggered by our thing , then it 's irrelevant , and it doesn't hurt to leave it out for the moment . but      think this is just a mental exercise . if you think about , focus on this question , how would you design that ? is it do you feel confident about saying this is part of the language already to detect those plans , and why would anyone care about location , if not , and forth . or do you actually , this is perfectly legitimate , and i would not have any problems with erasing this and say , that 's all we can activate , based on the utterance out of context . what ? and then the miracle that we get out the intention , go there , happens , based on what we know about that entity , about the user , about his various beliefs , goals , desires , blah blah . fine . but this is the thing , i propose that we think about , that we actually end up with nodes for the discourse and ontology that we can put them into our bayes net , never change them , we all there is "" where is x "" , and , eva can play around with the observed things , and we can run our better javabayes , and have it produce some output . and for the first time in th in the world , we look at our output , and and see whether it 's any good .    for me this is just a ba matter of curiosity , i wanna would like to look at what this ad hoc process of designing a belief net would actually produce . if we ask it where is something . and , it also h enables you to think about certain things more specifically , come up with interesting questions , to which you can find interesting answers . ","we want to come up with what gets input , and how inter in case of a "" where is "" question . what would the outcome of your parser look like ? and , what other discourse information from the discourse history could we hope to get , squeeze out of that utterance ? define the input into the bayes net based on what the utterance , "" where is x "" , gives us . if we have a construction node , "" where is x "" , it 's gonna both get the po posterior probability that it 's info on up , info on is true up , and that go there is true up , as which would be exactly analogous to what i 'm proposing is , this makes makes something here true , and this makes this true up , and this makes this true up as if you can , definitely do , if i if it 's not triggered by our thing , then it 's irrelevant , think this is just a mental exercise . focus on this question , how would you design that ? that we actually end up with nodes for the discourse and ontology that we can put them into our bayes net , and we can run our better javabayes , and have it produce some output . ","It was suggested that they start analysing what the Discourse and Ontology would give as inputs to the Bayes-net by working on simple utterances like ""where is X?"". With this addition, all input layers of the net would be functioning. "
Bed013.D,"and , additionally it might fit in really nicely with the paper . because if we want an example for the paper , i suggest there it is . th this might be a opening paragraph for the paper as saying , "" people look at kinds of at ambiguities "" , and in the literature there 's "" bank "" and whatever kinds of garden path phenomenon . and we can say , that 's all nonsense . a , a , these things are never really ambiguous in discourse , b , b , don't ever occur really in discourse , but normal statements that seem completely unambiguous , such as "" where is the blah "" , actually are terribly complex , and completely ambiguous . and what every everybody else has been doing far in has been completely nonsensical , and can all go into the wastepaper bin , and the only  and the only   overture , but , just not really i 'm eja exaggerating , but that might be , saying "" hey "" , some is actually complex , if you look at it in the vacuum and ceases to be complex in reality . and some that 's as that 's straightforward in the vacuum , is actually terribly complex in reality . would be also , bottom up linguistics , type message . versus the old top down school . i 'm running out of time .  at four ten . this is the other bit of news . the subjects today know fey , she can't be here , and do the wizarding . 'm gonna do the wizarding and thilo 's gonna do the instructing . also we 're getting a person who just got fired from her job . person from oakland who is interested in continuing the wizard bit once fey leaves in august . and she 's gonna look at it today . which is good news in the sense that if we want to continue , after the thir after july , we can . we could . and , and that 's also interesting for keith and whoever , if you wanna get some more into the data collection . remember this , we can completely change the set up any time we want . look at the results we 've gotten far for the first , whatever , fifty some subjects ? no , we 're approaching twenty now . but , until fey is leaving , we surely will hit the some of the higher numbers . and that 's can a do more funky  we have found someone here who 's hand st hand transcribing the first twelve . first dozen subjects just we can build a language model for the recognizer . but , those should be available soon . the first twelve . and ch st e but you can listen to a y you can listen to all of them from your solaris box . if you want . it 's always fun . ","th this might be a opening paragraph for the paper as saying , "" people look at kinds of at ambiguities "" , a , these things are never really ambiguous in discourse , b , but normal statements that seem completely unambiguous , such as "" where is the blah "" , actually are terribly complex , and completely ambiguous . also we 're getting a person who just got fired from her job . person from oakland who is interested in continuing the wizard bit once fey leaves in august . remember this , we can completely change the set up any time we want . look at the results we 've gotten far for the first , whatever , fifty some subjects ? no , we 're approaching twenty now . but , until fey is leaving , we surely will hit the some of the higher numbers . we have found someone here who 's hand st hand transcribing the first twelve . ",
Bed013.E,"as usual . something 's not right here . what a great time to be coming back to the you 'll see see the fireworks from your plane coming in .  you 'll get even better service than usual . great .   except this smacks a little bit more of a schizophrenic computer than ai . that 's good .  right , right . no problem . i don't know . e i 'm have the impression that getting it to say the right thing in the right circumstances is much more difficult than getting it to understand something given the circumstances and on , just cuz it 's harder to learn to speak correctly in a foreign language , rather than learning to understand it . right ?  just the fact that we 'll get that getting it to understand one construction doesn't mean that it will n always know exactly when it 's correct to use that construction . right ?  nnn ,  you 're not gonna are you gonna get a variety of intentions out of that then ? you 're just talking about like given this user , what 's the th what is it what is that user most likely to want to do ? and , have it talk about   i don't know if that 's right or not . th that 's big . that 's just that 's it 's a billion , right ? right . argh .  that 's big .  alright . is it t comes to twenty billion that 's pretty big , though . i remember there being some other one floating around . but anyway , it 's g anyway , that given all of these different factors , it 's it 's still going to be impossible to run through all of the possible situations or whatever . but this 'll get us a bit closer at least , right ?   long ! tah dah ! here in the group ? jerry feldman . i that would the g the bald guy . i 'm not going back .  non conducive . that 's approaching . he 's coming back when ? next  alright .   i don't have much experience with conference papers for compu in the computer science realm , and when i looked at what you had , which was complete submission , said what just i didn't really to do with it , like , this is the the basic outline of the system or whatever , or or "" here 's an idea "" , right ? that 's what that paper was , "" here 's one possible thing you could do "" , short , eight pages , and don't you have in mind for expanding . like i 'd i what i didn't do is go to the web site of the conference and look at what they 're looking for or whatever . right . setting that aside .   right . backwards . there 's a s diagram somewhere which tells you how to put that but that 's what you get for coming late to the meeting .   about how all of these things the submitting to a major international conference .   why , we 've got over a week !  just what would one possibly put in such a paper ? are in the process of   my gosh . you were we were talking about something which was much more like ten   that would be hard . four thousand lines . isn't a isn't it about fifty s fifty five , sixty lines to a page ? he decided i 'm chilling in the five one o .   i got this from the two one two .  the thing with the goats and the helicopters ? no .  shoot . we 'll see .   but we have to decide what the general idea of  we 're gonna have an example case right ? i m to like this "" where is "" case ,   l looking at looking at that paper that you had , you didn't really explain in detail what was going on in the xml cases or whatever you just sorta said here 's the general idea , some gets put in there . hopefully you can say something like constituents tells you what the construction is made out of , without going into this intense detail .  give them the one paragraph whirlwind tour of w what this is for , and  saw the diagram in the office , way ! god , i hope not . like "" sussudio "" , that horrible , horrible song that should never have been created . in here  it sounds too rocking for that . anyway . what 's going on here ? what are what was wollte der kuenstler uns damit sagen ? those are little bugs . that 's a c that 's cuz things fit onto that , see ? in a vaguely obscene fashion .  what a what are these letters again , situr situation , user , discourse and ontology . it 's discourse is all things linguistic ,  since this technical is going over my head , that you that when someone 's talking about a castle , that it 's the thing that people are likely to wanna go into ? or , is it the fact that if there 's an admission fee , then one of the things we know about admission fees is that you pay them in order to go in ? and then the idea of entering is active in the discourse and then blah blah ?      no , go ahead .       but you 're still doing look up that when the person that when the person says , "" where is it ? "" then you say , let 's go back and look at other things and then decide , rather than the other possibility which is that all through discourse as they talk about different things like w ","e i 'm have the impression that getting it to say the right thing in the right circumstances is much more difficult than getting it to understand something given the circumstances and on , just the fact that we 'll get that getting it to understand one construction doesn't mean that it will n always know exactly when it 's correct to use that construction . right ? it 's g anyway , that given all of these different factors , it 's it 's still going to be impossible to run through all of the possible situations or whatever . what would one possibly put in such a paper ? ",
Bed013.E,"prior to the "" where is it "" question they say , "" how much does it cost to get in , to see a movie around here "" , "" where is the closest theater "" that by mentioning admission fees , that just stays active now . that becomes part of like , their current ongoing active conceptual structure . and then , over in your bayes net or whatever , when the person says "" where is it "" , you 've already got , since they were talking about admission , and that evokes the idea of entering , then when they go and ask "" where is it "" , then you 're enter node is already active because that 's what the person is thinking about . that 's the cognitive linguistic y way , and probably not practical .    right .   and much harder to r program . and much harder to p to program .  we were  we 're supposed to we 're talking about anything that has the semantics of request for location , right ? actually ? or , anyway , the node in the the ultimate , in the bayes net thing when you 're done , the node that we 're talking about is one that says "" request for location , true "" , like that , right ? and exactly how that gets activated , like whether we want the sentence "" how do i get there ? "" to activate that node or not , that 's the issue that the linguistic y side has to deal with , right ?   alright , oy .  i 'm thinking about it .  i kinda like it better without that extra level of indirection too . with this points to that , and on because i don't know , it       right , th this it 's not that this is like semantically ambiguous between these two . it 's really about this but why would you care about this ? it 's because you also want to know this , like that right ?    right .  here 's hoping . here 's hoping . right ? now cross your fingers .       that 's always a good way to begin . all others are useless . that 's good .   true .     i 'll have to look more into that data . is that around ? like , cuz that 's getting posted right away when you get it ? or ? it has to be transcribed ,      that i looked at the first one and got enough data to keep me going for , probably most of july . but , a probably not the right way to do it actually .  right . ",i kinda like it better without that extra level of indirection too . ,
Bed014.A,"that 's good to know . but i will not give them to you unless you come into my lair . the usual party voices .   this is something you ha you get used to as a programmer , right ? and it 's it works out that way . where  what thing is this ?  and on . it was written by committee . right .     like i solved the problem of we were talking about how do you various issues of how come a plural noun gets to quote "" count as a noun phrase "" , occur as an argument of a higher construction , but a bare singular stem doesn't get to act that way .  and it would take a really long time to explain it now , but i 'm about to write it up this evening . i solved that at the same time as "" how do we keep adjectives from floating to the left of determiners and how do we keep all of that from floating outside the noun phrase "" to get something like "" i the kicked dog "" .  did it at once . it 'll be a similar thing . right .     same thing . alright . right . i do .  knows .   there 's the group as a whole knows but no individual member kno   hunh ! what was the date there ? monday or ? it 's a friday . end of next week . you said beginning of n  i have a busy weekend but after that gung ho . great ,    but at least try and work out what the state of the art is right now .   what was supposed to happen ? i 've been actually caught up in some other ones , i don't have a write up of or i haven't elaborated on the ideas that we were already talking about which were it 's gone . the question of whether the polysemy is like in the construction or pragmatic . it has to be the second case . ' you is it clear what we 're talking about here ? the question is whether the construction is semantic or like ambiguous between asking for location and asking for path .  or whether the construction semantically , is clearly only asking for location but pragmatically that 's construed as meaning "" tell me how to get there "" .   right .   right , this one is in the gray area . is it like that or is it just obvious from world knowledge that no one you wouldn't want to know the location without wanting to know how to get there or whatever .  the question is is this conventional or conversational implicature ? right . which of that is .   if someone mentions admission f fees , that activates an enter schema which sticks around for a little while in your rep in the representation of what 's being talked about . and then when someone asks "" where is x ? "" you 've already got the enter schema activated and you 're able to conclude on it .  right .     no ,   right .   "" here 's my plan for today . here 's my plan for tomorrow . "" hypothetically .      there 's a few of us around now .     it seems to always land in your category . you 're lucky .  made it much easier to make these decisions .  right , right . yes . excuse me .  anyhow . always good .  that 's normal . good . either way .  it 's i is it staying at the wednesday noon ? it was th off this week ,  to tell you the truth , i 'd rath i 'd , i 'd would like to avoid more than one icsi meeting per day , if possible . but i don't know . whatever . understand that .     next week . that 's right . that doesn't apply to a that should be relatively flexible be there 's just the two to four of us . right ?   and , nancy and i are just always talking anyway and sometimes we do it in that room .  all of the proposed times sound fine with me . earlier in the week   sounds great . that 's the eighteenth . exactly . two pm . alright .    why don't w you and i should meet more or less first thing monday morning and then we can work on this .  through the weekend because kate has a photography show .  if you have time after this i 'll show you the noun phrase thing .  alright .   oy , deadlines . someday we also have to we should probably talk about the other side of the "" where is x "" construction , which is the issue of , how do you simulate questions ? what does the simspec look like for a question ? because it 's a little different . we had to we had an idea for this which seemed like it would probably work .   it 's more general  it 's good for you .      i to tell you the truth , what i 've been looking at has not been the data far , said "" alright let 's see if get noun phrases and , major verb co constructions out of the way first . "" and i have not gotten them out of the way yet . surprise .  i have not really approached a lot of the data , but like these the question one , since we have this idea about the indefinite pronoun thing and all that , i ca can try and , run with that , try and do some of the sentence constructions now . it would make sense . the basic idea is that  let 's see if formulate this .  means . ","the question of whether the polysemy is like in the construction or pragmatic . the question is whether the construction is semantic or like ambiguous between asking for location and asking for path . or whether the construction semantically , is clearly only asking for location but pragmatically that 's construed as meaning "" tell me how to get there "" . the question is is this conventional or conversational implicature ? that 's the eighteenth . two pm . someday we also have to we should probably talk about the other side of the "" where is x "" construction , which is the issue of , how do you simulate questions ? since we have this idea about the indefinite pronoun thing and all that , i ca can try and , run with that , try and do some of the sentence constructions now . ","The constructions could be built assuming either conventional or conversational implicature. This module will eventually have to include ways to simulate questions, do emphasis and focus. "
Bed014.A,"the wh question has this as extra thing which says "" and when you 're done , tell me who fills that slot "" or w  and , this is way to do it , the idea of saying that you treat from the simulation point of view or whatever you treat , wh constructions similarly to indefinite pronouns like "" someone fixed the car "" because lots of languages , have wh questions with an indefinite pronoun in situ or whatever , and you just get intonation to tell you that it 's a question . it makes sense    shko   right . no . that 's right . it makes sense from that point of view , too , which is actually better .  anyway , but just that thing and we 'll figure out exactly how to write that up and on , but no , all the focus we just dropped that cuz it was too weird and we didn't even we were talking about exactly , what the object of study was .     then certainly we will . good . w we should figure out what our questions are , to ask you .      sometimes hans has been coming in there as like a devil 's advocate type role like "" this make i 'm going to pretend i 'm a linguist who has nothing to do with this . this makes no sense . "" and he 'll just go off on parts of it which definitely need fixing but aren't where we 're at right now , it 's               no , right . tha that role is , indispensable but that 's not where our heads were at in these meetings . it was a little strange .  don't his take will be on these meetings exactly , cuz sometimes he sounds like we 're talking a bunch of goobledy gook from his point of view .           shoot . bummer . ","the wh question has this as extra thing which says "" and when you 're done , tell me who fills that slot "" or w the idea of saying that you treat from the simulation point of view or whatever you treat , wh constructions similarly to indefinite pronouns and we 'll figure out exactly how to write that up and on , no , all the focus sometimes hans has been coming in there as like a devil 's advocate type role and he 'll just go off on parts of it which definitely need fixing ","This module will eventually have to include ways to simulate questions, do emphasis and focus. "
Bed014.B," mental palm pilot . right . hence no problem . hello i 'm channel one .  but mine is correct . it 's one . channel one .    but your p no , but the paper 's correct . look at the paper .   yes , you 've bested me again . that 's how of our continuing interaction . damn ! foiled again ! he 'll probably come later . forge ahead . are you in charge ? hiring somebody .   better .    i didn't know she spoke german .  rewrite the german ones into english . got it . got it .  wh which one ?  festival ? got it . i know . that doesn't sound , exactly right either .  let 's just pick whatever sounds best . whatever sounds best . unfortunately , probably male voices , a bit more research on .  oregon graduate insti  that 's good . i know . tha that 's the part i didn't understand .  will it work again , or ? where the "" where is "" construction is . i didn't know about it until robert told me y i was like , why didn't dan tell me ? it 's hard . it 's hard .    i was really strong . seems and not even all of them really do . but like right . communication ! communication . but , but the two of us will probably talk to you at before th  anyway , w let 's talk separately about how t  right . one of them was th right . right . i agree . you might be y and asking for directions .   slightly different . good .  right . or have every construction list all the possible pragmatic implications of the same one . right .  request . very  might be , right . right . which one it is . cuz there will be other k examples that are one way or the other . right . priming priming a spreading activation turn prior on . it would already be higher in the context . relevance .  renew  right . when you admit have admission fee and it changes something , it 's only for that particular it 's relational , right ? it 's only for that particular object .  right . of that object . for but right . forward chaining in a way , rather than backward .   guess it 's like i g the other thing is , whether you have a m user model that has , whatever , a current plan , whatever , plans that had been discussed , and i don't know ,   s yay , it 's not me . it 's always me when it 's someone 's thesis . now it 's not . yay ! i know it is . he said he 's gonna f finish his thesis by then . we 've done quite a bit of that . we 've been doing quite a bit of that . we have many jobs for you , ro robert . the conclusion .  no , you weren't there on purpose . like   no , they 're decisions .  actually , there 's a problem with that word , too , though . i 'll just pick a piece of the problem and then just push the hard into the center and say it 's robert 's . like .  i haven't . i didn't get it 's good i didn't read it . really ? bomb proof !  both . good luck . really . usually , he can . i always thought it was staying . it was just this week that we were changing it . those people who happen to be around . i 'm always here anyway ,  it doesn't matter .   did you just say that ami can't make one o '    could we do thursday at one thirty ? would that be horrible ? really ? you didn't tell me that . that 's fine .  we 're meeting tuesday . we usually meet tuesday or l like , linguists at two .  do you want to meet again here bef hhh . do need a palm pilot . usually ? the linguists ' meeting i happens to be at two , but that 's pretty flexible ,  the multiple meetings  right .  same here . what time ? at o one , two , three ? you guys will still remind me , right ? y you 'll come and take all the headph the good headphones first and then remind me . why do i have this unless i 'm gonna write ? fine . yes . would you like to ? i was actually gonna work on it for tomorrow like this weekend .  i  i i there was like , m in my head the goal to have like an intermediate version everything i know . and then , w i would talk to you and figure out everything that see if they 're consistent . yes . that 's f fine with me .  i might s you said you 're busy over th until the weekend , right ? that 's fine . we might continue our email thing and that might be fine , too . 'll send you some that would be  and we 'll you wanna m that 's for you  that 's cuz then you 'll find out more of what we 're making you do . we 'll make a presentation of your propo of your proposal . it 's like , "" this is what we 're doing . and the complement is robert . ""  i already sent you my fi my bib file .   i i only have to change one vowel . that 's great . all the old like graphs , just change the just mark out the  we 've talked a little bit about that , too , which ",you might be y and asking for directions . priming a spreading activation ,One suggestion was to use the spreading activation as a paradigm for activating nodes in the belief-net. 
Bed014.B,"it 's hard for me to figure out with our general linguistic issues , how they map onto this particular one , but understood . w do you have data , like the you have preliminary data ? cuz i know , we 've been using this one easy sentence and i 'm you guys have you are the one who 've been looking at the rest of it it 'd be useful for me , if we want to have it a little bit more data oriented .      use actually the same one .  right . let 's put a skolem constant in ,  right .    you should definitely , be on that by after monday we 'll y you can see what things we are and aren't   he 's been around . just not today . with us ?  i would say that tha that those discussions have been primarily , keith and me , but like in th the meeting he thin like the last meeting we had , we were all very much part of it but but different perspec  right . like what you call certain things , which we decided long ago we don't care that much right now . but in a sense , it 's good to know that he of all people like lot of people would have m much stronger reactions , he 's like a relatively friendly linguist and yet a word like "" constraint "" causes a lot of problems . and , right .     it 's good when we 're when we 're into data and looking at the some specific linguistic phenomenon in english or in german , in particular , whatever , that 's great , and ben and hans are , if anything , more they have more to say than , let 's say , i would about some of these things . but when it 's like , w how do we capture these things , it 's definitely been keith and i who have d who have worried more about the s which is fine .  yes . we actually have we have been making progress , and its surprising . like  anyone else would like ruin the balance of anyway . right . we could talk tomorrow . i was just gonna say , though , that , there was out of a meeting with johno came the suggestion that "" could it be that the meaning constraints really aren't used for selection ? "" which has been implicit in the parsing strategy we talked about . in which case we w we can just say that they 're the effects or the bindings . which far , in terms of like putting up all the constraints as , pushing them into type constraints , the when i 've , propo then proposed it to linguists who haven't yet given me we haven't yet thought of a reason that wouldn't work . right ? as long as we allow our type constraints to be reasonably complex . anyway , to be to talk about later .     that it would still generate too many . right ? by just having semantic even bringing semantics in for matching just in the form of j semantic types , right ? like "" conceptually these have to be construed as this , and this "" might still give us quite a few possibilities that , and it certainly helps a lot . le let 's put it that way .   friday , monday monday . that 's tuesday . like th that 's the conclusion . and i have nothing to do this weekend but work . no , that 's not really true , but like it 's almost true . i don't have it this weekend , tsk don't have to worry about that . speaking of dance , dance revolution i can't believe i 'm it 's a it 's like a game , but it 's for dancing . hard to it 's like karaoke , but for dancing , and they tell you what it 's amazing . it 's much fun . it 's good . my friend has a home version and he brought it over , and we are into it . it 's amazing . y of it ? i it 's one of your hobbies ? it 's great exercise , i must say . i can't to hear this .  definitely . they have places instead of like instead of karaoke bars now that have ddr , like i didn't until i started hanging out with this friend , who 's like "" bring over the ddr if you want . "" dance revolution he actually brought a clone called stepping selection , but it 's just as good .  anyw ","he 's been around . but different perspec when we 're into data and looking at the some specific linguistic phenomenon in english or in german , in particular , whatever , that 's great , but when it 's like , w how do we capture these things , it 's definitely been keith and i who have d who have worried more about the i was just gonna say , though , that , there was out of a meeting with johno came the suggestion that "" could it be that the meaning constraints really aren't used for selection ? "" which has been implicit in the parsing strategy we talked about . which far , in terms of like putting up all the constraints as , pushing them into type constraints , the when i 've , propo then proposed it to linguists who haven't yet given me we haven't yet thought of a reason that wouldn't work . right ? as long as we allow our type constraints to be reasonably complex . ","Finally, using type constraints in the construction analysis should work, as long as they are complex enough not to generate too many parses. "
Bed014.C,"nnn , it 's n it 's always offset . what he he 's probably not , is my guess .  right . this is not it 's not bad for the project if keith is talking to george . my suggestion is we just forge ahead ,  he charges much . right . no , it 's a good idea that you may as ask .  you were gonna send me a note about hiring i didn't finish the sentence but he understood it .  but nancy doesn't . no . syntax .  anyway , it we 'll sort this out .  but anyway , send me the note and then i 'll i 'll check with , morgan on the money . i don't anticipate any problem but we have to ask . this was on the generation thing ,  if sh y she 's really going to do that , then we should be able to get prosody as it 'll say it 's nonsense with perfect intonation . it 's the name of some program , the synthesizer . orego or oregon @ @ graduate institute it turns out there 's the long standing links with these guys in the speech group . very long . there 's this guy who 's got a joint appointment , hynek hermansky . he 's spends a fair amount of time here . anyway . leave it . won't be a problem . i did .   i it i it 's fine . anyway .  but c the meeting looks like it 's , it 's gonna be good .  it 's i ra i ran across it in i don't even know where , some just some weird place . and , i 'm surprised i didn't know about it since we know all the invited speakers , an right , or some anyway . but anyway ,  i did see that . wha before we get started on this st also had a email correspondence with daphne kohler , who said yes she would love to work with us on the , using these structured belief nets and but starting in august , that she 's also got a new student working on this and that we should get in touch with them again in august and then we 'll figure out a way for you you to get connected with , their group .  that 's , looks pretty good . and i 'll say it now .  and it looks to me like we 're now at a good point to do something start working on something really hard . we 've been far working on things that are easy . w which is mental spaces and and or  it 's a hard puzzle . but the other part of it is the way they connect to these , probabilistic relational models . there 's all the problems that the linguists know about , about mental spaces , and the cognitive linguists know about , but then there 's this problem of the belief net people have only done a moderately good job of dealing with temporal belief nets . which they call dynamic they incorrectly call dynamic belief nets . there 's a term "" dynamic belief net "" , doesn't mean that . it means time slices . and srini used those and people use them . but one of the things i w would like to do over the next , month , it may take more , is to st understand to what extent we can not only figure out the constructions for them for multiple worlds and what the formalism will look like and where the slots and fillers will be , but also what that would translate into in terms of belief net and the inferences . the story is that if you have these probabilistic relational models , they 're set up , in principle , that you can make new instances and instances connect to each other , and all that it should be feasible to set them up in such a way that if you 've got the past tense and the present tense and each of those is a separate belief structure that they do their inferences with just the couplings that are appropriate . but that 's g that 's , as far as tell , it 's putting together two real hard problems . one is the linguistic part of what are the couplings and when you have a certain , construction , that implies certain couplings and other couplings , between let 's say between the past and the present , or any other one of these things and then we have this inference problem of exactly technically how does the belief net work if it 's got let 's say one in , different tenses or my beliefs and your beliefs , or any of these other ones of multiple models .  in the long run we need to solve both of those and my suggestion is that we start digging into them both , in a way we that , th hopefully turns out to be consistent , that the  and sometimes it 's actually easier to solve two hard problems than one because they constrain each other . if you 've got huge ra huge range of possible choices  we 'll see . but anyway , that 's , right . that 's great .  no , i know , i th that is gonna be the key to this wh to th the big project of the summer of getting the constructions right is that people do manage to do this there probably are some , relatively clean rules , they 're just not context free trees . and if we if the formalism is good , then we should be able to have , moderate scale thing . and that is , keith , what i encouraged george to be talking with you about . not the formalism yet ","also had a email correspondence with daphne kohler , who said yes she would love to work with us on the , using these structured belief nets and and then we 'll figure out a way for you you to get connected with , their group . and it looks to me like we 're now at a good point to do something start working on something really hard . w which is mental spaces and and or but the other part of it is the way they connect to these , probabilistic relational models . there 's all the problems that the linguists know about , about mental spaces , and the cognitive linguists know about , but then there 's this problem of the belief net people have only done a moderately good job of dealing with temporal belief nets . one of the things i w would like to do over the next , month , it may take more , is to st understand to what extent we can not only figure out the constructions for them for multiple worlds and what the formalism will look like and where the slots and fillers will be , but also what that would translate into in terms of belief net and the inferences . but that 's g that 's , as far as tell , it 's putting together two real hard problems . one is the linguistic part of what are the couplings and when you have a certain , construction , that implies certain couplings and other couplings , and then we have this inference problem of exactly technically how does the belief net work no , i know , i th that is gonna be the key to this wh to th the big project of the summer of getting the constructions right is that people do manage to do this there probably are some , relatively clean rules , ","An important research issue to be investigated is how the concept of mental spaces and probabilistic relational models can be integrated into the belief-net. A step towards this goal is the construction formalism being put together. Mental space interdependencies are based on relatively clean rules, since people seem to manage them easily. "
Bed014.C,"but the phenomena . the p and another thing ,  there was this , thing that nancy to in a weak moment this morning that in a friendly moment . anyway , that we were that we 're gonna try to get a first cut at the revised formalism by the end of next week .  probably skipping the mental spaces part . just trying to write up essentially what you guys have worked out that everybody has something to look at . we 've talked about it , but only the innermost inner group currently , knows , right . that th there 's one of the advantages of a document , right ? , is that it actually transfers from head to head . anyway .   communication , documentation and anyway , with a little luck let 's , let 's have that as a goal anyway . and no , no . no , w we 're talking about a week fr e end of next week . someti sometime next week . now if it turns out that effort leads us into some big hole that 's fine . if you say we 're dump . there 's a really hard problem we haven't solved yet that , that 's just fine . right , t if to the extent that we have it , let 's write it and to the extent we don't , let 's find out what we need to do .  it is , but but i interrupted before keith got to tell us what happened with "" where is the powder tower ? "" or whatever    right . that 's a s that 's a separate issue . a i th i agree with you that , it 's a disaster to try to make separate constructions for every pragmatic reading , although there are some that will need to be there . there 's some that you can't do that either .  but , c almost certainly "" can you pass the salt "" is a construction worth noting that there is this th this ri   exactly . and see , the more important thing at this stage is that we should be able to know how we would handle it in ei f in the short run it 's more important to know how we would treat technically what we would do if we decided a and what we would do if we decided b , than it is t to decide a or b r right now . w we know for that we have to be able to do both . guess in the short run , let 's be real clear on h what the two alternatives would be . it was terrible .   right . that 's certainly more realistic . i m psychologically . now technically   you could do that .  but here 's a way in th in the bl bayes net you could think about it this way , that if at the time "" admissions fee "" was mentioned you could increase the probability that someone wanted to enter . fair enough , but , in terms of the c the current implementation right ? that  th that th the conditional probability that someone at the time you mentioned it this is essentially the bayes net equivalent of the spreading activation . it 's in some ways it 's not as good but it 's the implementation we got . we don't have a connectionist implementation . now my guess is that it 's not a question of time but it is a question of whether another intervening object has been mentioned . we could look at dialo this is the other thing we ha we do is , is we have this data coming which probably will blow all our theories , but skipping that but my guess is what 'll probably will happen , here 's a proposed design . is that there 're certain constructions which , for our purposes do change the probabilities of eva decisions and various other kinds and th that the , standard way that the these contexts work is stack like or whatever , but that 's the most recent thing . and it could be that when another en tourist entity gets mentioned , you re essentially re initiali re i essentially re initialize the state . and if we had a fancier one with multiple worlds you could have you could keep track of what someone was saying about this and that . "" i wanna go in the morning i wanna "" or in the morning i 'm planning t to go shopping , in the afternoon to the powder tower tal 'm talking about shopping and then you say , what 's it cost ? "" or anyway . one could imagine , but not yet . but i do th think that the it 'll turn out that it 's gonna be depend on whether there 's been an override .  right . right . i th  and the simple idea is that it 's on it 's only for m for the current tourist e entity of instre interest . no , no . it 's it goes the other d it goes in the other direction . is when th when the this is mentioned , the probability of , let 's say , entering changes changes .   now , but ro robert 's right , that to determine that , you may want to go through a th thesaurus and if the issue is , if now th this construction has been matched and you say "" does this actually have any implications for our decisions ? "" then there 's another piece of code that presumably does that computation .  but what 's robert 's saying is , and he 's right , is you don't want to try to build into the construction itself all the synonyms and all all the wo   ","anyway , that we were that we 're gonna try to get a first cut at the revised formalism by the end of next week . just trying to write up essentially what you guys have worked out that everybody has something to look at . but but i interrupted before keith got to tell us what happened with "" where is the powder tower ? "" or whatever a i th i agree with you that , it 's a disaster to try to make separate constructions for every pragmatic reading , although there are some that will need to be there . f in the short run it 's more important to know how we would treat technically what we would do if we decided a and what we would do if we decided b , than it is t to decide a or b r right now . w we know for that we have to be able to do both . in th in the bl bayes net you could think about it this way , that if at the time "" admissions fee "" was mentioned you could increase the probability that someone wanted to enter . but my guess is what 'll probably will happen , here 's a proposed design . is that there 're certain constructions which , for our purposes do change the probabilities of eva decisions and various other kinds th that the , standard way that the these contexts work is stack like or whatever , and it could be that when another en tourist entity gets mentioned , you re essentially re initiali re i essentially re initialize the state . and if we had a fancier one with multiple worlds you could have you could keep track of what someone was saying about this and that . now , but ro robert 's right , that to determine that , you may want to go through a th thesaurus if the issue is , if now th this construction has been matched and you say "" does this actually have any implications for our decisions ? "" then there 's another piece of code that presumably does that computation . ",At this stage both routes need to be examined. 
Bed014.C,"i 'll have to think about that . i don't know . it th thi think of arguments in either direction on that . but somehow you want to do it . wel the ar the argument is that you 're gonna have the if you 've recognized the word , you 've recognized the word , which means you have a lexical construction for it , you could just as tag the lexical construction with the fact that it 's a thirty percent increase in probability of entering . you you could you could invert the whole thing , you s you tag that information on to the lexicon since you had to recognize it anyway . that 's the argument in the other direction . at and this is there 's , ther there 's that as good . this is highly relevant to someone 's thesis . you 've noticed that .  it 's very likely that robert 's thesis is going to be along these lines , and the local rules are if it 's your thesis , you get to decide how it 's done . if , if this is if this becomes part of your thesis , you can say , hey we 're gonna do it this way , that 's the way it 's done . no , no ! no , no . we 've got a lot of theses going .  right . right . he 's got a th he 's got a meet meeting in germany with his thesis advisor . right .  think that 's the other thing . this is this is , speaking of hard problems , this is a very good time to start trying to make explicit where construal comes in and where c where the construction per se ends and where construal comes in , cuz this is clearly part of th  said . but that 's part of what the f he 's gonna need this . right . right . thing that 's part of why we want the formalism , is because th it is gonna have implicit in it  right . that 's tentative . they aren't decisions , they 're ju they 're just proposals . that 's the point , is th  anyway . but that 's w  no .  right . we will , but not yes . right .  ri no . wh you had you ha you had done one draft . and a another draft  d i i i this is i 'm shocked . this is the first time i 've seen a thesis proposal change . right . anyway , but , a second that would be great . a sec you 're gonna need it anyway . and right .  both proof . right .  that , th thi this this is the point , is we 're going to have to cycle through this , but th the draft of the p proposal on the constructions is going to tell us a lot about what we think needs to be done by construal . and , we oughta be doing it . and the ntl meeting moved to wednesday , cuz of , you weren't here , but s and if that 's with you , you would it was th right .  the only disadvantage is that it may interfere with other s other no , you people in this group connecting with those people who might not be around much . i don't care . i have no fixed  no , that 's fine . that  people differ in their tastes in this matter . i 'm neutral . @ @ that 's me too . i 'm 'm here .   interesting . you 're proposing that we meet tuesday . i could  whate what robert 's saying is that earlier we at least for next week , there 's a lot of we want to get done , why don't we plan to meet monday and we 'll see if we want to meet any more than that . i i actually two is the earliest meet on monday . here i 'm blissfully agreeing to things and realizing that i actually do have some scheduled on monday . @ @ w mond we can put this is part of what we can do monday , if we want . is some version  abso  now , we w great . simspec may need we may n need to re name that . let 's think of a name for whatever the this intermediate structure is . we talked about semspec , for "" semantic spec specification "" and that seems  it 's a m minimal change . just right . right , a little substi that 's what text substitution macros are for . anyway , let 's for the moment call it that until we think of something better . and , we need to find part of what was missing were markings of all sorts that weren't in there , incl including the questions we didn't we never did figure out how we were gonna do emphasis in the semspec . but that 's part of the formalism is got to be how things like that get marked .  alright , which is skolemization . in logic , it 's it 's @ @ it 's actual what ? that 's not saying it 's bad , it 's just that that the logicians have , good . if i part of what the exercise is , t by the end of next week , is to say what are the things that we just don't have answers for yet . that 's fine .  wel then t hans . has i haven't seen hans boas ? has he been involved with this , or ?  right .  this is consistent with the role i had suggested that he play , ","it th thi think of arguments in either direction on that . you 've recognized the word , which means you have a lexical construction for it , you could just as tag the lexical construction with the fact that it 's a thirty percent increase in probability of entering . it 's very likely that robert 's thesis is going to be along these lines , and the local rules are if it 's your thesis , you get to decide how it 's done . this is this is , speaking of hard problems , this is a very good time to start trying to make explicit where construal comes in and where c where the construction per se ends and where construal comes in , right . right . thing that 's part of why we want the formalism , why don't we plan to meet monday and we 'll see if we want to meet any more than that . we talked about semspec , for "" semantic spec specification "" part of what was missing were markings of all sorts that weren't in there , incl including the questions we didn't we never did figure out how we were gonna do emphasis in the semspec . skolemization . if i part of what the exercise is , t by the end of next week , is to say what are the things that we just don't have answers for yet . has i haven't seen hans boas ? this is consistent with the role i had suggested that he play , ","At this stage both routes need to be examined. The formalism will also serve as a starting point for the definition of construal mechanisms. This module will eventually have to include ways to simulate questions, do emphasis and focus. "
Bed014.C,"which was that o one of the things i would like to see happen is a paper that was tentatively called "" towards a formal cognitive semantics "" which was addressed to these linguists who haven't been following this it could be that he 's actually , at some level , thinking about how am i going to communicate this story internally , we should just do whatever works , cuz it 's hard enough . but if he g if he turns is really gonna turn around and help t to write this version that does connect with as many as possible of the other linguists in the world then it becomes important to use terminology that doesn't make it hard it 's gonna be plenty hard for people to understand it as it is , but y you don't want to make it worse .  right . no , that 's fine . wanted t to i have to catch up with him , and i wanted t to get a feeling for that . good .  right . that 's good . that 's that should be the core group and that 's , very close to the maximum number of people working together that can get something done . i definitely get that impression . that 's great . but but th then w then we have to come back to the bigger group . great . and then we 're gon we 're gonna because of this other big thing we haven't talked about is actually implementing this that the three of us are gonna connect tomorrow about that . right . it it has to in the sense that you 're gonna use them eventu it 's it 's , generate and test thing , and if you over generate then you 'll have to do more . if there are some constraints that you hold back and don't use in your initial matching then you 'll match some things i d i don't think there 's any way that it could completely fail . it could be that you wind up  the original bad idea of purely context free grammars died because there were just vastly too many parses . exponentially num many parses . and th the concern might be that not that it would fail , but that it would still genera  we don't know , but , no question . and it 's a perfectly fine place to start . and say , let 's see how far we can go this way . and , i 'm in favor of that . cuz it 's as it 's real hard and if w if we right .  ddr , he asked ? ","which was that o one of the things i would like to see happen is a paper that was tentatively called "" towards a formal cognitive semantics "" which was addressed to these linguists who haven't been following this it could be that he 's actually , at some level , thinking about how am i going to communicate this story and if you over generate then you 'll have to do more . ",
Bed014.D,"testing . sibilance . sibilance . three , three . i am three . see , that matches the seat up there .  cuz it 's that starts counting from zero and these start counting from one . ergo , the classic off by one error . is it ? your mike number is what we 're t ho ! i 've bested you again , nancy . the paper is correct . i didn't det i was saying the microphone , not the paper . is keith showing up ? he 's talking with george right now . is he gonna get a rip rip himself away from that ? then it 's just gonna be the five of us ?  but that 's some conversion program ? you should demand things from him .  the trees for the xml trees for the gene for the synthesizer are written . just need to do the , write a new set of tree combining rules . but those 'll be pretty similar to the old ones .  just gonna be i he 's talking about . the guy . what language is that written i is that scheme thing that you showed me ? she knows how to program in scheme ? i hope ? if you 're not used to functional programming , scheme can be completely incomprehensible . cuz , there 's no like there 's lots of unnamed functions and  are we gonna can we change the voice of the thing , because right now the voice sounds like a murderer . the little smarticus smarticus sounds like a murderer . "" i have your reservations . "" does ogi stand for ? original german institute ?    how was this by accident ?  i wa i was looking at it . it doesn't follow logically . it doesn't the first paragraph doesn't seem to have any link to the second paragraph .  each paragraph is good , though . i li is it doesn't it seem like if you just managed the dialogue history with a thread , that kept track of ho of the activity of cuz it would the thread would nodes like , needed to be activated , it could just keep track of how long it 's been since something 's been mentioned , and automatically load it in . we th that 's what i wa i wasn't i was i wasn't thinking in terms of enter schemas . i was just  you could just hav just ob it observes an er , it sets the a node for "" entered "" or "" true "" "" discourse enter "" . what what 's the argument for putting it in the construction ? is it just that the s synonym selection is better , or ?  i see . but it he the decisions i made wer had to do with my thesis . consequently don't i get to decide then that it 's robert 's job ? would it and the s is the speech gen meeting still at on tuesdays ? although you wanted to go camping on monday er , take off mondays a lot you could go camping . ha ha . no way !  it definitely makes the problem easier .  what about ddr ?  ","the xml trees for the gene for the synthesizer are written . just need to do the , write a new set of tree combining rules . but those 'll be pretty similar to the old ones . if you 're not used to functional programming , scheme can be completely incomprehensible . what what 's the argument for putting it in the construction ? ",
Bed014.E,"what does your thing say on the back ? no . look at the back . he was very affirmative in his way of saying he will be here at four . but that was before he knew about that george lecture probably .    i had informal talks with most of you . eva just reported she 's really happy about the cbt 's being in the same order in the xml as in the be java declaration format you don't have to do too much in the style sheet transversion . the java the embedded bayes wants to take input a bayes net in some java notation and eva is using the xalan style sheet processor to convert the xml that 's output by the java bayes for the into the , e bayes input .  and , pretty mu on t on the top of my list , i would have asked keith how the "" where is x ? "" hand parse is standing . but we 'll skip that . there 's good news from johno . the generation templates are done . yes . we w natural language generation produces not a just a surface string that is fed into a text to speech but , a surface string with a syntax tree that 's fed into a concept to speech . now and this concept to speech module has certain rules on how if you get the following syntactic structure , how to map this onto prosodic rules . and fey has foolheartedly to rewrite the german concept syntax to prosody rules no , she doesn't . but she speaks english . into english . and therefore the ,  if it 's that we give her a couple of more hours per week , then she 'll do that .  that 's the lisp type scheme . no , i my guess is i asked for a commented version of that file ? if we get that , then it 's doable , even without getting into it , even though the scheme li is really documented in the festival . we ha we have to change the voice . it is we have the choice between the , usual festival voices , which i already told the smartkom people we aren't gonna use because they 're really bad . but , ogi has , crafted a couple of diphone type voices that are really and we 're going to use that . we can still , d agree on a gender , if we want . we still have male or female .   oregon . try oregon .   and it 's probably also uninteresting for all of you to , learn that as of twenty minutes ago , david and i , per accident , managed to get the whole smartkom system running on the icsi linux machines with the icsi nt machines thereby increasing the number of running smartkom systems in this house from one on my laptop to three . i suggested to try something that was really even though against better knowledge shouldn't have worked , but it worked . intuition . bit for the ai i intuition thing .  and , we 'll never found out why . it 's just like why the generation ma the presentation manager is now working ? which  the people at saarbruecken and i decided not to touch it ever again . that would work .  was gonna ask you where something is and what we know about that . where is x ?  but by we can ask , did you get to read all four hundred words ? was it was it ?  that  can we ? is it worth thinking of an example out of our tourism thing domain , that involves a decent mental space shift or setting up we already came to the conclusion that we have two alternative paths that we two alternative ways of representing it . one is has a   or comes is resolved later .   it 's should we have a assume these are two , nodes we can observe in the bayes net . these are either true or false and it 's also just true or false . if we encounter a phrase such as "" where is x ? "" , should that set this to true and this to true , and the bayes net figures out which under the c situation in general is more likely ? or should it just activate this , have this be false , and the bayes net figures out whether this actually now means ? one or in some cases , it 's quite definitely s that you just know wanna know where it is .  and then the we had another idea floating around which we wanted to , get your input on , and that concerns the but we would have a person that would like to work on it , and that 's ir irina gurevich from eml who is going to be visiting us , the week before , august and a little bit into august . and she would like to apply the ontology that is , being crafted at eml . that 's not the one i sent you . the one i sent you was from gmd , out of a european crumpet .  and one of the reas one of the those ideas was ,  back to the old johno observation that if y if you have a dialogue history and it said the word "" admission fee "" was mentioned it 's more likely that the person actually wants to enter than just take a picture of it from the outside . now what could imagine to , have a list for each construction of things that one should look up in the discourse history , that 's the really stupid way . then there is the really clever way that was suggested by keith and then there is the , middle way that i 'm suggesting ","the java the embedded bayes wants to take input a bayes net in some java notation and eva is using the xalan style sheet processor to convert the xml that 's output by the java bayes for the into the , e bayes input . the generation templates are done . natural language generation produces not a just a surface string that is fed into a text to speech but , a surface string with a syntax tree that 's fed into a concept to speech . now and this concept to speech module has certain rules on how if you get the following syntactic structure , how to map this onto prosodic rules . and fey has foolheartedly to rewrite the german concept syntax to prosody rules that 's the lisp type scheme . we ha we have to change the voice . it is we have the choice between the , usual festival voices , which i already told the smartkom people we aren't gonna use because they 're really bad . ogi has , crafted a couple of diphone type voices that are really and it 's probably also uninteresting for all of you to , learn that as of twenty minutes ago , david and i , per accident , managed to get the whole smartkom system running on the icsi linux machines with the icsi nt machines but we would have a person that would like to work on it , and she would like to apply the ontology that is , being crafted at eml . back to the old johno observation that if y if you have a dialogue history and it said the word "" admission fee "" was mentioned it 's more likely that the person actually wants to enter than just take a picture of it and then there is the , middle way that i 'm suggesting ","Minor technical issues,such as format conversions for XML and JavaBayes and the full translation of the SmartKom generation module in English, are currently being resolved. The voice synthesiser will also be replaced by better technology. "
Bed014.E,"and that is you get x , which is whatever , the castle . the ontology will tell us that castles have opening hours , that they have admission fees , they have whatever . and then , this is we go via a thesaurus and look up certain linguistic surface structures that are related to these concepts and feed those through the dialogue history and check dynamically for each e entity . we look it up check whether any of these were mentioned and then activate the corresponding nodes on the discourse side . but keith suggested that a much cleaner way would be is , to keep track of the discourse in such a way that you if that something like that ha has been mentioned before , this just a continues to add up , in th in a if you ask "" how much does a train ride and cinema around the vineyards cost ? "" and then somebody tells you it 's sixty dollars and then you say "" how much is , would like to visit the "" whatever , something completely different , "" then i go to , point reyes "" , it 's not more likely that you want to enter anything , but it 's , a complete rejection of entering by doing that . but that 's this function , has the current object been mentioned in with a question about concerning its  it 's just another , construction side is how to get at the possible inferences we can draw from the discourse history or changing of the probabilities , and or even though the lexical construction itself out of context , won't do it . y you have to keep track whether the person says "" but i but i 'm not interested in the opening times "" is more a v type .    but , we 'll we have time to this is a s just a sidetrack , but it 's also something that people have not done before , is abuse an ontology for these kinds of , inferences , on whether anything relevant to the current something has been has crept up in the dialogue history already , or not . and , i have the , if we wanted to have that function in the dialogue hi dialogue module of smartkom , i have the written consent of jan to put it in there . yes , that 's i 'm keeping on good terms with jan .   let 's talk after friday the twenty ninth . then we 'll see how f  i should try to finish it by then .   was i ? in the room ? constraints . let 's call them constraints , around which one has to i 've always been completely in favor of consensus decisions , we 'll find a way . it might even be interesting then to say that i should be forced to pull some of the ideas that have been floating in my head out of the , out of the top hat and , that metaphor is not going anywhere , yes , and , it 's ha none of that is still around , but it 's  and i would like to d discuss it and , get you guys 's input and make it bomb proof . bullet proof . that 's the word i was looking for .  we need some then we need to make some dates .  meeting regular meeting time for the summer , we really haven't found one . we did thursdays one for a while . talked to ami . it 's it 's a coincidence that he can't do couldn't do it today here . usually he has no real constraints .  it was just an exception .  and , how do we feel about doing it wednesdays ? because it seems to me that this is time where when we have things to discuss with other people , there they seem to be s tons of people around . or subgroup meetings the i 'd like to have them all in one day , package them up and then it 's that if one thing is , this room is taken at after three thirty pr every day by the data collection . we have subjects anyway except for this week , we have subjects in here . that 's why it was one . we just knew i no , he can . let 's say thursday one . but for next week , this is a bit late . would suggest that we need to talk about the c the th no . yes . because , this room is again taken at two thirty by morgan . and the s meeting recorder meeting recording on meeting meetings  how about that ?  actually we w we did scrap our monday time just because bhaskara couldn't come monday . there 's nothing 's impeding monday anymore either . get a fresh start that 's another s thing . but , there are also usually then holidays anyways . like sometimes it works out that way .  forget about the b the camping thing . let 's any other problems w ? but , i suggested monday . if that 's a problem for me then i shouldn't suggest it .  monday ?   one , two , three ? three 's too late . two thirty ? two . w why do you ? and do i get to see th your formalism before that ?  i wo i would like i would get a notion of what you guys have in store for me .  you y the idea is on monday at two we 'll see an intermediate version of the formalism for the constructions , and do an on line merging with my construal ideas . it won't be for semi formal presentation of my proposal . it 'll be more like towards finalizing that proposal . that 's fine . ","and that is you get x , which is whatever , the castle . the ontology will tell us that castles have opening hours , and look up certain linguistic surface structures that are related to these concepts and feed those through the dialogue history and check dynamically for each e entity . we look it up check whether any of these were mentioned and then activate the corresponding nodes on the discourse side . but keith suggested that a much cleaner way would be is , to keep track of the discourse in such a way that you if that something like that ha has been mentioned before , this just a continues to add up , it 's also something that people have not done before , is abuse an ontology for these kinds of , inferences , on whether anything relevant to the current something has been has crept up in the dialogue history already , or not . i have the , if we wanted to have that function in the dialogue hi dialogue module of smartkom , i have the written consent of jan to put it in there . we need some then we need to make some dates . meeting regular meeting time for the summer , let 's say thursday one . the idea is on monday at two we 'll see an intermediate version of the formalism for the constructions , and do an on line merging with my construal ideas . ",
Bed014.E,"and then yikes . perfect . can you also write it up ? i 'll send you i 'll send you a style file , right ? you just  and , sounds good .  do you wanna run the indefinite pronoun idea past jerry ? mary fixed the car with a wrench . you perform the mental sum and then , "" who fixed the car with a wrench ? "" you are told , to do this in the in analogously to the way you would do "" someone fixed the car with a wrench "" . and then you hand it back to your hippocampus and find out what that , means , and then come up with that who that someone was . come up with this if you do wanna discuss focus background and then get me into that because i wo i w scientifically worked on that for almost two years . you your dance card is completely filled now ? why don't ","do you wanna run the indefinite pronoun idea past jerry ? and then , "" who fixed the car with a wrench ? "" in the in analogously to the way you would do "" someone fixed the car with a wrench "" . ",
Bed014.F,"let 's see . what ? i 'm supposed to be on channel five ? her . nope . doesn't seem to be ,  nnn , five . alright , i 'm five . i g guess it 's coming up then , or  the e   actually , could try emailing the guy and see if he has any something already . that 'd be weird , that he has both the java bayes and the embedded bayes in   and put them into different formats .  he could do that , too .   ","actually , could try emailing the guy and see if he has any something already . ",
Bed015.A,"we 're recording . what ? if you have an "" if then "" phrase , do what the "" then "" phrase is called ?  no , but no ! just , as a mental bridge , i 'm not i 'm skipping fourth of july . right afterwards i 'm back . i 've had it often enough . do you want to do the same for space ? space ? here ? now ?    this would involve everything you can imagine to fit under your c dot something where it 's contextually dependent , "" what is now , what was past , what is in the future , where is this , what is here , what is there , what is ""  say two things about the f you want to forget stress . this my f no , as just don't think about it . if canonically speaking you can if you look at a curve over sentence , you can find out where a certain stress is and say , "" hey , that 's my focus exponent . "" it doesn't tell you anything what the focus is . if it 's just that thing , a little bit more or the whole phrase .  the form bit because , as a form cue , not even trained experts can always they can tell you where the focus exponent is sometimes . and that 's also mostly true for read speech . in real speech , people may put stress . it 's context dependent on what was there before , phrase ba breaks , restarts . it 's just , it 's absurd . it 's complicated . and all or map from the contour to what the focus exponent is . but , if you don't you 're focus is then you 're hopeless ly lost anyways , and the only way of figuring out what that is , by generating all the possible alternatives to each focused element , decide which one in that context makes sense and which one doesn't . and then you 're left with a couple three . again , that 's something that h humans can do , but far outside the scope of any anything .   it 's u but it 's what it it 's pretty easy to put it in the formalism , though . because you can just say whatever "" i is the container being focused or the entire whatever , both , and forth . ""  we talked about that a little bit this morning . "" john is on the bus , not nancy . "" that 's focuses on john . "" john is on the bus and not on the train . "" "" john is on the bus "" versus "" john is on the train . "" and "" john is on the bus "" versus "" was "" , and e "" it 's the bu "" all of these and will we have u is it all the same constructions ? just with a different foc focus constituent ?      the once what the focus is the everything else is background . how about "" topic comment "" that 's the other side of information . topic comment .      but to make it m precise at least in my mind , it 's not precise . house "" is gender neuter ? in reality or in semantically .  no , just to make that we everybody that 's completely that it has nothing to do with , form . then "" predications "" makes sense to have it open for something like , accessibility or not .  i is there any meaning to when you have parameters behind it and when you don't ? just means   just , look read even sem semi formal mats rooth . if you haven't read it . it 's and just pick any paper on alternative semantics . that 's his that 's the best way of talking about focus , is his way . mats . mats . rooth . two o 's , yes , th . i never know how to pronounce his name because he 's he is dutch and , but very confused background and , and sadly enough he also just left the ims in stuttgart . he 's not there anymore . but , i don't know where he is right now but alternative semantics is if you type that into an , browser or search engine you 'll get tons of and what i 'm confused about is what the speaker and the hearer is doing there .  but you don't we ultimately want to handle that analogously to the way we handle time and place , because "" you "" , "" me "" , "" he "" , "" they "" , "" these guys "" , all these expressions , nuh , are in much the same way contextually dependent as "" here , "" and "" now , "" and "" there ""    that 's up at the reference part . and down there in the speaker hearer part ? it 's the speaker may in english is allowed to say "" i . "" among the twenty five percent most used words . but wouldn't the "" i "" then set up the s referent that happens to be the speaker this time and not "" they , "" whoever they are . or "" you "" much like the "" you "" could n not always . there 's "" and then he said , i w ""   twhhh whhh . but     and i 'm gonna read the transcript of this one .  but the , but it 's too bad that we don't have a camera . all the pointing is gonna be lost .   isn't i 'm i was dubious why he even introduces this reality , as your basic mental space and then builds up ","do you want to do the same for space ? you want to forget stress . canonically speaking you can if you look at a curve over sentence , you can find out where a certain stress is and say , "" hey , that 's my focus exponent . "" it doesn't tell you anything what the focus is . because , as a form cue , not even trained experts can always they can tell you where the focus exponent is sometimes . and the only way of figuring out what that is , by generating all the possible alternatives to each focused element , decide which one in that context makes sense and which one doesn't . the once what the focus is the everything else is background . how about "" topic comment "" just , look read even sem semi formal mats rooth . and what i 'm confused about is what the speaker and the hearer is doing there . but you don't we ultimately want to handle that analogously to the way we handle time and place , that 's up at the reference part . isn't i 'm i was dubious why he even introduces this reality , as your basic mental space ","Among the issues still being defined, mental spaces and context (eg pronoun references) present similarities that can be echoed in the specification. "
Bed015.A,"d doesn't start with some because it 's obvi it should be obvious , at least it is to me , that whenever i say something i could preface that with "" "" nuh ? there should be no categorical difference between your base and all the others that ensue . it 's  but about linguistic hedges , those tend to be , funky anyways because they blur  great word in the english language is called "" about "" . if you study how people use that it 's also "" about . "" it 's about clever .   but it i isn't that part easy though because in terms of the s simspec , it would just mean you put one more set of brack brackets around it , and then just tell it to negate whatever the content of that is in terms of irony or i also think the detailed discussion will hit bring us to problems that are of a general nature and even even suggest some solutions .      we have a little bit of news , just minor the one big    just small to eva on our web site we can now , if you want to run javabayes , you could see get download these classes . and then it will enable you she modified the gui it has now a m a button menu item for saving it into the embedded javabayes format . that 's wonderful . and , and she , a you tested it out . do you want to say something about that , that it works , right ? with the  that 's a bit unfortunate but for the time being it 's it 's fine to do it  but that 's probably in the long term that 's good news because it forces us to think a little bit more carefully how we want to get an out output . but that 's a different discussion for a different time . and , i don't know . we 're really running late , had , an idea yesterday but , i don't know whether we should even start discussing . the construal bit that , has been pointed to but hasn't been , made precise by any means , may w may work as follows . that we would , that the following thing would be in incredibly and i have no clue whether it will work or nothing . that 's just a tangent , a couple of mental disclaimers here . imagine you write a bayes net ,  bayes net , completely from scratch every time you do construal . you have nothing . just a white piece of paper . you consult your ontology which will tell you a bunch of and parts , and properties , then y you 'd simply write , these into onto your white piece of paper . and you will get a lot of notes and out of there . you won't get you won't really get any c p t 's , therefore we need everything that configures to what the situation is , ie , the context dependent you get whatever comes from discourse but also filtered . only the ontology relevant from the discourse plus the situation and the user model . and that fills in your cpt 's with which you can then query , the net that you just wrote and find out how thing x is construed as an utterance u . and the embedded javabayes works exactly like that , that once you we have , precise format in which to write it , we write it down . you query it . you get the result , and you throw it away . and the thing about this idea is that you don't ever have to sit down and think about it or write about it . you may have some general rules as to how things can be construed as what , that will allow you to craft the initial notes . but it 's in that respect it 's completely scalable . because it doesn't have any prior , configuration . it 's just you need an ontology of the domain and you need the context dependent modules . and if this can be made to work that 'd be funky . p r ms prm since you can unfold a prm into a straightforward bayes net then you can .  no , i was m using it generic . probabilistic , whatever , relational models . whatever you write it . in and then instantiate them . that 's ma the way the only way it works . but , except there 's no theorem prover involved .  what 's it ? yes .  in the process thereof , or whatever . fri thursday 's my last day here .  i would suggest as soon as possible . do by we , the whole ben gang ? we can do it th thursday again .   thursday at one ? also then run through the , the talk i have to give at eml which highlights all of our work . and we can make some last minute changes on that . no . but we can do four . one or four . i don't care . if it 's equal for all ? what should we do ? four ? it 's equal to all of us , you can decide one or four . liz actually said she likes four because it forces the meeting recorder people to cut , the discussions short . ","d doesn't start with some because it 's obvi it should be obvious , at least it is to me , that whenever i say something i could preface that with "" "" to eva on our web site we can now , if you want to run javabayes , you could see get download these classes . she modified the gui it has now a m a button menu item for saving it into the embedded javabayes format . the construal bit that , has been pointed to but hasn't been , made precise by any means , may w may work as follows . that the following thing would be in incredibly imagine you write a bayes net , completely from scratch every time you do construal . you consult your ontology you won't get you won't really get any c p t 's , therefore we need everything that configures to what the situation is , you get whatever comes from discourse plus the situation and the user model . and that fills in your cpt 's with which you can then query , the net that you just wrote and find out how thing x is construed as an utterance u . you may have some general rules as to how things can be construed as what , that will allow you to craft the initial notes . we can do it th thursday again . one or four . ","Work on construal will use Bayes-nets, which will be fed information from other modules and implement general rules to infer how utterances are construed. "
Bed015.B,"what things to talk about . check check . alright . good .  th but that 's why you put semantic constraints up top and meaning bindings down here ?  this should be semantic and th this definitely should be "" semantic constraints "" down at the bottom ?  or he w he went to college here .   we 're building a mental space , good . i see . right . every time nancy giggles it means that it 's your job . i r i read that paper , the hedges paper ? i read some of that paper actually . man .  there 's that quote in jurafsky and martin where it goes where some guy goes , "" every time i fire a linguist the performance of the recognizer goes up . "" ooo , can i ask a can i ask a quick question about this side ? is this , was it intentional to leave off things like "" inherits "" and  like constructions can inherit from other things , am i right ?    you can just give him the abstract that we wrote for the paper . the pressure 's on you nancy . ","is this , was it intentional to leave off things like "" inherits "" ",
Bed015.C,"right . what i was gonna right . i see . the current syntax is if it s if there 's a type it 's before construct that 's fine .  good . you definitely want to de couple the formalism from the parsing strategy . that whether or not it 's used for matching or only for verification , i s for i don't term we want to use but we don't want to  it 's g it 's gone . th i know . anyway , the other strategy you guys could consider is when you don't word to put , you could put no word , just meaning .  and the then let  whatever . or wh that b right . minor min problem   good . a and the  and there 's there 's ca some cases where the grammar depends on some form property of the head . and this enables you to get that , if i understand you right .  right . that all looks good . let me w i don't know . were you finished ?  i if i understand this the aside from , construed and all that the differences are mainly that , we 've gone to the possibility of having form meaning pairs for a type or actually gone back to , if we go back far enough i see .  i 'm you 're right . a construction type . that 's fine . but it ,   no , no , i don't think that you 'll do fine . these are , as long as mark isn't around , these are form constraints . nominal expression is the fact that it 's animate , is semantic . the fact that it 's n a nominal expression i would say on most people 's notion of f higher form types , this i this is one . and that 's just fine .  right . right . that i have no problem with it it 's fine . right . but they do .   right .  but it y it 's just moving it moving the c the cons the constraints around . that 's right . and that was the and going with that is that the designatum also now is a pair . instead of just the meaning . and that aside from some terminology , that 's it . want to b i 'm asking .  the whole the mental space thing is clearly not here . i do want to get on that as soon as robert gets back . the mental space thing . construal is a b is a big component of that this probably not worth trying to do anything till he gets back . but as soon as he gets back we ought to  and furthermore it 's worth missing . right . that 's great . right . right . right . right . right . that 's exactly right .  no , that i we 'll have to see how it works out when we do the details but my intuition would be that 's right .  good . correct . in the short run all we need is a enough mechanism on the form side to get things going . i you  that 's right . i i , think that 's not k i th i don't think it 's completely right . sentence examples you gave in f did constrain the meaning b the form did constrain the meaning , and it isn't ,  but bottom line , i agree with you , that we 're not expecting much out of the , the purely form cues , and , mean , you 're the linguist but , it seems to me that th these we we 've talked about half a dozen linguistics theses in the last few minutes  that 's my feeling that these are really hard problems that decide exactly what 's going on .  right , right . right . does that is that really what they mean in i didn't know that .  right , i 'll check . right . right . n no , no . th critically they 're not required syntactically . often they 're pres presu presupposed and all that right , there 's right . or or , the  right . it 's his thesis , right ? anyway , right , w this is gonna be a b you 're right , this is a bit of in a mess and we still have emphasis as or stress , or whatever .  great . i that 's fine .    good . but the poi i 'm not understand but here 's what i th think is going on . that if we do the constructions right when a particular construction matches , it the fact that it matches , does specify the focus .  at the very least it constrai for yes . there are constrai it 's not every but there are constructions , where you t explicitly take into account those considerations that you need to take into account in order to decide which what is being focused . right . right . right . all of those .   the question is actually i 'm go ahead , finish . s the question is , do we have a way on the other page , when we get to the s semantic side , of saying what the stressed element was , or stressed phrase , right . that 's down at the bottom here when we get over there .  i 'll i 'll   it 's there . right . this there seems to be context properties .  this is recursive cuz until we do the mental space story , we 're not quite th which is fine . we 'll just we 'll j we just don't know yet . right . semantically . ","but they do . the whole the mental space thing is clearly not here . that we 're not expecting much out of the , the purely form cues , and we still have emphasis as or stress , or whatever . ",
Bed015.C,"n now , for the moment we just need the ability to l write it down if somebody figured out what the rules were .    no , i th at this lev which is it should be where you have it . how you get it may in will often involve the discourse but by the time you 're simulating you sh y you should know that . correct . w it c no , no . i let 's see , we 're not i don't think we have it quite right yet . what this is , let 's suppose for the moment it 's complete . then this says that when an analysis is finished , the whole analysis is finished , you 'll have as a result , some s resulting s semspec for that utterance in context , which is made up entirely of these things and , bindings among them . and bindings to ontology items . that the who that this is the tool kit under whi out of which you can make a semantic specification . that 's a . but b , which is more relevant to your life , is this is also the tool kit that is used in the semantic side of constructions . this is an that anything you have , in the party line , anything you have as the semantic side of constructions comes , from pieces of this ignoring li in general , you ignore lots of it . but it 's got to be pieces of this along with constraints among them . that the , goal of the , "" source , path , goal "" has to be the landmark of the conta the interior of this container . or whate whatever . those constraints appear in constructions but this is the full range of semantic structures available to you . good . let 's mark that . we need a c right . and this again may ge our , and we and , worlds . right . s right . "" want "" itself can be i i and it i it 's an action . in our s in our in our s terminology , "" want "" can be an action and "" what you want "" is a world . that 's it 's certainly one way to do it . there are other things . causal we need . mental space we need . the context we need . anyway , keith is this comfortable to you that , once we have this defined , it is your tool kit for building the semantic part of constructions . and then when we combine constructions semantically , the goal is going to be to fill out more and more of the bindings needed in order to come up with the final one . and that 's the wh and that according to the party line , that 's the whole story . right . s swede ? dutch ? dutch .  now , this is assuming you 've already solved that . it 's fred and mary , the speaker would be fred and the   here   that 's right . again , this this is gonna to get us into the mental space and t because "" fred said that mary said "" , and whatever . and we 're , gonna have to , chain those as right . right .  except s it 's trickier than that because the reference he where it gets really tricky is there 's some things , and this is where blends and all terribl some things which really are meant to be identified and some things which aren't . all we need for the moment is some way to say that . you could do that .  had a had an idea that would be very if it works . i haven't told you what it is yet . this was my build up . an i an idea that would be right . if it worked .  right , it was a space builder . we might be able to handle context in the same way that we handle mental spaces because , you have somewhat the same things going on of , things being accessible or not . and i it c it , think if we did it right we might be able to get at least a lot of the same structure . that pulling something out of a discourse context is similar to other kinds of , mental space phenomena . i 've i 've never seen anybody write that up but they did . i don't know . that may be all over the literature . right .  we would have it be in quotes in english .   good , i love the formali that d that does sound like it 's co consistent with what we 're saying ,  this is worth some thought . but , this is very good actually cuz it to the extent that it works , it y it ties together several of these things . no , but there 's a gricean thing going on there , that when you say "" you 're actually hedging . right . we don't have that in here either do we ?  we probably should . confidence like that . about . that in that use of "" about "" , and if you want us to spend a pleasant six or seven hours you could get george started on that .   no . there 's all that let 's i don't  right . right , this raises the question of what are our current purposes . right ?  i don't know the answer but , it does seem that , this is coming along . it 's converging . it 's as far as tell there 's this one major thing we have to do which is the mental the whole s mental space thing . ","then this says that when an analysis is finished , the whole analysis is finished , you 'll have as a result , some s resulting s semspec for that utterance in context , which is made up entirely of these things and , bindings among them . and bindings to ontology items . that the who that this is the tool kit under whi out of which you can make a semantic specification . this is an that anything you have , in the party line , anything you have as the semantic side of constructions comes , from pieces of this ignoring li but it 's got to be pieces of this along with constraints among them . but this is the full range of semantic structures available to you . let 's mark that . in our s terminology , "" want "" can be an action and "" what you want "" is a world . causal we need . mental space we need . the context we need . again , this this is gonna to get us into the mental space and we 're , gonna have to , chain those as had a had an idea that would be very if it works . we might be able to handle context in the same way that we handle mental spaces it c it , think if we did it right we might be able to get at least a lot of the same structure . that pulling something out of a discourse context is similar to other kinds of , mental space phenomena . that when you say "" you 're actually hedging . we don't have that in here either do we ? confidence like that . it 's as far as tell there 's this one major thing we have to do which is the mental the whole s mental space thing . ","It is, essentially, a toolkit with which to create semantic constructions, as well as the bindings between them and with the ontology. Among the issues still being defined, mental spaces and context (eg pronoun references) present similarities that can be echoed in the specification. "
Bed015.C,"and then there 's some other minor things . and we 're going to have to s bound the complexity . if we get everything that anybody ever thought about w we 'll go nuts . we had started with the idea that the actual , constraint was related to this tourist domain and the kinds of interactions that might occur in the tourist domain , assuming that people were being helpful and weren't trying to d there 's all sorts of god knows , irony , and like which you isn't probably of much use in dealing with a tourist guide .   right . whatever .  y no end of things th that , we don't deal with . and go ahead . n no . no . no . right . right . no , no . anyway , let me make a proposal on how to proceed on that , which is that , it was keith 's , job over the summer to come up with this set of constructions . and my suggestion to keith is that you , over the next couple weeks , n don't try to do them in detail or formally but just try to describe which ones you think we ought to have . and then when robert gets back we 'll look at the set of them . just define your space . and , th these are this is a set of things that we ought to deal with . and then we 'll we 'll go back over it and w people will give feedback on it . and then we 'll have a at least initial spec of what we 're actually trying to do . and that 'll also be useful for anybody who 's trying to write a parser . knowing right , "" who might want "" et cetera .  and we get this , portals fixed and then we have an idea of the initial range . and then nancy you 're gonna have to , do your set of but you have to do that anyway . we 're gonna get the w we 're dealing with two domains , the tourist domain and the child language learning . and we 'll see what we need for those two . and then my proposal would be to , not cut off more general discussion but to focus really detailed work on the subset of things that we 've we really want to get done . and then as a separate thread , think about the more general things and all that . without doubt .  but what i want to do is to constrain the things that we really feel responsible for . that we say these are the things we 're really gonna try do by the end of the summer and other things we 'll put on a list of research problems because you can easily get to the point where nothing gets done because every time you start to do something you say , "" but what about this case ? "" this is called being a linguist . and ,  right . right . but anyway . is that does that make sense as a , general way to proceed ? exactly right .      let me right , right .  right . what i would like to do is separate that problem out .  my argument is there 's nothing you can do with that you can't do by just having more constructions . it 's uglier and it d doesn't have the deep linguistic insights and  right . and what i 'd like to do is in the short run focus on getting it right . and when we think we have it right then saying , "" aha ! , can we make it more elegant ? "" can we , what are the generalizations , and but rather than try to guess a inheritance structure and all that before we we 're doing . would say in the short run we 're not gonna b first of all , we 're not doing them yet and it could be that half way through we say , "" aha ! , we now see how we want to clean it up . "" and inheritance is only one that 's one way to organize it but there are others . and it may or may not be the best way . i 'm you had news . great . w what tell us what it is .  right . right . it sounds to me like you want p r beca because it b because no , you can't . see the critical thing about the prm is it gives these relations in general form . once you have instantiated the prm with the instances and ther then you can unfold it . no , but it matters a lot because you what you want are these generalized rules about the way things relate , th that you then instantiate in each case . and that 's that 's the only way it could work . i we have a our local expert on p r but my guess is that they 're not currently good enough to do that . but we 'll have to see .  yes . this is that 's that would be a good thing to try . it 's related to the hobbs abduction story in that you th you throw everything into a pot and you try to come up with the , no , there isn't a theorem prover but there but the , the cove the p r ms are like rules of inference and you 're coupling a bunch of them together . and then ins instead of proving you 're trying to , compute the most likely .  tricky . but you it 's a good it 's a good thing to put in your thesis proposal . ","and we 're going to have to s bound the complexity . we had started with the idea that the actual , constraint was related to this tourist domain and the kinds of interactions that might occur in the tourist domain , it was keith 's , job over the summer to come up with this set of constructions . and my suggestion to keith is that you , over the next couple weeks , n don't try to do them in detail or formally but just try to describe which ones you think we ought to have . just define your space . and that 'll also be useful for anybody who 's trying to write a parser . we 're gonna get the w we 're dealing with two domains , the tourist domain and the child language learning . and then my proposal would be to , not cut off more general discussion but to focus really detailed work on the subset of things that we 've we really want to get done . what i would like to do is separate that problem out . and what i 'd like to do is in the short run focus on getting it right . and when we think we have it right then saying , "" aha ! , can we make it more elegant ? "" once you have instantiated the prm with the instances and ther then you can unfold it . ",Work on both of these formalisms will continue with circumscription of the construction space that will be studied in more detail. 
Bed015.C,"are you gonna write something for us before you go ? you have something .  what 's what when are we gonna meet again ?  n no , i didn't mean y just the two of us . we we can do this . but the question is do you want to , send the little group , a draft of your thesis proposal and get , another session on feedback on that ? or alright .   that 'll tell him exactly what 's going on . that alright . ","but the question is do you want to , send the little group , a draft of your thesis proposal ",
Bed015.D,"  the   just one sheet .  front , back .  i was just checking like , when we wanna , get the posterior probability of variables . how you asked whether we can just observe all the variables like in the same list ? you can't . you have to make separate queries every time .   you just have to have a long list of , all the variables .   fri  ",,
Bed015.E,"this is just one sheet , right ?          extremely .    that 's the idea .  i   it 's that now , i 'm mentioned this , i don't know if i ever explained this but the point of , i mentioned in the last meeting , the point of having something called "" nominal expression "" is , because it seems like having the verb subcategorize for , like say taking as its object just some expression which , designates an object or designates a thing , or whatever , that leads to some syntactic problems you wanna , you have this problem like "" i 'll put the word "" , let 's say , the word "" dog "" , and that has to come right after the verb cuz we know verb meets its object . and then we have a construction that says , you can have "" the "" preceding a noun . and you 'd have this problem that the verb has to meet the designatum . and you could get , "" the kicked dog "" like that , meaning "" kicked the dog "" . you have to let this phrase idea in there but it    we thought we were getting away with , with , a p this is not reverting to the x bar theory of phrase structure . but , know that this is like , we didn't originally have in mind that , that verbs would subcategorize for a particular form .  but they does . at least in english .        what 's the time frame ? i forgot again when you 're going away for how long ?   yes .  n    i 'm s curious about how much of the mental i 'm not that the formalism , the grammatical side of things , is gonna have that much going on in terms of the mental space all of these called space builders that are in the sentence are going to of it as , giving you the coordinates of , assuming that at any point in discourse there 's the possibility that we could be talking about a bunch of different world scenarios , whatever , and the speaker 's supposed to be keeping track of those . the , the construction that you actually get is just gonna give you a cue as to which one of those that you 've already got going , you 're supposed to add structure to . in france , watergate wouldn't have hurt nixon "" like that . you say , "" alright , i 'm supposed to add some structure to my model of this hypothetical past france universe "" like that . the information in the sentence tells you that much but it doesn't tell you like exactly what it what the point of doing is . depending on the linguistic con context it could be like the question is what does "" watergate "" refer to there ? does it , does it refer to , if you just hear that sentence cold , the assumption is that when you say "" watergate "" you 're referring to "" a watergate like scandal as we might imagine it happening in france "" . but in a different context , "" if nixon had apologized right away it wouldn't watergate wouldn't have hurt him badly in the us and in france it wouldn't have hurt him . now we 're s now that "" watergate "" we 're now talking about the real one , and the "" would "" it 's a different dimension of hypothe theticality , right ? we 're not saying what 's hypothetical about this world . in the first case , hypothetically we 're imagining that watergate happened in france . in the second case we 're imagining hypothetically that nixon had apologized right away right ? lot of this isn't happening at the grammatical level . and i don't know where that sits then , the idea of sorting out what the person meant .       but the whole point of what fauconnier and turner have to say about , mental spaces , and blending , and all that is that you don't really get that much out of the sentence . there 's not that much information contained in the sentence . it just says , "" here . add this structure to this space . "" and exactly what that means for the overall ongoing interpretation is quite open . an individual sentence could mean a hundred different things depending on , quote , "" what the space configuration is at the time of utterance "" . and somebody 's gonna have to be doing a whole lot of work but not me ,  but like what was the point of saying that sentence about nixon and france ? that is not there is nothing about that in the sentence really .  y                        light up with focus ,  there 's a bunch .     right .   i 'm inclined to say let 's worry about specifying the information structure focus of the sentence and then , hhh , the phonology component can handle actually assigning an intonation contour to that . later on we 'll worry about exactly how y exactly . but figure out how the    japanese has this though .  that 's what "" wa "" is , just to mark which thing is the topic . it doesn't always have to be the subject . side one .        right , "" this guy i know from school came for dinner "" does not mean , "" there 's a guy , i know him from school , and he came over for dinner "" . that 's not the same effect .       the difference is whether you thought it was obvious what the possible fillers were .  "" whee ! "" that 's that one , right ? i 'm still just really not clear on what i 'm looking at . the "" scenario "" box , ","know that this is like , we didn't originally have in mind that , that verbs would subcategorize for a particular form . i 'm not that the formalism , the grammatical side of things , is gonna have that much going on in terms of the mental space all of these called space builders that are in the sentence are going to assuming that at any point in discourse there 's the possibility that we could be talking about a bunch of different world scenarios , whatever , and the speaker 's supposed to be keeping track of those . the , the construction that you actually get is just gonna give you a cue as to which one of those that you 've already got going , you 're supposed to add structure to . but it doesn't tell you like exactly what it what the point of doing is . light up with focus , side one . the "" scenario "" box , ","On the other hand, the semantic specification structures information in terms of ""scenario"", ""referent"" and ""discourse segment"". "
Bed015.E,"like , what does that look like for an example ? like , not all of these things are gonna be here . this is just says "" part of what i 'm going to hand you is a whole bunch of s schemas , image , and x schemas . here are some examples of the sorts of things you might have in there "" .      do you have to say about the binding in your is there a slot in here for that tells you how the bindings are done ?          right .              that 's         y right . that makes sense . mean , there 's this in the off in the scenario , which just tells you how various what schemas you 're using and they 're how they 're bound together . and that some of the discourse segment is that where you would sa that 's that 's where the information structure is which is a profiling on different parts of , of this . what 's interesting is that the information structure  there 's almost we keep coming back to how focus is like this , trajector landmark thing . if i say , "" in france it 's like this "" . great , we 've learned something about france but the fact is that utterances of that sort are generally used to help you draw a conclusion also about some implicit contrast , like "" in france it 's like this "" . and therefore you 're supposed to say , "" boy , life "" in france kids are allowed to drink at age three "" . and w you 're that 's not just a fact about france . you also conclude something about how boring it is here in the u s . right ? and  that comes in and ,         what was the name ?    mats gould .       there 's things like ther there 's all kinds of like , in mentioned last time in czech if you have a verb of saying then you say something like or i was thinking you can say something like , "" you are a republican "" like that . where as in english you would say , "" you were "" . the past tense being copied onto the lower verb doesn't happen there , you have to say something about , tense is determined relative to current blah blah . same things happens with pronouns . there 's languages where , if you have a verb of saying then , ehhh , where situation like "" bob said he was going to the movies "" , where that lower subject is the same as the person who was saying or thinking , you 're actually required to have "" i "" there . and it 's in an extended function  but it 's not perceived as a quotative construction . it 's been analyzed by the formalists as being a logophoric pronoun , which means a pronoun which refers back to the person who is speaking or that thing , right ?  but that happens to sound like the word for "" i "" but is actually semantically unrelated to it .   there 's a whole book which operates on this assumption . mary dalrymple , this book , a ninety three book on , on pronoun and then the same thing for asl where , you 're signing and someone says something . and then , he say "" , and then you do a role shift . and then you sign "" i , this , that , and the other "" . and "" i did this "" . that 's also been analyzed as logophoric and having nothing to do with "" i "" . and the role shift thing is completely left out and on .  that pronoun references , ties in with all this mental space and on , and forth . and right .     it 's like what 's happening that , what 's happening , there is that you 're moving the base space like that , right ? that 's how fauconnier would talk about it . and it happens diff under different circumstances in different languages . and things like pronoun reference and tense which we 're thinking of as being these discourse y things actually are relative to a bayes space which can change . and we need all the same machinery . schade .       y it 's an evidential . it 's semi grammaticalized . people have talked about it this way . and you can do special things . you can , th put just the phrase "" as a parenthetical in the middle of a sentence and on , and forth .      we were just talking about this evidentiality and like that , right ?  that 's what is , telling you what percent reality you should give this or the ,  and the fact that i 'm , the fact if it versus he thinks that might , depending on how much you trust the two of us or whatever ,   he wrote a paper about thirty five years ago on that one .  would you believe that paper lead directly to the development of anti lock brakes ? ask me about it later i 'll tell you how . when we 're not on tape . i don't really like we don't have to care too much about the speaker attitude , right ? like there 's not many different hhh , i don't know , m  mean there 's lots of different attitudes that the speaker could have and that we can clearly identify , and on , and forth . but like what are the distinctions among those that we actually care about for our current purposes ? shoot . here it is three fifteen already .     right . we have a theoretical model of sarcasm now . right ,         in case there 's any around .         exactly . we 'll start with that , ",""" part of what i 'm going to hand you is a whole bunch of s schemas , image , and x schemas . mean , there 's this in the off in the scenario , which just tells you how various what schemas you 're using and they 're how they 're bound together . and that some of the discourse segment that 's where the information structure is which is a profiling on different parts of , of this . there 's languages where , situation like "" bob said he was going to the movies "" , where that lower subject is the same as the person who was saying or thinking , you 're actually required to have "" i "" there . but it 's not perceived as a quotative construction . it 's been analyzed by the formalists as being a logophoric pronoun , which means a pronoun which refers back to the person who is speaking or that thing , right ? that pronoun references , ties in with all this mental space and on , and forth . it 's like what 's happening that , what 's happening , there is that you 're moving the base space like that , right ? we were just talking about this evidentiality and like that , right ? we don't have to care too much about the speaker attitude , right ? but like what are the distinctions among those that we actually care about for our current purposes ? ",
Bed015.E,"just figuring out what needs to be done then actually the next step is to start trying to do it . got it .  you ran out of power . no . there should be i wanted to s find out someday if there was gonna be some way of dealing with , if this is the right term , multiple inheritance , where one construction is inheriting from , from both parents , or different ones , or three or four different ones . cuz the problem is that then you have to which of which are how they 're getting bound together .  yes . that 's right . but whatever . no , no . no , by all means , right .  that 's  connect the dots .       fine with me . should we do the one pm time for thursday since we were on that before or ?  to me this is equal . i don't care . if you insist , then . ","there should be i wanted to s find out someday if there was gonna be some way of dealing with , if this is the right term , multiple inheritance , where one construction is inheriting from , from both parents , ",
Bed015.F,"i 'm what ? really ? that 's horrible ! disincentive ! hello ? hello ? which am i ? channel fi  are you doing something ? then 'm doing something .  the result of m much thinking since the last time we met , but not as much writing , is a sheet that i have a lot of thoughts and justification of comments on but i 'll just pass out as is right now .  here . if you could pass this around ? and there 's two things . and one on one side is a the revised updated semantic specification . and the other side is , revised construction formalism . it 's just one sheet . it 's just a nothing else .  enough to go around ?  and in some ways it 's it 's very similar to there are very few changes in some ways from what we 've , b done before but i don't think everyone here has seen all of this . i 'm not where to begin . as usual the disclaimers are there are all these things are it 's only slightly more stable than it was before . and , after a little bit more discussion and especially like keith and i have more linguistic things to settle in the next few days , it 'll probably change again some more . will let 's start b let 's start on number two actually on the notation , because that 's , i 'm thinking , possibly a little more familiar to , to people . the top block is just abstract nota it 's like , listings of the kinds of things that we can have . and certain things that have , changed , have changed back to this . there 's been a little bit of , going back and forth . but all constructions have some name . i forgot to include that you could have a type included in this line . something like , there 's an example the textual example at the end has clausal construction .  just to show it doesn't have to be beautiful it could be , simple old text as there are a couple of these three have various ways of doing certain things . 'll just try to go through them . they could all have a type at the beginning . and then they say the key word construction and they have some name . right . and then it has a block that is constituents . and as usual all the constructions her all the examples here have only , tsk one type of constituent , that is a constructional constituent . that 's actually gonna turn out to m be certainly the most common kind . but in general instead of the word "" construct "" , th here you might have "" meaning "" or "" form "" as  if there 's some element that doesn't that isn't yet constructional in the sense that it maps form and meaning .  the main change with the constructs which each of which has , the key word "" construct "" and then some name , and then some type specification , is that it 's it 's pro it 's often sometimes the case in the first case here that what construction it is . whatever i have here is gonna be a form of the word "" throw "" , or it 's gonna be a form of the word , i don't know , "" happy "" , like that . or , some it 'll be a specific word or you 'll have the type . you 'll say "" i need a p spatial relation phrase here "" or "" i need a directional specifier here "" . you could have a j a actual type here . or you could just say in the second case that you only know the meaning type . very common example of this is that , in directed motion , the first person to do something should be an agent of some kind , often a human . right ? if i the run down the street then i i run down the street , it 's typed , "" i "" , meaning category is what 's there . the new kind is this one that is pair and , skipping fonts and whatever . the idea is that sometimes there are , general constructions that that you 're going to need . it 's the equivalent of a noun phrase or a prepositional phrase , like that there . and usually it has formal considerations that will go along with it . and then you might know something much more specific depending on what construction you 're talking about , about what meaning what specific meaning you want . the example again at the bottom , which is directed motion , you might need a nominal expression to take the place of , "" the big th "" , "" the big the tall dark man "" , "" walked into the room "" . but because of the nature of this particular construction not just that it 's nominal of some kind but in particular , that it 's some animate nominal , and which will apply just as to like , a per a simple proper noun or to some complicated expression .  don't know if the syntax will hold but something that gives you a way to do both constructional and meaning types .  then i don't think the , at least none of these examples have anything different for formal constraints ? but you can refer to any of the , available elements and scope , right ? which here are the constructs , to say something about the relation . and if you not if you compare like the top block and the textual block , we dropped like the little f subscript . ","the result of m much thinking since the last time we met , but not as much writing , is a sheet that i have a lot of thoughts and justification of comments on and one on one side is a the revised updated semantic specification . and the other side is , revised construction formalism . it 's only slightly more stable than it was before . let 's start b let 's start on number two actually on the notation , the top block is just abstract nota it 's like , listings of the kinds of things that we can have . they could all have a type at the beginning . and then they say the key word construction and then it has a block that is constituents . but in general instead of the word "" construct "" , th here you might have "" meaning "" or "" form "" as or you could just say in the second case that you only know the meaning type . and usually it has formal considerations that will go along with it . ",The discussion concerned the revised semantic specification and the construction formalism. The different levels of the latter focus on what construction types are encountered and what bindings there are between them. 
Bed015.F,"the f subscripts refer to the "" form "" piece of the construct . and that , in general it 'll be unambiguous . like if you were giving a formal constraint then you 're referring to the formal pole of that . by saying if said "" name one "" then that means name one formal and we 're talking about formal struc which makes sense . there are certain times when we 'll have an exception to that , in which case you could just indicate "" here the meaningful for some reason "" . right ? or actually it 's more often that , only to handle this one special case of , "" george and jerry walk into the room in that order "" . we have a few funny things where something in the meaning might refer to something in the form . but s we 're not gonna really worry about that for right now and there are way we can be more specific if we have to later on . and in terms of the relations , as usual they 're before and ends . i should have put an example in of something that isn't an interval relation but in form you might also have a value binding . you could say that , "" name one dot "" , t "" number equals "" , a plural like that . there are certain things that are attribute value , similar to the bindings below but they 're just us usually they 're going to be value fillers , right ? and then again semantic constraints here are just bindings . there was talk of changing the name of that . and johno and i you and like fight about that if you like ? but about changing it to "" semantic n effects "" , which was a little bit too order biased and "" semantic bindings "" , which might be too restrictive in case we don't have only bindings . and it was an issue whether constraints there were some linguists who reacted against "" constraints "" , saying , "" if it 's not used for matching , then it shouldn't be called a constraint "" . but we want to be uncommitted about whether it 's used for matching or not . right ? cuz there are we thought of some situations where it would be useful to use whatever the c bindings are , for actual , like modified constraining purposes .  it 's used shouldn't matter , right ?   there was one time when hans explained why "" constraints "" was a misleading word for him . and the reason that he gave was similar to the reason why johno thought it was a misleading term , which was just an interesting coincidence . but , and was like , "" both of you don't like it ? fine , we can change it "" . but i 'm starting to like it again . that 's why i 'll stick with it .  what ? con a consequent ? but it 's not an "" if then "" .  that 's true .  no . that was just a mistake of cut and paste from when i was going with it . i 'm i didn't mean that one 's an in unintentional . sometimes i 'm intentionally inconsistent cuz i 'm not yet . here , i actually it was just a mistake .  unless i go with "" meaning "" but i like "" meaning "" better than "" semantic "" but there 's vestiges of other people 's biases . like minor point .  think the middle block doesn't really give you any more information , ex than the top block . and the bottom block similarly only just illus all it does is illustrate that you can drop the subscripts and that you can drop the , that you can give dual types . one thing i should mention is about "" designates "" . 'm actually inconsistent across these as strike out the m subscript on the middle block . now , this is actually this little change actually goes along with a big linguistic change , which is that "" designates "" isn't only something for the semantics to worry about now . we want s "" designates "" to actually know one of the constituents which acts like a head in some respects but is really important for say composition later on . if some other construction says , "" are you of type is this part of type whatever "" , the "" designates "" tells you which part is the meaning part . if you have like "" the big red ball "" , you wanna know if there 's an object or a noun . ball is going to be the designated element of that phrase .  there is a slight complication here which is that when we talk about form it 's useful sometimes to talk about , to talk about there also being a designated object and we think that 'll be the same one , right ? the ball is the head of the phrase , "" the r the "" , "" big red ball "" , and the entity denoted by the word "" ball "" is the semantic head in some ways of this in interesting larger element .  right , right . and , you might be able to say things like if the head has to go last in a head final language , you can refer to the head as a p the , the formal head as opposed to the rest of the form having to be at the end of that decision . that 's a useful thing that you can get some internal structural constraints in . there was a list of things that isn't included but you can ask a question . that might @ @ it .  right . ","and then again semantic constraints here are just bindings . and it was an issue whether constraints there were some linguists who reacted against "" constraints "" , saying , "" if it 's not used for matching , then it shouldn't be called a constraint "" . think the middle block doesn't really give you any more information , ex than the top block . and the bottom block similarly only just illus all it does is illustrate that you can drop the subscripts and that you can drop the , that you can give dual types . one thing i should mention is about "" designates "" . if some other construction says , "" are you of type is this part of type whatever "" , the "" designates "" tells you which part is the meaning part . ",The different levels of the latter focus on what construction types are encountered and what bindings there are between them. 
Bed015.F,"except for their construction meaning , it 's not clear that ,  right now it 's a c contr construction type and meaning type . don't form type is .  right . a and a previous , version of the notation certainly allowed you to single out the meaning bit by it . you could say "" construct of type whatever designates something "" . but that was mostly for reference purposes , just to refer to the meaning pole . i don't think that it was often used to give an extra meaning const type constraint on the meaning , which is really what we want most of the time  i don't know if we 'll ever have a case where we actually h if there is a form category constraint , you could imagine having a triple there that says , that 's weird .  right , right . which is fine ,   right , n s you may be you may not be like everyone else in berkeley , but that 's we don't mind either ,  right .  there 's an alternative to this which is , the question was did we want directed motion , which is an argument structure construction did we want it to worry about , anything more than the fact that it , has semantic it 's frame based construction . one option that , keith had mentioned also was like , if you have more abstract constructions such as subject , predicate , things like grammatical relations , those could intersect with these in such a way that subject , predicate , or subject , predicate , subject , verb , ob verb object would require that those things that f fill a subject and object are nom expressions . and that would be a little bit cleaner in some way . but for now ,  m moving it to another place , right . but there does there has to be that constraint somewhere , right ?   robert 's not happy now ?  yes .  right .   the un the un addressed questions in this , definitely would be semantic constraints we talked about . here are just bindings but , right ? we might want to introduce mental spaces there 's all these things that we don't right ? there 's going to be some extra definitely other notation we 'll need for that which we skip for now .      what ? you 're missing like the premier american holiday ? what 's the point of spending a year here ? anyway . i forgot .   not in california . that 's true . i like spending fourth of july in other countries , whenever  construal ,  there was one question that came out . i hate this thing .  which is , something like "" past "" which i we think is a very simple we 've often just stuck it in as a feature , "" this event takes place before speech time "" , is what this means . it 's often thought of as it is also considered a mental space , by , lots of people around here . there 's this issue of sometimes there are really exotic explicit space builders that say "" in france , blah blah "" , and you have to build up you ha you would imagine that would require you , to be very specific about the machinery , whereas past is a very conventionalized one and we it means but it we doesn't don't necessarily want to , unload all the notation every time we see that it 's past tense . we could think of our just like x schema "" walk "" refers to this complicated structure , past refers to , a certain configuration of this thing with respect to it . we 're like having our cake and eating it having it both ways , right ? i    wha space ? instead of just time ?  same thing . there are very conventionalized like deictic ones , right ? and then for other spaces that you introduce , you could just attach y whatever you could build up an appropriately appropriate structure according to the l the sentence .  right .    time and space . we 'll get that on the other side a little , like very minimally . there 's a there 's a slot for setting time and setting place . and you could imagine for both of those are absolute things you could say about the time and place , and then there are many in more interestingly , linguistically anyway , there are relative things that , you relate the event in time and space to where you are now . if there 's something a lot more complicated like , or hypothetical or whatever , then you have to do your job , like or somebody 's job anyway . i 'm gonna point to at random .  they 're real , right . i see right .   right .  it seems like , the grammatical things such as the auxiliaries that introduce these conditionals , whatever , give you the most basi th those we we can figure out what the possibilities are , right ? there are relatively limited number . and then how they interact with some extra thing like "" in france "" or "" if such and such "" , that 's like there are certain ways that they c they can one is a more specific version of the general pattern that the grammat grammar gives you .  but , whatever , we 're   that 's we usually don't know the point of the sentence but we it 's trying to say . we know that it 's what predication it 's setting up . that 's all . purely linguistic cues , right ?   ","right now it 's a c contr construction type and meaning type . don't form type is . one option that , keith had mentioned also was like , if you have more abstract constructions such as subject , predicate , things like grammatical relations , those could intersect with these in such a way that subject , predicate , or subject , predicate , subject , verb , ob verb object would require that those things that f fill a subject and object are nom expressions . there 's going to be some extra definitely other notation we 'll need for that which we skip for now . something like "" past "" which i we think is a very simple we 've often just stuck it in as a feature , it 's often thought of as it is also considered a mental space , whereas past is a very conventionalized one instead of just time ? same thing . there are very conventionalized like deictic ones , right ? ","Similarly, ways to handle mental spaces will have to be added on top. "
Bed015.F,"one other thing want to point out is there 's a lot of confusion about the terms like "" profile , designate , focus "" , et cetera , et cetera . for now i 'm gonna say like "" profile "" 's often used like two uses that come to mind immediately . one is in the traditional like semantic highlight of one element with respect to everything else . hypotenuse "" , you profiled this guy against the background of the right t right triangle .  and the second use , is in framenet it 's slightly different . i was asking hans about this . they use it to really mean , this in a frame th this is the profiles on the these are the ones that are required . they have to be there or expressed in some way . which i 'm not saying one and two are mutually exclusive but they 're different meanings . the closest thing was thinking about how it relates to this notation . for us , how is it designate "" framenet ? framenet ?  i was a little bit surprised about it too . i knew that that would be something like there 's another term that i 've heard for that thing but they at least hans says they use it that way . and and may he 's wrong . anyway , the "" designate "" that we have in terms of meaning is really the "" highlight this thing with respect to everything else "" . this is what it means . but the second one seems to be useful but we might not need a notation for it ? we don't have a notation for it but we might want one . we 've talked about if you 're talking about the lexical item "" walk "" , it 's an action . it also has this idea it carries along with it the idea of an actor or somebody 's gonna do the walking . or if you talk about an adjective "" red "" , it carries along the idea of the thing that has the property of having color red . we used to use the notation "" with "" for this and that 's closest to their second one . d don't yet know , i have no commitment , as to whether we need it . it might be it 's the thing that w a parser might want to think about whether we require these things are like it 's semantically part of it right . right , right . definitely .  "" in "" was a good example . if you walk "" in "" , like in what ? like you have to have the it 's only semantically is it it is still required , say , by simulation time though to have something . it 's that i meant the idea of like that the semantic value is filled in by sim simulation . i don't know if that 's something we need to spa to like say ever as part of the requirement ? or the construction ? or not . we 'll again defer . have it construed , is that the idea ? just point at robert . whenever i 'm confused just point to him . you tell me .  we 'll get , i we have thoughts about those as  the i w i would just s some of this is just like my by fiat . i 'm going to say , this is how we use these terms . i don't there 's lots of different ways in the world that people use it . that , the other terms that are related are like focus and stress . s that the way i we would like to think , is focus is something that comes up in , lots of this is the information structure . it 's like it 's not it might be that there 's a syntactic , device that you use to indicate focus or that there are things like , keith was telling me , things toward the end of the sentence , post verbal , tend to be the focused element , the new information . if i "" i walked into the room "" , you tend to think that , whatever , "" into the room "" is like the more focused thing . and when you , you have stress on something that might be , a cue that the stressed element , or the negated element is related to information structure . that 's like the new the like import or whatever of this thing . think that 's to keep "" focus "" being an information structure term . "" stress "" i th and then there are different kinds of focus that you can bring to it . like "" stress "" , th stress is pun on you might have like whatever accent stress . and that 's just a w we 'll want to distinguish stress as a form device . high volume or whatever .  t and distinguish that from it 's effect which is , "" the focus we have is we 're emphasizing this value often as opposed to other values "" , right ? focus carries along a scope . like if you 're gonna focus on this thing and you wanna know it evokes all the other possibilities that it wasn't . my classic my now classic example of saying , "" he did go to the meeting ? "" , that was my way of saying as opposed to , "" he didn't g "" or "" there was a meeting ? "" that was the example that was caught on by the linguists immediately . and the like if you said he ","one other thing want to point out is there 's a lot of confusion about the terms like "" profile , designate , focus "" , et cetera , et cetera . for now i 'm gonna say like "" profile "" 's often used one is in the traditional like semantic highlight of one element with respect to everything else . and the second use , is in framenet it 's they use it to really mean , this in a frame th this is the profiles on the these are the ones that are required . the "" designate "" that we have in terms of meaning is really the "" highlight this thing with respect to everything else "" . but the second one seems to be useful d don't yet know , i have no commitment , as to whether we need it . that , the other terms that are related are like focus and stress . it 's like it 's not it might be that there 's a syntactic , device that you use to indicate focus think that 's to keep "" focus "" being an information structure term . w we 'll want to distinguish stress as a form device . high volume or whatever . like if you 're gonna focus on this thing and you wanna know it evokes all the other possibilities that it wasn't . ",
Bed015.F,"there 's all these different things that if you put stress on a different part of it then you 're , c focusing , whatever , on , "" he walked to the meeting "" as opposed to "" he ran "" , or "" he did walk to the meeting "" as opposed to "" he didn't walk "" . we need to have a notation for that which , that 's still in progress . 'm still working it out . but it did one implication it does f have for the other side , which we 'll get to in a minute is that i couldn't think of a good way to say "" here are the possible things that you could focus on "" , cuz it seems like any entity in any sentence , or any meaning component of anyth all the possible meanings you could have , any of them could be the subject of focus . but one the one thing you can schematize is the focus , right ? you could say it 's the tense on this as opposed to , the action . or it 's it 's an identity thing or a contrast with other things , or stress this value as opposed to other things .  it 's it is like a profile background thing but i can't think of like the limited set of possible meanings that you would focu light highlight as opposed to other ones . it has some certain complications for the , later on . li the best thing come up with is that information has a list of focused elements . you one other type that i forgot to mention is like query elements and that 's probably relevant for the like "" where is "" , "" the castle "" thing ? because you might want to say that , location or cert certain wh words bring automatically focus in a , "" i don't know the identity of this thing "" way on certain elements .  anyway . that 's onl there are many more things that are uncl that are like a little bit unstable about the notation but it 's most it 's this is , the current form . other things we didn't deal with , we 've had a lot of other that keith and i have them working on in terms of like how you deal with like an adjective . a nominal expression . and , we should have put an example of this and we could do that later . but the not inherently like the general principles still work though , that , we can have constructions that have constituent structure in that there is like , one they have constituents , right ? you can like nest things when you need to , but they can also overlap in a flatter way . if you don't have like a lot of grammar experience , then like this might , be a little o opaque . but , we have the properties of dependency grammars and some properties of constituents constituent based grammar . that 's that 's the main thing we wanted to aim for and far it 's worked out   yes . as a word ? as a what 's that ?    or the constituent that it falls in . forget about stress , the form cue ?     i believe you ,  ways that you can get it come from th right .  right . that 's fine ,    i wouldn't have assumed that it 's an easy problem in absence of all the oth you need all the other information   exactly . the effect of it is something we want to be able to capture . w i 'm not about that . or it might limit it cert certainly constrains the possibilities of focus . that 's , th that 's certainly true . and depending on the construction it may or may not f specify the focus , right ?       right . is on . "" john is on the bus "" .  right . i would say that argument structure in terms of like the main like i don't know the fact that you can get it without any stress and you have some whatever is predicated anyway should be the same set of constructions . that 's why i was talking about overlapping constructions . then you have a separate thing that picks out , stress on something relative to everything else . and it would  and it w and that would have to it might be ambiguous as , whether it picks up that element , or the phrase , like that . but it 's still is limited possibility . that should , interact with it should overlap with whatever other construction is there .  that 's why i was saying how since i couldn't think of an easy like limited way of doing it , all say is that information structure has a focused slot and that should be able to refer to  and , infer and i don't have a great way or great examples but that something like that is probably gonna be , more what we have to do . but , that was one comment . and you had another one ? how about what ? that was the other thing . and didn't realize it before . it 's like , "" "" it was an epiphany that it topic and focus are a contrast set . topic is topic focused seems to me like , background profile , or a landmark trajector , or some something like that . there 's definitely , that thing going on . now i don't know whether i n i don't have as many great examples of like topic indicating constructions on like focus , right ? topic it seems that might be an ongoing thing . topic marker ?   right . again , information structure has a topic slot . ","we need to have a notation for that that 's still in progress . but it did one implication it does f have for the other side , which we 'll get to in a minute is that i couldn't think of a good way to say "" here are the possible things that you could focus on "" , but i can't think of like the limited set of possible meanings that you would focu li the best thing come up with is that information has a list of focused elements . other things we didn't deal with , we 've had a lot of other that keith and i have them working on in terms of like how you deal with like an adjective . a nominal expression . you can like nest things when you need to , but they can also overlap in a flatter way . but , we have the properties of dependency grammars and some properties of constituents constituent based grammar . the fact that you can get it without any stress and you have some whatever is predicated anyway should be the same set of constructions . then you have a separate thing that picks out , stress on something relative to everything else . since i couldn't think of an easy like limited way of doing it , all say is that information structure has a focused slot topic it seems that might be an ongoing thing . again , information structure has a topic slot . ","The encoding of features is still incomplete: frame profiles, focus, adjectives, nominal expressions are phenomena in the process of being integrated. The notation maintains properties of both dependency and constituent-based grammars. "
Bed015.F,"and , i stuck it in thinking that we might use it . stuck it in . and one thing that i didn't do consistently , is when we get there , is like indicate what thing fits into every role . have an idea of what it should be but th far we 've been getting away with like either a type constraint or , whatever . i forg it 'll be a frame . it 'll be another predication or it 'll be , i don't know , some value from some something , some variable and scope like that , or a slot chain based on a variable and scope . that 's should we flip over to the other side officially then ? i keep , pointing forward to it .  now we 'll go back to s this doesn't include something which mi may have some effect on it , which is , the discourse situation context record , right ? didn't i meant just like draw a line and like , you also have , some tracking of what was going on . and this is a big scale comment before i , look into the details of this . but you could imagine instead of having i changed the name of it used to be "" entities "" . you see it 's "" scenario "" , "" referent "" and "" discourse segment "" . and "" scenario "" is essentially what what 's the basic predication , what event happened . and actually it 's just a list of various slots from which you would draw in order to paint your picture , a bunch of frames , bi and bindings , right ? and there are other ones that are not included here , general cultural frames and general like , other action f specific x schema frames . whatever . the middle thing used to be "" entities "" because you could imagine it should be like really a list where here was various information . and this is intended to be grammatically specifiable information about a referent about some entity that you were going to talk about . harry walked into the room "" , "" harry "" and "" room "" , the room th but they would be represented in this list somehow . and it could also have it has this category slot . it should be either category or in or instance . it could be a pointer to ontology . that everything about this could be drawn in . but the important things for grammatical purposes are for things like number , gender , ki the ones i included here are slightly arbitrary but you could imagine that , you need to figure out wheth if it 's a group whether , some event is happening , linear time , linear spaces , like , are they doing something serially or is it like , 'm not because this partly came from , talmy 's schema and i 'm not we 'll need all of these actually . but and then the "" status "" i used was like , again , in some languages , like in child language you might distinguish between different status . th the big com and finally "" discourse segment "" is about speech act y information structure y , like utterance specific kinds of things . the comment i was going to make about , changing entity the entity 's block to reference is that you can imagine your discourse like situation context , you have a set of entities that you 're referring to . and you might that might be general , i don't know , database of all the things in this discourse that you could refer to . and i changed to "" reference "" cuz i would say , for a particular utterance you have particular referring expressions in it . and those are the ones that you get information about that you stick in here . i know it 's going to be plural . i know it 's gonna be feminine like that . and these could actually just point to , the id in my other list of enti active entities , right ?  th there 's all this about discourse status . we 've talked about . i almost listed "" discourse status "" as a slot where you could say it 's active . there 's this , hierarchy there 's a schematization of , things can be active or they can be , accessible , inaccessible . it was the one that , keith , emailed to us once , to some of us , not all of us . and that i noticed that , list was discourse dependent . it was like in this particular set , s instance , it has been referred to recently or it hasn't been , or this is something that 's like in my world knowledge but not active .  they 're contex and i used to have a location thing there but actually that 's a property of the situation . and it 's again , time , at cert certain points things are located , near or far from you and   some of these are , right . for now 'll just have in this list the things that are relevant to this particular utterance , right ? everything else here is utterance specific . and i left the slot , "" predications "" , open because you can have , things like "" the guy i know from school "" . or , like your referring expression might be constrained by certain like unbounded na amounts of prep predications that you might make . and it 's unclear whether you could just have in your scenario , "" here are some extra few things that are true "" , right ? and then you could just not have this slot here . right ? ","one thing that i didn't do consistently , is when we get there , is like indicate what thing fits into every role . it 'll be another predication or it 'll be , i don't know , some value from some something , some variable and scope like that , or a slot chain based on a variable and scope . you see it 's "" scenario "" , "" referent "" and "" discourse segment "" . and "" scenario "" is essentially what what 's the basic predication , what event happened . and actually it 's just a list of various slots from which you would draw in order to paint your picture , a bunch of frames , bi and bindings , right ? the middle thing used to be "" entities "" and this is intended to be grammatically specifiable information about a referent about some entity that you were going to talk about . it could be a pointer to ontology . because this partly came from , talmy 's schema and i 'm not we 'll need all of these actually . th the big com and finally "" discourse segment "" is about speech act y information structure y , like utterance specific kinds of things . ","On the other hand, the semantic specification structures information in terms of ""scenario"", ""referent"" and ""discourse segment"". Each category comprises a number of slots filled in by information derived from the utterance. "
Bed015.F,"you 're but it 's used for identification purposes . it 's a little bit different from just saying "" all these things are true from my utterance "" .  it 's a little bit different . right ? or that 's like a restrictive , non restrictive it 's like it gets into that thing for but 'm mixing , this is like the final result after parsing the sentence . you might imagine that the information you pass to , in identifying a particular referent would be , "" some "" "" it 's a guy and it 's someone i know from school "" . that would , be some intermediate structure that you would pass into the disc to the , whatever , construal engine or whatever , discourse context , to find either create this reference , in which case it 'd be created here , and you could imagine that this might not i 'm uncommitted to a couple of these things .  it could be in semantically , . it a table . a thing that c doesn't have a gender . it could be that you 'd not all these i wou i would say that i tried to keep slots here that were potentially relevant to most things .  that is semantic as opposed to that 's right .  s again open to various things . right . let 's see . having made that big sca like large scale comment , should go through each of these slots each of these blocks , a little bit ? mostly the top one is image schematic . and just a note , which was that , s when we actually ha  some of them seem more inherently static , like a container or support ish . and others are a little bit seemingly inherently dynamic like "" source , path , goal "" is often thought of that way or "" force "" , like that . but in actual fact , that they 're intended to be neutral with respect to that . and different x schemas use them in a way that 's either static or dynamic . path "" , you could just be talking about the path between this and this . and "" container "" that you can go in and out . all of these things . and this came up when , ben and i were working with the spaniards , the other day the "" spaniettes "" , as we called them to decide like how you want to split up image schematic contributions versus schematic contributions . how do you link them up . it 's gonna be something in the x schema that tells you "" is this static or is this dynamic "" . we definitely need that aspectual type gives you some of that . that , is it , a state or is it a change of state , or is it a , action of some kind ?   ! in the slot ? no , it 's like x sc it 's like i was thinking of type constraints but x schema , it has to be an x schema . "" agent "" , the performer of the x schema , that s depends on the x schema . and i in general it would probably be ,  "" aspectual type "" probably isn't obvious but i should have neglected to stick something in . "" perspective "" , "" actor "" , "" undergoer "" , "" observer "" , we 've often used "" agent "" , "" patient "" , obser exactly . exactly . and one thing that , we had talked about is this example of like , if you have a passive construction then one thing it does is ch definitely , it is one way to for you to , specifically take the perspective of the undergoing object . and then we talked about , whether does that specify topic as there are other things . now that it 's subject is more like a topic . and now that , anyway . i 'm gonna trail off on that one cuz it 's not that f important right now .  to know how exactly .  some of these other ones , let 's see .  one thing i 'm uncertain about is how polarity interacts . polarity , is using for like action did not take place by default it 'll be like "" true "" , if you 're specifying events that did happen . you could imagine that you skip out this leave off this polarity , not don't have it here . and then have it part of the speech act in some way . there 's some negation . but the reason why i left it in is cuz you might have a change of state , let 's say , where some state holds and then some state doesn't hold , and you 're just talking , if you 're trying to have the nuts and bolts of simulation you need to know that , whatever , the holder doesn't and it 's it 's it 's fine where it is .   may come from a few places . right . right .   it 's a grab bag of that 's exactly what it is . and for a particular instance which i will , make an example of something , is that you might have an instance of container and path , let 's say , as part of your , "" into "" definition . you would eventually have instances filled in with various values for all the different slots . and they 're bound up in , their bindings and values . except for "" , that i forgot . but anyway , there 's som some causal structure for composite events . it gets a little funny . ","having made that big sca like large scale comment , should go through each of these slots each of these blocks , a little bit ? mostly the top one is image schematic . some of them seem more inherently static , like a container or support ish . and others are a little bit seemingly inherently dynamic like "" source , path , goal "" is often thought of that way or "" force "" , like that . it 's gonna be something in the x schema that tells you "" is this static or is this dynamic "" . one thing i 'm uncertain about is how polarity interacts . polarity , is using for like action did not take place it 's a grab bag of except for "" , that i forgot . ",
Bed015.F,"these are all far these structures , especially from "" path "" and on down , these are relatively familiar , image schematic slots . now with "" , the fillers will actually be themselves frames . right ? you 'll say , "" event one causes event b event two "" , and that 's , these are all implicitly one within , within one world .  even though saying that place takes place , whatever . if y if i said "" time "" is , "" past "" , that would say "" set that this world "" , "" somewhere , before the world that corresponds to our current speech time "" . but that 's the within the event it 's st it 's still one world .  and other frames that could come in unfortunately you could bring in say "" desire "" like that , like "" want "" . and actually there is right now under "" discourse segments "" , "" attitude "" ? "" volition "" ? could fill that . there are a couple things where i like , "" i 'm not if i wanted to have it there or "" there was a whole list of possible speaker attitudes that like say talmy listed . and i don't it was like "" hope , wish . desire "" , blah blah . and it 's like , i feel like if i wanted to have an extra meaning i don't know if those are grammatically marked in the first place . they 're more lexically marked , right ? at least in english . if i wanted to i would stick in an extra frame in my meaning , saying , e th it 'd be a hierarchical frame them , right ? like "" naomi wants su a certain situation and that situation itself is a state of affairs "" . u can be just another frame that 's part of your  situation . right , right .     right . exactly .  right . right , right . s would prefer not to worry about that for right now and to think that there are , discourse level constructions in a sense , topic focus constructions that would say , "" when you focus something "" then just done the same way just actually in the same way as the lower level . if you stressed , "" john went to the "" , "" the bar "" whatever , you 're focusing that and a in a possible inference is "" in contrast to other things "" . similarly for a whole sentence , "" in france such and such happens "" . the whole thing is like again implicitly as opposed to other things that are possible .     for a particular segment it 's really just a reference to some other entity again in the situation , right ? for a particular segment the speaker might be you or might be me . hearer is a little bit harder . it could be like multiple people . that 's not very clear from here that 's not allowed here .  ye th right , the constructions might will refer , using pronouns or whatever . in which case they have to check to see , who the , speaker in here wa in order to resolve those . but when you actually say that "" he walked into "" , whatever , the "" he "" will refer to a particular you will already have figured who "" he "" or "" you "" , or "" i "" , is a bett better example , who "" i "" refers to . and then you 'd just be able to refer to harry , in wherever that person whatever role that person was playing in the event .  s that 's that 's just n speaker is known from the situation , right ? you 're when you hear something you 're told who the speaker is who the speaker is . that 's constraining how in some ways this before you get to the you fill in all the rest of it .  how else would you  right .  right , right .  s would say ref under referent should be something that corresponds to "" i "" . and each referent should probably have a list of way whatever , the way it was referred to . that 's "" i "" but , should we say it refers to , what ? if it were "" harry "" it would refer to like some ontology thing . if it were if it 's "" i "" it would refer to the current speaker , which is given to be like , whoever it is . "" i "" within the current world .    this entire thing is inside a world , not just like the top part . that 's   right . right . thought of having like for each referent , having the list of the things t with which it is identified . which , you you   it depends on if it is a referring exp if it 's identifiable already or it 's a new thing . if it 's a new thing you 'd have to like create a structure or whatever . if it 's an old thing it could be referring to , usually w something in a situation , right ? in ontology .  there 's a whatever , it c it could point at one of these . for what ? if it works .   we 're crossing our fingers .    use the same  and and  by default    right . right . that makes sense . no ! really ? you 're kidding . no , that 's horrible .  that 's horrible .    it 's like the unspecified mental spaces just are occurring in context . ","that 's , these are all implicitly one within , within one world . or "" there was a whole list of possible speaker attitudes that like say talmy listed . i don't know if those are grammatically marked in the first place . if you stressed , "" john went to the "" , "" the bar "" whatever , you 're focusing that and a in a possible inference is "" in contrast to other things "" . for a particular segment it 's really just a reference to some other entity again in the situation , right ? right , the constructions might will refer , using pronouns or whatever . but when you actually say that "" he walked into "" , whatever , the "" he "" will refer to a particular it depends on if it is a referring exp if it 's identifiable already or it 's a new thing . if it 's a new thing you 'd have to like create a structure or whatever . if it 's an old thing it could be referring to , usually w something in a situation , right ? it 's like the unspecified mental spaces just are occurring in context . ",
Bed015.F,"and then when you embed them sometimes you have to pop up to the h depending on the construction or the whatever , you you 're scope is m might extend out to the base one . it would be to actually use the same , mechanism since there are many cases where you actually need it 'll be one or the other . it 's like , actually , it 's the same operation .      right . robert . ties it all into it .    that 's why i said "" point to robert "" , when i did it .  it 's like i don't think i mostly think , actually one of the child language researchers who works with t tomasello studied a bunch of these constructions and it was like it 's not using any interesting embedded ways just to mark , uncertainty like that .  hedges ? hhh , i there used to be a slot for speaker , it was something like factivity . i couldn't really remember what it meant took it out . but it 's something we were talking about sarcasm too , right ?  right .   what 's the word ? as a hedge . what ? i 'd love to know . and someone had raised like sarcasm as a complication at some point . and we just won't deal with sarcastic people . certainly not as some they 're intonational markers for the most part . i don't know too much about the like grammatical   do we have any ?  m mockery .   in model theory cuz the semantics is always like "" speaker believes not p "" ,  like "" the speaker says p and believes not p "" . but right , but , if we knew anybody like that . for the same , data .  or me . or me . anyways   yes .   not really just on the constructions , right ?   i didn't want to think too much about that for now . it was subconsciously intentional .    refer to them . and there are certainly cases like that . even with just semantic schemas we have some examples .  and we 've been talking a little bit about that anyway . inherits . those are over rated . all the things you want to query , you just have to like ask for separately . bayes ?  grout out the things that you need .  best explanation . when are you leaving ? thursday , friday ?  can we do one thirty ? you already told me no . one , it 's fine . do one . it 's fine . it 's fine . it 's fine . fine .  no , no , i don't care . it 's fine .  four .  i am . ","and then when you embed them sometimes you have to pop up to the h depending on the construction or the whatever , you you 're scope is m might extend out to the base one . actually one of the child language researchers who works with t tomasello studied a bunch of these constructions and it was like it 's not using any interesting embedded ways just to mark , uncertainty like that . hhh , i there used to be a slot for speaker , and someone had raised like sarcasm as a complication at some point . i didn't want to think too much about that for now . grout out the things that you need . four . ",
Bed017.A,"why ? no , cuz she already told me it , before she told you . it doesn't matter what time . she hadn't just started transcribing me yet . anyway . i beg to differ . but you have to say something genuinely funny before you 'll get an example . no , it 's a different laugh .  whoa !   hi . hi . when you said "" andreas "" you were talking about stolcke . now i know that we aren't ,     that 's good . that 's definitely a job for artificial intelligence . except for humans can't really solve it either ,  and then you can blame the computer .  that should be one of them .  and some of the i don't know how much about the larger heidelberg project , i are you it seems like a lot of some of the issues are the same . it 's like , the c context based factors that influence how you interpret , s how to interpret . in this case , infer in knowing wanting to kinds of things to ask . we 've talked about that , but we haven't worried too much about that end of the discourse . but you guys had that in the previous models . documents that have the answers .  right . right .  you also don't have to figure out what the content is . you 're just taking the keywords as a topic text , as  right .      you 're not 'm trying to figure out how it maps to the kinds of things that we 've talked about in this group , and , actually associated groups , cuz some of us do pretty detailed linguistic analyses , and i 'm guessing that you won't be doing that ?  just checking .  you take the query , and      he had other things to do . the the other person of is dan gildea ? because he did some work on topic spotting w which is , you i don't depending on how you wanna integrate with that end , taking the data and fig you said the learning systems that figure out we there 's someone in icsi who actually has been working on has worked on that kinda and he 's worked with frame net , you could talk to him about , both of those things at once .  and he just finished writing a draft of his thesis .  i u dan gildea , gildea . and , he 's in one of the rooms on the fifth floor and and  if you fal solve the problem , hope you can do one for us too . talk about changing the topic . at least this is a private meeting . right , exactly , that 's the link . definitely . but for adults and not for the children .      greater than two ? right . ","cuz some of us do pretty detailed linguistic analyses , and i 'm guessing that you won't be doing that ? the other person of is dan gildea ? we there 's someone in icsi who actually has been working on has worked on that kinda ","Although no detailed linguistic analysis takes place, it was suggested that the use of FrameNet could be a useful approach. There were also further suggestions for meetings with ICSI researchers. "
Bed017.B," how to toggle the display width function yo .  in a smaller group we had talked and decided about continuation of the data collection . fey 's time with us is almost officially over , and she brought us some thirty subjects and , t collected the data , and ten dialogues have been transcribed and can be looked at . if you 're interested in that , talk to me . and we found another cogsci student who 's interested in playing wizard for us . here we 're gonna make it a little bit more complicated for the subjects , this round . she 's actually suggested to look at the psychology department students , because they have to partake in two experiments in order to fulfill some requirements . they have to be subjected , before they can actually graduate . and we want to design it that they really have to think about having some time , two days , to plan certain things and figure out which can be done at what time , and , package the whole thing in a re in a few more complicated structure . that 's for the data collection . as for smartkom , i 'm the last smartkom meeting i mentioned that we have some problems with the synthesis , which as of this morning should be resolved . and , "" should be "" means they aren't yet , but have the info now that i need . plus , johno and i are meeting tomorrow , when tomorrow is over , we 're done . and ha n hav we 'll never have to look at it again it 'll take some more time , to be realistic , but at least we 're seeing the end of the tunnel there . that was that .  the don't think we need to discuss the formalism that 'll be done officially s once we 're done .  something happened , in on eva 's side with the prm that we 're gonna look at today , and we have a visitor from bruchsal from the international university . andreas , you 've met everyone except nancy . hi . hi . and , andy , you actually go by andy , right ?   that will be reuter ?  my scientific director of the eml is also the dean of the international university , one of his many occupations that just contributes to the fact that he is very occupied . and , the he @ @ might tell us a little bit about what he 's actually doing , and why it is s somewhat related , and by using some of the same technologies that we are using . and was that enough of an update ? in what order shall we proceed ? you have your on line first of all great looks , mu much cleaner , nnn , nnn , certain beauty in it , if beauty is truth , then , we 're in good shape . but , the as , mentioned before we probably should look at t the details . if you have a write up then i 'd love to read it and because , you go all the way back to the very top ? these @ @ these w when these are instantiated they take on the same values ? that we had before ? or are they have they changed , in a sense ?    and the , other question i would have is that presumably , from the way the stanford people talk about it , you can put the probabilities also on the relations . if it 's in the definition or in the in daphne 's definition of a prm is that classes and relations , and you 're gonna have cpt 's over the classes and their relations . more uncertainty , or i should say . that would be exactly my question .     then the w long term perspective is pretty clear . we get rocking and rolling on this again , once we get a package , if , when , and how , then this becomes foregrounded profiled , focused , again . and until then we 'll come up with a something that 's @ @ that 's way more complicated for you . right ? because this was laughingly easy , right ? that 's not even something humans   but what does it would a pote potential result be to split up and never talk to each other again ?   good . then , we can move on and see what andreas has got out his sleeve . or andy , for that matter ?  in a in one t one s small difference in a way , is that he doesn't have to come up with an answer , but he wants to point to the places w you have to s still m understand what the content says about itself , and then match it to what you think the informational needs  remember the prashant story ? the no linguistic background person that the iu sent over here . and andreas and i tried to come up wi or we had come up actually with a with him working on an interface for framenet , as it was back then , that would p do some of the work for this machine , which never got done because prashant found a happy occupation which in the  but 'm just saying , the we had that idea to exploit framenet there as and and srini 's doing information extraction also , right ? with that framenet base .  it 's in the program ? you are being recorded right now , beware . who ? take you to his office . it 's just around the corner . i 'm i have think it was november two thousand three or some no . wh i had something in my calendar .  bribe my way out of this .  ","in a smaller group we had talked and decided about continuation of the data collection . fey 's time with us is almost officially over , and she brought us some thirty subjects and , t collected the data , and ten dialogues have been transcribed and we found another cogsci student who 's interested in playing wizard for us . here we 're gonna make it a little bit more complicated for the subjects , this round . she 's actually suggested to look at the psychology department students , because they have to partake in two experiments in order to fulfill some requirements . as for smartkom , i 'm the last smartkom meeting i mentioned that we have some problems with the synthesis , which as of this morning should be resolved . when tomorrow is over , we 're done . something happened , in on eva 's side with the prm that we 're gonna look at today , we have a visitor from bruchsal from the international university . and the , other question i would have is that presumably , from the way the stanford people talk about it , you can put the probabilities also on the relations . good . then , we can move on and see what andreas has got out his sleeve . ","There is a new wizard for phase two, during which subjects will be given more complex scenarios. Also finished are the modifications on SmartKom: the remaining glitches will take no more than a day to iron out. A big part of the meeting was covered by the presentation of the PRM of the proposed system. Following this, a visiting researcher presented an overview of a parallel project at the International University. "
Bed017.B,"did some double checking and it seems like spring break in two thousand one . no . this they refused the budget again ? is it about citris ? still nothing . did manage to get pull my head out of the sling by sidetracking into citris , but or a temporarily putting it out of the sling but , i 'll volunteer to put it right back in by stating that i am n among some other things in the process of writing up that we have been discussing at our daily meetings , and also revising , for all the comments , the c the original construal proposal . and , if i put one and one together , i may end up with a number that 's greater than one and that potentially present once you get back . nnn . s sometimes , the sum is not less than the  but and hopefully all sidetracking other things will have disappeared , soon . ",this they refused the budget again ? is it about citris ? still nothing . ,
Bed017.C,"  cuz there is another andreas around , to avoid some confusion .  for having me here , first of all . just a little background on my visit . i 'm not really involved in any project , that 's that 's relevant to you a at the moment , the reason is really for me to have an opportunity to talk to some other researchers in the field . and 'll just n give you a real quick introduction to what i 'm working on , and hope that you have some comments or , you 're interested in it to find out more , and 'll be happy to talk to you and i 'd also like to find out some more and 'll just walk around the office and and then and ask some questions , in a couple days . 'll be here for tomorrow and then the remainder of next week . what i started looking at , to begin with is just content management systems i in general .  what 's the state of the art there is to you have a bunch of documents or learning units or learning objects , and you store meta data associate to them . there 's some international standards like the i triple e , there 's an i triple e , lon standard , and these fields are pretty straightforward , you have author information , you have size information , format information and on . but they 're two fields that are more interesting . one is you store keywords associated with the with the document , and one is you have , what is the document about ? it 's some taxonomic ordering of the units . now , if you put on your semantic glasses , you say , that 's not all that easy , because there 's an implicit assumption behind that is that all the users of this system share the same interpretation of the keyword and the same interpretation of whichever taxonomy is used , and that 's a very that 's a key point of these systems and they always brush over this real quickly without really elaborating much of that and the only thing that m really works out far are library ordering codes , which are very , very coarse grain , you have some like , science , biology , and then but that 's really all that we have at the moment . think there 's a huge , need for improvement there . now , what this standard like this would give us is we could with a search engine just query different repositories all over the world . but we can't really what i 'm what i try to do is to have the scenario is the following , you 're working on some project and you encounter a certain problem . now , what we have at our university quite a bit is that students try to u program a certain assignment , they always run into the same problems , and they always come running to us , and they 'll say why 's it not it 's not working , and we always give out the same answer , we thought , it 'd be to have a system that could take care of this , and what i want to build is smart f a q system . now , what you need to do here is you need to provide some context information which is more elaborate than "" i 'm looking for this and this keyword . ""  and that i don't need to tell you this . i 'm you have the same when somebody utters a sentence in a certain , context it , and the same sentence in another context makes a huge difference . i want to be able to model information like , in the context of in the context of developing distributed systems , of a at a computer science school , what software is the person using , which homework assignment is he or she working on at the moment , what 's the background of that student 's which error message was encountered . this information should be transmitted , when a certain document is retrieved . now ,  giving this we somehow need to have a formalized way of writing this down and that 's where the shared interpretation of certain terms and keywords comes in again . and , using this and some knowledge about the domain you can do some simple inferences . like that when somebody 's working about working on servlets he 's using java , cuz servlets are used are written in java . some inferences like that , now , u using this you can infer more information , and you could then match this to the meta data of off the documents you 're searching against . what i wanna do is have some given these inputs , and then compute how many documents match , and use this as a metric in the search . now , what i plan to do is i want to do a try to improve the quality of the search results , and i want to do this by having a depth steepest descent approach . if i knew which operating system the person was working on , would this improve my search result ? and having a symbolic formalized model of this i could simply compute that , and find out which which questions are worth asking . and that 's what i then propagate back to the user , and try to optimize the search in this way . now , the big problem that i 'm facing right now is it 's fairly easy to hack up a system quickly , that works in the small domain , but the problem is the scalability . ","what i started looking at , to begin with is just content management systems i in general . what 's the state of the art there is to you have a bunch of documents or learning units or learning objects , and you store meta data associate to them . there 's some international standards because there 's an implicit assumption behind that is that all the users of this system share the same interpretation of the keyword and the same interpretation of whichever taxonomy is used , and the only thing that m really works out far are library ordering codes , and what i want to build is smart f a q system . now , what you need to do here is you need to provide some context information i want to be able to model information like , in the context of in the context of developing distributed systems , of a at a computer science school , now , u using this you can infer more information , and you could then match this to the meta data of off the documents you 're searching against . now , what i plan to do is i want to do a try to improve the quality of the search results , now , the big problem that i 'm facing right now is it 's fairly easy to hack up a system quickly , that works in the small domain , but the problem is the scalability . ","It attempts to build a smart tutoring system for a computer science course. The assumption is that document searches can give more personalised results, if they take into account contextual parameters (user, situation). "
Bed017.C,"and robert was mentioning earlier today is that microsoft with their printer set up program has a bayesian network , which does exactly this , but there you face a problem that these are very hard to extend . and what i 'm what i try to do is try to model this in a way that you could really combine knowledge from very different sources , and looking into some of the ideas that the semantic web community came up with . trying to have an approach how to integrate s certain representation of certain concepts and also some computational rules , what you can do with those .  what i 'm also looking into is a probabilistic approach into this because document retrievals is a very fuzzy procedure , it 's probably not that easy to simply have a symbolic computational model . that probably isn't expressive enough . that 's another thing , which you 're also looking into right now . and then as an add on to this whole idea , that would be now , depending on what the search engine or the content repository depending on which which rules and which ontologies it uses , or its view of the world , you can get very different results . it might ma make a lot of sense to actually query a lot of different search engines . and there you could have an idea where you actually have peer to peer approach , where we 're all carrying around our individual bookshelves , and if you have a question about a homework , it 's probably makes sense to ask somebody who 's in your class with you , the guru in the certain area , rather than going to some yahoo like search engine . these are some of the just in a nutshell , some of the ideas . and lot of the even though it 's a very different domain , but lot of the , issues are fairly similar .   know , know abou about it .  i 'm not i 'm not building an expert i want to build a smart librarian , that can point you to the right reference . i don't wanna compute the answer , it 's a little bit easier for me .  i assume that the there will be learning systems that tag their content . and m @ @ and what i envision is that you rather than just supplying a bunch of keywords you could for an faq you could state like a logic condition , when this document applies . this document explains how to set up your mail account on linux "" like this . something very specific that you can then but the that the key point with these learning systems is that a learning system is only as good as the amount of content it carries . you can have the best learning system with the best search interface , if there 's no content inside of it , it 's not very useful . think ultimately because developing these rules and these inference inferences is very costly , think you must be able to reuse some existing domain information , or ontologies that other people wrote and then try to integrate them , and then also search the entire web rather than just the small content management system . think that 's crucial for the success of or @ @  no . no .  not too much , but i have a rough overview .   i 'm could learn a lot about just how to come up with these structures , cuz it 's very easy to whip up something quickly , but it then makes sense to me , but not to anybody else , and if we want to share and integrate things , they must they must be designed really .  except prashant ?  don't know , the think it 's really the lack of students at iu at the moment . it 's ju it 's more the lack of students , really , and w we have all these sponsors that are always eager to get some teams . but mean if i were a student , i 'd love to come here , rather than work for some german company , or i didn't say anybody to anything to offend except for the sponsors but   'll go to the semantic web workshop , in two weeks .   who is that again ? great .  ","what i 'm also looking into is a probabilistic approach into this it 's probably not that easy to simply have a symbolic computational model . and lot of the even though it 's a very different domain , but lot of the , issues are fairly similar . i want to build a smart librarian , that can point you to the right reference . i don't wanna compute the answer , no . cuz it 's very easy to whip up something quickly , and if we want to share and integrate things , they must they must be designed really . ","It attempts to build a smart tutoring system for a computer science course. Although no detailed linguistic analysis takes place, it was suggested that the use of FrameNet could be a useful approach. "
Bed017.D,"  what is it ?  there .  don't know how to get to the next page . here . actually there . how weird . what ? !  i wasn't even doing anything . that was r actually robert 's idea . but anyhow .     i 've be just been looking at , ack ! what are you doing ?    i 've been looking at the prm  this is , like the latest thing i have on it , and i sorta constructed a couple of classes . like , a user class , a site class , and a time , a route , and then and a query class . and i tried to simplify it down a little bit , that actually look at it more . it 's the same paper that i gave to jerry last time .  took out a lot of a lot of the decision nodes , and then tried to the red lines on the , graph are the relations between the different classes . like , a user has like , a query , and then , also has , reference slots to its preferences , the special needs and , money , and the user interest . and this is more or less similar to the flat bayes net that i have , with the input nodes and all that . and tried to construct the dependency models , and a lot of these got from the flat bayes net , and what they depend on , and it turns out , the cpt 's are really big , if i do that , tried to see how do , put in the computational nodes in between . and what that would look like in a prm . and ended up making several classes actually , a class of with different attributes that are the intermediate nodes , and one of them is like , time affordability money affordability , site availability , and the travel compatibility . and some of these classes are s some of these attributes only depend on from , say , the user , or s f just from , i don't know , like the site . s like , these here , it 's only like , user , but , if you look at travel compatibility for each of these factors , you need to look at a pair of , what the preference of the user is versus , what type of an event it is , or which form of transportation the user has and whether , the onsite parking matters to the user , in that case . and that makes the scenario a little different in a prm , because , then you have one user objects and potentially you can have many different sites in mind . and for each of the site you 'll come up with this rating , of travel compatibility . and , they all depend on the same users , but different sites , and that makes a i 'm tr i w i wa have been trying to see whether the prm would make it more efficient if we do inferencing like that . and you end up having fewer number of nodes than in a flat bayes net , cuz otherwise you would c it 's probably the same . but no , you would definitely have be able to re use all the user and not having to recompute a lot of the because it 's all from the user side . if you changed sites , you can , save some work on that . but , in the case where , it depends on both the user and the site , then i 'm still having a hard time trying to see how using the prm will help . anyhow , using those intermediate nodes then , this would be the class that represent the intermediate nodes . and that would it 's just another class in the model , with , references to the user and the site and the time . and then , after you group them together this no the dependencies would of the queries would be reduced to this . and it 's easier to specify the cpt and all . think that 's about as far as i 've gone on the prm right . the output . it only makes two decisions , in this model . and one is how desirable a site is meaning , how good it matches the needs of a user . and the other is the mode of the visit , whether th it 's the eva decision .  instead of doing a lot of , computation about , which one site it wants of the user wants to visit , i 'll come try to come up with like , list of sites . and for each site , where h how it fits , and rating of how it fits and what to do with it .  anything else i missed ? no , not yet ,      i can't really see the whole thing . leave them to similar things . some of the things might that might be different , like are that the hours for the site . and , eventually i meant that to mean whether they 're open at this hour or not . and status would be , more or less like , whether they 're under construction , and or like that . which is the structural uncertainty ? i remember them learning when , you don't know the structure for but i don't remember reading how you specify wh to start with .     actually i had to take out a lot of the complicated cuz i made it really complicated in the beginning , and jerry was like , "" this is just too much "" . ","i 've been looking at the prm i sorta constructed a couple of classes . like , a user class , a site class , and a time , a route , and then and a query class . and i tried to simplify it down a little bit , the red lines on the , graph are the relations between the different classes . this is more or less similar to the flat bayes net that i have , with the input nodes and all that . tried to construct the dependency models , a lot of these got from the flat bayes net , and it turns out , the cpt 's are really big , if i do that , and ended up making several classes actually , a class of with different attributes that are the intermediate nodes , and one of them is like , time affordability money affordability , site availability , and the travel compatibility . but , if you look at travel compatibility for each of these factors , you need to look at a pair of , what the preference of the user is versus , what type of an event it is , and that makes the scenario a little different in a prm , anyhow , using those intermediate nodes then , this would be the class that represent the intermediate nodes . with , references to the user and the site and the time . and it 's easier to specify the cpt and all . it only makes two decisions , in this model . and one is how desirable a site is meaning , how good it matches the needs of a user . and the other is the mode of the visit , whether th it 's the eva decision . i remember them learning when , you don't know the structure for but i don't remember reading how you specify ","An alternative representation of the Bayes-net, it depicts context features as classes, and dependencies as relations between them. The current outputs show the desirability of a site, as well as its EVA mode. "
Bed017.E,"i 'm known . i no , she told me a long time ago . she told me like two weeks ago . let me explain something to you . my laugh is better than yours .  no . you should be at least be self satisfied enough to laugh at your own jokes . holy mackerel . eva 's got a laptop , she 's trying to show it off . once again . designated ? that 'd be second . that 's a long way away .  ",,
Bed017.F,"o k . here we are . once again , right , together . we haven't had a meeting for a while , and probably won't have one next week , number of people are gone . robert , why don't you bring us up to date on where we are with edu ? good .   no . you didn't yet tell us what the output is . what decisions does this make ? that was pretty quick . she 's ac eva 's got a little write up on it that probably gives the details to anybody who needs them .   the you didn't look yet to see if there 's anybody has a implementation .  one of the questions , about these p r ms is we aren't gonna build our own interpreter , if we can't find one , then we go off and do something else and until s one appears . one of the things that eva 's gonna do over the next few weeks is see if we can track that down .  the people at stanford write papers as if they had one , but , we 'll see . anyway . that 's a major open issue . if there is an interpreter , it looks like what eva 's got should run and we should be able to actually try to solve , the problems , to actually take the data , and do it . and we 'll see . i actually think it is cleaner , and the ability to instantiate , instance of people and sites and will help in the expression . whether the inference gets any faster or not i don't know . it wouldn't surprise me if it doesn't . it 's the same information . there are things that you can express this way which you can't express in a normal belief net , without going to some incredible hacking of rebuilding it on the fly . the notion of instantiating your el elements from the ontology and fits this very nicely and doesn't fit very into the extended belief net . that was one of the main reasons for doing it .  i don't know . people who have thought about the problem , like robert i it looked to me like if eva were able to come up with a value for each of a number of sites plus its eva thing , that a travel planner should be able to take it from there . and with some other information about how much time the person has and whatever , and then plan a route .  i that 's that was actually in the previous the ubenth i don't remember whether they carried that over to this or not , structural uncertainty .  alright .   right .  the plan is when daphne gets back , we 'll get in touch and supposedly , we 'll actually get s deep connected to their work and somebody 'll if it 's a group meeting once a week probably someone 'll go down and , whatever . we 'll actually figure all this out .  you could , from this , go on and say suppose there 's a group of people traveling together and you wanted to plan something that somehow , with some pareto optimal thing for or right . right . that 's the that would be a you could sell it , as a you don't have to fight about this , just give your preferences to the w exactly . right . anyway . there i there are some u elaborations of this that you could try to put in to this structure , but i don't think it 's worth it now . because we 're gonna see what else what else we 're gonna do . anyway . but it 's good , and there were a couple other ideas of things for eva to look at in the interim . on the other hand , framenet could be useful . do the framenet story ?  th that 's another thing you might wanna look into while you 're here . because , the standard story is that keyworks keywords evoke frames , and the frames may give you additional keywords or if that a bunch of keywords indicate a frame , then you can find documents that actually have the whole frame , rather th than just individual there 's a lot of and people are looking at that . most of the work here is just trying to get the frames right . there 's linguists and and there 's a lot of it and they 're busily working away . but there are some application efforts trying to exploit it . and this looks t it seems to be that this is a place where you might be able to do that . right . right . right .  w i know , it he w he did w what he did was much more s sensible for him .    the idea was there .  actually you guys never right .  you guys never sent anybody else from i u . you were y no  this was supposedly an exchange program , and i we it 's fine . we don't care , but it just i 'm a little surprised that andreas didn't come up with anyone else he wanted to send . alright . had forgotten a i to be honest with you , i 'd forgotten we had a program .   no , no . there was a whole co there was a little contract signed . it was  i know . right . right .  right . right ! right . anyway . right . thi tha that 's one of the things that might be worth looking into while you 're here . unfortunately , srini , who is heavily involved in daml and all this is himself out of town . right , and ","robert , why don't you bring us up to date on where we are with edu ? the you didn't look yet to see if there 's anybody has a implementation . we aren't gonna build our own interpreter , one of the things that eva 's gonna do over the next few weeks is see if we can track that down . the people at stanford write papers as if they had one , anyway . that 's a major open issue . i actually think it is cleaner , the notion of instantiating your el elements from the ontology and fits this very nicely and doesn't fit very into the extended belief net . the plan is when daphne gets back , we 'll get in touch and supposedly , we 'll actually get s deep connected to their work somebody 'll if it 's a group meeting once a week probably someone 'll go down and , whatever . on the other hand , framenet could be useful . unfortunately , srini , who is heavily involved in daml and all this is himself out of town . ","The fact that this model allows for instantiations of classes fits the research purposes much better than the extended belief-net. Although no detailed linguistic analysis takes place, it was suggested that the use of FrameNet could be a useful approach. "
Bed017.F,"for some reason he 's not doing that . i don't know why he @ @ i , who knows ? anyway , s you 'll see you 'll certainly see a lot of the people there .  st statistical that would be a very good idea . alright , was there anything else for this ? one of these times soon we 're gonna hear about construal . right . good thinking ! no , but he 's he 's as you said , he 's , like the state legislature , he 's trying to offer us bribes . this t the s we 're , involved in a literally three hundred million dollar program . with the state of california . and , the state of california is now a month and a half behind its legis its legally required date to approve a budget . the budget has not been approved . and two days ago there 's two l two branches of legislature . one branch approved it , and , yesterdayday there was this thought that the other branch would just approve it , but now there 's actually a little back sliding to people who approved it got flak from there , anyway .  i have to tell you a wonderful story about this ,  and then we 'll go . i it turns out i wound up having lunch today with a guy named tom kalil . kill kalil . and , he now works at berkeley . he 's hired to run a lot of citris , even though we don't have the money they they 've been hiring people right and left , they think the money 's coming . and he was , the chief staffer to clinton on technology matters . he was in the white house , i don't remember what he was saying . a anyway , like that . and , is now doing all the politics for citris , but also , has a a lot of interest in actually doing things for society , digital divide and like that . that 's interesting to me but not to you . but the really interesting thing was , he st he s said something about , 'm interested in things that have high social multiplier , something that is of great social value . he said , "" , this was his only example , "" if you had a adult literacy program that was as good as an individual tutor , and as compelling as a video game , then that would have a huge social impact "" . i said , "" great ! that 's a good problem to work on . "" anyway . it was that he 's got this view , of a , that 's what you should try to do , and b , language would be a good way to do it . that 's anyway , that 's the end of the story . this was i didn't push him on the ch on the child thing , but , a again , if you if you  and this was literacy , which actually is somewhat different problem . easier . i don't know . this is reading , rather than teaching another project we started on , and didn't get funded for was , to try to build an automatic tutoring program , for kids whose first language wasn't english . which is like half the school population in california . something like that , isn't it ?   enormous problem in california , and the idea was if we 're smart about language understanding and speech understanding , couldn't we build programs that would be tutors for the kids . we think we could . anyway . but this is a slightly different problem , and  i know none of us have the spare time to look at it right now , but it i it 's interesting and i may talk to him some more about is somebody already doing this , and like that . anyway , that was today 's little story . no , no . right .  you 're good . right . right . anyway . that 'd be great , but i 'd it 's time again , right ?  good .  done ? ","i it turns out i wound up having lunch today with a guy named tom kalil . he 's hired to run a lot of citris , he said , "" , "" if you had a adult literacy program that was as good as an individual tutor , and as compelling as a video game , then that would have a huge social impact "" . i said , "" great ! that 's a good problem to work on . "" ",
Bmr003.A,"this is one channel . can you say your name and talk into your mike one at a time ?  i don't think it 's on there , jane . i still don't see you jane . i s no . the mike isn't close enough to your mouth ,  s try speaking loudly ,   good .  we don't wanna renumber them , cuz we 've already have like , forms filled out with the numbers on them . let 's keep the same numbers on them . dan , are you on ? good . and i 'm getting lots of responses on different ones , assume the various and assorted p z ms are on .  this is not something you need to attend .  besides , i don't want anyone who has a weird accent . right , dan ? then put it on your head . what are you doing ? i m i would prefer that people wore it on their head but they were complaining about it . because it 's not it doesn't go over the ears . it 's very badly designed it 's but , there 's nowhere to put the pad it 's comfortable . and it feels good that way . again would like to do some digits .   let me i 'm just that digit y g sorta guy .  this is adam . i doubt it . we 're session four or m it might be five . i didn't bring my previous thing . d leave the channel blank . right . transcript number .  should i turn off the vu meter dan ? do you think that makes any difference ? why ? are you gonna do something other than hit "" quit "" ?  should have done it before . the vu meter which tells you what the levels on the various mikes are and there was one hypothesis that perhaps that the act of recording the vu meter was one of the things that contributed to the errors . that was me , that was the only reason that could be is if the driver has a bug . right ? because the machine just isn't very heavily loaded . no chance of that . just because it 's beta . look we usually do that .  that 's what we 've done before . which means we need to move this thing , and sorta decide how we 're actually going to do things .  right .  that 'll work . that 'll work . that 's right .   topic of this meeting is i wanna talk a little bit about transcription . i 've looked a little bit into commercial transcription services and jane has been working on doing transcription . and we wan wanna decide what we 're gonna do with that and then get an update on the electronics , and then , also talk a little bit about some infrastructure and tools , and on . eventually we 're probably gonna wanna distribute this thing and we should decide how we 're gonna handle some of these factors .   right . right . we 're collecting a corpus and it 's gonna be generally useful . it seems like it 's not a corpus which is has been done before . and think people will be interested in having it , and we will excuse me ?  audio d v c ds ,  and how we do we distribute the transcripts , how do we distribute the audio files , how do we just do all that infrastructure ? right , but should we do it in the same format as ldc and what does that mean to what we 've done already ? right .  as it is , it 's ad hoc combination of dan set and set up , which we may wanna make a little more formal .  right . that 's right .  i was actually thinking i wouldn't mind spending the summer up there . that would be fun .  visit my friends and spend some time and then also i have a bunch of for doing this digits . have a bunch of scripts with x waves , and some perl scripts , and other things that make it really easy to extract out and align where the digits are . and if u d uw 's going to do the same thing it 's worth while for them to do these digits tasks as and what i 've done is pretty ad hoc , we might wanna change it over to something a little more standard . stm files , or xml , what 's that ? they certainly wanna collect more data . and they 're applying , b is that right ? something like that . for some more money to do more data . we were planning to do like thirty or forty hours worth of meetings . they wanna do an additional hundred or hours . they want a very large data set . but we 're not gonna do that if we don't get money .  and i would like that just to get a disjoint speaker set and a disjoint room . one of the things morgan and i were talking about is we 're gonna get to know this room really the acoustics of this room . including the fan . it 's enormous . all the others have been on . y absolut  there 's definitely  high pitch   just get a variety . they 're very good . carbon monoxide poisoning ?    i wish i wish we had someone here working on adaptation because it would to be able to take that and adapt it to a meeting setting .  no , software , to adapt the speech recognition .  that 's true . that 's not good , right ? just these . we can look into it . we can get that just with , media costs , is that right ?  great . ","topic of this meeting is i wanna talk a little bit about transcription . i 've looked a little bit into commercial transcription services and jane has been working on doing transcription . and then get an update on the electronics , eventually we 're probably gonna wanna distribute this thing it seems like it 's not a corpus which is has been done before . and how we do we distribute the transcripts , how do we distribute the audio files , but should we do it in the same format as ldc have a bunch of scripts with x waves , and some perl scripts , and other things that make it really easy to extract out and align where the digits are . and if u d uw 's going to do the same thing it 's worth while for them to do these digits tasks as and what i 've done is pretty ad hoc , we might wanna change it over to something a little more standard . stm files , or xml , we were planning to do like thirty or forty hours worth of meetings . because it would to be able to take that and adapt it to a meeting setting . ","The Berkeley Meeting Recorder group discussed the aims, methods, timing, and outsourcing issues concerning transcription of the Meeting Recorder corpus. The group received an update on the meeting room recording setup and electronics. "
Bmr003.A,"that would be that would be something to look into .  it 's silly to do unless we 're gonna have someone to work on it , we need to think about it a little bit .  why don't you go ahead and do that then eric ? right . actually , that 's another thing i was thinking about is that jane should talk to liz , to see if there are any transcription issues related to discourse that she needs to get marked . a meeting . this is the meeting about the meeting .    i was even thinking that we need to at least ping the u dub to see say "" this is what we 're thinking about for our transcription "" , if nothing else . shall we move on and talk a little bit about transcription then ?  since that 's what we 're talking about . what we 're using right now is a tool , from this french group , called "" transcriber "" that seems to work very  it has a , useful tcl tk user interface and , right . yes ,  right , right . we 're at this point only looking for word level . all what you have to do is just identify a segment of speech in time , and then write down what was said within it , and identify the speaker . and the things we that we know that i want are the text , the start and end , and the speaker . but other people are interested in stress marking . and jane is doing primary stress , stress marks as and then things like repairs , and false starts , and , filled pauses , and all that other we have to decide how much of that we wanna do .     that 's part of the thing we 're talking about . what we wanted to do was have jane do one meeting 's worth , forty minutes to an hour , and  ten times about , is and one of the things was to get an estimate of how long it would take , and then also what tools we would use . and the next decision which has to be made actually pretty soon is how are we gonna do it ?  r right , one option is to get linguistics grad students and undergrads to do it . and that 's happened in the past . and that 's probably the right way to do it . it will require a post pass , people will have to look at it more than once to make that it 's been done correctly , but can't imagine that we 're gonna get anything that much better from a commercial one . and the commercial ones i 'm will be much more expensive . right . we will just get joy and jane to do everything . but , that 's what we 're talking about is getting some slaves who need money and , duh , again o i meant joy . i have to say "" are we recording "" and then say , morgan has consistently resisted telling me how much money we have .  if it 's zero then we can't do any transcription . cuz we 're we i can't imagine us doing it ourselves . right ? n right . right .  right . right . at any rate , jane was looking into the possibility of getting students , at is that right ? talking to people about that ?  right .  she 's already done quite a bit .  no . we 've thought about doing that but the recognition quality is gonna be horrendous . most of those are done by a person .   we we 've talked about it but we don't care about the timing of the words , just of the utterances .  what she 's done far , is more or less breath g not breath groups , phrases , continuous phrases . and that 's because you separate when you do an extract , you get a little silence on either end . that seems to work really   we could program that pretty easily , couldn't we dan ? mis mister tcl ? but , but , if we tried to do automatic speaker id . cuz primarily the markings are at speaker change . but that would be the question is how much time will it really save us versus the time to write all the tools to do it . but we 're gonna need ten to a hundred hours to train the tools , and validate the tools the do the d to do all this anyway . i knew you were gonna do that . just saw it coming .  she 's done about half a meeting . right ? about half ? one person would have to assign the boundaries and the other person would have to that 's easy enough . i could do that . no , no . that 's easy enough . i could generate the segmentation and you could do the words , and time yourself on it .   it that might be worth doing . that would at least tell us whether it 's worth spending a week or two trying to get a tool , that will compute the segmentations . right .  that that 'll s it might save ninety percent of the work though .   i 've already become pretty familiar with the format ,  it would be easy . if you 'd tell me where it is ,  it 's pretty cute . but at any rate .  right . think the guess at ten x seems to be pretty standard . everyone more or less everyone you talk to says about ten times for hard technical transcription . using stone age tools . i looked at cyber transcriber which is a service that you send an audio file , ","that would be that would be something to look into . why don't you go ahead and do that then eric ? actually , that 's another thing i was thinking about is that jane should talk to liz , to see if there are any transcription issues related to discourse that she needs to get marked . shall we move on and talk a little bit about transcription then ? what we 're using right now is a tool , from this french group , called "" transcriber "" it has a , useful tcl tk user interface we 're at this point only looking for word level . and the things we that we know that i want are the text , the start and end , and the speaker . but other people are interested in stress marking . and then things like repairs , and false starts , and , filled pauses , and all that other we have to decide how much of that we wanna do . what we wanted to do was have jane do one meeting 's worth , forty minutes to an hour , is and one of the things was to get an estimate of how long it would take , and then also what tools we would use . and the next decision which has to be made actually pretty soon is how are we gonna do it ? and that 's happened in the past . and that 's probably the right way to do it . but can't imagine that we 're gonna get anything that much better from a commercial one . what she 's done far , is more or less breath g not breath groups , phrases , continuous phrases . and that 's because you separate when you do an extract , you get a little silence on either end . we could program that pretty easily , i could generate the segmentation and you could do the words , and time yourself on it . that would at least tell us whether it 's worth spending a week or two trying to get a tool , that will compute the segmentations . i looked at cyber transcriber which is a service that you send an audio file , ","The Berkeley Meeting Recorder group discussed the aims, methods, timing, and outsourcing issues concerning transcription of the Meeting Recorder corpus. The Transcriber software tool was introduced, along with a set of transcription conventions for coding different speech events. "
Bmr003.A,"they do a first pass speech recognition . and then they do a clean up . but it 's gonna be horrible . they 're never gonna be able to do a meeting like this . for cyber transcriber they don't quote a price . they want you to call and talk . for other services , they were about thirty dollars an hour . thirty  for thirty dollars an hour for of their work . if it 's ten times it 's three hundred dollars an hour . no .   my search was pretty cursory . it was just a net search . and , it was only people who have web pages and are doing through that . right . trivial . they had two speakers over the telephone . mostly because they were doing much lower level time . they were doing phone and syllable transcription , as as , word transcription . and we 're w we decided early on that we were not gonna do that .  right . and what i 'm saying is that if we hire an external service we can expect three hundred dollars an hour . that 's the ball park . there were several different companies that and the range was very tight for technical documents . twenty eight to thirty two dollars an hour . they won't . we 'll have to mix them . yes , it is . sev several of them say that they 'll do meetings , and conferences , and s and on . none of them specifically said that they would do speaker id , or speaker change mark . they all just said transcription . the way it worked is it was scaled . what they had is , if it 's an easy task it costs twenty four dollars an hour and it will take five or six times real time . and what they said is for the hardest tasks , bad acoustics , meeting settings , it 's thirty two dollars an hour and it takes about ten times real time . think that we can count on that being about what they would do . it would probably be a little more because we 're gonna want them to do speaker marking .   we have to have a short meeting . stop talking ! and clearly . content words only .  but at any rate , we have a ballpark on how much it would cost if we send it out . thirty or forty . three hundred dollars an hour . right . right , these are linguistics grad students . six .  that 's why i said originally , that i couldn't imagine sending it out 's gonna be cheaper . and also we would have control of we could give them feedback . whereas if we do a service it 's gonna be limited amount . we can't tell them , "" for this meeting we really wanna mark stress and for this meeting we want "" and they 're not gonna provide stress , they 're not gonna re provide repairs , they 're not gonna provide they may or may not provide speaker id . that we would have to do our own tools to do that .   i hope it 's jane . is that alright ? i would imagine there would be some monetary involved but we 'd have to talk to morgan about it . i would like you to do it because you have a lot more experience than i do , but if that 's not feasible , i will do it with you as an advisor . six dollars an hour .  more . any more on transcript we wanna talk about ? the user interface only allows two . and if you 're using their interface to specify overlapping speakers you can only do two . but my script can handle any . and their save format can handle any . and using this the convention that jane and i have discussed , you can have as many overlapping speakers as you want .  french .  and they 're they 've been quite responsive . i 've been exchanging emails on various issues . yes , and they said that 's on in the works for the next version . multichannels was also they said they wanted to do it but that the code is really very organized around single channels . think that 's n unlikely to ha happen . for this exact task ? they 're linguists . it 's also all the source is available .  if you speak tcltk . and they have they 've actually asked if we are willing to do any development and i said , if we want if we did something like programmed in a delay , which actually is a great idea , i 'm they would want that incorporated back in . way . we talked about things like foot pedals and other analog mean , tho those are things we could do but don't know how much it 's worth doing . we 're just gonna have  point , whatever . non canonical . comments . what w what eric was talking about was channels other than the direct speech , right ?  there 's an overlapping mark . there 's a lot of overlapping at the beginning and end . huge amounts . when no one i when we 're not actually in the meeting , and we 're all separated , and doing things . but even during the meeting there 's a lot of overlap but it 's marked pretty clearly . some of the backchannel jane had some comments and but lot of them were because you were at the meeting . and think that often you can't tell . jane had comments like to who the person was speaking to .  but someone who , was just the transcriber wouldn't have known that . ","they do a first pass speech recognition . and then they do a clean up . but it 's gonna be horrible . they 're never gonna be able to do a meeting like this . and what i 'm saying is that if we hire an external service we can expect three hundred dollars an hour . they won't . but at any rate , we have a ballpark on how much it would cost if we send it out . these are linguistics grad students . that 's why i said originally , that i couldn't imagine sending it out 's gonna be cheaper . and also we would have control of we could give them feedback . whereas if we do a service it 's gonna be limited amount . and they 're not gonna provide stress , they 're not gonna re provide repairs , they may or may not provide speaker id . i hope it 's jane . the user interface only allows two . and if you 're using their interface to specify overlapping speakers you can only do two . but my script can handle any . yes , and they said that 's on in the works for the next version . and they have they 've actually asked if we are willing to do any development and i said , if we want if we did something like programmed in a delay , which actually is a great idea , i 'm they would want that incorporated back in . ",The prospect of sending the data to an external transcription service was weighed against that of hiring a graduate student transcriber pool. It was tentatively decided that the latter option would be less costly and allow BMR to maintain greater control over the transcription process. 
Bmr003.A,"or when dan said , "" i wa i wasn't talking to you "" . you have to turn off your mike .  but but when you w when you listen to it what it what happens is if you 're a transcriber listening to it sounds like dan is just being a total impolite .  but if you knew that i wasn't actually in the room , and that dan wasn't talking to me , it became  yes . right . stereo .   i should rewrite the mix tool to put half the people in one channel and half in the other . i have a auto gain mixer tool that mixes all the head mounted microphones into one signal and that seems to work really for the transcribers . i did notice that there were some segments that had pauses on the beginning and end . we should probably mark areas that have no speakers as no speaker . then , question mark colon is fine for that . just say silence . no one 's talking .  i wanna leave the marked i don't want them to be part of another utterance . you just you need to have the boundary at the start and the end . it can read and write as many as you want , it 's just that it right , i it 's i didn't explain it if we use the little the conventions that jane has established , i have a script that will convert from that convention to their saved convention . right . yes . right . it 's just user interface . it 's the whole saved form the saved format and the internal format , all that handles multiple speakers . it 's just there 's no user interface for specifying multiple any more than two .       especially for meetings . if i if you were just recording someone 's day , it would be impossible . if you were trying to do a remembrance agent . but for meetings it 's probably alright . but , a lot of these issues , that for from my point of view , where wanna do speech recognition and information retrieval , it doesn't really matter . but other people have other interests .  right . anyway , are we interested then in writing tools to try to generate any of this automatically ? is that something you want to do , dan ? no . but for a first try that 's about right . if we hire an infinite number of dan 's are we gonna run out of disk space  good . no . dan 's already started . can we sell banner ads ? what a good idea , that 's how we could pay for the transcription . hey , what about me ? we can do it all . and we have quite a disparate number of web and other sorts of documents on this project spread around . i have several and dan has a few , and  try to s consolidate . who wants to do that though ? no one wants to do that .  i own the project but i don't wanna do it . it 's mine ! all mine ! "" wah hah hah . "" i 'm talking about putting together all the data in a form that is legible , and pleasant to read , and up to date , and et cetera , et cetera .  it 's against the law to use a tool . i haven't found any tools that i like . it 's just as easy to use to edit the raw html as anything else . it 's not true . now , if i were doing more powerful excuse me more complex web sites i might want to . but most of the web sites i do aren't that complex . but . both . mostly in house .   send me links and i wi send me pointers , rather , and i 'll put it together .   let 's move on to electronics . does everyone know about the lip on the table ? it 's great . clink ! clink ! and crinkle them and yes . he is .  get your paper off my pda !  right . we wanna do that definitely .  sleeve .  not just sleeve them all ? and leave them loose ? whoo ! speed a "" sleeping policeman "" !   that 's really cruel .  that why do we have sixteen channels instead of like some fewer number ?  let me rephrase that . why two each ?   alright . right .  but then none of these . right . n none of these and no p z ms then . i didn't understand i see , i see . you 'd imagine some in some patch panel on top to figure out what the mapping was between each d of these two and each of those one or what ?  then it comes on . i see , i see .  good .  right . you g and did it work ? did it sound good ?  what 's the schedule on these things ?  think the other thing i 'd like to do is , do something about the set up that it 's a little more presentable and organized . and i 'm just not what that is . some cabinet .   i understand .  i need a desk at home too , alright ? is that gonna be a better solution than just going out and buy one ?  and it 's total crap . right , kleenex and telephones .  g it 's just a question , is that something you wanna spend your time on ? great .   lax . i 'm telling you , i 'm just gonna cart one of them away if they stay there much longer .  j ","we should probably mark areas that have no speakers as no speaker . if we use the little the conventions that jane has established , i have a script that will convert from that convention to their saved convention . right . the whole saved form the saved format and the internal format , all that handles multiple speakers . it 's just there 's no user interface for specifying multiple any more than two . anyway , are we interested then in writing tools to try to generate any of this automatically ? and we have quite a disparate number of web and other sorts of documents on this project spread around . i have several and dan has a few , let 's move on to electronics . we wanna do that definitely . think the other thing i 'd like to do is , do something about the set up that it 's a little more presentable and organized . ",The group received an update on the meeting room recording setup and electronics. 
Bmr003.A,"then the other question is do we wanna try to do a user interface that 's available out here ? a user interface . do we wanna try to get a monitor ? or just something . and how do we want to do that ? j just we see something . i have an iram machine i 've borrowed and we can use it . isn't that an ethernet connection or is that a phone ?  we jus right .  right , it 's just a question of getting a laptop and a wireless modem . to mac . airport . the question is , is there an apple driver ? right .   right . i 've borrowed the iram vaio sony thingy , and i don't think they 're ever gonna want it back .   but that does mean we can use that as i had i had actually earlier asked if i could borrow one of the cards to do wireless and they said , "" whenever you want "" . think it won't be a problem .  pc card . right , and if his doesn't work , as i said , we can use the pc . good .  jim is gonna be doing wiring and you 're gonna give some thought to cabinets ? great . they 're flashing ! when people talk , it they go on and off . cheap . a pc and a peanuts .  good . actually shorten there 's a speech compression program that works great on things like this , cuz if the dynamic range is low it encodes it with fewer bits . and most of the time no one 's talking it shortens it dramatically . but if you talk quieter , the dynamic range is lower and it will compress better .  probably . shorter words . how about if you just go "" ? how do you spell that ?  can you do one more round of digits ? are we done talking ? do we have more to talk about ? are you done ? i 'm done . i 'll remember to bring m and m 's next time . it 's harder at the end than at the beginning . i should have mentioned that s to pause between lines but it 's only a hard time for the transcriber not for the speech recognizer . me . ugh ! i didn't know that . i should have randomized it . because right . if we have it , we don't have to transcribe . we don't have to tran  bet we could do it . actually , this i got this directly from another training set , from aurora .  we can compare directly . what ? great .  the mike 's off . all . ",then the other question is do we wanna try to do a user interface that 's available out here ? do we wanna try to get a monitor ? ,
Bmr003.B,"one t one five ,   that 's a good idea . i 'm on two and i should be on .  i don't know . i don't know . it 's very badly designed ? why ? it 's not s it 's not supposed to cover up your ears . it 's only badly that 's strange .  it 's still the same words . we didn't that 's the microphone number . transcript number god . no , let me do it . no , but i 'm gonna look at the logs as there was there was a bug . there was a glitch last time we ran . no . no , we don't . but we ought to st we ought to standardize . i s i spoke to somebody , morgan , about that . we should put mar no , w we can do that . i they 're four , three , two , one . in order now . three , two , and one . but we should put them in standard positions . we should make little marks on the table top . that we can put them that 's the point . it 'll be a lot easier if we have a if we have them permanently in place like that . you do ? gosh . when 's it gonna be installed ? i see .   i see . distribute what ? the data ?  yes . right . the it 's not much the actu the logistics of distribution are secondary to preparing the data in a suitable form for distribution . and the other thing is that , university of washington may want to start recording meetings as in which case w we 'll have to decide what we 've actually got that we can give them a copy . really ? different for you . yes . i don't know . i see . all about that . now you 've touched the fan control , now all our data 's gonna be it 's great . that 's   it 's like "" low "" is mid scale . it could be that it 's not actually wired backwards it 's just that ambiguous . they do .   what 's it sound like ?         let 's .  that 's right . really . i have such a hard name .  right .        that 's true . we don't know , actually . we haven't decided which time we care about , and that 's one of the things that you 're saying , is like you have the option to put in more or less timing data and , be in the absence of more specific instructions , we 're trying to figure out what the most convenient thing to do is .      it could do that couldn't it .  i would have thought    but but we 've got the most channel data . we 'd have to do it from your signal . right . we 've got we 've got a lot of data . right . but the chances are if we 're talking about collecting ten or a hundred hours , which is going to take a hundred or a thousand hours to transcribe if we 're just doing silence detection i it seems like  i don't know .  it 's like a week 's work to get to do something like this . forty or fifty hours .  several minutes . no , you should do it do it again from scratch and then do it again at the boundaries . you do the whole thing three times and then we get    the point we where do we get the oracle boundaries from ? or the boundaries . we could get fake that would be the automatic boundaries . it w   yes . right . need to we need to look at what the final output is but it seems like we it doesn't it seems like it 's not really not that hard to have an automatic tool to generate the phrase marks , and the speaker , and speaker identity without putting in the words .   no .  don't know if we 'd be able to do any thing f to help stp type problems . but certainly for this problem we can do a lot better than no . because they had because they only had two speakers , right ? the segmentation problem is    they won't . they w they 'll refuse to do it .  no , but they won't they will refuse to transcribe this material . that 's not what they 're d quoting for , right ? for quoting meetings ?    i see .  right .  that 's right . it 'd be cheap . cheap to transcribe . for ten thousand dollars . three hundred . how much lower are they ? ten . give them a break . no , it isn't .    no .   out of adam 's pocket .  we 'd like to . unfortunately that 's right .  what s what are you you 've done some portion of the first meeting . and what 's your plan ? to carry on doing it ?  what do they cover ?      their academic . really ? linguists .   pre lay .          i transcribed a minute of this and there was a lot of overlapping . it was   it was at the beginning .   you don't have to .  i see . no .  but that 's but there 's only one time boundary for both speakers , right ?  no . "" is "" u h u h . "" h u h . "" we have to mark those ? don't they d can't we just leave them unmarked ?    it seems like it seems like the , tran the transcription problem would be very different if we had these automatic speaker detection turn placing things . because suddenly i don't know , ","it 's not much the actu the logistics of distribution are secondary to preparing the data in a suitable form for distribution . and the other thing is that , university of washington may want to start recording meetings as in which case w we 'll have to decide what we 've actually got that we can give them a copy . we don't know , actually . we haven't decided which time we care about , and that 's one of the things that you 're saying , is like you have the option to put in more or less timing data and , be in the absence of more specific instructions , we 're trying to figure out what the most convenient thing to do is .  but it seems like we it doesn't it seems like it 's not really not that hard to have an automatic tool to generate the phrase marks , and the speaker , and speaker identity without putting in the words . i transcribed a minute of this and there was a lot of overlapping . but that 's but there 's only one time boundary for both speakers , ",
Bmr003.B,"actually it sounds like there might be a problem putting it into the software if the software only handles two parallel channels . but assuming we can get around that somehow . but what if you wanna edit it ? right ? we 're gonna generate this transcript with five tracks in it , but with no words . someone 's gonna have to go in and type in the words .  and if there are five people speaking at once ,  yes .  right .      but the only time that becomes ambiguous is if you have two speakers . like , if you only have one person , if you only have one thought that 's continuing across a particular time boundary , you just need one arrow at each end , and if it 's picked up by a different speaker , it 's picked up by a different speaker . the time it becomes ambiguous if you have more than one speaker and that and they swap . if you have more than one thread going , then you need to know whether they were swapped or not . hopefully not very much .  i know . but it does feel like it 's really in there . i did this transcription and i marked that , i marked it with ellipsis because it seemed like there was a difference . it 's something you wanted to indicate that it that i this was the end of the phrase , this was the end of that particular transcript , but it was continued later . and i picked up with an ellipsis . i didn't have the equal , not equal thing .  no . but it 's something @ @ that i feel we definitely ought to do . it took me half an hour to transcribe a minute , but i didn't have any i didn't even have a i was trying to get transcriber to run but i couldn't . was doing it by typ typing into a text file and trying to fit it was horrible .   is it it was actually it was quite it was a t it w  no . web site ! that 's great ! we could have like business to business e commerce as  we can have  yes . yes . we c we can do it all ! we can write   we could actually we could use the tcl plug in . man . i know , but that but , i right . but i should be allowed to but i sh i shouldn't be allowed to by m by my own by my according to my own priorities . alright . let 's look at it anyway . definitely we should have some access to the data . yes .  then th the other side is , right , that 's the problem . no one owns the project . no one owns the project . no one wants to own the project . then you have to do the web site . it 's like , it 's that simple . no  that 's not true , but you have right . that 's true . that 's right . no , both . i i i 'm not o  i 'm not how important that distinction is . i don't think we should say , "" it 's internal therefore we don't have to make it very good "" . you can say "" it 's internal therefore we can put data in it that we don't have to worry about releasing "" . but to try and be coherent and make it a presentation .   great . no , we 're doing great . what ? what ? i see . you trying to screw up the m the microphones ? th   right . all the lights . velcro . no .  it 's like a it 's a sleeping policeman . speed bump ! speed bump . that 's the s that 's british for speed bump ,    how else are you gonna distribute them around the tables ? because then you don't have to just have one each . that if t if you have two people sitting next to each other they can actually go into the same box . only if you had it depends on this box , right ? exactly .   but there are only four .   we i had that last time . but there are actually that there 's an extra there 's a mix out on the radio receiver ? there are actually six xlr outs on the back of the radio receiver and only five cables going in , i had the wrong five , ended up not recording one of the channels and recording the mix . no . but i subtracted the four that i did have from the mix and got a pretty good approximation of the @ @ .  it 's not bad . it 's not bad ,   but , you always  see      exactly . we 'll know to come after .    we do .    which we 'll borrow from them , when we need it . a applecard .  right . you could use my machine . i or the that 's an ethernet connection . it 's going next door .  no , no , that 's the right way to do it . t to have it just  and given that we 've got a wireless that we 've got a we got the field . right .   i don't know . w we don't need x access but that 's fine . that 's what it does ,   with a with a w no .  i do !   no , i would love to but i 'm not if my laptop is compatible with the wave lan thing they 're using . apple has their own thing , right ? apple has their own thing . and  what ",alright . let 's look at it anyway . definitely we should have some access to the data . that if t if you have two people sitting next to each other they can actually go into the same box . ,
Bmr003.B,"you it just plug plugs in a pc card , you could probably make it run with that , but . i 'm i imagine there is . but anyway there are abs there are a bunch of machines at icsi that have those cards and think if w if it doesn't we should be able to find a machine that does that . know that doesn't don't the important people have those little blue vaios that     i see .       you 're kidding !  i 'd trade them a flat panel display for it .  huge vu meters .  that 's an end   and having it on wireless is the neatest way to do it .        that sounds like a d good solution one way or the other . we 'd   does that it means it 's gonna explode . no .  this again , washington wants to equip a system . our system , we spent ten thousand dollars on equipment not including the pc . however , seven and a half thousand of that was the wireless mikes .  using these  that 's true but we haven't spent that , right ? but once we 've done the intellectual part of these , we can just knock them out , right ? we can start we you can make a hundred of them and then we could washington could have a system that didn't have any wireless but would had what 's based on these and it would cost pc and two thousand dollars for the a to d and that 's about cuz you wouldn't even need the mixer if you didn't have the th the p z p z ms cost a lot . but anyway you 'd save , on the seven or eight thousand for the wireless system . actually that might be attractive .  move my thumb now .   but if the words are more predictable .   tha  that 's been filled in for you . but they 're in order ! they start , six , seven , eight , nine , zero , one , two , three , four , five , six , eight , nine . and they 're in order because they 're sorted lexically by the file names , which are have the numbers in digits . and they 're actually this is like all the all utterances that were generated by speaker mpj and then within mpj they 're sorted by what he actually said . it doesn't matter ! it 's like cuz you said "" six , seven , eight "" . we think it doesn't matter . if i if not i cuz we have these writt written down , right ? that 's why you can generate  that 's a great idea . alright . looks good . looks like there were no errors . there were no direct driver errors , by the look of it , which is good . 'm gonna stop it .    ","again , washington wants to equip a system . our system , we spent ten thousand dollars on equipment not including the pc . however , seven and a half thousand of that was the wireless mikes . but once we 've done the intellectual part of these , we can just knock them out , right ? washington could have a system that didn't have any wireless but would had what 's based on these and it would cost pc and two thousand dollars for the a to d p z ms cost a lot . but anyway you 'd save , on the seven or eight thousand for the wireless system . ",
Bmr003.C,"this is eric on channel three , i believe . you 're always having one of those days , dave . it 's not neck mounted . it 's supposed to be h head mounted . right . i that 's what i have . it feels good when i stop . you 're always doing digits . this is eric on microphone number three , would it make you feel more important ? i see . mean , for that particular issue ther there are known sources where people go to find these things like the ldc right .   a little bit . it would it would real really mean that we should do short meetings when you turn off the air conditioning , got to finish this meeting . that 's right . right , i see .  in addition to this issue about the uw there was announced today , via the ldc , a corpus from i believe santa barbara . of general spoken english . and i don't know exactly how they recorded it but there 's a lot of different styles of speech and what not . and i see . it is far field right ?  s but it may be useful in what i was thinking is it may be useful in transcribing , if it 's far field right ? in doing , some of our first automatic speech recognition models , it may be useful to have that data because that 's very different than any data that we have far . that 's not great . no , and their web page didn't answer it either . 'm , i was thinking that we should contact them . it 's that 's beside the point . but . right . we get it for free cuz they 're distributing it through the ldc . actually arrange for it to arrive in short order if we 're   we should get a copy of it just to see what they did that we can compare . alright , i 'll do that . i can't remember the name of the corpus . it 's corps s s right ,   they 're this was like phase one and the there 's still more that they 're gonna do like that unless they have funding issues and then it ma they may not do phase two but from all the web documentation it looked like , "" this is phase one "" , whatever that means .  but , it it would also help be helpful for liz , if she wanted to start working on some discourse issues , looking at some of this data and then ,  when she gets here that might be a good thing for her . we should have a big meeting .   right . but we should , find some day that liz liz and andreas seem to be around more often . we should find a day when they 're gonna be here and morgan 's gonna be here , and we can meet , at least this subgroup . not necessarily have the u dub people down . we need to talk to them some more .  how fast are you ? right . but sometimes it 's easier to type out something instead of going through and figuring out which is the right it depends on the error rate , right ? but we don't care about the timing of the words . we cut it s right .  right .   we could try the following experiment . take the data that you 've already transcribed and already in the past . she 's done one she 's one right . right . i 'm go right .  and throw out the words , but keep the time markings . and then go through and go through and try and re transcribe it , given that we had perfect boundary detection . and see if it see if it feels easier to you . that 's part of the problem is , is that what we really need is somebody else to come along .  right . right . right . no , no , no . you wanna know given a perfect human segmentation , you wanna know how the question is , is it worth giving you the segmentation ? right . right . right . there 's gonna be in the meeting , like the reading group meeting that we had the other day , that 's it 's gonna be a bit of a problem because wasn't wearing a microphone f and there were other people that weren't wearing microphones . that 's true but but , yes .  that 's three hours . right . right . and who who knows if they 're gonna be able to m manage multal multiple channel data ? right . meanwhile it 's thirty dollars an hour , essentially , right ? but we can pay a graduate student seven dollars an hour . and the question is what 's the difference or ei eight dollars . what do what the going rate is ? it 's on the order of eight to ten .  but i 'm not let 's say ten . cuz it 's easier . i don't i don't the standard but there is a standard pay scale don't it is .  that means that even if it takes them thirty times real time it 's cheaper to do graduate students .  right . that 's a multi multichannels . i see .  for transcription . it 's they 're they have some connection to the ldc cuz the ldc has been advising them on this process , the linguistic data consortium .   but a apart from that .  right . right .     how are you handling backchannels ? what do by du i see .  what is wh when somebody says "" in the middle of , a @ @ ","in addition to this issue about the uw there was announced today , via the ldc , a corpus from i believe santa barbara . what i was thinking is it may be useful in transcribing , if it 's far field in doing , some of our first automatic speech recognition models , it may be useful to have that data we get it for free cuz they 're distributing it through the ldc . we should get a copy of it just to see what they did that we can compare . but , it it would also help be helpful for liz , if she wanted to start working on some discourse issues , looking at some of this data and then , we could try the following experiment . take the data that you 've already transcribed and throw out the words , but keep the time markings . and then go through and go through and try and re transcribe it , given that we had perfect boundary detection . and see if it see if it feels easier to you . the question is , is it worth giving you the segmentation ? who knows if they 're gonna be able to m manage multal multiple channel data ? but we can pay a graduate student seven dollars an hour . that means that even if it takes them thirty times real time it 's cheaper to do graduate students . how are you handling backchannels ? ",The prospect of sending the data to an external transcription service was weighed against that of hiring a graduate student transcriber pool. It was tentatively decided that the latter option would be less costly and allow BMR to maintain greater control over the transcription process. 
Bmr003.C,"cuz i was listening to dan was agreeing a lot to things that you were saying as you were talking .  and i see .  right .  s i was just gonna ask , just wanted to c finish off the question i had about backchannels , if that 's which was , say somebody 's talking for a while and somebody goes "" in the middle of it , and what not , does the conversation come out from the or the person who 's speaking for the long time as one segment and then there 's this little tiny segment of this other speaker or does it does the fact that there 's a backchannel split the it in two .   i see , i see ,  right .   how often does that happen do you think ?  if we hired a who if we hired a whole bunch of dan 's  is there we should s consider also , starting to build up a web site around all of these things . i know . that 's right . no , but i 'm it would be interesting to see i want to introduce i want to introduce the word "" snot head "" into the conversation at this point . you see , cuz cuz exactly .  no . the r w what  no . alright , see here 's here 's my thought behind it which is that , the that you 've been describing , jane , i gu one has to , indicate , i is very interesting , and i 'd like to be able to pore through , the types of tr conventions that you 've come up with and like that . would like to see that on the web . either 's fine . ow . see he said the word tcl and that 's  right , we can add in links and like that to other things . the right . we could put disorganized group gestalt right . no , in mostly internal . right . internal to the project . no . no . what is what does that mean ? is it a speed bump ?  it could go either way .   he 's  what is the , projector supposed to be hooked up to ? but that 's another possibility that , solves it 's it really come down to the driver .  now , shorter words wouldn't would induce more dynamics , right ? you want to have  i 'm done . dan isn't but he 's not gonna say anything . ","or does it does the fact that there 's a backchannel split the it in two .  we should s consider also , starting to build up a web site around all of these things . i 'd like to be able to pore through , the types of tr conventions that you 've come up with and like that . we can add in links and like that to other things . mostly internal . what is the , projector supposed to be hooked up to ? ","Methods for distributing the data were briefly discussed, along with an initiative for creating a BMR project website. "
Bmr003.D,"tasting one two three , tasting . can you see me on channel four ? really ? my lucky day . i like the high quality labelling . david , can we borrow your labelling machine to improve the quality of the labelling a little bit here ? how many are there , one to five ?  want to join the meeting , dave ? do we have a spare , we ' r we 're we ' r this is a meeting . i don't understand if it 's neck mounted you don't get very good performance .  it should be head mounted . right ? cuz when you do this , you can rouww . why ? what do it doesn't go over the ears ? somebody wanna somebody wanna close the door ? psss ! that 's good . but number has to be ? we have to look up the number . good . this is beck on mike four . but eric , you didn't think that was a reasonable hypothesis , right ? i 'm that was malarkey . no chance of that . are yo are you recording where the table mikes are do which channels why not ? why don't you just do this ? four . three . till the projector gets installed . cuz it 's gonna hang down , make noise . it depends on is this b is this being recorded ? lila actually is almost getting r pretty close to even getting ready to put out the purchase order . i handed it off to her about a month ago . u using audio d v ds like that ? audio d v or t  tapes . a field trip .  an and there 's interest up there ? there 's interest up there ? including the fan . did you notice the fan difference ? hear the difference ? do you wanna leave it off or not ? the you you think that things after the f then this fan 's wired backwards this is high speed here . not clear . it isn't . that 's right . i was wondering also , get ready . whether the lights made any noise . do our meetings in the dark with no air conditioning in the future . short meetings , that 's right . or  tear t tear your clothing off to stay actually , the a th air the air conditioning 's still working , that 's just an auxiliary fan . tr but far field means great distance ?  not head mounted ? and that 's why they 're getting away with just two channels or are they using multiple dats ? still a point . that would be a meeting ? thi this is the process of converting audio to text ? and this requires humans just like the stp i is there already some plan in place for how this gonna be staffed or done ? or is it real is that what we 're talking about here ? yourself ? it this is like five times real time or ten times real time and you make jane do the first one then she can decide , we don't need all this just the words are fine . can't we get joy to do it all ? is tha wasn't that what she was doing before ?  that 's right . right . right . the answer is zero . there 's a reason why he 's resisted . but . right . we already we already have a plan in place for the first meeting . right ? that 's i b but morgan 's in a bind over this and thing to do is just the field of dreams theory , which is we go ahead as though there will be money at the time that we need the money . and that 's the best we can do . i b to not do anything until we get money is ridiculous . we 're not gonna do any get anything done if we do that . i d do until you actually have a little experience with what this french thing does we don't even have we have . i 'm that 's where you came up with the f the ten x number ? or is that really just a guess ?  d does this tool you 're using is strictly it doesn't do any speech recognition does it ? but is there anyway to wire a speech recognizer up to it and actually run it through a couple things . first of all the time marking you 'd get you could get by a tool . and if the issue really i 'm think about the close caption that you see running by on live news casts . yo i know that . no , i understand . and in a lot of them you see typos and things like that , but it occurs to me that it may be a lot easier to correct things than it is to do things from scratch , no matter how wonderful the tool is . but if there was a way to merge the two but again the timing is for fr should be for free . the timing should be thought you just that 's said that was a critical issue . a i a ar but are those d delays adjustable ? those delays adjustable ? see a lot of people who actually build with human computer interfaces understand that delay , and when you by the time you click it 'll be right on because it 'll go back in time to put the if if we can go from ten x to five x we 're doing a big put it on your sweater . is this already in the past or already in the future ? you 've already done some ? i see .  good . ",but is there anyway to wire a speech recognizer up to it first of all the time marking you 'd get you could get by a tool . are those d delays adjustable ? ,
Bmr003.D,"and forgetting all the words because you 've been thr and then w since we need some statistics do it three more . and you 'll get down to one point two x by the time you get done . no , but the fact that she 's did it before just might give a lower bound . that 's all . which is fine . it 's and if the lower bound is nine x then w it 's a waste of time . a little double blind ear thing . and the thing to keep in mind too about this tool , guys is that you can do the computation for what we 're gonna do in the future but if uw 's talking about doing two , or three , or five times as much and they can use the same tool , then there 's a real multiplier there . use it . that 's why we s bought the expensive microphones . but you didn't say anything worth while anyway , right ? using wh using stone age using stone age tools . right . d did you talk to anybody that does closed captioning for tv ? cuz they a usually at the end of the show they 'll tell what the name of the company is , the captioning company that 's doing it . the thing about this is thinking little more globally than i should here but that really this could be a big contribution we could make . we 've been through the stp thing , we it 's like to manage the process , and admittedly they might have been looking for more detail than what we 're looking for here but it was a big hassle , right ? they constantly could 've reminding people and going over it . and clearly some new needs to be done here . and it 's only our time , where "" our "" includes dan , dan and you guys . it doesn't include me  j just seems like bec why ? because they wanted a lot more detail ? only had two . i see . what took them long ? right . right . i see . but there 's still the same issue of managing the process , of reviewing and keeping the files straight , and all this that which is clearly a hassle . they might quote it th the th there may be just multiplier for five people costs twice as much and for ten people co something like that . a lot of companies i 've worked for y the , the person leading the meeting , the executive or whatever , would go around the room and mentally calculate h how many dollars per hour this meeting was costing , right ? in university atmosphere you get a little different thing . but it 's a lot like , "" he 's worth fifty an hour , he 's worth "" and he here we 're thinking , "" let 's see , if the meeting goes another hour it 's going to be another thousand dollars . ""  it 's ch every everybody ta talk really fast . let 's get it over with . and only talk when you 're pointed to . and we 're talking about do doing how many hours worth of meetings ? thirty or forty thousand dollars .  what it was thirty times i 'm three hundred . right , i w got an extra factor of three there .  the these are not for engineering graduate students , right ? that 's right . just hypoth hypothetically assuming that we go ahead and ended up using graduate students . i who 's the person in charge ? who 's gonna be the steve here ? you ? it just means you have to stop working for dave . see ? that 's why dave should have been here . to pr protect his people . w we 'd like you to do it and we 'd like to pay you . not being morgan though , it 's  and then an and be and say , would you like fries with that when you 're thinking about your pay scale . is there a limit to the number of speakers ? do y is this a , university project ? th this is the french software , right ?  did you ask them to change the interface for more speakers ? good . good . do what they 're using it for ? why 'd they develop it ? are they linguists ? but are they linguists or are they speech recognition people ?  great .  good . their pre lay . loop it ? yo you n there 's al also the user interface that 's missing . it 's missing from all of our offices , and that is some analog input for something like this . it 's what audio people actually use it 's something that wh when you move your hand further , the sound goes faster past it , like fast forward . like a joy stick or a you could wire a mouse or trackball to do something like that . no , but i 'm saying if this is what professionals who actually do this thing for m for video or for audio where you need to do this , and you get very good at jostling back and forth , rather than hitting tab , and backspace , and carriage return , and enter , and things like that .  ye right .    i 'll be right back . you take a bathroom break in the middle and keep your head mount you do ? he it was a lot funnier if you were there though . th this is gonna go on the meeting transcriber bloopers tape , right ?  great . ","and the thing to keep in mind too about this tool , guys is that you can do the computation for what we 're gonna do in the future but if uw 's talking about doing two , or three , or five times as much and they can use the same tool , then there 's a real multiplier there . just hypoth hypothetically assuming that we go ahead and ended up using graduate students . did you ask them to change the interface for more speakers ? ",
Bmr003.D,"whenever we use these speech words we should always do the thing like you 're talking about , accent , what 's that mean ? re ye s silence all around .  but you 're saying that by the time you call it back in to from their saved format it opens up a window with five speakers ?  that is they didn't quite go the whole they didn't go the whole route , did they ? they just right . your script solves doesn't it solve all our problems , cuz we 're always gonna wanna go through this preprocessing assuming it works . i see . right . good . it l ou thirty to one 's what you got ? that 's a new upper limit ? that 's right . a it 'd b a d doesn't it beep in the other room when you 're out of disk space ? get paid for click throughs ? you wanna word that won't be recognized ? web site 's what ? but he does such a good job of it . he should be allowed to , w do it . if you just did a crappy job , no nobody would want you to do it . why ? what 's the issue ? no one what ? w do but but b but what are you talking about for web site hacking ? you 're talking about writing html , right ? but , is it against the law to actually use a tool to help your job go easier ? you y no kidding ? no , it it 's true that he hasn't found any he likes . the question is what 's he looked at . i use something called trellix . and it it 's it 's very powerful .  but what does internal mean ? you 're leaving . people at uw wanna look at it . it 's internal until i see . right . i agree . cuz you 're gonna have to wor do the work sooner or later . even if it 's just writing things up .  d we out of tape out of disk ? i was looking for the actual box i plan to use ,  but i c all i could i couldn't find it at the local store . but this is the technology . it 's actually a little bit thinner than this . and it 's two by two , by one , and it would fit right under the right under th the lip ,  there 's a lip in these tables . and , it oc i p especially brought the bottom along to try and generate some frequencies that you may not already have recorded . let 's see what it does to the but this was the just to review , and i also brought this along rather than the projector we can put these on the table , and push them around . that 's the six tables that we 're looking at . these six tables here , with little boxes in the middle here . which es would the boxes are out of the way anyway . i 'll i 'll show you the cro this is the table cross section . i don't know if people realize what they 're looking at . why not ? cuz this is what 's gonna happen . you got plenty of data . i won't come to your next meeting . and and you this is the box 's that 's right . "" or not to be "" .  the box , there 's a half inch lip here . the box is an inch thick it hangs down a half an inch . and the two head set jacks would be in the front and then the little led to indicate that box is live . the important issue about the led is the fact that we 're talking about eight of these total , which would be sixteen channels . and , even though we have sixteen channels back at the capture , they 're not all gonna be used for this . there 'd be a subset of them used for just use the ones at this end for this many .  excuse me . you 'd like a way to tell whether your box is live , the led wouldn't be on . if you 're plugged in it doesn't work and the led is off that 's a tip off . and then the , would wire the all of the cables in a bundle come through here and o collect these cables at the same time . this notion of putting down the p z ms and taking them away would somehow have to be turned into leaving them on the table or right . right . and the you we just epoxy them down big screw into the table .  and even though there 's eight cables they 're not really very big around my model is to get a p piece of that that people put with the little you slip the wires into that 's shaped like that cross section .  i 'm r a i 'm going up and then i 'm going down . it 's like a speed bum an and they 're ac they 're actually ext extruded from plastic . they sorta look like this . that the wires go through here .  s it would c go on the diagonal here . because the because they 're there .  and to see , thi this is really the way people sit on this table . th  dot , dot . that 's the way people sit . that 's how many chairs are in the room .  right . and certainly you could do a thing where all sixteen were plugged in . if you ha if you had nothing else .  right . right . i agree . true enough . ","but you 're saying that by the time you call it back in to from their saved format it opens up a window with five speakers ? your script solves doesn't it solve all our problems , there 's a lip in these tables . that 's the six tables that we 're looking at . these six tables here , with little boxes in the middle here . the box is an inch thick it hangs down a half an inch . and the two head set jacks would be in the front and then the little led to indicate that box is live . the important issue about the led is the fact that we 're talking about eight of these total , which would be sixteen channels . this notion of putting down the p z ms and taking them away would somehow have to be turned into leaving them on the table and to see , thi this is really the way people sit on this table . ",
Bmr003.D,"and actually , at the m my plan is to only bring eight wires out of this box . this box thi this box is a one off deal .  and , it 's function is to s to , essentially a wire converter to go from these little blue wires to these black wires , plus supply power to the microphones cuz the he the , cheap head mounteds all require low voltage . w i the simplest thing i could imagine , i which is really , really simple is to quite literally that these things plug in . and there 's a plug on the end of each of these , ei eight cables . an and there 's only four slots that are in the first version or the version we 're planning to build . that was the whole issue with the led , that you plug it in , the led comes on , and you 're live . now the subtle issue here is that tha i haven't really figured out a solution for this . we it 'll have to be convention . what happens if somebody unplugs this because they plug in more of something else ? the there 's no clever way to let the up stream guys know that you 're really not being powered .  th there will be a certain amount of looking at cables has to be done if people , rewire things . but .  how interesting . d did you do any recognition on the mix out ? wonder whether it works any got the fifth ?  is it is ain't science wonderful ?   was wrestling with th with literally the w number of connectors in the cable and the , powering system . and i was gonna do this very clever phantom power and i decided a couple days ago not to do it . 'm ready to build it . which is to say , the neighborhood of a week to get the circuit board done . i agree . can build a cabinet . the difficulty for this project is the intellectual capital to design the cabinet . in other words , to figure out ex exactly what the right thing is . that cabinet can go away . we can use that for kindling but if you can imagine what the right form factor is . dan and i have gone around on this , and we were thinking about something that opened up in the top to allow access to the mixer but there 's these things sticking out of the mixer which are pain , you end up with this thing that if you stuck the mixer up here and the top opened , it 'd be fine . you wouldn't necessarily  you s understand what i 'm the you can start s sketching it out , and certainly build it out of oak no problem , would it arb arbitrarily amount of the as we found out with the thing that , jeff bought a long time ago to hold our stereo system the you buy is total crap . and this is something you buy . and it 's total crap . it 's useless for this function . works fine for holding a kleenex , but it right .  i 'm paid for . i have no problem . no , but w certainly one of the issues is the , is security . we 've been lax and lucky . really lucky with these things . but they 're not ours ,  the , the flat panels . let the record show at at f four thirty five adam janin says slipped almost slipped it by dan . how about use the thing that aciri 's doing . which is to say just laptop with a wireless . what 's wrong with yours ? if we bought you a what ? n no , i 'm i 'm serious . does the wireless thing work on your no i 'm a i ain't joking here . i 'm serious , that it it 's very convenient especially if dan happens to be sitting at that end of the table to not have to run down here and look in the thing every often , but just have the it 's right there . right ? the antenna 's right there , right outside the y we need need to clear this with aciri but , how tough can that be ? there it you 'd all you need 's web access , isn't it ? in theory .  great , great . no , and he had , reque @ @ my proposal is you have a laptop . you don't ? if we bought you the thing would you mind using it with i the really ? your new one ? i 'm it just came through a serial p or an ethernet port . i e but the two t b that to me that 's a whole nother . that 's a whole nother issue . the idea of con convincing them that we should use their network i is fairly straight forward . the idea of being able to walk into their office and say , "" can i borrow your machine for a while "" , is a non starter . that i don't think that 's gonna work . either we figure out how to use a machine somebody already in the group already owns , a and the idea is that if it 's it perk , it 's an advantage not a disadvan or else we literally buy a machine e exactly for that purpose . certainly it solves a lot of the problems with leaving a monitor out here all the time . i i 'm not a big fan of doing things to the room that make the room less attractive for other people , right ? ","thi this box is a one off deal . and , it 's function is to s to , essentially a wire converter to go from these little blue wires to these black wires , plus supply power to the microphones cuz the he the , cheap head mounteds all require low voltage . 'm ready to build it . which is to say , the neighborhood of a week to get the circuit board done . can build a cabinet . no , but w certainly one of the issues is the , is security . which is to say just laptop with a wireless . either we figure out how to use a machine somebody already in the group already owns , a and the idea is that if it 's it perk , it 's an advantage not a disadvan or else we literally buy a machine e exactly for that purpose . certainly it solves a lot of the problems with leaving a monitor out here all the time . ",
Bmr003.D,"which is part of the reason for getting all this out of the way and , monitor sitting here all the time people are gonna walk up to it and go , "" how come i can't get , pong on this "" or , whatev right . the next conference they will .  the certainly , u you should give it a shot first see whether you can get compatible ask them what it costs . ask them if they have an extra one . who knows , they might have an extra hardware s good . the , tsk . it 's gonna be hooked up to all sorts of junk . there 's gonna be actually a plug at the front that 'll connect to people 's laptops you can walk in and plug it in . and it 's gonna be con connected to the machine at the back . we certainly could use that as a constant reminder of what the vu meters are doing . people sitting here are going "" testing , one , two , three "" ! it a  but the idea of having a control panel it 's that 's there in front of you is really r as long as you d as l as long as you 're not tempted to sit there and f keep fiddling with the volume controls going , "" can you talk a bit louder ? "" and it 's a pcmcia card , right ? pc card , you can have a slot , right ? in your new machine ? is it with s right , i it 'll work it 'll work the first time . i trust steve jobs . y we need to figure out what we want .  hey , what are those green lights doing ? cut the red wire , the red wire !  and it and the f the five thousand for the wires , if i 'm gonna do no . it 's a joke . i have to do of the boards ?   right .  peanuts . right . right . what ? like if we talked softer the disk lasts longer . it also helps if you talk in a monotone . constant volume all the time .  it 's a choice if we get a choice , let 's keep talking .  no , i 'm done . but you there 's a problem a structural problem with this though . you really need an incentive at the end if you 're gonna do digits again . like , candy bars or or a little , toothbrushes like they give you at the d dentist . or both . eric , you and i win . we didn't make any mistakes . no , i know . i 'm just giving you a hard time . very good . eric , you win . but the other thing is that there 's a colon for transcripts . and there shouldn't be a colon . because see , everything else is you fill in . right ? automatically . but real where 'd they come from ? we think it doesn't matter . but the real question i have is that , why bother with these ? why don't you just ask people to repeat numbers they already know ? like phone numbers , social security numbers . i know . i kn credit card numbers ,  you just say your credit card numbers , say your phone numbers , say your mother 's maiden name . pe people off the street . this mony on the mike . ",there 's gonna be actually a plug at the front that 'll connect to people 's laptops you can walk in and plug it in . and it 's gonna be con connected to the machine at the back . we certainly could use that as a constant reminder of what the vu meters are doing . but the idea of having a control panel it 's that 's there in front of you is really ,
Bmr003.E,"this is jane on channel five . darn , what am i doing wrong ? screen no , it is , it just warmed up ? darn , can you can't see channel five yet ? this would be k  is that better ? hello , hello . alright . would you like to join the meeting ? i bet this is abou we 're mainly being taped but we 're gonna talk about , transcription for the m future meeting meetings .  e  y you 'd be welcome . you 'd be welcome . why didn't i you were saying that but i could hear you really on the transcription on the , tape . it 's badly designed . that 's what you 're d he 's got it on his temples it cuts off his circulation . try it . we could do it with noise . this is the same one i had before . no now , just to be the numbers on the back , this is the channel ? that 's the microphone number .  good . five good .  this is jane , on mike number five .  start ? do i need to say anything more ? you said turn off the what ?  i see . i see .  i do wish there were big booms coming down from the ceiling .    that 'll be good .    that 's right . that 's better . that 's better . it 's noticeable .  candles would be if they don't make noise .  i saw it . i 've been watching for that corpus .   they had people come in to a certain degree and they have dat recorders . i assume actually , i hadn't thought about that . unless they added close field later on but , i 've listened to some of those data and i , i 've been i was actually on the advisory board for when they set the project up . i 'm glad to see that it got released . it 's a very thing . how do mechanical adaptation or  great idea . and their recording conditions are really clean . i 've heard i 've listened to the data . it sounds but what is that ,  good question and i can't ans answer it . i don't know .   the other thing too is from a the other thing too is that their jus their transcription format is really and simple in the discourse domain . but they also mentioned that they have it time aligned . i s i saw that write up . it 's very csae . corpus of spoken american english . sp i 've been i was really pleased to see that . i knew that they had some funding problems in completing it but , this is clever . got it through the ldc . great . great . super . super . great . that they 're really respected in the linguistics d side too and the discourse area , and this is a very good corpus .  i did include a glo a certain first pass . my view on it was when you have a repair then , it seems we saw , there was this presentation in the one of the speech group meetings about how and liz has done some too on that , that it , that you get it bracketed in terms of like if it 's parenthetical , which i know that liz has worked on , then you 'll have different prosodic aspects . and then also if it 's a r if it 's a repair where they 're like what did , then it 's to have sense of the continuity of the utterance , the start to be to the finish . and , it 's a little bit deceptive if you include the repai the pre repair part and sometimes or of it 's in the middle . anyway , what i was doing was bracketing them to indicate that they were repairs which isn't very time consuming .  as a pilot study .  as a pilot study . that 's right , that 's right . i wanna hear about these we have a g you were s continuing with the transcription conventions for s no , that 's i object to that characterization !   th there is als really . there is also the o other possibility which is if you can provide not money but instructional experience or some other perks , you can you could get people to to do it in exchange .  i 'm afraid i haven't made any progress in that front yet . i should 've sent email and i haven't yet . and i do have i have a bunch of hours ,  actually that 's the one people usually use , ten x . and i haven't really calculated how fast am i ? i haven't done a s see , i 've been at the same time doing boot strapping in deciding on the transcription conventions that are and like , how much there 's some interesting human factors problems like , what span of time is it useful to segment the thing into in order to transcribe it the most quickly . cuz then , you get like if you get a span of five words , that 's easy . but then you have to take the time to mark it . and then there 's the issue of it 's easier to hear it th right the first time if you 've marked it at a boundary instead of somewhere in the middle , cuz then the word 's bisected or whatever and and mean , i 've been playing with , different ways of mar cuz i 'm thinking , if you could get optimal instructions you could cut back on the number of hours it would take . no , it doesn't but what a super tool . ","they had people come in to a certain degree and they have dat recorders . csae . corpus of spoken american english . as a pilot study . there 's some interesting human factors problems like , what span of time is it useful to segment the thing into in order to transcribe it the most quickly . mean , i 've been playing with , different ways of mar cuz i 'm thinking , if you could get optimal instructions you could cut back on the number of hours it would take . ",
Bmr003.E,"it 's a great environment . that 's an interesting idea . hey ! that 's interesting .  i that 'd be fun . no , the boundary boundary . that 's ideal . although i was i the alternative , which i was experimenting with before i ran out of time , recently was , that , ev if it were like an arbitrary segment of time i t pre marked cuz it does take time to put those markings in . it 's really the i the interface is wonderful because , the time it takes is you listen to it , and then you press the return key . but then , it 's like , you press the tab key to stop the flow and , the return key to p to put in a marking of the boundary . but , there 's a lag between when you hear it and when you can press the return key it 's slightly delayed , then you listen to it a second time and move it over to here . that takes time . now if it could all be pre marked at some , l good   not in this case . it has other interesting point . interesting point . that would make a difference . it 's not bad but it does take twice . good point !  we 've got volume .  but it op i 'm i wish you had told me wish you 'd told me . at what part ?  i 'm alright . could you get it that with it would detect volume on a channel and insert a marker ? and the format 's really transparent . it 's just a matter of a very c clear it 's xml , isn't it ? it 's very i looked at the file format and it 's just it has a t a time indication and then something or other , and then an end time or other .  yes i have . s i 'm not if it 's that 's much but anyway , enough to work with .  good idea .  that 's what i was thinking . i 'd be cheating a little bit g with familiarity effect . no . now , there 's a plan .   i 'll do that tomorrow . i should have it finished by the end of the day . exactly .  but there 's an extra problem which is that i didn't really keep accurate it wasn't a pure task the first time , it 's gonna be an upper bound in that case . and it 's not really strictly comparable . think though it 's a good proposal to be used on a new batch of text that i haven't yet done yet in the same meeting . could use it on the next segment of the text . but couldn't i do it for the next i see what but the oracle boundaries would come from volume on a partic specific channel wouldn't they ?  i see what  i see .  that 's good . i like that . and the other thing too is with speaker identification , if that could handle speaker identification that 's a big deal .  that 's a feature . that 's a major that 's like , one of the two things that  that 'd be great .   we didn't finish the part of work already completed on this , did we ? you talked a little bit about the transcription conventions , and , you 've mentioned in your progress report , or status report , that you had written a script to convert it into i when i the it 's quickest for me in terms of the transcription part to say something like , if adam spoke to , to just say , "" a colon "" , like who could be , at the beginning of the line . and e colon instead of entering the interface for speaker identification and clicking on the thing , indicating the speaker id . and then he has a script that will convert it into the thing that , would indicate speaker id . if that 's clear . it 's perl script .   that 's right . that 's true , but what approximately , what did you find out in terms of price or whatever ? of tape ? or of action ?   of their   interesting .   and then there 's the problem also that  that 's very interesting . talk slowly but with few words . there you go . we could have some telegraphic meetings . that might be interesting .  that would give us a good estimate . i 'd say i was gonna say eight you 'd say ten ? that 's right . that 's right . and there 's another aspect too . the other thing too is that , if they were linguistics they 'd be in terms of like the post editing , i tu content wise they might be easier to handle cuz they might get it more right the first time .  good point . good point .  interesting . now would this involve some manner of monetary compensation or would i be the voluntary , coordinator of multiple transcribers for checking ?   i don't wanna stop working for dave .    we 'll see .  i see .   i see .  boy , if i wanted to increase my income i could start doing the transcribing again . i see . good . no , that i would be interested in that in becoming involved in the project in some aspect like that more .    yes .  what what was right now we have p gave him the proposal for the transcription conventions . he made his , suggestion of improvement . the it 's a good suggestion . as far as i 'm concerned those transcription conventions are fixed right now . and my next plan would be ","but then , it 's like , you press the tab key to stop the flow and , the return key to p to put in a marking of the boundary . but , there 's a lag between when you hear it and when you can press the return key could you get it that with it would detect volume on a channel and insert a marker ? but there 's an extra problem which is that i didn't really keep accurate it wasn't a pure task the first time , think though it 's a good proposal to be used on a new batch of text that i haven't yet done yet in the same meeting . could use it on the next segment of the text . and the other thing too is with speaker identification , and then he has a script that will convert it into the thing that , would indicate speaker id . the other thing too is that , if they were linguistics they 'd be in terms of like the post editing , i tu content wise they might be easier to handle cuz they might get it more right the first time . no , that i would be interested in that in becoming involved in the project in some aspect like that as far as i 'm concerned those transcription conventions are fixed right now . ","The Transcriber software tool was introduced, along with a set of transcription conventions for coding different speech events. "
Bmr003.E,"they 're very minimal . it would be good to just to summarize that . one of them is the idea of how to indicate speaker change , and this is a way which meshes with , making it that , on the at the boy , it 's such a interface . when you get the , you get the speech signal you also get down beneath it , an indication of , if you have two speakers overlapping in a s in a single segment , you see them one displayed one above each other . and then at the same time the top s part of the screen is the actual verbatim thing . you can clip click on individual utterances and it 'll take you immediately to that part of the speech signal , and play it for you . and you can , you can work pretty between those two these two things .  ho   i do too . pre lay . and they 've thought about things . they do have you have when you play it back , it 's it is useful to have , a break mark to se segment it . but it wouldn't be strictly necessary cuz you can use the the tabbed key to toggle the sound on and off . it 'll stop the s speech if you press a tab . and , and that 's a feature . and then also once you 've put a break in then you have the option of cycling through the unit . you could do it like multiply until you get crazy and decide to stop cycling through that unit . or or why , that 's that 's not something i wanted to have happen . i see .    i agree . they have several options . i mentioned the looping option . another option is it 'll pause when it reaches the end of the boundary . and then to get to the next boundary you just press tab and it goes on to the next unit . it 's very nicely thought out . they thought about and also it 'll go around the c the , i wanna say cursor but i 'm not if that 's the right thing . anyway , you can they thought about different ways of having windows that you c work within , and but in terms of the con the conventions , then , it 's strictly orthographic which means with some w provisions for , w colloquial forms . if a person said , "" cuz "" instead of "" because "" then i put a an apostrophe at the beginning of the word and then in double ang angle brackets what the full lexical item would be . and this could be something that was handled by a table but to have a convention marking it as a non standard or wha i don't mean standard but a non ortho orthographic , whatever . "" gonna "" or "" wanna "" , the same thing . and there would be limits to how much refinement you want in indicating something as non standard pres pronunciation . backchannels ?   yes , there was some in my view , when i when you 've got it densely overlapping , i didn't worry about s specific start times . that this is not gonna be easily processed anyway and shouldn't spend too much time getting exactly when the person said "" no "" , or , i "" immediate "" . and instead just rendered "" within this time slot , there were two people speaking during part of it and if you want more detail , figure it out for yourself "" , was the way i felt @ @  that happened very seldom . dan . appreciate it . if it if there was a word like "" right "" , then i wou i would indicate that it happened within the same tem time frame but wouldn't say exactly when it happened . a lot of overlapping ,  that 's true . that 's another issue .  only when it was otherwise gonna be puzzling because he was in the other room talking .  that 's true . i know . he was he was checking the meter levels and we were handling things while he was labeling the whatever it was , the pda ? and he was in you were talking  was saying , like "" and i could label this one left . right ? "" and he said , "" i don't see anything "" . and he said , "" i wasn't talking to you "" . or it wasn't it didn't sound quite that rude . but really , no , in the context if he can't hear what he 's saying  i know . you 'll see . you can listen to it . it was you who was . no , but you were asking off the wall questions . and that 's w that 's where i added comments . the rest of the time i didn't bother with who was talking to who but this was unusual circum circumstance . and part of it was funny , reason was because it was a mixed signal you couldn't get any clues from volume that , he was really far away from this conversation . you couldn't do that symmetrically in any case . that 's a good idea . but it would be i didn't wanna add more contextual comments than were needed but that , it seemed to me , clarified that the con what was going on . and ,  normalization    my focus was to try and maintain conten con content continuity and , to keep it within what he was saying . like i wouldn't say breath groups but prosodic or intonational groups as much as possible . ","one of them is the idea of how to indicate speaker change , and but in terms of the con the conventions , then , it 's strictly orthographic which means with some w provisions for , w colloquial forms . if it if there was a word like "" right "" , then i wou i would indicate that it happened within the same tem time frame but wouldn't say exactly when it happened . my focus was to try and maintain conten con content continuity and , to keep it within what he was saying . like i wouldn't say breath groups but prosodic or intonational groups as much as possible . ","The Transcriber software tool was introduced, along with a set of transcription conventions for coding different speech events. "
Bmr003.E,"if someone said "" in the middle of a of someone 's , intonational contour , i indicated it as , like what you just did . then i indicated it as a segment which contained @ @ this utterance plus an overlap .  that 's right . and it could be made more precise than that but thought  i see what and then "" hesitation "" .   and then , in terms of like words like "" and "" wrote them because i figured there 's a limited number , and i keep them to a limited set because it didn't matter if it was "" or "" , versus "" . just always wrote it as u m . and "" , "" "" like a s set of like five . but in any case i didn't mark those . i 'd be happy with that . that 'd be fine . it 'd be good to have that in the conventions , what 's to be used .  that 's a fine idea . that 's a fine idea .    had i d you see , that 's possible too .  now that 's refinement that , it could be handled by part of the script more  you were saying , it can read  which allows five . and it can be m edited after the fact , can't it also ? but their format , if you wanted to in indicate the speakers right there instead of doing it through this indirect route , then i they a c window comes up and it only allows you to enter two speakers .  but . and that and that works nicely cuz this quick to enter . wouldn't wanna do it through the interface anyway adding which worry who the speaker was . and then , let 's see what else . yes , i wanted to have sometimes a pers i in terms of like the continuity of thought for transcriptions , it 's i it isn't just words coming out , it 's like there 's some purpose for an utterance . and sometimes someone will do a backchannel in the middle of it but you wanna show that it 's continued at a later point . have a convention of putting like a dash arrow just to indicate that this person 's utterance continues . and then when it catches back up again then there 's an arrow dash , and then you have the opposite direction to indicate continuation of ones own utterance versus ,  sometimes we had the situation which is which you get in conversations , of someone continuing someone else 's utterance , and in that case i did a tilde arrow versus a arrow tilde , to indicate that it was continuation but it wasn't did equal arrow for the own for yourself things cuz it 's the speakers the same . and then tilde arrow if it was a different if a different speaker , con continuation . but just , the arrows showing continuation of a thought . and then you could track whether it was the same speaker or not by knowing at the end of this unit you 'd happened later . and that was like this person continued and you 'd be able to look for the continuation .    i didn't use it very often . excellent .   that 's that 's why i didn't do it n that 's why about it , and re ev and it didn't do i didn't do it in ten times the time .  i also wanted to ask you if you have a time estimate on the part that you transcribed . do you have a sense of how long    that 's because you didn't have the segmentation help and all the other  and there 's always a warm up thing of  i don't think you 're the one who raised the issue . alright .  now , w the alternative to a web site would be to put it in doctor speech . cuz what i have is a soft link to my transcription that i have on my account but it doesn't matter .  web site 's then you have to t you have to do an ht access . ooo ! he 's committed himself to something . i know , i know .    which one do you use jim ? that 's right . i remember .  which produces also site maps . would this be to document it also for outside people or mainly for in house use ?  we could do an ht access which would accommodate those things . wonderful . it is true , that is it benefits to that 's right . it 's the early on . it 's a great idea .  and th "" that "" being a diagram .   let the record show that this is exhibit two b . that 's good . that looks like a semi circle . sleeping pol speed bump . that 's good . there we go s is that right ? i never heard that .   which means two at each station .  i 'm just saying that for the recording . that being the wiring box . what  each of the blue wires ?   how great . that 's amazing .   tempting . tempting .  use user interface  like see meter readings , from while sitting here .      that 's a great idea . it 's to be thinking toward that .   interesting . and shorter words . that 's a long word ! i don't know . i 'm done ,  or both . we don't know that for do we ? but i also think you said channel four and you meant microphone four . and that 's a mistake .    interesting . social security numbers . bank account numbers . passport numbers . password to your account . go on . i was i the reason i made my mistake was wa was this ? ","if someone said "" in the middle of a of someone 's , intonational contour , i indicated it as , like what you just did . then i indicated it as a segment which contained @ @ this utterance plus an overlap .  and then , in terms of like words like "" and "" wrote them which allows five . and it can be m edited after the fact , and that works nicely cuz this quick to enter . wouldn't wanna do it through the interface anyway adding which worry who the speaker was . in terms of like the continuity of thought for transcriptions , it 's i it isn't just words coming out , have a convention of putting like a dash arrow just to indicate that this person 's utterance continues . sometimes we had the situation which is which you get in conversations , of someone continuing someone else 's utterance , and in that case i did a tilde arrow versus a arrow tilde , to indicate that it was continuation but just , the arrows showing continuation of a thought . and you 'd be able to look for the continuation . we could do an ht access which would accommodate those things . and th "" that "" being a diagram . which means two at each station . ","The Transcriber software tool was introduced, along with a set of transcription conventions for coding different speech events. "
Bmr003.E,good news .  ,,
Bmr006.A,"that is weird . it 's like when it 's been sitting for a long time next time you get it we should write it down . great . great . what a deal . no crunchy food . "" beep . "" that 's a good idea . what if you could tell them that you 'll give them the transcripts when they come back ? see you . where did you copy it to ? on the tape .   generating a clone ?   hunh ! is there a difference in price   i 've been looking at the , aurora data and , first look at it , there were three directories on there that could be moved . one was called aurora , one was spanish , which was carmen 's spanish and the other one was , spine . and i wrote to dan and he was very concerned that the spine was moving to a non backed up disk . i realized that probably not all of that should be moved , just the cd rom type data , the static data . moved that , and then i asked him to check out and see if it was before i actually deleted the old but i haven't heard back yet . i told him he could delete it if he wanted to , i haven't checked today to see if he 's deleted it or not . and then carmen 's i realized that when i had copied all of her to xa , i had copied there that was dynamic data . and i had to redo that one and just copy over the static data . and need to get with her now and delete the old off the disk . and then i lo haven't done any of the aurora i have to meet with , stephane to do that .  is that the one that has is that dc ?  i but the 'm moving from aurora is on the dc disk that we dc .  should , one question i had for you was , we need we sh probably should move the aurora an and all that other off of the meeting recorder disk . is there another backed up disk that of that would ?  right . right . do what happen to disk that is off ?    alright , i 'll find out from you .    these will be assigned by hand ? based on the  you need truth . you 're not using all of the data . is is your silence category pure silence , or ? what if there was a door slam pure silence .  you have your own ?   what 's it written in ?  i 've got a question . i this is a dumb question , but w it would be easier if you used a pda because can't you , couldn't you like use beam forming to detect speaker overlaps ?   is that not allowed with this project ? but i didn't mean i w given the goal . is that violation of the  right . right .  i see .  no , it 's not that much as it 's i don't know ho i would guess but th i don't think that matters , though . right . it 's like how confused is it about where the beam is . what looked different ? did b 'm not what dan 's page is that he was looking at the two    if there 's two if i was here and morgan was there and we were both talking , it wouldn't work . yes . once you got two what about just doing it from these mikes ?  that 's what i was asking about , what are the constraints ?   didn't they have something at cape ? i saw a demo .  and you could in a noisy room , they could have all kinds of noises and you can zoom right in on somebody . that is no , what you need to do is you 'd have a little fabric thing that you unroll and hang on a wall . it has all these mikes and it has a plug in jack to the pda . ooo ! network ! i still like my rug on the wall idea , if anybody patents that , then  hats ? shirts . are they new ?  we still have to do this , too , right ? digits ? i don't right , you don't wanna do that .   "" the person who 's doing the transcript "" the ibm people ? they 're just gonna write "" bob "" on it or do @ @ they can't do that . that would be hard .  but , at the beginning of this meeting or , you said , or s liz , said something about "" is mari gonna use the equipment ? "" how would you say that ? you have to really think , about what you 're saying bef  it would be really hard if we made a policy where we didn't say names , plus we 'd have to tell everybody else . right .  the don't know , my own two cents worth is that you don't do anything about what 's in the recordings , you only anonymize to the extent you can , the speakers have signed the forms and all . why ? we were gonna get it labelled speaker one , speaker two why do you have to know his name ?    i see , you wanna associated the word "" jose "" in the dialogue with the fact that then he responded . one thing to take into consideration is w are there any the people who are funding this work , they want this work to get out and be useful for discourse . if we all of a sudden do this and then release it to the public and it 's not longer useful for discourse ,   ","because can't you , couldn't you like use beam forming to detect speaker overlaps ? ",
Bmr006.A,"but if you release both but if both of those are publically available we should just not allow anybody to do research on discourse , and then , we wouldn't have to worry about it . mister white . but the syllables were in the same order , with respect to each other , but the acous what did it sound like ? it would be fun sometime to read them with different intonations . like as if you were talking like , "" nine eight six eight seven ? "" really . they were like looking ahead ,   i was thinking that it must get boring for the people who are gonna have to transcribe this they may as throw in some interesting intonations . ",,
Bmr006.B," now we 're on and it seems to be working .  i don't it is . but all i know is that it seems like every time i am up here after a meeting , and i start it , it works fine . and if i 'm up here and i start it and we 're all sitting here waiting to have a meeting , it gives me that error message and i have not yet sat down with been able to get that error message in a point where sit down and find out where it 's occurring in the code . we will . one of these days . no . and what 's he interested in , specifically ?  great . right . one offs ?  right .  we 're hoping that they 'll let us start recording regularly .    we have a lot of overlap between this meeting and the morning meeting . we 've only had three .    right .  just talking about . we all had the same thought .  that , think that the only thing we should say in the advertisement is that the meeting should be held in english . and if it 's a pre existing meeting and it 's held in english , it 's probably if a few of the people don't have g particularly good english skills . right . right . not to mention the fact that i would be hesitant certainly to take anyone under eighteen , probably even an anyone under twenty one .  what 's that ? age ist . the "" eighteen "" is because of the consent form . we 'd hafta get find their parent to sign for them .  we 'd need a real motivated partner to do that . we 'd need to find someone on campus who was interested in this .  right . i know that space is really scarce on at least in cs . to actually find a room that we could use regularly might actually be very difficult . that 's true . true .    it would be interesting because then we could regularly get another meeting . another type of meeting .  right . but if we wanna just record with the tabletop microphones , that 's easy . right ? that 's very easy , but that 's not the corpus that we 're collecting . and you don't really need the close microphone , ye tape recorder .  not enough for others , right .   for some of it .  right . special ?   here . too . i was thinking , lunch after .  i had a i spoke with some people up at haas business school who volunteered . should i pursue that ?   they originally they 've decided not to do go into speech . 'm not whether they 'll still be willing to volunteer , but i 'll send an email and ask . i 'll tell them about the free lunch . and they 'll say there 's no such thing .  right . that 's alright . no , the they 're very weird . the problem with engineers is "" beep . "" let them have their meeting . of the meeting ? it 'd be fun . it would just be fun , if nothing else , it 's a novelty item .   anyone can have the transcripts . we could point that out . that 's right . that 's a good point . right , it can't be the internal one . that 's right . that 's true .  see you . no . bye . we are slowly getting to the point where we have enough sp room to record meetings . did a bunch of archiving , and still doing a bunch of archiving , i 'm in the midst of doing the p files from broadcast news . and it took eleven hours to do to copy it . and it 'll take another eleven to do the clone . it 's abbott . it 's abbott , it just but it 's a lot of data . tape . i did an archive . 'm archiving it , and then i 'm gonna delete the files . that will give us ten gigabytes of free space . and  and one that will be done in about two hours . and at that point we 'll be able to record five more meetings .  right . especially because i 'm generating a clone , also . and that takes a while . two copies . one offsite , one onsite . no , the these are the p files from broadcast news , which are regeneratable if we really need to , but we had a lot of them . and for the full , hundred forty hour sets . and they were two gigabytes per file and we had six of them or six . the sun , ha takes more disks than the andatico one did . the sun rack takes th one took four and one took six , or it was eight and twelve . whatever it was , fifty percent more . what happened is that we bought all our racks and disks from andatico for years , according to dave , and andatico got bought by another company and doubled their prices . and we 're looking into other vendors . "" we "" by "" we "" dave .  spine .  we have space on the current disk right now , where meeting recorder is , and that 's probably enough for about four meetings .   no , no , it 's wherever the meeting recorder currently is . it 's di . i don't remember . th it 's dc it 's whatever that one is . don't remember , it might be dc . and that has enough for about four more meetings right now . ","that , think that the only thing we should say in the advertisement is that the meeting should be held in english . and you don't really need the close microphone , i had a i spoke with some people up at haas business school who volunteered . should i pursue that ? ",
Bmr006.B,"we were at a hundred percent and then we dropped down to eighty six for reasons i don't understand . someone deleted something somewhere . and we have some room again . and then with broadcast news , that 's five or six more meetings , we have a couple weeks . we 're until we get the new disk . we should put it onto the broadcast news one . that 's probably the best thing to do . and that way we consolidate meeting recorder onto one disk rather than spreading them out . no . tell you , don't know off the top of my head . but , we could ' jus just do that at the end of today , once the archive is complete , and i 've verified it . cuz that 'll give us plenty of disk .  i 've seen it already .  throughout the meeting .  you did that by hand ? can i see that ? can i get a copy ?  yes , and are you planning to do that or have you done that already ? have you done that or are you planning to do that ?  darn ! right . fans . you intend to hand mark those and exclude them ?  whew !  i should 've got the digital camera .   nonspeech . training , and validation .  but this is what you 're starting with . one or two or more . that 's what he was saying before . that 's what he was saying before , is that he excluded those .  right . with the fan . right . fine . go on . right . "" tone "" , whatever .  bad . right . but , as a feature , it might be we don't know . supervised clustering .    what classifier ar ? unimodal ? is it just one cluster per right . right , you can't analyse it . using something simpler first is probably fine . decision tree . right . right . right . deltas ,  context window ?  some that 's i 'm i 'm i didn't understand you what you said . what model ?  features .  features ? with right . mixed . right . that 's a good way to start . but . it would be interesting in itself to see . that would be an interesting result . right . but it it would be interesting to try a couple with both . because it it would be interesting to see if some features work with close mixed , and don't  right . they 're hidden . are probably better , if you used the array , rather than the signal from just one . but that 's  we hav need to put it on a little turntable , and but it 's another source of information .    cross co cross correlation . subtract them . and you find they get peaks . and if there are multiple people talking , you 'll see two peaks . right . or even if if people were sitting right across from each other , you couldn't tell the difference either . right . must do .  but and dan is still working on it . he actually he wrote me about it a little bit ,   then they 're much broader . we can do whatever we want . whatever you 're interested in .   big micro @ @ arrays . very finely . i saw one that was like a hundred microphones , a ten by ten array . and they had very precision . right . it was all in software and they and you could pick out an individual beam and listen to it . it was it was interesting . but  that 's on my web pages .  though all sorts of interesting things you can do with that , not only can you do microphone arrays , but you can do all sorts of multi band as it 's it would be neat . but  in terms of  in terms of the research th research , it 's really it 's whatever the person who is doing the research wants to do . if jose is interested in that , that 's great . but if he 's not , that 's great too . catch some tea ?  i had a couple things that i did wanna bring out . one is , do we need to sign new these again ?  i should 've checked with jane first , but the ch the form has changed . we may wanna have everyone sign the new form . i had some things i wanted to talk about with the thresholding 'm doing . but , if we 're in a hurry , we can put that off . and then also anonymity , how we want to anonymize the data .  no we don't have to do digits . go ahead , jane .  alright . we 're just we 're getting enough data now that i 'd like to do it now , before i get overwhelmed with once we decide how to do it going and dealing with it .  right .  no , because then that would give you a mapping , and you don't wanna have a mapping . no . because that would give you a mapping between the speaker 's real name and the tag we 're using , and we don't want  we don't we wanna we ha we want the transcript to be "" roger "" . because if we made the transcript be the tag that we 're using for roger , someone who had the transcript and the audio would then have a mapping between the anonymized name and the real name , and we wanna avoid that .  ugh ! that 's a good point . right . ugh !    shoot !  shoot ! i 'm thinking too much .  ","throughout the meeting . and are you planning to do that or have you done that already ? supervised clustering . if you used the array , rather than the signal from just one . and if there are multiple people talking , you 'll see two peaks . not only can you do microphone arrays , but you can do all sorts of multi band as and then also anonymity , how we want to anonymize the data . because that would give you a mapping between the speaker 's real name and the tag we 're using , and we don't want because if we made the transcript be the tag that we 're using for roger , someone who had the transcript and the audio would then have a mapping between the anonymized name and the real name , and we wanna avoid that . ","And, finally, the problem of speaker anonymization was explored. "
Bmr006.B,"i would sug i don't wanna change the names in the transcript , but that 's because i 'm focused much on the acoustics instead of on the discourse , and think that 's a really good point . you 're right , this is going to require more thought .  how will we how would the person who 's doing the transcript even know who they 're talking about ? do what i 'm saying ?  how is that information gonna get labeled anyway ? if i 'm saying in a meeting , "" and bob , wanted to do and , if you 're doing @ @ they 're just gonna write "" bob "" . and if you 're doing discourse analysis , really . the current one they don't do speaker identity . because in naturallyspeaking , or , excuse me , in viavoice , it 's only one person . and in their current conventions there are no multiple speaker conventions .  y yu ching . we can probably regenerate it pretty easily from the close talking mikes . but that doesn't this doesn't answer the question . the p it 's a good point , "" which what do you do for discourse tracking ? ""  for acoustics you don't but for discourse you do . ugh , that 's a problem . if you wanted to anonymize .  darn ! what i was gonna say is that the other option is that we could bleep out the names . but then , again that kills your discourse analysis . ugh ! but that as i said , that works great for the acoustics , but it hurts you a lot for trying to do discourse . because you don't have a map of who 's talking versus their name that they 're being referred to . but , h then you have to know that jose is speaker one and someone who 's doing discourse would wanna do that . and that violates our privacy . and that violates our privacy issue .  making some decisions ?  for the public one . what we could do also is have more than one version of release . one that 's public and one that requires licensing . and the licensed one would w we could it would be a sticky limitation . like we can talk about that later . depending on how much editing we do , you might be able to still have it useful . because for discourse you don't need the audio . right ? you could bleep out the names in the audio . and use the anonymized one through the transcript . but , n excuse me , but you could bleep out just the names . right . but in the transcript , you could say , everywhere they said "" jose "" that you could replace it with "" speaker seven "" . and then it wouldn't meet match the audio anymore . but it would be still useful for the but they right . good point . i didn't think when i wrote you that email i wasn't thinking it was a big can of worms , but it is . discourse . ab  did you read the paper on eurospeech ?  did you read the paper a few years ago where they were reversing the syllables ? they were di they had the utterances . and they would extract out the syllables and they would play them backwards . everything was in the same order , but they were the individual syll syllables were played backwards . and you could listen to it , and it would sound the same . people had no difficulty in interpreting it . what we need is something that 's the reverse , that a speech recognizer works exactly the same on it but people can't understand it . right . the speech recognizer 's symmetric , isn't it . anyway . we 'll quickly do digits .  go off here .  except ,  we have the transcript . we have the actual numbers they 're reading , we 're not necessarily depending on that . i 'm gonna go off . ","i would sug i don't wanna change the names in the transcript , but that 's because i 'm focused much on the acoustics instead of on the discourse , and think that 's a really good point . you 're right , this is going to require more thought . how will we how would the person who 's doing the transcript even know who they 're talking about ? how is that information gonna get labeled anyway ? the current one they don't do speaker identity . because in naturallyspeaking , or , excuse me , in viavoice , it 's only one person . and in their current conventions there are no multiple speaker conventions . ",
Bmr006.C,"one two three four five six         it 's difficult .     "" age ist "" .   but you need , another portable thing a another portable equipment to do , more e easier the recording process , out from icsi . and probably . i don't know . if you want to record , a seminar or a class , in the university , you need it would be very difficult to put , a lot of , head phones in different people when you have to record only with , this d device .  ye .             see you . eleven ? tape ?  eleven hours ?            i have , the result of my work during the last days . for your information because i read . and the last , days , i work , in my house , in a lot of ways and thinking , reading different things about the meeting recording project . and i have , some ideas . this information is very useful . because you have the distribution , now . but for me , is interesting because , here 's i is the demonstration of the overlap , problem . it 's a real problem , a frequently problem because you have overlapping zones all the time .  by a moment i have , nnn , the , n i did a mark of all the overlapped zones in the meeting recording , with a exact mark . heh ? that 's yet b by b by hand because , why . "" my idea is to work i do i don't @ @ i don't know , if , it will be possible because i haven't a lot enough time to work . only just six months , as but , my idea is , is very interesting to work in the line of , automatic segmenter . but in my opinion , we need a reference session to t to evaluate the tool . and no , with i  no , i plan to do that . i plan i plan , but the idea is the following . now , i need ehm , to detect all the overlapping zones exactly . i will talk about in the blackboard about the my ideas . this information with exactly time marks for the overlapping zones overlapping zone , and a speaker a pure speech speaker zone . zones of speech of one speaker without any noise any acoustic event that w is not speech , real speech . and , i need t true silence for that , because my idea is to study the nnn the set of parameters what , are more m more discriminant to classify . the overlapping zones in cooperation with the speech zones . the idea is to to use i 'm not to yet , but my idea is to use a cluster algorithm or , nnn , a person strong in neural net algorithm to study what is the , the property of the different feat feature , to classify speech and overlapping speech . and my idea is it would be interesting to have a control set . and my control set will be the silence without any noise . acoustic with this . with , the background . noise claps tape clips , the difference event which , has , a hard effect of distorti spectral distortion in the speech . i have mark in that not in all the file , only nnn , i have ehm i don't remind what is the quantity , but i have marked enough speech on over and all the overlapping zones . i have , two hundred and thirty , more or less , overlapping zones , and is similar to this information , because with the program , i cross the information of of jane with my segmentation by hand . and is mor more similar . but  and the idea is , i will use , i want my idea is , to to classify . i need the exact mark of the different , zones because i want to put , for each frame a label indicating . it 's a sup supervised and , hierarchical clustering process . i put , for each frame a label indicating what is th the type , what is the class , which it belong . the class you will overlapping speech "" overlapping "" is a class , "" speech "" @ @ the class that 's a i ha i h i put the mark by hand , because , my idea is , in the first session , i need , to be that the information that , i will cluster , is right . because , if not , i will i will , return to the speech file to analyze what is the problems , and i 'd prefer i would prefer , the to have , this labeled automatically , but , fro th i need truth .   speech    is one , two , three . but no , by th by the moment n .   in the first moment , because , i have information , of the overlapping zones , information about if the , overlapping zone is , from a speech , clear speech , from a one to a two speaker , or three speaker , or is the zone where the breath of a speaker overlaps onto a speech , another , especially speech . no , es especially overlapping speech from , different speaker .    he here i put speech from from , one speaker without , any events more . where ? where what is the class ? no . by the moment , no . for the by the @ @ no , @ @ because i want to limit the nnn , the study . the all i exactly .  be  "" why ? why ? what 's the reason ? "" because i it 's the first study . the first    ","i have , the result of my work during the last days . this information is very useful . because you have the distribution , now . but for me , is interesting because , here 's i is the demonstration of the overlap , problem . it 's a real problem , a frequently problem because you have overlapping zones all the time . by a moment i have , nnn , the , n i did a mark of all the overlapped zones in the meeting recording , heh ? that 's yet b by b by hand because , why . "" but , my idea is , is very interesting to work in the line of , automatic segmenter . no , i plan to do that . now , i need ehm , to detect all the overlapping zones exactly . this information with exactly time marks for the overlapping zones overlapping zone , and a speaker a pure speech speaker zone . zones of speech of one speaker without any noise any acoustic event that w is not speech , real speech . for that , because my idea is to study the nnn the set of parameters what , are more m more discriminant to classify . the overlapping zones in cooperation with the speech zones . the idea is to to use i 'm not to yet , but my idea is to use a cluster algorithm or , nnn , a person strong in neural net algorithm to study what is the , the property of the different feat feature , to classify speech and overlapping speech . and my control set will be the silence without any noise . event which , has , a hard effect of distorti spectral distortion in the speech . i have , two hundred and thirty , more or less , overlapping zones , and is similar to this information , because i want to put , for each frame a label indicating . it 's a sup supervised and , hierarchical clustering process . i put , for each frame a label indicating what is th the type , what is the class , which it belong . a i ha i h i put the mark by hand , because , my idea is , in the first session , i need , to be that the information that , i will cluster , is right . because , if not , i will i will , return to the speech file to analyze what is the problems ,  ",Ongoing efforts by speaker mn005 to automatically  detect regions of speaker overlap were considered. 
Bmr006.C,"in the future , the idea is to extend the class , to consider all the information , you mentioned before but the first idea because i don't hap what will happen with the study .  i it 's pure no , it 's pure silence . it 's the control set .  it 's the control set . it 's pure si pure silence with the machine on the roof .    h here yet , yet i there are that some noises that , don't wanted to be in that , in that control set . but i prefer , i prefer at the first , the silence with this this the of of noise .    is only  and , with this information the idea is nnn , i have a label for each , frame and , with a cluster algorithm i and  and am going to prepare a test bed , a set of feature structure models . and my idea is on because i have a pitch extractor yet . i have to test , but  i ha i have prepare . is a modified version of a pitch tracker , from , standar stanford university in stanford ? no . from , cambridge university . i don't remember what is the name of the author , because i have several i have library tools , from festival and of from edinburgh from cambridge , and from our department . and i have to because , in general the pitch tracker , doesn't work very and  this is and th the idea is to , to obtain , diff different no , a great number of fec twenty five , thirty parameters , for each one . and in a first nnn , step in the investi in the research in my idea is try to , to prove , what is the performance of the difference parameter , to classify the different , what is the front end approach to classify the different , frames of each class and what is the , nnn , nnn , what is the , the error of the data this is the first idea and the second is try to to use some ideas similar to the linear discriminant analysis .  similar , because the idea is to study what is the contribution of each parameter to the process of classify correctly the different parameters . the classifier is nnn by the moment is similar , nnn , that the classifier used in a quantifier vectorial quantifier is used to some distance to put a vector in a class different . is w with a model , is only to cluster using a @ @ or a similarity . a another possibility it to use netw a neural network . but what 's the p what is my idea ? what 's the problem i see in if you use the neural network ? if w when this cluster , clustering algorithm to can test , to can observe what happened you can't put up with your hand in the different parameter , but if you use a neural net is a good idea , but you don't happened in the interior of the neural net .      but    and i will include too the differential de derivates too .             s because   i but is my own vision , of the project . i the meeting recorder project , for me , has two w has several parts , several p objective because it 's a great project . but at the first , in the acoustic , parts of the project , think you we have two main objective . one of these is to to detect the change , the acoustic change . and for that , if you don't use , a speech recognizer , broad class , or not broad class to try to label the different frames , the ike criterion or bic criterion will be enough to detect the change . and probably . i would like to t prove . probably . when you have , the transition of speech or silence to overlap zone , this criterion is enough with probably with , this the more use used normal , regular parameter mf mfcc . you have to find you can find the mark . you can find the nnn , the acoustic change . but understand that you your objective is to classify , to know that that zone not is only a new zone in the file , that you have but you have to know that this is overlap zone . because in the future you will try to process that zone with a non regular speech recognizer model , i suppose . you will pretend to process the overlapping z zone with another algorithm because it 's very difficult to obtain the transcription from using regular , normal speech recognizer . that , is the idea . and the , nnn the system will have two models . a model to detect more acc the mor most accurately possible that is p will be possible the , the mark , the change and another model will @ @ or several models , to try s but several model robust models , sample models to try to classify the difference class . the classifiers of the n to detect the different class to the different zones before try to recognize , with to transcribe , with speech recognizer . and my idea is to use a neural net with the information we obtain from this study of the parameter with the selected parameter to try to to put the class of each frame . for the difference zone you have obtained in the first step with the bic criterion compare model and you i don't u i       it will be enough .          this  but i don't know it is the first way to do that and i would like to your opinion . ","in the future , the idea is to extend the class , and am going to prepare a test bed , a set of feature structure models . on because i have a pitch extractor yet . and in a first nnn , step in the investi in the research in my idea is try to , to prove , what is the performance of the difference parameter , to classify the different , what is the front end approach to classify the different , frames of each class and what is the , nnn , nnn , what is the , the error of the data and the second is try to to use some ideas similar to the linear discriminant analysis . the classifier is nnn by the moment is similar , nnn , that the classifier used in a quantifier vectorial quantifier is used to some distance to put a vector in a class different . a another possibility it to use netw a neural network . but understand that you your objective is to classify , to know that that zone not is only a new zone in the file , that you have but you have to know that this is overlap zone . because in the future you will try to process that zone with a non regular speech recognizer model , i suppose . you will pretend to process the overlapping z zone with another algorithm because it 's very difficult to obtain the transcription from using regular , normal speech recognizer . a model to detect more acc the mor most accurately possible that is p will be possible the , the mark , the change and another model will @ @ or several models , to try s but several model robust models , sample models to try to classify the difference class . ",
Bmr006.C,"all this study in the f in the first moment , i w i will pretend to do with equalizes speech . the equalizes speech , the speech the mixes of speech . the mix , mixed speech . why ? because the spectral distortion is more lot clearer , very much clearer if we compare with the pda . pda speech file is it will be difficult . i  fff ! because the n the noise to sp the signal to noise relation is is low . and , i don't know i don't know that the result of the study with this speech , the mix speech will work exactly with the pda files . what , what is the effect of the low ' signal to noise relation , with       but that the parameter we found , worked with both speech file , but what is the relation of of the performance when you use the , speech file the pda speech files . i don't know . but it it will be important . because people different groups has experience with this problem . is is not easy to solve , because if you i have seen the speech file from pda , and s some parts is very difficult because you don't see the spectrum the spectrogram . is very difficult to apply a parameter to detect change when you don't see . but i suppose  i will put the energy here .  you have a question .  no .         i i th    i   because the distance between the two microph microphone , in the pda is very near . but it 's from my opinion , it 's an interesting idea to try to study the binaural problem with information , because i found difference between the speech from each micro in the pda .  no . no . no , no . but        correlation ,                 it will be more interesting to study the pzm because the separation         right , hundred .   very complex ,            it 's a good idea .    because y you don't know to know , you don't need to what is the iden identification of the speakers . you only want to know for discourse , .        is            the ? ?      ","but what is the relation of of the performance when you use the , speech file the pda speech files . ",
Bmr006.D," the the new procedural change that just got suggested , which is a good idea is that we do the digit recordings at the end . and that way , if we 're recording somebody else 's meeting , and a number of the participants have to run off to some other meeting and don't have the time , then they can run off . it 'll mean we 'll get somewhat fewer sets of digits , but that way we 'll cut into people 's time , if someone 's on strict time less . i th we should start doing that . let 's see , we were having a discussion the other day , we should bring that up , about the nature of the data that we are collecting . @ that we should have a fair amount of data that is collected for the same meeting , that we can ,  i don't know . wh what were some of the points again about that ? is it  s  now , let l let me just give you the other side to that cuz i ca because i don't disagree with that , but there is a complimentary piece to it too . for other kinds of research , particularly the acoustic oriented research , i actually feel the opposite need . i 'd like to have lots of different people . as many people here a and talking about the thing that you were just talking about it would have too few people from my point of view . i 'd like to have many different speakers . would also very much like us to have a fair amount of really random scattered meetings , of somebody coming down from campus , and if we can get more from them , fine , but if we only get one or two from each group , that still could be useful acoustically just because we 'd have close and distant microphones with different people .  you want to i first place , i don't think we 'd just want to have random people come down and talk to one another , there should be a meeting that has some goal and point cuz that 's what we 're investigating ,   was thinking more in terms of talking to professors and senior d and doctoral students who are leading projects and offering to them that they have their hold their meeting down here . that 's the first point . the second point is  that for some time now , going back through berp that we have had speakers that we 've worked with who had non native accents and i th that    you 're not talking about foreign language you 're just talking about then we 're completely gone . it 's the habits are already burnt in . but  right .      i  that 's what you 're going to have in the networking group . because they most the network group is almost entirely germans and spaniards . i see .      i let 's see what we can get . it that if we 're aiming at groups of graduate students and professors and forth who are talking about things together , and it 's from the berkeley campus , probably most of it will be but    you age ist ! yes . they 're they 're d they 're assessing whether they should do that or y do something else , hopefully over the next few weeks . the other thing the other thing that i was hoping to do in the first place was to turn it into some portable thing you could wheel it around .  but . and    john would let us put it into the phonology lab      actually , that 's a int that raises an interesting point that came up in our discussion that 's worth repeating . we realized that , when we were talking about this that , there 's these different things that we want to do with it . it 's true that we wanna be selective in some ways , the way that you were speaking about with , not having an interlingua and these other issues . but on the other hand , it 's not necessarily true that we need all of the corpus to satisfy all of it . a as per the example that we wanna have a fair amount that 's done with a small n recorded with a small , typ number of types of meetings but we can also have another part that 's , just one or two meetings of each of a range of them and that 's too . i we realized in discussion that the other thing is , what about this business of distant and close microphones ? we really wanna have a substantial amount recorded this way , that 's why we did it . but what about for th for these issues of summarization , a lot of these higher level things you don't really need the distant microphone . you actually don't . you d you don't ne it doesn't you just need some microphone , somewhere .  you need some microphone , but  right . right . that but that i 'm raising that cuz it 's relevant exactly for this idea up there that if you think about , "" gee , we have this really complicated setup to do , "" you don't . if really all you want is to have a recording that 's good enough to get a a transcription from later , you just need to grab a tape recorder and go up and make a recording . we could have a fairly we could just get a dat machine and right .  i i agree . but that the we can't really underestimate the difficulty shouldn't really u underestimate the difficulty of getting a setup like this up . ","let 's see , we were having a discussion the other day , we should bring that up , about the nature of the data that we are collecting . @ that we should have a fair amount of data that is collected for the same meeting , that we can , for other kinds of research , particularly the acoustic oriented research , i actually feel the opposite need . i 'd like to have many different speakers . would also very much like us to have a fair amount of really random scattered meetings , of somebody coming down from campus , and but if we only get one or two from each group , that still could be useful acoustically just because we 'd have close and distant microphones with different people . was thinking more in terms of talking to professors and senior d and doctoral students who are leading projects and offering to them that they have their hold their meeting down here . it that if we 're aiming at groups of graduate students and professors and forth who are talking about things together , and it 's from the berkeley campus , probably most of it will be the other thing the other thing that i was hoping to do in the first place was to turn it into some portable thing you could wheel it around . i we realized in discussion that the other thing is , what about this business of distant and close microphones ? we really wanna have a substantial amount recorded this way , but what about for th for these issues of summarization , a lot of these higher level things you don't really need the distant microphone . but that the we can't really underestimate the difficulty shouldn't really u underestimate the difficulty of getting a setup like this up . ","It was agreed that a substantial amount of meeting data is required from different domains, and comprising several speakers, to perform the types of discourse and acoustic analyses desired. "
Bmr006.D,"and it took quite a while to get that together and to say , "" we 'll just do it up there , "" if you 're talking about something simple , where you throw away a lot of these dimensions , then you can do that right away . talking about something that has all of these different facets that we have here , it won't happen quickly , it won't be easy , and there 's all sorts of issues about th keeping the equipment safe , or else hauling it around , and all sorts of o the first priority should be to pry to get try to get people to come here . we 're set up for it . the room is really , underused .  free lunch is good .  they have to do their digits or they don't get their food .   tell them about the free lunch .  the oth the other h  "" beep "" the they make funny sounds . the o the other thing is , that we talked about is give to them burn an extra cd rom . and give them if they want a and audio record of their  if you 're having some planning meeting of some sort and you 'd like  but it als it also builds up towards the goal . we 're saying , "" look , you 're gonna get this . is isn't that neat . then you 're gonna go home with it . it 's actually p it 's probably gonna be pretty useless to you , but you 'll ge appreciate , where it 's useful and where it 's useless , and then , we 're gonna move this technology , it 'll become useful . ""   good point . that 's a very good point . we can we can r right . although it 's that 's let 's start with haas , and that 's fine .  that 's alright .  let 's see . that was that topic , and then another topic would be where are we in the whole disk resources question for sk it 's copying from one place on abbott to another place on abbott ?  i 'm is it ?  s w we are getting more space . we are getting , another disk rack and four thirty six gigabyte disks . but that 's not gonna happen instantaneously . or six ? how many how much but , you 're figuring you can record another five meetings with the space that you 're clearing up from the broadcast news , but , we have some other disks , some of which you 're using for aurora , but are we g do we have some other space now ?    @ @ then th the last thing i 'd had on my agenda was just to hear an update on what jose has been doing ,         go ahead . no , but there 's but , she 's saying "" where do you in these three categories , where do you put the instances in which there is one person speaking and other sounds which are not speech ? "" which category do you put that in ? right , where do you put speech from one speaker that does have a nonspeech event at the same time ? which catege which category ? you not marked .  got it . fine .  that 's fine . no , it 's a perfectly sensible way to go . we just wondered trying to understand what you were doing .  i don't think we were asking for that . we were jus just trying to understand   what you  w what you m what is that it 's nonspeech segments that don't have impulsive noises . right ? cuz you 're calling what you 're calling "" event "" is somebody coughing or clicking , or rustling paper , or hitting something , which are impulsive noises . but steady state noises are part of the background . which , are being , included in that . right ?    right , it 's it 's "" background "" might be a better word than "" silence "" . it 's just that the background acoustic   right .  actually , you can do sensitivity analyses which show you what the importance of the different parce pieces of the input are . it 's hard to w what you it 's hard to tell on a neural net is what 's going on internally . but it 's actually not that hard to analyse it and figure out the effects of different inputs , especially if they 're all normalized . but this isn't tru if you really wonder what different if then a decision tree is really good , but here he 's not he 's not like he has one a bunch of very distinct variables , like pitch and this he 's talking about all these cepstral coefficients , and forth , in which case a any reasonable classifier is gonna be a mess , and it 's gonna be hard to figure out what  the other thing that one this is , good thing to do , to look at these things at least see what i 'd let me tell you what i would do . i would take just a few features . instead of taking all the mfcc 's , or all the plp 's or whatever , i would just take a couple .  like c one , c two , something like that , that you can visualize it . and look at these different examples and look at scatter plots . before you do build up any fancy classifiers , just take a look in two dimensions , at how these things are split apart . that will give you a lot of insight of what is likely to be a useful feature when you put it into a more complicated classifier . ","if you 're talking about something simple , where you throw away a lot of these dimensions , then you can do that right away . the first priority should be to pry to get try to get people to come here . the o the other thing is , that we talked about is give to them burn an extra cd rom . and then another topic would be where are we in the whole disk resources question we are getting , another disk rack and four thirty six gigabyte disks . but that 's not gonna happen instantaneously . @ @ then th the last thing i 'd had on my agenda was just to hear an update on what jose has been doing , cuz you 're calling what you 're calling "" event "" is somebody coughing or clicking , or rustling paper , or hitting something , which are impulsive noises . but steady state noises are part of the background . right , it 's it 's "" background "" might be a better word than "" silence "" . but here he 's not he 's not like he has one a bunch of very distinct variables , like pitch and this he 's talking about all these cepstral coefficients , and forth , in which case a any reasonable classifier is gonna be a mess , and it 's gonna be hard to figure out what i would take just a few features . instead of taking all the mfcc 's , or all the plp 's or whatever , i would just take a couple . like c one , c two , something like that , that you can visualize it . and look at these different examples and look at scatter plots . before you do build up any fancy classifiers , just take a look in two dimensions , at how these things are split apart . ","Disk space issues were discussed. It was suggested that speaker mn005 focus on a small set of acoustic parameters, e.g. energy and harmonics-related features, to distinguish regions of overlap from those containing the speech of just one speaker. "
Bmr006.D,"and the second thing is , once you actually get to the point of building these classifiers , @ @ what this lacks far is the temporal properties . if you 're just looking at a frame and a time , you don't know anything about , the structure of it over time , and you may wanna build @ @ build a markov model of some sort or else have features that really are based on on some bigger chunk of time . but this is a good place to start . but don't anyway , this is my suggestion , is don't just , throw in twenty features at it , the deltas , and the delta del and all that into some classifier , even if it 's k nearest neighbors , you still won't know what it 's doing , even it 's to it 's to have a better feeling for what it 's look at som some picture that shows you , "" here 's these things are offer some separation . "" and , in lpc , the thing to particularly look at is , is something like , the residual     but , in any event we 're that the first step is because what we had before for speaker change detection did not include these overlaps . the first thing is for you to build up something that will detect the overlaps . right ? again , the first thing to do to detect the overlaps is to look at these in in i again , the things you 've written up there are way too big . if you 're talking about , say , twelfth order mfcc 's like that it 's just way too much . you won't be able to look at it . all you 'll be able to do is put it into a classifier and see how it does . whereas if you have things if you pick one or two dimensional things , or three of you have some very fancy display , and look at how the different classes separate themselves out , you 'll have much more insight about what 's going on . you 'll get a feeling for what 's happening , if you look at suppose you look at first and second order cepstral coefficients for some one of these kinds of things and you find that the first order is much more effective than the second , and then you look at the third and there 's not and not too much there , you may just take first and second order cepstral coefficients , right ? and with lpc , lpc per se isn't gonna tell you much more than the other , and on the other hand , the lpc residual , the energy in the lpc residual , will say how the low order lpc model 's fitting it , which should be pretty poorly for two or more people speaking at the same time , and it should be pretty for w for one . if you take a few of these things that are prob promising features and look at them in pairs , you 'll have much more of a sense of "" i now have doing a bunch of these analyses , i now have ten likely candidates . "" and then you can do decision trees or whatever to see how they combine .  n u we think it 's not a it 's not unreasonable . it makes sense to start with the simpler signal because if you have features which don't aren't even helpful in the high signal to noise ratio , then there 's no point in putting them into the low signal ratio , one would think , anyway . and if you can get @ @ again , my prescription would be that you would , with a mixed signal , you would take a collection of possible features look at them , look at how these different classes that you 've marked , separate themselves , and then collect , in pairs , and then collect ten of them and then proceed with a bigger classifier . and then if you can get that to work then you go to the other signal . and then , and they won't work as but how m how much and then you can re optimize , and on .  that 's the it 's true that it also , it could be useful to do this exploratory analysis where you 're looking at scatter plots and on in both cases .  right .   that that 's another reason why very simple features , things like energy , and things like harmonicity , and residual energy are are better to use than very complex ones because they 'll be more reliable . ch chuck was gonna ask something nah . no , you 're right that if we made use of the fact that there are two microphones , you do have some location information . which we don't have with the one and that 's no , we don't have any rules , r really . think it 's it 's a it 's an additional interesting question . you wanna know whether you can do it with one , because it 's not necessarily true that every device that you 're trying to do this with will have two . if , on the other hand , we show that there 's a huge advantage with two , then that could be a real point . but , we don't n even know yet what the effect of detecting having the ability to detect overlaps is . it doesn't matter too much . this is all pretty early stages . but no , you 're right . that 's a good thing to consider . it does , i it d it does , but the issue is that it 's timing difference . it 's not amplitude , ","if you 're just looking at a frame and a time , you don't know anything about , the structure of it over time , and you may wanna build @ @ build a markov model of some sort or else have features that really are based on on some bigger chunk of time . but don't anyway , this is my suggestion , is don't just , throw in twenty features at it , the deltas , and the delta del and all that into some classifier , even if it 's k nearest neighbors , you still won't know look at som some picture that shows you , "" here 's these things are offer some separation . "" and , in lpc , the thing to particularly look at is , is something like , the residual because what we had before for speaker change detection did not include these overlaps . the first thing is for you to build up something that will detect the overlaps . if you look at suppose you look at first and second order cepstral coefficients for some one of these kinds of things and you find that the first order is much more effective than the second , and then you look at the third and there 's not and not too much there , you may just take first and second order cepstral coefficients , and with lpc , lpc per se isn't gonna tell you much more than the other , and on the other hand , the lpc residual , the energy in the lpc residual , will say how the low order lpc model 's fitting it , which should be pretty poorly for two or more people speaking at the same time , and it should be pretty for w for one . and then you can do decision trees or whatever to see how they combine . and if you can get @ @ again , my prescription would be that you would , with a mixed signal , you would take a collection of possible features look at them , look at how these different classes that you 've marked , separate themselves , and then collect , in pairs , and then collect ten of them and then proceed with a bigger classifier . and then if you can get that to work then you go to the other signal . that that 's another reason why very simple features , things like energy , and things like harmonicity , and residual energy are are better to use than very complex ones because they 'll be more reliable . think it 's it 's a it 's an additional interesting question . that 's a good thing to consider . ","Ongoing efforts by speaker mn005 to automatically  detect regions of speaker overlap were considered. It was suggested that speaker mn005 focus on a small set of acoustic parameters, e.g. energy and harmonics-related features, to distinguish regions of overlap from those containing the speech of just one speaker. "
Bmr006.D,"right ? s right . that 's fine . that 's @ @ the issue is , "" is there a clean signal coming from only one direction ? "" if it 's not coming from just one direction , if it if th if there 's a broader pattern , it means that it 's more likely there 's multiple people speaking , wherever they are . is it a is it is there a narrow beam pattern or is it a distributed beam pattern ? if there 's a distributed beam pattern , then it looks more like it 's multiple people . wherever you are , even if he moves around . ideal would be to have the wall filled with them , but but just having two mikes if you looked at that thing on dan 's page , it was when there were two people speaking , and it looked really different . basic he was looking at correlation . just cross correlation between two sides . cross correlation is pretty sensitive . you take the signal from the two microphones and you cros and you cross correlate them with different lags .  when one person is speaking , then wherever they happen to be at the point when they 're speaking , then there 's a pretty big maximum right around that point in the l in the lag . if at whatever angle you are , at some lag corresponding to the time difference between the two there , you get this boost in the cross correlation value function . it 's spread out .  the i 'm if they 're right next to one another ? i e i see .  we d we don't have a third dimension there . it 's but it 's almost a what you 're talking about i there 's two things . there 's a sensitivity issue , and then there 's a pathological error issue . th the one where someone is just right directly in line is pathological error . if someone just happens to be sitting right there then we won't get good information from it . if they 're close , it 's just a question of the sensitivity . if the sensitivity is good enough and we just don't have enough , experience with it to know how   the other thing you can do if i we 're assuming that it would be a big deal just to get somebody convince somebody to put two microphones in the pda . but if you h put a third in , you could put in the other axis . and then then you 're then you could cover @ but that 's we can we 'll be all of this is there for us to study . but one of the at least one of the things i was hoping to get at with this is what can we do with what we think would be the normal situation if some people get together and one of them has a pda . right . that 's the constraint of one question that both adam and i were interested in .  but if you can instrument a room , this is really minor league compared with what some people are doing , right ? some people at at brown and at and at cape , they both have these , big arrays on the wall . and if you could do that , you 've got microphones all over the place tens of microphones , and and if you do that then you can really get very selectivity  ye  but , the reason why i haven't focused on that as the fir my first concern is because i 'm interested in what happens for people , random people out in some random place where they 're p having an impromptu discussion . and you can't just always go , "" let 's go to this heavily instrumented room that we spent tens of thousands of dollars to se to set up "" . the other thing actually , that gets at this a little bit of something else i 'd like to do , is what happens if you have two p d and they communicate with each other ? and then they 're in random positions , the likelihood that there wouldn't be any l likely to be any nulls , if you even had two . if you had three or four it 's    i i would actually like us to wind it down , see if we can still get to the end of the , birthdays thing there .   this morning we didn't sign anything cuz we said that if anybody had signed it already , we didn't have to .  wha what right . right . why don't we @ @ @ it sounds like u there were a couple technical things people would like to talk about . why don't we just take a couple minutes to briefly do them , and then and then and then we    we could s once you get to the publication you can certainly do that . you can go , "" z "" t it doesn't i 'm not knowledgeable about this , but it certainly doesn't bother me to have someone 's first name in the transcript . you don't wanna have their full name to be listed . and  again , th the issue is if you 're tracking discourse things , if someone says , "" frank said this "" and then you wanna connect it to something later , you 've gotta have this part where that 's "" frank colon "" . right ?  i was too .    l let me just back up this to make a brief comment about the , what we 're covering in the meeting . realize when you 're doing this that mean , i didn't realize that you had a bunch of things that you wanted to talk about . ","if there 's a distributed beam pattern , then it looks more like it 's multiple people . it 's spread out . but one of the at least one of the things i was hoping to get at with this is what can we do with what we think would be the normal situation if some people get together and one of them has a pda . but if you can instrument a room , this is really minor league compared with what some people are doing , right ? but , the reason why i haven't focused on that as the fir my first concern is because i 'm interested in what happens for people , random people out in some random place where they 're p having an impromptu discussion . the other thing actually , that gets at this a little bit of something else i 'd like to do , is what happens if you have two p d and they communicate with each other ? and then they 're in random positions , the likelihood that there wouldn't be any l likely to be any nulls , if you even had two . if you had three or four it 's again , th the issue is if you 're tracking discourse things , if someone says , "" frank said this "" and then you wanna connect it to something later , you 've gotta have this part where that 's "" frank colon "" . ",
Bmr006.D,"and and was proceeding some somewhat at random , frankly . think what would be helpful would be i and i 'll mention this to liz and andreas too , that before the meeting if anybody could send me , any , agenda items that they were interested in and i 'll take the role of organizing them into the agenda , but i 'd be very pleased to have everyone else completely make up the agenda . i 've no desire to make it up , but if no one 's told me things , then i 'm just proceeding from my guesses , and and i ye i 'm it ended up with your out your time to i 'm just always asking jose what he 's doing , and it 's there 's there 's other things going on . what ar how are they gonna do any of this ? they 're gonna say speaker one , or speaker two or speaker it may just be one long transcript of a bunch of words . yu ching , yu ching . and it may very be since they 're not going to sit there and worry ab about , it being the same speaker , they may very go the the first se the first time it changes to another speaker , that 'll be speaker two . and the next time it 'll be speaker three even if it 's actually speaker one .   but that you do .  if someone says , "" what is jose doing ? "" and then jose says something , you need to know that was jose responding .  "" is who up in where ? "" right ? use the   th bec suppose someone says , "" don't know if i really heard what what jose said . "" and then , jose responds . and part of your learning about the dialogue is jose responding to it . but it doesn't say "" jose "" , it says "" speaker five "" .  right . and if we pass out the data to someone else , and it says "" speaker five "" there , we also have to pass them this little guide that says that speaker five is jose , and if were gonna do that we might as give them "" jose "" say it was "" jose "" .  i agree . i agree with jane . that we have a need to have a consistent licensing policy of some sort , and  she no , but she 's saying , from the argument before , she wants to be able to say if someone said "" jose "" in their thing , and then connect to to what he said later , then you need it . see . i see . and th and the other thing is if liz were here , what she might say is that she wants to look if things that cut across between the audio and the dialogue , and    a lot of these things are . we should only have meetings between people who don't know one another and who are also amnesiacs who don't know their own name . that 's there 's an easy way to do that . jus just play it all backwards . what , what does the speech recognizer care ?  let 's do digits . we already missed the party .  ","that we have a need to have a consistent licensing policy of some sort , and and th and the other thing is if liz were here , what she might say is that she wants to look if things that cut across between the audio and the dialogue , ",
Bmr006.E,"there we go . this looks good . was it a pause , or ?  was it on "" pause ""  don't know .   can i say about that the issues that adam and i raised were more a matter of advertising that you get more native speakers . because if you just say an and in particular , my suggestion was to advertise to linguistics grad students because there you 'd have people who 'd have proficiency enough in english that it would be useful for purposes but 've been i 've gathered data from undergrads at on campus and if you just post randomly to undergrads you 'd get such a mixed bag that it would be hard to know how much conversation you 'd have and the english you 'd have the language models would be really hard to build because it would not really be it would be an interlanguage rather than a   interesting ! i see . interesting ! i 'm not saying accents . u the accent 's not the problem . no , it 's more a matter of proficiency , e just simply fluency . i deal with people on campus who sometimes people , undergraduates in computer science have language skills that make , that their fluency and writing skills are not strong . e think , but it 's like when you get into the graduate level , no problem . i 'm not saying accents . i 'm say i 'm saying fluency .  i 'm just saying fluency . now can i say the other aspect of this from my perspective which is that there 's this issue , you have a corpus out there , it should be used for multiple things cuz it 's expensive to put together . and if people want to approach  i know e this the idea of computational linguistics and probabilistic grammars and all may not be the focus of this group , but the idea of language models , which are fund generally speaking t terms of like the amount of benefit per dollar spent or an hour invested in preparing the data , if you have a choice between people who are pr more proficient in i more fluent , more close to being academic english , then it would seem to me to be a good thing . because otherwise y you don't have the ability to have if you have a bunch of idiolects that 's the worst possible case . if you have people who are using english as a as an interlanguage because they don't they can't speak in their native languages and but their interlanguage isn't really a match to any existing , language model , this is the worst case scenario . and   but that these people are of high enough level in their language proficiency that and i 'm not objecting to accents . i 'm just thinking that we have to think at a higher level view , could we have a language model , a grammar a grammar , that wo would be a possibility . if you wanted to bring in a model like dan jurafsky 's model , an and do some top down it to help th the bottom up and merge the things or whatever , it seems like i don't see that there 's an argument i 'm i what is that why not have the corpus , since it 's expensive to put together , useful for the widest range of central corp things that people generally use corpora for and which are , used in computational linguistics . that 's my point . which includes both top down and bottom up . yes , that 's fine . that 's fine . exactly . and my point in m in my note to liz was that undergrads are an iff iffy population . grads and professors , fine . age ist . that 's true . which one did   the free lunch idea was a great idea .   alth  i hav i have to raise a little eensy weensy concern about doing th giving them the cd immediately , because of these issues of , this where  we could burn it after it 's been cleared with the transcript stage . and then they get a cd , but just not the same day . there we go . i like that . put . put . after the transcript screening phase . things have been weeded out . that 's right , say "" i got this cd , and , your honor , i "" the archiving m program does take a long time . one thing the good news about that is that once it 's archived , it 's pretty quick to get back . it the other direction is fast , but this direction is really slow .  that 's a good point .  now , what will is the plan to g to will be saved , it 's just that you 're relocating it ? we 're gonna get more disk space ? or did i ?  good . i see .    wonderful .  i 'm glad to hear it . glad to hear it .    duration . which means that we 'd still you 'd hear the that 's interesting . this is like a ground level , with it 's not total silence .  great . great . excellent . glad to hear it . good . i 've gotta ask you . the difference between the top two , i start at the bottom , silence "" is clear . by "" speech "" do speech by one sp by one person only ? this is un and then the top includes people speaking at the same time , or a speaker and a breath overlapping , someone else 's breath , or clicking , overlapping with speech that 's all those possibilities in the top one .  ","if you have people who are using english as a as an interlanguage because they don't they can't speak in their native languages and but their interlanguage isn't really a match to any existing , language model , and i 'm not objecting to accents . i 'm i what is that why not have the corpus , since it 's expensive to put together , useful for the widest range of central corp things that people generally use corpora for and which are , used in computational linguistics . and my point in m in my note to liz was that undergrads are an iff iffy population . we could burn it after it 's been cleared with the transcript stage . after the transcript screening phase . ",
Bmr006.E,"it 's basi it 's speech wi som with something overlapping , which could be speech but doesn't need to be . that 's right . that 's my question .  like a c  you don't i it 's not in that you 're ignoring overlapping events unless they 're speech with speech .  we 're just  cuz you 've talked about other overlapping events in the past . this is a subset .   we just wanted to the category was here . it 's like a signal noise situation .  steady state . we needed to get the categories ,   can i ask ? it strikes me that there 's another piece of information that might be useful and that 's simply the transition . w if you go from a transition of silence to overlap versus a transition from silence to speech , there 's gonna be a b a big informative area there , it seems to me .   clustering .     interesting .  with what ? with what ? "" mixed "" . it 's messier . the pda is messier . that 's good . there is a complication though , and that is if a person turns their back to the pda , then some of the positional information goes away ? and then , and if they 're on the access on the axis of it , that was the other thing i was thinking . he you mentioned this last time , that if you 're straight down the midline , then the r the left right 's gonna be different , and in his case , he 's closer to it anyway . it seems to me that it 's not a p it 's this the topograph the topology of it is a little bit complicated . agree ! and we use it ourselves . i i know that 's a very important cue . but i 'm just saying that the way we 're seated around a table , is not the same with respect to each person with respect to the pda , we 're gonna have a lot of differences with ref respect to the speaker .  it just seemed to me that that this isn't the ideal type of separation . it 's see the value o    his a web page .  let me ask you , if both people were over there , it would be less effective than if one was there and one was across , catty corner ? no ? next one over n over on this side of the p pda . there we go . good example , the same one i 'm asking . versus and we 're catty corner across the table , and i 'm farther away from this one and you 're farther away from that one . it seems like that would be pretty strong . across the same axis , you don't have as much to differentiate . and my point was just that it 's gonna be differentially varia valuable . it 's not to say i certainly think it 's extremely val and we humans n depend on these binaural cues . but . yes .  and i and if there it and if it 's the two of you guys on the same side    'm not trying to argue against using it , by any means . wanted to point out that weakness , that it 's topo topologically impossible to get it perfect for everybody . great . no , i don't mean to discourage that interesting . interesting . interesting . interesting . interesting .   you could have strips that you stick to your clothing . it 's slightly different . would say it would be a good idea . cuz it 's slightly different . it 's slightly different . i had to make one should have some results to present , but guess we won't have time to do that this time . but it seems like the anonymization is is also something that we might wanna discuss in greater length . if we 're about to wind down , what i would prefer is that we delay the anonymization thing till next week , and i would like to present the results that i have on the overlaps . i 'd i 'd prefer to have more time for my results . e could i do that next week that 's what i 'm asking . and the anonymization , if y if you want to proceed with that now , think that 's a discussion which also n really deserves a lo a more that just a minute . i really do think that , because you raised a couple of possibilities yourself , you and i have discussed it previously , and there are different ways that people approach it , e and we should  it 's just i 'll give you the short version , but i do think it 's an issue that we can't resolve in five minutes . the short thing is we have tape recording digitized recor recordings . those we won't be able to change . if someone says "" hey , roger and . that 's gonna stay that person 's name . now , in terms of like the transcript , the question becomes what symbol are you gonna put in there for everybody 's name , and whether you 're gonna put it in the text where he says "" hey roger "" or are we gonna put that person 's anonymized name in instead ? first decision is , we 're gonna anonymize the same name for the speaker identifier and also in the text whenever the speaker 's name is mentioned . i don't think you understood what i said . in within the context of an utterance , someone says "" roger , what do you think ? ""  ","you 're ignoring overlapping events unless they 're speech with speech . the question becomes what symbol are you gonna put in there for everybody 's name , and whether you 're gonna put it in the text where he says "" hey roger "" or are we gonna put that person 's anonymized name in instead ? ","And, finally, the problem of speaker anonymization was explored. "
Bmr006.E,"then , it seems to me that it seems to me that if you change the name , the transcript 's gonna disagree with the audio , and you won't be able to use that . but then there 's this issue of if we 're gonna use this for a discourse type of thing , then and , liz was mentioning in a previous meeting about gaze direction and who 's the addressee and all , then to have "" roger "" be the thing in the utterance and then actually have the speaker identifier who was "" roger "" be "" frank "" , that 's going to be really confusing and make it useless for discourse analysis . now , if you want to , in some cases , i know that susan ervin tripp in some of hers , actually did do a filter of the s signal where the person 's name was mentioned , except and i cer and i the question then becomes one level back . how important is it for a person to be identified by first name versus full name ? on the one hand , it 's not a full identity , we 're taking all these precautions , and they 'll be taking precautions , which are probably even the more important ones , to they 'll be reviewing the transcripts , to see if there 's something they don't like that 's enough protection . on the other hand , this is a small pool , and people who say things about topic x e who are researchers and known in the field , they 'll be identifiable and simply from the first name . however , taking one step further back , they 'd be identifiable anyway , even if we changed all the names . is it really , now , in terms of like did some results , which i 'll report on n next time , which do mention individual speakers by name . now , there , the human subjects committee is very precise . you don't wanna mention subjects by name in published reports . now , it would be very possible for me to take those data put them in a study , and just change everybody 's name for the purpose of the publication . and someone who looked exactly . doesn't matter if that 's the same thing you saw . and in the form that they sign , it does say "" your first name may arise in the course of the meetings "" . or "" your name "" . and even more i immediate than that just being able to , it just seems like to track from one utterance to the next utterance who 's speaking and who 's speaking to whom , cuz that can be important . s i "" you raised the point , and , it 's be to be able to know who "" you "" was . and ac and actually you remember furthermore , you remember last time we had this discussion of how i was avoiding mentioning people 's names , and it was and we made the decision that was artificial . if we 're going to step in after the fact and change people 's names in the transcript , we 've done something one step worse . misleading .   it 's not a problem . couldn't do it in two minutes . how do who what they 're who they 're talking about ? how do they won't be able to change it themselves . i 'm betting we 're gonna have huge chunks that are just un untranscribable by them . that my understanding from yen is it yen ching ? is that how you pronounce her name ? yu ching ? yu ching ? was that they will that they will adopt the part of the conventions that we discussed , where they put speaker identifier down . but , h they won't know these people , think it 's they 'll adopt some convention but we haven't specified to them they 'll do something like speaker one , speaker two , is what i bet , but i 'm betting there 'll be huge variations in the accuracy of their labeling the speakers . we 'll have to review the transcripts in any case .    that would be a very practical solution on their part . and but then we would need to label it . and that 's yes , i was thinking , the temp the time values of when it changes . that 'd be very efficient .  unless we adopt a different set of norms which is to not id to make a point of not identifying people by name , which then leads you to be more contextually ex explicit . people are very flexible . when we did this las last week , i felt that now , andreas may , @ @ he i sometimes people think of something else at the same time and they miss a sentence and because he missed something , then he missed the r the initial introduction of who we were talking about , and was unable to do the tracking . but i felt like most of us were doing the tracking and knew who we were talking about and we just weren't mentioning the name . people are really flexible .  it   that 's the issue .     now , that we have these two phases in the data , which is the one which is o our use , university of washington 's use , ibm , sri . and within that , it may be that it 's sufficient to not change the to not incorporate anonymization yet , but always , always in the publications we have to . and also , when we take it that next step and distribute it to the world , we have to . ","then , it seems to me that it seems to me that if you change the name , the transcript 's gonna disagree with the audio , and you won't be able to use that . but then there 's this issue of if we 're gonna use this for a discourse type of thing , then and , liz was mentioning in a previous meeting about gaze direction and who 's the addressee and all , then to have "" roger "" be the thing in the utterance and then actually have the speaker identifier who was "" roger "" be "" frank "" , that 's going to be really confusing and make it useless for discourse analysis . how important is it for a person to be identified by first name versus full name ? on the other hand , this is a small pool , and people who say things about topic x e who are researchers and known in the field , they 'll be identifiable and simply from the first name . however , taking one step further back , they 'd be identifiable anyway , even if we changed all the names . now , it would be very possible for me to take those data put them in a study , and just change everybody 's name for the purpose of the publication . and even more i immediate than that just being able to , it just seems like to track from one utterance to the next utterance who 's speaking and who 's speaking to whom , cuz that can be important . and within that , it may be that it 's sufficient to not change the to not incorporate anonymization yet , but always , always in the publications we have to . ","And, finally, the problem of speaker anonymization was explored. "
Bmr006.E,"but i don that 's a long way from now and it 's a matter of between now and then of d of deciding how i it it may be s that we 'll need to do something like actually x out that part of the the audio , and just put in brackets "" speaker one "" .   that 's risky . that the public should be the same . that when we do that world release , it should be the same . for a bunch of reasons , legal . but i also think a consistent licensing policy is important . excuse me . we do need audio for discourse . but i also wanna say that people  that 's good . you see ? it 's complicated .  we have to think about w @ @ how . that this can't be decided today . but it 's g but it was good to introduce the thing and we can do it next time . it discourse , also i wanted to make the point that discourse is gonna be more than just looking at a transcript . it 's gonna be looking at a t and prosod prosodic is involved , and that means you 're going to be listening to the audio , and then you come directly into this confronting this problem .  we should just market it to non english speaking countries . we could have little labels . i wanna introduce my reservoir dogs solution again , which is everyone has like "" mister white "" , "" mister pink "" , "" mister blue "" . do we do digits ? or ? what do we do ? or do we just quit ?  in the one i transcribed , i did find a couple instances i found one instance of contrastive stress , where it was like the string had a li it was like "" nine eight two four , nine two four "" . and they differed . at that session i did feel like they did it more as sentences . but , sometimes people do it as phone numbers . i 've i am interested in and sometimes , i s and i never know . when i do it , i ask myself what i 'm doing each time . and i i like your question intonation . that 's very funny . i haven't heard that one . ",you see ? it 's complicated . we have to think about w @ @ how . that this can't be decided today . ,
Bmr006.F,"that 's looks strange . i 'll back up . at the previous at last week 's meeting , this meeting i was griping about wanting to get more data and i talked about this with jane and adam , and was thinking of this mostly just that we could do research on this data since we 'll have a new this new student di does wanna work with us , th the guy that was at the last meeting . and he 's already funded part time , we 'll only be paying him for for half of the normal part time ,   he 's comes from a signal processing background , but i liked him a lot cuz he 's very interested in higher level things , like language , and disfluencies and all kinds of eb prosody , he 's just getting his feet wet in that . anyway , we should have enough data that if he starts he 'd be starting in january , next semester that we 'd have , enough data to work with . but , jane and adam brought up a lot of good points that just posting a note to berkeley people to have them come down here has some problems in that you m you need to make that the speakers are who you want and that the meeting type is what you want , and forth . about that and it 's still possible , but i 'd rather try to get more regular meetings of types that we know about , and hear , then mish mosh of a bunch of one time just because it would be very hard to process the data in all senses , both to get the , to figure out what type of meeting it is and to do any higher level work on it , like i was talking to morgan about things like summarization , or what 's this meeting about . it 's very different if you have a group that 's just giving a report on what they did that week , versus coming to a decision and forth . then i was talking to morgan about some new proposed work in this area , separate issue from what the student would be working on where i was thinking of doing some summarization of meetings or trying to find cues in both the utterances and in the utterance patterns , like in numbers of overlaps and amount of speech , raw cues from the interaction that can be measured from the signals and from the diff different microphones that point to hot spots in the meeting , or things where is going on that might be important for someone who didn't attend to listen to . and in that regard , we definitely w will need it 'd b it 'd be for us to have a bunch of data from a few different domains , or a few different kinds of meetings . this meeting is one of them , although i 'm not can participate if i i would feel very strange being part of a meeting that you were then analysing later for things like summarization . and then there are some others that menti that morgan mentioned , like the front end meeting and networking group meeting . if that were the case then we 'd have enough . but for anything where you 're trying to get a summarization of some meeting meaning out of the meeting , it would be too hard to have fifty different kinds of meetings where we didn't really have a good grasp on what does it mean to summarize , but rather we should have different meetings by the same group but hopefully that have different summaries . and then we need a couple that of we don't wanna just have one group because that might be specific to that particular group , but @ @ three or four different kinds . see , i 've never listened to the data for the front end meeting .  but that 's enough . in general , i was thinking more data but also data where we hold some parameters constant or fairly similar , like a meeting about of people doing a certain work where at least half the participants each time are the same . right . right . right . i definitely agree with that . definitely . it has to be a pre existing meeting , like a meeting that would otherwise happen anyway . that 's what we and i agree with . i definitely agree with that , for this purpose . right , i have a question . morgan , you were mentioning that mari may not use the k equipment from ibm if they found something else , cuz there 's a cuz one remote possibility is that if we st if we inherited that equipment , if she weren't using it , could we set up a room in the linguistics department ? and there may be a lot more or in psych , or in comp wherever , in another building where we could record people there . we 'd have a better chance right , but right . but if there were such a it 's a remote possibility , then one of us could go up there and record the meeting rather than bring all of them down here . it 's just a thought if they end up not using the hardware . but you may not need a separate room , the idea is , if they have a meeting room and they can guarantee that the equipment will be safe and forth , and if one of us is up there once a week to record the meeting  it 's not out of the question .   right . right . right , i c there 's yea you actually don't really even need any fancy microphone . you can use found data . you can . ","and was thinking of this mostly just that we could do research on this data since we 'll have a new this new student di does wanna work with us , he 's comes from a signal processing background , cuz he 's very interested in higher level things , like language , and disfluencies and all kinds of eb prosody , but i 'd rather try to get more regular meetings of types that we know about , and hear , then mish mosh of a bunch of one time then i was talking to morgan about some new proposed work in this area , separate issue from what the student would be working on where i was thinking of doing some summarization of meetings or trying to find cues in both the utterances and in the utterance patterns , like in numbers of overlaps and amount of speech , raw cues from the interaction that can be measured from the signals and from the diff different microphones that point to hot spots in the meeting , or things where is going on that might be important for someone who didn't attend to listen to . and in that regard , we definitely w will need it 'd b it 'd be for us to have a bunch of data from a few different domains , or a few different kinds of meetings . like the front end meeting and networking group meeting . if that were the case then we 'd have enough . but rather we should have different meetings by the same group but hopefully that have different summaries . but also data where we hold some parameters constant or fairly similar , like a meeting about of people doing a certain work where at least half the participants each time are the same . it has to be a pre existing meeting , like a meeting that would otherwise happen anyway . morgan , you were mentioning that mari may not use the k equipment from ibm if they found something else , cuz there 's a cuz one remote possibility is that if we st if we inherited that equipment , if she weren't using it , could we set up a room in the linguistics department ? and there may be a lot more or in psych , or in comp wherever , in another building where we could record people there . ","The Berkeley Meeting Recorder group discussed research aims and corresponding concerns for future data collection. It was agreed that a substantial amount of meeting data is required from different domains, and comprising several speakers, to perform the types of discourse and acoustic analyses desired. "
Bmr006.F,"you can use but that any data that we spend a lot of effort to collect , each person who 's interested in we have a cou we have a bunch of different , slants and perspectives on what it 's useful for , they need to be taking charge of making they 're getting enough of the data that they want . and in my case , there w there is enough data for some kinds of projects and not enough for others . and 'm looking and thinking , "" 'd be glad to walk over and record people and forth if it 's to help th in my interest . "" and other people need to do that for themselves , h or at least discuss it that we can find some optimal right . i agree with jane , though , on the other hand that that might be true , you may say summarization , that sounds very language oriented . you may say "" you just do that from transcripts of a radio show . "" you don't even need the speech signal . but what you what i was thinking is long term what would be neat is to be able to pick up on suppose you just had a distant microphone there and you really wanted to be able to determine this . there 's lots of cues you 're not gonna have . do think that long term you should always try to satisfy the greatest number of interests and have this parallel information , which is really what makes this corpus powerful . otherwise , lots of other sites can propose individual studies ,  then we should try to bring people here . that 's that 's   right . i and we can get people to come here , that but the issue is you definitely wanna make that the group you 're getting is the right group that you don't waste a lot of your time and the overhead in bringing people down . it would be lunch afterwards . right . and they 'd have to do their digits or they don't get dessert .  definitely ,   i 'd love to get people that are not linguists or engineers , cuz these are both weird i know , i shouldn't say that . we need a wider sampling . that was he meant , "" give them a music cd , "" like they g then he said a cd of the of their speech and it depends of what audience you 're talking to , but i personally would not want a cd of my meeting , but you 're right . right . right . right . right . no , that 's a great idea , actually . but we might need a little more to incentivize them , that 's all . that 's interesting . right . if it should be the same cd rom that we distribute publically , right ? otherwise they 're not allowed to play it for anyone . otherwise we 'd need two lawyer stages . that 's a good point . to have to have to leave . i will be here full time next week . ","each person who 's interested in we have a cou we have a bunch of different , slants and perspectives on what it 's useful for , they need to be taking charge of making they 're getting enough of the data that they want . and in my case , there w there is enough data for some kinds of projects and not enough for others . and other people need to do that for themselves , h or at least discuss it that we can find some optimal do think that long term you should always try to satisfy the greatest number of interests and have this parallel information , which is really what makes this corpus powerful . but the issue is you definitely wanna make that the group you 're getting is the right group definitely , i 'd love to get people that are not linguists or engineers , cuz these are both weird ","It was agreed that a substantial amount of meeting data is required from different domains, and comprising several speakers, to perform the types of discourse and acoustic analyses desired. "
Bmr007.A," that is really great . that 's terrific . now you won't be able to walk or ride your bike , a list that you have to send off to who ?  what about the , your trip , yesterday ?  same idea ?  but the numbers speak for themselves . it 'd be interesting but it w it 'd be interesting to see what the total amount of time is in the overlaps , versus     here i have a question . what  in the two person in the two person conversations , when there 's backchannel , is there a great deal of overlap in the speech ? or cuz my impression is sometimes it happens when there 's a pause , like you get a lot of backchannel , when somebody 's pausing it 's hard to do both ,  no , when there 's backchannel , just i was just listening , and when there 's two people talking and there 's backchannel it seems like , the backchannel happens when , the pitch drops and the first person and a lot of times , the first person actually stops talking and then there 's a backchannel and then they start up again , and 'm wondering about h wonder how much overlap there is . is there a lot ?   but just a small overlap ? i was just thinking more in terms of alignment , alignment overlap . hostile takeovers . i wonder what determines who gets the floor ?  why do we want to have a picture of the meeting ? we can't you figure it out from the mike number ?   where you could get it ? beam forming during the digit just remembered a joke . how big their heads are . he how did you do it adam ?  wh what was the   every frame that 's over what threshold ? in terms of energy ?   did you ever try running the filter before you pick a threshold ? who was it trained on ?  he 's saying the onset detector . "" mixed "" . you have candidates . to make marking easier .  but he 's not gonna even read that .  actually , i saw a woman at the bus stop the other day who , was talking on her cell phone speaking japanese , and was bowing . profusely . just , kept i 'll be peeking . technical it 's too complicated . no , no . you can you could make a m as long as you keep using the same beep , people could make a model of that beep , and  it 's more obvious that there was something there than if there 's just silence . yea right . right . but if you just replaced it with silence , it 's not clear whether that 's really silence or they 're easy to find , then . actually that 's what you were giving us was another meeting and i was like , "" "" but it has to be hand labeled first ? that 'd be interesting .   it 's too late now . ","it 'd be interesting to see what the total amount of time is in the overlaps , versus no , when there 's backchannel , just i was just listening , and when there 's two people talking and there 's backchannel it seems like , the backchannel happens when , the pitch drops and the first person ",
Bmr007.B,"we 're , we didn't have a house before .  right . the new consent form .  exactly !   that 's good , cuz the overall rate is  but ,  what 's really interesting though , it is before d saying "" yes , meetings have a lot of overlaps "" is to actually find out how many more we have than two party . cuz in two party conversations , like switchboard , there 's an awful lot too if you just look at backchannels , if you consider those overlaps ? it 's also ver it 's huge . it 's just that people haven't been looking at that because they 've been doing single channel processing for speech recognition . the question is , how many more overlaps do you have of , say the two person type , by adding more people . to a meeting , and it may be a lot more but i it may not be .   it 's not really "" . it depends what you 're doing . if you were actually having ,  depends what you 're doing , if right now we 're do we have individual mikes on the people in this meeting . the question is , are there really more overlaps happening than there would be in a two person party "" . and there may be , but i agree that it 's an issue here but it 's also an issue for switchboard and if you think of meetings being recorded over the telephone , which this whole point of studying meetings isn't just to have people in a room but to also have meetings over different phone lines . far field mike people wouldn't be interested in that but all the dialogue issues still apply , if each of us was calling and having a meeting that way you kn like a conference call . and , just the question is , y in switchboard you would think that 's the simplest case of a meeting of more than one person , and i 'm wondering how much more overlap of the types that jane described happen with more people present . it may be that having three people is very different from having two people or it may not be .  not you , me . but but there 's actually to tell you the truth , the reason why it 's hard to measure is because of from the point of view of studying dialogue , which dan jurafsky and andreas and i had some projects on , you want to know the sequence of turns . what happens is if you 're talking and i have a backchannel in the middle of your turn , and then you keep going what it looks like in a dialogue model is your turn and then my backchannel , even though my backchannel occurred completely inside your turn . for things like language modeling or dialogue modeling it 's we know that 's wrong in real time . but , because of the acoustic segmentations that were done and the fact that some of the acoustic data in switchboard were missing , people couldn't study it , but that doesn't mean in the real world that people don't talk that way . it 's we 've als right . we 're looking at it here .  all i meant is that if you 're asking the question from the point of view of what 's different about a meeting , studying meetings of , say , more than two people versus what kinds of questions you could ask with a two person meeting . it 's important to distinguish that , this project is getting a lot of overlap but other projects were too , but we just couldn't study them . and there is a high rate ,  it 's but i don't know how high , that would be interesting to know .  i don't di i agree with that . right . that 's also true of switchboard . it may not be right . it 's just ,  all i 'm saying is that from the right . no , i agree with that . i 'm just saying that it may the reason you get overlaps may or may not be due to the number of people in the meeting . and that 's all . and it would actually be interesting to find out because some of the data say switchboard , which isn't exactly the same context , these are two people who don't know each other and forth , but we should still be able to somehow say what is the added contra contribution to overlap time of each additional person , like that . but right . right . right . if you can see them , actually . it 's interesting , if you watch people are going like right , like this here , but that may not be the case if you couldn't see them .  there 's a lot of head nodding , in this yes .  yes . right . what were you saying ?  there 's a lot of the kind that jose was talking about , where this is called "" precision timing "" in conversation analysis , where they come in overlapping , but at a point where the information is mostly complete . all you 're missing is some last syllables or the last word or some highly predictable words . technically , it 's an overlap . but from information flow point of view it 's not an overlap in the predictable information .  that 's exactly , exactly why we wanted to study the precise timing of overlaps ins in switchboard , say , because there 's a lot of that .  i was thinking you should be able to do this from the acoustics , on the close talking mikes , right ? right , adam was right . ","the question is , how many more overlaps do you have of , say the two person type , by adding more people . to a meeting , i agree that it 's an issue here but it 's also an issue for switchboard it may be that having three people is very different from having two people or it may not be . from the point of view of studying dialogue , which dan jurafsky and andreas and i had some projects on , you want to know the sequence of turns . what happens is if you 're talking and i have a backchannel in the middle of your turn , and then you keep going what it looks like in a dialogue model is your turn and then my backchannel , even though my backchannel occurred completely inside your turn . for things like language modeling or dialogue modeling it 's we know that 's wrong in real time . but , because of the acoustic segmentations that were done and the fact that some of the acoustic data in switchboard were missing , people couldn't study it , it 's important to distinguish that , this project is getting a lot of overlap but other projects were too , but we just couldn't study them . but we should still be able to somehow say what is the added contra contribution to overlap time of each additional person , like that . there 's a lot of the kind that jose was talking about , where this is called "" precision timing "" in conversation analysis , where they come in overlapping , but at a point where the information is mostly complete . all you 're missing is some last syllables or the last word or some highly predictable words . technically , it 's an overlap . but from information flow point of view it 's not an overlap in the predictable information . that 's exactly , exactly why we wanted to study the precise timing of overlaps ins in switchboard , i was thinking you should be able to do this from the acoustics , on the close talking mikes , ",Efforts by speakers fe008 and fe016 are in progress to categorize and subcategorize types of overlapping speech and evaluate the contribution of multiple speakers in an interaction to the amount and types of overlap observed. 
Bmr007.B,"not as as what you wouldn't be able to have any typology , but you 'd get some rough statistics .  my first comment was , only that we should n not attribute overlaps only to meetings , but that 's obvious , everybody knew that , but that in normal conversation with two people there 's an awful lot of the same kinds of overlap , and that it would be interesting to look at whether there are these kinds of constraints that jane mentioned , that what the additional people add to this competition that happens right after a turn , because now you can have five people trying to grab the turn , but pretty quickly there 're they back off and you go back to this only one person at a time with one person interrupting at a time . i don't know . to answer your question i it i don't think it 's crucial to have controls but it 's worth recording all the meetings we can .  d i wouldn't not record a two person meeting just because it only has two people . can we actually record ? physically can we record the o the other that 's what they did on map task , this map task corpus ? they ran exactly the same pairs of people with and without visual cues and it 's quite interesting . we could just put b blindfolds on . and we 'd take a picture of everybody sitting here with blindfolds . that would ee transc no but probably from these you could 've infer it . it would be a research task .  but you have to keep the chairs in the same pla like here . the fashion statement . but does it work for that one speaker throughout the whole meeting ? that 'd be really interesting too , with blindfolds . then  the question is , like whether trying with and without , but then there 's just one @ @ , like . that 's really common . it 's very difficult if you try while you 're trying , say , to convince somebody on the phone it 's difficult not to move your hands . not if you watch people they 'll actually do these things .  i still think we should try a meeting or two with the blindfolds , at least of this meeting that we have lots of recordings of for part of the meeting , we don't have to do it the whole meeting . that could be fun . it 'll be too hard to make barriers , i was thinking because they have to go all the way see chuck even if you put a barrier here . y but then we also have these mikes , is the other thing i was thinking , we need a barrier that doesn't disturb the sound ,  it sounds weird but it 's cheap and , be interesting to have the camera going . the beep is a really good idea . also notice how quiet i am . you have some people who only have beeps as their speech in these meetings . definitely . guess if there 's an overlap if i 'm saying something that 's bleepable and somebody else overlaps during it they also get bleeped , too ? and , i wanted to say , this is really interesting analysis . i meant to say that before i started off on the switchboard it 's neat .  does it take how long does it take , just briefly , like t to to label the ,   it 's really neat . wear it , if you  i feel like this troublemaker .  i 'm ","my first comment was , only that we should n not attribute overlaps only to meetings , but that in normal conversation with two people there 's an awful lot of the same kinds of overlap , and that it would be interesting to look at whether there are these kinds of constraints that jane mentioned , that what the additional people add to this competition that happens right after a turn , to answer your question i it i don't think it 's crucial to have controls but it 's worth recording all the meetings we can . it 'll be too hard to make barriers , i was thinking because they have to go all the way we need a barrier that doesn't disturb the sound , ",Efforts by speakers fe008 and fe016 are in progress to categorize and subcategorize types of overlapping speech and evaluate the contribution of multiple speakers in an interaction to the amount and types of overlap observed. 
Bmr007.C,"          what is what not really . i didn't get it . wh what is "" audio pixelization "" ?  i got that .  and you can say       ","wh what is "" audio pixelization "" ? ",
Bmr007.D,"  we 're on again ?     we were gonna do that at the end , remember ?  just to be consistent , from here on in at least , that we 'll do it at the end .  it ju it might be that someone here has to go , and right ? that was the point . had asked actually anybody who had any ideas for an agenda to send it to me and no one did .   right , s one item for an agenda is jane has some some research to talk about , research issues . and adam has some short research issues . i have a list of things that were done over the last three months i was supposed to send off , and , sent a note about it to to adam and jane but 'll just run through it also and see if someone thinks it 's inaccurate or insufficient . to ibm .  they 're ,  i 'll go through that . and , anything else ? anyone wants to talk about ? no .   off topic cuz that 's cuz that was all about the , chat with you about that off line . that 's another thing . and , anything else ? nothing else ? there 's a there is a , telephone call tomorrow , which will be a conference call that some of us are involved in for possible proposal . we 'll talk about it next week if something we 'll talk about that after our meeting .   it sounds like the three main things that we have to talk about are , this list , jane and adam have some research items , and , other than that , anything , as usual , anything goes beyond that . jane , since you were cut off last time why don't we start with yours , make we get to it . what was what 's the parenthesized that says , like e the first one that says six overlaps and then two point eight ?   s i it would be statistically incorrect to conclude from this that adam talked too much   excuse me . b i rather enjoyed it , but this     th the biggest , result here , which is one we 've talked about many times and isn't new to us , but which would be interesting to show someone who isn't familiar with this is just the sheer number of overlaps . that right ? that , here 's a relatively short meeting , it 's a forty plus minute meeting , and not only were there two hundred and fifteen overlaps but , think there 's one minute there where there wasn't any overlap ? it 's throughout this thing ? it 's you have the bottom three did have s going on ? there was speech ? if the this about how much is it ? o what 's the what 's the average length ? you don't know ? you don you don't have a feeling for roughly how much it is ?   i 'm    but i 'd u go ahead . i i i 'm i 'm confused now . let me restate what andreas was saying and see . let 's say that in second fifty seven of one minute , you start talking and i start talking and we ignore each other and keep on talking for six seconds . we go over we were talking over one another , and it 's just in each case , it 's just one interval . right ? we talked over the minute boundary . is this considered as one overlap in each of the minutes , the way you have done this . that 's good , in the sense that andreas meant the question , right ?     but see , i find it interesting even if it wasn't any more , because since we were dealing with this full duplex thing in switchboard where it was just all separated out we just everything was just that the issue is in a situation where th that 's  let m let me rephrase what i 'm saying cuz i don't 'm getting it across . what i shouldn't use words like "" because that 's too i too imprecise . but what is that , in switchboard , despite the many other problems that we have , one problem that we 're not considering is overlap . and what we 're doing now is , aside from the many other differences in the task , we are considering overlap and one of the reasons that we 're considering it , one of them not all of them , one of them is that w at least , 'm very interested in the scenario in which , both people talking are equally audible , and from a single microphone . and in that case , it does get mixed in , and it 's pretty hard to jus to just ignore it , to just do processing on one and not on the other .    that 's an important question to ask . what i 'm all i 'm s really saying is that i don't think we were considering that in switchboard . were you ? were you were you measuring it ? w were     i wasn't saying that . right ? i was just saying that w now we 're looking at it . and and , you wanted to look at it before but , for these various technical reasons in terms of how the data was you weren't . that 's why it 's coming to us as new even though it may be if your hypothes the hypothesis you were offering right ? if it 's the null poth hypothesis , and if actually you have as much overlap in a two person , we don't know the answer to that . ","th the biggest , result here , which is one we 've talked about many times and isn't new to us , but which would be interesting to show someone who isn't familiar with this is just the sheer number of overlaps . here 's a relatively short meeting , it 's a forty plus minute meeting , and not only were there two hundred and fifteen overlaps but , think there 's one minute there where there wasn't any overlap ? we talked over the minute boundary . is this considered as one overlap in each of the minutes , the way you have done this . but what is that , in switchboard , despite the many other problems that we have , one problem that we 're not considering is overlap . and what we 're doing now is , aside from the many other differences in the task , we are considering overlap and one of the reasons that we 're considering it , one of them not all of them , one of them is that w at least , 'm very interested in the scenario in which , both people talking are equally audible , and from a single microphone . and in that case , it does get mixed in , and it 's pretty hard to jus to just ignore it , to just do processing on one and not on the other . ","Speaker fe008 presented raw counts and percentages for one transcribed meeting, revealing a large number of overlaps throughout the 40-plus-minute transcript. The Berkeley Meeting Recorder group focussed its discussion on overlapping speech segments. "
Bmr007.D,"the reason we don't know the answer to is cuz it wasn't studied and it wasn't studied because it wasn't set up . right ?  may have been . may have been . right ? we do kn we don't know the numbers . see , i le let me t my point was just if you wanted to say to somebody , "" what have we learned about overlaps here ? "" just never mind comparison with something else , what we 've learned about is overlaps in this situation , is that the first order thing i would say is that there 's a lot of them . right ? in the sense that i if you said if i in a way , what i 'm comparing to is more the common sense notion of how much people overlap . the fact that when , adam was looking for a stretch of speech before , that didn't have any overlaps , and he w he was having such a hard time and now i look at this and i go , "" see why he was having such a hard time "" . it 's happening a lot . i wasn't saying it wasn't . right ? i was commenting about this . i 'm saying if i have this complicated thing in front of me , and we sh which , we 're gonna get much more sophisticated about when we get lots more data , but then , if i was gonna describe to somebody what did you learn right here , about , the modest amount of data that was analyzed i 'd say , "" the first order thing was there was a lot of overlaps "" . and it 's not just an overlap bunch of overlaps second order thing is it 's not just a bunch of overlaps in one particular point , but that there 's overlaps , throughout the thing . and that 's interesting . that 's all .   i wasn't making any statement about that .  that would be good to know , but w we   u actually , 've done it a fair number of times today . but .    i have a feeling most of these things are that are not a benevolent kind are , are competitive as opposed to real really hostile . but . vote in florida .  o one thing i wanted to or you can tell a good joke and then everybody 's laughing and you get a chance to g break in . but . but .  the other thing i was thinking was that , these all these interesting questions are , pretty hard to answer with , a small amount of data . wonder if what you 're saying suggests that we should make a conscious attempt to have , fair number of meetings with , smaller number of people . right ? we most of our meetings are meetings currently with say five , six , seven , eight people should we really try to have some two person meetings , or some three person meetings and re record them just to beef up the statistics on that ? liz was raising the question of whether i it 's the number there 's a relationship between the number of people and the number of overlaps or type of overlaps there , and , if you had two people meeting in this circumstance then you 'd still have the visuals . you wouldn't have that difference also that you have in the say , in switchboard data .   acoustic is fine , but   but what do you think about that ? do you think that would be useful ? i 'm just thinking that as an action item of whether we should try to record some two person meetings      we 'll have to set up for it .  we 're not really set up for it to do that . but .  we record this meeting regularly it wouldn't be that little strange . th that was the other thing , weren't we gonna take a picture at the beginning of each of these meetings ? yes . there 's a head nodding here vigorously , but if you just f but from one picture , i don't know that you really get that . right ? you 'd want a video for that , think  speaking of taking control , you said you had some research to talk about .      the the reason that he , just used silence was not because he thought it was better , it was it was the place he was starting . he was trying to get something going , and , as is in your case , if you 're here for only a modest number of months you try to pick a realistic goal , but his goal was always to proceed from there to then allow broad category change also .          i u look , this is a one once it 's a i used to work on voiced on voice silence detection , and this is this thing . if you have somebody who has some experience with this thing , and they work on it for a couple months , they can come up with something that gets most of the cases fairly easily . then you say , "" i don't just wanna get most of the cases i want it to be really accurate . "" then it gets really hard no matter what you do . the p the problem is that if you say , "" have these other data over here , that i learn things from , either explicit training of neural nets or of gaussian mixture models or whatever . "" suppose you don't use any of those things . you say you have looked for acoustic change . what does that mean ? that means you set some thresholds somewhere right ? and where do you get your thresholds from ? ","what we 've learned about is overlaps in this situation , is that the first order thing i would say is that there 's a lot of them . and it 's not just an overlap bunch of overlaps second order thing is it 's not just a bunch of overlaps in one particular point , but that there 's overlaps , throughout the thing . i have a feeling most of these things are that are not a benevolent kind are , are competitive as opposed to real really hostile . the other thing i was thinking was that , these all these interesting questions are , pretty hard to answer with , a small amount of data . we most of our meetings are meetings currently with say five , six , seven , eight people should we really try to have some two person meetings , or some three person meetings and re record them just to beef up the statistics on that ? we 're not really set up for it to do that . weren't we gonna take a picture at the beginning of each of these meetings ? ","Speaker fe008 presented raw counts and percentages for one transcribed meeting, revealing a large number of overlaps throughout the 40-plus-minute transcript. "
Bmr007.D,"from something that you looked at . you always have this problem , you 're going to new data how are you going to adapt whatever you can very quickly learn about the new data ? if it 's gonna be different from old data that you have ? and that 's a problem with this .  but actually , andreas may just something simpler but along the lines of what you 're saying , i was just realizing , i used to know this guy who used to build , mike mixers automatic mike mixers where , t in order to able to turn up the gain , as much as you can , you lower the gain on the mikes of people who aren't talking , right ? and then he had some reasonable way of doing that , but what if you were just looking at very simple measures like energy measures but you don't just compare it to some threshold overall but you compare it to the energy in the other microphones .   it 's probably harder , but what i was s nnn noting just when he when andreas raised that , was that there 's other information to be gained from looking of the microphones and you may not need to look at very sophisticated things , because if there 's if most of the overlaps this doesn't cover , say , three , but if most of the overlaps , say , are two , if the distribution looks like there 's a couple high ones and the rest of them are low , what there 's some information there about their distribution even with very simple measures . i had an idea with while i was watching chuck nodding at a lot of these things , is that we can all wear little bells on our heads , that then you 'd know that    th it 's a great idea . w  blindfolds would be good . probably we should until after adam 's set up the mikes , but . that 's that 's that 's the one that we videotape .  i wanna move this along . did have this other agenda item which is , @ it 's list which i sent to couple folks , but wanted to get broader input on it , this is the things that we did in the last three months not everything we did but highlights that tell s some outside person , what were you actually working on . in no particular order one , ten more hours of meeting r meetings recorded , something like that , from , three months ago . xml formats and other transcription aspects sorted out and sent to ibm . pilot data put together and sent to ibm for transcription , next batch of recorded data put together on the cd roms for shipment to ibm , but that 's why i phrased it that way , human subjects approval on campus , and release forms worked out the meeting participants have a chance to request audio pixelization of selected parts of the spee their speech . audio pixelization software written and tested . preliminary analysis of overlaps in the pilot data we have transcribed , and exploratory analysis of long distance inferences for topic coherence , that was i was wasn't if those were the right way that was the right way to describe that because of that little exercise that you and lokendra did . i i 'm probably saying this wrong , but what i said was exploratory analysis of long distance inferences for topic coherence . something like that . a lot of that was from , what you two were doing sent it to you , and mail me , the corrections or suggestions for changing i don't want to make this twice it 's length but just im improve it . is there anything anybody "" bunch of for s "" send me a sentence that 's a little thought through about that . "" bunch of , "" is probably bad too ,    "" range of things "" , and i threw in what you did with what jane did on in under the , preliminary analysis of overlaps . thilo , can you tell us about all the work you 've done on this project in the last , last three months ? that 's audio pix wh he did it , why don't you explain it quickly ?  we spent a fair amount of time early on just talk dealing with this issue about op w e we realized , "" people are speaking in an impromptu way and they might say something that would embarrass them or others later "" , and , how do you get around that in the consent form it says , you we will look at the transcripts later and if there 's something that you 're unhappy with , but you don't want to just excise it because  you have to be careful about excising it , how you excise it keeping the timing right and forth that at the moment tho th the idea we 're running with is h putting the beep over it . that he 's removing the old thing and and   ke keep a back door .  alright , think we should , go on to the digits ?     d i did before we do the digits , i did also wanna remind people , do send me , thoughts for an agenda ,  that would be that 'd be good . that , people 's ideas don't get it does creep up , doesn't it ?  go ahead that 's let 's let 's do digits . ","how are you going to adapt whatever you can very quickly learn about the new data ? if it 's gonna be different from old data that you have ? and that 's a problem with this . but what if you were just looking at very simple measures like energy measures but you don't just compare it to some threshold overall but you compare it to the energy in the other microphones . but what i was s nnn noting just when he when andreas raised that , was that there 's other information to be gained from looking of the microphones and you may not need to look at very sophisticated things , this is the things that we did in the last three months in no particular order one , ten more hours of meeting r meetings recorded , something like that , from , three months ago . pilot data put together and sent to ibm for transcription , next batch of recorded data put together on the cd roms for shipment to ibm , human subjects approval on campus , and release forms worked out the meeting participants have a chance to request audio pixelization of selected parts of the spee their speech . audio pixelization software written and tested . preliminary analysis of overlaps in the pilot data we have transcribed , and exploratory analysis of long distance inferences for topic coherence , that was i was wasn't if those were the right way that was the right way to describe that because of that little exercise that you and lokendra did . ","The group also tentatively discussed the erection of visual barriers during meeting recordings, and speaker me013 presented a list of work performed by BMR over the previous three months to be included in a forthcoming report to IBM. Speaker fe008 presented raw counts and percentages for one transcribed meeting, revealing a large number of overlaps throughout the 40-plus-minute transcript. "
Bmr007.E,"        he 's .  yes , yes !   i h i have this that infor i have th that information now . the duration of of each of the overlaps . m i haven't averaged it now but , will do the study of the with the program with the the different , the , nnn , distribution of the duration of the overlaps . because the @ @ is @ @ . the duration is , the variation of the duration is very big on the dat but  because , on your surface bit of zone of overlapping with the duration overlapped and another very short . i probably it 's very difficult to because the overlap is , on is only the in the final "" s "" of the fin the end word of the , previous speaker with the next word of the new speaker . i considered that 's an overlap but it 's very short , it 's an "" x "" with a and the idea is probably , when we studied th that zone , we h we have confusion with noise . with that fricative sounds , but have new information but i have to study .          more ,     voting for  is the same .       is possible to get information from the rhythmic f from the ge , files .  the chair a video , only with but think , when , y i saw the speech from pda and , close talker . the there is a great difference in the signal . but that in the mixed file you can find , zone with , great different , level of energy . think for , algorithm based on energy , that more or less , like first sound energy detector . nnn . when y you the detect the first at the end of the detector of , ehm princ what is the name in english ? the , the de detector of , ehm of a word in the s in an isolated word in the background that , that when you use , any  it 's probably to work because , you have in the mixed files a great level of energy . and great difference between the sp speaker . and probably is not easy when you use the pda , that because the signal is , the in the e energy level . in that , speech file is , more similar . between the different speaker , think is it will i is my opinion . it will be , more difficult to detect bass tone energy . the change . that , in the pda .   and the another question , that when i review the work of javier . the , nnn , that the idea of using a neural network to get a broad class of phonetic , from , candidate from the speech signal . if you have , 'm considering , only because javier , only consider , like candidate , the , nnn , the silence , because it is the only model , he used that , nnn , to detect the possibility of a change between the speaker , another research thing , different groups , working , on broadcast news prefer to , to consider hypothesis between each phoneme . because , it 's more realistic that , only consider the silence between the speaker . there exists silence between , speaker . is , acoustic , event , important to consider . i found that the , silence in many occasions in the speech file , but , when you have , two speakers together without enough silence between them , think is better to use the acoustic change detector and i ix or , bic criterion for consider all the frames in my opinion .       but , do you think that if you consider all the frames to apply the , the bic criterion to detect the different acoustic change , between speaker , without , with , silence or with overlapping ,  like , general , way of process the acoustic change . in a first step , an and then , without considering the you , you can consider the energy like a another parameter in the feature vector ,  this is the idea . and if , if you do that , with a bic criterion or with another of distance in a first step , and then you , you get the , the hypothesis to the this change acoustic , to po process because , probably you can find the small gap of silence between speaker with ga small duration less than , two hundred milliseconds and apply another algorithm , another approach like , detector of ene , detector of bass tone energy to consider that , zone . of s a small silence between speaker , or another algorithm to process , the segment between marks founded by the bic criterion and applied for each frame . is , nnn , it will be a an a more general approach the if we compare with use , neural net or another , speech recognizer with a broad class or narrow class , because , in my opinion it 's in my opinion , if you change the condition of the speech , if you adjust to your algorithm with a mixed speech file and to , adapt the neural net , used by javier with a mixed file . with a m mixed file , with a the mix , mix .  and then you , you try to apply that , speech recognizer to that signal , to the pda , speech file , you will have problems , because the condition you will need t i suppose that you will need to retrain it . really ?      the candidate .    but , i ","but , will do the study of the with the program with the the different , the , nnn , distribution of the duration of the overlaps . the duration is , the variation of the duration is very big on the dat ",
Bmr007.E,"i have found that when i analyzed the speech files from the , mike , from the close microphone , found zones with a different level of energy . including overlap zone . including . because , depend on the position of the microph of the each speaker to , to get more o or less energy i in the mixed sign in the signal . and then , if you consider energy to detect overlapping in , and you process the in the speech file from the mixed signals . the mixed signals , it 's difficult , only to en with energy to consider that in that zone we have overlapping zone if you process only the energy of the , of each frame .                  ","it 's difficult , only to en with energy to consider that in that zone we have overlapping zone if you process only the energy of the , of each frame . ",
Bmr007.F," testing , one , two , three . from last time i wanted to the an iss one topic from last time . it 's very it 's very brief , just let me just hand these out .  it 's slightly different . i the same . but , same idea . if you 've looked at this you 've seen it before , as part of the encoding includes a mark that indicates an overlap . it 's not indicated with , tight precision , it 's just indicated that it 's indicated to the people parts of sp which stretches of speech were in the clear , versus being overlapped by others . i used this mark and , and , divided the i wrote a script which divides things into individual minutes , of which we ended up with forty five , and a little bit . and , minute zero , is the first minute up to sixty seconds . and , what you can see is the number of overlaps and then to the right , whether they involve two speakers , three speakers , or more than three speakers . and , and , what i was looking for sp specifically was the question of whether they 're distributed evenly throughout or whether they 're bursts of them .  and it looked to me as though this is just this would this is not statistically verified , but it did look to me as though there are bursts throughout , rather than being localized to a particular region . the part down there , where there 's the maximum number of , overlaps is an area where we were discussing whether or not it would be useful to indi to s to code stress , sentence stress as possible indication of , information retrieval . it 's like , rather , lively discussion there .  th that 's the per cent . six is , two point eight percent of the total number of overlaps in the session . at the very end , this is when people were , packing up to go there 's this final we i don't remember where the digits fell . i 'd have to look at that . but the final three there are no overlaps and couple times there are not . i it seems like it goes through bursts but , that 's it . now , another question is there are there individual differences in whether you 're likely to be overlapped with or to overlap with others . and , again i want to emphasize this is just one particular one particular meeting , and also there 's been no statistical testing of it all , but i , took the coding of the i , my i had this script figure out , who was the first speaker , who was the second speaker involved in a two person overlap , i didn't look at the ones involving three or more . and , this is how it breaks down in the individual cells of who tended to be overlapping most often with who else , and if you look at the marginal totals , which is the ones on the right side and across the bottom , you get the totals for an individual . if you look at the bottom , those are the , numbers of overlaps in which adam was involved as the person doing the overlapping and if you look i 'm but you 're o alphabetical , that 's why i 'm choosing you and then if you look across the right , then that 's where he was the person who was the sp first speaker in the pair and got overlap overlapped with by somebody . and , then if you look down in the summary table , then you see that , th they 're differences in whether a person got overlapped with or overlapped by . raw counts . yes , very true very true it would be good to normalize with respect to that . now on the table i did take one step toward , away from the raw frequencies by putting , percentages . that the percentage of time of the times that a person spoke , what percentage w of the times a person spoke and furthermore was involved in a two person overlap , what percentage of the time were they the overlapper and what percent of the time were they th the overlappee ? and there , it looks like you see some differences , that some people tend to be overlapped with more often than they 're overlapped , but , e this is just one meeting , there 's no statistical testing involved , and that would be required for a finding of any scientific reliability . no , no . that 's right . that 's right . and i 'm i 'm i don't see a point of singling people out , now , this is a case where it 's like i 'm not saying on the tape who did better or worse because i don't think that it 's i and th here 's a case where human subjects people would say be that you anonymize the results , and , might as do this . fair enough . fair enough . and actually , not about an individual , it 's the point about tendencies toward different styles , different speaker styles . and it would be , there 's also the question of what type of overlap was this , and w what were they , and i and i know that distinguish at least three types and , probably more , the general cultural idea which w the conversation analysts originally started with in the seventies was that we have this strict model where politeness involves that you let the person finish th before you start talking , ","as part of the encoding includes a mark that indicates an overlap . it 's not indicated with , tight precision , it 's just indicated that it 's indicated to the people parts of sp which stretches of speech were in the clear , versus being overlapped by others . and , what you can see is the number of overlaps and then to the right , whether they involve two speakers , three speakers , or more than three speakers . and , and , what i was looking for sp specifically was the question of whether they 're distributed evenly throughout or whether they 're bursts of them . this is just this would this is not statistically verified , but it did look to me as though there are bursts throughout , rather than being localized to a particular region . the part down there , where there 's the maximum number of , overlaps is an area where we were discussing whether or not it would be useful to indi to s to code stress , sentence stress as possible indication of , information retrieval . now , another question is there are there individual differences in whether you 're likely to be overlapped with or to overlap with others . i , my i had this script figure out , who was the first speaker , who was the second speaker involved in a two person overlap , i didn't look at the ones involving three or more . and , then if you look down in the summary table , then you see that , th they 're differences in whether a person got overlapped with or overlapped by . raw counts . of the times a person spoke and furthermore was involved in a two person overlap , what percentage of the time were they the overlapper and what percent of the time were they th the overlappee ? that some people tend to be overlapped with more often than they 're overlapped , but , e this is just one meeting , there 's no statistical testing involved , and that would be required for a finding of any scientific reliability . and actually , not about an individual , it 's the point about tendencies toward different styles , different speaker styles . and it would be , there 's also the question of what type of overlap was this , and w what were they , and i and i know that distinguish at least three types and , probably more , ","Speaker fe008 presented raw counts and percentages for one transcribed meeting, revealing a large number of overlaps throughout the 40-plus-minute transcript. Efforts by speakers fe008 and fe016 are in progress to categorize and subcategorize types of overlapping speech and evaluate the contribution of multiple speakers in an interaction to the amount and types of overlap observed. "
Bmr007.F,"and w we know that an and they 've loosened up on that too s in the intervening time , that that 's viewed as being a culturally relative thing , that you have the high involvement style from the east coast where people will overlap often as an indication of interest in what the other person is saying . and exactly ! there you go . fine , that 's alright , that 's and , in contrast , deborah d and also deborah tannen 's thesis she talked about differences of these types , that they 're just different styles , and it 's you can't impose a model of there of the ideal being no overlaps , and conversational analysts also agree with that , it 's now , universally a ag with . and , als i can't say universally , but anyway , the people who used to say it was strict , now , don't . they also ack acknowledge the influence of sub of subcultural norms and cross cultural norms and things . then it beco though just superficially to give couple ideas of the types of overlaps involved , i have at the bottom several that i noticed . there are backchannels , like what adam just did now and , anticipating the end of a question and simply answering it earlier , and there are several of those in this in these data where because we 're people who 've talked to each other , we the topic is , what the possibilities are and w and we 've spoken with each other we the other person 's style is likely to be and and t there are a number of places where someone just answered early . no problem . and places also which were interesting , where two or more people gave exactly th the same answer in unison different words but the everyone 's saying "" yes "" or or ev even more sp specific than that . that , overlap 's not necessarily a bad thing and that it would be im i useful to subdivide these further and see if there are individual differences in styles with respect to the types involved . and that 's all i wanted to say on that , unless people have questions . interesting . at the bottom , you have the bottom three . four minutes all together with none . yes ,  but just no overlaps . yes , exactly and that 's where jose 's pro project comes in . i suspect that it will also differ , depending on the type of overlap involved . backchannels will be very brief and  yes .  actually , actually not . le let 's think about the case where a starts speaking and then b overlaps with a , and then the minute boundary happens . and let 's say that after that minute boundary , is still speaking , and a overlaps with b , that would be a new overlap . but otherwise let 's say b comes to the conclusion of that turn without anyone overlapping with him or her , in which case there would be no overlap counted in that second minute .  in that case , my c the coding that i was using since we haven't , incorporated adam 's , coding of overlap yets , the coding of "" yets "" is not a word . since we haven't incorporated adam 's method of handling overl overlaps yet then that would have fallen through the cra cracks . it would be an underestimate of the number of overlaps because , wou i wouldn't be able to pick it up from the way it was encoded far . we just haven't done th the precise second to sec second to second coding of when they occur .      no , it wouldn't . it would be considered as an overlap in the first one .   they 're not double counted . i should also say i did a simplifying , count in that if a was speaking b overlapped with a and then a came back again and overlapped with b again , i didn't count that as a three person overlap , i counted that as a two person overlap , and it was a being overlapped with by d . because the idea was the first speaker had the floor and the second person started speaking and then the f the first person reasserted the floor thing . these are simplifying assumptions , didn't happen very often , there may be like three overlaps affected that way in the whole thing .  that 's interesting . that 's interesting . there 's a lot of backchannel , a lot o a lot of it is . too , now . wh i agree with adam . and the reason is because there 's a limit there 's an upper bound on how many you can have , simply from the standpoint of audibility . when we speak we do make a judgment of "" can "" as adults . children don't adjust if a truck goes rolling past , adults will depending , but mostly , adults will hold off to what to finish the end of the sentence till the noise is past . and we generally do monitor things like that , about whether we whether our utterance will be in the clear or not . and partly it 's related to rhythmic structure in conversation , you t this is d also people tend to time their , when they come into the conversation based on the overall rhythmic , ambient thing . you don't want to be c cross cutting . and , just to finish this , that that that there may be an upper bound on how many overlaps you can have , simply from the standpoint of audibility and how loud the other people are who are already in the fray . but i of certain types . ","then it beco though just superficially to give couple ideas of the types of overlaps involved , i have at the bottom several that i noticed . there are backchannels , like what adam just did now and , anticipating the end of a question and simply answering it earlier , and places also which were interesting , where two or more people gave exactly th the same answer in unison different words that , overlap 's not necessarily a bad thing and that it would be im i useful to subdivide these further and see if there are individual differences in styles with respect to the types involved . le let 's think about the case where a starts speaking and then b overlaps with a , and then the minute boundary happens . and let 's say that after that minute boundary , is still speaking , and a overlaps with b , that would be a new overlap . but otherwise let 's say b comes to the conclusion of that turn without anyone overlapping with him or her , in which case there would be no overlap counted in that second minute . we just haven't done th the precise second to sec second to second coding of when they occur . no , it wouldn't . it would be considered as an overlap in the first one . if a truck goes rolling past , adults will depending , but mostly , adults will hold off to what to finish the end of the sentence till the noise is past . and we generally do monitor things like that , about whether we whether our utterance will be in the clear or not . and partly it 's related to rhythmic structure in conversation , and , just to finish this , that that that there may be an upper bound on how many overlaps you can have , simply from the standpoint of audibility and how loud the other people are who are already in the fray . ",Efforts by speakers fe008 and fe016 are in progress to categorize and subcategorize types of overlapping speech and evaluate the contribution of multiple speakers in an interaction to the amount and types of overlap observed. 
Bmr007.F,"now if it 's just backchannels , people may be doing that with less intention of being heard , just spontaneously doing backchannels , in which case that those might there may be no upper bound on those . he could , he could . e she 's doing that . you could do that . i ju that in this meeting i really had the feeling that wasn't happening , that the hostile type . these were benevolent types , as people finishing each other 's sentences , and i agree . i agree . there are various things , you have the that 's a control . it seems like there are two possibilities there , it seems like if you have just two people it 's not really , y like a meeting , w is not as similar as the rest of the sample . it depends on what you 're after , but it seems like that would be more a case of the control condition , compared to , an experimental condition , with more than two .   i 'm just thinking that 'd be more like a c control condition .  you 've been working on that .  blindf linguistic  linguistic anthropologists would suggest it would be useful to also take a picture of the meeting . the because you get then the spatial relationship of the speakers . and that could be but they the s the linguistic anthropologists would say it would be good to have a digital picture anyway , because you get a sense also of posture . posture , and we could like , block out the person 's face or whatever but , these are important cues , the how a person is sitting is it 'd be better than nothing , is from a single picture you can tell some aspects . could tell you if i if i 'm in certain meetings i notice that there are certain people who really do the body language is very is very interesting in terms of the dominance aspect . you black out the that part . but it 's just , the body     say that again ? frame over fres threshold .    "" mixed . ""  "" ding "" . that 's cute !  actually also say i made barr barriers for that the was doing with collin wha which just used , this foam board . r really inexpensive . you can masking tape it together , these are pretty l large partitions . it 's true , it would disturb the , the long range it would  we 're going to have to work on the , on the human subjects form . "" do you mind being blindfolded while you 're interviewed ? "" what was that called ? the , say again ?  i like that idea . it 's very clear . then you don't think it 's a long pause .  i agree . one question . do you do it on all channels ? interesting . i like that . i like that . very clear . very clear . the other thing that the alternative might be to s  that 's great .  i have one concept a t i want to say , which is that it 's that you 're preserving the time relations , s you 're not just cutting you 're not doing scissor snips . you 're keeping the , the time duration of a de deleted part . good , digits . it 's great . good .     aw , no . i have the script now , it can work off the , other thing , but  because , once his algorithm is up and running then we can do it that way . but worked off of my  appreciate that . what i what this has , caused me this discussion caused me to wanna subdivide these further . i 'm gonna take a look at the , backchannels , how much we have anal i hope to have that for next time . let 's do it .  do you want us to put a mark on the bottom of these when they 've actually been read , or do you just i i the only one that wasn't read is is known , we don't do it .  ","now if it 's just backchannels , people may be doing that with less intention of being heard , just spontaneously doing backchannels , in which case that those might there may be no upper bound on those . these were benevolent types , as people finishing each other 's sentences , and the because you get then the spatial relationship of the speakers . what i what this has , caused me this discussion caused me to wanna subdivide these further . i 'm gonna take a look at the , backchannels , how much we have anal i hope to have that for next time . ",Efforts by speakers fe008 and fe016 are in progress to categorize and subcategorize types of overlapping speech and evaluate the contribution of multiple speakers in an interaction to the amount and types of overlap observed. 
Bmr007.G,"i was about to ask can i you split this by minute , if an overlap straddles the boundary between two minutes , that counts towards both of those minutes . no , but suppose they both talk simultaneously both a portion of it is in minute one and another portion of minute two .  other otherwise you 'd get double counts , here and there . and then it would be harder i have a feeling that backchannels , which are the vast majority of overlaps in switchboard , don't play as big a role here , because it 's very unnatural to backchannel if in a multi audience in a multi person audience . right . but , it 's odd if one person 's speaking and everybody 's listening , and it 's unusual to have everybody going "" ""  plus the  actually , that 's in part because the nodding , if you have visual contact , the nodding has the same function , but on the phone , in switchboard you that wouldn't work . you need to use the backchannel .  right . here 's a first interesting labeling task . to distinguish between , say , backchannels precision timing benevolent overlaps , and w and don't know , hostile overlaps , where someone is trying to grab the floor from someone else . that might be an interesting , problem to look at .  i could imagine that as there 's a fair number of cases where , and this is not really hostile , but competitive , where one person is finishing something and you have two or three people jumping trying to trying to , grab the next turn . and it 's not against the person who talks first because actually we 're all waiting for that person to finish . but they all want to be next . right . seniority . if the goal were to just look at overlap you would you could serve yourself save yourself a lot of time but not even transcri transcribe the words . i have an idea . could we could we , we have in the past and continue will continue to have a fair number of phone conference calls . and , and as a to , as another c comparison condition , we could see what happens in terms of overlap , when you don't have visual contact .  or , this is getting a little extravagant , we could put up some blinds to remove , visual contact . no you f  you could do that by just noting on the enrollment sheet the seat number . you 'd number them somehow . but it 's it would be trivial not the chairs . the chairs are movable . put them like , put them on the table where they what people were wearing . andreas was  andreas was wearing that same old sweater again . and  and morgan had that funny hair again . no , you just like to be in charge , that 's why you 're sitting  actually actually i or  i i , unfortunately , have to run , but , can imagine building a model of speaker change detection that takes into account both the far field and the actually , not just the close talking mike for that speaker , but actually for all of th for all of the speakers . if you model the effect that me speaking has on your microphone and everybody else 's microphone , as as on that , and you build , think you 'd you would build a an that has as a state space all of the possible speaker combinations and , you can control it 's not that big actually ,      i have to go . ","other otherwise you 'd get double counts , here and there . actually , that 's in part because the nodding , if you have visual contact , the nodding has the same function , here 's a first interesting labeling task . to distinguish between , say , backchannels precision timing benevolent overlaps , and w and don't know , hostile overlaps , where someone is trying to grab the floor from someone else . if the goal were to just look at overlap you would you could serve yourself save yourself a lot of time but not even transcri transcribe the words . we have in the past and continue will continue to have a fair number of phone conference calls . and , and as a to , as another c comparison condition , we could see what happens in terms of overlap , when you don't have visual contact . or , this is getting a little extravagant , we could put up some blinds to remove , visual contact . you could do that by just noting on the enrollment sheet the seat number . put them like , put them on the table where they but , can imagine building a model of speaker change detection that takes into account both the far field and the actually , not just the close talking mike for that speaker , but actually for all of th for all of the speakers . ","The group also tentatively discussed the erection of visual barriers during meeting recordings, and speaker me013 presented a list of work performed by BMR over the previous three months to be included in a forthcoming report to IBM. "
Bmr007.H,"if if anyone hasn't signed the consent form , do the new consent form . the new and improved consent form . and shall i go ahead and do some digits ? whatever you want . it 's it doesn't matter .  we all forgot . and i have some short research issues . do you want me to be there for that ? i noticed you c ' ed me , but i wasn't actually a recipient . i didn't quite to make of that .  is this the same as the email or different ?  is this just raw counts or is it it would be interesting to see how much each person spoke . normalized to how much no actually , that would be actually statistically correct , but yes , that 's right , you don't nee when this is what this is actually when jane sent this email first , is what caused me to start thinking about anonymizing the data .   hundred ninety seven . s n are statistical .   i want to go back and listen to minute forty one . cuz i find it interesting that there were a large number of overlaps and they were all two speaker . what what i would have thought in is that when there were a large number of overlaps , it was because everyone was talking at once , but not . that 's really neat . this is really interesting data .  though it wasn't in the design . right .  i could certainly see it going either way .  we need to put trackers on it . you don't have it . your mike is that is an earphone , if you just put it it 's on your ear . there you go .  it 'd be interesting if we could do prediction . language model prediction of overlap , that would be really interesting . right .  let 's pick a different word . trying to get the floor . it 's been studied a lot . ach .  but from the acoustic point of view , it 's all good .  that 's the that was my status report , once we 're done with this discussing ,  can . right . we talked about this repeatedly . it just seems like that 's a very different thing than what we 're doing . barriers ! we can record , but no one can look at each other . close your eyes . turn off the lights . what i had thought we were gonna do is just take pictures of the whiteboards . rather than take pictures of the meeting . and , seat number , that 's a good idea . i 'll do that . i 'll do that on the next set of forms . i finally remembered to put , put native language on the newer forms . no . the wireless ones . and even the jacks , i 'm sitting here and the jack is over in front of you . it would be another task . having ground tu truth would be seat number would be good . 'm gonna put little labels on all the chairs with the seat number . that 's a good idea . but ,     the where we sit at the table , i find is very interesting , that we do tend to cong to gravitate to the same place each time . and it 's somewhat coincidental . i 'm sitting here that run into the room if the hardware starts , catching fire want to be at the head of the table . take control . i 've been playing with , using the close talking mike to do to try to figure out who 's speaking . my first attempt was just using thresholding and filtering , that we talked about two weeks ago , and played with that a little bit , and it works o k , except that it 's very sensitive to your choice of your filter width and your threshold . if you fiddle around with it a little bit and you get good numbers you can actually do a pretty good job of segmenting when someone 's talking and when they 're not . but if you try to use the same paramenters on another speaker , it doesn't work anymore , even if you normalize it based on the absolute loudness . it does work for the one speaker throughout the whole meeting . pretty pretty how did i do it ? what do the algorithm was , take o every frame that 's over the threshold , and then median filter it , and then look for runs . there was a minimum run length , that a threshold that you pick .  you take a each frame , and you compute the energy and if it 's over the threshold you set it to one , and if it 's under the threshold you set it to zero , now you have a bit stream of zeros and ones . and then i median filtered that using , fairly long filter length . actually depends on what by long , tenth of a second sorts of numbers . and that 's to average out pitch , the pitch contours , and things like that . and then , looked for long runs . and that works o k , if you fil if you tune the filter parameters , if you tune how long your median filter is and how high you 're looking for your thresholds . no . i certainly could though . but this was just i had the program mostly written already it was easy to do . and then the other thing i did , was i took javier 's speaker change detector acoustic change detector , and i implemented that with the close talking mikes , and unfortunately that 's not working real and it looks like it 's ","cuz i find it interesting that there were a large number of overlaps and they were all two speaker . language model prediction of overlap , that would be really interesting . what i had thought we were gonna do is just take pictures of the whiteboards . rather than take pictures of the meeting . seat number , that 's a good idea . i 'll do that on the next set of forms . 'm gonna put little labels on all the chairs with the seat number . i 've been playing with , using the close talking mike to do to try to figure out who 's speaking . my first attempt was just using thresholding and filtering , that we talked about two weeks ago , if you fiddle around with it a little bit and you get good numbers you can actually do a pretty good job of segmenting when someone 's talking and when they 're not . but if you try to use the same paramenters on another speaker , it doesn't work anymore , even if you normalize it based on the absolute loudness . it does work for the one speaker throughout the whole meeting . the algorithm was , take o every frame that 's over the threshold , and then median filter it , and then look for runs . there was a minimum run length , you take a each frame , and you compute the energy and if it 's over the threshold you set it to one , and if it 's under the threshold you set it to zero , now you have a bit stream of zeros and ones . and then i median filtered that using , fairly long filter length . actually depends on what by long , tenth of a second sorts of numbers . and that 's to average out pitch , the pitch contours , and things like that . and then , looked for long runs . and that works o k , if you fil if you tune the filter parameters , if you tune how long your median filter is and how high you 're looking for your thresholds . and then the other thing i did , was i took javier 's speaker change detector acoustic change detector , and i implemented that with the close talking mikes , and unfortunately that 's not working real and it looks like it 's ",Speaker me011 described his attempts to automatically identify speakers via the close-talking microphone channels using thresholding and filtering methods and an existing speaker-change detection algorithm. 
Bmr007.H,"the problem is he does it in two passes , the first pass is to find candidate places to do a break . and he does that using a neural net doing broad phone classification and he has the , one of the phone classes is silence . and the possible breaks are where silence starts and ends . and then he has a second pass which is a modeling a gaussian mixture model . looking for whether it improves or degrades to split at one of those particular places . and what looks like it 's happening is that the even on the close talking mike the broad phone class classifier 's doing a really bad job . i have no idea . i don't remember . does an do you remember , morgan , was it broadcast news ? at any rate , my next attempt , which i 'm in the midst of and haven't quite finished yet was actually using the thresholding as the way of generating the candidates . because one of the things that definitely happens is if you put the threshold low you get lots of breaks . all of which are definitely acoustic events . they 're definitely someone talking . but it could be someone who isn't the person here , but the person over there or it can be the person breathing . and then feeding that into the acoustic change detector . and think that might work . but , i haven't gotten very far on that . but all of this is close talking mike ,  it 's , just trying to get some ground truth .  my intention for this is as an aide for ground truth . not say it again ? i 'm not what you 're saying , can you try onset detector , right . right . but different speakers . in the clo in the p d a ,  no question . it 'll be much harder . much harder . right .  when a phone changes .  do something . right .  right . with the what file ? "" mixed ? ""  this is not what i was suggesting to do . also what i 'm doing right now is not intended to be an acoustic change detector for far field mikes . what i 'm doing is trying to use the close talking mike and just use can and just generate candidate and just try to get a first pass at something that works . and i haven't spent a lot of time on it and i 'm not intending to spend a lot of time on it .   everyone else . all the it 's a little big . two to the n . two to the number of people in the meeting . anyway . i was thinking about doing that originally to find out who 's the loudest , and that person is certainly talking . but i also wanted to find threshold excuse me , mol overlap . not just the loudest .  could you fill that out anyway ? just , put your name in . are y you want me to do it ? i 'll do it . i know . and everyone else is low , ding , ding , ding . nodding with blindfolds , "" what are you nodding about ? "" "" i 'm just going to sleep . ""  we could just turn out the lights . the acoustics . blindfolds . that 's right , we didn't tell them we would be blindfolding . hasn't been sent yet , but it 's getting ready .  i did a bunch of for supporting of digits . i 'll send you a sentence that doesn't just say "" a bunch of "" ?  "" is not very technical . i 'll try to phrase it in passive voice . it 's just , beeping out parts that you don't want included in the meeting you can say things like , "" this should probably not be on the record , but beep "" you can either beep or it can be silence . i couldn't decide . which was the right way to do it . beep is good auditorily , if someone is listening to it , there 's no mistake that it 's been beeped out , but for software it 's probably better for it to be silence .  and i use it 's , it 's an a below middle c beep ,   it 's not   you have to do it on all channels because it 's , audible . it 's potentially audible , you could potentially recover it .  i haven't thrown away any of the meetings that i beeped . actually yours is the only one that i beeped and then , the ar darpa meeting .  and then the darpa meeting excised completely , it 's in a private directory .  right . since we wanna possibly synchronize these things as i should have done that . shoot .  you 'll lose it . there 's no way around that . agenda ? thursday crept up on me this week . it 's definitely . i was gonna say "" can you do that for the other meetings , can you do it for them ? "" and , no actually , you can't . "" ooo , "" it 's as soon as we get labels , if it works enough . right now it 's not . not quite to the point where it works . my algorithm worked great actually on these , but when you wear it like that or with the lapel or if you have it very far from your face , that 's when it starts failing . it doesn't matter . we want it to work , right ? i don't want to change the way we do the meeting . ","the problem is he does it in two passes , the first pass is to find candidate places to do a break . and he does that using a neural net doing broad phone classification and he has the , one of the phone classes is silence . and then he has a second pass which is a modeling a gaussian mixture model . looking for whether it improves or degrades to split at one of those particular places . and what looks like it 's happening is that the even on the close talking mike the broad phone class classifier 's doing a really bad job . at any rate , my next attempt , which i 'm in the midst of and haven't quite finished yet was actually using the thresholding as the way of generating the candidates . and then feeding that into the acoustic change detector . but all of this is close talking mike , my intention for this is as an aide for ground truth . also what i 'm doing right now is not intended to be an acoustic change detector for far field mikes . what i 'm doing is trying to use the close talking mike and just use can and just generate candidate and just try to get a first pass at something that works . i was thinking about doing that originally to find out who 's the loudest , but i also wanted to find threshold excuse me , mol overlap . it 's just , beeping out parts that you don't want included in the meeting ",Speaker me011 described his attempts to automatically identify speakers via the close-talking microphone channels using thresholding and filtering methods and an existing speaker-change detection algorithm. 
Bmr007.H,"it 's it was just a comment on the software , not a comment on prescriptions on how you wear microphones . get the bolts , "" whh ""   ",,
Bmr013.A,"new version of the presegmentation . per digit . place .  worked a little bit on the presegmentation to get another version which does channel specific , speech nonspeech detection . and , what i did is i used some normalized features which , look in into the which is normalized energy , energy normalized by the mean over the channels and by the , minimum over the , other . within each channel . and to , to , to normalize also loudness and modified loudness and things and that those special features actually are in my feature vector . and , therefore to be able to , somewhat distinguish between foreground and background speech in the different in each channel . and , i tested it on three or four meetings and it seems to work , fairly i would say . there are some problems with the lapel mike .   and .  and . and i had , specific problems with .   then i did some things like that , as there are some problems in , when , in the channel , there they the speaker doesn't talk much or doesn't talk then , the , there are some problems with n with normalization , and , then , there the system doesn't work i 'm glad that there is the digit part , where everybody is forced to say something , that 's great for my purpose . and , , then the evaluation of the system is a little bit hard , as i don't have any references . that 's the one wh where i do the training on can't do the evaluation on can the transcribers perhaps do some , some meetings in terms of speech nonspeech in the specific channels ?  great .  that 's great . that 's great for me .        that that 's great , but what would be to have some more meetings , not just one meeting to be that , there is a system ,   it seems to me that it would be good to have , a few minutes from different meetings ,  but i 'm not about how much . both both . different number of speakers , different conditions . m  not really as because of the normalization ,      with the recognizer ?   m i would quite like to have some manually transcribed references for the system , as i 'm not if it 's really good to compare with some other automatic , found boundaries .     to a adjust them , or ,   great .  great . if it 's not the first minute of the meeting , that 's with me , but , in the first minute , often there are some strange things going on which aren't really , for , which aren't re really good . what i 'd quite like , perhaps , is , to have , some five minutes of different meetings ,   i could do a retraining with that , that 's but i hope that i don't need to do it . it c can be do in an unsupervised way .  i 'm not but , for those three meetings whi which i did , it seems to be , quite but , there are some as i said some problems with the lapel mike , but , perhaps we can do something with cross correlations to , to get rid of the of those . and .  that 's what i that 's my future work . what i want to do is to look into cross correlations for removing those , false overlaps . i 'm not if there are any wired mikes in those meetings , or , i have to loo have a look at them but , i 'm there 's no difference between ,   no . that i know , some of the nsa meetings ,     that 's that 's .  do the transcribers actually start wi with , transcribing new meetings , or are they ?          that perhaps the transcribers could start then from the those mult multi channel , speech nonspeech detections , if they would like to .     s ","new version of the presegmentation . worked a little bit on the presegmentation to get another version which does channel specific , speech nonspeech detection . and , what i did is i used some normalized features which , look in into the which is normalized energy , energy normalized by the mean over the channels and by the , minimum over the , other . within each channel . and to , to , to normalize also loudness and modified loudness and things and that those special features actually are in my feature vector . and , therefore to be able to , somewhat distinguish between foreground and background speech in the different in each channel . and , i tested it on three or four meetings and it seems to work , fairly i would say . there are some problems with the lapel mike . then i did some things like that , then , the , there are some problems with n with normalization , and , then , there the system doesn't work and , , then the evaluation of the system is a little bit hard , as i don't have any references . that that 's great , but what would be to have some more meetings , not just one meeting to be that , there is a system , it seems to me that it would be good to have , a few minutes from different meetings , i could do a retraining with that , but , there are some as i said some problems with the lapel mike , but , perhaps we can do something with cross correlations to , to get rid of the of those . what i want to do is to look into cross correlations for removing those , false overlaps . that perhaps the transcribers could start then from the those mult multi channel , speech nonspeech detections , if they would like to . ",Pre-segmentation manipulations that allow for the segmentation of channel-specific speech/non-speech portions of the signal and the distinction of foreground versus background speech were discussed. 
Bmr013.B,"alright . do we wanna say something about the , an update of the , transcript ?  it 'll be it 'll be a re cap of a meeting that we had jointly this morning .  my feeling is that we discussed this right before coffee and it 's a fine idea partly because , it 's not un unrelated to their present skill set , but it will add , for them , an extra dimension , it might be an interesting break for them . and also it is contributing to the , c composition of the transcript cuz we can incorporate those numbers directly and it 'll be a more complete transcript . 'm it 's fine , that part .  and , that , i 'm not , that one i 'm not if it 's into the , things that , i , wanted to use the hours for , because the , the time that they 'd be spending doing that they wouldn't be able to be putting more words on . but that 's really your choice , it 's your  it 's gonna be fun to see how we , compare at this . very exciting . s @ @ . s @ @ . it s strikes me that there are more each of them is more informative because it 's random , and that people might articulate more , and you that might end up with more a closer correspondence .  h that could be an interesting design , too , cuz then you 'd have the com the comparison of the , predictable speech versus the less predictable speech and you 'd find that it worked in , in the , case of the pr of the , non predictable .  also you were thinking of a much more restricted set of features , that      it would seem to me that the points of articulation would be m more , g that 's about articulatory features , about , points of articulation , which means , rather than vowels . is it , bilabial or dental or is it , palatal . which are all like where your tongue comes to rest . place . what whatev whatever i s said , that 's i really meant place .   that 's isn't that that was , but that wasn't that kinda the direction ?  w it seems like you could do both . i was thinking that it would be interesting , to do it with respect to , parts of switchboard anyway , in terms of , partly to see , if you could , generate first guesses at what the articulatory feature would be , based on the phone representation at that lower level . it might be a time gain . but also in terms of comparability of , what you gain   and you could tell that and you get the relative gain up ahead .    in our case you 'd think about us s starting with the regular dictionary entry , and then ? or would we but  was thinking    and i 'm and these people might they are , s most of them are trained with ipa . they 'd be able to do phonetic level coding , or articulatory . they , they 're interested in continuing working with us , mean i , and this would be up their alley , we could when the when you d meet with , with john ohala and find , what taxonomy you want to apply , then , they 'd be , good to train onto it .  too . interesting idea . he 's got lip lipsmacks .   interesting . i have now we need  might have done what you 're requesting , though i did it in the service of a different thing . i have thirty minutes that i 've more tightly transcribed with reference to individual channels . and i could and and no , actually it 's a different meeting . e the , we have the , th they transcribe as if it 's one channel with these with the slashes to separate the overlapping parts . and then we run it through then it then i 'm gonna edit it and i 'm gonna run it through channelize which takes it into dave gelbart 's form format . and then you have , all these things split across according to channel , and then that means that , if a person contributed more than once in a given , overlap during that time bend that two parts of the utterance end up together , it 's the same channel , and then i took his tool , and last night for the first thirty minutes of one of these transcripts , i , tightened up the , boundaries on individual speakers ' channels , cuz his interface allows me to have total flexibility in the time tags across the channels . and yes . might not be what you need .  how m much time the meetings vary in length , what are we talking about in terms of the number of minutes you 'd like to have as your training set ? now you 're saying different meetings because of different speakers or because of different audio quality or both or ?   the pre presegment  no , if we were to start with this and then tweak it h manually , would that would be  how many minutes would you want from we could easily , get a section , like say a minute or from every meeting that we have from the newer ones that we 're working on , everyone that we have . and then , should provide this . somewhere not in the very beginning , five minutes , and , then i wanted to ask you just for my inter information , then , would you , be trai cuz i don't quite unders ","and it 's a fine idea partly because , it 's not un unrelated to their present skill set , might have done what you 're requesting , though i did it in the service of a different thing . i have thirty minutes that i 've more tightly transcribed with reference to individual channels . ",
Bmr013.B,"would you be training then , the segmenter that , it could , on the basis of that , segment the rest of the meeting ? if i give you like five minutes is the idea that this would then be applied to , to , providing tighter time bands ? interesting .   excellent . excellent , wonderful . then , if that 's five minutes per meeting we 've got like twelve minutes , twelve meetings , roughly , that i 'm that i 've been working with , then wa in terms of the speakers or the conditions or the ? we have different combinations of speakers . just from what i 've seen , there are some where , you 're present or not present , and , then you have the difference between the networks group and this group we do . no . we could , you recorded one last week or i could get that new one in this week i get that new one in . great . if i , included include , then , if i were to include all together samples from twelve meetings that would only take an hour and i could get the transcribers to do that right what is , that would be an hour sampled , and then they 'd transcribe those that hour , right ? that 's what i should do ? i don't mean transcribe adjust . they get it into the multi channel format and then adjust the timebands it 's precise .  i did i did , last night i did , gosh , last night , i did about half an hour in , three hours , which is not , terrific , but , anyway , it 's an hour and a half per i can't calculate on my , on my feet . they 're still working they still have enough to finish that i haven't assigned a new meeting , but the next , m i was about to need to assign a new meeting and i was going to take it from one of the new ones , and i could easily give them jerry feldman 's meeting , no problem . and , then  that first set . and was in the process of like editing them but this is wonderful news . we funded the experiment with , also we were thinking applying that to getting the , that 'll be , very useful to getting the overlaps to be more precise all the way through . yes , it does . liz , and don , and i met this morning , in the barco room , with the lecture hall , and this afternoon , it drifted into the afternoon , concerning this issue of , the , there 's the issue of the interplay between the transcript format and the processing that , they need to do for , the sri recognizer . and , i mentioned the process that i 'm going through with the data , i get the data back from the transcri s metaphorically , get the data back from the transcriber , and then i , check for simple things like spelling errors and things like that . and , i 'm going to be doing a more thorough editing , with respect to consistency of the conventions . but they 're generally very good . and , then , i run it through , the channelize program to get it into the multi channel format , and the , what we discussed this morning , i would summarize as saying that , these units that result , in a particular channel and a particular timeband , at that level , vary in length . and , their recognizer would prefer that the units not be overly long . but it 's really an empirical question , whether the units we get at this point through , just that process i described might be sufficient for them . as a first pass through , a first chance without having to do a lot of hand editing , what we 're gonna do , is , i 'll run it through channelize , give them those data after i 've done the editing process and be it 's clean . and do that , pretty quickly , with just , that minimal editing , without having to hand break things . and then we 'll see if the units that we 're getting , with the at that level , are sufficient . and they don't need to be further broken down . and if they do need to be further broken down then it just be piece wise , it won't be the whole thing . that 's what we were discussing , this morning as far as i among also we discussed some adaptational things , it 's like , hadn't , incorporated , a convention explicitly to handle acronyms , but if someone says , pzm it would be to have that be directly interpretable from , the transcript what they said , or pi tcl it 's like y it 's and i 've incorporated also convention , with that but that 's easy to handle at the post editing phase , and i 'll mention it to , transcribers for the next phase but that 's and then , a similar conv convention for numbers . if they say one eighty three versus one eight three . and also i 'll be , encoding , as i do my post editing , the , things that are in curly brackets , which are clarificational material . and to incorporate , keyword , at the beginning . it 's gonna be either a gloss or it 's gonna be a vocal sound like a , laugh or a cough , or , forth . ","would you be training then , the segmenter that , it could , on the basis of that , segment the rest of the meeting ? it drifted into the afternoon , concerning this issue of , the , there 's the issue of the interplay between the transcript format and the processing that , they need to do for , the sri recognizer . and the , what we discussed this morning , i would summarize as saying that , these units that result , in a particular channel and a particular timeband , at that level , vary in length . and , their recognizer would prefer that the units not be overly long . as a first pass through , a first chance without having to do a lot of hand editing , what we 're gonna do , is , i 'll run it through channelize , give them those data after i 've done the editing process and be it 's clean . and do that , pretty quickly , with just , that minimal editing , without having to hand break things . and then we 'll see if the units that we 're getting , with the at that level , are sufficient . and if they do need to be further broken down then it just be piece wise , it won't be the whole thing . also we discussed some adaptational things , hadn't , incorporated , a convention explicitly to handle acronyms , and then , a similar conv convention for numbers . and also i 'll be , encoding , as i do my post editing , the , things that are in curly brackets , which are clarificational material . it 's gonna be either a gloss or it 's gonna be a vocal sound like a , laugh or a cough , or , forth . ","Finally, speaker fe008 and fe016 reported on new efforts to adapt transcriptions to the needs of the SRI recognizer, including conventions for encoding acronyms, numbers, ambient noise, and unidentified inbreaths. "
Bmr013.B,"or a non vocal sound like a doors door slam , and that can be easily done with a , just a one little additional thing in the , in the general format .  i 've been adding that to the ones i 've been editing .  and  and that doesn't the amount of editing that it would require is not very much either . i 'm just hoping that the units that are provided in that way , will be sufficient cuz i would save a lot of , time , dividing things .  one question , e w would that be a single speaker or is that multiple speakers overlapping ?  that 's very important . in doing the hand marking ? that 's what i was thinking , too .  wanted to ask one thing , the microphones the new microphones , when do we get , exciting . k . k . you said it was used by aerobics instructors ? that says a lot .  ","or a non vocal sound like a doors door slam , and that can be easily done with a , just a one little additional thing in the , in the general format . that 's very important . the microphones the new microphones , ",
Bmr013.C," good . right . agenda items , we have digits , what else we got ? new version of presegmentation . update on transcripts . filtering for what ?  got it . anything else more pressing than those things ? why don't we just do those . you said yours was brief , i 'm impressed by what we could do , is take the standard training set for ti digits , train up with whatever , great features we think we have , and then test on this test set . and presumably it should do reasonably on that , and then , presumably , we should go to the distant mike , and it should do poorly . and then we should get really smart over the next year or two , and it that should get better .  right . is this what do you think ? you think it 's fine to have the transcribers do it ?     just by way of a order of magnitude , we 've been working with this aurora , data set . and , the best score , on the , nicest part of the data , that is , where you 've got training and test set that are the same kinds of noise and forth , is about ,  the best score was something like five percent , error , per digit . that you 're right . if you were doing ten digit , recognition , you would really be in trouble . the point there , and this is car noise things , but real situation , "" real "" , the there 's one microphone that 's close , that they have as this thing , close versus distant . but in a car , instead of having a projector noise it 's car noise . but it wasn't artificially added to get some artificial signal to noise ratio . it was just people driving around in a car . that 's an indication , that was with , many sites competing , and this was the very best score and forth , more typical numbers like you 're right . that we could have done better on the models , but that we got this is the typical number , for all of the , things in this task , all of the , languages . and think we 'd probably the models would be better in some than in others . anyway , just an indication once you get into this realm even if you 're looking at connected digits it can be pretty hard .   i 'm not how no , no it 's connected , digits ,  but . we were in the . i th no we got under a percent , but it was but it 's but the very best system that i saw in the literature was a point two five percent that somebody had at bell labs , or . but . but , pulling out all the stops . but lot of systems get half a percent , or three quarters a percent , and we 're in there somewhere .    when they 're wide awake ,  after coffee , you 're right . not after lunch .   one question i have that we wouldn't know the answer to now but might , do some guessing , but i was talking before about doing some model modeling of arti marking of articulatory , features , with overlap and on . and , on some subset . one thought might be to do this on the digits , or some piece of the digits . it 'd be easier , and forth . the only thing is i 'm a little concerned that the phenomena , in w i the reason for doing it is because the argument is that certainly with conversational speech , the that we 've looked at here before , just doing the simple mapping , from , the phone , to the corresponding features that you could look up in a book , isn't right . it isn't actually right . there 's these overlapping processes where some voicing some up and then some , some nasality is comes in here , and forth . and you do this gross thing saying "" guess it 's this phone starting there "" . that 's the reasoning . but , it could be that when we 're reading digits , because it 's for such a limited set , that that phenomenon doesn't occur as much . i don't know . di an anybody ? do you have any ? anybody have any opinion about that ,    right .  see , i don't know . may the thing will be do to take some very small subset , not have a big , program , but take a small set , subset of the conversational speech and a small subset of the digits , and look and just get a feeling for it . just take a look . really . cuz i don't think anybody is , i at least , i don't know , of anybody , i don't know , the answers .    but i was , like he said , i was gonna bring john in and ask john what he thought . right . but you want it be restrictive but you also want it to have coverage . you should . it should be such that if you , if you had o all of the features , determined that you were ch have chosen , that would tell you , in the steady state case , the phone .   place , place .    we got our jargon then ,  right . you might be right that mi might be the way at getting at , what i was talking about , ","new version of presegmentation . update on transcripts . i 'm impressed by what we could do , is take the standard training set for ti digits , train up with whatever , great features we think we have , and then test on this test set . and presumably it should do reasonably on that , and then , presumably , we should go to the distant mike , and it should do poorly . just by way of a order of magnitude , we 've been working with this aurora , data set . and , the best score , on the , nicest part of the data , that is , where you 've got training and test set that are the same kinds of noise and forth , is about , the best score was something like five percent , error , per digit . the point there , and this is car noise things , but real situation , the there 's one microphone that 's close , that they have as this thing , close versus distant . but in a car , instead of having a projector noise it 's car noise . that we could have done better on the models , but that we got this is the typical number , for all of the , things in this task , all of the , languages . anyway , just an indication once you get into this realm even if you 're looking at connected digits it can be pretty hard . i th no we got under a percent , but it was but it 's but the very best system that i saw in the literature was a point two five percent that somebody had at bell labs , or . but . but , pulling out all the stops . one question i have that we wouldn't know the answer to now but might , do some guessing , but i was talking before about doing some model modeling of arti marking of articulatory , features , with overlap and on . one thought might be to do this on the digits , or some piece of the digits . the reason for doing it is because the argument is that certainly with conversational speech , the that we 've looked at here before , just doing the simple mapping , from , the phone , to the corresponding features that you could look up in a book , isn't right . there 's these overlapping processes where some voicing some up and then some , some nasality is comes in here , and forth . you should . it should be such that if you , if you had o all of the features , determined that you were ch have chosen , that would tell you , in the steady state case , the phone . ","Anticipated results were discussed in reference to results obtained for other digits corpora, i.e. Aurora and TI-digits. The group also considered the prospect of performing fine-grained acoustic-phonetic analyses on a subset of Meeting Recorder digits or Switchboard data. "
Bmr013.C,"but the particular reason why i was interested in doing that was because i remember , when that happened , and , john ohala was over here and he was looking at the spectrograms of the more difficult ones . he didn't to say , about , what is the sequence of phones there . they came up with some compromise . because that really wasn't what it look like . it didn't look like a sequence of phones it look like this blending thing happening here and here .   right .  right .  do i i 'm jus at the moment we 're just talking about what , to provide as a tool for people to do research who have different ideas about how to do it . you might have someone who just has a wor has words with states , and has comes from articulatory gestures to that . and someone else , might actually want some phonetic intermediate thing . think it would be best to have all of it if we could . but   this is the reason why i remember when at one of the switchboard , workshops , that when we talked about doing the transcription project , dave talkin said , "" can't be done "" . he was he was , what he meant was that this isn't , a sequence of phones , and when you actually look at switchboard that 's , not what you see , and , and . it , mean it was    right . right .  no i don't disagree with that . i don't disagree with it the on the only thing is that , what you actually will end en end up with is something , i it 's all compromised , right , the string that you end up with isn't , actually , what happened . but it 's the best compromise that a group of people scratching their heads could come up with to describe what happened . but . and it 's more accurate than the dictionary or , if you 've got a pronunciation lexicon that has three or four , this might be have been the fifth one that you tr that you pruned or whatever ,     right . mean , what where this is , i want would like to have something that 's useful to people other than those who are doing the specific research i have in mind , it should be something broader . but , the but where i 'm coming from is , we 're coming off of that larry saul did with , john dalan and muzim rahim in which , they , have , a m a multi band system that is , trained through a combination of gradient learning an and to estimate , the , value for m for a particular feature .  and this is part of a larger , image that john dalan has about how the human brain does it in which he 's imagining that , individual frequency channels are coming up with their own estimate , of these , these kinds of something like this . might not be , exact features that , jakobson thought of but some , something like that . some low level features , which are not , fully , phone classification . and the th this particular image , of how thi how it 's done , is that , then given all of these estimates at that level , there 's a level above it , then which is making , some sound unit classification such as , phone and , you could argue what , what a sound unit should be , and forth . but that 's what i was imagining doing , and but it 's still open within that whether you would have an intermediate level in which it was actually phones , or not . you wouldn't necessarily have to . but , again , i wouldn't wanna , wouldn't want what we produced to be know , local in perspective that it was matched , what we were thinking of doing one week , and , what you 're saying is right . that , that if we , can we should put in , another level of , of description there if we 're gonna get into some of this low level    it 's it 's a little different . mean i we 'll see wha how much we can , get the people to do , and how much money we 'll have and all this thing , but , might be do both . think what 'm a l little behind in what they 're doing , now , and , the they 're doing on switchboard now . but that , steve and the gang are doing , something with an automatic system first and then doing some adjustment . as i re as i recall . mean that 's probably the right way to go anyway , is to start off with an automatic system with a pretty rich pronunciation dictionary that , tries , to label it all . and then , people go through and fix it . regular dictionary , this is a pretty rich dictionary . it 's got , got a fair number of pronunciations in it  actually they 're using phone recognizers . is that what they 're doing ?   think that i we also don't have , we 've got a good start on it , but we don't have a really good , meeting , recorder or recognizer or transcriber or anything yet ,  another way to look at this is to , do some on switchboard which has all this other , to it . and then , as we get , further down the road and we can do more things ahead of time , we can , do some of the same things to the meeting data .    anyway , this is , not an urgent thing ","i i 'm jus at the moment we 're just talking about what , to provide as a tool for people to do research who have different ideas about how to do it . mean i we 'll see wha how much we can , get the people to do , and how much money we 'll have and all this thing , mean that 's probably the right way to go anyway , is to start off with an automatic system with a pretty rich pronunciation dictionary that , tries , to label it all . and then , people go through and fix it . another way to look at this is to , do some on switchboard which has all this other , to it . and then , as we get , further down the road and we can do more things ahead of time , we can , do some of the same things to the meeting data . ",The group also considered the prospect of performing fine-grained acoustic-phonetic analyses on a subset of Meeting Recorder digits or Switchboard data. 
Bmr013.C,"just it came up .   we should move on . new version of , presegmentation ? right . we don't have that much variety in meetings yet , we have this meeting and the feature meeting and we have a couple others that we have couple examples of . but , poten potentially .  of the meetings that you 're working with , how many of them are different , tha are there any of them that are different than , these two meetings ? speakers .    didn't know in the group you had if you had you have the networks meeting ? do you have any of jerry 's meetings in your , pack , er , no ?  cuz he really needs variety , and having as much variety for speaker certainly would be a big part of that  and . right . ye but you 're y that should be faster than the ten times thing ,    that 's probably . they 're running out of data unless we s make the decision that we should go over and start , transcribing the other set . there the first half . alright . this , blends nicely into the update on transcripts .    good s that 's probably our agenda , or starting up there . k . k . they go where old microphones go .   for the recor for the record adam is not a paid employee or a consultant of crown . i said "" for the record adam is not a paid consultant or employee of crown "" .  right .  you bet . you bet . if we go to a workshop about all this it 's gonna be a meeting about meetings .   what which 'll be the meeting about the meeting .  just start saying "" m four "" .  should we do the digits ?   ","and having as much variety for speaker certainly would be a big part of that this , blends nicely into the update on transcripts . ",
Bmr013.D,"we 'll have a corpus that 's the size of ti digits ? test set , great . great .  good . are these two separate tasks that can happen ? or do they have to happen at the same time before    although the models weren't , that good , right ? the models are pretty crappy ?  how did we do on the ti digits ? h how do h how do we do on ti digits ?  pre prehistory . less predictability , and you hafta hey . hafta think about , the particular acoustic features to mark , too , because , some things , they wouldn't be able to mark tense lax . some things are really difficult .  just listening .  points of articulation ? what do place of ar place of articulation .  i see . there was no name for that . it would be great if we had , either these labelings on , the same portion of switchboard that steve marked , or , steve 's type markings on this data , with these . and it 's more accurate than , phone labels .  it 's like a continuum . it 's you 're going all the way down ,  right .  right . it 's just having , multiple levels of , information and marking , on the signal .   mean if we 're talking about , having the , annotators annotate these kinds of features , it seems like , you the question is , do they do that on , meeting data ? or do they do that on , switchboard ? cuz the and then also , if you did it on switchboard , you would have , the full continuum of transcriptions . you 'd have it , from the lowest level , the ac acoustic features , then you 'd have the , the phonetic level that steve did , and ,  it 'd be a complete , set then . but it might be good to do what jane was saying seed it , with , guesses about what we think the features are , based on , the phone or steve 's transcriptions to make it quicker . adjusting ? exactly . scoot the voicing over a little , because or you could start from the if we were gonna , do the same set , of sentences that steve had , done , we could start with those transcriptions .     are they busy for the next couple years , or ? it 'd be very interesting though , to have that data .  of the f acoustic features ?  won't you have that from their transcriptions ? current this week . you ordered them already ? great . it 's a replacement for this headset mike ? what 's the , style of the headset ?  god . ","we 'll have a corpus that 's the size of ti digits ? do we do on ti digits ? mean if we 're talking about , having the , annotators annotate these kinds of features , it seems like , the question is , do they do that on , meeting data ? but it might be good to do what jane was saying seed it , with , guesses about what we think the features are , based on , the phone or steve 's transcriptions to make it quicker . ",
Bmr013.E,"even probably with the gains differently will affect it , cuz you use the normalization ?  i saw a couple , around twenty seconds , and that was just without looking too hard for it , i would imagine that there might be some that are longer . no . no , but if we 're gonna segment it , like if there 's one speaker in there , that says "" right in the middle , it 's gonna have a lot of dead time around it , it 's not   excuse me . ",,
Bmr013.F,"wanted to discuss digits briefly , but that won't take too long .  the , w as you can see from the numbers on the digits we 're almost done . the digits goes up to about four thousand . and we probably will be done with the ti digits in , another couple weeks . depending on how many we read each time . there were a bunch that we skipped . someone fills out the form and then they 're not at the meeting and it 's blank . but those are almost all filled in as and once we 're it 's done it would be very to train up a recognizer and actually start working with this data . and one particular test set of ti digits . i extracted , ther there was a file sitting around which people have used here as a test set . it had been randomized and on and that 's just what i used to generate the order . of these particular ones .  right . and inc increase it by one or two percent , but , in order to do that we need to extract out the actual digits . that the reason it 's not just a transcript is that there 're false starts , and misreads , and miscues and things like that . and have a set of scripts and x waves where you just select the portion , hit r , it tells you what the next one should be , and you just look for that . it 'll put on the screen , "" the next set is six nine , nine two "" . and you find that , and , hit the key and it records it in a file in a particular format . and the question is , should we have the transcribers do that or should we just do it ? some of us . i 've been do i 've done , eight meetings , something like that , just by hand . just myself , rather . it will not take long .  there is there is there 's one other small bit , which is just entering the information which at s which is at the top of this form , onto the computer , to go along with the where the digits are recorded automatically . and it 's just , typing in name , times time , date , and on . which again either they can do , but it is , firing up an editor , or , again , do . or someone else can do . no they don't have this you have to enter the data before , you do the second task , but they don't have to happen at the same time . it 's just i have a file whi which has this information on it , and then when you start using my scripts , for extracting the times , it adds the times at the bottom of the file . and it 's easy to create the files and leave them blank , and actually we could do it in either order . it 's to have the same person do it just as a double check , to make you 're entering for the right person . but , either way . per digit . the prosodics are much different s it 's gonna be , strange . the prosodics are not the same as ti digits , 'm not how much of effect that will have . just what we were talking about with grouping . that with these , the grouping , there 's no grouping and it 's just the only discontinuity you have is at the beginning and the end . aurora i don't know . i don't they do in aurora . but right . but in ti digits , they 're reading things like zip codes and phone numbers and things like that , it 's gonna be different . i don't remember . very good , right ? one and a half percent , two percent , something like that ? really ?  alright . right . but that it 's really it 's close talking mikes , no noise , clean signal , just digits , every everything is good . yes , exactly . and we 've only recently got it to anywhere near human . and it 's still like an order of magnitude worse than what humans do .   after coffee . what i 'll do then is i 'll go ahead and enter , this data . and then , hand off to jane , and the transcribers to do the actual extraction of the digits .  that 's i agree . that it 's just it 's a would , this corpus really be the right one to even try that on ? m we can get ohala in to , give us some advice on that . right . even , with vowels that would be pretty hard , wouldn't it ? to identify actually , which one it is ?  uvular . right . right . you have this feature here , and , overlap , and or "" gonta "" . don't think morgan 's suggesting that we do that , though . but what i 'm imagining is a score like notation , where each line is a particular feature . right , you would say , it 's voiced through here , and you have label here , and you have nas nasal here , and , they could be overlapping in all sorts of bizarre ways that don't correspond to the timing on phones . right . and the inter annotator agreement was not that good , right ? on the harder ones ? the word .  the other difference is that the features , are not synchronous , right . they overlap each other in weird ways . ","the , w as you can see from the numbers on the digits we 're almost done . the digits goes up to about four thousand . and we probably will be done with the ti digits in , another couple weeks . depending on how many we read each time . and once we 're it 's done it would be very to train up a recognizer and actually start working with this data . one particular test set of ti digits . but , in order to do that we need to extract out the actual digits . that the reason it 's not just a transcript is that there 're false starts , and misreads , and miscues and things like that . and have a set of scripts and x waves where you just select the portion , hit r , it tells you what the next one should be , and you just look for that . and the question is , should we have the transcribers do that or should we just do it ? the prosodics are not the same as ti digits , just what we were talking about with grouping . that with these , the grouping , there 's no grouping and it 's just the only discontinuity you have is at the beginning and the end . but that it 's really it 's close talking mikes , no noise , clean signal , just digits , every everything is good . what i 'll do then is i 'll go ahead and enter , this data . and then , hand off to jane , and the transcribers to do the actual extraction of the digits . but what i 'm imagining is a score like notation , where each line is a particular feature . the other difference is that the features , are not synchronous , they overlap each other in weird ways . ",The Berkeley Meeting Recorder group discussed the collection status for a set of connected digits recordings that are nearly complete and ready to be trained on a recognizer. 
Bmr013.F,"it 's not a strictly one dimensional signal . think that 's sorta qualitatively different . not with our current system but you could imagine designing a system , that the states were features , rather than phones .  that 's what i was saying , meeting data isn't the right corpus . alright , based on the phone transcripts they would all be synchronous , but then you could imagine , nudging them here and there . right . right . they are . i wonder , how would you do a forced alignment ? to you 'd wanna iterate , somehow .  it 's interesting thing to think about . you 'd want models for spreading .     that 's great . understand that 's what you were saying about your problem with , minimum . i get it . new use ninetieth quartile , rather than , minimum . we did the hand the one by hand .  no , cuz we need is really tight . hopefully that 's not the same meeting that we did . good . if we could get a couple meetings done with that level of precision that would be a good idea . shoot !  u right . right . an extra channel . they said it would take about a week .   the only thing we 're gonna have extra , for now , right , we don the only thing we 'll have extra now is just the lapel . not the , bodypack , just the lapel . and then one of the one of those . since , what i decided to do , on morgan 's suggestion , was just get two , new microphones , and try them out . and then , if we like them we 'll get more . since they 're like two hundred bucks a piece , we won't , at least try them out .  and they 're gonna do the wiring for us . it 's , it 's by crown , and it 's one of these mount around the ear thingies , and , when i s when i mentioned that we thought it was uncomfortable he said it was a common problem with the sony . and this is how lot of people are getting around it . and i checked on the web , and every site i went to , raved about this particular mike . it 's comfortable and stays on the head we 'll see if it 's any good . but , it 's promising . it was advertised for performers and excuse me ? excuse me ? that 's right . we 're using the crown p z these are crown aren't they ? the p z ms are crown , aren't they ? they were . and they work very and then it we have to go to the planning session for that workshop . cuz then it would be a meeting about the meeting about meetings .  m to the fourth . go for it . pause between the lines , remember ?  ","it 's not a strictly one dimensional signal . not with our current system but you could imagine designing a system , that the states were features , rather than phones . new use ninetieth quartile , rather than , minimum . if we could get a couple meetings done with that level of precision that would be a good idea . since , what i decided to do , on morgan 's suggestion , was just get two , new microphones , and try them out . it 's , it 's by crown , and it 's one of these mount around the ear thingies , ",
Bmr013.G,"why don't you summarize the and that includes some the filtering for the , the asi refs , too . for the references that we need to go from the fancy transcripts to the brain dead . with don , as what do the prosodics ? what are they doing in aurora , are they reading actual phone numbers , or , a digit at a time , or ? cuz it 's connected . there 's also the not just the prosody but the cross word modeling is probably quite different . right . it 's the beginning of time in speech recognition . it 's like the , single cell , it 's the beginning of life ,  right . it 's definitely true that , when people are , reading , even if they 're reading what , they had said spontaneously , that they have very different patterns . mitch showed that , and some , dissertations have shown that . the fact that they 're reading , first of all , whether they 're reading in a room of , people , or rea just the fact that they 're reading will make a difference . and , depends what you 're interested in . it 's also , there 's , really a difference between , the pronunciation models in the dictionary , and , the pronunciations that people produce . and , you get , some of that information from steve 's work on the labeling and it really , i actually think that data should be used more . that although the meeting context is great , that he has transcriptions that give you the actual phone sequence . and you can go from not from that to the articulatory features , but that would be a better starting point for marking , the gestural features , then , data where you don't have that , because , we you wanna know , both about the way that they 're producing a certain sound , and what kinds of , what kinds of , phonemic , differences you get between these , transcribed , sequences and the dictionary ones . right . right . but right . but it still is there 's a there are two steps . one one is going from a dictionary pronunciation of something gonna see you tomorrow "" , it could be "" going to "" or "" gonna "" or "" gonta s "" and , "" gonna see you tomorrow "" , "" guh see you tomorrow "" . and , that it would be to have these , intermediate , or these some these reduced pronunciations that those transcribers had marked or to have people mark those as because , it 's not , that easy to go from the , dictionary , word pronuncia the dictionary phone pronunciation , to the gestural one without this intermediate or a syllable level representation . it depends how you look at it , and i understand what you 're saying about this , transcription exactly , because i 've seen where does the voicing bar start and forth . all i 'm saying is that , it is useful to have that the transcription of what was really said , and which syllables were reduced . if you 're gonna add the features it 's also useful to have some level of representation which is , is a reduced it 's a pronunciation variant , that currently the dictionaries don't give you because if you add them to the dictionary and you run recognition , you add confusion . people purposely don't add them . it 's useful to know which variant was produced , at least at the phone level . right . that 's all , exactly . exactly . and steve 's type is fairly it 's not that slow ,  exactly what the , timing was , but .  right . right . right . that 's what i meant is an and in some places it would fill in , the kinds of gestural features are not everywhere . there are some things that you don't have access to either from your ear or the spectrogram , but what phone it was and that 's about all you can say . and then there are other cases where , nasality , voicing right . right . right . right . you can add the features in , but it 'll be underspecified . th there 'll be no way for you to actually mark what was said completely by features . and i if you 're we 've probably have a separate , discussion of , of whether you can do that . that 's all i was thinking about . it is telephone band , the bandwidth might be  that 's actually what i was thinking , is tha the problem is when you run , if you run a regular dictionary , even if you have variants , in there , which most people don't , you don't always get , out , the actual pronunciations , that 's why the human transcriber 's giving you the that pronunciation , and they that they were we should catch up on what steve is , think that would be a good i good idea .   might it might be i was thinking it might be n it might be neat to do some , phonetic , features on these , nonword words . are these kinds of words that people never the "" ""s and the "" ""s and the "" and the these k no , i 'm serious . there are all these kinds of functional , elements . i don't you call them . but not just fill pauses but all kinds of ways of interrupting and forth . and some of them are , "" ""s , and "" ""s , and , "" "" "" "" , "" grunts ,  that might be interesting . ","and that includes some the filtering for the , the asi refs , too . you can add the features in , but it 'll be underspecified . ",
Bmr013.G,"in the meetings . we can try running we haven't done this yet because , andreas an is gonna move over the sri recognizer . i ran out of machines at sri , cuz we 're running the evals and don't have machine time there . but , once that 's moved over , hopefully in a couple days , then , we can take , what jane just told us about as , the presegmented , the segmentations that you did , at level eight or som at some , threshold that jane , tha right , and try doing , forced alignment . on the word strings . and if it 's good , then that will that may give you a good boundary . if it 's good , we don't then we 're fine , but , i don't know yet whether these , segments that contain a lot of pauses around the words , will work or not .  right . right . they might be it it really depends on a lot of things , but , i would have transciber , look at the result of a forced alignment and then adjust those . that might save some time . if they 're horrible it won't help but they might not be horrible . but i 'll let when we , have that . are the , wireless , different than the wired , mikes , have you noticed any difference ? it 's just the lapel versus everything else ? we 're gonna be recording them every monday ,  they 're really running out of , data , prett that 's good .    go ahead . and this afternoon . right . then lots of right . we j we just needed a way to , strip , all the comments , all the things th the that linguist wants but the recognizer can't do anything with . but to keep things that we mapped to like reject models , or , mouth noise , or , cough . and then there 's this interesting issue jane brought up which i hadn't thought about before but i was , realizing as i went through the transcripts , that there are some noises like ,  the good example was an inbreath , where a transcriber working from , the mixed , signal , doesn't know whose breath it is , and they 've been assigning it to someone that may or may not be correct . and what we do is , if it 's a breath sound , a sound from the speaker , we map it , to , a noise model , like a mouth noise model in the recognizer , and , it probably doesn't hurt that much once in a while to have these , but , if they 're in the wrong channel , that 's , not a good idea . and then there 's also , things like door slams that 's really in no one 's channel , they 're like it 's in the room . and jane had this idea of having , like an extra , couple tiers ,  and we were thinking , that is useful also when there 's uncertainties . if they hear a breath and they don't know who breath it is it 's better to put it in that channel than to put it in the speaker 's channel because it was someone else 's breath , or think that 's a good you can always clean that up , post processing . lot of little details , but we 're , coming to some kinda closure , on that . the idea is then , don can take , jane 's post processed channelized version , and , with some scripts , convert that to a reference for the recognizer and we can , can run these . when that 's , ready as soon as that 's ready , and as soon as the recognizer is here we can get , twelve hours of force aligned and recognized data . and , start , working on it , we 're , coup a week or two away i would say from , if that process is automatic once we get your post process , transcript . some of them are quite long . just from  how long were you did one ? right . right . it 's not the fact that we can't process a twenty second segment , it 's the fact that , there 's twenty seconds in which to place one word in the wrong place if someone has a very short utterance there , and that 's where , we , might wanna have this individual , ha have your pre process input . and don't know , i have to run it . right . right . that 's probably what will happen , but we 'll try it this way and see . it 's probably good enough for force alignment . if it 's not then we 're really then we def definitely but for free recognition i 'm it 'll probably not be good enough . we 'll probably get lots of errors because of the cross talk , and , noises and things . what happens to our old microphones ? do we give them to someone , or ? we don't have more receivers , we just have right . just the lapel itself .   right . however , he may be solicited after these meetings are distributed . don't worry about finishing your dissertation . yes .  ","and then there 's also , things like door slams that 's really in no one 's channel , and jane had this idea of having , like an extra , couple tiers , and we were thinking , that is useful also when there 's uncertainties . if they hear a breath and they don't know who breath it is it 's better to put it in that channel than to put it in the speaker 's channel the idea is then , don can take , jane 's post processed channelized version , and , with some scripts , convert that to a reference for the recognizer when that 's , ready as soon as that 's ready , and as soon as the recognizer is here we can get , twelve hours of force aligned and recognized data . it 's probably good enough for force alignment . but for free recognition i 'm it 'll probably not be good enough . we 'll probably get lots of errors because of the cross talk , and , noises and things . ","Finally, speaker fe008 and fe016 reported on new efforts to adapt transcriptions to the needs of the SRI recognizer, including conventions for encoding acronyms, numbers, ambient noise, and unidentified inbreaths. "
Bmr014.A,"mr eleven . spikes ? touching .   no , no . he was in .  he was in s  he has a class .       i actually gave  the channel u thing ? it 's just i ran the recognizer the speech nonspeech detector on different channels and , it 's just in in this new multi channel format and output , and gave one meeting to liz who wanted to try it for the recognizer as the recognizer had problems with those long chunks of speech , which took too much memory or whatever , and she will try that and i 'm working on it . i hope no . i use some different features but not the basic thing is this base . there is some , as the energy is normalized across channels   but that 's one of the main changes . just use our loudness based things now as they before there were they were some in the log domain and i changed this to the  to no , i changed this to the to the loudness thingy with the how do you call it ? i 'm not with the , i 'm not about the term . i 'll look it up . and say it to you . and  that 's the thing . and i tried t to normalize the features , there 's loudness and modified loudness , within one channel , because they 're , to be able to distinguish between foreground and background speech . and it works quite but , not always .       i  but just put the button on the web page which say "" send me the scripts "" .       god .  burger king ","it 's just i ran the recognizer the speech nonspeech detector on different channels and , it 's just in in this new multi channel format and output , as the recognizer had problems with those long chunks of speech , which took too much memory or whatever , the basic thing is this base . and i tried t to normalize the features , there 's loudness and modified loudness , within one channel , because they 're , to be able to distinguish between foreground and background speech . and it works quite but , not always . ",Speaker mn014 briefly described his efforts to normalize loudness levels across speech channels to distinguish between foreground and background speech. 
Bmr014.B,""" spikes "" , like instantaneous click type spikes , or ?  you could try an experiment and say "" i 'm about to test for spikes "" , and then wiggle the thing there , and then go and when they go to transcribe it , it could , ask them to come and get you . "" come get me when you transcribe this and see if there 's spikes . "" no i 'm just that 'll be that 'll help that 'll help a lot , actually .  i would also guess that as we get more into processing the data and things like that there 'll be more things of interest to him . i don't quite understand how that works , . if we 're not increasing the number of channels .   i see . three wireds work , right ?   i checked them this morning , they should be . sri , really ?   he might have .   jane ? one suggestion and you may already be doing this , but i 've noticed in the past that when i 've gone through transcriptions and in order to build lexicons and things , if you just take all the transcriptions and separate them into words and then alphabetize them , a lot of times just scanning down that list you 'll find a lot of inconsistencies and mis   you already have that ,   cuz a lot of times they 'll appear next to each other , and i in alphabetized lists , they 'll appear next to each other and it makes it easier . that 's great .   right . right .     when for the person who missed "" gobbledy gook "" what did they put ?  good . how it sounds .    boy , they 're moving right along .  are people going to be allowed to bleep out sections of a meeting where they weren't speaking ? that means other people are editing what you say ? i don't know if i like that . far . what when you display it on the web page , what are you showing them ? utterances , or ? and can they bleep within an utterance ? whole utterances .  i know where you 're going . what morgan 's saying is the easier it is , the more is gonna be bleeped . you 're saying the sequence would be more like first adam goes to the contact lists , contacts them via whatever their preferred method is , to see if they want to review the meeting . and then if they don't , you 're done . if they do , then he provides them access to the web site . or a printed out form . only if they want it . it probably leaves it open how we get it to them . sarcasm , how do you indicate sarcasm ? any sub word level thing . no . there were quite a few .   good . having this headset reminds me of like working at burger king no i never did . but i feel like i could now . ",""" spikes "" , like instantaneous click type spikes , or ? we 're not increasing the number of channels . are people going to be allowed to bleep out sections of a meeting where they weren't speaking ? that means other people are editing what you say ? ",
Bmr014.C,"are you are we going ? yu the date 's written in there , and actually if everyone could cross out the r nine next to "" session "" , and write mr eleven . and let 's remember also to make that one 's gets marked as unread , unused . mr eleven . there 's lots of clicking i 'm as i 'm trying to get this to work correctly . i wanna talk a little bit about getting how we 're gonna to get people to edit bleeps , parts of the meeting that they don't want to include . what i 've done far , and i wanna get some opinions on , how to finish it up . really . clicks .  it 's it could be a number of things . it could be touching and fiddling , and the other thing is that it could the fact that it 's on a wired mike is suspicious . it might be a connector .  right . right .  right . it would be a good idea for one of us to like on wednesday , or tuesday send out a reminder for people to send in agenda items .  let me i 'll put that on my spare brain or it will not get done .   weirder things have happened . then actually i was going to say we need to talk about that too .  the new microphones , the two new ones are in . and they are being assembled as we speak , i hope . and i didn't bring my car today 'm gonna pick them up tomorrow . and then the other question i was thinking about is a couple things . first of all , if the other headsets are a lot more comfortable , we should probably just go ahead and get them . we 'll have to evaluate that when they come in , and get people 's opinions on what they think of them . then the other question i had is we should get another wireless . another wireless setup . it 's expensive , but it does seem to be better than the wired . i 'm pretty that you can daisy chain them together what we would do is replace the wired mikes with wireless . we currently have one base station with six wireless mike , possibility of six wireless receivers , and you can chain those together . and we could replace our wired mikes with wireless if we bought another base station and more wireless mikes . and it 's still , it 's fifteen minus six . right ? we could have up to nine . right . and we have five , we 're getting one more . and it 's about nine hundred dollars for the base station , and then eight hundred per channel . right .  'll look into how you daisy chain them and then just go ahead and order them . no , we 're just replacing the wired the two wired that are still working , along with a couple of the wired that aren't working , one of the wired that 's not working , with a wireless . three wireds work ,  right . right . everyone 's battery  we should talk to them about it because i know that sri is also in the process of looking at and what we should try to keep everyone on the same page with that .  they got sa apparent this needs to be bleeped out ? i have no clue . i don't know how much of it 's public . right . right . no , we 're having the them do it . it 's hand soldering it , but i 'm not doing it . they charge right . you 've never seen my hand soldering . but a as i said they 're coming in .    as professionally as you can get it done . it 's just their repair shop . right ? their maintenance people .  and , we 'll see , tomorrow , what it looks like . right , the decision was that jane did not want the transcribers to be doing any of the paperwork . did the all that last week . all the forms are now on the computer . and then i have a bunch of scripts that we 'll read those and let the transcribers use different tools . and want to talk to jane about how we transition to using those . i don't think it 'll take too long . just a matter of a few days i suspect . right . i 've already done five or six sets . if he wanted to , just have a few to start with , he could . and i also have a bunch of scripts that will generate p files and run recognition on them also . we don't have a active one but i 'll make he 's on the list . he 's still taking classes , he may have conflicts . didn't he say his signal processing class was like tuesdays and thursdays ? whatever .  we have about thirty two hours as of , week and a half ago , we probably now have about thirty five hours . that 's including digits . i haven't separated it out have no clue how much of that is digits . of non digits ?  the digits don't take up that much time . nine two , right .  misspelled . right . you don't they could be . how are you doing the how are you doing the acronyms if i say pzm what would it appear on the transcript ?   right .  right . it sounds good . right . have you also been doing spot checks , jane ? good . good . good . right . right . it was a technical term that she didn't recognize , right . obscure ,  ","i wanna talk a little bit about getting how we 're gonna to get people to edit bleeps , parts of the meeting that they don't want to include . the new microphones , the two new ones are in . and they are being assembled as we speak , i hope . first of all , if the other headsets are a lot more comfortable , we should probably just go ahead and get them . we 'll have to evaluate that when they come in , and get people 's opinions on what they think of them . i 'm pretty that you can daisy chain them together what we would do is replace the wired mikes with wireless . we currently have one base station with six wireless mike , and we could replace our wired mikes with wireless if we bought another base station and more wireless mikes . no , we 're just replacing the wired the two wired that are still working , along with a couple of the wired that aren't working , one of the wired that 's not working , with a wireless . we should talk to them about it because i know that sri is also in the process of looking at and what we should try to keep everyone on the same page with that . i don't think it 'll take too long . just a matter of a few days i suspect . we have about thirty two hours that 's including digits . of non digits ? the digits don't take up that much time . how are you doing the acronyms if i say pzm what would it appear on the transcript ? ","Finally, the group discussed legal and procedural issues concerning the provision of transcripts to meeting participants for 'bleeping out' any sections of speech they want excluded from the Meeting Recorder database. The Berkeley Meeting Recorder group discussed recording equipment issues, including the purchase of two additional headsets and the prospect of getting a new base station and a set of wireless microphones to replace those wired microphones currently in use. "
Bmr014.C,"is this anything different than the system you were using before ?  there 's still no knowledge using different channels at the same time . what across all of them .    good . right . the idea is that we need to have we need to provide the transcripts to every participant of every meeting to give them an opportunity to bleep out sections they don't want . 've written a bunch of tools that will generate web pages , with the transcription in it that they can click on them and piece pieces and they can scroll through and read them , and then they can check on each one if they want it excluded . and then , it 's a form , html form , they can submit it and it will end up sending me email with the times that they want excluded . and some of the questions on this is what do we do about the privacy issue . and thought about this a little bit and the best way to do it is every participant will have a password , a single password . each person will have a single password , user name and password . and then each meeting , we 'll only allow the participants who were at that meeting to look at it . and that way each person only has to remember one password .  right , th the fact that you could listen to it over the web is a minor thing that i had already done for other reasons . and that 's a minor part of it , wanted some web interface that people you didn't actually have to send everyone the text . what my intention to do is that as the transcripts become ready , would take them , and generate the web pages and send email to every participant or contact them using the contact method they wanted , and just tell them , "" here 's the web page "" , "" you need a password "" . th question number one is how do we distribute the passwords , and question number two is how else do we wanna provide this information if they want it . that there are a subset of people who will want printouts that we can certainly provide . but certainly i wouldn't want a printout . these are big , and i would much rather be ha be able to just sit and leaf through it . certainly read books by hand . but for something like this , it 's easier to do it on the web . cuz you 're gonna get , if i 'm in a bunch of meetings and i don't wanna get a stack of these . i wanna just be able to go to the web site and visit it as i want . i don't think it 's that much harder than , paper .  no fre for the most for the most frequent case they just say "" it 's and then they 're done . and almost everyone would rather do that by email than any other method . cuz you don't have to visit the web page if you don't want to . that was another thing i had assumed that we didn't need their signature , that it that an email approval was sufficient . but i don't actually know . yes . if someone feels strongly enough about it , then they should be allowed to do that .  the only other choice is that the person would say "" no , don't distribute this meeting , and i would rather they were able to edit out other people then just say "" don't distribute it . but if someone is having a conversation , and you only bleep out one side of it , that 's not sufficient . i don't think because if i object to the conversation . if i say "" we were having a conversation , and i consider that conversation private , "" and i consider that your side of it is enough for other people to infer , i wanna be able to bleep out your side . can certainly provide a printable version if people want it .   think most of the people in the meetings are the former .   right . and that but if they want to print it out that 's alright . everyone in the meeting can access the web . does that mean that i can't use email ? or what ? i don't don't think we can send the text through email because of the privacy issues . giving them , you think a web site to say , "" if you wanna print it out here it is "" , is not sufficient ? i 'm just thinking for people that 's not sufficient for , what the only sufficient thing would be for me to walk up to them and hand it to them . equivalent . that 's right .  no . whole utterances only . and that was just convenience for my sake , that it 's it would end up being fairly difficult to edit the transcripts if we would do it at the sub utterance level . because this way just delete an entire line out of a transcript file rather than have to do it by hand . that 's why i did the web form , because for me that would be my most convenient .  don't see having a few phrases here and there in a meeting being that mu much of a headache , bleeped out .   don't see any way of avoiding that . we have to provi we have promised that we would provide them the transcript and that they can remove parts that they don't like . that the the only question is the problem is if it 's harder for them it 's also harder for me . whereas this web interface , get email , ","we need to provide the transcripts to every participant of every meeting to give them an opportunity to bleep out sections they don't want . if someone feels strongly enough about it , then they should be allowed to do that . ","Finally, the group discussed legal and procedural issues concerning the provision of transcripts to meeting participants for 'bleeping out' any sections of speech they want excluded from the Meeting Recorder database. "
Bmr014.C,"it 's all formatted , it 's all ready to go and just insert it .  to some extent i have to do that anyway because as i said we have to distribute passwords .  but what i 'm saying is that i can't just email them the password because that 's not secure . they have to call me and ask . we do because of privacy . we can't just make it openly available on the web . but the problem with what you 're suggesting is it 's not just inconvenient for them , it 's inconvenient for me . because that means multiple contacts every time for every single meeting every time anyone wants anything . i would much prefer to have all be automatic , they visit the web site if they want to . they don't have to .  think you 're thinking people are going to arbitrarily start bleeping and don't think that 's gonna happen . it seems to me that sending them email , saying "" if you have an o reply to this email and say if you have a problem with it contact me and i 'll give you a password "" , seems like is a perfectly , reasonable compromise . and if they want a printout they can print it out themselves . having it . the in the consent form is right in there if anyone wants to look at it ,  d you want me to grab one ? but you 're wired aren't you ? "" if you agree to participate you 'll have the opportunity to have anything ex anything excised , which you would prefer not to have included in the data set . "" "" once a transcript is available we will ask your permission to include the data in the corpus for the r larger research community . there again you will be allowed to indicate any sections that you 'd prefer to have excised from the database , and they will m be removed both from the transcript and the recording . "" it the one question is definitely clear with anything as opposed to just what you said . they just have to make that it is available to them . right . it 's just a check box next to the text , it 's not any fun but they won't get that feedback . all no because it doesn't automatically bleep it at the time . it just sends me right . it just sends me the time intervals . and then at some point i 'll incorporate them all and put bleeps . don't wanna have t ha do that yet until we actually release the data because then we have to have two copies of every meeting and we 're already short on disk space . wanna keep the times until we actually wanna release the data and then we bleep it . since you seem to feel heart strongest about it , would you like to do the first pass ?  i don't think because thi th they 're signing here that they 're agreeing to the paragraph which says "" you 'll be given an opportunity . "" and don't think they need another signature . right . guess i probably should at the minimum , think about how to present it in a printed form . i 'm not really what 's best with that . the problem is a lot of them are really short , and don't necessarily wanna do one per line . but i don't know how else to do it .  think actually my opinion probably is that the only time someone will need to listen to it is if the transcript is not good . if there are lots of mumbles and parentheses and things like that . right . that was all mumbled ? microsoft is transcribers . they 're gonna hate this meeting . actually liz will like it . but . that 's right .   that would be good to get , definitely . just for corrections . in terms of password distribution , phone is really the only way to do it , phone and in person . or mail , physical mail . any sub wor  you could do it with pgp or things like that but it 's too complex . you probably won't listen to it . how about them energy crises . done ? shall we do digits ? did find a bunch we should count out how many more digits to forms do we have back there ? that 's what i f i was going through them all and i found actually a lot filed in with them , that were blanks , that no one had actually read . and we still have more than we did . we have a few more digits before we 're done .  i 'd like a burger with that , do you want fries with that ? and ","the consent form is right in there if anyone wants to look at it , "" if you agree to participate you 'll have the opportunity to have anything ex anything excised , which you would prefer not to have included in the data set . "" "" once a transcript is available we will ask your permission to include the data in the corpus for the r larger research community . there again you will be allowed to indicate any sections that you 'd prefer to have excised from the database , and they will m be removed both from the transcript and the recording . "" it just sends me the time intervals . and then at some point i 'll incorporate them all and put bleeps . since you seem to feel heart strongest about it , would you like to do the first pass ? ","Finally, the group discussed legal and procedural issues concerning the provision of transcripts to meeting participants for 'bleeping out' any sections of speech they want excluded from the Meeting Recorder database. "
Bmr014.D,you talking about david gelbart ? he 's taking two twenty five a which is now .  not really . no . my project is going along but i 'm really just here to fill the project the overall progress . i don't really have anything specific to talk about .  it ,,
Bmr014.E,"alright .  it is must be february fifteenth .   we didn't have a front end meeting today .     agenda . any agenda items today ?  audio monitoring , jane .   were this a professional audio recording , what we would do what you would do is in testing it is , you would actually do all this wiggling and make that things are not giving that performance . and if they are , then they can't be used .  let 's see . would like to have a discussion about where we are on recording , transcription where we are on the corpus . and then the other thing which i would like to talk about which is a real meta quest , deal is , agendas . 'll start with that actually . andreas brought up the fact that he would kinda like to know , if possible , what we were gonna be talking about because he 's peripherally involved to this point , and if there 's gonna be a topic about discussion about something that he strongly cares about then he would come and part of his motivation with this is that he 's trying to help us out , in the because of the fact that the meetings are tending to become reasonably large now on days when everybody shows up and he figures he could help that out by not showing and i 'm help out his own time . by not showing up if it 's a meeting that he 's in order i 'd that this is a wish on his part . it 's actually gonna be hard because it seems like a lot of times things come up that are unanticipated and but we could try anyway , do another try at coming up with the agenda at some point before the meeting , say the day before .  you wanna volunteer to do that ?  alright we 'll send out agenda request .  i have to tell you for the for the admin meeting that we have , lila does that every time before an admin meeting . and she ends up getting the agenda requests ten minutes before the meeting . but but . but we can try . it 'll work .   actually it this brings up another topic which is we 're done with that topic . the other topic i was thinking of was the sta status on microphones and channels , and all that .  why don't we do that . how many channels do you get to have in a wireless setup ?  let 's see we and right now we can have up to six .   the only beyond the mike the cost of the mikes the only thing is the base station that 's nine hundred dollars . we should do it .    we found  but we 've had more problems with that . and that bypasses the whole jimbox thing and all that . and we seem to have a reliable way of getting the data in , which is through the ra sony radio mikes , as long as we 're conscious about the batteries . that seems to be the key issue .  that 's the only thing with them . but the quality seems really good and heard from uw that they 're very close to getting their , setup purchased . they 're they 're buying something that you can just buy off the shelf .  i don't know . probably we shouldn't talk about funding  but anyway there 's there 's other activities that are going on there and and nist and uw .  but thin that at least the message we can tell other people is that our experience is quite positive with the sony , radio mikes . now the one thing that you have said that actually concerns me a little is you 're talking about changing the headsets meaning changing the connector , which means some hand soldering right ? no ?   nothing against you and your hand soldering but that 's being done professionally and   it could if they do a lot of it , it 's we 'll see what it 's like . that tha that can be quite good . th this  good .  let 's go with that .   dave isn't here but he was going to start working on some things with the digits . he 'll be interested in what 's going on with that .  was the decision last time was that the transcribers were going to be doing with the digits as has that started , or is that ?  anyway anyway we have at least one user for the digits once they get done , which will be dave . he might be asking right .  is dave i don't know if dave is on the list , if he 's invited to these meetings ,  if he knows . i don't know . it 's  this might be a conflict for him .        that 's why we 're not seeing him .  transcriptions , beyond the digits , where we are , and on . and the recordings also , just where we are .  and that 's how much of that is digits ? it 's that 's including digits , right ?   anyway there 's at least probably thirty hours , of there 's got to be more than thirty hour i it couldn't of non digits .    the main track that you 're working with is elev eleven hours ? is that right ?  is that including digits ?  let 's say roughly ten hours or of it 's probably more than that but with of non digits .  i see . i see .   what 's the deal with your  i see . right .    what are some of the other features ? besides the energy ? you said you 're trying some different features , cu cube root ?  fletcher munson ? no .  alright .     ","audio monitoring , jane . would like to have a discussion about where we are on recording , transcription where we are on the corpus . the other topic i was thinking of was the sta status on microphones and channels , and all that . how many channels do you get to have in a wireless setup ? heard from uw that they 're very close to getting their , setup purchased . was the decision last time was that the transcribers were going to be doing with the digits as has that started , or is that ? transcriptions , beyond the digits , where we are , and on . there 's got to be more than thirty hour ","The Berkeley Meeting Recorder group discussed recording equipment issues, including the purchase of two additional headsets and the prospect of getting a new base station and a set of wireless microphones to replace those wired microphones currently in use. "
Bmr014.E,"let 's see . the were you done with the transcription part ? guess the next thing is this bleep editing .  i can't help but wonder if this is little more elaborate than is needed . if people have  for me i would actually want to have some pieces of paper that had the transcription and i would flip through it . and then if it was i 'd say "" it 's . and , i mean it depends how this really ends up working out , but my thought was that the occasion of somebody wondering whether something was or not and needing to listen to it was gonna be extremely rare .  that 's what i was saying is that if you just say "" here is a here is "" this it sounds paleolithic but thought if you handed them some sheets of paper , that said , "" here 's what was said in this transcription is it with you ? and if it is , here 's this other sheet of paper that you sign that says that it 's . and then they 'd hand it back to you . you find it easier to go through a large how do you read books ? really ? it going to a web site is easy , but flipping through a hundred pounds a hundred pages of is not easy on the web . really ? here 's the way i was imagining it , and 'm wrong , but the way i imagined it was that the largest set of people is gonna go "" didn't say anything funny in that meeting just go ahead , where 's the release ? "" and then there 'll be a subset of people , right ? there 's think of who it is we 've been recording mostly . there 'll be a subset of people , who will say i really would like to see that . "" and for them , the easiest way to flip through , if it 's a really large document , unless you 're searching . searching , should be electronic , but if you 're not if you provide some search mechanism you go to every place they said something like that , but see then we 're getting more elaborate with this thing . if you don't have search mechanisms you just have this really , really long document , whenever i 've had a really , really long document that it was sitting on the web , i 've always ended up printing it out . it 's you 're not necessarily gonna be sitting at the desk all the time , you wanna figure you have a train ride , and there 's all these situations where i this is how i was imagining it , anyway . and then i figured , that out of that group , there would be a subset who would go "" 'm really not about this section here , "" and then that group would need it s it seems like i if i 'm right in that , it seems like you 're setting it up for the most infrequent case , rather than for the most frequent case . that now we have to worry about privacy , we have to worry about all these passwords , for different people  that 's true .  we don't need their signature . an email is alright . don't know about that . but th what they signed in the consent form , was something that said you can use my voice . right ?  but that 's our decision then . right ? it is . i see . if that 's what it said . mean it 's also a mixture of people , some people are r do their work primarily by sitting at the computer , flipping around the web , and others do not . others would consider it this set of skills that they would have to gain .  it depends on what meetings . in the meetings far , but we 're trying to expand this , right ? actually think that paper is the more universal thing . no , we have to be able to print it out . it 's not just if they want to print it out .  i th we there was this no . right . certainly for everybody who 's been in the meetings far it would be sufficient . i 'm just wondering about there 's another aspect to this which is part of why this is bothering me . you 're really trying very hard to make this as convenient as possible for people to do this . i understand . that 's the bad idea . see because you 're gon you 're really . you 're gonna end up with all these little patchy things , whereas really what we want to do is have the bias towards letting it go . because nob you know it there was a one or twi once or twice , in the re in the meetings we 've heard , where somebody said something that they might be embarrassed by , but overall people are talking about technical topics . nobody 's gonna get hurt . nobody 's being l libeled . this is this we 're covering we 're playing the lawyer 's game , and we 're playing we 're we 're looking for the extreme case . if we really orient it towards that extreme case , make it really easy , we 're gonna end up encouraging a headache . that that 's i 'm psyching myself out here , i 'm trying to but that 's it 's but i and it really depends on what research you 're doing . ","the transcription part ? guess the next thing is this bleep editing . but the way i imagined it was that the largest set of people is gonna go "" didn't say anything funny in that meeting just go ahead , where 's the release ? "" there 'll be a subset of people , who will say i really would like to see that . "" and for them , the easiest way to flip through , if it 's a really large document , unless you 're searching . searching , should be electronic , ","Finally, the group discussed legal and procedural issues concerning the provision of transcripts to meeting participants for 'bleeping out' any sections of speech they want excluded from the Meeting Recorder database. "
Bmr014.E,"some researchers who are gonna be working with this corpus years from now are really gonna be cursing the fact that there 's a bunch of in there that 's missing from the dialogue . it depends on the research they 're doing , but it might be , it might be really a pain . and , where it 's really gonna hurt somebody , in some way the one who said it or someone who is being spoken about , we definitely want to allow the option of it being bleeped out . but i really think we wanna make it the rare incidence . and i am just a little worried about making it easy for people to do , and much fun ! that they 're gonna go through and bleep out and they can bleep out they don't like too , right from somebody else , as you say , didn't like what he said . ""  no , i don't you 've talked me into that , but think that we should make it harder to do . you don't give them access to the web interface unless they really need it .  i 'm this is a s a way out of it . you 've provided something that 's useful for you to do handle , and useful for someone else if they need it . but the issue of privacy and ease and forth should be that they get access to this if they really need it . right . w there 's there y but you don't necessarily have to distribute passwords is what i 'm saying .  no , no . but you aren't necessarily giving them right . but we don't even necessarily need to end up distributing passwords no , no . you 're missing the point . we 're trying i we 're trying to make it less of an obvious just l fall off a log , to do this . right ? th what i would see , is that first you contact them and ask them if they would like to review it for to check for the not just for fun ,  but to check this for things that they 're worried about having said or if they 're willing to just send an approval of it , at from their memory . and , and we should think carefully actually we should review go through how that 's worded ,  then , if someone wants to review it , and i know you don't like this , but i 'm offering this as a suggestion , is that we then give them a print out . and then if they say that "" i have a potential problem with these things , "" then , you say "" you might wanna hear this in context to s think if you need that , "" you issue them a password , i in the i know you 'd prefer it , but the proble we have there 's a problem with it . you can go too far in that direction , and you need to find somewhere between because   having access to it doesn't necessarily mean , that having it right ? it just means they have the right to have it .  don't wanna fool them , meant that e every ev any time you say anything to anyone there is bias that is presented , right ? of and  i no that it tha that 's right . i  wh have an idea that may be sat may satisfy both you and me in this which is , it 's a it we just go over carefully how these notes to people are worded . just want it to be worded in such a way where it gives the strong impre it gives very , nothing hidden , v very strongly the bias that we would really like to use all of these data . that we really would rather it wasn't a patchwork of things tossed out , that it would be better for , our , field if that is the case . but if you really think something is gonna and i don't think there 's anything in the legal aspects that is hurt by our expressing that bias . and then my concern about which you might be right , it may be it was just paranoia on my part , but people just see i 'm @ @ worried about this interface much fun that people start bleeping out just as just because they can .  don't know . i had fun when you played me something that was bleeped out .  i they won't ? good . you haven't made it much fun . good .     alright , think if we have if i again let 's circulate the wording on each of these things and get it right , but  fair enough . turn about is fair play ,  i 'm i 'm about it with one of my background processes and i it 's it 's fine to do the email .   and and furthermore i it 's now fairly routine in a lot of arrangements that i do with people on contracts and forth that if it 's that thing where you 're saying agree , we want eighty hours of this person at such and such amount , and i agree that 's "" if it 's a follow up to some other agreement where there was a signature it 's often done in email now it 's     liz will like it . we had a pretty strong disagreement going there .  but it the some something might sometime , and they if it 's something that they said , they might i you might be very accurate in putting down what they actually said , but , when they hear it , themselves , they may hear something different because they they meant . no , i 'm serious . the the ","and , where it 's really gonna hurt somebody , in some way the one who said it or someone who is being spoken about , we definitely want to allow the option of it being bleeped out . but i really think we wanna make it the rare incidence . and i am just a little worried about making it easy for people to do , just want it to be worded in such a way where it gives the strong impre it gives very , nothing hidden , v very strongly the bias that we would really like to use all of these data . that we really would rather it wasn't a patchwork of things tossed out , again let 's circulate the wording on each of these things and get it right , ",
Bmr014.E,"we might get some feedback from people that such and such was , not really what i said . but ,    but you can't dep most people will not wanna take the time to do that , though . and they have to but if you were at a meeting , and you don't think , at least , that you said anything funny and the meeting was about , some funny thing about semantics or   you would think it would be rare , we 're not talking about the energy crisis people have  we 're done . actually , i was gonna di did you have anything n that 's going on , or  that 's fine . didn't wanna go by you , if you had something . you don't have anything to say . nah . transcribers , he was rattling the b marbles in his brain back and forth just then this   ",,
Bmr014.F," that sounds like a spy code . i wanna ask about some aud audio monitoring on some of the some of the equipment . in particular , the that 's just what i wanna ask . ba based on some of the tran in listening to some of these meetings that have already been recorded there are sometimes big spikes on particular things , and in pact this one i 'm talking on is one of the ones that showed up in one of the meetings ,      and i don't the e electronics is but .    then we don't really have to talk about that as an i take that off the agenda . that  good . i 'm wondering if he were to just , specify particular topics ,  we 'd be able to meet that request of his a little more .   it would be to use his interface and i was going to meet with him today about that .  he has a set up that they it w it will be efficient for them to do that .  i don't tend to get an invitation myself for them even .  should we call him ? is he d is he definitely not available today ? should i call his office and see ? he wasn't there at cof  yes .    should we don't wan wanna do the recording status first , or ? and the transcribers h i , don't have the exact numbers , but it would come to about eleven hours that are finished transcribing from them right now . the next step is to that i 'm working on is to insure that the data are clean first , and then channelized . what by clean is that they 're spell checked , that the mark up is consistent all the way throughout , and also that we now incorporate these additional conventions that liz requested in terms of in terms of having a s a systematic handling of numbers , and acronyms which i hadn't been specific about . i they 'll say ninety two "" . and how you could e exactly . if you just say "" nine two "" , the there are many s ways that could have been expressed . an and had them a certain number of them did put the words down , but now we have a convention which also involves having it followed by , a gloss th and things . you 're talking about the type token frequency listings , and i use those too . y just on each line there 's a one word right ? it 's one token from the corpus . those are e extremely efficient and i agree that 's a very good use of it . that 's a way that 's the spell check does that but in addition yes , that 's exactly the strategy i wanna do in terms of locating these things which are colloquial spoken forms which aren't in the lexicon . exactly . and then you ca then you can do a s  i agree . that 's a very good suggestion . and that was that 's my strategy for handling a lot of these things , in terms of things that need to be glossed . i didn't get to that point but there are numbers , then there are acronyms , and then there 's a he she wants the actually a an explicit marker of what type of comment this is , curly b inside the curly brackets i 'm gonna put either "" voc "" for vocalized , like cough or like laugh or whatever , "" nonvoc "" for door slam , and "" gloss "" for things that have to do with if they said a s a spoken form with this m this pronunciation error . i already had that convention but i haven't been asking these people to do it systematically cuz it most ha most efficiently handled by by a filter . that was what i was always planing on . that , you get a whole long list exactly what you 're saying , you get a whole list of things that say "" curly bracket laugh curly bracket "" , then y it 's you risk less error if you handle it by a filter , than if you have this transcriber ch laboriously typing in voc space , man many ways that error prone . 'm going to convert that via a filter , into these tagged subcategorized comments , and same thing with we see you get a subset when you do what you 're saying , you end up with a s with you 're collapsing across a frequency you just have the tokens and you can have a filter which more efficiently makes those changes . but the numbers and acronyms have to be handled by hand , because , mean , jus now timit 's clear and plp is clear but there are things that are not known , in or have variant u uses like the numbers you can say "" nine two "" or you can say "" ninety two "" , and i 'd handle the numbers individually . it would be separate the letters would be separated in space and potentially they 'll have a curly bracket thing afterwards e but i 'm not if that 's necessary , clarifying what it is , gloss of whatever . i don't know if that 's really necessary to do that . it 's a thing to do because of it then indicating this is a step away from i indicating that it really is intentional that those spaces are there , and indicating why they 're there to indicate that it 's the enumerated , or i it 's not a good way of saying but it 's the specific way of stating these letters . and anyway , the clean those are those things ","in listening to some of these meetings that have already been recorded there are sometimes big spikes on particular things ,   should we don't wan wanna do the recording status first , or ? but it would come to about eleven hours that are finished transcribing from them right now . the next step is to that i 'm working on is to insure that the data are clean first , and then channelized . what by clean is that they 're spell checked , that the mark up is consistent all the way throughout , and also that we now incorporate these additional conventions that liz requested in terms of in terms of having a s a systematic handling of numbers , and acronyms which i hadn't been specific about . there are numbers , then there are acronyms , and then there 's a he she wants the actually a an explicit marker of what type of comment this is , curly b inside the curly brackets i 'm gonna put either "" voc "" for vocalized , like cough or like laugh or whatever , "" nonvoc "" for door slam , and "" gloss "" for things that have to do with if they said a s a spoken form with this m this pronunciation error . 'm going to convert that via a filter , into these tagged subcategorized comments , but the numbers and acronyms have to be handled by hand , the letters would be separated in space ","Speaker fe008 presented the current status on transcriptions, and explained procedures for cleaning up transcripts and ensuring they conform with set conventions. "
Bmr014.F,"and then channelized is to then get it into this multichannel format . and at that point then it 's ready for use by liz and don . but that 's been my top priority beyond getting it tanel channelized , the next step is to work on tightening up the boundaries of the time bins . and thilo had a e a breakthrough with this last week in terms of getting the channel based speech nonspeech segmentation up and running and i haven't been able to use that yet cuz i 'm working s re this is my top priority get the data clean , and channelized . yes . you see that 's part of the cleaning process . i spent actually have a segment of ten minutes that was transcribed by two of our transcribers , and i went through it last night , it 's almost spooky how similar these are , word for word . and there are some differences in commas cuz commas i left them discretion at commas . and because it 's not part of our st of our ne needed conventions . and and they 'll be a difference in commas , but it 's word by word the same , in huge patches of the data . and i have t ten minute stretch where show that . and sometimes it turns out that one of these transcribers has a better ear for technical jargon , and the other one has a better ear for colloquial speech . the one i the colloquial speech person picked up "" gobbledy gook "" . and the other one didn't . and on this side , this one 's picking up things like "" neural nets "" and the one that 's good on the sp o on th the vocabulary on the colloquial didn't . it was an interesting approximation , put in parentheses , cuz i have this convention that , i if they 're not what it was , they put it in parentheses . they tried to approximate it , but it was it was spelled gabbl yes . more of an attempt to it was very clear to her that these the a this was a sound these are the sounds , but  but she knew that she didn't know it . it was a technical ter exactly . but she even though her technical perception is just really you 've i 'm tempted to ask her if she 's taken any courses in this area or if she 's taken cognitive science courses then cuz "" neural nets "" and she has some things that are downsampled "" , she got that right . and some of these are rather unexpected . but ch ten solid ch s chunk of ten solid minutes where they both coded the same data . and yes exactly . and that 's part of this eleven hours . yes it is .  it 'd be more than that because i my recollection is the minutes that da digits don't take more than half a minute . per person . but the total set that i gave them is twelve hours of tape , but they haven't gotten to the end of that yet . they 're still working some of them are two of them are still working on completing that .  they are . they 're very efficient . there 're some who have more hours that they devote to it than others .  i have one question . are you thinking that the person would have a transcript and go strictly from the transcript ? because i do think that there 's a benefit to being able to hear the tone of voice and the  the other thing too is it seems like go ahead . i also  the i agree that the consent forms were i cons agree with what adam 's saying , that the consent form did leave open this possibility that they could edit things which they found offensive whe whether they said them or didn't say them . and the other thing is from the standpoint of the l i 'm not a law lawyer , but it strikes me that we wouldn't want someone to say "" yes , i was a little concerned about it but it was too hard to access "" . think it 's to have this facility to listen to it . now in terms of like editing it by hand , it 's i some people would find that easier to specify the bleep part by having a document they edited . but it seems to me that sometimes if a person had a bad day , and they had a tone in their voice that they didn't really like , it 's to be able to listen to it and be that was that 's true .   cuz you could send it through email you 're thinking . good . for security ? good . good point . you could mail it to them . get an a mailing address . but it 's easier to drop in the box . that 's interesting . much fun . guess    not everyone gets a password , unless they ask for it .  i 'm also concerned about the spirit of the informed consent thing . cuz if they feel that it 's i th if it turns out that something gets published in this corpus that someone really should have eliminated and didn't detect , then it could have been because of their own negligence that they didn't pursue that next level and get the password and do that , but they might be able to argue "" it was cumbersome , and i was busy and it was gonna take me too much time to trace it down "" . it could that the burden would come back onto us . 'm a little bit worried about making it harder for them , from the legal standpoint .  ","the next step is to work on tightening up the boundaries of the time bins . and thilo had a e a breakthrough with this last week in terms of getting the channel based speech nonspeech segmentation up and running actually have a segment of ten minutes that was transcribed by two of our transcribers , and i went through it last night , it 's almost spooky how similar these are , word for word . ",
Bmr014.F,"or we could print it up for them , we could offer that but there 's another aspect to that and that is that in the informed consent form , my impression is that they that we offered them at the very least that they definitely would have access to the transcript . and i ha i don't know that there 's a chance of really skipping that stage . thought that you were misinterpreted what you said but it 's giving it to them .  alright . fine .  fair enough . sh could i 'm closer . i could  that is true . i don't know  know . that 's true .   that 's more open than i realized . tha that 's true . that 's more severe , but the next one says the transcript will be around . and it doesn't really say we 'll send it to you , or wi it 'll be available for you on the web , or anything . at least it more often .  it means also we don't have to g to give it to them . like morgan was saying they it 's available to them if they ask for it . good . great . great , great .  i agree . al also it ther there is this other question , the legal question that adam 's raised , about whether we need a concrete signature , or email c i suffices or whatever and i don't know how that works . i there 's something down there about "" if you agree to ""  fine . good .  great .  s i also have this it 's you have it viewab her hearable on the web for those who might wonder about the non nonverbal side , agree that our bias should be as expressed here , and but it 's that a person could check . cuz sometimes you the words on a on the page , come out soun sounding different in terms of the social dynamics if they hear it . and i realize we shouldn't emphasize that people shouldn't borrow trouble . what it comes down to but or what if there was an error in the transcript that didn't get detected and there was a whole segment a against some personal i th exactly or even there was a line about how "" bill gates duh duh . "" but it was all the words were all visible , but they didn't end up i some there was a slip in the transcript . that 's true .  don't know . we 're assuming that the transcript is a close enough approximation and that my double checking will be close to perfect that it that nothing will slip by .  i don't know how to notate that . that 's right . that 's right .  or if for leave it on their voice mail . just realized something , which is of e th this question about the the possible mismatch of  and actually also the lawyer saying that we shouldn't really have them have the people believing that they will be cleared by our checks .  it 's like i in a way it 's to have the responsibility still on them to listen to the tape and hear the transcript , to have that be the fair enough . and they 're s they 're absorbing the responsibility themselves . it 's not good . it is true that tec that the content is technical , i and and we 're not having these discussions which when i listen to these things , i don't find things that are questionable , in other people 's speech or in my own . just it should be very rare .   did you do that ? ",,
Bmr015.A,"    it 's just , how many t u how many times you crash in a day . first time in the day ,   that 's great .  do we have an agenda ? liz and andreas can't sh can't can't come . they won't be here . right , was just gonna talk briefly about the nsf itr .  and then , you have i won't say much , but but then , you said wanna talk about digits ? right . if we we shouldn't add things in just to add things in . i 'm actually pretty busy today , if we can we a short meeting would be fine . but there 's often things where people do false starts . i 've done it , where i say a it 's five or six times out of thousands ? four thousand ? i would , tak do the easy way ,  it 's kinda wh who knows what studies people will be doing on speaker dependent things and think having it all the speakers who we had is at least interesting . that 's a couple hours of , speech , probably . which is a reasonable test set . i see . and the decision here , was to continue with the words rather than the numerics . or neither . but it 's just two thing ways that you can say it . right ?  that 's the only thought i have because if you t start talking about these , tr she 's trying to get at natural groupings , but it there 's nothing natural about reading numbers this way . if you saw a telephone number you would never see it this way .   she 's right . it 's a different problem . it 's a it 's an interesting problem we 've done with numbers before , and sometimes people if you say s "" three nine eight one "" sometimes people will say "" thirty nine eighty one "" or "" three hundred eighty nine one "" , or i don't think they 'd say that , but but th no but  th thirty eight ninety one is probably how they 'd do it . but i see .  we 're probably gonna be collecting meetings for a while and if we decide we still wanna do some digits later we might be able to do some different ver different versions , but this is the next suggestion ,   let me , get my short thing out about the nsf . i sent this actually this is little side thing . i sent to what we had , in some previous mail , as the right joint thing to send to , which was "" m mtg rcdr hyphen joint "" . but then i got some funny mail saying that the moderator was going to   no , th i got , little excited notes from mari and jeff and on , it 's   right . i see . anyway , everybody here are y are you are on that list , right ? you got the note ?   this was , a , proposal that we put in before on more higher level , issues in meetings , from higher level from my point of view . and , meeting mappings , and , is i for it was a proposal for the itr program , information technology research program 's part of national science foundation . it 's the second year of their doing , these grants . they 're they 're a lot of them are some of them anyway , are larger grants than the usual , small nsf grants , and . they 're very competitive , and they have a first phase where you put in pre proposals , and we , got through that . and th the next phase will be we 'll actually be doing a larger proposal . and i 'm i hope to be doing very little of it . and which was also true for the pre proposal ,  there 'll be bunch of people working on it .  april ninth , it 's about a month .  tomorrow . march second , i said . that 's amazing you showed up at this meeting !   my favorite is was when one reviewer says , "" this should be far more detailed "" , and the nex the next reviewer says , "" there 's way too much detail "" .   we 'll see . there 'll be something useful . and , do anything about the numbers ? i i should go back and look . i didn't i don't think that 's true . we 'll have to see what the numbers are .  but they have to weed out enough that they have enough reviewers . they didn't r weed out as much as usual , but it 's usually a pretty but it it 's certainly not i 'm that it 's not down to one in two of what 's left . i 'm it 's , there 's different numbers of w awards for different size they have three size grants . this one there 's ,  see the small ones are less than five hundred thousand total over three years and that they have a fair number of them .  and the large ones are ,  boy , i forget , more than ,  more than a million and a half , more than two million like that . and we 're in the middle middle category . we 're ,  i forget what it was . but , i don't remember , but it 's pr probably along the li i could be wrong on this but probably along the lines of fifteen or that they 'll fund , or twenty . when they do how many they funded when they f in chuck 's , that he got last year ?  they fund they    ","right , was just gonna talk briefly about the nsf itr . that 's a couple hours of , speech , probably . and the decision here , was to continue with the words rather than the numerics . or neither . but it 's just two thing ways that you can say it . she 's trying to get at natural groupings , but it there 's nothing natural about reading numbers this way . we 're probably gonna be collecting meetings for a while let me , get my short thing out about the nsf . this was , a , proposal that we put in before on more higher level , issues in meetings , is i for it was a proposal for the itr program , it 's the second year of their doing , these grants . they 're very competitive , and they have a first phase where you put in pre proposals , and we , got through that . and th the next phase will be we 'll actually be doing a larger proposal . they have three size grants . and we 're in the middle middle category . ","The group also discussed a proposal for a grant from the NSF's ITR (Information Technology Research) program, transcriptions, and efforts by speaker mn005 to detect speaker overlap using harmonicity-related features. "
Bmr015.A,"last time they just had two categories , small and big , and this time they came up with a middle one , it 'll there 'll be more of them that they fund than of the big .  it i none of it will go for those yachts that we 've talking about .  no , it 's u it it 's extending the research , right ? because the other  the other things that we have , been working on with , the c with communicator especially with the newer things with the more acoustically oriented things are lower level . and , this is dealing with , mapping on the level of , the conversation of mapping the conversations to different planes . but , it 's all that none of us are doing right now , or none of us are funded for , it 's it would be new . there 's evenings , and there 's weekends , and there would be new hires , and there would be expansion , but , also , there 's always for everybody there 's always things that are dropping off , grants that are ending , or other things that are ending ,  there 's a continual need to bring in new things . but there definitely would be new , students , and forth , both at uw and here . not clear yet . not clear yet . we got we have two of them are two in the c there 're two in the class already here , and then and , then there 's a third who 's doing a project here , who , but he won't be in the country that long , and , another will end up . actually there is one other guy who 's looking that 's that guy , jeremy ? anyway , that 's all i was gonna say is that 's that 's and we 're sorta preceding to the next step , and , it 'll mean some more work , in march in getting the proposal out , and then , it 's , we 'll see what happens . the last one was that you had there , was about naming ? since we have such a short agenda list wi i will ask how are the transcriptions going ?   i 'm a little confused . that one of the reason we thought we were much faster than , the other transcription , thing was that we were using the mixed file .        think it 's a short meeting . you 're you 're still in the midst of what you 're doing from what you described last time , i assume , and       i 'd like to talk with you about it . if if , if i don't have enough time and y you wanna discuss with someone else some someone else besides us that you might want to talk to , might be stephane . and thilo ,  but i see . that 's wh    i 'd hafta look at that and think about it . it 's it 's i haven't worked with that either 'm not the way the simple minded way i suggested was what chuck was just saying , is that you could make a sieve . y you actually say that here is let 's hypothesize that it 's this frequency or that frequency , and , you could use some other cute methods to , short cut it by making some guesses , but i would , you could make some guesses from , from the auto correlation but then , given those guesses , try ,  only looking at the energy at multiples of the of that frequency , and see how much of the take the one that 's maximum . call that the but of all the harmonics of that . no . to get the pitch , yes .  that the this is for , a ,   that 'd be good . but , but i don't know that you need to but i don't need if you need to get rid of it . that 'd be but i don't know if it 's ess if it 's essential . cuz the main thing is that , you 're trying wha what are you doing this for ? you 're trying distinguish between the case where there is , where there are more than where there 's more than one speaker and the case where there 's only one speaker . if there 's more than one speaker ,  guess you could you 're you 're not distinguished between voiced and unvoiced , i if you don't care about that see , if you also wanna just determine if you also wanna determine whether it 's unvoiced , then you want to look at high frequencies also , because the f the fact that there 's more energy in the high frequencies is gonna be an ob obvious cue that it 's unvoiced . but , but , other than that as far as the one person versus two persons , it would be primarily a low frequency phenomenon . and if you looked at the low frequencies , yes the higher frequencies are gonna there 's gonna be a spectral slope . the higher frequencies will be lower energy . but what . that 's w  but don't think you can you 're not gonna be able to look at every frame , mean really thought that the best way to do it , and i 'm speaking with no experience on this particular point , but , my impression was that the best way to do it was however you 've used instantaneous frequency , whatever . however you 've come up you with your candidates , you wanna see how much of the energy is in that as coppo as opposed to all of the all the total energy . and , if it 's voiced , ","it 's extending the research , this is dealing with , mapping on the level of , the conversation of mapping the conversations to different planes . there would be new hires , and there would be expansion , and , it 'll mean some more work , in march in getting the proposal out , the last one was that you had there , was about naming ? since we have such a short agenda list wi i will ask how are the transcriptions going ? you could make some guesses from , from the auto correlation but then , given those guesses , try , only looking at the energy at multiples of the of that frequency , take the one that 's maximum . you 're trying distinguish between the case where there is , where there are more than where there 's more than one speaker and the case where there 's only one speaker . other than that as far as the one person versus two persons , it would be primarily a low frequency phenomenon . and if you looked at the low frequencies , yes the higher frequencies are gonna there 's gonna be a spectral slope . the higher frequencies will be lower energy . ","Topics discussed by the Berkeley Meeting Recorder group included the status of the first test set of digits data, naming conventions for files, speaker identification tags, and encoding files with details about the recording. The group also discussed a proposal for a grant from the NSF's ITR (Information Technology Research) program, transcriptions, and efforts by speaker mn005 to detect speaker overlap using harmonicity-related features. "
Bmr015.A,"you do need a voiced unvoiced determination too . but if it 's voiced , and the , e the fraction of the energy that 's in the harmonic sequence that you 're looking at is relatively low , then it should be then it 's more likely to be an overlap . but you 're looking a y you 're looking at let 's take a second with this .  you 're looking at f at the phase derivative ,  in , what domain ? this is in bands ? or just overall and you just take the instantaneous frequency ?   right .  but the instantaneous frequency , wouldn't that give you something more like the central frequency of the of the where most of the energy is ? if you does i does it why would it correspond to pitch ?    you scale you s you do a scaling along that axis according to instantaneous it 's a kinda normalization .   i see .   guess i 'm not following it enough . i 'll probably gonna hafta look at the paper , but which i 'm not gonna have time to do in the next few days , but i 'm curious about it .   i don't know think it 'd be ideal . we see , we 're dealing with real speech and we 're trying to have it be as real as possible and breaths are part of real speech .  it is but it is if you record it .  if it gets right . if it gets in the way of what somebody is doing with it then you might wanna have some method which will allow you to block it , but you it 's real data . you don't wanna b but you don't if s if there 's a little bit of noise out there , and somebody is talking about something they 're doing , that 's part of what we accept as part of a real meeting , even and we have the f the fan and the in the projector up there , and , this is it 's this is actual that we wanna work with .     wh what what if you put it in but didn't put the boundaries ? you just know it 's between these other things , right ? mean i 'm think if it 's too hard for us to annotate the breaths per se , we are gonna be building up models for these things and these things are somewhat self aligning , if we i if we say there is some thing which we call a "" breath "" or a "" breath in "" or "" breath out "" , the models will learn that thing . but you do want them to point them at some region where the breaths really are .  i there is there 's this dynamic tension between marking everything , as and and marking just a little bit and counting on the statistical methods . the more we can mark the better . but if there seems to be a lot of effort for a small amount of reward in some area , and this might be one like this although i 'd be interested to h get input from liz and andreas on this to see if they cuz they 've they 've got lots of experience with the breaths in , their transcripts . actually yes they do , but we can handle that without them here . but but , you were gonna say something about that sounds like a reasonable compromise .  u i wanted to comment a little more just for clarification about this business about the different purposes . see , in a way this is a really key point , that for speech recognition , research ,  e a it 's not just a minor part . the would say the core thing that we 're trying to do is to recognize the actual , meaningful components in the midst of other things that are not meaningful . it 's critical it 's not just incidental it 's critical for us to get these other components that are not meaningful . because that 's what we 're trying to pull the other out of . that 's our problem . if we had nothing if we had only linguistically relevant things if we only had changes in the spectrum that were associated with words , with different spectral components , and , we didn't have noise , we didn't have convolutional errors , we didn't have extraneous , behaviors , and forth , and moving your head and all these sorts of things , then , actually speech recognition i isn't that bad right now . you can it 's the technology 's come along pretty the reason we still complain about it is because is when you have more realistic conditions then things fall apart . but that 's a research question ,  and that and we don't either . it 's it right now it 's just raw d it 's just data that we 're collecting , and we don't wanna presuppose that people will be able to get rid of particular degradations because that 's actually the research that we 're trying to feed . an and in five years it 'll work really and it 'll only mess up ten percent of the time , but then we would still want to account for that ten percent ,   i see . right .  should we do the digits ? ","you do need a voiced unvoiced determination too . but if it 's voiced , e the fraction of the energy that 's in the harmonic sequence that you 're looking at is relatively low , then it should be then it 's more likely to be an overlap . i don't know think it 'd be ideal . we see , we 're dealing with real speech and we 're trying to have it be as real as possible and breaths are part of real speech . if it gets in the way of what somebody is doing with it then you might wanna have some method which will allow you to block it , but you it 's real data . what if you put it in but didn't put the boundaries ? mean i 'm think if it 's too hard for us to annotate the breaths per se , we are gonna be building up models for these things and these things are somewhat self aligning , if we i if we say there is some thing which we call a "" breath "" or a "" breath in "" or "" breath out "" , the models will learn that thing . but you do want them to point them at some region where the breaths really are . the would say the core thing that we 're trying to do is to recognize the actual , meaningful components in the midst of other things that are not meaningful . it 's critical for us to get these other components that are not meaningful . because that 's what we 're trying to pull the other out of . ",
Bmr015.B,"we 're on and we seem to be working . we didn't crash we 're not crashing anymore and it really bothers me . you crashed this morning ? i did not crash this morning . i do . i have agenda and it 's all me . cuz no one sent me anything else . i have no idea but got it a few minutes ago . right when you were in my office it arrived . does anyone have any a agenda items other than me ? i actually have one more also which is to talk about the digits . great . i have a short thing about digits and then wanna talk a little bit about naming conventions , although it 's unclear whether this is the right place to talk about it . just talk about it very briefly and take the details to the people who for whom it 's relevant . the only thing i wanna say about digits is , we are done with the first test set . there are probably forms here and there that are marked as having been read that weren't really read . won't really know until i go through all the transcriber forms and extract out pieces that are in error . wa two things . the first is what should we do about digits that were misread ? my opinion is , we should just throw them out completely , and have them read again by someone else . the grouping is completely random , it 's perfectly fine to put a group together again of errors and have them re read , just to finish out the test set . the other thing you could do is change the transcript to match what they really said . those are the two options . what the transcribers did with that is if they did a correction , and they eventually did read the right string , you extract the right string . and didn't notice . which happens in a few places .  correct . and the two options are change the transcript to match what they really said , but then the transcript isn't the aurora test set anymore . i don't think that really matters because the conditions are different . and that would be a little easier . five or six times . no , it 's not much  four thousand .  four thousand lines . and each line is between one and about ten digits . i didn't compute the average . the average was around four or five .   and , jane , i do have a set of forms which you have copies of somewhere . you do ? good . i was just wond had all of them back from you . and then the other thing is that , the forms in front of us here that we 're gonna read later , were suggested by liz because she wanted to elicit some different prosodics from digits . and wanted people to , take a quick look at the instructions and the way it wa worked and see if it makes sense and if anyone has any comments on it . yes , although we could switch it back . the problem was o and zero . although we could switch it back and tell them always to say "" zero "" or always to say "" o "" .   right . the problem also is she did want to stick with digits . 'm speaking for her since she 's not here . but , the other problem we were thinking about is if you just put the numerals , they might say forty three instead of four three . she and i were talking about it , and she felt that it 's very , very natural to do that chunking . not very frequently but , they certainly could . this is something that liz and i spoke about and , since this was something that liz asked for specifically , we need to defer to her . do something different ,  it was . joint .  it 's that 's because they set the one up at uw that 's not on our side , that 's on the u dub side . and uw set it up as a moderated list . and , i have no idea whether it actually ever goes to anyone you might just wanna mail to mari and good . the moderator actually did repost it . cuz i had sent one earlier actually the same thing happened to me i had sent one earlier . the message says , "" you 'll be informed "" and then i was never informed but i got replies from people indicating that they had gotten it ,  it 's just to prevent spam . when 's the full proposal due ?  and they said end of business day you could check on the reviewer forms , is that i 've been a day off all week . that 's a good thing cuz that way i got my papers done early . it is . it is actually quite amazing .  or "" this is way too general "" , and the other reviewer says , "" this is way too specific "" . "" this is way too hard "" , "" way too easy "" . it sounded like they the first gate was pretty easy . is that right ? that they didn't reject a lot of the pre proposals ? no . just th  like that ,  right . right . how many awards are there , do  it was smaller , that it was like four or five , wasn't it ? it doesn't matter , we 'll find out one way or another .  exactly what we say in the proposal . it 's go higher level than we 've been talking about for meeting recorder .  ","i have a short thing about digits and then wanna talk a little bit about naming conventions , the only thing i wanna say about digits is , we are done with the first test set . the first is what should we do about digits that were misread ? what the transcribers did with that is if they did a correction , and they eventually did read the right string , you extract the right string . four thousand lines . and each line is between one and about ten digits . and then the other thing is that , the forms in front of us here that we 're gonna read later , were suggested by liz because she wanted to elicit some different prosodics from digits . the problem was o and zero . but , the other problem we were thinking about is if you just put the numerals , they might say forty three instead of four three . it 's go higher level than we 've been talking about for meeting recorder . ","Topics discussed by the Berkeley Meeting Recorder group included the status of the first test set of digits data, naming conventions for files, speaker identification tags, and encoding files with details about the recording. "
Bmr015.B,"are there any students in your class who are expressing interest ? other than the one who 's already here .    it just , we 've been cutting up sound files , in for ba both digits and for , doing recognition . and liz had some suggestions on naming and it just brought up the whole issue that hasn't really been resolved about naming . one thing she would like to have is for all the names to be the same length that sorting is easier .  same number of characters that when you 're sorting filenames you can easily extract out bits and pieces that you want . and that 's easy enough to do . and i don't think we have many meetings that 's a big deal just to change the names . that means , instead of calling it "" mr one "" , "" mr two "" , you 'd call it "" mrm zero one "" , "" mrm zero two "" , things like that . just that they 're all the same length . the problem is that they 're a lot of fields . alright , we have th we 're gonna have the speaker id , the session ,  information on the microphones , information on the speak on the channels and all that . and if each one of those is a fixed length , the sorting becomes a lot easier .  and as i said , the it 's we just don't have that many that 's a big deal . and at some point we have to take a few days off , let the transcribers have a few days off , make no one 's touching the data and reorganize the file structures . and when we do that we can also rationalize some of the naming . right . right . the only thing that would change with that is just the directory names , i would change them to match . instead of being mr one it would be mrm zero one . but i don't think that 's a big deal . for m the meetings we were thinking about three letters and three numbers for meeting i ds . for speakers , m or f and then three numbers , for , and , that also brings up the point that we have to start assembling a speaker database that we get those links back and forth and keep it consistent .  and then , the microphone issues . we want some way of specifying , more than looking in the "" key "" file , what channel and what mike . what channel , what mike , and what broadcaster . or i don't know how to s say it . mean with this one it 's this particular headset with this particular transmitter w as a wireless . and that one is a different headset and different channel . and we just need some naming conventions on that . and , that 's gonna become especially important once we start changing the microphone set up . we have some new microphones that i 'd like to start trying out ,  once i test them . and then we 'll need to specify that somewhere . was just gonna do a fixed list of , microphones and types . as i said open wide !  keep forgetting .  the p d a might not have to , but more people than just pda users are interested in this corpus . mean you 're right we could remove it , but we don't wanna w remove it from the corpus , in terms of delivering it because the people will want it in there . just to save the transcribers time .   they have lots of experience with breathing ? right .   ","one thing she would like to have is for all the names to be the same length same number of characters and i don't think we have many meetings that 's a big deal just to change the names . for m the meetings we were thinking about three letters and three numbers for speakers , m or f and then three numbers , that also brings up the point that we have to start assembling a speaker database that we get those links back and forth and keep it consistent . and then , the microphone issues . we want some way of specifying , more than looking in the "" key "" file , what channel and what mike . what channel , what mike , and what broadcaster . and we just need some naming conventions on that . was just gonna do a fixed list of , microphones and types . ","Topics discussed by the Berkeley Meeting Recorder group included the status of the first test set of digits data, naming conventions for files, speaker identification tags, and encoding files with details about the recording. "
Bmr015.C,"yes . one , two , three , four , f no crashing .  no ?        four thous four thousand .           tomorrow .                is true . i haven't results , yet but , i 'm continue working with the mixed signal now , after the last experience . and i 'm tried to , adjust the to improve , an harmonicity , detector that , i implement . but i have problem because , i get ,  very much harmonics now . harmonic possi possible harmonics ,  and now i 'm i 'm trying to find , some , of h of help , using the energy to distinguish between possible harmonics , and other fre frequency peaks , that , corres not harmonics . and , i have to talk with y with you , with the group , about the instantaneous frequency , because i have , an algorithm , and , i get ,  t results similar results the paper , that i am following . but , the rules , that , people used in the paper to distinguish the harmonics , is doesn't work and i not that i the way o to ob the way to obtain the instantaneous frequency is right , or it 's not right .  i haven't enough file feeling to distinguish what happened .  i talked with stephane and thilo and , they nnn they didn't they think that the experience is not enough to no , no it 's no no . no . no . i don't proth process the fundamental . i , ehm i calculate the phase derivate using the fft . and the algorithm said that , if you change the , nnn the x the frequency "" x "" , using the in the instantaneous frequency , you can find , how , in several frequencies that proba probably the harmonics , the errors of peaks the frequency peaks , move around these , frequency harmonic the frequency of the harmonic . and , if you compare the instantaneous frequency , of the of the , continuous , filters , that , that , they used to get , the instantaneous frequency , it probably too , you can find , that the instantaneous frequency for the continuous , the output of the continuous filters are very near . and in my case i in equal with our signal , it doesn't happened . and    using the energy of the multiple of the frequency .  i don't use . but , i know many people use , low pass filter to get , the pitch . i don't use . to get the pitch , yes . but the harmonic , no .    i will prepare for the next week all my results about the harmonicity and will try to come in and to discuss here , because , i haven't enough feeling to u many time to understand what happened with the with , many peaks ,  and i see the harmonics there many time but , there are a lot of peaks , that , they are not harmonics .  i have to discover what is the w the best way to c to use them    is height .  this is the idea i had to compare the ratio of the energy of the harmonics with the with the , total energy in the spectrum and try to get a ratio to distinguish between overlapping and speech .  no , no . it 's a o i w the band is , from zero to four kilohertz . and i ot i i u m t i used two m two method two methods . one , based on the f ftt . to fft to obtain the or to study the harmonics from the spectrum directly , and to study the energy and the multiples of frequency . and another algorithm i have is the in the instantaneous frequency , based on on the fft to to calculate the phase derivate in the time . the d have two algorithms . but , in m i in my opinion the instantaneous frequency , the behavior , was th it was very interesting . because i saw how the spectrum concentrate , around the harmonic . but then when i apply the rule , of the in the instantaneous frequency of the ne of the continuous filter in the near filter , the rule that , people propose in the paper doesn't work . and i don't know why .  i not i try to when first i calculate , using the fft , the i get the spectrum , and i represent all the frequency . and when ou i obtained the instantaneous frequency . and i change the @ @ , using the instantaneous frequency , here . i use    because when when i i use these frequency , the range is different , and the resolution is different . and i observe more more or less , thing like this . and the paper said that , these frequencies are probably , harmonics . but , they used , a rule ,  based in the because to calculate the instantaneous frequency , they use a hanning window . and , they said that , if these peak are , harmonics , the f instantaneous frequency , of the contiguous ,  filters are very near , or have to be very near . but , phh ! i don't i don i i and i don't is the what is the distance . and i tried to put different distance ,  to put difference , length of the window , different front sieve , pfff ! and i not what happened .         ","i 'm continue working with the mixed signal now , after the last experience . and i 'm tried to , adjust the to improve , an harmonicity , detector that , i implement . and now i 'm i 'm trying to find , some , of h of help , using the energy to distinguish between possible harmonics , and other fre frequency peaks , that , corres not harmonics . i have to talk with y with you , with the group , about the instantaneous frequency , no . i don't proth process the fundamental . i , ehm i calculate the phase derivate using the fft . i will prepare for the next week all my results about the harmonicity ","The group also discussed a proposal for a grant from the NSF's ITR (Information Technology Research) program, transcriptions, and efforts by speaker mn005 to detect speaker overlap using harmonicity-related features. "
Bmr015.D,"she wanted to keep them the same lengths across different meetings also . like , the nsa meeting lengths , all filenames are gonna be the same length as the meeting recorder meeting names ? alright . ",,
Bmr015.E,"      eight two nine .     p s tomorrow ?    i said something ,  very ,      but those backchannels will always be a problem especially if they 're really short and they 're not very loud and it can it will always happen that also the automatic s detection system will miss some of them ,     i 'm not too experienced with harmonics and to get the pitch ,      no . no i      and that 's that quite co corresponds to the way i try to train the speech nonspeech detector , as i really try to not to detect those breaths which are not within a speech chunk but with which are just in a silence region . and they they hopefully won't be marked in those channel specific files . but ","but those backchannels will always be a problem especially if they 're really short and they 're not very loud and it can it will always happen that also the automatic s detection system will miss some of them , and that 's that quite co corresponds to the way i try to train the speech nonspeech detector , ",
Bmr015.F," self learning , can w i could always say something about transcription . i 've been but   this does sound like we 're doing fine ,  that won't do . by throw them out completely ?  and s and you 're talking string wise , you 're not talking about the entire page ? i get it . true .  no , not yet .   if there 's space , though , between them . you can with when you space them out they don't look like , forty three anymore .  but , when you , do things like that you can always as long as you have you can always search from the beginning or the end of the string . zero two ""  your example was really i  i would think though that the transcribe the transcripts themselves wouldn't need to have such lengthy names . you 're dealing with a different domain there , and with start and end times and all that , and channels and it 's a different set . fine . fine . the news is that i 've i s in s 've switched to start my new sentence . i switched to doing the channel by channel transcriptions to provide , the tighter time bins for partly for use in thilo 's work and also it 's of relevance to other people in the project . and , i discovered in the process a couple of interesting things , which , one of them is that , it seems that there are time lags involved in doing this ,  using an interface that has much more complexity to it . and i wanted to ask , chuck to help me with some of the questions of efficiency . was thinking the best way to do this in the long run may be to give them single channel parts and then piece them together later . and i have a script , piece them together . it 's like , i know that take them apart and put them together and i 'll end up with the representation which is where the real power of that interface is . and it may be that it 's faster to transcribe a channel at a time with only one , sound file and one , set of , utterances to check through . yes . but , with the mixed , when you have an overlap , you only have a choice of one start and end time for that entire overlap , which means that you 're not tightly , tuning the individual parts th of that overlap by different speakers . someone may have only said two words in that entire big chunk of overlap . and for purposes of , things like things like training the speech nonspeech segmentation thing . th it 's necessary to have it more tightly tuned than that . and w and , is a it would be wonderful if , it 's possible then to use that algorithm to more tightly tie in all the channels after that but , i 've th the  i don't know exactly where that 's going at this point . but m i was experimenting with doing this by hand and i really do think that it 's wise that we 've had them start the way we have with , m y working off the mixed signal ,  having the interface that doesn't require them to do the ti the time bins for every single channel at a t through the entire interaction . i did discover a couple other things by doing this though , and one of them is that ,  once in a while a backchannel will be overlooked by the transcriber . as you might expect , because when it 's a b backchannel could happen in a very densely populated overlap . and if we 're gonna study types of overlaps , which is what i wanna do , an analysis of that , then that really does require listening to every single channel all the way through the entire length for all the different speakers . now , for only four speakers , that 's not gonna be too much time , but if it 's nine speakers , then that i that is more time . it 's li wondering it 's like this it 's really valuable that thilo 's working on the speech nonspeech segmentation because we can close in on that wi without having to actually go to the time that it would take to listen to every single channel from start to finish through every single meeting .  then , the answer is to , listen especially densely in places of overlap , just that they 're not being overlooked because of that , and count on accuracy during the sparser phases . cuz there are large s spaces of the that 's a good point . there are large spaces where there 's no overlap someone 's giving a presentation , or whatever . that 's a good that 's a good thought . and , let 's see , there was one other thing i was gonna say . it 's really interesting data to work with , i have to say , it 's very enjoyable . i really , not a problem spending time with these data . really interesting . and not just because i 'm in there . no , it 's real interesting . di digital camera . i did i it did occur to me that this is the return to the transcription , that there 's one third thing i wanted to ex raise as a to as an issue which is , how to handle breaths . i wanted to raise the question of whether people in speech recognition want to know where the breaths are . and the reason i ask the question is , aside from the fact that they 're very time consuming to encode , ","i switched to doing the channel by channel transcriptions to provide , the tighter time bins for partly for use in thilo 's work and also it 's of relevance to other people in the project . one of them is that , it seems that there are time lags involved in doing this , using an interface that has much more complexity to it . was thinking the best way to do this in the long run may be to give them single channel parts and then piece them together later . and it may be that it 's faster to transcribe a channel at a time with only one , sound file and one , set of , utterances to check through . but , with the mixed , when you have an overlap , you only have a choice of one start and end time for that entire overlap , and for purposes of , things like things like training the speech nonspeech segmentation thing . th it 's necessary to have it more tightly tuned than that . i really do think that it 's wise that we 've had them start the way we have with , m y working off the mixed signal , having the interface that doesn't require them to do the ti the time bins for every single channel at a t through the entire interaction . once in a while a backchannel will be overlooked by the transcriber . and if we 're gonna study types of overlaps , then that really does require listening to every single channel all the way through the entire length for all the different speakers . it 's like this it 's really valuable that thilo 's working on the speech nonspeech segmentation because we can close in on that wi without having to actually go to the time that it would take to listen to every single channel from start to finish through every single meeting . then , the answer is to , listen especially densely in places of overlap , i did i it did occur to me that this is the return to the transcription , that there 's one third thing i wanted to ex raise as a to as an issue which is , how to handle breaths . aside from the fact that they 're very time consuming to encode , ","Particular focus was paid to questions about transcription procedures, i.e. how to deal with overlooked backchannels, and audible breaths. "
Bmr015.F,"the fact that there was some i had the indication from dan ellis in the email that i sent to you , and about , that in principle we might be able to , handle breaths by accessi by using cross talk from the other things , be able that in principle , we could get rid of them ,  and i was i don't know , we had this an and i didn't couldn't get back to you , but the question of whether it 'd be possible to eliminate them from the audio signal , which would be the ideal situation , cuz except that these are really truly ther there 's a segment in o the one i did n the first one that i did for i for this , where truly w we 're hearing you breathing like as if we 're you 're in our ear , and it 's like i y i breath is natural , but not except that we 're trying to mimic i see what you 're saying . you 're saying that the pda application would have have to cope with breath . but then the then i have two questions .  the question is notating it .   this is in very interesting because i it has a i it shows very clearly the contrast between , speech recognition research and discourse research because in discourse and linguistic research , what counts is what 's communit communicative . and breath , everyone breathes , they breathe all the time . and once in a while breath is communicative , but r very rarely . now , i had a discussion with chuck about the data structure and the idea is that the transcripts will that get stored as a master there 'll be a master transcript which has in it everything that 's needed for both of these uses . and the one that 's used for speech recognition will be processed via scripts . don 's been writing scripts and , to process it for the speech recognition side . discourse side will have this side over he the we 'll have a s ch not being very fluent here . but , this the discourse side will have a script which will stri strip away the things which are non communicative . then the then let 's think about the practicalities of how we get to that master copy with reference to breaths . what i would r what i would wonder is would it be possible to encode those automatically ? could we get a breath detector ? you just have no idea . if you 're getting a breath several times every minute , and just simply the keystrokes it takes to negotiate , to put the boundaries in , to type it in , i it 's just a huge amount of time . and you wanna be it 's used , and you wanna be it 's done as efficiently as possible , and if it can be done automatically , that would be ideal . but now there 's another possibility which is , the time boundaries could mark off words from nonwords . and that would be extremely time effective , if that 's sufficient . but that would include a pause as and that wouldn't be a problem to have it , pause plus breath plus laugh plus sneeze ? that 's what they 've been doing . within an overlap segment , they do this . you 're saying it 's uncharted territory .   fair enough . i what i was wondering is what at what level does the breathing aspect enter into the problem ? because if it were likely that a pda would be able to be built which would get rid of the breathing , it wouldn't even have to be processed at thi at this computational le let me see , it 'd have to be computationally processed to get rid of it , but if there were , like likely on the frontier , a good breath extractor then , and then you 'd have to see and that 's what i wouldn't know .  there 's another aspect which is that as we 've improved our microphone technique , we have a lot less breath in the more recent , recordings , it 's in a way it 's an artifact that there 's much on the earlier ones . and it 's also the fact that they differ a lot from one channel to the other because of the way the microphone 's adjusted .  ","but the question of whether it 'd be possible to eliminate them from the audio signal , because i it has a i it shows very clearly the contrast between , speech recognition research and discourse research now , i had a discussion with chuck about the data structure there 'll be a master transcript which has in it everything that 's needed for both of these uses . and the one that 's used for speech recognition will be processed via scripts . what i would r what i would wonder is would it be possible to encode those automatically ? could we get a breath detector ? which is that as we 've improved our microphone technique , we have a lot less breath in the more recent , recordings , it 's in a way it 's an artifact that there 's much on the earlier ones . ",
Bmr015.G,"i do . i crashed when i started this morning . really ?   or it 's once you 've done enough meetings it won't crash on you anymore . it 's a matter of experience .  did did they send , the messages to you about the meeting today ?   cuz i checked my mail . i didn't have anything . you 're talking about where they completely read the wrong string and didn't correct it ?  how many are how often does that happen ? it 's not very much . seems like we should just change the transcripts to match .  it 's  you how many digits have been transcribed now ? four thousand lines ?      u tomorrow . it would be interesting it 'll be interesting to see the reviewer 's comments . it 's just from his message it sounded like that . gary strong 's there was a sentence at the end of one of his paragraphs i  he said the next phase 'll be very , competitive because we didn't want to weed out much in the first phase . i don't know . i 'm i don't remember . if we end up getting this , what will it mean to icsi in terms of , w wh where will the money go to , what would we be doing with it ? which part is icsi though .  dang ! it 's just for the research to continue the research on the meeting recorder   right , right . assuming everybody 's completely busy now , it means we 're gonna hafta , hire more students , or , something ? right . right . i see . cuz of digits . that sounds good . is this the algorithm where you hypothesize a fundamental , and then get the energy for all the harmonics of that fundamental ? and then hypothesize a new fundamental and get the energy do you hafta do some low pass filter before you do that ? or but i but the harmonics are gonna be ,  i don't the right word is .  they 're gonna be dampened by the vocal tract , right ? the response of the vocal tract . and just looking at the energy on those at the harmonics , is that gonna ? i m what you 'd like to do is get rid of the effect of the vocal tract . right ? and just look at the signal coming out of the glottis .    an any application may have to .  there 's a there 's i one possible way that we could handle it is that ,  as the transcribers are going through , and if they get a hunk of speech that they 're gonna transcribe , u th they 're gonna transcribe it because there 's words in there or whatnot . if there 's a breath in there , they could transcribe that . right . but right . but if there 's a big hunk of speech , let 's say on morgan 's mike where he 's not talking don't worry about that . what we 're saying is , there 's no guarantee that , for the chunks that are transcribed , everything 's transcribed . but outside of those boundaries , there could have been that wasn't transcribed . you just somebody can't rely on that data and say "" that 's perfectly clean data "" . do you see what i 'm saying ? would say don't tell them to transcribe anything that 's outside of a grouping of words .  one of the just to add to this one of the ways that we will be able to get rid of breath is by having models for them . that 's what a lot of people do nowadays . and in order to build the model you need to have some amount of it marked , that where the boundaries are .  i don't think we need to worry a lot about breaths that are happening outside of a , conversation . we don't have to go and search for them to mark them but , if they 're there while they 're transcribing some hunk of words , i 'd say put them in if possible .  ",you 're talking about where they completely read the wrong string and didn't correct it ? seems like we should just change the transcripts you how many digits have been transcribed now ? would say don't tell them to transcribe anything that 's outside of a grouping of words . ,
Bmr018.A,"  that was fun . that was fun .  excellent . will we have time to , to prepare something that we in the format we were planning for the ibm transcribers by then , or ?  he 's he 's he generated , a channel wise presegmented version of a meeting , but it was robustness rather than edu guess depends on whether we 're willing to use robustness ?   great . i 'll i 'll , get make that available .   that 's right . that 's right . we haven't done that . i could set someone on that tomorrow . they 're coming  what would be a good number of minutes ?    and have them fix it over the entire meeting too ?  i gue if it 's got like for speakers then if individual channels .  there is this issue of , if the segmenter thought there was no speech on a particular stretch , on a particular channel , and there really was , then , if it didn't show up in a mixed signal to verify , then it might be overlooked , the question is "" should a transcriber listen to the entire thing or can it g can it be based on the mixed signal ? "" and i th far as i 'm concerned it 's fine to base it on the mixed signal at this point , and and that cuts down the time .  that 's good .  good , good . what aspect ? should be pretty good ,  but those would be but presumably , most of those they should be able to hear from the mixed signal unless they 're embedded in the heavil heavy overlap section when in which case they 'd be listening to the channels anyway .  i am too . and it 's an empirical question . they can that 's it .  and if   w the other problem is the breaths cuz you also see the breaths on the waveform . i 've looked at the int s i 've tried to do that with a single channel , and you do see all sorts of other besides just the voice . that i 'm not what you the digital what the digital task that you had your interface ? i know for a fact that one of those sh she could really she could judge what th what the number was based on the waveform . she could tell which one was seven .  they have a choice . they could choose any signal to look at . i 've tried lookin but usually they look at the mixed . but i 've tried looking at the single signal and in order to judge when it was speech and when it wasn't , but the problem is then you have breaths which show up on the signal . yes . yes . yes .  they show up on the separate ribbons . you have a separate ribbon for each channel , and i it 'll be because it 's being segmented as channel at a time with his with thilo 's new procedure , then you don't have the correspondence of the times across the bins across the ribbons you could have yes .  not "" look "" . not very quickly . you can but it takes time . that 's it .  visually . you can switch quickly between the audio , but you just can't get the visual display to show quickly . you have to it takes , i don't know , three , four minutes to it takes long enough it takes long enough cuz it has to reload the i don't know exactly what it 's doing frankly cuz but it t it takes long enough that it 's just not a practical alternative . now you could set up multiple windows , each one with a different signal showing , and then look between the windows . that 's the solution .   i am thinking if we have a meeting with only four speakers and , you could fire up a transcriber interface for , y in different windows , multiple ones , one for each channel . and it 's hack but it would be one way of seeing the visual form .    i do think that this will be a doable procedure , and have them starting with mixed and , then when they get into overlaps , just have them systematically check all the channels to be that there isn't something hidden from audio view .  yes . yes . click  i 'm not what click on the ribbon ? you can get that  get you can get the , you can get it to switch audio ? not last i tried , but , he 's changed it again . i disagree . there 's a reason i disagree , and that is that , you it 's very good to have a dissociation between the visual and the audio . there 're times when i wanna hear the mixed signal , bu but i want to transcribe on the single channel . right now don't i don't see that it 's a that 's the that might be a personal style thing . i find it really convenient the way it 's set up right now . that 's fine . it 's true . it could be faster , but , th in the ideal world  no i agree that 'd be       you did you have , something in the report about , for f forced alignment ? have you started on that ?  it 's a merging problem . if you had a s if you had a script which would i 've thought about this , and i 've discussed it with thilo , the , i in principle i could imagine writing a script which would approximate it to some degree , but there is this problem of slippage ,  they can be stretched . ","he generated , a channel wise presegmented version of a meeting ,  there is this issue of , if the segmenter thought there was no speech on a particular stretch , on a particular channel , and there really was , then , if it didn't show up in a mixed signal to verify , then it might be overlooked , the question is "" should a transcriber listen to the entire thing or can it g can it be based on the mixed signal ? "" but presumably , most of those they should be able to hear from the mixed signal unless they 're embedded in the heavil heavy overlap section they could choose any signal to look at . i 've tried lookin but usually they look at the mixed . but i 've tried looking at the single signal and in order to judge when it was speech and when it wasn't , they show up on the separate ribbons . and i it 'll be because it 's being segmented as channel at a time with his with thilo 's new procedure , then you don't have the correspondence of the times across the bins across the ribbons you can switch quickly between the audio , but you just can't get the visual display to show quickly . i do think that this will be a doable procedure , and have them starting with mixed and , then when they get into overlaps , just have them systematically check all the channels to be that there isn't something hidden from audio view . ",
Bmr018.A,"i wouldn't make that generalization cuz sometimes people will say , "" and then i "" and there 's a long pause and finish the sentence and sometimes it looks coherent and the it 's not a simple problem . but it 's really and then it 's coupled with the problem that sometimes , with a fricative you might get the beginning of the word cut off and it 's coupled with the problem that thilo 's isn't perfect either . we 've i th it 's like you have a merging problem plus merging plus this problem of , not y i if the speech nonspeech were perfect to begin with , the detector , that would already be an improvement , but that 's impossible , i that 's too much to ask . and and may it 's that there always th there would have to be some hand tweaking , but it 's possible that a script could be written to merge those two types of things . i 've discussed it with thilo and in terms of not him doing it , but we discussed some of the parameters of that and how hard it would be to in principle to write something that would do that . it 's just , a matter of we had the revolution of improved , interface , one month too late , but it 's like , it 's wonderful to have the revolution , it 's just a matter of , from now on we 'll be able to have things channelized to begin with .  that 's right . that 's right . good point .  the problem is i it 's a really good question , and i really find it a pain in the neck to delete things because you have to get the mouse up there on the t on the text line and i and otherwise you just use an arrow to get down i it depends on how lar th there 's many extra things that would make it one of them harder than the other , or vice versa . it 's not a simple question . but , in principle if one of them is easier then to bias it towards whichever one 's easier . it 's easier to add than delete , frankly , because you have to , maneuver around on the on both windows then . to delete . it 's possible . think there 's a complication which is that you can have speech and noise in s on the same channel , the same speaker , now sometimes you get a ni microphone pop and , there 're these fuzzy hybrid cases , and then the problem with the boundaries that have to be shifted around . it 's not a simple problem . and also , i still haven't given up on forced alignment . that when brian comes , this 'll be an interesting aspect to ask him as when brian kingsbury comes . good question . ryan could come . that 's what my hope has been , and that 's what ever since the february meeting that i transcribed from last year , forced alignment has been on the table as a way of cleaning them up later . and 'm hopeful that 's possible . i know that there 's complication in the overlap sections and with the lapel mikes , but i agree . i agree .  excellent .  you said , "" speaking about energy "" , that was very that 's great . i did go through one of these meetings . i had , one of the transcribers go through and tighten up the bins on one of the , nsa meetings , and then i went through afterwards and double checked it that one is really very accurate . i men i mentioned the link . i sent that one ? i 'm trying to remember i don't remember the number off hand . it 's one of the nsa 's . i sent email before the conference , before last week . bef what is wednesday , thursday . i 'm that one 's accurate , i 've been through it myself . i corrected it for a number of the words . i 'm that , they 're accurate now . won i noticed when you turned your head , it would tilt .  it 's com this is the first time i 've worn this , i find it very comfortable .   wonder if it 's if he was wearing it over his hair instead of under his hair . what did you say ?      r  maryland .  i like the idea that adam had of , z generating minutes based on some of these things that we have because it would be easy to do that just , and it has to be , though , someone from this group because of the technical nature of the thing . i do take notes . it was an interesting session . one of those w that 's it . this was a very provocative slide . she put this up , and it was like this is this p people kept saying , "" can i see that slide again ? "" and then they 'd make a comment , and one person said , known person said , "" before you dismiss forty five years including my work "" that was very offending , very offending .  that 's good .  ","cuz sometimes people will say , "" and then i "" and there 's a long pause and finish the sentence and sometimes it looks coherent and the and then it 's coupled with the problem that sometimes , with a fricative you might get the beginning of the word cut off but it 's possible that a script could be written to merge those two types of things . it 's just a matter of , from now on we 'll be able to have things channelized to begin with . the problem is i it 's a really good question , and i really find it a pain in the neck to delete things i had , one of the transcribers go through and tighten up the bins on one of the , nsa meetings , and then i went through afterwards and double checked it that one is really very accurate . ",
Bmr018.B,"when the power went out the other day and i restarted it , it crashed the first time . after the power out this wasn't actually , this wasn't a before your meeting , this was , tuesday afternoon when , robert just wanted to do a little recording , and the power had gone out earlier in the day . talk about a good noise shield .  you wanted to pe keep people from listening in , you could like have that playing outside the room . nobody could listen in . and then we 'll go back later and review the individual channels , right ? if you wanna practically , with all the overlaps . i wouldn't mind hearing how the conference was . yes ,  he 's i 'm i should have forwarded that along . mentioned at the last meeting , he said that , he talked to them and it was fine with the beeps they would be that 's easy for them to do . for this experiment we can use pre anything . this experiment of just we 've talked about that as being the next ones we wanted to transcribe . but for the purpose of sending him a sample one to f i don't think it matte right , we need to run thilo 's thing on it , and then we go in and adjust the boundaries . right .  and we probably don't have to do necessarily a whole meeting for that if we just wanna send them a sample to try . i don't know , we can figure out how long it 'll take @ @ to do . the only thing i 'm not about is , how quickly can the transcribers scan over and fix the boundaries , and is it pretty easy ? as of what point ?  the the question on my mind is do we for the transcribers to adjust the marks for the whole meeting before we give anything to ibm , or do we go ahead and send them a sample ? let their mean , i don't know .  that i agree . i agree . we 're just doing the individual channels , right ? it 's gonna be , depending on the number of people in the meeting ,  i don't see how that will work , though .   i that 's what i 'm concerned about the part . can't we couldn't we just have , i don't know , this just doesn't fit with the software , but if i didn't know anything about transcriber and i was gonna make something to let them adjust boundaries , i would just show them one channel at a time , with the marks , and let them adju but i but it 's very quick , right ? you scan if you have a display of the waveform .  the problem is if anything 's cut off , you can't expand it from the chopped up did you run the andreas the r sri recognizer on the digits ? i it wasn't zero percent error ? this is error you 're talking about ?  and it didn't matter whether it was the lapel or whether it was the  was curious about that . i didn't think that his message said it wasn't straight forward . he 's just saying you have to look over a longer time window when you do it . right . you just have to look over longer time when you 're trying to align the things , you can't just look andreas , how did it work on the non lapel  because really the at least in terms of how we were gonna use this in our system was to get an ideal an idea , for each channel about the start and end boundaries . we don't really care about like intermediate word boundaries ,    right , exactly . that 's why i was wondering if it if it doesn't work for lapel we can just not use that and we c what ? the best way to find that would be to look through these . cuz you can see the seat numbers , and then you can see what type of mike they were using . and we just look for , somebody sitting next to adam at one of the meetings what is why do you need the , the forced alignment for the hlt for the eurospeech paper ? it was to get more data and better to squeeze the boundaries in .   thilo 's won't put down two separate marks in that case we were never just gonna go with these as the final alignments . we were always gonna run them past somebody . could you at the same time adapt the reject model to the speech from all the other channels ? not just the speech from that of the other people from that channel , but the speech from the a actual other channels . if you actually if you have a larger head , that mike 's gotta go farther away which means the balance is gonna make it wanna tip down . can i see that ? i i don't want it on , want to , say what is a problem with this . if you are wearing this over your ears and you 've got it all the way out here , then the balance is gonna want to pull it this way . where as if somebody with a smaller head has it back here , right ?  then it falls back this way it 's this is supposed to be under that little protuberance .  it 's really supposed to go more like this than like this . but then isn't that going to you can control that . it would be an advantage . the other thing that would do it would be to hang a five pound weight off the back . ","right , we need to run thilo 's thing on it , and then we go in and adjust the boundaries . how quickly can the transcribers scan over and fix the boundaries , we 're just doing the individual channels , right ? but if i didn't know anything about transcriber and i was gonna make something to let them adjust boundaries , i would just show them one channel at a time , with the marks , and let them adju did you run the andreas the r sri recognizer on the digits ? zero percent error ? he 's just saying you have to look over a longer time window when you do it . you just have to look over longer time when you 're trying to align the things , andreas , how did it work on the non lapel because really the at least in terms of how we were gonna use this in our system was to get an ideal an idea , for each channel about the start and end boundaries . we don't really care about like intermediate word boundaries , ","The Berkeley Meeting Recorder group discussed the preparation of a data sample for IBM, the manual adjustment of time bins by transcribers, recognition results for a test set of digits data, and forced alignments. "
Bmr018.B,"hang a five pound weight off the back . counter balance . did they give a talk on this or was this informal ? what was the , the paper by , lori lamel that you mentioned ? what was their rough what was their conclusion ? did they ever try going the other direction from simpler task to more complicated tasks , or ?  do you remember who the groups were that we 're doing ? was were there folks from bbn presenting ? was sra one of the groups talking about summarization , no ? this was my concern about the recognizer in aurora . that the differences we 're seeing in the front end is b are irrelevant once you get a real recognizer at the back end .  but doesn't their conclusion just you could have guessed that before they even started ? because if you assume that these learning things get better and better , then as you approach there 's a point where you can't get any better , right ? you get everything right . they 're all approaching . but what i 'm saying is that th they have to , as they all get better , they have to get closer together . but they 're all going the same way , right ? you have to get closer . they didn't ? they should have said "" focus "" ",,
Bmr018.C,"go ahead . alright , and no crash .   no connection . i don't know when would be a good excuse for it , but can't to be giving a talk t and use the example from last week with everybody t doing the digits at once . i 'd love to play somebody that . it was . it was really efficient .   everybody give the reports about what they were doing at exactly the same time ,  actually isn't that what we have been doing ? what are we doing ? and i 'm just what conference ? that is right . the next weekend . that 's when they 're coming . that 's correct . no , but that would be a good idea . why don't we w they 're not even gonna be here until eleven or cuz they 're flying up that day . saturday . saturday . s saturday .  no , they 're flying up from down from seattle .  and they 'll end up here . and also brian kingsbury is actually flying from , the east coast on that morning . i will be he 's taking a very early flight and we do have the time work difference running the right way , but i still think that there 's no way we could start before eleven . it might end up really being twelve . when we get closer we 'll find people 's plane schedules , and let everybody know . that 's good . we can start gathering those ideas , but then we should firm it up by next thursday 's meeting . yes except that if they had if there was a choice between having fifteen minutes that was fully the way you wanted it , and having a whole meeting that didn't get at what you wanted for them it 's just dependent of how much  can we pipeline it that say there 's , the transcriber gets done with a quarter of the meeting and then we you run it through this other   that 's right . the first thing is the automatic thing , and then it 's then it 's the transcribers tightening up , and then it 's ibm . you might as ha run the automatic thing over the entire meeting , and then and then , you would give ibm whatever was fixed . but start from the beginning and go to the end , right ? if they were only half way through then that 's what you 'd give ibm . right ? why wouldn't we s @ @ w i if they were going sequentially through it , why wouldn't we give them are we trying to get something done by the time brian comes ? if we were , then it seems like giving them something , whatever they had gotten up to , would be better than nothing . you 're talking about tightening up time boundaries ? how do you don't i 'm now entirely confused about what they do . they 're looking at a mixed signal , or they 're looking what are they looking at visually ? but the procedure that you 're imagining , people vary from this , is that they have the mixed signal wave form in front of them , and they have multiple , let 's see , there isn't we don't have transcription yet . but there 's markers of some sort that have been happening automatically , and those show up on the mixed signal ? there 's a @ @ clicks ? there 're separate ribbons . and is there a line moving across the waveform as it goes ? the way you 're imaging is they play it , and they see this happened , then and if it 's about right , they just let it slide , and if it there 's a question on something , they stop and look at the individual wave form . they might look at it , right ?      but right now , to do this limitation , the switching is going to be switching of the audio ? is what she 's saying .  they 're using their ears to do these markings anyway . done with that ? does any i forget , does anybody , working on any eurospeech submission related to this ?  there was that we that 's right , we had that one conversation about , what did it mean for , one of those speakers to be pathological , was it a right .  there 's zero , a little bit , and a lot .   y was it fifteen ?  what we 're calling .  no , but there 's a little difference , and we haven't looked at it for digits , right ? and cuz because what he was what i was saying when i looked at those things is it i was almost gonna call it quadrimodal because there was a whole lot of cases where it was zero percent . they just plain got it all right . and then there was another bunch that were couple percent    i see . i see .   unless we do this , cancellation business . the short amount of time thing , right .    if you can feel confident that what the that there 's actually something that you 're not gonna miss something ,  that 's what he just said .  we 're not turning in to eurospeech , a redo of the hlt paper . that i don't wanna do that , but . bleep . that wa that was the battery meter saying that it was fully charged ,      no i in your case , you were joking about it , but , your case the fact that your talking about similar things at a couple of conferences , it 's not these are conferences that have d really different emphases . ","the first thing is the automatic thing , and then it 's then it 's the transcribers tightening up , and then it 's ibm . you 're talking about tightening up time boundaries ? but the procedure that you 're imagining , people vary from this , is that they have the mixed signal wave form in front of them , let 's see , there isn't we don't have transcription yet . but there 's markers of some sort that have been happening automatically , and those show up on the mixed signal ? the way you 're imaging is they play it , and if it there 's a question on something , they stop and look at the individual wave form . does anybody , working on any eurospeech submission related to this ? we had that one conversation about , what did it mean for , one of those speakers to be pathological , y unless we do this , cancellation business . ","The Berkeley Meeting Recorder group discussed the preparation of a data sample for IBM, the manual adjustment of time bins by transcribers, recognition results for a test set of digits data, and forced alignments. "
Bmr018.C,"whereas hlt and eurospeech , pretty similar , can't see really just putting in the same thing , but  or some or some i would see eurospeech if we have some eurospeech papers , these will be paper p submissions . these will be things that are particular things , aspects of it that we 're looking at , rather than , attempt at a global paper about it .   see ya . i don't think we 'll go much longer .   see ya . but i had it on this morning and it was fine .  we should we shou we should work on compressing the heads , and  that 's good ! hang a five pound weight off the back . weight . or this could be helpful just for evening the conversation between people . if people those who talk a lot have to wear heavier weights and and what was i gonna say ? i was gonna say , i had these , conversations with nist folks also while i was there and , they have their plan for a room , with , mikes in the middle of the table , and , close mounted mikes , and they 're talking about close mounted and lapels , just cuz and the array . they were and like multiple video cameras coverin covering every everybody every place in the room , the the mikes in the middle , the head mounted mikes , the lapel mikes , the array , with there 's some discussion of fifty nine , they might go down to fifty seven because , there is , some pressure from a couple people at the meeting for them to use a kemar head . i forget what kemar , stands for , but what it is it 's dummy head that is very specially designed , and and , what they 're actually doing is they 're really there 's really two recording systems . they may not be precisely synchronous , but the but there 's two recording systems , one with , twenty four channels , and one with sixty four channels . and the sixty four channel one is for the array , but they 've got some empty channels there , and anyway they like they 're saying they may give up a couple if for the kemar head if they go with that .   i 'm not too worried about that . i was thinking  no , we just had some discussions , various discussions with them . we sh we should just have you read it , but , i mea ba i we 've all got these little proceedings , but , it was about , going to a new task where you have insufficient data and using data from something else , and adapting , and how that works . it was pretty related to what liz and andreas did , except that this was not with meeting it was with like they s didn't they start off with broadcast news system ? and then they went to  ti digits was one of them , and , wall street journal .   probably . that might be hard .       and they have they have better adaptation than we had than that system , they  we should probably what would actually what we should do , i haven't said anything about this , but probably the five of us should pick out a paper or two that , got our interest , and we should go around the room at one of the tuesday lunch meetings and say , what was good about the conference ,  columbia have anything ? no .  that was an interesting discussion , i i didn't have as much disagreement as i would have liked , but i didn't wanna i wouldn i didn't wanna get into it because , it was the application was one i didn't know anything about , it just would have been , me getting up to be argumentative , but , the missing thi what they were saying it 's one of these things is all you need is more data , but i mea i wh it @ @ that 's dissing it , improperly , it was a study . they were doing this it wasn't word sense disambiguation , it was was it w was it word sense ? yes .   right . and what they did was they had these different kinds of learning machines , and they had different amounts of data , and they did like , eight different methods that everybody , argues about , "" my learning machine is better than your learning machine . "" and , they were started off with a million words that they used , which was evidently a number that a lot of people doing that particular task had been using . they went up , being microsoft , they went up to a billion . and then they had this log scale showing a and naturally everything gets they it 's a big company , i didn't mean it as a ne anything negative , but i   but , yes . there was the effect that , one would expect that that you got better and better performance with more and more data . but the real point was that the different learning machines are all over the place , and by going up significantly in data you can have much bigger effect then by switching learning machines and furthermore which learning machine was on top depended on where you were in this picture ,   that     could be . that was it 's a good point , but the problem i had with it was that the implications out of this was that , the choices you make about learning machines were therefore irrelevant which is not at n t as for as i know in tasks i 'm more familiar with @ @ is not true . ",,
Bmr018.C,"what i what is true is that different learning machines have different properties , and you wanna those properties are . and someone else implied that we s a all the study of learning machine we still don't those properties are . we don't know them perfectly , but we know that some kinds use more memory and some other kinds use more computation and some are hav have limited discrimination , but are just easy to use , and others are you would guess  it w  eventually . o one would  that 's getting cl  the spread was still pretty wide that 's th that 's true , but , it would be irntu intu intuition that this would be the case , but , to really see it and to have the intuition is quite different , somebody w let 's see who was talking about earlier that the effect of having a lot more data is quite different in switchboard than it is in broadcast news ,   right .   but anyway , it 's just the i it 's it 's not really the conclusion they came to much , as the conclusion that some of the , commenters in the crowd came up with that , this therefore is further evidence that , more data is really all you should care about , and that was just going too far the other way , and the , one person ga g got up and made a brief defense , but it was a different grounds , it was that , i w the reason people were not using much data before was not because they were stupid or didn't realize data was important , but th they didn't have it available . but the other point to make a again is that , machine learning still does matter , but it matters more in some situations than in others , and it and also there 's not just mattering or not mattering , but there 's mattering in different ways . you might be in some situation where you care how much memory you 're using , or you care , what recall time is , or you care , and  or ,   and there 's cost ! there 's just plain cost ,  these , th the in the speech side , the thing that @ @ always occurs to me is that if you if you one person has a system that requires ten thousand hours to train on , and the other only requires a hundred , and they both do about the same because the hundred hour one was smarter , that 's gonna be better . because people , there isn't gonna be just one system that people train on and then that 's it for the r for all of time . people are gonna be doing other different things , and it these things matters matter .  right .  anyway , tea is tea is , starting . let 's do it all at once . we @ @ let 's try that again . boy , is that ever efficient .   ",,
Bmr018.D,"it never crashes on me . what is that ?   then there would be no temp files .  it it doesn't clear them ,  but that 's usually the meeting that i recorded , and it neve it doesn't crash on me .  right .   it was quick . i had this idea we could make our whole meeting faster that way . and we 'll just all leave , and  i had one question about aren't the uw folks coming this weekend ? next weekend ? not the days coming up , but  within ten days . are we do we have like an agenda or anything that we should be  this is on sunday ? or saturday ?  except for it doesn't do on short things , remember . it will miss them . it will miss most of the really short things . like that .  it will miss you have to say "" more slowly to get c no , i 'm s i 'm actually serious . it will miss like that which right , and that 's what i 'm not about . it 's very slow to do that . that w  that 's actually what of , loading the chopped up waveforms , that would make it faster  right , but if you a at some point no , the individual channels that were chopped up that it 'd be to be able to go back and forth between those short segments . cuz you don't really nee like nine tenths of the time you 're throwing most of them out , but what you need are tho that particular channel , or that particular location , and , might be cuz we save those out already , to be able to do that . but it won't work for ibm it only works here cuz they 're not saving out the individual channels . i don't know that you can locate them very from the mixed signal , but you would know that they were there , and then you would switch . right . and then you would switch into the other  but there 's no overlap during the digit readings , it shouldn't really matter . right , but that 's that was our plan , but it 's clear from dan that this is not something you can do in a short amount of time .  we we had spent a lot of time , writing up the hlt paper and we wanted to use that , analysis , but the hlt paper has , it 's a very crude measure of overlap . it 's not really something you could scientifically say is overlap , it 's just whether or not the , the segments that were all synchronized , whether there was some overlap somewhere . and , that pointed out some differences , he thought if we can do something quick and dirty because dan said the cross cancellation , it 's not straight forward . if it were straight forward then we would try it , but it 's good to hear that it was not straight forward , thinking if we can get decent forced alignments , then at least we can do overall report of what happens with actual overlap in time , but , and the but there are some issues of this timing , in the recordings and i that was side issue . and it 's dynamic , guess it was more dynamic than some simple models would be able t to there are some things available , and i don't know too much about this area where if people aren't moving around much than you could apply them , and it should work pretty if you took care of this recording time difference . which a at least is defined , and but then if you add the dynamic aspect of adapting distances , then it wasn't it just wasn't something that he could do quickly and not in time for us to be able to do something by two weeks from now ,  less than a week . don't we can do if anything , that 's worth , a eurospeech paper at this point . right . actually y we can tell from the data that we have , there 's a way to tell . it might not be a single person who 's always overlapping that person but any number of people , and , if you align the two hypothesis files across the channels , just word alignment , you 'd be able to find that . guess that 's last ther there 're few things we could do . one is just do like non lapels if we can get good enough alignments . another one was to try to get somehow align thilo 's energy segmentations with what we have . but then you have the problem of not knowing where the words are because these meetings were done before that segmentation . but there 's something that could be done . wanted to just do something not on recognition experiments because that 's ju way too early , but to be able to report , actual numbers . like if we had hand transcribed pe good alignments or hand checked alignments , then we could do this paper . it 's not that we need it to be automatic . but without knowing where the real words are , in time to an overlap really if it 's really an overlap , or if it 's just a segment correlated with an overlap , and that 's the difference to me between like a real paper and a promissory paper . if we d it might be possible to take thilo 's output and like if you have , like right now these meetings are all ,  they 're time aligned , if these are two different channels and somebody 's talking here and somebody else is talking here , just that word , ","except for it doesn't do on short things , remember . like that . i don't know that you can locate them very from the mixed signal , but there 's no overlap during the digit readings , it shouldn't really matter . but it 's clear from dan that this is not something you can do in a short amount of time . he thought if we can do something quick and dirty because dan said the cross cancellation , it 's not straight forward . it 's good to hear that it was not straight forward , thinking if we can get decent forced alignments , then at least we can do overall report of what happens with actual overlap in time , and it should work pretty if you took care of this recording time difference . but then if you add the dynamic aspect of adapting distances , then it wasn't don't we can do if anything , that 's worth , a eurospeech paper at this point . actually y we can tell from the data that we have , and , if you align the two hypothesis files across the channels , just word alignment , you 'd be able to find that . ",
Bmr018.D,"if thilo can tell us that there 're boundaries here , we should be able to figure that out because the only thing transcribed in this channel is this word . but , if there are things if you have two and they 're at the edges , it 's like here and here , and there 's speech here , then it doesn't really help you ,  it w it would , but , we don't know exactly where the words are because the transcriber gave us two words in this time bin and we don't really know ,  it 's if you have any ideas . i would right . that would be really helpful . that was another possibility .  right . in the future it won't be as much as an issue if transcribers are using the tightened boundaries to start with , then we have a good idea of where the forced alignment is constrained to . 'm no i don't know if this it 's a   but he also can adjust this minimum time duration constraint and then what you get is noises mostly , but that might be an right . and you can also see in the waveform exac   it 's you could just say it 's a noise , though , and write , a post processor will just all you have to do is just or just say it 's just put "" x , "" like "" not speech "" and then you can get or anyways , guess there 's something though , about keeping , and this is probably another discussion , keeping the that thilo 's detector detected as possible speech and just marking it as not speech than deleting it . because then when you align it , then the alignment can you can put a reject model or whatever , and you 're consistent with th the automatic system , whereas if you delete it or some , dummy reject mod whatever ,  that 's actually a better way to do it cuz the a the forced alignment will probably be more consistent than if it 's just as easy , but anyway , quick question , though , at a high level do people think , let 's just say that we 're moving to this new era of like using the , pre segmented t non synchronous conversations , does it make sense to try to take what we have now , which are the ones that , we have recognition on which are synchronous and not time tightened , and try to get something out of those for purposes of illustrating the structure and the nature of the meetings , or is it better to just , forget that and tr it 's right . that was everybody 's hope . and we can for the non lapel , but is it worth if we can't then we can fake it even if we 're we report , we 're wrong twenty percent of the time or ten percent of the time . that 's a good question actually . actually that 's a good question because we 'd have to completely redo those meetings , and we have like ten of them now . no , you 're right , actually no , that 's a good point , though , because for feature extraction like for prosody the meetings we have now , it 's a good chunk of data we need to get a decent f  we should at least try it even if we can't , right ? we might be able , at the very worst , we can get transcribers to correct the cases where you have a good estimate where these places are because the recognition 's poor . right ? and you 're  we need some way to push these first chunk of meetings into a state where we get good alignments .  right . but what you do wanna do is take the , even if it 's klugey , take the segments the synchronous segments , the ones from the hlt paper , where only that speaker was talking . use those for adaptation , cuz if you use everything , then you get all the cross talk in the adaptation , and it 's just blurred . and that we know , we have that . and it 's about roughly two thirds , very roughly averaged . that 's not completely negligible . like a third of it is bad for adaptation or it really it depends a lot . this is just an overall  but we 're morgan 's talk went very morgan 's talk went very it woke it was really a presented and got people laughing  no , i d i don't think that paper is really the hlt paper is really more of a introduction to the project paper , and , it 's probably wouldn't make sense , but right , right .    that might have been the one of the ones that we did . that might actually be useful but they 're all non native speakers . and e and extremely hard to follow , like word wise , i bet the transcri i have no idea what they 're talking about ,   this is tough for a language model probably but that might be useful just for speech . the the s thing that you have tightened @ @ ,   we have to 'm not saying anything about bias towards small headsize , but does seem , right . a little ,  and arrays , which is the i interesting and video , right .  right . that 's a great idea .  but they 're still planning to do like fake they have to do something like that , right . th that 's true .  no . it 's a good paper , bring the right . the summarization was interesting , i don't know anything about that field , ","if thilo can tell us that there 're boundaries here , we should be able to figure that out because the only thing transcribed in this channel is this word . but , if there are things if you have two and they 're at the edges , it 's like here and here , and there 's speech here , then it doesn't really help you , does it make sense to try to take what we have now , which are the ones that , we have recognition on which are synchronous and not time tightened , and try to get something out of those for purposes of illustrating the structure and the nature of the meetings , or is it better to just , forget that and tr because for feature extraction like for prosody the meetings we have now , it 's a good chunk of data we need some way to push these first chunk of meetings into a state where we get good alignments . but what you do wanna do is take the , even if it 's klugey , take the segments the synchronous segments , the ones from the hlt paper , where only that speaker was talking . use those for adaptation , cuz if you use everything , then you get all the cross talk in the adaptation , and it 's just blurred . like a third of it is bad for adaptation or the hlt paper is really more of a introduction to the project paper , and , that might actually be useful but they 're all non native speakers . this is tough for a language model probably ",Efforts to deal with cross-talk and improve forced alignments for non-digits data were also discussed. 
Bmr018.D,"but for this proposal on meeting summarization , it 's far cry because they weren't working with meeting type data , but he got an overview on some of the different approaches ,  there 're this was the last day , but , there 's that 's a huge field and probably the groups there may not be representative of the field , i don't know exactly that everyone submits to this particular conference , but yet there was , let 's see , this was on the last day , mitre , bbn , and , prager i wo it was no it was this was wednesday morning . the sentence ordering one , was that barselou , and these guys ? anyway , i it 's in the program , i should have read it to remind myself , but that 's useful and like when mari and katrin and jeff are here it 'd be good to figure out some kinds of things that we can start doing just on the transcripts cuz we already have   right . but what 's interesting is there 's all these different evaluations , like just , how do you evaluate whether the summary is good or not , and that 's what 's was interesting to me is that there 's different ways to do it , and hm umm . no .  the data issue comes up all the ti  and there and their and and that you could do better with more data , that 's clearly statistically the bigger the company the more words they use for training ? if you add more data ? or  it 's just no it 's different for different tasks . it depends a lot on whether , it disambiguation is exactly the case where more data is better , right ? you 're you can assume similar distributions , but if you wanted to do disambiguation on a different type of , test data then your training data , then that extra data wouldn't generalize ,  or done another language , or you there 's papers on portability and rapid prototyping and blah blah , and then there 's people saying , "" just add more data . ""  these are like two different religions ,    but th the same thing has happened in computational linguistics , right ? you look at the acl papers coming out , and now there 's turn back towards , we 've learned statistic we 're getting what we expect out of some statistical methods , and , the there 's arguments on both sides ,   and then you hit this yes ! and we won't laugh this time also . ",,
Bmr018.E,"we 're recording . i pre crashed it . it 's actually it depends on if the temp files are there or not , that at least that 's my current working hypothesis , that what happens is it tries to clear the temp files and if they 're too big , it crashes . that 's right . no , it doesn't clear those necessarily ,  it 's i they 're called temp files , but they 're not actually in the temp directory they 're in the scratch ,  they 're not backed up , but they 're not erased either on power failure .    and then everyone can listen to it later . yes . it 's what it sounds like . i since i 've been gone all week , i didn't send out a reminder for an agenda ,  do we have anything to talk about or should we just read digits and go ? really . it 's all a blur .  next weekend , week from a week from saturday . that 's good . y eurospeech is due on friday and then i 'm going down to san san jose friday night , if if we start and late saturday that 's a good thing . seattle . they 're flying from somewhere to somewhere , but , an agenda , or at least some things to talk about would be a good idea .   have you heard back from brian about that , chuck ? great .  though thi thilo isn't here , but , i have the program to insert the beeps . what i don't have is something to parse the output of the channelized transcripts to find out where to put the beeps , but that should be really easy to do . do we have a meeting that 's been done with , that we 've tightened it up to the point where we can actually give it to ibm and have them try it out ?  we had talked about doing edu as a good choice , though . whatever we have . right . it doesn't matter . and has it been corrected ? hand checked ? cuz that was one of the processes we were talking about as and time how long it takes .  i don't know , it seems to me w we probably should go ahead and do a whole meeting because we 'll have to transcribe the whole meeting anyway sometime . like guess if we have to do it again anyway , but , it 's gonna be one or two times real time at excuse me , two or more times real time , right ? cuz they have to at least listen to it . the other is i b i 'm just thinking that from a data keeping track of the data point of view , it may be best to send them whole meetings at a time and not try to send them bits and pieces . right . right . right . that was the question . though . i don't think h they typically work for what , four hours , something like that ? the they should be able to get through a whole meeting in one sitting . i would think , unless it 's a lot harder than we think it is , which it could be , certainly . or seven or eight .  that 's what it seems to me too , in that if they need to , just like in the other cases , they can listen to the individual , if they need to . but they don't have to for most of it . they have the normal channeltrans interface where they have each individual speaker has their own line , but you 're listening to the mixed signal and you 're tightening the boundaries , correcting the boundaries . you shouldn't have to tighten them too much because thilo 's program does that . right , you 'll have to i    i 'll work on that . that 's something that the transcribers will have to do . but then they have to do but then they for this meeting they would have to do seven times real time , and it would probably be more than that . right ? because they 'd have to at least listen to each channel all the way through . you 're talking about visually . don't think and that they 're going much more on acoustics than they are on visuals .  that 's actually true . you 're right . you 're right . i found the same thing that when i was scanning through the wave form i could see when someone started to read digits just by the shapes .  but  right . n the t right . yes . right . right . right . they wouldn't look at it at this point . they would just listen . the problem is that the interface doesn't really allow you to switch visuals . the problem is that the tcl tk interface with the visuals , it 's very slow to load waveforms . and when i tried that was the first thing i tried when i first started it , right ? it does some shape pre computation that it can then scroll it quickly ,  but then you can't change the resolution or scroll quickly .  we could do different interfaces , right ? we could use like x waves instead of transcriber , and it loads faster , certainly . that 's what i tried originally . actually before , dave gelbart did this , i did an interface which showed each waveform and ea a ribbon for each waveform , but the problem with it is even with just three waveforms it was just painfully slow to scroll . you just scroll a screen and it would , go "" kur chunk ! "" ","i have the program to insert the beeps . what i don't have is something to parse the output of the channelized transcripts to find out where to put the beeps , but that should be really easy to do . excuse me , two or more times real time , they have the normal channeltrans interface where they have each individual speaker has their own line , but you 're listening to the mixed signal and you 're tightening the boundaries , correcting the boundaries . you shouldn't have to tighten them too much because thilo 's program does that .  that 's something that the transcribers will have to do . but then they for this meeting they would have to do seven times real time , and it would probably be more than that . the problem is that the tcl tk interface with the visuals , it 's very slow to load waveforms . ","The Berkeley Meeting Recorder group discussed the preparation of a data sample for IBM, the manual adjustment of time bins by transcribers, recognition results for a test set of digits data, and forced alignments. "
Bmr018.E,"and it just was not doable with the current interface . that if we decide that we need that they need to see the visuals , we need to change the interface that they can do that . an but isn't the chopped up waveforms . isn't that and wouldn't that be the same as the mixed signal ?   hopefully , the mixed signal , the overlaps are pretty audible because it is volume equalized . think they should be able to hear . the only problem is , counting how many and if they 're really correct or not . i don't know . right but once that they happen , you can at least listen to the close talking ,  right . right ,  did dave do that change where you can actually just click rather than having to go up to the menu to listen to the individual channels ? i had suggested it before . don't know whether he did it or not .   we should get him to do that because , that would be much , much faster than going to the menu . then just buttons down at the bottom next to it . just something that it 's not in the menu option that you can do it much faster . it just seems to me that if you wanna quickly "" was that jane , no , was that chuck , no , was that morgan "" , right now , you have to go up to the menu , and each time , go up to the menu , select it , listen to that channel then click below , and then go back to the menu , select the next one , and then click below . you can definitely streamline that with the i with the interface . what ?  i would like to try to do something on digits but don't know if we have time . it 's due next friday we have to do the experiments and write the paper . i 'm gonna try , but , we 'll just have to see . actually i wanna get together with both andreas and , stephane with their respective systems . right , and i haven't had s chance to sit down and listen . i was going to do that this afternoon . morgan and i were having a debate about that . whereas it 's probably something pathologic and actually stephane 's results , confirm that . he s he did the aurora system also got very lousy average error , like fifteen or , fifteen to twenty percent average ? but then he ran it just on the lapel , and got about five or six percent word error ? that means to me that somewhere in the other recordings there are some pathological cases . but , we th that may not be true . it may be just some of the segments they 're just doing a lousy job on . 'll listen to it and find out since you 'd actually split it up by segment . can actually listen to it . he had sent that around to everyone , did you just sent that to me ?  it was bimodal . was it trimodal ,  just something really wrong with a bug is what that it 's like which probably means like there was a th the recording interface crashed , or there was a short someone was jiggling with a cord or , i extracted it incorrectly , it was labeled it was transcribed incorrectly , something really bad happened , and haven't listened to it yet to find out what it was . there 's a lot .  a normal .  cuz some of our non natives are pretty non native .  c high correlation . if we 'd just  are you talking about the fact that the recording software doesn't do time synchronous ? is that what you 're referring to ? that seems to me you can do that over the entire file and get a very accurate i didn't think either . right , which should be pretty straight forward .  that 's what i was gonna say . c mncm .  meeting with me in it . ugh ! i forgot the digital camera again . every meeting !  two words . thilo 's will . but . that will get enough of the cases to be useful . cuz it seemed like most of the cases are the single word sorts , or at least a single phrase in most of the bins . right .  yes .  tools . right . and we 'll just have to see how hard that is . whether the corrections take too much time . i was just thinking about the fact that if thilo 's missed these short segments , that might be quite time consuming for them to insert them . spurious . it might be easier to delete something that 's wrong than to insert something that 's missing . what do you think , jane ?  cuz then you just delete it , and you don't have to pick a time . the semantics aren't clear when you delete a segment , right ? because you would say you would have to determine what the surroundings were . if it 's really a noise . to add or to delete ?  that that 's an interface issue that might be addressable . but it 's the semantics that are questionable to me , that you delete something let 's say someone is talking to here , and then you have a little segment here . is that part of the speech ? is it part of the nonspeech ? w what do you embed it in ? i see . then they could just like put that 's what you meant by just put an "" x "" there . that 's an interesting idea . ","that if we decide that we need that they need to see the visuals , we need to change the interface that they can do that . the mixed signal , the overlaps are pretty audible because it is volume equalized . think they should be able to hear . the only problem is , counting how many and if they 're really correct or not . i would like to try to do something on digits but don't know if we have time . whereas it 's probably something pathologic and actually stephane 's results , confirm that . he s he did the aurora system also got very lousy average error , like fifteen or , fifteen to twenty percent average ? but then he ran it just on the lapel , and got about five or six percent word error ? that means to me that somewhere in the other recordings there are some pathological cases . it may be just some of the segments they 're just doing a lousy job on . 'll listen to it and find out since you 'd actually split it up by segment . just something really wrong with a bug is what which probably means like there was a th the recording interface crashed , or there was a short someone was jiggling with a cord or , i extracted it incorrectly , it was transcribed incorrectly , two words . and we 'll just have to see how hard that is . i was just thinking about the fact that if thilo 's missed these short segments , that might be quite time consuming for them to insert them . ",
Bmr018.E,"all they that all they would have to do is put like an "" x "" there . blank for silence , "" s "" "" s "" for speech , "" x "" "" x "" for something else . we 'll have to , eventually . and my hope was that we would be able to use the forced alignment to get it . but if we can't but if we can't , then we just have to i 'm thinking are you talking about for a paper , or are talking about for the corpus . cuz for the corpus it would be if everything were we wouldn't have to re do them , we would just have to edit them . when brian . you s you said ryan . and it 's like , "" who 's ryan ? ""   on the table , right ? that 's what he was saying . i don't think i don't think that would work , right ? because you 'd a lot of it 's dominated by channel properties .  it was higher than that , that 's pr right . i 'm doing that for avios . "" bleep "" . really . especially the batteried meter popping up , that was hilarious . right when you were talking about that . it 's full .  but that was funny . he was onto the bullet points about talking about the the little hand held , and trying to get lower power and on , and microsoft pops up a little window saying "" your batteries are now fully charged . "" i 'm thinking about scripting that for my talk , put a little script in there to say "" your batteries are low "" right when i 'm saying that . are too close ,  for eurospeech we want some results if we can get them . detail ,  overall . those are all  that 's what i was gonna say . the problem with those , they 're all german .  andreas is leaving the building .  see ya . before you l go it 's alright for you to talk a little without the mike i noticed you adjusting the mike a lot , did it not fit you  it wasn't just tightened enough , or  anyway . cuz , i 'm just thinking , we were we 're we 've been talking about changing the mikes , for a while , and if these aren't acoustically they seem really good , but if they 're not comfortable , we have the same problems we have with these stupid things . i find it very comfortable too , but , it looked like andreas was having problems , and morgan was saying it  you did wear it this morning ? it 's off , you can put it on . right . it 's more balanced . wh what it 's supposed to do is the backstrap is supposed to be under your crown , and that should be if it 's right against your head there , which is what it 's supposed to be , that balances it it doesn't slide up . right below if you feel the back of your head , you feel a little lump , and it 's supposed to be right under that . yes , exactly . that tilts , right ? in lots and lots of different ways . about heads ? probably it was  it probably just wasn't tight enough to the back of his head . the directions do talk about bending it to your size , which is not really what we want . wh we did that we at boeing i used i was doing augmented reality they had head mounts on , and we had a little jury rigged one with a welder 's helmet , and we had just a bag with a bunch of marbles in it as a counter balance .  anyway .  and arrays ,  and cameras . fifty nine elements . that 's right .  right . it is a good idea . h j jonathan fiscus did say that , they have lots of software for doing calibration for skew and offset between channels and that they 've found that 's just not a big deal .  scenario based . y right . their legal issues won't allow them to do otherwise . but it sounded like they were pretty thought out and they 're gonna be real meetings , it 's just that they 're with str with people who would not be meeting otherwise .  no . it 's just informal . i also sat and chatted with several of the nist folks . they seemed like a good group . right . the their broadcast news was their acoustic models and then all the other tasks were much simpler . they were command and control and that thing .  read wall street journal . it works .  that was one of the ones that i liked . that it not only works , in some cases it was better , which was pretty interesting , but that 's cuz they didn't control for parameters .  the broadcast news nets were not nets , acoustic models were a lot more complex . n not in that paper . one of the big problems with that is often the simpler task isn't fully doesn't have all the phones in it , and that makes it very hard . but i 've done the same thing . i 've been using broadcast news nets for digits , like for the spr speech proxy thing that i did ? that 's what i did . it works .  they have some . present .  do a trip report . right . a lot of different ones . mitre , bbn , ibm .  wasn't who did the order one ? ugh ! i 'm just bad at that . we do have word transcripts .  ","we 'll have to , eventually . and my hope was that we would be able to use the forced alignment to get it . for eurospeech we want some results cuz , i 'm just thinking , we were we 're we 've been talking about changing the mikes , for a while , acoustically they seem really good , but if they 're not comfortable , we have the same problems we have with these stupid things . wh what it 's supposed to do is the backstrap is supposed to be under your crown , it doesn't slide up . if you feel the back of your head , you feel a little lump , and it 's supposed to be right under that . ",
Bmr018.E,"someone who actually does take notes , i 'm very bad at note taking . i always write down the wrong things . a judge .  and as i said , i like the microsoft talk on scaling issues in , word sense disambiguation , that was interesting . the it was the only one it was the only one that had any real disagreement about .   it was . but it was a very simple case of "" to "" versus "" too "" versus "" two "" and "" there "" , "" their "" , "" they 're ""  them being beep , they went off to a billion .  the reason they can do that , is that they assumed that text that they get off the web , like from wall street journal , is correct , and edit it . that 's what they used as training data . it 's just saying if it 's in this corpus it 's correct . are irrelevant . but no , but there was still a spread . they weren't all up they weren't converging . they were all still spread . but they right , right .  but they hadn't even come close to that point . all the tasks were still improving when they hit a billion . but they didn't get closer . they just switched position .   it was liz .  right . but , one of their p they had a couple points . w one of them was that "" simpler algorithms and more data are is better "" . less memory , faster operation , simpler . right ? because their simplest , most brain dead algorithm did pretty darn when you got gave it a lot more data . and then also they were saying , "" m you have access to a lot more data . why are you sticking with a million words ? "" their point was that this million word corpus that everyone uses is ten or fifteen years old . and everyone is still using it ,  but we could talk about this this would be fun to do . right . machine learning . right . or you only have a million words for your some new task .  right .  cost .  that 's a big one .  that 's one of the slides they put up . forty five years of research .  the matters is the thing that was misleading . is that all of them are based on all the others , right ? just , you can't say   and i 'm saying the same thing happened with speech recognition , right ? for a long time people were hand c coding linguistic rules and then they discovered machine learning worked better . and now they 're throwing more and more data and worrying perhaps worrying less and less about , the exact details of the algorithms . except when they have a eurospeech paper . anyway . shall we read some digits ? are we gonna do one at a time ? or should we read them all agai at once again .  remember to read the transcript number that , everyone knows that what it is . and ready ? three , two , one . that 's really fast . ",,
Bmr018.F,"pre crashed ! no . the next , right ? it 's like the the deal is that be available after , like ten thirty i don't know how s how early you wanted to   saturday .   i haven't listened to them either , but there must be something wrong ,  unless our   no , i d i didn't . since i considered those preliminary , i didn't . but , if you take if you it 's actually , it it was trimodal , actually trimodal ,  there were t there was one h one bump at ze around zero , which were the native speakers , the non pathological native speakers . then there was another bump at , like fifteen whe  those were the non natives . and then there was another distinct bump at hundred , which must have been some problem . i can't imagine that in the recording and there was this one meeting , i forget which one it was , where like , six out of the eight channels were all , like had a hundred percent error . but but if i excluded the pathological ones , by definition , those that had like over ninety five percent error rate , and the non natives , then the average error rate was like one point four which seemed reasonable given that , the models weren't tuned for it . and the grammar wasn't tuned either . it was just a @ @ . i haven't split it up that way , but it would be right . it should   but if you p if you actually histogrammed it , and it was a it was zero was the most of them , but then there were the others were decaying from there . and then there was the bump for the non natives and then the pathological ones ,  've been struggling with the forced alignments . the scheme that i drew on the board last time where we tried to , allow reject models for the s speech from other speakers , most of the time it doesn't work very and the i haven't done the only way to check this right now was for me to actually load these into x waves and , plus the alignments , and s play them and see where the and it looks and looked of the utterances from you , chuck , in that one conversation , i don't know which you probably know which one it 's where you were on the lapel and morgan was sitting next to you and we can hear everything morgan says . but and some of what you you also appear quite a bit in that cross talk . i actually went through all of those , there were fifty five segments , in x waves , and did a crude check , and more often than not , it gets it wrong . there 's either the beginning , mostly the beginning word , where th you , chuck talks somewhere into the segment , but the first , word of what he says , often "" i "" but it 's very reduced "" i , "" that 's just aligned to the beginning of someone else 's speech , in that segment , which is cross talk . i 'm still tinkering with it , but it might be that we can't get clean alignments out of this out of those , channels ,  right . i don't thi i d i don't think that was the issue . the issue was that you have to you have you first have to have a pretty good speech detection on the individual channels . i haven't checked those yet . it 's very tedious to check these . we would really need , ideally , a transcriber to time mark the the be at least the beginning and s ends of contiguous speech . and , then with the time marks , you can do an automatic comparison of your forced alignments .  no , that 's how i 've been looking at it . i don't care that the individual words are aligned correctly , but you don't wanna , infer from the alignment that someone spoke who didn't .   i haven't i ha just haven't had the time to , do the same procedure on one of the would need a k i would need a channel that has a speaker whose who has a lot of overlap but s is a non lapel mike . and , where preferably , also there 's someone sitting next to them who talks a lot . i someone can help me find a good candidate and then i would be willing to hand from the insertions , fr from the right .  there 's  i 'm probably going to spend another day or trying to improve things by , by using , acoustic adaptation . the right now i 'm using the unadapted models for the forced alignments , and it 's possible that you get considerably better results if you , manage to adapt the , phone models to the speaker and the reject model to the to all the other speech .  that 's what said . right . i see .  no , it th exactly . you want to u that 's a good point .     some good jokes in it ? po low power we could compare before and after and see darn ! actually i have to go . ","since i considered those preliminary , i didn't . it 's actually , it it was trimodal , actually there were t there was one h one bump at ze around zero , which were the native speakers , then there was another bump at , like fifteen those were the non natives . and then there was another distinct bump at hundred , which must have been some problem . in the recording and there was this one meeting , i forget which one it was , where like , six out of the eight channels were all , like had a hundred percent error . if i excluded the pathological ones , by definition , those that had like over ninety five percent error rate , and the non natives , then the average error rate was like one point four which seemed reasonable given that , the models weren't tuned for it . and the grammar wasn't tuned either . but if you p if you actually histogrammed it , and it was a it was zero was the most of them , 've been struggling with the forced alignments . most of the time it doesn't work very i 'm still tinkering with it , but it might be that we can't get clean alignments out of this out of those , channels , the issue was that you have to you have you first have to have a pretty good speech detection on the individual channels . i haven't checked those yet . it 's very tedious to check these . we would really need , ideally , a transcriber to time mark the the be at least the beginning and s ends of contiguous speech . and , then with the time marks , you can do an automatic comparison of your forced alignments . but you don't wanna , infer from the alignment that someone spoke who didn't . would need a k i would need a channel that has a speaker whose who has a lot of overlap but s is a non lapel mike . and , where preferably , also there 's someone sitting next to them who talks a lot . and it 's possible that you get considerably better results if you , manage to adapt the , phone models to the speaker and the reject model to the to all the other speech . ","The Berkeley Meeting Recorder group discussed the preparation of a data sample for IBM, the manual adjustment of time bins by transcribers, recognition results for a test set of digits data, and forced alignments. Preliminary recognition results were presented for a subset of digits data. "
Bmr018.G,how about channel alright . but you can cancel that . really ?  what if you preload them all ? what if you were to preload all the channels or initially like doesn't    right . what is patho what do by pathological ? i 'm i don't   i see . right .    right . the which one ? i 'm    that 's the problem with the nsa speakers .  right .  ,what is patho what do by pathological ? ,
Bmr020.A," we 're recording . curly brackets . right . do we use square brackets for anything ? it 's still not a good idea .  you wanna keep them on you get good noise noise floors , through the whole meeting . change what in the software ? certainly we could do that , but i don't think that 's a good idea . we can do that in post processing if the application needs it . as an argument .  the only agenda items were jane was jane wanted to talk about some of the ibm transcription process . i condensed the three things you said into that . and then just i only have like , this afternoon and tomorrow morning to get anything done before i go to japan for ten days . if there 's anything that n desperately needs to be done , you should let me know now . you sent it in late .   that was the other thing  dave gelbart sent me email , he sent it to you too , that there 's a special topic , section in si in eurospeech on new , corp corpors corpora . and it 's not due until like may fifteenth . no . it 's a different one . and i s forwarded it to jane as being the most relevant person .  it was highly relevant have you did you look at the url ?  i 'll help , but can't , really do , most of it ,  but any help you need certainly provide .  that 's just cuz he talks really fast . i know but re regardless . it 's he 's in all of them , and he talks a lot . one participant . did you identify him as a senior member ?  the good , the bad , and the ugly . i 'm surprised . i have i had better start changing all my slides !   i was gonna ask that too . but but i don't know if that 's really a fair way of comparing between , multi party , conversations and two party conversations .  i don't know . that 's just something  i bet there 's a weak dependence . i 'm it 's not a real strong one . right ? because you right . you have a lot of two party , subsets within the meeting . regardless it 's an interesting result regardless .  did we all said "" and nodded at the same time ,    nope . right . who 's on channel four ? you 're getting a lot of breath . right . that 's great . that doesn't surprise me , because , with the close talking mikes , the signal will be much stronger . what normalization do you do ? in you recognizer , in the sri recognizer . over an entire utterance ? or windowed ?  right . i 'm not looking forward to it . at pause boundaries . on t closures , only . it 's to actually measure it though . made the font smaller and the narrows longer . took out white space .   there was monty python sketch with that . where the barber who was afraid of scissors was playing a tape of clipping sounds , and saying "" ,  "" how about them sports teams ? ""  printed it out , haven't read it yet . pub real . ask dan ellis . right . beta ? don't don't say . i put digits in my own home directory home ftp directory , but i 'll probably move them there as we can put it in the same place . just put in another directory . we 're losing , don and andreas at three thirty , right ?   it was just to talk about how to generate it . just that while i 'm gone , you can regenerate it if you decide to do it a different way . chuck and thilo should , now more or less know how to generate the file and , the other thing chuck pointed out is that , since this one is hand marked , there are discourse boundaries . right ? when one person is speaking , there 's breaks . whereas thilo 's won't have that . what we 're probably gonna do is just write a script , that if two , chunks are very close to each other on the same channel we 'll just merge them . and that will get around the problem of , the , one word beep , one word beep , one word beep "" .  that 's on the other channel . that 's because of channel overlap . it 's i that 's not gonna be true of the foreground speaker . that 'll only be if it 's the background speaker . that 's what said ,  that 's definitely a problem . battery . let me make a note on yours . the only , disadvantage of that is , then it 's hard to use an automatic method to do that . the advantage is that it 's probably faster to do that than it is to use the automated method and correct it .  we 'll just have to see .  it 's not that different . transcriber will do it . we pick the easy parts of the data and transcriber marks it by hand . and because no . after .  i didn't understand that .  leave the mikes on , and just put them on the table . let me mark you as no digits . we just have to listen to it and see how good they are . release to begin with . no , the undead meeting ,  blech . stress test . one and a half times real time . it just depends on how go ahead . ","the only agenda items were jane was jane wanted to talk about some of the ibm transcription process . dave gelbart sent me email , he sent it to you too , that there 's a special topic , section in si in eurospeech on new , corp corpors corpora . and it 's not due until like may fifteenth . i bet there 's a weak dependence . you have a lot of two party , subsets within the meeting . what normalization do you do ? and , the other thing chuck pointed out is that , since this one is hand marked , there are discourse boundaries . what we 're probably gonna do is just write a script , that if two , chunks are very close to each other on the same channel we 'll just merge them . that 's because of channel overlap . ","The main topics of the agenda were a paper submitted to Eurospeech and the organising of the recording transcriptions to be done by IBM. Regarding the transcriptions to be carried out by IBM, the discussion mainly concerned the format of the recordings that should be sent to them. "
Bmr020.A,"think , we won't know until we generate a bunch of beep files automatically , listen to them and see how bad they are . if that 's not hard to do . just it takes it just takes five minutes rather than , taking a second . hand hard coded it . no , but it 's easy enough to do . there are lots of ways to do it . i have one program that 'll do it . you can find other programs .  minus d , capital d . i didn't mean listen to everything , i meant , just see if they 're any good . we should  and we should just double check with brian on a few simple conventions on how they should mark things . cuz @ @ what i had originally said to brian was they 'll have to mark , when they can't distinguish between the foreground and background , because that was gonna be the most prevalent . but if we send them without editing , then we 're also gonna hafta have m notations for words that are cut off , and other sorts of , acoustic problems . but what we would like them to do is be conservative that they should only write down the transcript if they 're and otherwise they should mark it that we can check .  right . that 's a good idea . or at least sample it .  what can you do ?  it 's a little bit confusing . what 're we gonna do ? even a hand transcription would a hand transcriber would have trouble with that .  cuz there will be no channel on which it is foreground .  right , but , in general i don't think we want them transcribing the background , cuz that would be too much work . right ? for it because in the overlap sections , then they 'll but that 's gonna be all over the place . how w how will they tell the difference between that background and the dormal normal background of two people talking at once ? how would they know that ? because otherwise it 's gonna be too much work for them to mark it . they 'll be marking it all over the place .  but how are they gonna tell bet the difference between that and two people just talking at the same time ? but how do we d how do we do that for the i b m folks ? how can they tell that ? yes , that 's my opinion as we don't do anything for it with it . and they 'll just mark it however they mark it , and we 'll correct it when it comes back .  the default . no , not default . right .  worry about it when we get back .  as i say , we 'll just have to listen to it and see how horrible it is . sample it , rather .  and they 're very it 's very audible ? on the close talking channels ?  it 's the same problem as the lapel mike . but are we gonna do it altogether or separately ? nnn , there probably will be . i do . total concentration . are you guys ready ? ","and we should just double check with brian on a few simple conventions on how they should mark things . what can you do ? a hand transcriber would have trouble with that . we don't do anything for it with it . and they 'll just mark it however they mark it , and we 'll correct it when it comes back . ",
Bmr020.B,"that 's not allowed , curly brackets .  it 's not that bad if it 's at the end , but it 's in the beginning , it 's bad . manual post processing .  no it 's   i got this mail from was this smartkom message ? christoph draxler sent this ,    short words . but and in f but five percent of time or five percent of what ?    then you have to then then normalize by something like that ,    i j was just wondering .   don't train  somewhere in between the start and the end ?  somewhere in between the start and the end of the foreground ?  tag by  font smaller ,  put the abstract end .  battery ?   looks good .  i also used something around zero point five seconds for the speech nonspeech detector for the minimum silence length .  and hopefully the new meetings which will start from the channelized version will have better time boundaries and alignments .    whi which could have one drawback . if there is backchannel in between those three things , the n the backchannel will occur at the end of those three . and in the previous version where in the n which is used now , there , the backchannel would be in between there somewhere ,  that would be more natural but   i 'm @ @ now i 'm confused . you start with the presegmentation , r   and you just and you just use the s the segments of the dominant speaker then ? for sending to ibm or ?  on that meeting .  but but then we could just use the output of the detector , and do the beeping on it , and send it to i b  for some meetings , i 'm it i n that 's and some on some meetings it 's good .    we should perhaps just select meetings on which the speech nonspeech detection works and just use , those meetings to send to ibm and , do the other ones . it really depends . my impression is that it 's better for meetings with fewer speakers , and it 's better for meetings where nobody is breathing .  get that 's it .      and erase   nope .  u u  there 's there are some meetings where it would it 's possible like this .    what doing the gain ? it 's no problem . adjusting the gain ? that 's no problem . we can do that .  i used it ,            mark it .       th  the problem is that , nnn , the numbers ian gave in the paper is just some frame error rate . that 's not really what will be effective for the transcribers , is they have to in they have to insure that 's a real s spurt and but , the numbers   let me think . the speech the amount of speech that is missed by the detector , for a good meeting , i th is around or under one percent , i would say . but there can be  for  but there can be more there 's more amount speech more amount of the detector says there is speech , but there is none . that can be a lot when it 's really a breathy channel .   i can't really hhh , tsk . i don't have really representative numbers , that 's really i did this on four meetings and only five minutes of every meet of these meetings it 's not that representative , but , it 's perhaps , fff .  it 's perhaps then it 's perhaps five percent of something , which s the frames speech frames which are missed , but i can't really tell .     but   but that 's n that really doesn't happen very often that a word is cut in the middle that 's really not normal . that is marked as speech .    it 's i als i also thought of there are really some channels where it is almost only bre breathing in it . and to re run 's i 've got a p a method with loops into the cross correlation with the pzm mike , and then to reject everything which seems to be breath . i could run this on those breathy channels , and perhaps throw out     process it , hear into it . i would listen to it , and then     no . that won't be good .  and there 's one point which i which i r we covered when i r listened to one of the edu meetings , and that 's that somebody is playing sound from his laptop . and i the speech nonspeech detector just assigns randomly the speech to one of the channels ,  haven't i didn't think of s of this before , but what shall we do about s things like this ? but , sometimes the laptop is in the background and some somebody is talking , and , that 's really a little bit confusing , but     that 's a second question , "" what will different transcribers do with the laptop sound ? ""  it 's speech .  but , when thi when this is sent to the i m i b m transcribers , i don't know if they can tell that 's really        it 's really good sound ,  that would be very important ,   th there was a category for @ @ speech .     with with the laptop sound , or ? just  that will be a little bit of a problem as it really switches around between two different channels , what i would   comparable ,    what time is it ?   no . i don't . no . perhaps there are lots of errors in it ","i also used something around zero point five seconds for the speech nonspeech detector whi which could have one drawback . if there is backchannel in between those three things , the n the backchannel will occur at the end of those three . and you just use the s the segments of the dominant speaker then ? for sending to ibm but then we could just use the output of the detector , and do the beeping on it , and send it to i b the speech the amount of speech that is missed by the detector , for a good meeting , i th is around or under one percent , i would say . i can't really hhh , tsk . i don't have really representative numbers , i 've got a p a method with loops into the cross correlation with the pzm mike , and then to reject everything which seems to be breath . i could run this on those breathy channels , and there 's one point which i which i r we covered when i r listened to one of the edu meetings , and that 's that somebody is playing sound from his laptop . and i the speech nonspeech detector just assigns randomly the speech to one of the channels , ","Suggestions included sending only the channels with the dominant speakers for transcription, but it was finally agreed on sending the original files with minimal modifications, as there will be extensive in-house post-processing. "
Bmr020.C,"cur curly brackets . channel two .   not ri not right now . no . that 's interesting .  'm  too . i haven't gotten over to there yet , but what our discussion yesterday , i really i wanna submit one .  and , you offered to join me , if you want me to .  that 's right .  in terms of what ? in term one ?   do because is it partly , c correctly identified words ? or is it or just overall volume ?       that 's interesting .    no , it doesn't necessarily go against what he said , cuz he said "" generally speaking "" . in order to go against that claim you 'd have to big canvassing .  exactly . it 's i it 's not against his conclusion , it just says that it 's a bi bell curve , and that , you have something that has a range , in your sampling .     that 's a good point .  good idea .  yes , that 's right .   di did you use upper lower case also , or not ? u upper lower case or no ?   that 's but comma also or not ? i have a reference for that though .  i didn't know about liz 's finding on that , but i know of another paper that talks about something that  he still has his unix account here ,  and he and he 's i 'd hafta add him to meeting recorder , but   that 's good .  that adam created a b a script to generate the beep file ? to then create something to send to ibm . and , you should probably talk about that . but you were gonna to use the originally transcribed file because i tightened the time bins and that 's also the one that they had already in trying to debug the first stage of this . and my understanding was that ,  i haven't listened to it yet , but it sounded very good and i understand that you guys were going to have a meeting today , before this meeting . excellent .     interesting .     makes sense .   clever . yes . clever .  excellent . and that 's the purpose .  great idea !  now one thing that prevented us from apply you from applying exactly . the training that is the training meeting .   interesting .   interesting idea . great . i went back and hand marked the ba the bins , i ment i mentioned that last week .      that was   they were , reasonably tight , but not excruciatingly tight . that would 've taken more time . wanted to get it tha that if you have like "" in a swimming in a big bin , then it 's i can't answer that , but my main goal was in these areas where you have a three way overlap and one of the overlaps involves "" , and it 's swimming in this huge bin , i wanted to get it that it was clo more closely localized . i wanted to i wanted it to be able to l he be heard normally , that if you play back that bin and have it in the mode where it stops at the boundary , it sounds like a normal word . it doesn't sound like the person i it sounds normal . it 's as if the person could 've stopped there . and it wouldn't have been an awkward place to stop . now sometimes it 's these are involved in places where there was no time . and there wouldn't be a gap afterwards because some cases , there 're some people who have very long segments of discourse where , they 'll breath and then i put a break . but other than that , it 's really pretty continuous and this includes things like going from one sentence into the u one utterance into the next , one sentence into the next ,  w without really stopping . they , i in writing you have this two spaces and a big gap  but some people are planning and , a lot we always are planning what we 're going to say next . but in which case , the gap between these two complete syntactic units , which spoken things are not always complete syntactically , but it would be a shorter p shorter break than you might like . but the goal there was to not have the text be crudely parsed in a time bin . because from a discourse m purpose it 's more it 's more useful to be able to see and also from a speech recognition purpose my impression is that if you have too long a unit , it 's it doesn't help you very much either , cuz of the memory . that means that the amount of time after something is variable depending partly on context , but my general goal when there was sufficient space , room , pause after it to have it be natural feeling gap . which i c i don't it would be quantified as . wally chafe says that in producing narratives , the spurts that people use tend to be , that the what would be a pause might be something like two seconds . and that would be , one speaker . the discourse the people who look at turn taking often do use i was interested that you chose the that you use cuz that 's a unit that would be more consistent with sociolinguistics .     in any case , this meeting that i hand i hand adjusted two of them i mentioned before , and i sent email ,  and i sent the path . but i like this idea of for our purposes for the ibm preparation , n having these joined together , and it makes a lot of sense . ","no , it doesn't necessarily go against what he said , that adam created a b a script to generate the beep file ? but you were gonna to use the originally transcribed file because i tightened the time bins they were , reasonably tight , but not excruciatingly tight . i wanted it to be able to l he be heard normally , that if you play back that bin and have it in the mode where it stops at the boundary , it sounds like a normal word . it 's as if the person could 've stopped there . that means that the amount of time after something is variable depending partly on context , but my general goal when there was sufficient space , room , pause after it to have it be natural feeling gap . wally chafe says that in producing narratives , the spurts that people use tend to be , that the what would be a pause might be something like two seconds . i hand adjusted two of them but i like this idea of for our purposes for the ibm preparation , n having these joined together , ","Within this discussion, the rationale behind the coding of the time bins according to the flow of discourse was also explained. "
Bmr020.C,"and in terms of transcription , it would be easy to do it that way . the way that they have with the longer units , not having to fuss with adding these units at this time .  yes . i see .   that 's right , but thi this brings me to the other f stage of this which i discussed with you earlier today , which is the second stage is w what to do in terms of the transcribers adjustment of these data . i discussed this with you too . the tr the idea initially was , we would get for the new meetings , the e edu meetings , that thilo ha has now presegmented all of them for us , on a channel by channel basis . and i 've assigned i 've assigned them to our transcribers and far i 've discussed it with one , with and i had a about an hour discussion with her about this yesterday , we went through edu one , at some extent . and it occurred to me that that what we have in this format is you could consider it as a staggered mixed file , we had some discussion over the weekend a about at this other meeting that we were all a at about whether the tran the ibm transcribers should hear a single channel audio , or a mixed channel audio . and in a way , by having this chunk and then the backchannel after it , it 's like a stagal staggered mixed channel . and it occurred to me in my discussion with her yesterday that  the maximal gain , it 's from the ibm people , may be in long stretches of connected speech . it 's whole bunch of words which they can really do , because of the continuity within that person 's turn . what i 'm thinking , and it may be that not all meetings will be good for this , but what i 'm thinking is that in the edu meetings , they tend to be driven by a couple of dominant speakers . and , if the chunked files focused on the dominant speakers , then , when it got s patched together when it comes back from ibm , we can add the backchannels . it seems to me that the backchannels per se wouldn't be hard , but then there 's this question of the time @ @ marking , and whether the beeps would be and i 'm not exactly how that would work with the backchannels . and ,  and certainly things that are intrusions of multiple words , taken out of context and displaced in time from where they occurred , that would be hard . m my thought is i 'm having this transcriber go through the edu one meeting , and indicate a start time f for each dominant speaker , endpoi end time for each dominant speaker , and the idea that these units would be generated for the dominant speakers , and not for the other channels . it  the original plan was that the transcriber would adjust the t the boundaries , and all that for all the channels but , that is time consuming , and since we have a bottleneck here , we want to get ibm things that are usable s as soon as possible , then this seemed to me it 'd be a way of gett to get them a flood of data , which would be useful when it comes back to us . and also , at the same time she when she goes through this , she 'll be if there 's anything that was encoded as a pause , but really has something transcribable in it , then she 's going to make a mark w that bin would be marked as it as double dots and she 'll just add an s . and in the other case , if it 's marked as speech , and really there 's nothing transcribable in it , then she 's going to put a s dash , and i 'll go through and it and with a substitution command , get it that it 's clear that those are the other category . i 'll just , recode them . but the transcribable events that i 'm considering in this , continue to be laugh , as as speech , and cough and things like that , 'm not stripping out anything , just being very lenient in what 's considered speech .   what it what it involves is really a s the original pr procedure , but only applied to a certain strategically chosen s aspect of the data .  you got it . yes ! yes !   we start with your presegmented version we start with the presegmented version  and then the transcriber , instead of going painstakingly through all the channels and moving the boundaries around , and deciding if it 's speech or not , but not transcribing anything .  instead of doing that , which was our original plan , the tra they focus on the dominant speaker  what they do is they identify who 's the di dominant speaker , and when the speaker starts . mean , you 're still gonna we 're it 's based on your se presegmentation , that 's the basic thing .  exactly .  no . no , no .  s that 's why she 's notating the start and end points of the dominant speakers . on a in edu one , i as far as i listened to it , you start off with a s section by jerry . jerry starts at minute and and goes until minute and and then mark paskin comes in . and he starts at minute such and such , and goes on till minute and  and then meanwhile , she 's listening to both of these guys ' channels , ","but thi this brings me to the other f stage of this which i discussed with you earlier today , the e edu meetings , that thilo ha has now presegmented all of them for us , on a channel by channel basis . i 've assigned i 've assigned them to our transcribers and in a way , by having this chunk and then the backchannel after it , it 's like a stagal staggered mixed channel . the maximal gain , it 's from the ibm people , may be in long stretches of connected speech . what i 'm thinking , and it may be that not all meetings will be good for this , but what i 'm thinking is that in the edu meetings , they tend to be driven by a couple of dominant speakers . and , if the chunked files focused on the dominant speakers , then , when it got s patched together when it comes back from ibm , we can add the backchannels . the original plan was that the transcriber would adjust the t the boundaries , and all that for all the channels but , that is time consuming ,  ","Suggestions included sending only the channels with the dominant speakers for transcription, but it was finally agreed on sending the original files with minimal modifications, as there will be extensive in-house post-processing. "
Bmr020.C,"determining if there 're any cases of misclassification of speech as nothing , and nothing as speech , and a and adding a tag if that happens . but i wanted to say , his segmentation is good , that the part that i listened to with her yesterday didn't need any adjustments of the bins . far we haven't . this is not gonna be a major part of the process , at least not in not on ones that really  there 's the question o of whether  she i it 's a question of how much time we want our transcriber to invest here when she 's gonna have to invest that when it comes back from ibm anyway . if it 's only inserting "" ""s here and there , then , wouldn't that be something that would be just as efficient to do at this end , instead of having it go through i b m , then be patched together , then be double checked here .  i 'm open to that , it was yea good . the detector , this now , you were saying that they differ in how they work depending on channel s sys systems and but edu is great . how interesting .     is intelligible . that 's interesting ! cuz that 's directly related to the e end task . how interesting ! listening does take time too . how interesting ! edu was gonna say , edu one is good enough , we could include it in this set of this we send .    i see . numbers . that 'd be great .   they do already .  we have the unintelligibility convention . and actually they have one also , which certainty . was is it in a what is the t in a good meeting , what ?  see , the characteristics .    just  the other problem is , that when it i on the breathy ones , where you get breathing , inti indicated as speech . and we could just indicate to the transcribers not to encode that if they we could still do the beep file .     that would be great . that 's a great idea . excellent . i 'd be delighted with that , i was very impressed with the result .   interesting .   i pr i much prefer this , i was just trying to find a way cuz i don't think the staggered mixed channel is awfully good as a way of handling overlaps . but but    i 'd be delighted .  you were suggesting you suggested just not sending that part of the meeting . but do you would you would go ahead .    my standard approach has been if it 's not someone close miked , then , they don't end up on one of the close miked channels . they end up on a different channel . and we have any number of channels available , it 's an infinite number of channels . just put them on some other channel .  that 's right . they have a convention , in their own procedures , which is for a background sound .  it 'd be easy to say "" background laptop "" . because one of them i s background laptop or , background lt wouldn't take any time . and you can tell . acoustically , can't you tell ? is it ?    that sounds good . that sounds good .   s a as it comes back , we have a when we can use the channelized interface for encoding it , then it 'll be easy for us to handle . but if out of context , they can't tell if it 's a channeled speak a close miked speaker or not , then that would be confusing to them . i don't know , i it doesn't i don't either way would be fine with me , i don't really care . i have o i have one question . do you think we should send the that whole meeting to them and not worry about pre processing it ? or what is we should leave the part with the audio in the beep file that we send to ibm for that one , or should we start after the that part of the meeting is over in what we send . the part where they 're using sounds from their laptops . w if we have speech from the laptop should we just excise that from what we send to ibm , or should we i give it to them and let them do with it what they can ?  that 'd be to have a uniform procedure . good . and see how they do . and give them freedom to indicate if it 's just not workable .   excellent .    alright . that 's great . interesting .  alright . digits . we read the transcript number first , right ? quarter to four .  it 's interesting if there 're any more errors in these , than we had the first set . i usually do . i didn't this time . ","but i wanted to say , his segmentation is good , that the part that i listened to with her yesterday didn't need any adjustments of the bins . i 'm open to that , the other problem is , that when it i on the breathy ones , where you get breathing , inti indicated as speech . ",
Bmr020.D,"there 's gonna be some zeros from this morning 's meeting because i noticed that barry , you turned your mike off before the digits were  was it during digits ? it doesn't matter .   and then she said "" did i say three ? i meant four . "" wonder if you have to normalize by the numbers of speakers cuz not everybody talks .  three words from the end . i wonder i wonder about the and effect there . in other words if you weren't going to pause you will because you 're g being interrupted .   right . no , no . right , i see .   wasn't there some result , andreas liz presented this at some conference a while ago about backchannels  and that they tend to happen when the pitch drops . you get a falling pitch . and that 's when people tend to backchannel . do you rem right . right . but  you do . am i recalling correctly ? about   it made me think about a little device that could be built to  to handle those people that call you on the phone and just like to talk and talk . and you just have this little detector that listens for these drops in pitch and gives them the backchannel . and then you hook that to the phone and go off and do the do whatever you r wanna do , while that thing keeps them busy .      it wouldn't matter ?  random intervals . is it the same directory that you had suggested ? we could point mari to this also for her march o one request ? or you n remember she was she was saying that it would be if we had they had a or was she talking  she was saying it would be if they had the same set , that when they did experiments they could compare .   for the thing that we need to give brian the beeps file , was gonna probably put it it i 'll make another directory .  exactly .  after our meeting this morning thilo came in and said that there could be other differences between the already transcribed meeting with the beeps in it and one that has just r been run through his process . tomorrow , when we go to make the chunked file for ibm , we 're going to actually compare the two . he 's gonna run his process on that same meeting , and then we 're gonna do the beep ify on both , and listen to them and see if we notice any real differences .  w and we know that . wel we just wanna if there 're any major differences between doing it on the hand but the but there 's but there is this one issue with them in that there 're there are time boundaries in there that occur in the middle of speech .  like when we went t to  when i was listening to the original file that adam had , it 's like you hear a word then you hear a beep and then you hear the continuation of what is the same sentence .  and the th there are these chunks that look like that have right . you 'll have a chunk of , channel a which starts at zero and ends at ten , and then the same channel starting at eleven , ending at fifteen , and then again , starting at sixteen , ending at twenty . right , that 's three chunks where actually we w can just make one chunk out of that which is a , zero , twenty .  just wanted to make that it was clear . if you were to use these , you have to be careful not to pull out these individual     jane tightened these up by hand . jane ? in terms of the this new procedure you 're suggesting , u what is the 'm a little confused , because how do we know where to put beeps ? is it i d y is it but after we 've done thilo 's thing .  they just do that on the main channels .  now jane , my question is when they 're all done adjusting the w time boundaries for the dominant speaker , have they then also erased the time boundaries for the other ones ? how will we know who   she does the adjustments on those guys ?  if you don't have to adjust the bins , why not just do what it for all the channels ? why not just throw all the channels to ibm ?   right . without having her check anything . we have to fix it when it comes back anyhow . this might suggest an alternative c a hybrid between these two things . the one suggestion is we run thilo 's thing and then we have somebody go and adjust all the time boundaries and we send it to ibm . the other one is we just run his thing and send it to ibm . there 's a another possibility if we find that there are some problems , and that is if we go ahead and we just run his , and we generate the beeps file , then we have somebody listen beeps file . and they listen to each section and say "" yes , no "" whether that section is i intelligible or not . and it just there 's a little interface which will for all the "" yes "" es it then that will be the final beep file .   it wouldn't be that much fun for a transcriber to sit there , hear it , beep , yes or no . but it would be quick . but there 's no adjusting . and that 's what 's slow . there 's no adjusting of time boundaries .   right . they  that 's true . ","wonder if you have to normalize by the numbers of speakers i wonder about the and effect there . in other words if you weren't going to pause you will because you 're g being interrupted . liz presented this at some conference a while ago about backchannels and that they tend to happen when the pitch drops . we need to give brian the beeps file , was gonna probably put it after our meeting this morning thilo came in and said that there could be other differences between the already transcribed meeting with the beeps in it and one that has just r been run through his process . tomorrow , when we go to make the chunked file for ibm , we 're going to actually compare the two . and then we 're gonna do the beep ify on both , and listen to them and see if we notice any real differences . when i was listening to the original file that adam had , it 's like you hear a word then you hear a beep and then you hear the continuation of what is the same sentence . without having her check anything . the one suggestion is we run thilo 's thing and then we have somebody go and adjust all the time boundaries and we send it to ibm . the other one is we just run his thing and send it to ibm . there 's a another possibility if we find that there are some problems , and that is if we go ahead and we just run his , and we generate the beeps file , then we have somebody listen beeps file . and they listen to each section and say "" yes , no "" whether that section is ","Suggestions included sending only the channels with the dominant speakers for transcription, but it was finally agreed on sending the original files with minimal modifications, as there will be extensive in-house post-processing. "
Bmr020.D,"we can just catch it at the catch everything at this side . that 's the best way to go , just  we won't be able to s include it with this first thing , because there 's a part of the process of the beep file which requires knowing the normalization coefficients . and  right , except i don't think that the c the instructions for doing that was in that directory , right ? i didn't see where you had gener n doing th no , getting the coefficients , for each channel .  we just run that one we just run that j sound stat ?   send it to them .   when they when there 's either no speech in there , they don't understand , things like that .   and they may just guess at what those cut off words are , but w we 're gonna adjust everything when we come back    good . that really simplifies thing then . and we can just , get the meeting , process it , put the beeps file , send it off to ibm .  with very little work on our side . do what ? sample it . sample it .   right .  that would be very good . and then we can that 'll oughta be a good way to get the pipeline going . don't think jane 's saying they 're gonna transcribe it , but they 'll just mark it as being there 's some background there , right ? but minute , why would they treat them differently ? we may just have to do it when it gets back here .   we should just it 's gonna be too much work if we hafta worry about that if we just m send it all to them .  let worry about it when we get back in .  e  do you guys plug your ears when you do it ? i do . you don't ? how can you do that ? i gah ! you hate to have your ears plugged ? really ? ","that 's the best way to go , and we can just , get the meeting , process it , put the beeps file , send it off to ibm . ",
Bmr020.E,"is that voiced or unvoiced ? these poor transcribers . is there any way to change that in the software ? where like you just don't like if you if it starts catching zeros , like in the driver in the card , or somewhere in the hardware where if you start seeing zeros on w across one channel , you just add some random , @ @ noise floor like a small noise floor .   right .   right .  did he mean face like face to face ? or ?  that 's that 's me . that 's right . we 're gonna be looking at that . i 'd like to see that reference too .  that 's w that 's what i do .  i and , andreas , sampled ?   either we should regenerate the original versions , or we should just make a note of it . that 's the first meeting i cut both versions . just to check which w if there is a significant difference . they 're all downsampled ,    probably by tomorrow  i 'll send you an email .  because liz decided to go ahead with the downsampled versions cuz we can there was no s like , r significant difference . it does take up less disk space , and it did even better than the original versions , which is just , probably random . but , they probably w want the originals . hey mon hafta booga . i have to go as   ","but , they probably w want the originals . ",
Bmr020.F,"we can say the word "" zero "" all we want , but just curly brackets .  correction for transcribers .  u u   i probably just should have left it on . did have to run , but i u i actually don't the default is anymore as to how we 're using the front end but for when we use the icsi front end , but there is an o an option in rasta , which , in when i first put it in , back in the days when i actually wrote things , i did actually put in a random bit or that was in it , but then i realized that putting in a random bit was equivalent to adding adding flat spectrum , and it was a lot faster to just add a constant to the spectrum . then started doing that instead of calling "" rand ""  it d it does that . gee ! here we all are ! there 's an agenda ? and you just sent off a eurospeech paper ,  right . you first you have to do the first one , and then  they had some extension that they announced this isn't the aurora one ? it 's another one ?  that 's  that 's a great idea . n no .  we have now , but  get these aarp things , but i 'm not se really senior yet , but  but other than that delightful result , what was the rest of the paper about ? you sent it to me but i haven't seen it yet . we have pretty limited sample here . but what was it like , say , in the robustness meeting , ten percent ?    and right . were you including the lapel in this ? and did the la did the problems with the lapel go away also ? or fray for insertions ? less you still i would presume that you still would have somewhat higher error with the lapel for insertions than  cuz again , looking forward to the non close miked case , that we s still i it 's the high signal to noise ratio here that helps you .  but he he 's right , y you weren't intending to pause but you were intending to stop for fifty seven milliseconds , but then chuck came in and you paused for a second or more .  right .  actually for a lot of these people you could just backchannel continuously and it would be fine .   u r d rdr ,   the no vowels .   anyone who hears this meeting now knows the is that a dash or a dot in there ?  that 's why it was good to have andreas , say these things but we should probably talk about the ibm transcription process that  it looks much better . right . if it 's working that sounds like a good idea since as you say you have to do with the other end anyway . what 's the problem the l i forget . is the problem the lapel , or  the dead meetings . i don't know . it would be quick but they 're still listening to everything .  i don't know , 'm really tending towards what 's the worst that happens ? do the transcribers as long as th on the other end they can say there 's something conventions that they say "" "" and then we can flag those later . i it i  but i have a  but but i have another suggestion on that , which is , since , really what this is , is trying to in the large , send the right thing to them and there is gonna be this post processing step ,  why don't we check through a bunch of things by sampling it ? right ? in other words , rather than , saying we 're gonna listen to everything  you do a bunch of meetings , you listen to a little bit here and there , if it sounds like it 's almost always right and there 's not any big problem you send it to them . and , then they 'll send us back what we w what they send back to us , and we 'll fix things up and some meetings will cost more time to fix up than others .  have an order of it 's probably in your paper that i haven't looked at lately , but an order of magnitude notion of how on a good meeting , how often do you get segments that come in the middle of words and forth , and in a bad meeting how often ? he 's saying , that the edu meeting was a good meeting , right ? and it was almost always doing the right thing . wanted to get some sense of what almost always meant . and then , in a bad meeting , or p some meetings where he said he 's had some problems , what does that mean ? mean does one of the does it mean one percent and ten percent ? or does it mean five percent and fifty percent ?  or percentage isn't the right word , but how many per minute , or  but that 's less of a problem . they 'll just listen . it 's just wasted time . and th and that 's for a good meeting . now what about in a meeting that you said we 've you 've had some more trouble with ? right . sometime , we might wanna go back and look at it more in terms of how many times is there a spurt that 's interrupted ? something like that ? and again that is probably less of a problem ","and you just sent off a eurospeech paper , we should probably talk about the ibm transcription process that but i have another suggestion on that , which is , since , really what this is , is trying to in the large , send the right thing to them and there is gonna be this post processing step , why don't we check through a bunch of things by sampling it ? if it sounds like it 's almost always right and there 's not any big problem you send it to them . and , then they 'll send us back what we w what they send back to us , and we 'll fix things up notion of how on a good meeting , how often do you get segments that come in the middle of words and forth , and in a bad meeting how often ? ","The main topics of the agenda were a paper submitted to Eurospeech and the organising of the recording transcriptions to be done by IBM. Regarding the transcriptions to be carried out by IBM, the discussion mainly concerned the format of the recordings that should be sent to them. Suggestions included sending only the channels with the dominant speakers for transcription, but it was finally agreed on sending the original files with minimal modifications, as there will be extensive in-house post-processing. "
Bmr020.F,"because if you 're if there 's if a word is split , then they might have to listen to it a few times to really understand that they can't quite get it . whereas if they listen to it and there 's don't hear any speech they 'd probably just listen to it once . there 'd you 'd think there 'd be a factor of three or four in , cost function , between them what you 're saying is that nearly always what happens when there 's a problem is that there 's some nonspeech that that is b interpreted as speech . then , we really should just send the right ? because that doesn't do any harm . if they hear a dog bark and they say what was the word , they they ruff !    but th again , that that would be good , and what that 'll do is just cut the time a little further . but none of this is that really needs somebody doing these explicit markings . cuz the other thing that was concerning me about it was that it seemed specialized to the edu meeting , and that then when you get a meeting like this and you have a b a bunch of different dominant speakers how are you gonna handle it . whereas this sounds like a more general solution is   i would just use some samples , make you don't send them three hours of "" bzzz ""  great . that 's life .  what was the l what was the laptop sound ? was it speech , or was it great .   isn't there a category something like "" sounds for someone for whom there is no i close mike "" ?    shall we do digits and get out of here ? yes ma ' which part ?   cuz , i wouldn't don't think we would mind having that transcribed , if they did it .   let 's do digits . why don't we do it together , that 's a fast way to do it . one , two , three , go ! i haven't been , no . concentration .  ",and what that 'll do is just cut the time a little further . ,
Bmr020.G,"i 'm doing some square brackets , coffee sipping , square brackets . gar darn ! right . i hope they accept it . i both actu as a submission and as a paper .  but we actually exceeded the delayed deadline by o another day ,   liz had sent them a note saying "" could we have another "" i don't know , "" three days "" and they said yes . but u several people sent this ,    there were some interesting results in this paper , though . that morgan accounted for fifty six percent of the robustness meetings in terms of number of words . number of words . no . according to the transcripts . we didn't mention morgan by name we just we something about no , we as identify him as the person dominating the conversation . right   it was about it had three sections  three kinds of results , if you will . the one was that the just the amount of overlap  s in terms of number of words and also we computed something called a "" spurt "" , which is essentially a stretch of speech with no pauses exceeding five hundred milliseconds . and we computed how many overlapped i spurts there were and how many overlapped words there were . for four different corpora , the meeting recorder meetings , the robustness meetings switchboard and callhome , and , found and compared the numbers .  and found that the ,  as you might expect the meeting recorder meetings had the most overlap but next were switchboard and callhome , which both had roughly the same , almost identical and the robustness meetings were had the least ,  one unexpected result there is that two party telephone conversations have about the same amount of overlap , in gen order of magnitude wise as , as face to face meetings with multiple  also , i in the levinson , the pragmatics book , in textbook , there 's i found this great quote where he says how people it talks about how how people are good at turn taking , and they 're good that generally , u the overlapped speech does not is less than five percent .  this is way more than five percent . in real conversations , everyday conversations . it 's what these conversation analysts have been studying for years and years there . he made a claim  it 's time . but still u  there are slight there are differences in how you measure it , but still it 's the difference between between that number and what we have in meetings , which is more like , close to in meetings like these , close to twenty percent . that robustness meeting ? it was about half of the r in terms of number of words , it 's like seventeen or eigh eighteen percent for the meeting recorder meetings and about half that for , the robustness . we didn't get to look at that , but this obvious thing to see if there 's a dependence on the number of participants . right . right . right .  right . and then and we also d computed this both with and without backchannels , you might think that backchannels have a special status because they 're essentially just r right . but , even if you take out all the backchannels you treat backchannels l as nonspeech , as pauses , you still have significant overlap . it goes down from for switchboard it goes down from i don't know f don't know f fourteen percent of the words to don't know , eleven percent it 's not a dramatic change , it 's anyway , it 's that was one set of results , and then the second one was just the we had in the hlt paper on how overlaps effect the recognition performance . and we rescored things a little bit more carefully . we also fixed the transcripts in numerous ways . but mostly we added one number , which was what if you score ignoring all the conjecture from the hlt results was that most of the added recognition error is from insertions due to background speech . we scored all the recognition results , in such a way that the  don 's been working hard .  if you have the foreground speaker speaking here , and then there 's some background speech , may be overlapping it somehow , and this is the time bin that we used , then you 're gonna get insertion errors here and here . right ? we scored everything , and i must say the nist scoring tools are pretty for this , where you just ignore everything outside of the , region that was deemed to be foreground speech . and where that was we had to use the t forced alignment , results from s for  that 's somewhat subject to error , but still we don did some ha hand checking and we think that based on that , we think that the results are valid , although some error is gonna be in there . but what we found is after we take out these regions we only score the regions that were certified as foreground speech , the recognition error went down to almost the level of the non overlapped speech . that means that even if you do have background speech , if you can somehow separate out or find where it is , the recognizer does a good job , even though there is this back right . right .    we just @ @ we do u vit we do vtl vocal tract length normalization , w and we we make all the features have zero mean and unit variance . over the entire c over the entire channel . over the but now we didn't re align the recognizer for this . we just took the old ","i hope they accept it . we actually exceeded the delayed deadline by o another day , there were some interesting results in this paper , though . that morgan accounted for fifty six percent of the robustness meetings in terms of number of words . no . according to the transcripts . we as identify him as the person dominating the conversation . it was about it had three sections the one was that the just the amount of overlap s in terms of number of words and also we computed something called a "" spurt "" , which is essentially a stretch of speech with no pauses exceeding five hundred milliseconds . and we computed how many overlapped i spurts there were and how many overlapped words there were . for four different corpora , the meeting recorder meetings , the robustness meetings switchboard and callhome , as you might expect the meeting recorder meetings had the most overlap but next were switchboard and callhome , which both had roughly the same , and the robustness meetings were had the least , also , i in the levinson , the pragmatics book , in textbook , there 's i found this great quote where he says how people it talks about how how people are good at turn taking , and they 're good that generally , u the overlapped speech does not is less than five percent . in terms of number of words , it 's like seventeen or eigh eighteen percent for the meeting recorder meetings and about half that for , the robustness . we didn't get to look at that , but , even if you take out all the backchannels you still have significant overlap . and then the second one was just the we had in the hlt paper on how overlaps effect the recognition performance . and we rescored things a little bit more carefully . the conjecture from the hlt results was that most of the added recognition error is from insertions due to background speech . we scored everything , and i must say the nist scoring tools are pretty for this , where you just ignore everything outside of the , region that was deemed to be foreground speech . but what we found is after we take out these regions we only score the regions that were certified as foreground speech , the recognition error went down to almost the level of the non overlapped speech . we do vtl vocal tract length normalization , w and we we make all the features have zero mean and unit variance . over the entire c over the entire channel . now we didn't re align the recognizer for this . ","All these measurements were based on the sample of available transcripts. The results presented in the former show a significant percentage of overlapping speech even without counting in backchanneling. Additionally, the high error rate in the recognition of such overlapping speech by the SRI recogniser was minimised simply by changing the scoring method used. "
Bmr020.G,"this is actually a sub optimal way of doing it , right ? we took the old recognition output and we just scored it differently . the recognizer didn't have the benefit of knowing where the foreground speech a start yes . it it u not per not completely , but yes , dramatically . we have to  should bring the table with results . we can look at it monday . yes . it 's it 's yes .   right . u s right .  that was number that was the second set of the second section . and then , the third thing was , we looked at , what we call "" interrupts "" , although that 's that may be a misnomer , but we looked at cases where we used the punctuation from the original transcripts and we inferred the beginnings and ends of sentences .     no , we only used , periods , question marks and exclamation . and we know that there 's th that 's not a very g we miss a lot of them , but it 's f i no commas . no . and then we looked at locations where ,  if you have overlapping speech and someone else starts a sentence , where do these where do other people start their turns not turns really , but sentences ,  we only looked at cases where there was a foreground speaker and then at the to at the the foreground speaker started into their sentence and then someone else started later .  and what  yes . that such that there was overlap between the two sentences . the question was how can we what can we say about the places where the second or actually , several second speakers , start their "" interrupts "" , as we call them . w and we looked at this in terms of  we had  to for the purposes of this analysis , we tagged the word sequences , and we time aligned them .  and we considered it interrupt if it occurred in the middle of a word , we considered that to be a interrupt as if it were at the beginning of the word . that , if any part of the word was overlapped , it was considered an interrupted word . and then we looked at the locatio the , the features that the tags because we had tagged these word strings , that occurred right before these interrupt locations . and the tags we looked at are the spurt tag , which says or actually  end of spurt . whether there was a pause essentially here , because spurts are a defined as being five hundred milliseconds or longer pauses , and then we had things like discourse markers , backchannels , disfluencies .  filled pauses disfluen the d 's are for , the interruption points of a disfluency , where you hesitate , or where you start the repair there . what else do we had . repeated repeated words is another of that disfluencies and forth . we had both the beginnings and ends of these the end of a filled pause and the end of a discourse marker . and we just eyeballed we didn't really hand tag all of these things . we just looked at the distribution of words , and every "" and "" , and "" were the were deemed to be backchannels and "" and "" and right "" , were not "" right "" . "" right "" is a backchannel . but we just based on the lexical identity of the words , we tagged them as one of these things . and the d the interruption points we got from the original transcripts .  and then we looked at the disti we looked at the distribution of these different kinds of tags , overall and particularly at the interruption points . and we found that there is a marked difference  that after at the end after a discourse marker or after backchannel or after filled pause , you 're much more likely to be interrupted than before .  and also after spurt ends , which means in p inside pauses . pauses are always an opportunity for we have this little histogram which shows these distributions and , it 's it 's not no big surprises , but it is interesting from  we 're ne right . there 's no statement about and effect . this is just a statistical correlation ,  right . right . right . anyway . and that was it . and we we wrote this and then , we found we were at six pages , and then we started cutting furiously and threw out half of the material again , and played with the latex and  and until it fi no , no . w d you couldn't really make everything smaller but we s we put i the gap between the two columns is like ten millimeters , d shrunk it to eight millimeters and that helped some . and like that .     y we didn't talk about , prosodic , properties although that 's i take it that 's something that don will look at now that we have the data and we have the alignment ,  this is purely based on the words and  anyway ,   there 's actually there 's this a former student of here from berkeley , nigel ward . do him ? he did a system in he lives in japan now , and he did this backchanneling , automatic backchanneling system . it 's a very exactly what you describe , but for japanese . and it 's for japa in japanese it 's really important that you backchannel . it 's really impolite if you don't , and  anyway . the paper 's on line and y cc ' ed a message to meeting recorder with the url you can get it . one more thing . ","the recognizer didn't have the benefit of knowing where the foreground speech a start and then , the third thing was , we looked at , what we call "" interrupts "" , we used the punctuation from the original transcripts and we inferred the beginnings and ends of sentences . if you have overlapping speech and someone else starts a sentence , where do these where do other people start their turns not turns really , but sentences , the question was how can we what can we say about the places where the second or actually , several second speakers , start their "" interrupts "" , as we call them . to for the purposes of this analysis , we tagged the word sequences , and we time aligned them . that , if any part of the word was overlapped , it was considered an interrupted word . because we had tagged these word strings , that occurred right before these interrupt locations . and the tags we looked at are the spurt tag , or actually end of spurt . whether there was a pause essentially here , and then we had things like discourse markers , backchannels , disfluencies . filled pauses we didn't really hand tag all of these things . but we just based on the lexical identity of the words , we tagged them as one of these things . at the end after a discourse marker or after backchannel or after filled pause , you 're much more likely to be interrupted than before . and also after spurt ends , which means in p inside pauses . there 's no statement about and effect . y we didn't talk about , prosodic , properties although that 's i take it that 's something that don will look at now that we have the data and we have the alignment , there 's actually there 's this a former student of here from berkeley , nigel ward . and he did this backchanneling , automatic backchanneling system . but for japanese . and it 's for japa in japanese it 's really important that you backchannel . anyway . the paper 's on line ","Finally, a strong correlation between pauses and interruptions was confirmed. Other features, like prosody, will be studied in the near future. "
Bmr020.G,"'m actually about to send brian kingbury an email saying where he can find the s the m the material he wanted for the s for the speech recognition experiment ,  but i haven't sent it out yet because actually my desktop locked up , like i can't type anything .  b if there 's any suggestions you have for that i was just gonna send him the i made a directory . i called it  this isn't he does ?  but he has to he prefe he said he would prefer ftp and also , the other person that wants it there is one person at sri who wants to look at the the the data we have far , and figured that ftp is the best approach . what i did is i @ i made a n new directory after chuck said that would c that was gonna be a good thing . it 's "" ftp pub real "" exactly . mtgc what is it again ? cr or  right ? the same as the mailing list , and   and then under there actually and this directory , is not readable . it 's only accessible . in other words , to access anything under there , you have to be told what the name is . that 's g quick and dirty way of doing access control .  and the directory for this i call it i "" asr zero point one "" because it 's meant for recognition . and then in there i have a file that lists all the other files , that someone can get that file and then know the file names and therefore download them . if you don't know the file names you can't you can dash . anyway . all i was gonna do there was stick the transcripts after we the way that we munged them for scoring , because that 's what he cares about , and  and also and then the waveforms that don segmented . just tar them all up f for each meeting i tar them all into one tar file and g zip them and stick them there . and    march o one .  she wanted that also ? right , but they don't have a recognizer even . but we can send cc mari on this that she knows right . make ano make another directory . you don't n m   they are ?   beca because in one directory there 's two versions .  and but  but for the other meetings it 's the downsampled version that you have .  that 's th important to know ,   we should probably give them the non downsampled versions .  alright , then i 'll hold off on that and i 'll for you  gen  alright .  definitely they should have the full bandwidth version ,  it takes up less disk space , for one thing .   right . it was a small difference but    good . good that it 's a good thing that  beep ify ! this training meeting , un is that some data where we have very accurate time marks ? for   because   it right , what i would i was interested in is having a se having time marks for the beginnings and ends of speech by each speaker . because we could use that to fine tune our alignment process to make it more accurate .   it i don't care that there 's actually abutting segments that we have to join together . that 's fine . but what we do care about is that the beginnings and ends are actually close to the speech inside of that   what is the how tight are they ?  no , no ! i don actually i i it 's f that 's fine because we don't want to th that 's perfectly fine . it 's good . you always want to have a little bit of pause or nonspeech around the speech , say for recognition purposes .  but just u w get an id wanted to have an idea of the of how much extra you allowed  that interpret the numbers if i compared that with a forced alignment segmentation .    right . but are we talking about , i don't know , a tenth of a second ? a ?  how much extra would you allow at most        right .    that 's fine .    we chose half a second because if you go much larger , you have a y your statement about how much overlap there is becomes less , precise , because you include more of actual pause time into what you consider overlap speech .   it 's compromise , and it 's also based liz suggested that value based on the distribution of pause times that you see in switchboard and other corpora .    i see .     at some point we will try to fine tune our forced alignment using those as references because what you would do is you would play with different parameters . and to get an object you need an objective measure of how closely you can align the models to the actual speech . and that 's where your data would be very important to have . i will   right .   right . and i 'm leaving .  ","'m actually about to send brian kingbury an email saying where he can find the s the m the material he wanted for the s for the speech recognition experiment , he prefe he said he would prefer ftp and also , the other person that wants it there is one person at sri who wants to look at the the the data we have far , and figured that ftp is the best approach . what i did is i @ i made a n new directory actually and this directory , is not readable . it 's only accessible . that someone can get that file and then know the file names and therefore download them . all i was gonna do there was stick the transcripts after we the way that we munged them for scoring , and also and then the waveforms that don segmented . but for the other meetings it 's the downsampled version that you have . we should probably give them the non downsampled versions . what i would i was interested in is having a se having time marks for the beginnings and ends of speech by each speaker . because we could use that to fine tune our alignment process it 's good . you always want to have a little bit of pause or nonspeech around the speech , say for recognition purposes . we chose half a second because if you go much larger , you have a y your statement about how much overlap there is becomes less , precise , liz suggested that value based on the distribution of pause times that you see in switchboard and other corpora . at some point we will try to fine tune our forced alignment using those as references ",An FTP directory containing such experimental data is being set up for the benefit of other researchers. 
Bro023.A," we 're going . just for a visit ?   really guy . wh back when i was a grad student he was here for a , year or n six months . something like that .  we got lots to catch up on . and we haven't met for a couple of weeks . we didn't meet last week , morgan . i went around and talked to everybody , and it seemed like they had some new results but rather than them coming up and telling me i figured we should just week and they can tell both all of us .  why don't we start with you , dave , and then , we can go on .  twelve seconds twelve seconds back from the current frame , is that what     it seems like for your in normal situations you would never get twelve seconds of speech , right ? i 'm not e u is this twelve seconds of regardless of speech or silence ? or twelve seconds of speech ?   you cache the utterances ? that 's how you get your ,       what would be really is if you could have this probably users would never like this but if you had could have a system where , before they began to use it they had to introduce themselves , verbally .  "" hi , my name is and i 'm from blah blah . "" and you could use that initial speech to do all these adaptations and  is that , that it ?  do you wanna go , sunil ? improves over the base line mfcc system ?   is this with the v new vad ? can i ask just a high level question ? can you just say like one or two sentences about wiener filtering and why are people doing that ? what 's the deal with that ?    do you assume the noise is the same ?  i see .  i see .   is this , similar to just regular spectral subtraction ?  do people use the wiener filtering in combination with the spectral subtraction typically , or is i are they competing techniques ?  o i see , i see .    why did you choose , wiener filtering over some other one of these other techniques ?  you 're trying @ @ them all .  i see .     that makes sense .          that 's like , best case performance ? tha that it ?  do you wanna go , stephane ? "" subtracting more "" , meaning ?  i see .      speech shaped ? when y when you talk about there being something less than zero after subtracting the noise , is that at a particular frequency bin ?  and when you say you 're adding something that has the overall shape of speech , is that in a particular frequency bin ? or you 're adding something across all the frequencies when you get these negatives ?   i gotcha . right .  what does that mean ? i 'm trying to understand what it means when you do the spectral subtraction and you get a negative . it means that at that particular frequency range you subtracted more energy than there was actually   in an ideal word i world if the noise were always the same , then , when you subtracted it the worst that i you would get would be a zero . the lowest you would get would be a zero , cuz i if there was no other energy there you 're just subtracting exactly the noise .    the opposite of that would be if you find out you 're going to get a negative number , you don't do the subtraction for that bin . that would be almost the opposite , right ? instead of leaving it negative , you don't do it . if your subtraction 's going to result in a negative number , you don't do subtraction in that .  i 'm just saying that 's like the opposite .    what is it the , france telecom system uses for do they use spectral subtraction , or wiener filtering , or ?  i see .   i see .  does the smoothing in the time domain help do you get this musical noise with wiener filtering or is that only with , spectral subtraction ? does the smoothing in the time domain help with that ? or some other smoothing ?       that 's the musical noise ?   could you train a neural net to do spectral subtraction ?  i was thinking if you had a clean version of the signal and a noisy version , and your targets were the m f whatever , frequency bins people do that ?    how did it compare on for good cases where it that it was trained on ? did it do pretty    you could say it 's built in .   and that 's what causes the latency ?    a quick question just about the latency thing . if there 's another part of the system that causes a latency of a hundred milliseconds , is this an additive thing ? or c or is yours hidden in that ?  it 's additive .    couldn't ,  i couldn't you just also i if that the l the largest latency in the system is two hundred milliseconds , don't you couldn't you just buffer up that number of frames and then everything uses that buffer ? and that way it 's not additive ?    i wasn't thinking of that one in particular but more of , if there is some part of your system that has to buffer twenty frames , can't the other parts of the system draw out of that buffer and therefore not add to the latency ?   you have one minimum for each frequency ?   it 'll keep going till when they run out of disk space , but we 're  shall we , do digits ? want to go ahead , morgan ?  ","just for a visit ? we got lots to catch up on . and we haven't met for a couple of weeks . why don't we start with you , dave , it seems like for your in normal situations you would never get twelve seconds of speech , do you wanna go , sunil ? improves over the base line mfcc system ? can i ask just a high level question ? can you just say like one or two sentences about wiener filtering and why are people doing that ? do you wanna go , stephane ? ","There are hopes that a visitor coming for three weeks, may lead to a longer term collaboration. The ICSI Meeting Recorder Group of Berkeley met for the first time in two weeks. A number of the group also took time to explain the basics of their approaches to the group. "
Bro023.B,"  that 's   we met him in amsterdam .  i haven't noticed him .  you need twelve seconds in the past to estimate , right ? or l or you 're looking at six sec seconds in future and six in no , it 's all   but do you really want to calculate the mean ? and you neglect all the silence regions or you just use everything that 's twelve seconds , and ye   and they are pretty short . shor     you really need a lot of speech to estimate the mean of it .         the last two weeks was , like 've been working on that wiener filtering . and ,  found that , s single like , do a s normal wiener filtering , like the standard method of wiener filtering . and that doesn't actually give me any improvement over like b it actually improves over the baseline but it 's not like it doesn't meet something like fifty percent i 've been playing with the v     that 's the improvement is somewhere around thirty percent over the baseline . no , just one stage wiener filter which is a standard wiener filter .  just plug in the wiener filtering . in the s in our system , where i di i di no . it actually improves over the baseline of not having a wiener filter in the whole system . like i have an lda f lda plus on line normalization , and then i plug in the wiener filter in that , it improves over not having the wiener filter . it improves but it doesn't take it like be beyond like thirty percent over the baseline .  no , it 's like , these are not no , it 's the old vad . my baseline was , nine this is like w the baseline is ninety five point six eight , and eighty nine , and what was that ?    errors , right , i don't have . it 's all accuracies . the t there are two baselines .  the baseline one baseline is mfcc baseline that when i said thirty percent improvement it 's like mfcc baseline . it 's the it 's just the mel frequency and that 's it . don't have that number here .  i have it here . it 's the vad plus the baseline actually . i 'm talking about the mfcc plus i do a frame dropping on it . that 's like the word error rate is like four point three . like ten point seven . it 's a medium misma  there 's a ma matched , medium mismatched , and a high matched . don't have the like the  and forty . forty percent is the high mismatch . and that becomes like four point three  it 's like ten point one . still the same . and the high mismatch is like eighteen point five . five . the one is this one is just the baseline plus the , wiener filter plugged into it .     with the on line normalization , the performance was , ten it 's like four point three .  that 's the ba the ten point , four and twenty point one . that was with on line normalization and lda . the h matched has like literally not changed by adding on line or lda on it . but the even the medium mismatch is the same . and the high mismatch was improved by twenty percent absolute . it 's the it 's italian . i 'm talking about italian ,   you have it ?    this is the single stage wiener filter , with the noise estimation was based on first ten frames . actually i started with using the vad to estimate the noise and then i found that it works it doesn't work for finnish and spanish because the vad endpoints are not good to estimate the noise because it cuts into the speech sometimes , end up overestimating the noise and getting a worse result . it works only for italian by u for using a vad to estimate noise . it works for italian because the vad was trained on italian .  this was , and this was giving  this was like not improving a lot on this baseline of not having the wiener filter on it . and ,  i ran this with one more stage of wiener filtering on it but the second time , what i did was i estimated the new wiener filter based on the cleaned up speech , and did , smoothing in the frequency to reduce the variance i have i 've observed there are lot of bumps in the frequency when i do this wiener filtering which is more like a musical noise and by adding another stage of wiener filtering , the results on the speechdat car was like ,  i still don't have the word error rate . i 'm about it . but the overall improvement was like fifty six point four six . this was again using ten frames of noise estimate and two stage of wiener filtering . and the rest is like the lda plu and the on line normalization all remaining the same .  this was compared to , fifty seven is what you got by using the french telecom system , right ? y i no , this is over the whole speechdat car .  point  the new wiener filtering schema is like some fifty six point four six which is like one percent still less than what you got using the french telecom system . it 's very similar . it 's different in a sense like i 'm actually cleaning up the cleaned up spectrum which they 're not doing . they 're d what they 're doing is , they have two stage stages of estimating the wiener filter , but the final filter , what they do is they take it to their time domain by doing an inverse fourier transform . ","'ve been working on that wiener filtering . found that , s single like , do a s normal wiener filtering , like the standard method of wiener filtering . and that doesn't actually give me any improvement over like b it actually improves over the baseline but it 's not like it doesn't meet something like fifty percent that 's the improvement is somewhere around thirty percent over the baseline . no , just one stage wiener filter which is a standard wiener filter . i ran this with one more stage of wiener filtering on it but the second time , what i did was i estimated the new wiener filter based on the cleaned up speech , and did , smoothing in the frequency to reduce the variance and by adding another stage of wiener filtering , the results on the speechdat car was like , but the overall improvement was like fifty six point four six . ","Group members reported their progress in the areas of spectral subtraction, Wiener filtering and noise estimation. "
Bro023.B,"and they filter the original signal using that fil filter , which is like final filter is acting on the input noisy speech rather than on the cleaned up . this is more like i 'm doing wiener filter twice , but the only thing is that the second time i 'm actually smoothing the filter and then cleaning up the cleaned up spectrum first level . and that 's what the difference is . and actually i tried it on s the original clean the original spectrum where the second time i estimate the filter but actually clean up the noisy speech rather the c s first output of the first stage and that doesn't seems to be a giving , that much improvement . i didn't run it for the whole case . and and what i t what i tried was , by using the same thing but we actually found that the vad is very crucial . just by changing the vad itself gives you the a lot of improvement by instead of using the current vad , if you just take up the vad output from the channel zero , when instead of using channel zero and channel one , because that was the p that was the reason why i was not getting a lot of improvement for estimating the noise . just used the channel zero vad to estimate the noise that it gives me some reliable mar markers for this noise estimation .  it 's like  the close talking without because the channel zero and channel one are like the same speech , but only w the same endpoints . but the only thing is that the speech is very noisy for channel one , you can actually use the output of the channel zero for channel one for the vad . that 's like a cheating method . that 's which is the channel zero . but actually their alignment actually is not seems to be improving in like on all cases .  which is it gives like negative in like some italian and ti digits , right ?  by using the endpointed speech , actually it 's worse than the baseline in some instances , which could be due to the word pattern . our neural net     the wiener filter , it 's like it 's like you try to minimize the basic principle of wiener filter is like you try to minimize the , d difference between the noisy signal and the clean signal if you have two channels . like let 's say you have a clean t signal and you have an additional channel where what is the noisy signal . and then you try to minimize the error between these two . that 's the basic principle . and you get you can do that if you have only a c noisy signal , at a level which you , you w try to estimate the noise from the w assuming that the first few frames are noise or if you have a w voice activity detector , you estimate the noise spectrum . and then you  in after the speech starts .  but that 's not the case in , many of our cases but it works reasonably and then you what you do is you , fff . again , write down some of these eq   and then you do this this is the transfer function of the wiener filter , sf "" is a clean speech spectrum , power spectrum and "" n "" is the noisy power spectrum . and this is the transfer function . and ,  and then you multiply your noisy power spectrum with this . you get an estimate of the clean power spectrum .  but that you have to estimate the sf from the noisy spectrum , what you have . you estimate the nf from the initial noise portions and then you subtract that from the current noisy spectrum to get an estimate of the sf . sometimes that becomes zero because you do you don't have a true estimate of the noise . the f filter will have like sometimes zeros in it because some frequency values will be zeroed out because of that . and that creates a lot of discontinuities across the spectrum because @ @ the filter .   that 's what that was just the first stage of wiener filtering that i tried . it  not seen . they are very s similar techniques . it 's like i haven't seen anybody using s wiener filter with spectral subtraction .  the reason was we had this choice of using spectral subtraction , wiener filtering , and there was one more thing which i 'm trying , is this sub space approach .  stephane is working on spectral subtraction . picked up y we just wanted to have a few noise production compensation techniques and then pick some from that pick one . va vad . w   one of the things that i tried , like i said , was to remove those zeros in the fri filter by doing some smoothing of the filter . like , you estimate the edge of square and then you do a f smoothing across the frequency that those zeros get flattened out . and that doesn't seems to be improving by trying it on the first time . what i did was like i p did this and then you i plugged in the one more the same thing but with the smoothed filter the second time . and that seems to be working . that 's where i got like fifty six point five percent improvement on speechdat car with that . and the other thing what i tried was i used still the ten frames of noise estimate but i used this channel zero vad to drop the frames . 'm not still not estimating . and that has taken the performance to like sixty seven percent in speechdat car , ","the basic principle of wiener filter is like you try to minimize the , d difference between the noisy signal and the clean signal ",A number of the group also took time to explain the basics of their approaches to the group. 
Bro023.B,"which is which like shows that by using a proper vad you can just take it to further , better levels . and   far i 've seen sixty seven no , i haven't seen s like sixty seven percent . and , using the channel zero vad to estimate the noise also seems to be improving but i don't have the results for all the cases with that . used channel zero vad to estimate noise as a lesser 2 x frame , which is like , everywhere i use the channel zero vad . and that seems to be the best combination , rather than using a few frames to estimate and then drop a channel . nnn , no . this is just to test whether we can really improve by using a better vad .  this is like the noise compensation f is fixed but you make a better decision on the endpoints . that 's , like seems to be we c mean , which means by using this technique what we improve just the vad we can just take the performance by another ten percent or better . that was just the , reason for doing that experiment . and , w but this all these things , i have to still try it on the ti digits , which is like i 'm just running . and there seems to be not improving a lot on the ti digits , 'm like investigating that , why it 's not . and ,   after that .   the other thing is like i 've been i 'm doing all this on the power spectrum .  tried this on the mel as mel and the magnitude , and mel magnitude , and all those things . but it seems to be the power spectrum seems to be getting the best result . one of reasons like doing the averaging , after the filtering using the mel filter bank , that seems to be helping rather than trying it on the mel filter ba filtered outputs . just th  th that 's the only thing that i could think of why it 's giving improvement on the mel . and , that 's it . subspace , i 'm like that 's still in a little bit in the back burner because i 've been p putting a lot effort on this to make it work , on tuning things and other  i was like going parallely but not much of improvement . i 'm just have some skeletons ready , need some more time for it .    is that the log ? after that . no , after . but you will but you end up reducing some neighboring frequency bins @ @ in the average , right ? when you add the negative to the positive value which is the true estimate .      that is true . we just  for frames , frequency bins .  the one you showed yesterday . right ? fff . no , i don't have , for each , have the final number here .  no , i actually didn't give you the number which is the final one , which is , after two stages of wiener filtering . that was like the overall improvement is like fifty six point five .  his number is still better than what i got in the two stages of wiener filtering .   right ,  they use spectral subtraction , right . french telecom . it 's wiener filtering .  filtering . it 's not exactly wiener filtering but some variant of wiener filtering .  s they have like  th the just noise compensation technique is a variant of wiener filtering , plus they do some smoothing techniques on the final filter . the th they actually do the filtering in the time domain . they would take this hf squared back , taking inverse fourier transform . and they convolve the time domain signal with that . and they do some smoothing on that final filter , impulse response . i 'm i 'm @ @ . but . it 's similar in the smoothing and   the frequency domain . no , you get it with wiener filtering also . no , you still end up with zeros in the s spectrum . sometimes .  i know .    the   the m the mean is computed o based on some frames in the future also ? or no ?  i 'm why is that delay coming ? like , you estimate the mean ?  it isn't  it 's like it looks into the future also .  we can  we can do something in parallel also , in some like some cases like , if you wanted to do voice activity detection . and we can do that in parallel with some other filtering you can do . you can make a decision on that voice activity detection and then you decide whether you want to filter or not . but by then you already have the sufficient samples to do the filtering .  sometimes you can do it anyway .  the data , the super frame but that has a variable latency because the last frame doesn't have any latency and first frame has a twenty framed latency . you can't r rely on that latency all the time . because the transmission over the air interface is like a buffer . twenty frame twenty four frames .  but the only thing is that the first frame in that twenty four frame buffer has a twenty four frame latency . and the last frame doesn't have any latency . because it just goes as  i used ten just ten frames . because the reason was like in ti digits i don't have a lot . i had twenty frames most of the time . that 's using the channel zero . if i use a channel zero vad to estimate the noise . which channel zero dropping .  t this f     ",,
Bro023.B,"'m also using that n new noise estimate technique on this wiener filtering what i 'm trying . have some experiments running , i don't have the results .  i don't estimate the f noise on the ten frames but use his estimate . there 's no . it doesn't seems to help by their use of channel zero or channel one . their d the frame dropping , right ? it doesn't italian . ti digits .    the energy also .  ",,
Bro023.C,"and hans hans guenter will be here , by next tuesday or he 's going to be here for about three weeks , and ,  we 'll see . we might end up with some longer collaboration he 's gonna look in on everything we 're doing and give us his thoughts . and it 'll be another good person looking at things .      no , he 'll be around for three weeks . he 's , very , easygoing , easy to talk to , and , very interested in everything .    he 's been here before . he 's he 's he 's n nine months . something like that .   he 's done a couple stays here .    it was pretty tiny .  but it but looking at it the other way , isn't it what you 're saying that it didn't help you to have the longer time for training , if you were going to have a short time for why would you do it , if you knew that you were going to have short windows in testing .  no , total . the other thing , which relates a little bit to something else we 've talked about in terms of windowing and on is , that , i wonder if you trained with twelve seconds , and then when you were two seconds in you used two seconds , and when you were four seconds in , you used four seconds , and when you were six and you build up to the twelve seconds . that if you have very long utterances you have the best , but if you have shorter utterances you use what you can .   right . but the other thing is that 's the other way of looking at this , going back to , mean cepstral subtraction versus rasta things , is that you could look at mean cepstral subtraction , especially the way you 're doing it , as being a filter . and the other thing is just to design a filter . you 're you 're doing a high pass filter or a band pass filter of some sort and just design a filter . and then , a filter will have a certain behavior and you loo can look at the start up behavior when you start up with nothing . and , it will , if you have an iir filter it will , not behave in the steady state way that you would like it to behave until you get a long enough period , but ,  by just constraining yourself to have your filter be only a subtraction of the mean , you 're tying your hands behind your back because there 's filters have all sorts of be temporal and spectral behaviors . and the only thing , consistent that we know about is that you want to get rid of the very low frequency component .   and , if you take this filtering perspective and if you essentially have it build up over time . if you computed means over two and then over four , and over six , essentially what you 're getting at is a ramp up of a filter anyway . and you may just want to think of it as a filter . but , if you do that , then , in practice somebody using the smartkom system , one would think if they 're using it for a while , it means that their first utterance , instead of , getting , a forty percent error rate reduction , they 'll get a over what , you 'd get without this , policy , you get thirty percent . and then the second utterance that you give , they get the full full benefit of it if it 's this ongoing thing . i 'm saying in practice , that 's if somebody 's using a system to ask for directions they 'll say something first . and to begin with if it doesn't get them quite right , ma m they 'll come back and say , "" excuse me ? ""  or some it should have some policy like that anyway . and , in any event they might ask a second question . and it 's not like what he 's doing doesn't , improve things . it does improve things , just not as much as he would like . and there 's a higher probability of it making an error , in the first utterance .   right . the other thing which ,  i don't know much about as much as i should about the rest of the system but , couldn't you , if you did a first pass i don't capability we have at the moment for doing second passes on , some little small lattice , or a graph , or confusion network , but if you did first pass with , the with either without the mean sub subtraction or with a very short time one , and then , once you , actually had the whole utterance in , if you did , the , longer time version then , based on everything that you had , and then at that point only used it to distinguish between , top n , possible utterances you might it might not take very much time . i know in the large vocabulary stu systems , people were evaluating on in the past , some people really pushed everything in to make it in one pass but other people didn't and had multiple passes . and , the argument , against multiple passes was u has often been "" but we want to this to be r have a interactive response "" . and the counterargument to that which , say , bbn had , was "" but our second responses are second , passes and third passes are really , really fast "" . if your second pass takes a millisecond who cares ?   ","and hans hans guenter will be here , by next tuesday or he 's going to be here for about three weeks , we 'll see . we might end up with some longer collaboration he 's gonna look in on everything we 're doing and give us his thoughts .   why would you do it , if you knew that you were going to have short windows in testing . the other thing , which relates a little bit to something else we 've talked about in terms of windowing and on is , that , i wonder if you trained with twelve seconds , and then when you were two seconds in you used two seconds , and when you were four seconds in , you used four seconds , and when you were six and you build up to the twelve seconds . that if you have very long utterances you have the best , but if you have shorter utterances you use what you can . i don't know much about as much as i should about the rest of the system but if you did first pass with , the with either without the mean sub subtraction or with a very short time one , and then , once you , actually had the whole utterance in , if you did , the , longer time version then , based on everything that you had , and then at that point only used it to distinguish between , top n , possible utterances you might it might not take very much time . i know in the large vocabulary stu systems , people were evaluating on in the past , some people really pushed everything in to make it in one pass but other people didn't and had multiple passes . the argument , against multiple passes was u has often been "" but we want to this to be r have a interactive response "" . and the counterargument to that which , say , bbn had , was "" but our second responses are second , passes and third passes are really , really fast "" . ","There are hopes that a visitor coming for three weeks, may lead to a longer term collaboration. They also discusses topics relating to the rules and preferences of the project they are working on, including single vs multiple passes. "
Bro023.C,"if it turned out to be a problem , that you didn't have enough speech because you need a longer window to do this processing , then , one tactic is looking at the larger system and not just at the front end is to take in , the speech with some simpler mechanism or shorter time mechanism , do the best you can , and come up with some al possible alternates of what might have been said . and , either in the form of an n best list or in the form of a lattice , or confusion network , or whatever . and then the decoding of that is much , much faster or can be much , much faster if it isn't a big bushy network . and you can decode that now with speech that you 've actually processed using this longer time , subtraction . mean , it 's common that people do this thing where they do more things that are more complex or require looking over more time , whatever , in some second pass . if the second pass is really , really fast another one i 've heard of is in connected digit going back and l and through backtrace and finding regions that are considered to be a d a digit , but , which have very low energy . mean , there 's lots of things you can do in second passes , sorts of levels . anyway , i 'm throwing too many things out . but . is that using in combination with something else ? with a no , no , but in combination with our on line normalization or with the lda ?  does it g does that mean it gets worse ? or ?  but that 's what i 'm confused about , cuz thought that our system was more like forty percent without the wiener filtering . mean , if you can do all these in word errors it 's a lot easier actually . if you do all these in word error rates it 's a lot easier , right ?  cuz then you can figure out the percentages .   what 's it start on ? the mfcc baseline is what ? is at what level ? no , what 's the number ? four point three . what 's ten point seven ?    four point three , ten point seven , and  not changed . eighteen point five . and what were you just describing ? but where 's the , on line normalization and on ?  and what number an and what are we talking about here ? is this ti digits or italian ? and what did what was the , corresponding number , say , for , the alcatel system do        but it 's a pretty similar number in any event .  but again , you 're more or less doing what they were doing , right ?     what 's a channel zero vad ? i 'm confused about that .  right .  are they going to pro what are they doing to do , do we know yet ? about as far as what they 're what the rules are going to be and what we can use ? it 's not like that 's being done in one place or one time . that 's just a rule and we 'd you were permitted to do that . is that it ? they will send files everybody will have the same boundaries to work with ?       c right actually ,  it 's all pretty related ,  it 's there 's a di there 's a whole class of techniques where you try in some sense to minimize the noise . and it 's typically a mean square sense , i in some way . and , spectral subtraction is , one approach to it . in the long run you 're doing the same thing but y but there you make different approximations , and in spectral subtraction , there 's a an estimation factor . you sometimes will figure out what the noise is and you 'll multiply that noise spectrum times some constant and subtract that rather than and sometimes people even though this really should be in the power domain , sometimes people s work in the magnitude domain because it works better . and , i m there 's car carmen 's working on another , on the vector taylor series . they were just trying to cover a bunch of different things with this task and see , what are the issues for each of them .   'm still a little confused . is that channel zero information going to be accessible during this test .    yes .    ma makes sense . how about the subspace    what are you doing with negative , powers ? right . there 's all sorts of , deviations from the ideal here . you 're talking about the signal and noise , at a particular point . and even if something is stationary in ster terms of statistics , there 's no guarantee that any particular instantiation or piece of it is exactly a particular number or bounded by a particular range . you 're figuring out from some chunk of the signal what you think the noise is . then you 're subtracting that from another chunk , and there 's no reason to think that you 'd know that it wouldn't , be negative in some places . on the other hand that just means that in some sense you 've made a mistake because you certainly have stra subtracted a bigger number than is due to the noise . also , we speak the whole where all this comes from is from an assumption that signal and noise are uncorrelated . and that certainly makes sense in s in a statistical interpretation , that , over , all possible realizations that they 're uncorrelated ",is that using in combination with something else ? do we know yet ? about as far as what they 're what the rules are going to be and what we can use ? they will send files everybody will have the same boundaries to work with ? ,"They also discusses topics relating to the rules and preferences of the project they are working on, including single vs multiple passes. "
Bro023.C,"or assuming , ergodicity that i across time , it 's uncorrelated . but if you just look at a quarter second , and you cross multiply the two things , you could very end up with something that sums to something that 's not zero . the two signals could have some relation to one another . and there 's all sorts of deviations from ideal in this . and given all that , you could definitely end up with something that 's negative . but if down the road you 're making use of something as if it is a power spectrum , then it can be bad to have something negative . now , the other thing i wonder about actually is , what if you left it negative ? what happens ? because are you taking the log before you add them up to the mel ? right . i wonder how if you put your thresholds after that , i wonder how often you would end up with , with negative values .  but nonetheless , these are it 's another f smoothing , right ? that you 're doing . right . you 've done your best shot at figuring out what the noise should be , and now i then you 've subtracted it off . and then after that , instead of instead of , leaving it as is and adding things adding up some neighbors , you artificially push it up . which is , it 's there 's no particular reason that 's the right thing to do either , right ?   i what you 'd be doing is saying , "" we 're d we 're going to definitely diminish the effect of this frequency in this little frequency bin in the overall mel summation "" . it 's just a thought . i d i don't know if it would be nnn , although  but that means that in a situation where you thought that the bin was almost entirely noise , you left it .   that 's the opposite ,   people can also , reflect it back up and essentially do a full wave rectification instead of a instead of half wave . but it was just a thought that it might be something to try .    these numbers he was giving before with the four point three , and the ten point one , and forth , those were italian , right ?  right . right . but do you have numbers in terms of word error rates on italian ? just you have some sense of reference ?   and this is , spectral subtraction plus what ? on line normalization and lda ?   right .  plus , they have some cepstral normalization , as it 's not clear that these musical noises hurt us in recognition . we don't know if they do . they sound bad . but we 're not listening to it , usually . none of these systems , have y you both are working with , our system that does not have the neural net , right ?  one would hope , presumably , that the neural net part of it would improve things further as they did before .      it could do a nonlinear spectral subtraction but i don't know if it you have to figure out what your targets are . right . that 's not much spectral subtraction then , but it 's but at any rate , people ,  y we had visitors here who did that when you were here ba way back when .  people d done lots of experimentation over the years with training neural nets . and it 's not a bad thing to do . it 's another approach . m it 's it , the objection everyone always raises , which has some truth to it is that , it 's good for mapping from a particular noise to clean but then you get a different noise . and the experiments we saw that visitors did here showed that it there was at least some , gentleness to the degradation when you switched to different noises . it did seem to help . that you 're right , that 's another way to go .  it did very   but to some extent that 's what we 're doing . we 're not doing exactly that , we 're not trying to generate good examples but by trying to do the best classifier you possibly can , for these little phonetic categories , it 's  it 's built into that . and that 's why we have found that it does help .    we 'll just have to try it . but i would i would imagine that it will help some . it we 'll just have to see whether it helps more or less the same , but i would imagine it would help some . in any event , all of this i was just confirming that all of this was with a simpler system .    it 's amazing how often that happens .  one five ? one five ? five zero ? five zero .  what if you just look into the past ? how m by how much ? by how much ? worse .  it 's depending on how all this comes out we may or may not be able to add any latency .  s the only thing is that i would worry about it a little . because if we completely ignore latency , and then we discover that we really have to do something about it , we 're going to be find ourselves in a bind .  you could make it twenty five . what just , just be a little conservative because we may end up with this crunch where all of a sudden we have to cut the latency in half  everything is sent over in buffers cuz of isn't it the tcp buffer some ?      and that 's one of the ","none of these systems , have y you both are working with , our system that does not have the neural net , one would hope , presumably , that the neural net part of it would improve things further as they did before . it 's depending on how all this comes out we may or may not be able to add any latency . i would worry about it a little . because if we completely ignore latency , and then we discover that we really have to do something about it , we 're going to be find ourselves in a bind . and that 's one of the ","They also discusses topics relating to the rules and preferences of the project they are working on, including single vs multiple passes. "
Bro023.C,"all of that is things that they 're debating in their standards committee . that 'd be more like the jrasta thing in a sense .  i 'm confused . you said five hundred milliseconds but you said sixty four milliseconds . which is which ? what ?    you take sixty four millisecond f ts and then you average them over five hundred ? or ? what do you do over five hundred ?   i see . i see .   but are you comparing with something e i 'm p s a little confused again , i it when you compare it with the v a d based , vad is this the ? you 're not doing this with our system ?  right . but  but the spectral subtraction scheme that you reported on also re requires a noise estimate . couldn't you try this for that ? do you think it might help ? i see , i see .       it 's interesting . in jrasta we were essentially adding in , white noise dependent on our estimate of the noise . on the overall estimate of the noise . it never occurred to us to use a probability in there . you could imagine one that made use of where the amount that you added in was , a function of the probability of it being s speech or noise .  cuz that brings in powers of classifiers that we don't really have in , this other estimate . it could be interesting . what point does the , system stop recording ? how much it went a little long ? disk     right .  hans guenter will be here next week think he 'll be interested in all of these things . and ,    ",all of that is things that they 're debating in their standards committee . but the spectral subtraction scheme that you reported on also re requires a noise estimate . couldn't you try this for that ? do you think it might help ? ,"They also discusses topics relating to the rules and preferences of the project they are working on, including single vs multiple passes. "
Bro023.D,"damn .    the baseline is something similar to a w the t the baseline that you are talking about is the mfcc baseline , right ? or ?   it looks to be ,  it 's three point four , eight point , seven , and , thirteen point seven .  no , i don't think is it on italian ? fifty seven right .   it 's the close talking microphone .  actually i received a new document , describing this . and what they did finally is to , not to align the utterances but to perform recognition , only on the close talking microphone , and to take the result of the recognition to get the boundaries of speech . and they will send , files but we don't   i  what happened here is that , the overall improvement that they have with this method to be more precise , what they have is , they have these alignments and then they drop the beginning silence and the end silence but they keep , two hundred milliseconds before speech and two hundred after speech . and they keep the speech pauses also .  and the overall improvement over the mfcc baseline when they just , add this frame dropping in addition it 's r forty percent , right ? fourteen percent ,  which is ,  t which is the overall improvement . but in some cases it doesn't improve like , y do you remember which case ?  some @ @ . right .   and the other thing also is that fourteen percent is less than what you obtain using a real vad . with without cheating like this .   think this shows that there is still work working on the vad is still important     i 've been , working still on the spectral subtraction .  to r to remind you a little bit of what i did before , is just to apply some spectral subtraction with an overestimation factor also to get , an estimate of the noise , spectrum , and subtract this estimation of the noise spectrum from the , signal spectrum , but subtracting more when the snr is , low , which is a technique that it 's often used . you overestimate the noise spectrum . you multiply the noise spectrum by a factor , which depends on the snr . above twenty db , it 's one , you just subtract the noise . and then it 's b generally i use , actually , a linear , function of the snr , which is bounded to two or three , when the snr is below zero db . doing just this , either on the fft bins or on the mel bands , t doesn't yield any improvement o  there is also a threshold , because after subtraction you can have negative energies , and what do is to put , to add to put the threshold first and then to add a small amount of noise , which right now is speech shaped .   it 's a it has the overall energy ,  pow it has the overall power spectrum of speech . with a bump around one kilohertz . i   there can be frequency bins with negative values . for each frequencies i a i 'm adding some , noise , but the a the amount of noise i add is not the same for all the frequency bins . right now i don't think if it makes sense to add something that 's speech shaped , because then you have silence portion that have some spectra similar to the sp the overall speech spectra . but  this is something still work on , but  that means that   you have an estimation of the noise spectrum , but sometimes , it 's as the noise is not perfectly stationary , sometimes this estimation can be , too small , you don't subtract enough . but sometimes it can be too large also . if the noise , energy in this particular frequency band drops for some reason .         and , some people also if it 's a negative value they , re compute it using inter interpolation from the edges and bins . there are different things that you can do .    actually i tried , something else based on this , is to put some smoothing , because it seems to help or it seems to help the wiener filtering and ,  what i did is , some nonlinear smoothing . actually i have a recursion that computes let me go back a little bit . actually , when you do spectral subtraction you can , find this equivalent in the s in the spectral domain . you can compute , y you can say that d your spectral subtraction is a filter , and the gain of this filter is the , signal energy minus what you subtract , divided by the signal energy . and this is a gain that varies over time , and , depending on the s on the noise spectrum and on the speech spectrum . and what happen actually is that during low snr values , the gain is close to zero but it varies a lot .  and this is the of musical noise and all these the fact you we go below zero one frame and then you can have an energy that 's above zero . and  the smoothing is i did a smoothing actually on this gain , trajectory . but it 's the smoothing is nonlinear in the sense that i tried to not smooth if the gain is high , because in this case we know that , the estimate of the gain is correct because we are not close to zero , and to do more smoothing if the gain is low .      that 's this idea , and it seems to give pretty good results , although i 've just tested on italian and finnish . ","actually i received a new document , describing this . and what they did finally is to , not to align the utterances but to perform recognition , only on the close talking microphone , and to take the result of the recognition to get the boundaries of speech .  i 've been , working still on the spectral subtraction . to r to remind you a little bit of what i did before , is just to apply some spectral subtraction with an overestimation factor doing just this , either on the fft bins or on the mel bands , t doesn't yield any improvement actually i tried , something else based on this , is to put some smoothing , because it seems to help or it seems to help the wiener filtering what i did is , some nonlinear smoothing . although i 've just tested on italian and finnish . ","They also discusses topics relating to the rules and preferences of the project they are working on, including single vs multiple passes. Group members reported their progress in the areas of spectral subtraction, Wiener filtering and noise estimation. "
Bro023.D,"and on italian it seems my result seems to be a little bit better than the wiener filtering , right ? i don't know if you have these improvement the detailed improvements for italian , finnish , and spanish there or you have just have your own .   no , we 've   on italian . but on finnish it 's a little bit worse ,   it 's , three point , eight . am i right ? and then , d nine point , one . and finally , sixteen point five . plus nonlinear smoothing . it 's the system it 's exactly the sys the same system as sunil tried , but  but instead of double stage wiener filtering , it 's this smoothed spectral subtraction .  for what ? it 's wiener filtering , am i right ? it 's some wiener filtering    but they also have two different smoothing @ @ . one in the time domain and one in the frequency domain by just taking the first , coefficients of the impulse response . it 's similar . what you did , it 's similar because you have also two smoothing . one in the time domain , and one in the frequency domain ,      actually the smoothing that i did do here reduced the musical noise . it  i cannot you cannot hear beca actually what i d did not say is that this is not in the fft bins . this is in the mel frequency bands .   it could be seen as a f a smoothing in the frequency domain because i used , in ad mel bands in addition and then the other phase of smoothing in the time domain .  but , when you look at the spectrogram , if you don't have an any smoothing , you clearly see , like in silence portions , and at the beginning and end of speech , you see spots of high energy randomly distributed over the spectrogram .  which is musical noise ,  if it if you listen to it if you do this in the fft bins , then you have spots of energy randomly distributing . and if you f if you re synthesize these spot sounds as sounds ,  and      although if we , look at the result from the proposals , one of the reason , the n system with the neural net was , more than around five percent better , is that it was much better on highly mismatched condition . i 'm thinking , on the ti digits trained on clean speech and tested on noisy speech . for this case , the system with the neural net was much better . but not much on the in the other cases . and if we have no , spectral subtraction or wiener filtering , i the system is we thought the neural network is much better than before , even in these cases of high mismatch . the neural net will help less but ,            this is th the , actually , this was the first try with this spectral subtraction plus smoothing , and i was excited by the result . then i started to optimize the different parameters . and , the first thing i tried to optimize is the , time constant of the smoothing . and it seems that the one that i chose for the first experiment was the optimal one ,   this is the first thing .  another thing that i it 's important to mention is , that this has a this has some additional latency .  because when i do the smoothing , it 's a recursion that estimated the means , of the g of the gain curve . and this is a filter that has some latency . and i noticed that it 's better if we take into account this latency . instead o of using the current estimated mean to , subtract the current frame , it 's better to use an estimate that 's some somewhere in the future .   it 's the recursion , it 's the center recursion , right ?  and the latency of this recursion is around fifty milliseconds . five zero ,     the mean estimation has some delay , right ? the filter that estimates the mean has a time constant .  it 's , not as good . it 's not bad . it helps a lot over the ba the baseline but , it it 's around three percent , relative .      but  it depends . y actually , it 's l it 's three percent . right .   b but i don't think we have to worry too much on that right now while you kno .      yes . s     there are other things in the , algorithm that i didn't , @ @ a lot yet , which  no , it 's added .            there is these parameters that i still have to look at . like , i played a little bit with this overestimation factor ,  but i still have to look more at this ,  at the level of noise i add after . i know that adding noise helped , the system just using spectral subtraction without smoothing , but i don't know right now if it 's still important or not , and if the level i choose before is still the right one . same thing for the shape of the noise . it would be better to add just white noise instead of speech shaped noise .   and another thing is to  for this use as noise estimate the mean , spectrum of the first twenty frames of each utterance . i don't remember for this experiment what did you use for these two stage the ten frames ?   but , what 's this result you told me about , the fact that if you use more than ten frames you can improve by t  but this is ten frames plus channel no , ","and on italian it seems my result seems to be a little bit better than the wiener filtering ,  another thing that i it 's important to mention is , that this has a this has some additional latency . and i noticed that it 's better if we take into account this latency . b but i don't think we have to worry too much on that right now while you kno . ",
Bro023.D,"these results with two stage wiener filtering is ten frames but possibly more . if channel one vad gives you    but in this experiment i did i didn't use any vad . used the twenty first frame to estimate the noise . and expected it to be a little bit better , if , i use more frames .  that 's it for spectral subtraction . the second thing i was working on is to , try to look at noise estimation , and using some technique that doesn't need voice activity detection .  and for this i u simply used some code that , i had from belgium , which is technique that , takes a bunch of frame ,  and for each frequency bands of this frame , takes a look at the minima of the energy . and then average these minima and take this as an energy estimate of the noise for this particular frequency band . and there is something more to this actually . what is done is that , these minima are computed , based on , high resolution spectra . i compute an fft based on the long , signal frame which is sixty four millisecond what i d i do actually , is to take a bunch of to take a tile on the spectrogram and this tile is five hundred milliseconds long and two hundred hertz wide . and this tile in this tile appears the harmonics if you have a voiced sound , because it 's the ftt bins . and when you take the m the minima of these this tile , when you don't have speech , these minima will give you some noise level estimate , if you have voiced speech , these minima will still give you some noise estimate because the minima are between the harmonics . and if you have other speech sounds then it 's not the case , but if the time frame is long enough , like s five hundred milliseconds seems to be long enough , you still have portions which , are very close whi which minima are very close to the noise energy .  sixty four milliseconds is to compute the fft , bins . the fft .  actually it 's better to use sixty four milliseconds because , if you use thirty milliseconds , then , because of the this short windowing and at low pitch , sounds , the harmonics are not , wha correctly separated . if you take these minima , it b they will overestimate the noise a lot . take to i take a bunch of these sixty four millisecond frame to cover five hundred milliseconds , and then i look for the minima , on the bunch of fifty frames , right ?  the interest of this is that , as y with this technique you can estimate u some reasonable noise spectra with only five hundred milliseconds of signal , if the n the noise varies a lot , you can track better track the noise , which is not the case if you rely on the voice activity detector . even if there are no speech pauses , you can track the noise level . the only requirement is that you must have , in these five hundred milliseconds segment , you must have voiced sound at least . cuz this these will help you to track the noise level .  what i did is just to simply replace the vad based , noise estimate by this estimate , first on speechdat car only on speechdat car actually . and it 's , slightly worse , like one percent relative compared to the vad based estimates .  the reason why it 's not better , is that the speechdat car noises are all stationary .  u y there really is no need to have something that 's adaptive and they are mainly stationary .  but , i expect s some improvement on ti digits because , nnn , in this case the noises are all sometimes very variable . have to test it .   it 's it 's the france telecom based spectra , s wiener filtering and vad . it 's their system but just i replace their noise estimate by this one . in i 'm not no , no .  it 's our system but with just the wiener filtering from their system . right ?   actually , th the best system that we still have is , our system but with their noise compensation scheme , right ? 'm trying to improve on this , and by replacing their noise estimate by , something that might be better .   but i di not yet , because i did this in parallel , and i was working on one and the other .  for will . try also , the spectral subtraction .     i , also implemented a sp spectral whitening idea which is in the , ericsson proposal . the idea is just to flatten the log , spectrum , and to flatten it more if the probability of silence is higher . in this way , you can also reduce somewhat reduce the musical noise and you reduce the variability if you have different noise shapes , because the spectrum becomes more flat in the silence portions .   with this , no improvement , but there are a lot of parameters that we can play with and ,  actually , this could be seen as a soft version of the frame dropping because , you could just put the threshold and say that "" below the threshold , i will flatten comp completely flatten the spectrum "" . and above this threshold , keep the same spectrum . it would be like frame dropping , because during the silence portions which are below the threshold of voice activity probability , w you would have some dummy frame which is a perfectly flat spectrum . ","the second thing i was working on is to , try to look at noise estimation , and using some technique that doesn't need voice activity detection . and for this i u simply used some code that , i had from belgium , which is technique that , takes a bunch of frame , and for each frequency bands of this frame , takes a look at the minima of the energy . and then average these minima and take this as an energy estimate of the noise for this particular frequency band .  for will . try also , the spectral subtraction . ",A number of the group also took time to explain the basics of their approaches to the group. 
Bro023.D,"and this , whitening is something that 's more soft because , you whiten you just , have a function the whitening is a function of the speech probability , it 's not a hard decision .  think it can be used together with frame dropping and when we are not about if it 's speech or silence , it has something do with this .     w right now it 's a constant that just depending on the noise spectrum .        there are with this technique there are some did something exactly the same as the ericsson proposal but , the probability of speech is not computed the same way . and i for for a lot of things , actually a g a good speech probability is important . like for frame dropping you improve , like you can improve from ten percent as sunil showed , if you use the channel zero speech probabilities . for this it might help ,  s   the next thing i started to do is to , try to develop a better voice activity detector . and ,  i d  for this we can try to train the neural network for voice activity detection on all the data that we have , including all the speechdat car data .  and 'm starting to obtain alignments on these databases . and the way i mi i do that is that use the htk system but i train it only on the close talking microphone . and then i aligned i obtained the viterbi alignment of the training utterances .  it seems to be ,  actually what i observed is that for italian it doesn't seem th there seems to be a problem .  because what ?   u but actually the vad was trained on italian also ,  the c the current vad that we have was trained on , t spine , right ? italian , and ti digits with noise and  and it seems to work on italian but not on the finnish and spanish data . one reason is that s finnish and spanish noise are different . and actually we observed we listened to some of the utterances and sometimes for finnish there is music in the recordings and strange things , right ?  the idea was to train all the databases and obtain an alignment to train on these databases , and , also to , try different features , as input to the vad network . and we came up with a bunch of features that we want to try like , the spectral slope , the , the degree o degree of voicing with the features that , we started to develop with carmen , e with , the correlation between bands and different features , and the energy .    ",,
Bro023.E,"th that 's his spectral subtraction group ? is that right ?  guess i should probably talk to him a bit too ?  since we 're looking at putting this , mean log m magnitude spectral subtraction , into the smartkom system , i did a test seeing if , it would work using past only and plus the present to calculate the mean . i did a test , where i used twelve seconds from the past and the present frame to , calculate the mean . and  twelve seconds , counting back from the end of the current frame ,  it was , twen it was twenty one frames and that worked out to about twelve seconds . and compared to , do using a twelve second centered window , there was a drop in performance but it was just a slight drop . is that right ?  that was encouraging . and , that that 's encouraging for the idea of using it in an interactive system like and , another issue i 'm thinking about is in the smartkom system . say twe twelve seconds in the earlier test seemed like a good length of time , but what happens if you have less than twelve seconds ? and , w bef before , back in may , i did some experiments using , say , two seconds , or four seconds , or six seconds . in those i trained the models using mean subtraction with the means calculated over two seconds , or four seconds , or six seconds . and , here , i was curious , what if i trained the models using twelve seconds but i f i gave it a situation where the test set i was subtracted using two seconds , or four seconds , or six seconds . and , did that for about three different conditions . and , i th it was , four se it was , something like four seconds and , six seconds , and eight seconds . something like that . and it seems like it hurts compared to if you actually train the models using th that same length of time but it doesn't hurt that much .  u usually less than point five percent , although did see one where it was a point eight percent or rise in word error rate . but this is , w where , even if i train on the , model , and mean subtracted it with the same length of time as in the test , it the word error rate is around , ten percent or nine percent . it doesn't seem like that big a d a difference . that 's true .  wa t twelve s n for the test it 's just twelve seconds in the past . of speech .  right . and that 's actually what we 're planning to do in but s g guess the que the question i was trying to get at with those experiments is , "" does it matter what models you use ? does it matter how much time y you use to calculate the mean when you were , tra doing the training data ? ""     you do in my tests far ? most of the silence has been cut out . just there 's just inter word silences . pretty short .  if i only use six seconds , it still works pretty i saw in my test before . i was trying twelve seconds cuz that was the best in my test before and that increasing past twelve seconds didn't seem to help . th it 's something i need to play with more to decide how to set that up for the smartkom system . like , may if i trained on six seconds it would work better when i only had two seconds or four seconds , and  m  s the idea of the second pass would be waiting till you have more recorded speech ? or ?        that 's it . ","th that 's his spectral subtraction group ? is that right ? guess i should probably talk to him a bit too ? since we 're looking at putting this , mean log m magnitude spectral subtraction , into the smartkom system , i did a test seeing if , it would work using past only and plus the present to calculate the mean . i did a test , where i used twelve seconds from the past and the present frame to , calculate the mean . twelve seconds , counting back from the end of the current frame , it was , twen it was twenty one frames and compared to , do using a twelve second centered window , there was a drop in performance but it was just a slight drop . say twe twelve seconds in the earlier test seemed like a good length of time , but what happens if you have less than twelve seconds ? w bef before , back in may , i did some experiments using , say , two seconds , or four seconds , or six seconds . in those i trained the models using mean subtraction with the means calculated over two seconds , or four seconds , or six seconds . here , i was curious , what if i trained the models using twelve seconds but i f i gave it a situation where the test set i was subtracted using two seconds , or four seconds , or six seconds . and it seems like it hurts compared to if you actually train the models using th that same length of time and that 's actually what we 're planning to do in ","Group members reported their progress in the areas of spectral subtraction, Wiener filtering and noise estimation. "
Bro024.A,"  for the past , week an or two , i 've been just writing my , formal thesis proposal . 'm taking this qualifier exam that 's coming up in two weeks . and i finish writing a proposal and submit it to the committee .  and should i explain , more about what i 'm proposing to do , and s and   briefly , i 'm proposing to do a n a new p approach to speech recognition using a combination of , multi band ideas and ideas , about the acoustic phonec phonetic approach to speech recognition . will be using these graphical models that that implement the multi band approach to recognize a set of intermediate categories that might involve , things like phonetic features or other f feature things that are more closely related to the acoustic signal itself . and the hope in all of this is that by going multi band and by going into these , intermediate classifications , that we can get a system that 's more robust to unseen noises , and situations like that .  and some of the research issues involved in this are , one , what intermediate categories do we need to classify ? another one is what other types of structures in these multi band graphical models should we consider in order to combine evidence from the sub bands ? and , the third one is how do we merge all the , information from the individual multi band classifiers to come up with word recognition or phone recognition things .  that 's what i 've been doing . and , i got two weeks to brush up on d presentation and , but . that too .  yes . yes . i , 'm gonna do some . would you be interested ? to help out ?    that 's it .  is this vad a mlp ?  how big is it ?  seven . 'm eight , you 're seven .  ","for the past , week an or two , i 've been just writing my , formal thesis proposal . 'm taking this qualifier exam that 's coming up in two weeks . and i finish writing a proposal and submit it to the committee . briefly , i 'm proposing to do a n a new p approach to speech recognition using a combination of , multi band ideas and ideas , about the acoustic phonec phonetic approach to speech recognition . will be using these graphical models that that implement the multi band approach to recognize a set of intermediate categories that might involve , things like phonetic features or other f feature things that are more closely related to the acoustic signal itself . and the hope in all of this is that by going multi band and by going into these , intermediate classifications , that we can get a system that 's more robust to unseen noises , and situations like that . ",
Bro024.B,"  but i actually stuck most of this in our m last meeting with guenter .  but i 'll just  the last week , i showed some results with only speechdat car which was like some fifty six percent . and , i didn't h i found that the results i wasn't getting that r results on the ti digit . was like looking into "" why , what is wrong with the ti digits ? "" . why i was not getting it . and i found that , the noise estimation is a reason for the ti digits to perform worse than the baseline . i actually , picked th the first thing i did was scaled the noise estimate by a factor which is less than one to see if that because i found there are a lot of zeros in the spectrogram for the ti digits when i used this approach . the first thing i did was scaled the noise estimate . and i found the results that i 've shown here are the complete results using the new the n the new technique is nothing but the noise estimate scaled by a factor of point five . it 's just an ad hoc some intermediate result , because it 's not optimized for anything . the results the trend the only trend i could see from those results was like the p the current noise estimation or the , noise composition scheme is working good for like the car noise type of thing . because i 've the only p very good result in the ti digits is the noise car noise condition for their test a , which is like the best i could see that for any non stationary noise like "" babble "" or "" subway "" or any "" street "" , some "" restaurant "" noise , it 's like it 's not performing w very  the that 's the first thing i c i could make out from this and     and in that twenty percent @ @ it 's very inconsistent across different noise conditions . have like a forty five percent for "" car noise "" and then there 's a minus five percent for the "" babble "" , and there 's this thirty three for the "" station "" . and it 's not it 's not actually very consistent across .  the only correlation between the speechdat car and this performance is the c stationarity of the noise that is there in these conditions and the speechdat car . and ,  the overall result is like in the last page , which is like forty seven , which is still very imbalanced because there are like fifty six percent on the speechdat car and thirty five percent on the ti digits . and  ps the fifty six percent is like comparable to what the french telecom gets , but the thirty five percent is way off .    for that 's for the clean training and the noisy testing for the ti digits .    no .  actually the noise compensation whatever , we are put in it works very for the high mismatch condition . it 's consistent in the speechdat car and in the clean training also it gives it but this fifty percent is that the high mismatch performance equivalent to the high mismatch performance in the speech .   i do .  by putting this noise  the reference drops like a very fast      it 's not written anywhere . it 's ti digits . the first r spreadsheet is ti digits . the "" car "" ?  still it still , that 's still consistent . i get the best performance in the case of "" car "" , which is the third column in the a condition .  that 's the next spreadsheet , is that is the performance for italian , finnish and spanish .  improvement . that 's "" percentage increase "" is the percentage improvement over the baseline . that 's    there 's a which is there in the spreadsheet . i 'm not changing anything in there .    all the hi h m numbers are w very good , in the sense , they are better than what the french telecom gets .  but the only number that 's still which stephane also got in his result was that medium mismatch of the finnish , which is very which is a very strange situation where we used the we changed the proto for initializing the this is because it gets stuck in some local minimum in the training . that seventy five point seven nine in the finnish mismatch which is that the eleven point nine six what we see .   we start with that different proto and it becomes eighty eight , which is like some fifty percent improvement . different prototype , which is like a different initialization for the , s transition probabilities . it 's just that right now , the initialization is to stay more in the current state , which is point four point six , right ?  and if it changes to point five , which is equal @ @ for transition and self loop where it becomes eighty eight percent .  we can't do it .   very s it has a very few at actually , c tran words also . it 's a very , very small set , actually . there is     it has some music also . very horrible music like i know .   that 's the that 's about the results . and , the summary is like  there are the other thing what i tried was , which i explained in the last meeting , is using the channel zero for , for both dropping and estimating the noise . and that 's like just to f n get a feel of how good it is . the fifty six percent improvement in the speechdat car becomes like sixty seven percent . like ten percent better . ","the last week , i showed some results with only speechdat car which was like some fifty six percent . i wasn't getting that r results on the ti digit . was like looking into "" why , what is wrong with the ti digits ? "" . and i found that , the noise estimation is a reason for the ti digits to perform worse than the baseline . ","The groups regulars reported progress on their work on mean subtraction, noise estimation, voice activity detection and the Vector Taylor Series. "
Bro024.B,"but that 's not a that 's a cheating experiment .  that 's just  m w  we had forty four percent in the first proposal .  we have f a big im the major improvement that we got was in all the high mismatch cases , because all those numbers were in sixties and seventies because we never had any noise compensations . that 's where the biggest improvement came up . not much in the match and the medium match and ti digits also right now . this is still at three or four percent improvement over the first proposal .        yes . stephane also has the same experience of using the spectral subtraction right ?  here i found that it 's if i changed the noise estimate i could get an improvement . that 's it 's something which actually pursue , is the noise estimate . and      th that 's true . the c the models are not complex enough to absorb that additional variability that you 're introducing . that 's   it 's  very different from speech . still , it shouldn't confuse the     the that 's true . that those regions are the for this @ @ those negative values or whatever you get .       c z c zero and log energy also ,  now ?   the log energy , the after the clean cleaning up . they add a random noise to it . no . on only to the log energy . like , mean no their filter is not m domain . s they did filter their time signal and then what @ @ u  then after that it is s almost the same as the baseline prop system . and then the final log energy that they get , that to the to that they add some random noise .  it 's not the mel . it 's not the mel filter bank output . these are log energy computed from the time s domain signal , not from the mel filter banks .  did becomes flat . the variance , reduces ,    although  the  the other thing is the i 'm just looking at a little bit on the delay issue where the delay of the system is like a hundred and eighty millisecond . just tried another sk system another filter which i 've like shown at the end . which is very similar to the existing filter . only only thing is that the phase is like a nonlinear phase because it 's a it 's not a symmetric filter anymore .  this is like this makes the delay like zero for lda because it 's completely causal .  got actually just the results for the italian for that and that 's like the fifty one point o nine has become forty eight point o six , which is like three percent relative degradation . have like the fifty one point o nine and  i don't know it f fares for the other conditions . it 's just like it 's like a three percent relative degradation , with the u may the french telecom . thirty four .      if they include the delta , it will be an additional forty millisecond . no , they 're using a nine point window , which is like a four on either side , which is like f they didn't include that .  that 's the way the frames are packed , like you have to for one more frame to pack . because it 's the crc is computed for two frames always . no . they actually changed the compression scheme altogether . they have their own compression and decoding scheme and they i don't they have . but they have coded zero delay for that . because they ch i know they changed it , their compression . they have their own crc , their own error correction mechanism . they don't have to more than one more frame to know whether the current frame is in error . they changed the whole thing that there 's no delay for that compression and part also . even you have reported actually zero delay for the compression . you also have some different     no . that threshold  s the detection threshold is very    the median filtering is fixed . you just change the threshold ?    three hundred and fifty inputs ,  six thousand hidden nodes and two outputs . t    s it 's not trained on finnish . the mlp 's not trained on finnish .   it 's italian ti digits .  that 's right .  the it 's true .    there are like some s some parameters you wanted to use or  we actually trained , the on the italian training part . we had another system with u  it must be somewhere .  what no it  that 's true . syste    took their entire italian training part . it was both channel zero plus channel one . on one . possible . we can do a realignment . that 's true .  possible . it the system the vad was trained on different set of labels for channel zero and channel one and was the alignments were w were different for s certainly different because they were independently trained . we didn't copy the channel zero alignments to channel one .  but for the new alignments what you generated , you just copied the channel zero to channel one , right ?  but this number . this by by reducing the noise a decent threshold like minus thirty db , it 's like you are like r reducing the floor of the noisy regions , right ?  before it 's like adding this , col to the o exi original    for all the languages .   d does latency  go ahead . actually i d i do all the smoothing .  before estimating the snr , @ @ smooth the envelope .  or some silence probability from the vad if you have  not right now  ","the other thing is the i 'm just looking at a little bit on the delay issue where the delay of the system is like a hundred and eighty millisecond . just tried another sk system another filter which i 've like shown at the end . which is very similar to the existing filter . only only thing is that the phase is like a nonlinear phase it 's just like it 's like a three percent relative degradation , ",
Bro024.B,"the fifty eight is like the be some fifty six point  that 's true . slightly better .   you caught up .  that 's true .   it 's better for high mismatch . over all it gets , worse for the matched condition ,   that 's the best thing , is like the french telecom system is optimized for the matched condition . they c  they know that the weighting is good for the matched , and there 's everywhere the matched 's performance is very good for the french telecom . t we are we may also have to do something similar @ @ . the you that 's somewhere you s you have a better r  you have some results that are good for the high mismatch .  using the clean filter .  i 'll try . i 'll try the cle no , i my result is with the noisy lda .  it 's with the noisy .  it 's not the clean lda . it 's in the front sheet , i have like the summary .   this is your results are all with the clean lda result ?  all noisy ,    on ti digits this matters . absolute .  i will have to look at it . that 's true . t ",,
Bro024.C,"   the this past week i 've been main mainly occupied with , getting some results , u from the sri system trained on this short hub five training set for the mean subtraction method . and , i ran some tests last night . but , c the results are suspicious . it 's , cuz they 're the baseline results are worse than , andreas than results andreas got previously . and it could have something to do with , that 's on digits . it c it could h it could have something to do with , downsampling . that 's worth looking into .  d and , ap apart from that , the main thing i have t ta i have to talk is , where i 'm planning to go over the next week .  've been working on integrating this mean subtraction approach into the smartkom system . and there 's this question of , in my tests before with htk i found it worked the best with about twelve seconds of data used to estimate the mean , but , we 'll often have less in the smartkom system .  think we 'll use as much data as we have at a particular time , and we 'll concatenate utterances together , to get as much data as we possibly can from the user . but , there 's a question of how to set up the models . we could train the models . if we think twelve seconds is ideal we could train the models using twelve seconds to calculate the mean , to mean subtract the training data . or we could , use some other amount . like i did an experiment where i , was using six seconds in test , but , for i tried twelve seconds in train . and i tried , the same in train i 'm a i tried six seconds in train . and six seconds in train was about point three percent better . and it 's not clear to me yet whether that 's something significant . wanna do some tests and , actually make some plots of , for a particular amount of data and test what happens if you vary the amount of data in train . y s was i actually ran the experiments mostly and i was hoping to have the plots with me today . didn't get to it . but , i wou i would be curious about people 's feedback on this cuz i 'm @ @ i p there are some it 's like a bit of a tricky engineering problem . i 'm trying to figure out what 's the optimal way to set this up . i 'll try to make the plots and then put some postscript up on my web page . and i 'll mention it in my status report if people wanna take a look . w it c i don't think it 's just for any mismatch you take a hit . i in some cases it might be u better to have a mismatch . like saw something like if you only have two seconds in test , or , it was something like four seconds , you actually do a little better if you , train on six seconds than if you train on four seconds .  but the case , with the point three percent hit was using six seconds in test , comparing train on twelve seconds versus train on six seconds . the train on twelve seconds . on the accuracies w went from it was something vaguely like ninety five point six accuracy , improved to ninety five point nine wh when i    that 's interesting . alright , the e i see your point . was thinking of it as , an interesting research problem . the how to g i was thinking that for the asru paper we could have a section saying , "" for smartkom , we d in we tried this approach in , interactive system "" , which i don't think has been done before . and then there was two research questions from that . and one is the k does it still work if you just use the past history ? alright , and the other was this question of , what i was just talking about now . guess that 's why it was interesting .   o that 's that 's standard .    right .  and , let 's l let 's see .   and then there 's another thing i wanna start looking at , wi is , the choice of the analysis window length . 've just been using two seconds just because that 's what carlos did before . i wrote to him asking about he chose the two seconds . and it seemed like he chose it a bit informally .  with the htk set up i should be able to do some experiments , on just varying that length , say between one and three seconds , in a few different reverberation conditions , say this room and also a few of the artificial impulse responses we have for reverberation , just , making some plots and seeing how they look . and ,  with the sampling rate i was using , one second or two seconds or four seconds is at a power of two number of samples and , i 'll jus f for the ones in between 'll just zero pad .    i don't think the ti digits data that i have , i is would be appropriate for that . but what do you what about if i w i fed it through some speech processing algorithm that changed the speech rate ?  just if you think it 's worth looking into . it is getting a little away from reverberation .  right . and th the third thing , is , barry explained lda filtering to me yesterday . ","the this past week i 've been main mainly occupied with , getting some results , u from the sri system trained on this short hub five training set for the mean subtraction method . i ran some tests last night . the results are suspicious . it 's , cuz they 're the baseline results are worse than , andreas than results andreas got previously . ap apart from that , the main thing i have t ta i have to talk is , where i 'm planning to go over the next week . 've been working on integrating this mean subtraction approach into the smartkom system . and there 's this question of , in my tests before with htk i found it worked the best with about twelve seconds of data used to estimate the mean , but , we 'll often have less in the smartkom system . think we 'll use as much data as we have at a particular time , and we 'll concatenate utterances together , to get as much data as we possibly can from the user . but , there 's a question of how to set up the models . we could train the models . if we think twelve seconds is ideal we could train the models using twelve seconds to calculate the mean , to mean subtract the training data . or we could , use some other amount . and then there 's another thing i wanna start looking at , wi is , the choice of the analysis window length . with the htk set up i should be able to do some experiments , on just varying that length , say between one and three seconds , in a few different reverberation conditions , ","The groups regulars reported progress on their work on mean subtraction, noise estimation, voice activity detection and the Vector Taylor Series. While on these topics, related areas discussed included recognition window length, training versus test set sizes, artificial distortion and latency concerns. "
Bro024.C,"and mike shire in his thesis did a series of experiments , training lda filters in d on different conditions . and you were interested in having me repeat this for for this mean subtraction approach ? is that right ? or for these long analysis windows , is the right way to put it .  right .    o  a actually i was just thinking about what i was asking about earlier , wi which is about having less than say twelve seconds in the smartkom system to do the mean subtraction . you said in systems where you use cepstral mean subtraction , they concatenate utterances and , do how they address this issue of , testing versus training ? can     and , in tha in that case , wh what do they do when they 're t performing the cepstral mean subtraction on the training data ? because you 'd have hours and hours of training data . do they cut it off and start over ? at intervals ? or ? no . not . but  but it 's  if someone 's interacting with the system , though , morgan said that you would tend to , chain utterances together r   right . i g the question i had was , amount of data e u was the amount of data that you 'd give it to , update this estimate . because say you if you have say five thousand utterances in your training set , and you keep the mean from the last utterance , by the time it gets to the five thousandth utterance  they would g s r and it right .  you 'd you and in training you would start over at every new phone call or at every new speaker .   r right . right ,  i see . bec because i this smartkom task first off , it 's this tv and movie information system . and   right . right . i see . i was about to say . if you ask it "" what movies are on tv tonight ? "" , if i look at my wristwatch when i say that it 's about two seconds . the way i currently have the mean subtraction , set up , the analysis window is two seconds . what you just said , about what do you start with , raises a question of what do i start with then ? it because  right .  right . right . right . and i g s just started thinking of another question , which is , for the very first frame , w what do i do if i 'm if i take if i use that frame to calculate the mean , then i 'm just gonna get n nothing .  should probably have some default mean for the first f couple of frames ?  or subtract nothing . and that 's that 's something that 's p people have figured out how to deal with in cepstral mean subtraction as        that was all i had , for now .  ","a actually i was just thinking about what i was asking about earlier , wi which is about having less than say twelve seconds in the smartkom system to do the mean subtraction . you said in systems where you use cepstral mean subtraction , they concatenate utterances and , do how they address this issue of , testing versus training ? and , in tha in that case , wh what do they do when they 're t performing the cepstral mean subtraction on the training data ? because you 'd have hours and hours of training data . do they cut it off and start over ? you 'd you and in training you would start over at every new phone call or at every new speaker . ","While on these topics, related areas discussed included recognition window length, training versus test set sizes, artificial distortion and latency concerns. "
Bro024.D," might wanna close the door that stephane will  that 's the virtual stephane over there .    the suggestion was to have these guys start to guenter , i don't know if you t followed this but this is , a long term window f  he you talked about it .  what he 's doing . alright . you could clarify something for me . you 're saying point three percent , you take a point three percent hit , when the training and testing links are don't match is that what it is ? or ?   right . and which was worse ?  but point three percent , w from what to what ? that 's point three percent four point four to four point one .  about a about an eight percent , seven or eight percent relative ?   in a p if you were going for an evaluation system you 'd care . but if you were doing a live system that people were actually using nobody would notice . it 's to get something that 's practical , that you could really use .     a short time fft short time cepstrum calculation , mean u mean calculation work that people have in commercial systems , they do this all the time . they the they calculate it from previous utterances and then use it , but , as you say , there hasn't been that much with this long time , spectra work .   pretty common .   but , u yes . no , it is interesting . and the other thing is , there 's two sides to these really small , gradations in performance . on the one hand in a practical system if something is , four point four percent error , four point one percent error , people won't really tell be able to tell the difference . on the other hand , when you 're doing , research , you may , you might find that the way that you build up a change from a ninety five percent accurate system to a ninety eight percent accurate system is through ten or twelve little things that you do that each are point three percent . the they it 's i don't mean to say that they 're irrelevant . they are relevant . but , i for a demo , you won't see it .   one thing that might also be an issue , cuz part of what you 're doing is you 're getting a spectrum over a bunch of different kinds of speech sounds .  and it might matter how fast someone was talking if you if there 's a lot of phones in one second you 'll get a really good sampling of all these different things , and , on the other hand if someone 's talking slowly you 'd need more .  i don't know if you have some samples of faster or slower speech but it might make a difference . i don't know . probably not .  but then you 'll have the degradation of , whatever you do added onto that . but  if you get something that sounds that 's does a pretty job at that . you could imagine that .  it 's just that you 're making a choice i was thinking more from the system aspect , if you 're making a choice for smartkom , that it might be that it 's it c the optimal number could be different , depending on could be . i don't know . the issue i was the general issue i was bringing up was that if you 're have a moving window , a wa a set of weights times things that , move along , shift along in time , that you have linear time invariant filter . and you just happened to have picked a particular one by setting all the weights to be equal . and the issue is what are some other filters that you could use , in that sense of "" filter "" ? and , as i was saying , the simplest thing to do is not to train anything , but just to do some hamming or hanning , window , thing , just to de emphasize the jarring . think that would be the first thing to do . but then , the lda i is interesting because it would say suppose you actually trained this up to do the best you could by some criterion , what would the filter look like then ?  and , that 's what we 're doing in this aur aurora and , it 's still not clear to me in the long run whether the best thing to do would be to do that or to have some stylized version of the filter that looks like these things you 've trained up , because you always have the problem that it 's trained up for one condition and it isn't quite right for another .  that 's why that 's why rasta filter has actually ended up lasting a long time , people still using it quite a bit , because y you don't change it .  doesn't get any worse .  anyway . go ahead . what i was s what i was saying was that , at any given point you are gonna start off with what you had from before . from and if you 're splitting things up into utterances in a dialogue system , where you 're gonna be asking , th for some information , there 's some initial th something . and , the first time out you might have some general average . but you d you don't have very much information yet . but at after they 've given one utterance you 've got something . you can compute your mean cepstra from that , and then can use it for the next thing that they say ,  that , the performance should be better that second time .  ","one thing that might also be an issue , cuz part of what you 're doing is you 're getting a spectrum over a bunch of different kinds of speech sounds . and it might matter how fast someone was talking if you if there 's a lot of phones in one second you 'll get a really good sampling of all these different things , and , on the other hand if someone 's talking slowly you 'd need more . and if you 're splitting things up into utterances in a dialogue system , where you 're gonna be asking , th for some information , there 's some initial th something . ","While on these topics, related areas discussed included recognition window length, training versus test set sizes, artificial distortion and latency concerns. "
Bro024.D,"and the heuristics of exactly how people handle that and how they handle their training i 'm vary from place to place . but the ideally , it seems to me anyway , that you would wanna do the same thing in training as you do in test . but that 's just , a prejudice . and anybody working on this with some particular task would experiment . no , but those are all different people with different i in y in the in a telephone task , these are different phone calls . you don't wanna @ @ chain it together from a different phone call . it 's within speaker , within phone call , if it 's a dialogue system , it 's within whatever this characteristic you 're trying to get rid of is expected to be consistent over , right ?   now , you 'd use something from the others just because at the beginning of a call you don't know anything , and you might have some general thing that 's your best guess to start with . but s i a lot of these things are proprietary we 're doing a little bit of guesswork here . what do comp what do people do who really face these problems in the field ? they have companies and they don't tell other people exactly what they do . but when you the hints that you get from what they when they talk about it are that they do they all do something like this . but you might have somebody who 's using it and then later you might have somebody else who 's using it . and you 'd wanna set some      w in that situation , though , th what 's a little different there , is you 're talking about there 's only one it also depends we 're getting a little off track here . r but there 's been some discussion about whether the work we 're doing in that project is gonna be for the kiosk or for the mobile or for both . and for this discussion it matters . if it 's in the kiosk , then the physical situation is the same . it 's gonna the exact interaction of the microphone 's gonna differ depending on the person and forth . but at least the basic acoustics are gonna be the same . if it 's really in one kiosk , then that you could just chain together and as much speech as possible to because what you 're really trying to get at is the reverberation characteristic . but in the case of the mobile , presumably the acoustic 's changing all over the place . and in that case you probably don't wanna have it be endless because you wanna have some it 's not a question of how long do you think it 's you can get an approximation to a stationary something , given that it 's not really stationary .   right .    or subtract nothing . it 's  people do something . they , they have some ,  in cepstral mean subtraction , for short term window analysis windows , as is usually done , you 're trying to get rid of some very general characteristic . and if you have any other information about what a general characteristic would be , then you can do it there .  that 's  the other thing is that and i remember b n doing this , is that if you have a multi pass system , if the first pass ta it takes most of the computation , the second and the third pass could be very , very quick , just looking at a relatively small n small , space of hypotheses . then you can do your first pass without any subtraction and then your second pass , eliminates those most of those hypotheses by , by having an improved version o of the analysis .   yes , briefly . you were finishing your thesis in two weeks .  i 'm confused but this i 'm looking on the second page , and it says "" fifty percent "" looking in the lower right hand corner , "" fifty percent relative performance "" . is that is that fifty percent improvement ? it 's improvement over the baseline mel cepstrum ? but the baseline mel cepstrum under those training doesn't do as i 'm trying to understand why it 's eighty percent that 's an accuracy number , right ? that 's not as good as the one up above . but the fifty is better than the one up above , 'm confused .   i see . i see . this is ti digits we 're looking at ? this whole page is ti digits or this is ?  how does clean training do for the , "" car ""  no . this is added noise . this is ti digits . i 'm i meant in the , multi language , finnish and "" training condition "" right . clean "" corresponds to "" high mismatch "" . and "" increase "" , that 's increase e which means decrease in word error rate ?  percentage increase "" means decrease ?   alright .  we have to jiggle it somehow ? s minute . start with a different what ?  for that one you need a much smarter vad ?  if it 's music . that 's good . then if we can improve the noise estimation , then it should get better .   we probably should at some point here try the tandem the system two with this , with the spectral subtraction for that reason . cuz again , it should do a transformation to a domain where it looks more gaussian .  but isn't that s again the idea of the additive thing , if it as we had in the j ",and the heuristics of exactly how people handle that and how they handle their training i 'm vary from place to place . ,"While on these topics, related areas discussed included recognition window length, training versus test set sizes, artificial distortion and latency concerns. "
Bro024.D,"if you have random data , in the time domain , then when you look at the s spectrum it 's gonna be pretty flat . and ,  just add something everywhere rather than just in those places . it 's just a constant , right ?   see if you add something everywhere , it has almost no effect up on top . and it and it has significant effect down there . that was , the idea . when it 's noisy people should just speak up . they do !   to the l to the just the energy , or to the mel to the mel filter ?  it cuz this is most interesting for the mel filters . right ? or f one or the other . but again , that 's just log energy as opposed to filter bank energy .    it could reduce the dependence on the amplitude and on .   th this is this is our position is that , we shouldn't be unduly constraining the latency at this point because we 're all still experimenting with trying to make the performance better in the presence of noise . there is a minority in that group who is a arguing who are arguing for having a further constraining of the latency . we 're s just continuing to keep aware of what the trade offs are and , what do we gain from having longer or shorter latencies ? but since we always seem to at least get something out of longer latencies not being constrained , we 're tending to go with that if we 're not told we can't do it . france telecom was very short latency and they had a very good result . it was thirty five .  th  it 's possible to get very short latency . but , again , we 're the approaches that we 're using are ones that take advantage of   that the they would need that forty milliseconds also . right ?      minute . it 's minute . 'm confused . alright .   i have four now because i left one with dave because was dropping one off and passing the others on . no , we 're not .  we need one more over here .  middle sized one . what 's it trained on ? right , what 's it trained on ?  it 's trained on italian ?    cuz i notice the ti digits number is exactly the same for these last two ?  that means the only thing  you just should look at that fifty eight perc point o nine percent and on .  good . i 'm when you say minus twenty five or minus thirty db , with respect to what ?  you 're creating a signal to noise ratio of twenty five or thirty db ?  but did you do that before the thresholding to zero , or ?  you 'd really want to do it before , right ?  because then the then you would have less of that phenomenon .  c  it right . that will reduce the variance . that 'll help . but if you does do it before you get less of these funny looking things he 's drawing . right at the point where you 've done the subtraction . essentially you 're adding a constant into everything .  better do it different , then .  just you just ta you just set it for a particular signal to noise ratio that you want ?     i 'm then i 'm confused .  you 're saying it doesn't depend on the utterance but you were adding an amount that was twenty five db down from the signal energy .  it 's just a constant amount over all .  but in in the real thing you 're not gonna be able to measure what people are doing over half an hour or an hour , or anything , right ? you have to come up with this number from something else . but what he is doing language dependent is measuring what that number i reference is that he comes down twenty five down from . no ?  it 's arbitrary . if y if    something more adaptive ,   the vad later will be much better .   i see . our tradition here has always been to focus on the mismatched . cuz it 's more interesting .       right .  what are these numbers here ? are these with the clean or with the noisy ?     and your result is with the you really might wanna try the clean  that could be sizeable right there .  be my guest .   i 'll borrow the head back and agree .  that 's that 's right . actually i g the , the spanish government , requires that anyway . they want some report from everybody who 's in the program .  and 'd we 'd like to see it too .   we have them now ? why don why don't we do it ? just take a minute .   seat ? mike ? ","our position is that , we shouldn't be unduly constraining the latency at this point because we 're all still experimenting with trying to make the performance better in the presence of noise . there is a minority in that group who is a arguing who are arguing for having a further constraining of the latency . we 're s just continuing to keep aware of what the trade offs are and , what do we gain from having longer or shorter latencies ? france telecom was very short latency ","While on these topics, related areas discussed included recognition window length, training versus test set sizes, artificial distortion and latency concerns. "
Bro024.E,"hello .   if we look at the figures on the right , we see that the reference system is very bad . like for clean training condition . nnn .      i also have the feeling that the reason ye why it doesn't work is that the models are much are t not complex enough . because i actually i als always had a good experience with spectral subtraction , just a straight spectral subtraction algorithm when i was using neural networks , big neural networks , which are more able to model strange distributions and but  then i tried the same exactly the same spectral subtraction algorithm on these aurora tasks and it simply doesn't work . it 's even it , hurts even .      if we look at the france telecom proposal , they use some noise addition . they have a random number generator , right ? and they add noise on the trajectory of , the log energy only , right ?   but i don't know how much effect it this have , but they do that .  because they have th log energy ,  and then just generate random number . they have some mean and variance , and they add this number to the log energy simply .   only   it 's just a way to decrease the importance of this particular parameter in the world feature vector cu if you add noise to one of the parameters , you widen the distributions and eee sss     where does the comprish compression in decoding delay comes from ?   go next .   it 's  we have to take   you have w one sheet ? this one is you don't need it , alright . you have to take the whole the five . there should be five sheets . there 's not enough for everybody . but can we look at this ?  there are two figures showing actually the , performance of the current vad . it 's a n neural network based on plp parameters , which estimate silence probabilities , and then put a median filtering on this to smooth the probabilities , right ?  i didn't use the scheme that 's currently in the proposal because i don't want to in the proposal in the system we want to add like speech frame before every word and a little bit of , s a couple of frames after also . but to estimate the performance of the vad , we don't want to do that , because it would artificially increase the the false alarm rate of speech detection . right ?   there is u normally a figure for the finnish and one for italian . and someone has two for the italian because i 'm missing one figure here .  whatever . one surprising thing that we can notice first is that the speech miss rate is higher than the false alarm rate .  it means  there are two curves . one curve 's for the close talking microphone , which is the lower curve . and the other one is for the distant microphone which has more noise  it 's logical that it performs worse . as i was saying , the miss rate is quite important which means that we tend to label speech as a silence . and , i didn't analyze further yet , but it 's it may be due to the fricative sounds which may be in noisy condition label labelled as silence . and it may also be due to the alignment because the reference alignment . because right now use an alignment obtained from a system trained on channel zero . and i checked it a little bit but there might be alignment errors .  e like the fact that the models tend to align their first state on silence and their last state o on silence also . the reference alignment would label as speech some silence frame before speech and after speech . this is something that we already noticed before when  this cus this could also explain , the high miss rate   right .   and the different points of the curves are for five thresholds on the probability from point three to point seven .   the v the vad ?  there first , a threshold on the probability @ @ that puts all the values to zero or one . and then the median filtering .  it 's fixed ,   going from channel zero to channel one , almost double the error rate .   it 's a reference performance that we can if we want to work on the vad , we can work on this basis and  it 's a very big one . i don't remember . m    ppp . i don't know , you have questions about that , or suggestions ? it seems the performance seems worse in finnish , which  it 's not trained on finnish ,   and and also there are like funny noises on finnish more than on italian . like music and  we were looking at this . but for most of the noises , noises are  i don't know if we want to talk about that . but , the "" car "" noises are below like five hundred hertz . and we were looking at the "" music "" utterances and in this case the noise is more about two thousand hertz . the music energy 's very low  from zero to two thousand hertz . just looking at this frequency range for from five hundred to two thousand would improve somewhat the vad and   but yes .  the next ,  it 's there .  no . it 's not . it 's it was trained on some alignment obtained  for the italian data , we trained the neural network on with embedded training . re estimation of the alignment using the neural network , that 's right ?  it was a f a phonetic classification system for the italian aurora data . ","go next . there are two figures showing actually the , performance of the current vad . it 's a n neural network based on plp parameters , which estimate silence probabilities , and then put a median filtering on this to smooth the probabilities , right ? ","The groups regulars reported progress on their work on mean subtraction, noise estimation, voice activity detection and the Vector Taylor Series. "
Bro024.E,"for the aurora data that it was trained on , it was different . like , for ti digits you used a previous system that you had , the alignments from the different database that are used for training came from different system . then we put them tog together . you put them together and trained the vad on them .   but did you use channel did you align channel one also ? or  di  the alignments might be wrong then on channel one , right ? we might ,  at least want to retrain on these alignments , which should be better because they come from close talking microphone .        right .   and hhh actually when we look at the vad , for some utterances it 's almost perfect , it just dropped one frame , the first frame of speech or there are some utterances where it 's almost one hundred percent vad performance .  but   the next thing is i have the spreadsheet for three different system . but for this you only have to look right now on the speechdat car performance because i didn't test didn't test the spectral subtraction on ti digits yet . you have three she sheets . one is the proposal one system . actually , it 's not exe exactly proposal one . it 's the system that sunil just described .  but with wiener filtering from france telecom included . this gives like fifty seven point seven percent , s error rate reduction on the speechdat car data .  and then i have two sheets where it 's for a system where  it 's again the same system . but in this case we have spectral subtraction with a maximum overestimation factor of two point five . there is smoothing of the gain trajectory with some low pass filter , which has forty milliseconds latency . and then , after subtraction i add a constant to the energies and i have two cases d where the first case is where the constant is twenty five db below the mean speech energy and the other is thirty db below .  and for these s two system we have like fifty five point , five percent improvement , and fifty eight point one . again , it 's around fifty six , fifty seven .  because i didn't for the france telecom spectral subtraction included in the our system , the ti digits number are the right one , but not for the other system because i didn't test it yet this system , including with spectral subtraction on the ti digits data . tested it on speechdat car . this , we have to  yes . right . right .      the floor is lower .   to the average speech energy which is estimated on the world database .  but it 's not it 's  right . it 's but , it 's after the thresholding .   we might do it before ,     but still , when you do this and you take the log after that , it reduce the variance . but   we would       it 's clear . i should have gi given other results . also it 's clear when you don't add noise , it 's much worse . like , around five percent worse and if you add too much noise it get worse also . and it seems that right now this is c a constant that does not depend on anything that you can learn from the utterance . it 's just a constant noise addition .  and   the way i did that , measured the average speech energy of the all the italian data . and then i have i used this as mean speech energy .   and wha what i observed is that for italian and spanish , when you go to thirty and twenty five db , it 's good . it stays in this range , it 's , the p u the performance of the this algorithm is quite good . but for finnish , you have a degradation already when you go from thirty five to thirty and then from thirty to twenty five . and i have the feeling that it 's because just finnish has a mean energy that 's lower than the other databases . and due to this the thresholds should be the a the noise addition should be lower and   it 's not . it 's just something that 's fixed .    g no . it no . because i did it i started working on italian . i obtained this average energy and then i used this one .    the next thing is to use this as initialization and then use something on line . but and i expect improvement at least in finnish because the way   for italian and spanish it 's th this value works good but not necessarily for finnish .  but unfortunately there is this forty millisecond latency and ,  would try to somewhat reduce this @ @ . i already know that if i completely remove this latency , it there is a three percent hit on italian .  it 's a smoothing over the gain of the subtraction algorithm . right . to smooth this thing .    no , i did not .     no , it 's just the gain that 's smoothed actually but it 's smoothed   no , in this case it 's just the gain . and but the way it 's done is that for low gain , there is this non nonlinear smoothing actually . for low gains i use the smoothed sm smoothed version but for high gain @ @ it 's i don't smooth .     i could try this .   but  then i would need to find a way to like smooth less also when there is high energy . cuz i noticed that it helps a little bit to s like smooth more during low energy portions and less during speech , ","for italian and spanish it 's th this value works good but not necessarily for finnish . but unfortunately there is this forty millisecond latency would try to somewhat reduce this @ @ . i already know that if i completely remove this latency , it there is a three percent hit on italian . ",
Bro024.E,"because if you smooth then y you distort the speech .           but i don't trust the current vad .    fff that 's it .       and , i the condition where it 's better than your approach , it 's it just because it 's better on matched and that the weight on matched is bigger , because if you don't weigh differently the different condition , you can see that your the win the two stage wiener filtering is better or it 's better for high mismatch , right ?  but a little bit worse for matched .       it 's  i did that but it doesn't matter on speechdat car , but , it matters , a lot on ti digits .  d it 's much better when you we used the clean derived lda filter .  but , sunil in your result it 's it 's with the noisy one .   it 's with the clean lda .  and in your case it 's all noisy ,  but  but i observe my case it 's in , at least on speechdat car it doesn't matter but ti digits it 's like two or three percent absolute , better . if dave ? is it the channel , or the mike ? i don't remember . it 's the mike ? it 's not four . ",,
Bro024.F,"and we 're on . i 'll get it . hey dave ? could you go ahead and turn on , stephane 's   a linux box .  it 's got , like sixteen channels going into it .   far , it 's been pretty good .  why don't you go ahead , dave ? that 's on digits ?   you can also you can also reflect the data . you take ,  i 'm not how many frames you need . but you take that many from the front and flip it around to a as the negative value . you can always do you wanna go , barry ? briefly . you 've got two weeks , are you gonna do any dry runs for your thing , or are you just gonna   is that it ? hhh .  hhh . let 's see . we 've got forty minutes left , and it seems like there 's a lot of material . an any suggestions about where we should go next ?  do you wanna go , sunil ? we 'll just start with you . s since the high mismatch performance is much worse to begin with , it 's easier to get a better relative improvement . but that involves mucking with the back end , which is not allowed .  adam . is , is that about it ? or ? this is for the lda ?  what where was the , the smallest latency of all the systems last time ? what was it ? thirteen ? thirty .  i was just curious about where we are compared to , the shortest that people have done .   we 've got twenty minutes we should probably try to move along . did you wanna go next , stephane ? share with barry . is that it ? we need to combine these two . carmen ? do you ,  what 's do you think we , should do the digits or skip it ? or what are what do you think ?  got them .  would you pass those down ?   guess i 'll go ahead .   if you could just leave , your mike on top of your , digit form fill in any information that 's missing . that 's i didn't get a chance to fill them out ahead of time .  we 're gonna have to fix that . let 's see , it starts with one here , and then goes around and ends with nine here . he 's eight , you 're seven , ","why don't you go ahead , dave ? do you wanna go , barry ? do you wanna go , sunil ? did you wanna go next , stephane ? carmen ? ",
Bro024.G,"do you use a pc for recording ? or   the quality is quite good ? or ?   we spoke about it already ,  what they do is they do it always on line , that you just take what you have from the past , that you calculate the mean of this and subtract the mean . and then you can you can increase your window whi while you get while you are getting more samples . do you have you have files which are hours of hours long ? or ?  usually you have in the training set you have similar conditions , file lengths are , the same order or in the same size as for test data , or aren't they ?    what is important to see is that there is a big difference between the training modes .  if you have clean training , you get also a fifty percent improvement . but if you have muddy condition training you get only twenty percent .     for the clean training . u and if you look   this is next page .  improvement .  it 's a  the w there was a very long discussion about this on the , amsterdam meeting . how to calculate it then . you are using finally this the scheme which they    it i it is known , this medium match condition of the finnish data has some strange effects . that is  that too .   there is a l a there is a lot of there are a lot of utterances with music in the background .  but the but the , forty seven point nine percent which you have now , that 's already a remarkable improvement in comparison to the first proposal .       i started thinking about also discovered the same problem when i started working on on this aurora task almost two years ago , that you have the problem with this mulit a at the beginning we had only this multi condition training of the ti digits . and , i found the same problem . just taking what we were used to u use , some type of spectral subtraction , y you get even worse results than the basis and i tried to find an explanation for it ,    what you do is in when you have the this multi condition training mode , then you have then you can train models for the speech , for the words , as as for the pauses where you really have all information about the noise available . and it was surprising at the beginning it was not surprising to me that you get really the best results on doing it this way , in comparison to any type of training on clean data and any type of processing . but it was u it seems to be the best what wh what we can do in this moment is multi condition training . and every when we now start introducing some noise reduction technique we introduce also somehow artificial distortions . and these artificial distortions i have the feeling that they are the reason why we have the problems in this multi condition training . that means the h m ms we trained , they are based on gaussians , and on modeling gaussians . and if you can i move a little bit with this ?  and if we introduce now this u spectral subtraction , or wiener filtering usually what you have is i 'm showing now an envelope  you 'll f for this time . usually you have in clean condition you have something which looks like this . and if it is noisy it is somewhere here . and then you try to subtract it or wiener filter or whatever . and what you get is you have always these problems , that you have this these zeros in there . and you have to do something if you get these negative values . this is your noise estimate and you somehow subtract it or do whatever . and then you have and then what you do is you introduce some artificial distribution in this  in the models . i you train it also this way but , i somehow there is u there is no longer a gaussian distribution . it is somehow a strange distribution which we introduce with these artificial distortions . and i was thinking that might be the reason why you get these problems in the especially in the multi condition training mode . s  yes .       y i was whe w just yesterday when i was thinking about it what we could try to do , or do about it if you get at this in this situation that you get this negative values and you simply set it to zero or to a constant or whatever if we would use there a somehow , random generator which has a certain distribution , u not a certain a special distribution we should see we have to think about it . and that we , introduce again some natural behavior in this trajectory . similar to what you see really u in the real noisy situation . or i in the clean situation . but somehow a natural distribution .     it 's just especially in these segments , you introduce , very artificial behavior . and  i   we could trit we could think how w what we could try . it was just an idea . we to   it it is l somehow similar to what   but they do not apply filtering of the log energy or what like a spectral subtraction or  i kn and then they calculate from this , the log energy or ?    but is there a problem with the one hundred eighty milliseconds ? or ? i talked to i ta i talked , about it with hynek . there is   it 's it was in the order of thirty milliseconds or thirty .  ","what they do is they do it always on line , that you just take what you have from the past , that you calculate the mean of this and subtract the mean . it seems to be the best what wh what we can do in this moment is multi condition training . and every when we now start introducing some noise reduction technique we introduce also somehow artificial distortions . and these artificial distortions i have the feeling that they are the reason why we have the problems in this multi condition training . that means the h m ms we trained , they are based on gaussians , and if we introduce now this u spectral subtraction , or wiener filtering this is your noise estimate and you somehow subtract it or do whatever . and then what you do is you introduce some artificial distribution in this in the models . but is there a problem with the one hundred eighty milliseconds ? it was in the order of thirty milliseconds ","While on these topics, related areas discussed included recognition window length, training versus test set sizes, artificial distortion and latency concerns. "
Bro024.G,"but this thirty milliseconds they did it did not include the delta calculation . and this is included now ,   i don't remember the i th they were not using the htk delta ? nine point .       no , used this scheme as it was before .  what is the lower curve and the upper curve ?   and this curves are the average over the whole database ,    is the is the training based on these labels files which you take as reference here ? wh when you train the neural net y you   the that was my idea . if it ha if it is not the same labeling which is taking the spaces .      these numbers are simply   s what you do is this . i when you have this , after you subtracted it , then you get something w with this , where you set the values to zero and then you simply add an additive constant again . you shift it somehow . this whole curve is shifted again . e hhh .  but but the way stephane did it , it is exactly the way i have implemented in the phone ,  made s similar investigations like stephane did here , just adding this constant and looking how dependent is it on the value of the constant and then , must choose them somehow to give on average the best results for a certain range of the signal to noise ratios .  but you are not doing it now language dependent ? or ? no . it 's overall .   i  your smoothing was @ @ over this s to say , the factor of the wiener . and then it 's , what was it ? this this smoothing , it was over the subtraction factor , to say . was this done  and you are looking into the future , into the past . and smoothing .  and did you try simply to smooth to smooth the t to smooth stronger the envelope ?  because it should have a similar effect if you you have now several stages of smoothing , to say . you start up . as far as i remember you smooth somehow the envelope , you smooth somehow the noise estimate , and later on you smooth also this subtraction factor .  it w it was you .      it experience shows you , if you do the the best is to do the smoo smoothing as early as possible . when you start up . you start up with the somehow with the noisy envelope . and , best is to smooth this somehow . and    yes , y   right . when w you could do it in this way that you say , if you if i 'm you have somehow a noise estimate , and , if you say i 'm with my envelope i 'm close to this noise estimate , then you have a bad signal to noise ratio and then you would like to have a stronger smoothing . you could base it on your estimation of the signal to noise ratio on your actual s to summarize the performance of these , speechdat car results is similar than yours to say . y you have fifty six point four and dependent on this additive constant , it is s better or worse .   mu my mine was it too , before i started working on this aurora .   you are leaving in about two weeks carmen . no ?  mean , if i would put it put on the head of a project mana manager i would say , mean there is not much time left now . if what i would do is i would pick @ @ the best consolation , which you think , and c create all the results for the whole database that you get to the final number as sunil did it and and also to write somehow a document where you describe your approach , and what you have done .  what is this ?  ","s to summarize the performance of these , speechdat car results is similar than yours to say . you are leaving in about two weeks carmen . what i would do is i would pick @ @ the best consolation , which you think , and c create all the results for the whole database that you get to the final number as sunil did it and also to write somehow a document where you describe your approach , and what you have done . ",
Bro024.H,"give me one . it 's worse . i only say that the this is , a summary of the of all the vts experiments and say that the result in the last for italian the last experiment for italian , are bad . i make a mistake when i write . up at d i copy one of the bad result . and there . this .   if we put everything , we improve a lot u the spectral use of the vts but the final result are not still good like the wiener filter i don't know . it 's @ @ it 's possible to have the same result . i don't know exactly .  because i have , worse result in medium mismatch and high mismatch . and i someti are more or less similar but are worse . and still i don't have the result for ti digits . the program is training . for this weekend i will have result ti digits and complete that s like this .  one thing that i note are not here in this result but are speak are spoken before with sunil i improve my result using clean lda filter . if i use , the lda filter that are training with the noisy speech , that hurts the res my results . this is with the clean . with the noise i have worse result , that if i doesn't use it . but m that may be because with this technique we are using really clean speech . the speech the representation that go to the htk is really clean speech because it 's from the dictionary , the code book and from that . i don't know . because that you did some experiments using the two lda filter , clean and noi and noise , and it doesn't matter too much . it 's better to use clean .  you can do d also this . to use clean speech . with the clean lda . is that the reason ? and and this is everything .  and prepare at the s  i was thinking to do that next week .  i wi i will do that next week .   send yet . this is date and time . no . on the channel , channel . ","i only say that the this is , a summary of the of all the vts experiments and say that the result in the last for italian the last experiment for italian , are bad . if we put everything , we improve a lot u the spectral use of the vts but the final result are not still good like the wiener filter i was thinking to do that next week . i wi i will do that next week . ","The groups regulars reported progress on their work on mean subtraction, noise estimation, voice activity detection and the Vector Taylor Series. "
Bro025.A,"alright . we 're on . what are these ? are you looking at one in particular of these two ? what 's happened ? 've missed something . i didn't .        you guys have combined or you 're going to be combining the software ?  they 're close enough . how is how good is that ? i don't have a sense of  compared to the last evaluation numbers ?    will the neural net operate on the output from either the wiener filtering or the spectral subtraction ? or will it operate on the original ?  but just conceptually , where does the neural net go ? do you wanna h run it on the output of the spectrally subtracted ?  right .   right .   what was the issue with the vad ? and the w the default , boundaries that they provide are they 're but they 're not all that great ? outside the beginnings and end .     on top of the vad that they provide ?  theirs is fourteen ? i see .    how much latency does the , does our vad add ? is it significant , or ? how much , delay was there on the lda ?  i see .  what amount of latency are you thinking about when you say that ?    were you thinking of the two fifty or the one thirty when you said we should have enough for the neural net ?     which could be a funny delta . right ? did that help then ? you have , when you don't quite understand how this works , but , couldn't you just send all of the frames , but mark the ones that are supposed to be dropped ? cuz you have a bunch more bandwidth . right ?  and that way the net could use if the net 's on the server side then it could use all of the frames .  but you could even mark them , before they get to the server .   i see .  i see . i see . i see .  what was that ?  i i don't remember what you said the answer to my , question earlier . will you train the net on after you 've done the spectral subtraction or the wiener filtering ?  you 're talking about the vad net .  i see .   i see . i see . can you use the same net to do both , or ? can you use the same net that you that i was talking about to do the vad ?    cuz that 's used by some of these other ?  i see . that was only used for doing frame dropping later on .   i see . hynek is coming back next week , you said ?  is he in europe right now or is he up at ?           you 're now you 're looking to try to gather a set of these types of features ?     should we do digits ? go ahead , morgan . you can start .  and we 're off . ",you guys have combined or you 're going to be combining the software ? how is how good is that ? compared to the last evaluation numbers ? what was the issue with the vad ? what amount of latency are you thinking about when you say that ? ,"They have developed a piece of software which allows them to implement their two main approaches to dealing with noise. The base rate is currently set at the second best rate as of the last project evaluation, and it does not yet include everything the group have been working on. With this in mind, they have decided to set most things, and concentrate on studying only a few key aspects, the neural network, the voice activity detector, and the noise estimation. "
Bro025.B,"test , test , test . guess that 's me .   there 's two sheets of paper in front of us . this is the arm wrestling ? good . excellent . that 's the best thing . tell me about it . right .       it 's actually , very similar . if you look at databases ,  the , one that has the smallest smaller overall number is actually better on the finnish and spanish , but it is , worse on the , aurora on the , ti digits ,   it probably doesn't matter that much either way . but , when you say u unified do it 's one piece of software now , or ?  week ago you weren't around when hynek and guenther and i ? let 's summarize . and then if i summarize somebody can tell me if i 'm wrong , which will also be possibly helpful . what did press here ? i hope this is still working . we , we looked at , anyway we after coming back from qualcomm we had , very strong feedback and , it was hynek and guenter 's and my opinion also that , we spread out to look at a number of different ways of doing noise suppression . but given the limited time , it was time to choose one . and th the vector taylor series hadn't really worked out that much . the subspace had not been worked with much . it came down to spectral subtraction versus wiener filtering . we had a long discussion about how they were the same and how they were d completely different . and , fundamentally they 're the same thing but the math is a little different that there 's a there 's an exponent difference in the index what 's the ideal filtering , and depending on how you construct the problem . and , it 's sort after that meeting it made more sense to me because if you 're dealing with power spectra then how are you gonna choose your error ? and typically you 'll do choose something like a variance . and that means it 'll be something like the square of the power spectra . whereas when you 're doing the , looking at it the other way , you 're gonna be dealing with signals and you 're gonna end up looking at power noise power that you 're trying to reduce . and there should be a difference of conceptually of , a factor of two in the exponent . but there 're many different little factors that you adjust in terms of , over subtraction and and forth , that arguably , you 're c and the choice of do you operate on the mel bands or do you operate on the fft beforehand . there 're many other choices to make that are almost if not independent , certainly in addition to the choice of whether you , do spectral subtraction or wiener filtering , that , @ @ again we felt the gang should just figure out which it is they wanna do and then let 's pick it , go forward with it . that 's that was last week . and , we said , take a week , go arm wrestle ,  figure it out . and th the joke there was that each of them had specialized in one of them . and they instead they went to yosemite and bonded , and they came out with a single piece of software . it 's another victory for international collaboration .   that 's fine , but the important thing is that there is a piece of software that you that we all will be using now . yes .     but , w which we were before but we were considerably far behind . and this doesn't have neural net in yet  it it 's not using our full bal bag of tricks , if you will . and , and it is , very close in performance to the best thing that was there before . but , looking at it another way , more importantly , we didn't have any explicit noise , handling stationary dealing with e we didn't explicitly have anything to deal with stationary noise . and now we do . argu arguably , what we should do i gather you have it sounds like you have a few more days of nailing things down with the software and on . but and then but , arguably what we should do is , even though the software can do many things , we should for now pick a set of things , th these things i would guess , and not change that . and then focus on everything that 's left . and that our goal should be by next week , when hynek comes back , to really just to have a firm path , for the for the time he 's gone , of , what things will be attacked . but i would i would thought think that what we would wanna do is not futz with this for a while because what 'll happen is we 'll change many other things in the system , and then we 'll probably wanna come back to this and possibly make some other choices . but , depending on its size one question is , is it on the , server side or is it on the terminal side ? if it 's on the server side , it you probably don't have to worry too much about size . that 's an argument for that . we do still , however , have to consider its latency . the issue is , could we have a neural net that only looked at the past ? what we 've done in in the past is to use the neural net , to transform , all of the features that we use . ","let 's summarize . anyway we after coming back from qualcomm we had , very strong feedback and , it was hynek and guenter 's and my opinion also that , we spread out to look at a number of different ways of doing noise suppression . but given the limited time , it was time to choose one . and th the vector taylor series hadn't really worked out that much . the subspace had not been worked with much . it came down to spectral subtraction versus wiener filtering . we had a long discussion about how they were the same and how they were d completely different . that , @ @ again we felt the gang should just figure out which it is they wanna do and then let 's pick it , instead they went to yosemite and bonded , and they came out with a single piece of software . it 's another victory for international collaboration . but the important thing is that there is a piece of software that you that we all will be using now . it it 's not using our full bal bag of tricks , if you will . and , and it is , very close in performance to the best thing that was there before . but , looking at it another way , more importantly , we didn't have any explicit noise , handling we didn't explicitly have anything to deal with stationary noise . i gather you have it sounds like you have a few more days of nailing things down with the software and on . but and then but , arguably what we should do is , even though the software can do many things , we should for now pick a set of things , and not change that . and then focus on everything that 's left . and that our goal should be by next week , when hynek comes back , to really just to have a firm path , for the for the time he 's gone , of , what things will be attacked . we do still , however , have to consider its latency . ","ICSI's Meeting Recorder Group have returned from a meeting with some important decisions to make. They have developed a piece of software which allows them to implement their two main approaches to dealing with noise. The base rate is currently set at the second best rate as of the last project evaluation, and it does not yet include everything the group have been working on. With this in mind, they have decided to set most things, and concentrate on studying only a few key aspects, the neural network, the voice activity detector, and the noise estimation. "
Bro025.B,"this is done early on . this is essentially , guess it 's more or less like a spee a speech enhancement technique here right ? where we 're just creating new if not new speech at least new fft 's that have which could be turned into speech that have some of the noise removed . after that we still do a mess of other things to produce a bunch of features . and then those features are not now currently transformed by the neural net . and then the way that we had it in our proposal two before , we had the neural net transformed features and we had the untransformed features , which you actually did linearly transform with the klt , but to orthogonalize them but they were not , processed through a neural net . and stephane 's idea with that , as i recall , was that you 'd have one part of the feature vector that was very discriminant and another part that wasn't , which would smooth things a bit for those occasions when , the testing set was quite different than what you 'd trained your discriminant features for . all of that is , still seems like a good idea . now we know some other constraints . we can't have unlimited amounts of latency . y that 's still being debated by the by people in europe but , no matter how they end up there , it 's not going to be unlimited amounts , we have to be a little conscious of that .  there 's the neural net issue . there 's the vad issue . and , there 's the second stream thing . and those that we last time we that those are the three things that have to get , focused on . better ones are good . they still allow two hundred milliseconds on either side or some ? is that what the deal is ? with the rank ordering ? i 'm this is for the vad .    was just noticing on this that it makes reference to delay . what 's the ? if you ignore the vad is in parallel , isn't i isn't it , with the ? it isn't additive with the , lda and the wiener filtering , and forth . right ?   and there and there didn't seem to be any , penalty for that ? there didn't seem to be any penalty for making it causal ?  may as then . and he says wiener filter is forty milliseconds delay . is it ? the smoothing ? right .  that 's really not bad . we may we 'll see what they decide . we may have , the , latency time available for to have a neural net . sounds like we probably will .  that 'd be good . cuz i cuz it certainly always helped us before .   they 're they 're disputing it . they 're saying , one group is saying a hundred and thirty milliseconds and another group is saying two hundred and fifty milliseconds . two hundred and fifty is what it was before actually .  some people are lobbying to make it shorter .  and , it just it when we find that out it might change exactly how we do it , is all . how much effort do we put into making it causal ? the neural net will probably do better if it looks at a little bit of the future . but , it will probably work to some extent to look only at the past . and we ha limited machine and human time , and effort . and , how much time should we put into that ? it 'd be helpful if we find out from the standards folks whether , they 're gonna restrict that or not .  but at this point our major concern is making the performance better and , if , something has to take a little longer in latency in order to do it that 's a secondary issue . but if we get told otherwise then , we may have to c clamp down a bit more .    that 's fixed in this . we talked about that . good .  @ @ you were doing a lot of changes . did you happen to notice how much , the change was due to just this frame dropping problem ? what about this ?  but like we 're saying , if there 's four or five things like that then pretty sho soon you 're talking real improvement .   that 's a real good point . it might be hard if it 's at the server side . right ?  you could . it always seemed to us that it would be to in addition to , reducing insertions , actually use up less bandwidth . but nobody seems to have cared about that in this evaluation .  it would be more or less the same thing with the neural net , actually .     what 's , that 's a good set of work that , i was wondering about that . that was i had written that down there .    it 's not surprising it 'd be worse the first time . but , it does seem like , i some compromise between always depending on the first fifteen frames and a always depending on a pause is a good idea . you have to weight the estimate from the first teen fifteen frames more heavily than was done in your first attempt . but but   no ,  do you have any way of assessing how or how poorly the noise estimation is currently doing ?  that 's something you could do with , this final system . right ? just do this everything that is in this final system except , use the channel zero .  and then see how much better it gets . ","we can't have unlimited amounts of latency . y that 's still being debated by the by people in europe but , no matter how they end up there , it 's not going to be unlimited amounts , there 's the neural net issue . there 's the vad issue . and , there 's the second stream thing . they still allow two hundred milliseconds on either side or some ? that 's really not bad . we may we 'll see what they decide . we may have , the , latency time available for to have a neural net . they 're saying , one group is saying a hundred and thirty milliseconds and another group is saying two hundred and fifty milliseconds . did you happen to notice how much , the change was due to just this frame dropping problem ? that 's a real good point . that 's a good set of work that , i was wondering about that . ","With this in mind, they have decided to set most things, and concentrate on studying only a few key aspects, the neural network, the voice activity detector, and the noise estimation. "
Bro025.B,"if it 's , essentially not better , then it 's probably not worth any more . i see . not using these methods anyway . and also there 's just the fact that , although we 're trying to do very on this evaluation , we actually would like to have something that worked in general . and , relying on having fifteen frames at the front is pretty you might not .  it 'd certainly be more robust to different kinds of input if you had at least some updates .  but , i don't know . what do you , what do you guys see as being what you would be doing in the next week , given wha what 's happened ?  this is a different net . you see , the idea is that the , initial decision to that you 're in silence or speech happens pretty quickly . and that and that 's fed forward , and you say "" flush everything , it 's not speech anymore "" . it is used , it 's only used f it 's used for frame dropping . it 's used for end of utterance because , there 's if you have more than five hundred milliseconds of nonspeech then you figure it 's end of utterance like that .    probably the vad and testing out the noise estimation a little bit . keeping the same method but , seeing if you cou but , noise estimation could be improved . those are related issues . it probably makes sense to move from there . and then , later on in the month we wanna start including the neural net at the end .  anything else ? good . you didn't fall . that 's good . our e our effort would have been devastated if you guys had run into problems . that 's the plan . the week after he 'll be , going back to europe , and we wanna no , no . he 's he 's dropped into the us .   the idea was that , we 'd sort out where we were going next with this work before he , left on this next trip . good . barry , you just got through your quals , don't know if you have much to say . but , in conversational speech in particular . you can put them in pretty reliably in synthetic speech . but we don't have too much trouble recognizing synthetic speech since we create it in the first place . it 's short meeting . that 's next week hopefully we 'll can get hynek here to join us and ,  digits , digits . now . alright . let me get my glasses on can see them .   ","good . barry , you just got through your quals , don't know if you have much to say . ",
Bro025.C,"we formed a coalition actually . we already made it into one .  hynek was here .  the piece of software has plenty of options , like you can parse command line arguments . depending on that , it becomes either spectral subtraction or wiener filtering . ye  there 's just one piece of software . right . parameters . best system .   no . our way . like another ten frames . the smoothing the m the filtering of the probabilities . on the r .    the lda ? what happened right now , we removed the delay of the lda . we if if we if which is like if we reduce the delay of va the f the final delay 's now ba is f determined by the delay of the vad , because the lda doesn't have any delay . if we re if we reduce the delay of the vad , it 's like effectively reducing the delay . the lda and the vad both had a hundred millisecond delay . and they were in parallel , which means you pick either one of them the biggest , whatever . right now the lda delays are more . pardon ? no . it actually made it point one percent better actually . like that and that 's the one which stephane was discussing , like the you smooth it and then delay the decision by   the one difference is that was there is like we tried computing the delta and then doing the frame dropping . the earlier system was do the frame dropping and then compute the delta on the this   we have no delta . and then the frame dropping is the last thing that we do . what we do is we compute the silence probability , convert it to that binary flag , and then in the end you c up upsample it to match the final features number of it seems to be helping on the matched condition . that 's why this improvement i got from the last result . and it actually r reduced a little bit on the high mismatch , in the final weightage it 's b better because the matched is still weighted more than y you had something on it . right ?  yes , it could be . it 's you just transferred everything and then finally drop the frames after the neural net . right ? that 's one thing which right now we are ri right now what wha what we did is we just mark we just have this additional bit which goes around the features , saying it 's currently a it 's a speech or a nonspeech . there is no frame dropping till the final features including the deltas are computed . and after the deltas are computed , you just pick up the ones that are marked silence and then drop them . that 's what that 's what , this is doing right now . just one more thing . like , should we do something f more for the noise estimation , because we still ?  is there was there any experiment with ? i did the only experiment where i tried was i used the channel zero vad for the noise estimation and frame dropping . don't have a split , like which one helped more . it was the best result i could get . that 's the  for the noise estimation . we can try something .  but the guenter 's argument is slightly different . it 's ev even if i use a channel zero vad , i 'm just averaging the s power spectrum . but the guenter 's argument is if it is a non stationary segment , then he doesn't update the noise spectrum . he 's , like he tries to capture only the stationary part in it . the averaging is different from updating the noise spectrum only during stationary segments . th the guenter was arguing that , even if you have a very good vad , averaging it over the whole thing is not a good idea . because you 're averaging the stationary and the non stationary , and finally you end up getting something which is not really the s because , you anyway , you can't remove the stationary part fr non stationary part from the signal .  you just update only doing or update only the stationary components . that 's that 's still a slight difference from what guenter is trying   cure the vad ? vad . and just the cepstra .  no . we have a vad which is like neur that 's a neural net .  that vad was trained on the noisy features . right now we have we have the cleaned up features , we can have a better vad by training the net on the cleaned up speech . but we need a vad for noise estimation also . it 's where do we want to put the vad ? it 's like for  it actually comes at v at the very end . the net the final net which is the feature net that actually comes after a chain of lda plus everything . it 's it takes a long time to get a decision out of it . and you can actually do it for final frame dropping , but not for the va f noise estimation .    ","the piece of software has plenty of options , depending on that , it becomes either spectral subtraction or wiener filtering .  we if if we if which is like if we reduce the delay of va the you smooth it and then delay the decision by the frame dropping is the last thing that we do . just one more thing . like , should we do something f more for the noise estimation , ","They have developed a piece of software which allows them to implement their two main approaches to dealing with noise. The base rate is currently set at the second best rate as of the last project evaluation, and it does not yet include everything the group have been working on. With this in mind, they have decided to set most things, and concentrate on studying only a few key aspects, the neural network, the voice activity detector, and the noise estimation. "
Bro025.D,"thursday .  rank .  dar  s  no , just , looking into some of the things that , john ohala and hynek , gave as feedback , as a starting point for the project .  in my proposal , i was thinking about starting from a set of , phonological features , or a subset of them . but that might not be necessarily a good idea according to , john . he said , these phonological features are figments of imagination also . s ye right . a better way would be something more data driven , just looking at the data and seeing what 's similar and what 's not similar . i 'm i 'm , taking a look at some of , sangita 's work on traps . she did something where , where the traps learn she clustered the temporal patterns of , certain phonemes in m averaged over many , many contexts . and , some things tended to cluster . right ? like stop consonants clustered really silence was by its own self . and , v vocalic was clustered . and , those are interesting things to right .  just to see where i could start off from ,  a set of small features and continue to iterate and find , a better set .  ","no , just , looking into some of the things that , john ohala and hynek , gave as feedback , in my proposal , i was thinking about starting from a set of , phonological features , or a subset of them . but that might not be necessarily a good idea according to , john . ",
Bro025.E," almost .   it 's it 's spectral subtraction or wiener filtering ,  depending on if we put if we square the transfer function or not . and then with over estimation of the noise , depending on the , the snr , with smoothing along time ,  smoothing along frequency . it 's very simple , smoothing things . and , the best result is when we apply this procedure on fft bins , with a wiener filter . and there is no noise addition after that . it 's good because it 's difficult when we have to add noise to find the right level . the sh it 's the sheet that gives fifty f three point sixty six . the second sheet is abo about the same . it 's the same , idea but it 's working on mel bands , and it 's a spectral subtraction instead of wiener filter , and there is also a noise addition after , cleaning up the mel bins .  the results are similar .  it 's worse on on the multi condition in ti digits .  now we are , setting up the software . it should be ready , very soon . and we p p boy .  i need to allow it to do everything and even more than this . if we want to optimize different parameters of we can do it later . but , still there will be a piece of software with , will give this system , the fifty three point sixty six , by default and  it 's just one percent off of the best proposal . it 's between i we are second actually if we take this system . right ?      right .  th they keep two hundred milliseconds at the beginning and end of speech . and they keep all the  and all the speech pauses , which is sometimes on the speechdat car you have pauses that are more than one or two seconds . more than one second for   and , it seems to us that this way of just dropping the beginning and end is not we cou we can do better , because , with this way of dropping the frames they improve over the baseline by fourteen percent and sunil already showed that with our current vad we can improve by more than twenty percent . just using either their vad or our current vad . our current vad is more than twenty percent , while their is fourteen .    and another thing that we did also is that we have all this training data for let 's say , for speechdat car . we have channel zero which is clean , channel one which is far field microphone . and if we just take only the , vad probabilities computed on the clean signal and apply them on the far field , test utterances , then results are much better . in some cases it divides the error rate by two . it means that there are stim still if we can have a good vad , it would be great . right now it 's , a neural net with nine frames . it 's forty milliseconds plus , the rank ordering , which , should be ten  right now it 's one hundred and forty milliseconds . the , it 's not a median filtering . it 's just we don't take the median value . we take something we have eleven , frames . and for the vad , and we take th the third .        just the frame dropping problem . but it 's difficult . sometime we change two things together and but it 's around it 's less than one percent . it  and it  and then we have to be careful with that also with the neural net because in the proposal the neural net was also , working on after frame dropping .  we 'll have to be to do the same correction . we can do the frame dropping on the server side or we can just be careful at the terminal side to send a couple of more frames before and after , and it 's     we , actually i did the first experiment . this is with just fifteen frames .  we take the first fifteen frame of each utterance to it , and average their power spectra .  i tried just plugging the , guenter noise estimation on this system , and it it got worse .  but didn't play with it . but i didn't do much more for noise estimation . tried this , and    no , we don't . we don't have nothing that       should we keep the same ? we might try to keep the same idea of having a neural network , but training it on more data and adding better features , but because the current network is just plp features . it 's trained on noisy plp plp features computed on noisy speech . but there is no nothing particularly robust in these features . there 's no rasta , no    and it seems important for the on line normalization . we don't want to update the mean and variance during silen long silence portions . it has to be done before this mean and variance normalization .   the half dome was great . ","but , still there will be a piece of software with , will give this system , the fifty three point sixty six , by default it 's just one percent off of the best proposal . it 's between i we are second actually if we take this system . and all the speech pauses , which is sometimes on the speechdat car you have pauses that are more than one or two seconds . we cou we can do better , our current vad is more than twenty percent , while their is fourteen . just the frame dropping problem . and then we have to be careful with that also with the neural net because in the proposal the neural net was also , working on after frame dropping . ","The base rate is currently set at the second best rate as of the last project evaluation, and it does not yet include everything the group have been working on. With this in mind, they have decided to set most things, and concentrate on studying only a few key aspects, the neural network, the voice activity detector, and the noise estimation. "
Bro026.A," you probably received the mail .  what was the update ? there is th then the all the new features that go in . the , noise suppression , the re synthesis of speech after suppression . these are the  i don't know if they use it , but . i don't know if hari did that or you d actually i tried wh while when i installed the repository , i tried from belgium . i logged in there and i tried to import it works . but it 's right now it 's the mechanism with ssh . i don't s i didn't set up you can also set up a cvs server on a new port . it 's like main server , or d you can do a cvs server . but . right . but i didn't do that because i was not about security problems . i would have to right .   you ha in this way you ca you have to set up a cvs server but then , you can access it . you can set up priorities . you can access them and mostly if you if y the set the server is set up like this .  since the meeting , i 've been train training a new vad and a new feature net . they should be ready .    we 've been working like six weeks on the noise compensation and we end up with something that seems reasonable .  finally it 's , wiener filtering on fft bins . and it uses , two steps , smoothing of the transfer function , the first step , that 's along time , which use recursion . and after this step there is a further smoothing along frequency , which use a sliding window of twenty fft bins .  and ,   it was  it 's on the transfer function .   we tried different configuration within this idea . we tried u applying this on mel bands , having spectral subtraction instead of wiener filtering .  finally we end up with this configuration that works , quite we are going to fix this for the moment and work on the other aspects of the whole system .   we do not fo we do , but we don't re synthesize . in the program we don't re synthesize and then re analyze once again . we just use the clean fft bins . this is an option that then you can   the , the other parts of the system are the blocks that were already present before and that we did not modify a lot . th then the mel filter bank , then the log operation ,   then the lda filter , then the downsampling , dct , then , on line normalization , followed by upsampling . then finally , we compute delta and we put the neural network also .  and finally frame dropping , which would be a neural network also , used for estimated silence probabilities . and the input of this neural network would be somewhere between log mel bands or one of the earlier stages of the processing .   it , ri right now it 's second .  no , we didn't . no ,     we are between their two systems .  i it is a triumph . but everything is within the range of one percent .    not better , not worse . what about norm normalizing also ?  and there is also the idea of using traps , for the vad , which , pratibha showed , when , she was at ibm , that it 's a good idea .  i have no idea . it would have to fit but   i 've a new feature net ready also . no , two network , one vad and one feature net .    but , there are plenty of issues to work on for the feature net @ @ .  no . it 's training on a range between ten and twenty db , and testing between five and fifteen . that 's what i got on  and the noise is there is a range of different noises also which are selected randomly and added randomly , to the files . and there are noises that are different from the noises used on ti digits . i don't know ,  we can for september , we can set up a work schedule and we can work independently . and then at some point it be better to work together again . i  but ,   right . ","there is th then the all the new features that go in . the , noise suppression , the re synthesis of speech after suppression .  i don't know if they use it , actually i tried wh while when i installed the repository , i tried from belgium . i logged in there and i tried to import it works . we 've been working like six weeks on the noise compensation and we end up with something that seems reasonable . finally it 's , wiener filtering on fft bins . we are going to fix this for the moment and work on the other aspects of the whole system . ri right now it 's second . ","Some members of the group met recently with research partners to settle on the current state of their software, and decide on the future work they would investigate, and these decisions were relayed to the rest of the group. "
Bro026.B," we had a meeting with , with hynek , in which , sunil and stephane , summarized where they were and , talked about where we were gonna go . that happened mid week .  what was the update ?  it more likely that what it means is that when sunil is up there he will grab it . they 're they 're working on a different task . but what 'll happen is he 'll go back up there and , pratibha will come back from , the east coast .  and , and actually , after eurospeech for a little bit , he 'll go up there too . actually everybody who 's working on it will be up there for at least a little while . they 'll remotely access it from there .  good idea .   for this don't think we 're quite up to that . we 're still much in development . we want to have just the insiders .    the thing to me might be i me i 'm you 've just been working on , details of that since the meeting , right ? and that was tuesday .  but the thing since you weren't yo you guys weren't at that meeting , might be just to , recap , the conclusions of the meeting .   cuz that was we 'd been working up to that , he would come here this week and we would since he 's going out of town like now , and i 'm going out town in a couple weeks , and time is marching , given all the mu many wonderful things we could be working on , what will we actually focus on ? and , and what do we freeze ? and , what do we ?  this software that these guys created was certainly a key part . then there 's something central and there aren't at least a bunch of different versions going off in ways that differ trivially . and , and then within that , the idea was to freeze a certain set of options for now , to run it , a particular way , and decide on what things are gonna be experimented with , as opposed to just experimenting with everything . keep a certain set of things constant .  describe roughly what we are keeping constant for now , or ? this smoothing is done on the estimate , of what you 're going to subtract ? or on the thing that has already had something subtracted ? it 's on the transfer function for the wiener filter .  actually , let me int dave isn't here to talk about it , but let me just interject . this module , in principle , you would know whether it 's true is somewhat independent from the rest of it . because you re synthesize speech , right ?  you don't you don't re synthesize speech , but you could but you could . but you have a re synthesized thing that you that 's an option here . i gu my point is that , i in some of the work he 's doing in reverberation , one of the things that we 're finding is that , it 's for the for an artificial situation , we can just deal with the reverberation and his techniques work really but for the real situation problem is , is that you don't just have reverberation , you have reverberation in noise . and if you don't include that in the model , it doesn't work very it might be a very thing to do , to just take the noise removal part of it and put that in front of what he 's looking at . and , generate new files or whatever , and , and then do the reverberation part . it 's anyway . no , no . he 's e prelims , right .   but , that 'll it 's clear that we , we are not with the real case that we 're looking at , we can't just look at reverberation in isolation because the interaction between that and noise is considerable . and that 's in the past we 've looked at , and this is hard enough , the interaction between channel effects and , and additive noise , convolutional effects and additive effects . and that 's hard enough . i don't think we really we 're trying to deal with that . in a sense that 's what we 're trying to deal with in this aurora task . and we have , the , lda that in principle is doing something about convolutional effects . and we have the noise suppression that 's doing something about noise . even that 's hard enough . and the on line normalization as in that s category . i there 's all these interactions between these two and that 's part of why these guys had to work hard on juggling everything around . but now when you throw in the reverberation , it 's even worse , because not only do you have these effects , but you also have some long time effects . and , dave has something which , is doing some things under some conditions with long time effects but when it 's when there 's noise there too , it 's it 's pretty hard . we have to start since any almost any real situation is gonna have where you have the microphone distant , is going to have both things , we actually have to think about both at the same time .  there 's this noise suppression thing , which is worked out and then , you should just continue telling what else is in the form we have . that 's again , that 's the wiener filtering , followed by , that 's done at the fft level . then   the filtering is done in the frequency domain ?   ","we had a meeting with , with hynek , in which , sunil and stephane , summarized where they were and , talked about where we were gonna go . that happened mid week . what was the update ? they 're working on a different task . but the thing since you weren't yo you guys weren't at that meeting , might be just to , recap , the conclusions of the meeting . since he 's going out of town like now , and i 'm going out town in a couple weeks , and time is marching , given all the mu many wonderful things we could be working on , what will we actually focus on ? and , and what do we freeze ? and , what do we ? and then within that , the idea was to freeze a certain set of options for now , to run it , a particular way , and decide on what things are gonna be experimented with , as opposed to just experimenting with everything . keep a certain set of things constant . describe roughly what we are keeping constant for now , ","Some members of the group met recently with research partners to settle on the current state of their software, and decide on the future work they would investigate, and these decisions were relayed to the rest of the group. "
Bro026.B,"and then the mel and then the log , and then the lda filter . and then downsample , dct , on line norm , right , and then in parallel with an a neural net . and then following neural net , some probably some orthogonalization .    that 's most of this is is operating parallel with this other  the things that we , we there 's some , neat ideas for v a in there 's like there 's a bunch of tuning things to improve there 's questions about various places where there 's an exponent , if it 's the right exponent , or ways that we 're estimating noise , that we can improve estimating noise . and there 's gonna be a host of those . but structurally it seemed like the things the main things that we brought up that , are gonna need to get worked on are , a significantly better vad , putting the neural net on , which , we haven't been doing anything with , the , neural net at the end there , and , the , opening up the second front .  cuz we have , half the , data rate that they allow . and , the initial thing which came from , the meeting that we had down south was , that , we 'll initially just put in a mel spectrum as the second one . it 's , cheap , easy .  there 's a question about exactly how we do it . we probably will go to something better later , but the initial thing is that cepstra and spectra behave differently ,  tony robinson used to do i was saying this before . he used to do mel , spectra and mel cepstra . he used them as alternate features . put them together .  although you haven't tested it actually on the german and danish , have you ?   would it but when you 're saying second , you 're comparing to the numbers that the , that the best system before got on , also without german and danish ?  ranking didn't before , but i 'm just asking where this is to where theirs was without the german and danish , right ?  we were also esp essentially second , although there were we had a couple systems and they had a couple systems . and by that we were third , but there were two systems that were pretty close , that came from the same place . institutionally we were second , with , the third system . see no it 's also institutional , isn't it ? right ? both of their systems probably are we ? is it ? they 're all pretty close . and , in some sense we 're all doing fairly similar things . one could argue about the lda and forth but in a lot of ways we 're doing very similar things . but what why are we using half ? you could you c think you guys are closer to it than me , correct me if i 'm wrong , but that what 's going on is that in both cases , some normalization is done to deal with convola convolutional effects . they have some cepstral modification , right ? in our case we have a couple things . we have the on line normalization and then we have the lda rasta . and they seem to comple complement each other enough and be different enough that they both seem to help us . but in any event , they 're both doing the same thing . but there 's one difference . the lda rasta , throws away high modulation frequencies . and they 're not doing that . that if you throw away high modulation frequencies , then you can downsample .   it doesn't affect it , does it ?  think since we 're not evidently throwing away useful information , let 's try to put in some useful information . and , we 've found in a lot of ways for quite a while that having a second stream helps a lot . that 's put in , and it may even end up with mel spectrum even though i 'm saying we could do much better , just because it 's simple .  and in the long run having something everybody will look at and say , "" i understand "" , is very helpful . that 's a question . we were talking about that . it looks like it 'd be straightforward to , remove the noise , and ,  to do it after the mel conversion after the noise removal , after the mel conversion . there 's even a question in my mind anyhow of whether th you should take the log or not .  i think you should , but i don't know . right .  but normalizing spectra instead of cepstra ? probably . some kind would be good .  i would think . if you do or don't normalize ? right . yes , mean , one would think that you would want to normalize . but i w my thought is , particularly if you take the log , try it . and then if normalization helps , then y you have something to compare against , and say , "" this much effect "" you don't want to change six things and then see what happens . you want to change them one at a time . adding this other stream in , that 's simple in some way . and then saying , particularly because we 've found in the past there 's all these different results you get with slight modifications of how you do normalization . normalization 's a very tricky , sensitive thing and you learn a lot . ","but structurally it seemed like the things the main things that we brought up that , are gonna need to get worked on are , a significantly better vad , putting the neural net on , which , we haven't been doing anything with , the , neural net at the end there , and , the , opening up the second front . cuz we have , half the , data rate that they allow . and , the initial thing which came from , the meeting that we had down south was , that , we 'll initially just put in a mel spectrum as the second one . it 's , cheap , easy . there 's a question about exactly how we do it . we probably will go to something better later , and , in some sense we 're all doing fairly similar things . why are we using half ? we have the on line normalization and then we have the lda rasta . the lda rasta , throws away high modulation frequencies . and they 're not doing that . that if you throw away high modulation frequencies , then you can downsample . and , we 've found in a lot of ways for quite a while that having a second stream helps a lot . that 's put in , and it may even end up with mel spectrum even though i 'm saying we could do much better , just because it 's simple . ","Of the three areas for the future, they touched mostly upon the use of a second, parallel, data stream. Some members of the group met recently with research partners to settle on the current state of their software, and decide on the future work they would investigate, and these decisions were relayed to the rest of the group. "
Bro026.B,"i would think you would wanna have some baseline that says , "" we don't normalize , this is what we get "" , when we do this normalization , when we do that normalization . but the other question is think ultimately we 'll wind up doing some normalization . i agree . no , it 's in parallel . we 're not talking about computation time here . we 're ta we 're pretty far out . it 's just in terms of what data it 's depending on . it 's depending on the same data as the other . it 's in parallel .   there 's the delays and the storage ,  but i don't think the storage is big for that . th the biggest we 've run into for storage is the neural net . right ?   and guess the issue there is , are we using neural net based traps , and how big are they ? that 'll be , an issue . they can be little ones . mini traps . right . and for vad they would be   that 's true . or a simple neural net , right ? if you 're doing correlation , you 're just doing a simple dot product , with some weights which you happened to learn from this learn from the data . and putting a nonlinearity on it is , not that big a deal . it certainly doesn't take much space . the question is , how complex a function do you need ? do you need to have an added layer in which case , potentially , it could be big .   what 's next ? remind us . what to freeze and then what to do after we froze .  and like i was saying , the the basic directions are , mean , there 's lots of little things , such as improve the noise estimator but the bigger things are adding on the neural net and , the second stream . and then , improving the vad .   right . right .  have you ever ? very good question . have you ever worked with the mississippi state h software ?  you may be called upon to help , on account of , all the work in this here has been , with small vocabulary . do we already have it ? you could , point it at chuck , because , cuz one of the things that might be helpful , if you 've got time in all of this is , is if these guys are really focusing on improving , all the digit and you got the front end from them , you could do the runs for the and , iron out hassles that you have to , tweak joe about or whatever , because you 're more experienced with running the large vocabulary s th certainly the thing that i would want to know about is whether we get really hurt , on in insertion penalty , language model , scaling , sorts of things .   in which case , h hari or hynek will need to , push the case more about this .  yes . in this case , that 's right . that 's right . some of that may be , a last minute rush thing because if the if our features are changing  but , the other thing is that even though it 's months away , it 's starting to seem to me now like november fifteenth is right around the corner . and , if they haven't decided things like this , like what the parameters are gonna be for this , when "" deciding "" is not just somebody deciding . there should be some understanding behind the , deciding , which means some experiments and forth . it seems pretty tight to me . that 's when the evaluation is .   after but , they may even decide in the end to push it off . it wouldn't , entirely surprise me . but , due to other reasons , like some people are going away , i 'm hoping it 's not pushed off for a l a long while . that would be , put us in an awkward position . but anyway . great . that 'll be helpful . there 's not anybody ogi currently who 's , working with this and it 's , it depends how badly you do . that it is  it 's conceptually , it my impression , again , you guys correct me if i 'm wrong , but my impression is that , they want it as a double check . that you haven't come across you haven't invented features which are actually gonna do badly for a significantly different task , particularly one with larger vocabulary . and , but it 's not the main emphasis . the truth is , most of the applications they 're looking at are pretty small vocabulary . it 's a double check . they 'll probably assign it some low weight .  but , we 'll we 'll see what they come up with . but in the current thing , where you have this matched , moderately matched , and mis highly mismatched , the emphasis is somewhat on the matched , but it 's only a marginal , right ? it 's like forty , thirty five , twenty five , like that . you still if you were way , way off on the highly mismatched , it would have a big effect . and , it wouldn't surprise me if they did something like that with this . again , if you 're if you get if it doesn't help you much , for noisy versions of this of large vocabulary data , then , it may not hurt you that much . ","no , it 's in parallel . we 're not talking about computation time here . it 's just in terms of what data it 's depending on . it 's depending on the same data as the other . have you ever worked with the mississippi state h software ? you may be called upon to help , on account of , all the work in this here has been , with small vocabulary . cuz one of the things that might be helpful , if you 've got time in all of this is , is if these guys are really focusing on improving , all the digit and you got the front end from them , you could do the runs for the and , iron out hassles that you have to , tweak joe about or whatever , because you 're more experienced with running the large vocabulary th certainly the thing that i would want to know about is whether we get really hurt , on in insertion penalty , language model , scaling , sorts of things . in which case , h hari or hynek will need to , push the case more about this . ","Of the three areas for the future, they touched mostly upon the use of a second, parallel, data stream. The group also discussed a new part to the evaluation, the use of a chunk of the Wall Street Journal. "
Bro026.B,"but if it if you don't if it doesn't help you much or to put it another way , if it helps some people a lot more than it helps other people , if their strategies do , then that 's it .   we have the data , just not the recognizer .  there 's training and test , right ? no , if it 's like the other things , there 's data for training the h m ms and data for testing it . wouldn't it 's training the recognizer , but ,  but it 's trained on clean and is it trained on clean and test on ?   i see .  i wouldn't imagine that the amount of testing data was that huge . they probably put training almost certain they put training data there too . not .  that 's that . anybody have anything else ? that 's pretty soon . their they have a lot of options in their recognizer and the svm is one of the things they 've done with it , but it 's not their more standard thing . for the most part it 's gaussian mixtures .   the svm thing was an also . it was just a it was like a hybrid , like what ?    if you look into it a little bit , it might be reasonable joe , right ?  just to ask him about the issue of , different features having different kinds of , scaling characteristics and on . that , w possibly having entirely different optimal values for the usual twiddle factors and what 's the plan about that ?  is that and just , se see . do you have hari 's , just cc hari and say that you 've just been asked to handle the large vocabulary part here , and ,  why don't you just ask joe but cc hari , and then in the note say , "" hari , hopefully this is with you "" . and then if joe feels like he needs a confirmation , hari can answer it . that way you can get started asking joe quickly while he 's still , putting in nails and screws and  have you thought about how long would be most useful for you to go up to ogi ? you 're imagining more that you would come back here first for a while and then go up there ? it 's to you . i ju you guys are y anyway , you don't have to decide this second but thi think about it about what you would think would be the best way to work it . i 'll support it either way ,   got anything to tell us ?  are you looking at these in narrow bands ? cuz that 's what you 're gonna be using , right ? it seems somehow that needs th there 's a couple things that i wonder about with this . one is , again , looking at the same representation , if you 're going for this thing where you have little detectors that are looking at narrow bands , then what you 're going to be looking for should be some category that you can find with the narrow bands . that seems to be fundamental to it . and then the other thing , is that i wonder about with it , and don't take this in the wrong way , like i 'm doing or anything , but , just wondering really . the standard answer about this thing is that if you 're trying to find the right system in some sense , whether you 're trying by categories or parameters and your goal is discrimination , then having choices based on discrimination as opposed to , unsupervised nearness of things , is actually better . and i don't know if that since you 're dealing with issues of robustness , this isn't right , but it 'd be something i 'd be concerned about . because , you can imagine , i if you remember from , from your quals , john ohala saying that , "" buh "" and "" puh "" differed , not really cuz of voicing but because of aspiration . in as far as wha what 's really there in the acoustics . if you looked if you were doing some coarse clustering , you probably would put those two sounds together . and yet , i would gue i would guess that many of your recognition errors were coming from , pfft , screwing up on this distinction . it 's a little hard because recognizers , to first order , work . and the reasons we 're doing the things we 're doing is because they don't work as as we 'd like . and since they work , it means that they are already doing if you go and take any recognizer that 's already out there and you say , "" how is it distinguishing between schwas and stops ? "" boy , i bet they 're all doing nearly perfectly on this , right ? these big categories that differ in huge obvious ways , we already know how to do . what are we bringing to the party ? what we wanna do is have something that , particularly in the presence of noise , is better at distinguishing between , categories that are actually close to one another , and hence , would probably be clustered together . that 's th that 's the hard thing . i understand that there 's this other constraint that you 're considering , is that you wanna have categories that , that would be straightforward for , say , a human being to mark if you had manual annotation . and it 's something that you really think you can pick up . ","joe , just to ask him about the issue of , different features having different kinds of , scaling characteristics and on . and just , se see . just cc hari and say that you 've just been asked to handle the large vocabulary part here , why don't you just ask joe but cc hari , and then in the note say , "" hari , hopefully this is with you "" . and then if joe feels like he needs a confirmation , hari can answer it . got anything to tell us ? are you looking at these in narrow bands ? it seems somehow that needs th there 's a couple things that i wonder about with this . if you 're going for this thing where you have little detectors that are looking at narrow bands , then what you 're going to be looking for should be some category that you can find with the narrow bands . the standard answer about this thing is that if you 're trying to find the right system in some sense , whether you 're trying by categories or parameters and your goal is discrimination , then having choices based on discrimination as opposed to , unsupervised nearness of things , is actually better . and i don't know if that since you 're dealing with issues of robustness , this isn't right , but it 'd be something i 'd be concerned about . because , you can imagine , i if you remember from , from your quals , john ohala saying that , "" buh "" and "" puh "" differed , not really cuz of voicing but because of aspiration . if you looked if you were doing some coarse clustering , you probably would put those two sounds together . and yet , i would gue i would guess that many of your recognition errors were coming from , pfft , screwing up on this distinction . if you go and take any recognizer that 's already out there and you say , "" how is it distinguishing between schwas and stops ? "" boy , i bet they 're all doing nearly perfectly on this , ","Speaker me006 is working on data clustering, and discussion of related issues led to more general acoustic matters. "
Bro026.B,"but it 's also essential that you wanna look at what are the confusions that you 're making and how can you come up with , categories that , can clarify these confusions . the standard way of doing that is take a look at the algorithms you 're looking at , but then throw in some discriminative aspect to it . y this is more like , how does lda differ from pca ? they 're the same thing . they 're both orthogonalizing . but , and , this is a little harder because you 're not just trying to find parameters . you 're actually trying to find the categories themselves . little more like brain surgery , on yourself .    anyway . that 's my thought . you 've been thinking about this problem for a long time actually . actually , you stopped thinking about it for a long time , but you used to think about it a lot . and you 've been thinking about it more now , these categories .   right . here 's a here 's a , here 's a generic and possibly useless thought , which is , what do you really in a sense the only s systems that make sense , are ones that have something from top down in th in them . right ? because if e even the smallest organism that 's trying to learn to do anything , if it doesn't have any reward for doing or penal penalty for doing anything , then it 's just going to behave randomly . whether you 're talking about something being learned through evolution or being learned through experience , it 's gotta have something come down to it that gives its reward or , at least some reinforcement learning , right ? and right , but i me that in some ways part of the difficulty is trying to deal with the with these phonemes . and i it 's almost like you want categories if our , metric of goodness , i if our correction if our metric of badness is word error rate then , we should be looking at words . for very reasons we 've looked for a while at syllables , and they have a lot of good properties , but i if you go all the way to words , that 's really d w in many applications you wanna go further . you wanna go to concepts or have concepts , actions , this thing . but , words aren't bad , and  but we 're not trying for models of words here . see , her here 's where if the issue is that we 're trying to come up with , some intermediate categories which will then be useful for later then it doesn't matter that we can't have enough what you wanna do is build up these categories that are best for word recognition . and somehow if that 's built into the loop of what the categories we do this every day in this very gross way of running o a thousand experiments because we have fast computers and picking the thing that has the best word error rate . in some way we derive that all the time . in some ways it 's really not a bad thing to do because it tells you how your adjustments at the very low level affect the final goal . there 's a way to even put that in a much more automatic way , where you take , something about the error at the level of the word or some other it could be syllable but in some large unit , and you may not have word models , you have phone models , whatever , but you don't worry about that , and just somehow feed it back through . that 's , wh what i called a useless comments because i 'm not really telling you how to do it . but it 's a it 's , it right .   now , that being said , that if you have something that is , once you start dealing with spontaneous speech , all the things you 're saying are really true . if you have read speech that 's been manually annotated , like timit , then , i you the phones are gonna be right , actually , for the most part . it doesn't really hurt them to do that , to put in discrimination at that level . if you go to spontaneous speech then it 's trickier and and , the phones are it 's gonna be based on bad pronunciation models that you have of and , and it won't allow for the overlapping phenomenon  the other thing i is to think of a little bit we when y when you start looking at these results it usually is pretty intuitive , but start looking at what are the kinds of confusions that you do make , between words if you want or , even phones in read speech , say , when there is noise . is it more across place or more across manner ? or is it cor is it ? i know one thing that happens is that you , you lose the , low energy phones . if there 's added noise then low energy phones sometimes don't get heard . and if that is if it if that turns it into another word or different or another pair of words then it 's more likely to happen . but , i don't know , i w i would guess that you 'd w i don't know . anyway , that 's  that that 's really big . but even if you do diagnostic rhyme test things , where there really isn't an any information like that , people are still better in noise than they are in , than the machines are . that 's i ",,
Bro026.B,"right . we can't get it without any language models . language models are there and important but ,  if we 're not working on that then we should work on something else and improve it , but especially if it looks like the potential is there .  should we do some digits ? since we 're here ?  that 's all folks . ",,
Bro026.C,"pre prelim hell . get down . para with this , new stream would you train up a vad on both features , somehow ?  that 's  would that fit on the handset , or ?    right . right . cuz sh right . cuz she also does the , the correlation based , traps , with without the neural net , just looking at the correlation between    right .  feature net . is this their , svm recognizer ?     gaussian mixture    i 've been reading some literature about clustering of data . just , let me put it in context . we 're talking about discovering intermediate categories to , to classify . and , i was looking at some of the work that , sangita was doing on these traps things . she has , she has temporal patterns for , a certain set of phonemes , from timit , right ? the most common phonemes . and each one of them has a pattern over time , a one second window . and it has these patterns . she has , trap for each one of the phonemes , times fifteen , for each of the fifteen critical bands . and , she does this agglomerative hierarchical clustering which is a clustering algorithm that , starts with many , many different points many different clusters corresponding to the number of data , patterns that you have in the data . and then you have this distance mej metric which , measures how closely related they are . and you start , by merging the patterns that are most closely related . and y a dendrogram tree .  right , usually it 's when , when the sol similarity measures , don't go down as much . and you stop at that point . and what she found was , sh was there were five broad , broad categories , corresponding to , things like , fricatives and , vocalic , and , stops . and , one for silence and another one for schwa sounds . and , i was thinking about ways to generalize this because w you 're it 's like a it 's not a completely automatic way of clustering , because yo beforehand you have these traps and you 're saying that these frames correspond to this particular phoneme . and that 's constraining your clustering to the set of phonemes that you already have . whereas we want to just take a look at , arbitrary windows in time , of varying length , and cluster those . and i 'm thinking if we do that , then we would probably , at some point in the clustering algorithm find that we 've clustered things like , thi this is a transition , this is a relatively stable point . and i 'm hoping to find other things of similarity and use these things as the intermediate , intermediate categories that , i 'll later classify . right . f i 'm   i haven't exactly figured out , the exact details for that but , the representation of the data that i was thinking of , was using , critical band , energies , over different lengths of time .     right .          right .     we 're doing some prediction of what  ","i 've been reading some literature about clustering of data . we 're talking about discovering intermediate categories to , to classify . and , i was looking at some of the work that , sangita was doing on these traps things . she has , she has temporal patterns for , a certain set of phonemes , from timit , and , i was thinking about ways to generalize this because w you 're it 's like a it 's not a completely automatic way of clustering , ","Speaker me006 is working on data clustering, and discussion of related issues led to more general acoustic matters. "
Bro026.D,"  it 's it 's it was updated yesterday , right ?  i don't don't think i don't think anybody up there is like working on it right now .   right now nobody 's working on aurora there .  actually do it today . just log into no , i didn't . 'll try it today .    second . and th the ranking actually didn't change after the german and danish .      their first system is fifty four point something . and , we are fifty three point something . and their second system is also fifty three point something . one percent .  it it actually makes it dependent on the overall energy of the the frame . if yo if you don't normalize and if you don't normalize .  no , the vad has its own set of features . which could be this one of these streams , or it can be something derived from these streams . that 's also it has t the th if it has to fit the delays and all this    i 'll , 'll actually after the meeting i 'll add the second stream to the vad and 'll start with the feature net in that case . it 's like , you 're looking at the vad , right ? i 'll for the vad ? you already have it ? just figure how to take the features from the final     th it 's almost ready .  that 's what they have released their , document , describing the system .  it no , it 's just downloadable from their web site . 'll point you to the web site and the mails corresponding .  they are still , tuning something on that . they 're like , d they 're varying different parameters like the insertion penalty and other and then seeing what 's the performance . w there is , time during which people are gonna make suggestions . after that .  these sugges these this , period during which people are gonna make suggestions is to know whether it is actually biased towards any set of features or b  the wall street ?   it 's , it 's like a medium mismatch condition , one some preliminary version is already there . it 's already there .  but they 're actually parallel y doing some modifications also , guess the f final system will be frozen by middle of one more week that 's just one more . no , it 's just a straightforward it 's just a gaussian mixture model . this is a g this i  guess something like that . it 's like as painless as possible , is what do they provide all the scripts , everything , and then just , ju i th sh shall we add chuck also to the mailing lists ? it may be better , in that case if he 's going to because there 's a mailing list for this . hari or hynek , one of them , has to send a mail to joe . or if you to add or wh that 's just fine .    and there is an , archive of all the mails that has been gon that has gone , between these people among these people . just you can see all this mails in the isip web site mississippi web site . it 's password protected . it 's , like  ","it 's it 's it was updated yesterday , i don't think anybody up there is like working on it right now . right now nobody 's working on aurora there . i 'll , 'll actually after the meeting i 'll add the second stream to the vad and 'll start with the feature net in that case . just figure how to take the features from the final th it 's almost ready . they have released their , document , describing the system . 'll point you to the web site and the mails corresponding . these sugges these this , period during which people are gonna make suggestions is to know whether it is actually biased towards any set of features or sh shall we add chuck also to the mailing lists ? hari or hynek , one of them , has to send a mail to joe . ","The group also discussed a new part to the evaluation, the use of a chunk of the Wall Street Journal. "
Bro026.E," d did you guys get your code pushed together ?  right , i saw the note .  is the , the cvs mechanism working are people , up at ogi grabbing code via that ? or ?    i see . i see .   has anybody tried remotely accessing the cvs using , ssh ? have you tried it yet ?   it worked good ? good ! great !  right . then that 's using the cvs password mechanism and all that , right ? when you came in from belgian belgium , using ssh , was it asking you for your own password into icsi ? if yo you can only do that if you have an account at icsi ?  cuz there is an a way to set up anonymous cvs right ? that  the anonymous mechanism  because a lot of the open source works with anonymous cvs and i 'm just wondering for our transcripts we may want to do that .     i wasn't suggesting for this . i 'm thinking of the meeting recorder but .    what 's new ? great . you 're talking about the meeting with hynek ?    that 's are you gonna use which of the two techniques ? this is on the before any mel scaling has been done ? this is  dave hasn't tried that yet ? he 's busy with    the other half of the channel ? that what   if you took the system the way it is now , the way it 's fro you 're gonna freeze it , and it ran it on the last evaluation , where it would it be ? in terms of ranking ?  on the ones that you did test it on it would have been second ? where were we actually on the last test ?  i see .  we 're this second that you 're saying now is system wide second ? still institutionally second ?  that 's very close .  how did they fill up this all these bits ? if we 're u  or how are they using more than half , is what i th i see . i see . what if you didn't do you explicitly downsample then ? do we explicitly downsample ? and what if we didn't do that ? would we get worse performance ? i see .     you would you 're thinking to put the , mel spectrum in before any of the noise removal or after ? cuz that happens before the mel conversion , right ? this second stream , will it add latency to the system or ? s  same data .  the meeting with hynek that you guys just had was to decide exactly what you were gonna freeze in this system ? is that ? or was there ? were you talking about what t new or ?  what about the , the new part of the evaluation , the , wall street journal part ? no . not yet .   what how is the , interaction supposed to happen ? i remember the last time we talked about this , it was up in the air whether they were going to be taking , people 's features and then running them or they were gonna give the system out or they 're gonna just deliver a system  i see . we 'll have to grab this over cvs is that how they do it ?      and it but it 's not ready yet , the system ? are those going to be parameters that are frozen , nobody can change ? or ? but everybody 's gonna have to use the same values .  interesting .  using our features .   and we may be able to revisit this idea about , somehow modifying our features to work with   wha what 's the significance of november fifteenth ?   is this part of the evaluation just a small part , or ho how important is this to the overall ? this is one of those things that will be debated afterwards ?   seems to me that if it 's a double check , they should give you a one or a zero . y you passed the threshold or you didn't pass the threshold , and they shouldn't even care about what the score is .     is this , guenter was putting a bunch of wall street journal data on our disks . that 's the data that we 'll be running on ? i see .  this test may take quite a while to run , then . may judging by the amount of data that he was putting on . i 'm not   there 's one last question on that . when did they estimate that they would have that system available for download ? there 's w something you can download to just learn ?  good .  just that i understand , they 're providing scripts and everything that you push a button and it does training , and then it does test , and everything ? is that the idea ?  i see .  somehow yo there 's hooks to put your features in and     that 'd be great . i could send him an email . i know him really i was just talking with him on email the other day actually . about other things , but . i have hari 's  would it be better if i asked hari to ask joe ?     is that a password controlled ?  and you create a tree .  and then you can pick , values anywhere along that tree to fix your set of clusters .        i don't it 's not clear to me how to reconcile , what you 're saying , which is right , with the way i 've been looking at it . that it 's it 's all not very clear to me . but it seems to me that the desire the desirable feature to have is something that , is bottom up . however we do that . ","d did you guys get your code pushed together ? is the , the cvs mechanism working are people , up at ogi grabbing code via that ? has anybody tried remotely accessing the cvs using , ssh ? it worked good ? you 're talking about the meeting with hynek ? are you gonna use which of the two techniques ? the other half of the channel ? if you took the system the way it is now , the way it 's fro you 're gonna freeze it , and it ran it on the last evaluation , where it would it be ? in terms of ranking ? how did they fill up this all these bits ? this second stream , will it add latency to the system what about the , the new part of the evaluation , the , wall street journal part ? not yet .  they 're gonna just deliver a system  using our features . and we may be able to revisit this idea about , somehow modifying our features to work with that 'd be great . i could send him an email . i was just talking with him on email the other day actually . ","Some members of the group met recently with research partners to settle on the current state of their software, and decide on the future work they would investigate, and these decisions were relayed to the rest of the group. Of the three areas for the future, they touched mostly upon the use of a second, parallel, data stream. The group also discussed a new part to the evaluation, the use of a chunk of the Wall Street Journal. "
Bro026.E,"and guess what i don't understand is how to do that and still be discriminative , because to be discriminative you have to have categories and the only categories that we know of to use are these human sig significant categories that are significant to humans , like phonemes , things like that . but that 's what you want to avoid . and that feels i don't know how to get out of this .  right . the question is , how far down ? we could stop at words , but we don't , right ? we go all the way down to phonemes .    but words would be a the common right , the common wisdom is you can't do words because there 's too many of them , right ? you have to have some smaller set that you can use , and everybody goes to phonemes . but the problem is that we build models of words in terms of phonemes and these models are really cartoon ish , right ? when you look at conversational speech , you don't see the phonemes that you have in your word models .   right . right . right .    right .   no , but the important part in there is that , if you want to be discriminative , you have to have categories . and this the important categories are the words , and not the phones .  and right . if you can put the words in to the loop somehow for determining goodness of your sets of clusters      it 's almost like there 's this mechanism that we have that , when we 're hearing read speech and all the phonemes are there we deal with that , but when we go to conversational , and then all of a sudden not all the phonemes are there , it doesn't really matter that much to us as humans because we have some mechanism that allows for these word models , whatever those models are , to be munged , and it doesn't really hurt , and i 'm not how to build that in .  part of the difficulty is that a l a lot of the robustness that we have is probably coming from a much higher level . we understand the context of the situation when we 're having a conversation . and if there 's noise in there , our brain fills in and imagines what should be there . exactly .   go ahead , morgan .  ",,
Bro027.A," we 're going . this is for asru . from the actual , recordings ? it 's nine db ?  that 's on th that 's on the f the far field ones though , right ?  wha what is , what 's causing that ?      i see .  when are his prelims ?   i  i guessed that they were gonna do it some time during the semester but they 'll do it any time , is it already ? yikes .  i , started working on the mississippi state recognizer . i got in touch with joe and , from your email and things like that . and , they added me to the list the mailing list . and he gave me all of the pointers and everything that i needed . and downloaded the , there were two things , that they had to download . one was the , the software . and another wad was a , like a sample run . downloaded the software and compiled all of that . and it compiled fine . no problems . and , i grabbed the sample but i haven't , compiled it . no i haven't grabbed that one yet . there 's two . there was another short one ,  and haven't grabbed the latest one that he just , put out yet .  but , the software seemed to compile fine and everything ,  and ,  no , i d you asked me to write to him and forgot to ask him about that . or if i did ask him , he didn't reply . i don't remember yet . i 'll d i 'll double check that and ask him again .   'll send it to the list .   i haven't seen that one yet .   and they 've picked the values .      do you think that 's something i should just send to him or do you should send it to this there 's an a m a mailing list .     right .        i that was a particular version .  susi or whatever it was but we don't have that .  should be it compiled fine actually . no errors . nothing .   who 's the second jeff ? no .    that would be neat .  is that nine frames u s centered around the current frame ? or i 'm s what is different between this and what you    what if you used a smaller window for the delta ? could that help a little bit ? there 's a lot of things you could do to is two hundred the d i a hun  wh what 's the baseline you need to be under ? two hundred ?  how do that what you have is too much if they 're still deciding ?   i see .  but still , that 's a pretty big , win . and it doesn't seem like you 're in terms of your delay , you 're , that  that 's what it seems like to me . it 's pretty good . where is this fifty seven point o two in comparison to the last evaluation ? is that right ?   this is almost ten percent .  this is really good .  what was that ? say that last part again ?  that would be even that wouldn't change this number down here to sixty two ?   that 's the best you could hope for . i see . those are th what is going into the tandem net ? those two ?    i see .  right .  compared to these numbers ? that 's how you get down to twenty eight ? why twenty eight ?   i see .  that makes sense . it seems funny that i don't know , don't u quite understand everything , but that adding features if you 're keeping the back end fixed . that 's it . because it seems like just adding information shouldn't give worse results . but if you 're keeping the number of gaussians fixed in the recognizer , then   i wasn't necessarily saying it should be better . i 'm just surprised that you 're getting fifteen percent relative worse on the wel on the highly mismatch .   what if you did the would it make sense to do the klt on the full set of combined features ? instead of just on the i see . you tried the global klt before and it didn't really i see .   what is the you said there was a limit of sixty features what 's the relation between that limit and the , forty eight forty eight hundred bits per second ? don't understand , because i if you 're only using h  you 're saying , add the macrophone data to the training of the neural net ? the tandem net ?  right . what was it trained on again ? the one that you used ?  and did an other numbers stay the same ? insertion substitutions stay the same ? roughly ?  that says that , the , the models in , the recognizer are really paying attention to the neural net features .  i 've been wondering about something . in the , lot of the , the hub five systems , recently have been using lda . and they , they run lda on the features right before they train the models . there 's the lda is right there before the h m you guys are using lda but it seems like it 's pretty far back in the process .   you c you can . it 's you 're just you 're shifting the feature space .   what i what about , u what i w i don't know if this is a good idea or not , but what if you put ran the other lda , on your features right before they go into the  right , it 's the it 's right . the it 's like the tandem is like i nonlinear lda . ","i , started working on the mississippi state recognizer . i got in touch with joe and , from your email and things like that . and , they added me to the list the mailing list . and he gave me all of the pointers and everything that i needed . and downloaded the , there were two things , that they had to download . downloaded the software and compiled all of that . and it compiled fine . you asked me to write to him i 'll d i 'll double check that and ask him again . what if you used a smaller window for the delta ? there 's a lot of things you could do to wh what 's the baseline you need to be under ? how do that what you have is too much if they 're still deciding ? where is this fifty seven point o two in comparison to the last evaluation ? that 's how you get down to twenty eight ? and did an other numbers stay the same ? in the , lot of the , the hub five systems , recently have been using lda . and they , they run lda on the features right before they train the models . but what if you put ran the other lda , on your features right before they go into the the tandem is like i nonlinear lda . ","The group discussed possible further investigations that arose from these areas, including better linking the two. "
Bro027.A,"i g  but w but the other features that you have , th the non tandem ones ,   right .      right . you wouldn't necessarily then want to do lda on the non tandem features because now you 're doing something to them that  right . right . right .    exactly . we , we were getting ready to do the tandem , for the hub five system , and , andreas and i talked about it , and the idea w the thought was , "" that i th the neural net should be better , but we should at least have a number , to show that we did try the lda in place of the neural net , that we can show a clear path . that you have it without it , then you have the lda , then you have the neural net , and you can see , theoretically .  i was just wondering i  no . that 's what we 're gonna do next as soon as i finish this other thing .  we just want to show . it everybody believes it , but we just      and everybody 's putting that on their systems now , and i that 's what made me wonder about this , but . what is it 's like in the hub five evaluations , and you read the system descriptions and everybody 's got , lda on their features . and  it 's different .  exactly . cuz they don't have these , mismatches that you guys have . that 's why i was wondering if it 's not even a good idea . i don't know . i don't know enough about it , but what do y do you have that feature available for the test data ? i see . i see .   you 're saying , feed that , also , into the neural net .   right . but in principle wouldn't it be better to feed it in ? and let the net do that ?   what what if you right . what if you then , since this , what if you only use the neural net on the speech portions ? that 's the same . that 's similar . but train the net only on but if you 're gonna if you 're going to multiply the output of the net by this other decision , would then you don't care about whether the net makes that distinction , right ?  right ,  that 's a good point . be interesting to look at the  for the i wonder if you could do this . but if you look at the , highly mism high mismat the output of the net on the high mismatch case and just look at , the distribution versus the other ones , do you see more peaks  but if you were gonna put it in as a feature it means you already have it by the time you get to the tandem net , right ?   right . for the tandem net  if ,  if the , high mismatch case had been more like the , the other two cases in terms of giving you just a better performance , how would this number have changed ? y like sixty ?   this would be sixty two ? which is all the other ones were five percent , the   when when do you leave ? but you 're are you you 're not gonna be around this afternoon ?      what 's september sixth ? right .   you 're gonna be gone for the next three weeks that 's you won't be at the next three of these meetings . is that right ? right . right .  when do you go back ? when is the evaluation ? november ,   should we do digits ?  ","but w but the other features that you have , th the non tandem ones , you 're saying , feed that , also , into the neural net . ","The group discussed possible further investigations that arose from these areas, including better linking the two. "
Bro027.B,"test .  let 's see . move it bit . test ? test ?  it 's alright .  let 's see . barry 's not here and dave 's not here . say about just q just quickly to get through it , that dave and i submitted this asru .    it 's interesting . we 're dealing with rever reverberation , and , when we deal with pure reverberation , the technique he 's using works really , really and when they had the reverberation here , we 'll measure the signal to noise ratio and it 's , about nine db .   a fair amount of    and actually it brought up a question which may be relevant to the aurora too . i know that when you figured out the filters that we 're using for the mel scale , there was some experimentation that went on at , at ogi .  but one of the differences that we found between the two systems that we were using , the aurora htk system baseline system and the system that we were the other system we were using , the the sri system , was that the sri system had , hundred hertz high pass . and the , aurora htk , it was like twenty .  sixty four ?  is that the ba band center ? the edge is really , sixty four ? for some reason , dave thought it was twenty , but . but do h how far down it would be at twenty hertz ? what the how much rejection would there be at twenty hertz , let 's say ?  any idea what the curve looks like ? it 's actually set to zero ? what filter is that ? is this from the from you , you really set it to zero , the fft ? right .    that 's a little different than dave thought , but ,  still , it 's possible that we 're getting in some more noise . wonder , is it @ @ was there their experimentation with , say , throwing away that filter and ,  right , but the question is , whether sixty four hertz is , too , low .  on what test set ? it was on the speechdat car .  and on the , ti digits also ?  that 'd be something to look at sometime because what , he was looking at was performance in this room . would that be more like you 'd think that 'd be more like speechdat car ,  in terms of the noise . the speechdat car is more , roughly stationary , a lot of it . and ti digits is not much as    it 's not a big deal . but , anyway , that was just something we wondered about . but , certainly a lot of the noise , is , below a hundred hertz . the signal to noise ratio , looks a fair amount better if you high pass filter it from this room . but , but it 's still pretty noisy . even for a hundred hertz up , it 's still fairly noisy . the signal to noise ratio is actually still pretty bad .  the main the  that 's on the far field . the near field 's pretty good . we got a video projector in here ,  and , which we keep on during every session we record , which , i w we were aware of but we thought it wasn't a bad thing . that 's a noise source . and there 's also the , air conditioning . which , is a pretty low frequency thing . but , those are major components , for the stationary  but , it , i said this last week too but it really became apparent to us that we need to take account of noise . and , think when he gets done with his prelim study one of the next things we 'd want to do is to take this , noise , processing and , synthesize some speech from it . and then in about , a little less than two weeks .    it might even be sooner . let 's see , this is the sixteenth , seventeenth ? i don't know if he 's before it might even be in a week . a week , week and a half . they seem to be the semester actually is starting up .  the semester 's late august they start here . they do it right at the beginning of the semester .    that was one  the overall results seemed to be first place in the case of either , artificial reverberation or a modest sized training set . either way , i it helped a lot . and but if you had a really big training set , a recognizer , system that was capable of taking advantage of a really large training set that one thing with the htk is that is has the as we 're using the configuration we 're using is w s is being bound by the terms of aurora , we have all those parameters just set as they are . even if we had a hundred times as much data , we wouldn't go out to , ten or t or a hundred times as many gaussians or anything .  it 's hard to take advantage of big chunks of data . whereas the other one does expand as you have more training data . it does it automatically , actually . and   that one really benefited from the larger set . and it was also a diverse set with different noises and forth .  that , that seemed to be ","say about just q just quickly to get through it , that dave and i submitted this asru . we 're dealing with rever reverberation , and , when we deal with pure reverberation , the technique he 's using works really , really and actually it brought up a question which may be relevant to the aurora too . i know that when you figured out the filters that we 're using for the mel scale , there was some experimentation that went on at , at ogi . but one of the differences that we found between the two systems that we were using , the aurora htk system baseline system and the system that we were the other system we were using , the the sri system , was that the sri system had , hundred hertz high pass . still , it 's possible that we 're getting in some more noise . wonder , is it @ @ was there their experimentation with , say , throwing away that filter think when he gets done with his prelim study one of the next things we 'd want to do is to take this , noise , processing and , synthesize some speech from it . ",They also consider how aspects of an absent member's work might be applied to the current project. 
Bro027.B,"if you have that better recognizer that can build up more parameters , and if you , have the natural room , which in this case has a p a pretty bad signal to noise ratio , then in that case , the right thing to do is just do u use speaker adaptation . and not bother with this acoustic , processing . but that would not be true if we did some explicit noise processing as as , the convolutional things we were doing .  that 's what we found . is there any word yet about the issues about , adjustments for different feature sets or anything ?    it 's like that could r turn out to be an important issue for us .  for r w what test set ? but that has nothing to do with what we 're testing on , right ? right . they 're set they 're setting it based on that ?  now , we may come back to the situation where we may be looking for a modification of the features to account for the fact that we can't modify these parameters . but ,  but it 's still worth , just since just chatting with joe about the issue .  it 's not a secret . we 're , certainly willing to talk about it with everybody , but that , it 's probably best to start talking with him just to @ it 's a dialogue between two of you about what what does he think about this and what what could be done about it .  if you get ten people in involved in it there 'll be a lot of perspectives based on , how   but , it all should come up eventually , but if there is any , way to move in a way that would , be more open to different kinds of features . but if , if there isn't , and it 's just shut down and then also there 's probably not worthwhile bringing it into a larger forum where political issues will come in . this is slightly off topic but , i noticed , just glancing at the , hopkins workshop , web site that , one of the thing i don't know we 'll see how much they accomplish , but one of the things that they were trying to do in the graphical models thing was to put together a , tool kit for doing , arbitrary graphical models for , speech recognition . and jeff , the two jeffs were  do geoff zweig ?  he , he was here for a couple years and he , got his phd . he and he 's , been at ibm for the last couple years .  he did his phd on dynamic bayes nets , for speech recognition . he had some continuity built into the model , presumably to handle some , inertia in the production system , and ,   what was it using before ? s i 'm there 's there 's how many inputs ? twelve times nine inputs , and a hundred , hidden . two outputs .  guess about eleven thousand parameters , which actually shouldn't be a problem , even in small phones . and , it 's a l it 's a lot better . that 's great . what 's the latency ? i 'm confused . you started off with two twenty and you ended up with one seventy ? two seventy .  it 's two twenty . i the is this are these twenty millisecond frames ? is that why ? is it after downsampling ? or a  one hundred milliseconds for smoothing .  median . and then forty forty p  p minute . it 's forty for the cleaning of the speech , forty for the i n ann , a hundred for the smoothing . but at ten , twenty for delta . delta at input to net ? and then ten milliseconds for ten milliseconds for lda filter , and t and ten another ten milliseconds you said for the frame ?  and then there 's delta besides that ?   no , the after the noise part , the forty the other hundred and eighty  minute . some of this is , is in parallel , isn't it ? the lda you have the lda as part of the v d vad ? or it does ?  in that case there isn't too much in parallel .  the delta at the end is how much ? fifty . alright .     if you put the delta before the , ana on line if  then it could go in parallel . and then y then you don't have that additive   and you ought to be able to shove tw , sh pull off twenty milliseconds from somewhere else to get it under two hundred , right ?  the hundred milla mill a hundred milliseconds for smoothing is an arbitrary amount . it could be eighty and probably do @ @ we don't know . they 're still arguing about it . if it 's two if it 's , if it 's two fifty , then we could keep the delta where it is if we shaved off twenty . if it 's two hundred , if we shaved off twenty , we could we could , meet it by moving the delta back . we don't , but it 's just the main thing is that since that we got burned last time , and by not worrying about it very much , we 're just staying conscious of it . and th if a week before we have to be done someone says , "" you have to have fifty milliseconds less than you have now "" , it would be pretty frantic around here .   he added a bit on , because before we were had were able to have the noise , and the lva be in parallel . ","is there any word yet about the issues about , adjustments for different feature sets or anything ? it 's like that could r turn out to be an important issue for us . now , we may come back to the situation where we may be looking for a modification of the features to account for the fact that we can't modify these parameters . but it 's still worth , just since just chatting with joe about the issue . and , it 's a l it 's a lot better . if you put the delta before the , ana on line if then it could go in parallel . we don't know . they 're still arguing about it . if it 's two if it 's , if it 's two fifty , then we could keep the delta where it is if we shaved off twenty . if it 's two hundred , if we shaved off twenty , we could we could , meet it by moving the delta back . the main thing is that since that we got burned last time , and by not worrying about it very much , we 're just staying conscious of it . if a week before we have to be done someone says , "" you have to have fifty milliseconds less than you have now "" , it would be pretty frantic around here . ","The group discussed possible further investigations that arose from these areas, including better linking the two. "
Bro027.B,"and now he 's requiring it to be done first . right . you say let 's say ten milliseconds seconds for the lda . ten . and then forty for the other . right , you could start pulling back , but but you have you have twenty for delta computation which y now you 're doing twice , right ? but yo w were you doing that before ? right . what you have now is fort forty for the noise , twenty for the delta , and ten for the lda . that 's seventy milliseconds of which was formerly in parallel , right ? think , that 's the difference as far as the timing , right ?  and you could experiment with cutting various pieces of these back a bit , but we 're s we 're not in terrible shape .  it 's not like it 's adding up to four hundred milliseconds it 's it 's better than anything , anybody got .    with the f with the neural net .  and r and   and we still don't have the neural net in . it 's  it 's we 're doing better . we 're getting better recognition . i 'm other people working on this are not sitting still either , but but but ,  the important thing is that we learn how to do this better , and ,    our ,  you can see the numbers that we 're having , say , on speechdat car which is a hard task , cuz it 's really , think it 's just reasonable numbers , starting to be . it 's still terri   probably half . good !  you were get probably . fi si fifty three is what you were getting with the old vad . and , and sixty two with the , quote , unquote , cheating vad . and fifty seven is what you got with the real vad . that 's great .    no .  h he likes to use them both , cuz then it has one part that 's discriminative , one part that 's not . y you 're just using the full ninety features ? y you have ninety features ? and from the other side it 's forty five . it 's you have seventy three features , and you 're just feeding them like that . there isn't any klt or anything ? it 's a multiple of seven .    but , just in general , adding information suppose the information you added , was a really terrible feature and all it brought in was noise . right ?  or suppose it wasn't completely terrible , but it was completely equivalent to another one feature that you had , except it was noisier . right ? in that case you wouldn't necessarily expect it to be better  on the highly mismatched condition . "" highly mismatched condition "" means that your training is a bad estimate of your test . having , a g a l a greater number of features , if they aren't the right features that you use , certainly can e can easily , make things worse . you 're right . if you have if you have , lots and lots of data , and you have and your training is representative of your test , then getting more sources of information should just help . but it 's it doesn't necessarily work that way . wonder ,  what 's your thought about what to do next with it ?   we might we might have to experiment with , better training sets . again . but , i the other thing is , before you found that was the best configuration , but you might have to retest those things now that we have different the rest of it is different , right ?    what 's the effect of just putting the neural net on without the o other path ? what the straight features do . that gives you this . what it does in combination . you don't necessarily but , that 's another thing to try , since things are different . and if the these are all all of these seventy three features are going into , the , the and is are i are any deltas being computed of tha of them ? n not of the are not . could . i  but the other thing i was thinking was ,  now i lost track of what i was thinking . but .  i was gonna say . no relation . the issue was that , this is supposed to be a standard that 's then gonna be fed to somebody 's recognizer somewhere which might be , it might be a concern how many parameters are use u used and forth . and  they felt they wanted to set a limit . they chose sixty . some people wanted to use hundreds of parameters and that bothered some other people . u and they just chose that . it 's arbitrary too . but that 's what was chosen . i remembered what i was going to say . what i was going to say is that , with the noise removal , these things are now more correlated . you have two sets of things that are uncorrelated , within themselves , but they 're pretty correlated with one another . and , they 're being fed into these , variants , only gaussians and forth , and , it would be a better idea now than it was before to , have , one klt over everything , to de correlate it .    we found this , this macrophone data , and forth , that we were using for these other experiments , to be pretty good . that 's i after you explore these other alternatives , that might be another way to start looking , is just improving the training set . ","and you could experiment with cutting various pieces of these back a bit , we 're s we 're not in terrible shape . it 's it 's better than anything , anybody got . you 're just using the full ninety features ? and from the other side it 's forty five . it 's you have seventy three features , what 's your thought about what to do next with it ? we might we might have to experiment with , better training sets . i the other thing is , before you found that was the best configuration , but you might have to retest those things now that we have different the rest of it is different , what 's the effect of just putting the neural net on without the o other path ? what the straight features do . they felt they wanted to set a limit . they chose sixty . it 's arbitrary too . ","The group discussed possible further investigations that arose from these areas, including better linking the two. "
Bro027.B,"we were getting , lots better recognition using that , than you do have the problem that , u i we are not able to increase the number of gaussians , or anything to , to match anything . we 're only improving the training of our feature set , but that 's still probably something .  that 's the only place that we can train . we can't train the other with anything other than the standard amount ,     how big is the net , you did experiments back then where you made it bigger and it and that was the threshold point . much less than that , it was worse , and much more than that , it wasn't much better .   right . the training the neural net is being trained with noise compensated which makes sense , but , you 're saying the noisier ones are still going to be , even after our noise compensation , are still gonna be pretty noisy . right . yes . right . right . right , but the speechdat car data that you 're seeing is also reduced in noise by the noise compensation .    it depends on whether you believe that the noise compensation is equally reducing the noise on the test set and the training set .  right ? you 're saying there 's a mismatch in noise that wasn't there before , but if they were both the same before , then if they were both reduic reduced equally , then , there would not be a mismatch .  this may be heaven forbid , this noise compensation process may be imperfect , but .  it 's treating some things differently . one of the things about the macrophone data , it was recorded over many different telephones . and , there 's lots of different kinds of acoustic conditions . it 's not artificially added noise or anything . it 's not the same . i don't think there 's anybody recording over a car from a car , but it 's varied enough that if doing this adjustments , and playing around with it doesn't , make it better , the most it seems like the most obvious thing to do is to improve the training set .  what we were the condition it gave us an enormous amount of improvement in what we were doing with meeting recorder digits , even though there , again , these m macrophone digits were very , very different from , what we were going on here . we weren't talking over a telephone here . but it was just just having a variation in acoustic conditions was just a good thing . number of deletions .  me either . did they increase the number of deletions even for the cases that got better ? say , for the it it 's only the highly mismatched ? and it remind me again , the "" highly mismatched "" means that the  close mike training right .  the noise subtraction is subtracting off speech . wh right . that 's right .  but , actually the timit noises are range of noises and they 're not much the stationary driving noises , right ? it 's pretty different . isn't it ?   that if you run it actually , you you remember this . when you in the old experiments when you ran with the neural net only , and didn't have this side path , with the pure features as did it make things better to have the neural net ? was it about the same ? w i than ?  until you put the second path in with the pure features , the neural net wasn't helping that 's interesting .   they were doing similar enough things . i still think it would be k interesting to see what would happen if you just had the neural net without the side thing . and the thing i have in mind is , you 'll see that the results are not just a little bit worse . that they 're a lot worse .  and , but if on the ha other hand , it 's , say , somewhere in between what you 're seeing now and , what you 'd have with just the pure features , then there is some problem of a , combination of these things , or correlation between them somehow . if it really is that the net is hurting you at the moment , then the issue is to focus on , improving the net .  what 's the overall effe you haven't done all the experiments but you said it was i somewhat better , say , five percent better , for the first two conditions , and fifteen percent worse for the other one ? but it 's but that one 's weighted lower , wonder what the net effect is . right . right . the worst it could be , if the others were exactly the same , is four , and , since the others are somewhat better  it should be pretty close to cancelled out .  the a the argument i is in and it 's not like we really know , but the argument anyway is that , we always have the prob discriminative things are good . lda , neural nets , they 're good . they 're good because you learn to distinguish between these categories that you want to be good at distinguishing between . and pca doesn't do that . it pac pca low order pca throws away pieces that are not gonna be helpful just because they 're small , but , the problem is , training sets aren't perfect and testing sets are different . you f you face the potential problem with discriminative be it lda or neural nets , that you are training to discriminate between categories in one space but what you 're really gonna be g getting is something else . ","me either . did they increase the number of deletions even for the cases that got better ? it 's only the highly mismatched ? when you in the old experiments when you ran with the neural net only , and didn't have this side path , with the pure features as did it make things better to have the neural net ? until you put the second path in with the pure features , the neural net wasn't helping i still think it would be k interesting to see what would happen if you just had the neural net without the side thing . and the thing i have in mind is , you 'll see that the results are not just a little bit worse . that they 're a lot worse . but if on the ha other hand , it 's , say , somewhere in between what you 're seeing now and , what you 'd have with just the pure features , then there is some problem of a , combination of these things , or correlation between them somehow . if it really is that the net is hurting you at the moment , then the issue is to focus on , improving the net . ",
Bro027.B,"and stephane 's idea was , let 's feed , both this discriminatively trained thing and something that 's not . you have a good set of features that everybody 's worked really hard to make , and then , you discriminately train it , but you also take the path that doesn't have that , and putting those in together . and that seem it 's like a combination of the what , dan has been calling , a feature a feature combination versus posterior combination it 's it 's , you have the posterior combination but then you get the features from that and use them as a feature combination with these other things . and that seemed , at least in the last one , as he was just saying , he when he only did discriminative i it actually was it didn't help in this particular case . there was enough of a difference , between the testing and training . but by having them both there the fact is some of the time , the discriminative is gonna help you . and some of the time it 's going to hurt you , and by combining two information sources if , if that i that 's counter to that idea . now , again , it 's we 're just trying these different things . we don't really 's gonna work best . but if that 's the hypothesis , at least it would be counter to that hypothesis to do that .  and in principle you would think that the neural net would do better at the discriminant part than lda . though , not . right . that 's a good idea . did you do that or tha that 's a   no , that 's a good idea . i i no it 's a g no , no , but it might not even be true . it 's it 's it 's a great idea . one of the things that always disturbed me , in the resurgence of neural nets that happened in the eighties was that , a lot of people because neural nets were pretty easy to use a lot of people were just using them for all sorts of things without , looking into the linear , versions of them . and , people were doing recurrent nets but not looking at iir filters , and think , it 's definitely a good idea to try it . they 've been putting them in their systems off and on for ten years , but but , and now they all have that . i see .  part of why part of why you were getting into the klt y you were describing to me at one point that you wanted to see if , getting good orthogonal features was and combining the different temporal ranges was the key thing that was happening or whether it was this discriminant thing , right ? you were just trying you r this is it doesn't have the lda aspect but th as far as the orthogonalizing transformation , you were trying that at one point , right ? you were . does something . it doesn't work as       but i d i 'm does it still have the median filter it still has most of the delay , it just doesn't w i plus the delta , right .        now this , "" before and after clean "" , it sounds like you think that 's a good feature . that , it you th think that the , the i it appears to be a good feature , right ? what about using it in the neural net ?    if we can live with the latency or cut the latencies elsewhere , then that would be a , good thing . anybody has anybody you guys or naren , somebody , tried the , second th second stream thing ?        what would be more what you 'd want to do is , put it into another neural net . right ? and then but , we 're not quite there yet . we have to figure out the neural nets , wh the vad what ?    you could feed it into the neural net . the other thing you could do is just , p modify the , output probabilities of the , neural net , tandem neural net , based on the fact that you have a silence probability . right ? you have an independent estimator of what the silence probability is , and you could multiply the two things , and renormalize . you 'd have to do the nonlinearity part and deal with that . go backwards from what the nonlinearity would , would be . but , u not  let 's put it this way . y you have this complicated system with thousands and thousand parameters and you can tell it , "" learn this thing . "" or you can say , "" it 's silence ! go away ! ""  i doesn't ? the second one sounds a lot more direct .    y you 'd have to actually run it continuously , but it 's @ @ no , you want to train on the nonspeech also , because that 's part of what you 're learning in it , to generate , that it 's it has to distinguish between .  but this other thing isn't perfect . that you bring in some information from the net itself .  now the only thing that bothers me about all this is that i the fact i it 's bothersome that you 're getting more deletions . is too high .        but i bu  now the only problem is you don't want to ta for the output of the vad before you can put something into the other system , cuz that 'll shoot up the latency a lot , right ? am i missing something here ?  ","the other thing you could do is just , p modify the , output probabilities of the , neural net , tandem neural net , based on the fact that you have a silence probability . now the only thing that bothers me about all this is that i the fact i it 's bothersome that you 're getting more deletions . ","The group discussed possible further investigations that arose from these areas, including better linking the two. "
Bro027.B,"that 's problem with what i was just saying . but but no .  it 's done in some of the things are , not in parallel , but certainly , it would be in parallel with the with a tandem net . in time . if that doesn't work ,  but it would be interesting to see if that was the problem , anyway . and then another alternative would be to take the feature that you 're feeding into the vad , and feeding it into the other one as and then it would just learn it better .  but that 's that 's an interesting thing to try to see , if what 's going on is that in the highly mismatched condition , it 's , causing deletions by having this silence probability up too high , at some point where the vad is saying it 's actually speech . which is probably true . cuz the v a if the vad said since the vad is right a lot ,   anyway . might be .  we just started working with it . but these are some good ideas problem is , if you are going to run this on different m test sets , including large vocabulary ,      but i d it i it 's all worth looking at , but it sounds to me like , looking at the relationship between this and the speech noise is probably a key thing . that and the correlation between we don't 's it 's gonna be the ti digits yet . he hasn't got the results back yet . sixty two .      won't be here for i 'm leaving next wednesday . may or may not be in the morning . i leave in the afternoon .     i 'm talking about next week . i 'm leaving next wednesday . this afternoon right , for the meeting ? that 's just cuz of something on campus .  but ,  next week i won't , and the week after i won't , cuz i 'll be in finland . and the week after that i won't . by that time you 'll be you 'll both be gone from here . there 'll be no definitely no meeting on september sixth .  and that 's during eurospeech . sunil will be in oregon . stephane and i will be in denmark .  right ? it 'll be a few weeks , really , before we have a meeting of the same cast of characters .  but , just you guys should probably meet . and barry will be around . and and then we 'll start up again with dave and barry and stephane and us on the , twentieth . no . thirteenth ? about a month ? i 'm gone for two and a half weeks starting next wed late next wednesday . i won't it 's probably four because of is it three ? let 's see , twenty third , thirtieth , sixth . that 's right , next three . and the third one won't probably won't be a meeting , cuz , su sunil , stephane , and i will all not be here .  it 's just , the next two where there will be there , may as be meetings , but won't be at them . and then starting up on the thirteenth , we 'll have meetings again but we 'll have to do without sunil here somehow .       it was supposed to be november fifteenth . has anybody heard anything different ?  but , no , this is good progress .    guess we 're done . digits ?  it 's a wrap . ","won't be here for i 'm leaving next wednesday . i 'm leaving next wednesday . next week i won't , and the week after i won't , cuz i 'll be in finland . by that time you 'll be you 'll both be gone from here . it 'll be a few weeks , really , before we have a meeting of the same cast of characters . and then we 'll start up again with dave and barry and stephane and us on the , twentieth . ","The meeting closed with a discussion of upcoming absences, and how meetings would continue. "
Bro027.C,"eight , eight ? three . yea actually , the left edge of the first filter is at sixty four .    it this is the filter bank in the frequency domain that starts at sixty four .        i 've been playing with , first , the , vad . it 's exactly the same approach , but the features that the vad neural network use are , mfcc after noise compensation . have the results . before it was just p l   noisy features .  this is what we get after this actually , we , here the features are noise compensated and there is also the lda filter . and then it 's a pretty small neural network which use , nine frames of six features from c zero to c fives , plus the first derivatives . and it has one hundred hidden units .   it 's twelve times nine . hidden and two outputs .  it should be the previous syst it 's based on the system that has a fifty three point sixty six percent improvement . it 's the same system . the only thing that changed is the n a p es the estimation of the silence probabilities . which now is based on , cleaned features .   it 's not bad , but the problem is still that the latency is too large . because  the latency of the vad is two hundred and twenty milliseconds . and , the vad is used i for on line normalization , and it 's used before the delta computation . if you add these components it goes t to a hundred and seventy , right ? with two an two hundred and seventy . if  if you add the c delta comp delta computation which is done afterwards .  the two twenty is one hundred milliseconds for the no , it 's forty milliseconds for t for the , cleaning of the speech .  then there is , the neural network which use nine frames . it adds forty milliseconds .  after that , you have the filtering of the silence probabilities . which is a million filter it , and it creates a one hundred milliseconds delay .   and there is the delta at the input which is ,  it 's @ @  forty this forty plus twenty , plus one hundred .  there are twenty that comes from there is ten that comes from the lda filters also . right ? it 's two hundred and ten ,  plus the frame , it 's two twenty . it 's five frames , but .  forty cleaning .  twenty for the delta .   for the frame i computed two twenty it 's it 's for the fr the this is the features that are used by our network and then afterwards , you have to compute the delta on the , main feature stream , which is delta and double deltas , which is fifty milliseconds . the vad use , lda filtered features also .  no . there is , just downsampling , upsampling , and the lda . it 's fifty . but we could probably put the delta , before on line normalization . it should not that make a big difference , because   but , nnn  cuz i  cuz the time constant of the on line normalization is pretty long compared to the delta window ,  it should not make     but the main thing , is the cleaning of the speech , which takes forty milliseconds or and and but the lda is , pretty short right now .  no .  this is the first try . i the lda 's not very useful then .  in the proposal , the input of the vad network were just three frames , static features .     the best was fifty four point five . and our system was forty nine , but with the neural network . it would  even for a matched case it 's sixty percent error rate reduction , which is   actually , this is in between what we had with the previous vad and what sunil did with an idl vad . which gave sixty two percent improvement , right ?   if you use an idl vad , for dropping the frames , the best that we can get i that means that we estimate the silence probability on the clean version of the utterances . then you can go up to sixty two percent error rate reduction , globally .    if you add a g good v very good vad , that works as as a vad working on clean speech , then you wou you would go    the next thing is , i started to play i don't want to worry too much about the delay , no . it 's better to for the decision from the committee . but i started to play with the , tandem neural network .  did the configuration that 's very similar to what we did for the february proposal . and  there is a f a first feature stream that use straight mfcc features . these features actually . and the other stream is the output of a neural network , using as input , also , these , cleaned mfcc .  i don't have the comp  there is just this feature stream , the fifteen mfcc plus delta and double delta . it 's makes forty five features that are used as input to the htk . and then , there is there are more inputs that comes from the tandem mlp .     right now it seems that tested on speechdat car while the experiment are running on your on ti digits . it improves on the matched and the mismatched conditions , but it get worse on the highly mismatched .  compared to these numbers ,  like , on the match and medium mismatch , the gain is around five percent relative , but it goes down a lot more , like fifteen percent on the hm case . the ","i 've been playing with , first , the , vad . it 's exactly the same approach , but the features that the vad neural network use are , mfcc after noise compensation . before it was just p l it 's based on the system that has a fifty three point sixty six percent improvement . the only thing that changed is the n a p es the estimation of the silence probabilities . which now is based on , cleaned features . but the problem is still that the latency is too large . the latency of the vad is two hundred and twenty milliseconds . but we could probably put the delta , before on line normalization . cuz the time constant of the on line normalization is pretty long compared to the delta window , the best was fifty four point five . but i started to play with the , tandem neural network . did the configuration that 's very similar to what we did for the february proposal . there is a f a first feature stream that use straight mfcc features . and the other stream is the output of a neural network , using as input , also , these , cleaned mfcc . it improves on the matched and the mismatched conditions , but it get worse on the highly mismatched . ","The main areas being worked on were the voice activity detector and the tandem data streams. The group discussed possible further investigations that arose from these areas, including better linking the two. "
Bro027.C,"i i have ,  from the networks , it 's twenty eight .  d i it 's forty five .    there 's a klt after the neural network , as before .  i don't know .  it 's i it 's because it 's what we did for the first proposal . we tested , trying to go down and    i wanted to do something very similar to the proposal as a first try . but we have to for we have to go down , because the limit is now sixty features .   we have to find a way to decrease the number of features .   but it 's worse . i    i don't know . i 'm surprised , because i expected the neural net to help more when there is more mismatch , as it was the case for the it 's the same training set , it 's timit with the ti digits ' , noises , added .       i g  the reason i did it this ways is that in february , it we tested different things like that , having two klt , having just a klt for a network , or having a global klt . and   and , th  the differences between these configurations were not huge , but it was marginally better with this configuration .     of the straight features ,  but n th the , tandem features are u used as they are .  we can add some context from these features also as dan did in his last work .  not no relation . the f the forty eight hundred bits is for transmission of some features . and generally , i it s allows you to transmit like , fifteen , cepstrum .    i see . it 's , ranging from zero to clean ?  from zero to clean .   it 's timit with noise . it 's rather a small  it 's , five hundred hidden units . and      they k       the most noisy occurrences on speechdat car might be a lot more noisy than       if the initial range of snr is different , we the problem was already there before . and because      clean training , we 'll we 'll see .        actually to s what i observed in the hm case is that the number of deletion dramatically increases . it doubles . when i added the num the neural network it doubles the number of deletions . don't how to interpret that , but , t they p stayed the same , they they are a little bit lower . they are a little bit better . but  no , it doesn't . no . clean training and it 's clean training close microphone training and distant microphone , high speed ,  the most noisy cases are the distant microphone for testing . separating .  but  but without the neural network it 's it 's better . it 's just when we add the neural networks . the feature are the same except that   there is a car noise . there are f just four noises .  "" car "" , "" babble "" , "" subway "" , right ? and and "" street "" isn't "" train station "" , it 's mostly "" car "" is stationary , "" babble "" , it 's a stationary background plus some voices , some speech over it . and the other two are rather stationary also .  it was b a little bit worse . than just the features ,   it was helping , if the features are b were bad ,  just plain p l ps or m f c cs . as soon as we added lda on line normalization , and all these things , then      y  i d it 's it was one or two percent . that 's not that bad , but it was l like two percent relative worse on speechdat car . i have to check that . i have i will .   it was slightly worse .    no , actually ,  what do we do with the ann is something like that except that it 's not linear . but it 's like a nonlinear discriminant analysis . but .  it 's    i know . that in the proposal , they were transformed u using pca , but it might be that lda could be better . it 's the transformation they 're estimating on they are trained on the same data as the final are .         eventually we could just then you don't have to worry about the thresholds and but just     right .   still not .  th    when that 's what  but might look at , is it due to the fact that the probability of the silence at the output of the network , is ,  too high or if it 's the case , then multiplying it again by i by something ?  eee hhh .    like the entropy of the output , or it seems that the vad network doesn't it doesn't drop , too many frames because the dele the number of deletion is reasonable . but it 's just when we add the tandem , the final mlp , and then u but  right .     m    and the other thing there are other issues for the tandem , like , do we want to , w do we want to work on the targets ? or instead of using phonemes , using more context dependent units ? i 'm  i 'm thinking , also , a w about dan 's work where he trained a network , not on phoneme targets but on the state targets . and it was giving s slightly better results .     i was just thinking about generalized diphones , and come up with a reasonable , not too large , set of context dependent units , and and  and then anyway we would have to reduce this with the klt .  but i don't know .    it would be  around five percent better , if i  ","from the networks , it 's twenty eight . there 's a klt after the neural network , as before . i wanted to do something very similar to the proposal as a first try . but we have to for we have to go down , because the limit is now sixty features . we have to find a way to decrease the number of features . i 'm surprised , because i expected the neural net to help more when there is more mismatch , as it was the case for the actually to s what i observed in the hm case is that the number of deletion dramatically increases . it doubles . when i added the num the neural network it doubles the number of deletions . don't how to interpret that , they p stayed the same , no . it was b a little bit worse . it was helping , if the features are b were bad , as soon as we added lda on line normalization , and all these things , then but it 's like a nonlinear discriminant analysis . in the proposal , they were transformed u using pca , it might be that lda could be better . might look at , is it due to the fact that the probability of the silence at the output of the network , is , too high ","The group discussed possible further investigations that arose from these areas, including better linking the two. "
Bro027.C,"if you extrapolate the speechdat car matched and medium mismatch , it 's around , five . sixty two ,  it 's around five percent , because it 's right ? if everything is five percent .  i d have the speechdat car right now ,  it 's running it shou we should have the results today during the afternoon , but  i don't know . the meeting in is the five and six of december .     the evaluation should be on a week before or ",,
Bro027.D,"this is three .    k  s sixty four . s sixty four .  if you 're using the baseline . no , the edge .  the , center would be somewhere around like hundred and hundred and it 's like fi hundred hertz . at twenty hertz . twenty hertz frequency it 's zero at twenty hertz , right ? the filter ? sixt s sixty four . anything less than sixty four is zero .    it 's a weight on the ball spectrum . triangular weighting . throwing away the first ?  we 've tried including the full bank . right ? from zero to four k . and that 's always worse than using sixty four hertz .  make it a hundred or i t 've tried a hundred and it was more or less the same , or slightly worse . on the same , speechdat car , aurora .  tried a hundred to four k .  it was no , no . just tried it on speechdat car .          great . eight . great . that sample was released only yesterday or the day before , right ? there is another short sample set o sample .   f   cuz they have it cuz they have , already frozen those in i insertion penalties and all those is what i feel . because they have this document explaining the recognizer . and they have these tables with , various language model weights , insertion penalties . u it 's th it 's there on that web . and , on that , they have run some experiments using various insertion penalties and all those they pi p they picked the values from p the one that they have reported is a nist evaluation , wall street journal .  no . they 're , like  they are actually trying to , fix that those values using the clean , training part of the wall street journal . which is the aurora . aurora has a clean subset . they want to train it and then this they 're going to run some evaluations .    this is now it 's compiled under solaris ?  because he there was some mail r saying that it 's may not be stable for linux and all those . susi     that 's fine .  that 's good .  it was actually no . not it was just the noisy features  not compensated . two outputs . plus there is a delta at the input . it 's like forty plus it 's two hundred actually .  if you are using t if you are using three frames if you are phrasing f using three frames , it is thirty here for delta . five frames , that 's twenty .  it 's who un two hundred and ten . at th at the input . that 's at the input to the net . and there i  it 's like s five , six cepstrum plus delta at nine frames of fi there 's an lda filter . it 's  the lda we don't know , is , like is it very crucial for the features , right ?  s h  l on the in the  just just the static , no delta . point s  this is like the first proposal . the proposal one . it was forty four , actually . it 's almost that . it 's almost an average somewhere around  o or the best we can get .    was the training set same as the p the february proposal ?  what are the s n rs in the training set , timit ?  is it though the performance , big relation in the high ma high mismatch has something to do with the , cleaning up that you that is done on the timit after adding noise ?  it 's i all the noises are from the ti digits , right ? you i it 's like the high mismatch of the speechdat car after cleaning up , having more noise than the training set of timit after clean s after you do the noise clean up . earlier you never had any compensation , you just trained it straight away . it had like all these different conditions of s n rs , actually in their training set of neural net . but after cleaning up you have now a different set of s n rs , right ? for the training of the neural net . and is it something to do with the mismatch that 's created after the cleaning up , like the high mismatch  of that the snr after the noise compensation of the speechdat car .    now the after noise compensation the neural net is seeing a different set of s n rs than that was originally there in the training set . of timit . because in the timit it was zero to some clean . the net saw all the snr @ @ conditions . now after cleaning up it 's a different set of snr . and that snr may not be com covering the whole set of s n rs that you 're getting in the speechdat car .  it is . but , i 'm saying , there could be some issues of on the test set ,    i i don't know . that could be seen from the ti digits , testing condition because , the noises are from the ti digits , right ? noise cleaning up the ti digits and if the performance goes down in the ti digits mismatch high mismatch like this on a clean training , or zero db testing .  then it 's something to do .  "" babble . "" "" street "" or "" airport "" or "" train station "" .  it will overall it will be still better even if it is fifteen percent worse , because the fifteen percent worse is given like f w twenty five point two five eight . is it like ","cuz they have , already frozen those in i insertion penalties and all those is what i feel . and they have these tables with , various language model weights , insertion penalties . it was just the noisy features ",
Bro027.D,"it 's four . is i either it 'll get cancelled out , or you 'll get almost the same . slightly bad .    this lda is different from the lda that you are talking about . the lda that you saying is you take a block of features , like nine frames and then do an lda on it , and then reduce the dimensionality to something like twenty four like that . and then feed it to this is like a two d two dimensional tile . this is a two dimensional tile . and the lda that we are f applying is only in time , not in frequency high cost frequency . it 's like more like a filtering in time , rather than doing a r it m  i 've been exploring a parallel vad without neural network with less latency using snr and energy , after the cleaning up . what i 'd been trying was ,  after the b after the noise compensation , n i was trying t to f find a f feature based on the ratio of the energies , that is , cl after clean and before clean . that if they are pretty c close to one , which means it 's speech . and if it is n if it is close to zero , which is it 's like a scale @ @ probability value . was trying , with full band and multiple bands , m ps separating them to different frequency bands and deriving separate decisions on each bands , and trying to combine them .  the advantage being like it doesn't have the latency of the neural net if it can g and it gave me like , one point one more than one percent relative improvement . from fifty three point six it went to fifty f four point eight . it 's only slightly more than a percent improvement , just like which means that it 's doing a slightly better job than the previous vad , at a l lower delay .    it still has the median filter .   with the delay , that 's gone is the input , which is the sixty millisecond . the forty plus twenty . at the input of the neural net you have this , f nine frames of context plus the delta .  that delay , plus the lda . the delay is only the forty millisecond of the noise cleaning , plus the hundred millisecond smoothing at the output .   the di the biggest the problem f for me was to find a consistent threshold that works across the different databases , because i t i try to make it work on tr speechdat car and it fails on ti digits , or if i try to make it work on that it 's just the italian it doesn't work on the finnish .   there are there was some problem in balancing the deletions and insertions when i try different thresholds .  the i 'm still trying to make it better by using some other features from the after the p clean up some , correlation auto correlation or some s additional features of to mainly the improvement of the vad . i 've been trying .     that 's the  we 've been thinking about putting it into the neural net also . because they did that itself there 's a threshold and  that 's ,   put the second stream in place and , ran one experiment , but just like just to know that everything is fine . it was like , forty five cepstrum plus twenty three mel log mel . and , just it gave me the baseline performance of the aurora , which is like zero improvement . just tried it on italian just to know that everything is but i didn't export anything out of it because it was weird feature set .   the other thing i was wondering was , if the neural net , has any because of the different noise con unseen noise conditions for the neural net , where you train it on those four noise conditions , while you are feeding it with additional some four plus some f few more conditions which it hasn't seen , actually , from the f while testing .  instead of just h having c those cleaned up t cepstrum , sh should we feed some additional information , like the we have the vad flag . should we f feed the vad flag , also , at the input that it has some additional discriminating information at the input ? we have the vad information also available at the back end . if it is something the neural net is not able to discriminate the classes  because most of it is sil we have dropped some silence f we have dropped silence frames ? no , we haven't dropped silence frames still .   the b biggest classification would be the speech and silence . by having an additional , feature which says "" this is speech and this is nonspeech "" , it certainly helps in some unseen noise conditions for the neural net . we have we are transferring the vad to the back end feature to the back end . because we are dropping it at the back end after everything all the features are computed .  the neural that is coming from a separate neural net or some vad . which is certainly giving a to it 's an additional discriminating information . that  through t to the soft max . speech . it may not be it  it may be too it 's too high in a sense everything is more like a , flat probability . it 's not really doing any distinction between speech and nonspeech or , different among classes .   we w we don't have it , actually , because it 's it has a high rate energy the vad has a somewhere around sixty , must be . ","this lda is different from the lda that you are talking about . the lda that you saying is you take a block of features , like nine frames and then do an lda on it , and then reduce the dimensionality to something like twenty four like that . this is a two dimensional tile . and the lda that we are f applying is only in time , it 's like more like a filtering in time , the other thing i was wondering was , if the neural net , has any because of the different noise con unseen noise conditions for the neural net , where you train it on those four noise conditions , while you are feeding it with additional some four plus some f few more conditions which it hasn't seen , actually , instead of just h having c those cleaned up t cepstrum , sh should we feed some additional information , like the should we f feed the vad flag , also , at the input that it has some additional discriminating information at the input ? we have the vad information also available at the back end . if it is something the neural net is not able to discriminate the classes by having an additional , feature which says "" this is speech and this is nonspeech "" , it certainly helps in some unseen noise conditions for the neural net . it 's an additional discriminating information . ","The group discussed possible further investigations that arose from these areas, including better linking the two. "
Bro027.D,"right ?    thirty first , august . p s it 's like it 's tentatively all full .  that 's a proposed date , ",,
