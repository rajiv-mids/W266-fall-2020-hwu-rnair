meeting,original,extractive,abstractive
Bed004.A,"hey , you 're not supposed to be drinking in here dude . do we have to read them that slowly ?  sounded like a robot . this is t when you read the numbers it reminded me of beat poetry . three six zero . four two zero one seven . that 's what of when of beat poetry . you ever seen "" married an axe murderer "" ? there 's a part wh there 's parts when he 's doing beat poetry . and he talks like that . that 's why i thi that probably is why of it that way . mike meyers is the guy . it 's his it 's his cute romantic comedy . that 's that 's that 's his cute romantic comedy , the other thing that 's real funny , i 'll spoil it for you . is when he 's he works in a coffee shop , in san francisco , and he 's sitting there on this couch and they bring him this massive cup of espresso , and he 's like "" excuse me i ordered the large espresso ? ""  do are y you 're trying to decide who 's the best taster of tiramisu ?   seems like seems like you could put a s magic special ingredient in , that everyone know which one was yours . then , if you were to bribe them , you could i 'm going back to visit my parents this weekend , i 'll be out of town . no , the south bay ,  we are . is nancy s gonna show up ?  wonder if these things ever emit a very piercing screech right in your ear ? is she mispronouncing "" anlage "" ? is it "" anlaga "" or "" anlunga ""  yes . i wasn't whether wizard was the correct term for not a man "" . are you that 's @ . what i did for this is a pedagogical belief net because i was i took i tried to conceptually do what you were talking about with the nodes that you could expand out what i did was i took i made these dummy nodes called trajector in and trajector out that would isolate the things related to the trajector . and then there were the things with the source and the path and the goal . and i separated them out . and then i did similar things for our net to with the context and the discourse and whatnot , we could isolate them or whatever in terms of the top layer . and then the bottom layer is just the mode .  there 's just one more node and it says "" mode "" which is the decision between the all i did was i took the last belief net and i grouped things according to what how they would fit in to image schemas that would be related . ",what i did for this is a pedagogical belief net all i did was i took the last belief net and i grouped things according to what how they would fit in to image schemas that would be related . ,"It is not a working net yet, but identifying clusters of features that define the output mode provides a visual aid for further work. "
Bed004.A,"and the two that i came up with were trajector landmark and then source path goal as initial ones . and then i said the trajector would be the person in this case probably . we have the concept of what their intention was , whether they were trying to tour or do business or whatever , or they were hurried . that 's related to that . and then in terms of the source , the things the only things that we had on there i believe were whether actually , i i might have added these cuz i don't think we talked too much about the source in the old one but whether the where i 'm currently at is a landmark might have a bearing on whether or the "" landmark iness "" of where i 'm currently at . and "" usefulness "" is basi means is that an institutional facility like a town hall like that 's not something that you 'd visit for tourist 's tourism 's sake or whatever . "" travel constraints "" would be something like they said they can they only wanna take a bus like that , right ? and then those are somewhat related to the path , that would determine whether we 'd could take we would be telling them to go to the bus stop or versus walking there directly . "" goal "" . similar things as the source except they also added whether the entity was closed and whether they have somehow marked that is was the final destination . and then if you go up , robert , in terms of context , what we had currently said was whether they were a businessman or a tourist of some other person . discourse was related to whether they had asked about open hours or whether they asked about where the entrance was or the admission fee , along those lines . prosody i don't really i 'm not really what prosody means , in this context , just made up whether what they say is or h how they say it is that . the parse would be what verb they chose , and then how they modified it , in the sense of whether they said "" i need to get there quickly "" or whatever . and in terms of world knowledge , this would just be like opening and closing times of things , the time of day it is , and whatnot . tourbook ? that would be , i don't know , the "" landmark iness "" of things , whether it 's in the tourbook or not . this is not a working bayes net .  say what you were gonna say .  'd no , i was gonna until we 'd have to get rid of this and connect these things directly to the mode . cuz i don't understand how it would work otherwise . unders i understand that , ","and the two that i came up with were trajector landmark and then source path goal as initial ones . we have the concept of what their intention was , whether they were trying to tour or do business or whatever , or they were hurried . that 's related to that . in terms of context , what we had currently said was whether they were a businessman or a tourist of some other person . discourse was related to whether they had asked about open hours prosody i don't really i 'm not really what prosody means , in this context , the parse would be what verb they chose , and in terms of world knowledge , this would just be like opening and closing times of things , the time of day it is , and whatnot . this is not a working bayes net . ","It is not a working net yet, but identifying clusters of features that define the output mode provides a visual aid for further work. "
Bed004.A,"it 's hard for me to imagine how he could get around that .   it 's possible that we could do something like a summary node of some sort that  in that case , the sum we 'd have we these wouldn't be the summary nodes . we 'd have the summary nodes like where the things were if thi if things were related to business or some other     what i need to do is to take this one and the old one and merge them together ? that   we could actually , y draw it in a different way , in the sense that it would make it more abstract . right . this is what we 'd be generating would be a reference to a semantic like parameters for the x schema ?  right .  right . the immediate problem is just deciding w which  right and then , once we 've made the decision , how do we put that into the content ?   there 's just too many factors right now . right . what we really wanna do i cuz this is really just the three layer net , we wanna b make it expand it out into more layers right . instead of in instead it should really be just be "" intention "" as a node instead of "" intention business "" or "" intention tour "" . right . right . what was going through my mind when i did it was someone could both have a business intention and a touring intention and the probabilities of both of them happening at the same time   see i don't think those would be mutually it seems like something could both be  ",it 's hard for me to imagine how he could get around that . the immediate problem is just deciding w which ,
Bed004.B," are you trying to record this meeting ? s if you just number them "" one "" , "" two "" , "" three "" it 's  right .  true .  great .  right . right . right .   great . first of all , i agree that we should hire fey , and start paying her . probably pay for the time she 's put in as do exactly how to do that , or is lila what exactly do we do to put her on the payroll in some way ?  you 'll have to . right . anyway ,  why don't you ask lila and see what she says about exactly what we do for someone in th she 's un she 's not a student , she just graduated but anyway . if i agree , she sounded fine , she a actually was more present and than she was in conversation , she did a better job than i would have guessed from just talking to her . think that 's great .  right .  and then as she does it she 'll learn @ @ . that 's great . and also if she 's willing to take on the job of organizing all those subjects and that would be wonderful . and , she 's actually she 's going to graduate school in a an experimental paradigm , think this is all just fine in terms of h her learning things she 's gonna need to know to do her career . i my guess is she 'll be r quite happy to take on that job . and , great . as i say there is this s set of people next door , it 's not hard to   we could talk to the people who run it and see if they have a way that they could easily tell people that there 's a task , pays ten bucks but you have to be comfortable reading relatively complicated and there 'll probably be self selection to some extent . that 's good . now , i signed us up for the wednesday slot , and part of what we should do is this .  my idea on that was partly we 'll talk about system for the computer scientists , but partly i did want it to get the linguists involved in some of this issue about what the task is and all what the dialogue is , and what 's going on linguistically , because to the extent that we can get them contributing , that will be good . this issue about re formulating things , we can get some of the linguists sufficiently interested that they 'll help us with it , other linguists , if you 're a linguist , but in any case , the linguistics students and my idea on wednesday is partly to you what you did today would i is just fine . ","s if you just number them "" one "" , "" two "" , "" three "" it 's and also if she 's willing to take on the job of organizing all those subjects and that would be wonderful . we could talk to the people who run it and see if they have a way that they could easily tell people that there 's a task , pays ten bucks but you have to be comfortable reading relatively complicated now , i signed us up for the wednesday slot , and part of what we should do is this . my idea on that was partly we 'll talk about system for the computer scientists , but partly i did want it to get the linguists involved in some of this issue about what the task is and all what the dialogue is , and what 's going on linguistically , because to the extent that we can get them contributing , that will be good . ","The group decided to hire the ""wizard"" and continue with the refinement of the design and recruitment of subjects. "
Bed004.B,"you just do "" this is what we did , and here 's the thing , and here 's some of the dialogue and forth . "" but then , the other thing is we should give the computer scientists some idea of what 's going on with the system design , and where we think the belief nets fit in and where the pieces are and like that . is this make sense to everybody ?  i don't think it 's worth a lot of work , particularly on your part , to make a big presentation . i don't think you should you don't have to make any new powerpoint or anything . we got plenty of to talk about . and , then just see how a discussion goes . great .    let 's let 's i don't understand it . let 's go slide all the way up we see what the p very bottom looks like , or is that it ? great . alright .     right ,  right .   right ,  ch ch . now . alright , understand what 's what you got . i don't yet understand how you would use it . let me see if ask a s right . no , i understand that , but what let 's slide back up again and see start at the bottom and oop bo doop boop .  you could imagine w go ahead , you were about to go up there and point to something . good , do it ! no , go do it .  if you if we made if we wanted to make it into a real bayes net , that is , with fill actually f fill it @ @ in , then i don't that 's an issue .  here 's the problem . and bhaskara and i was talking about this a little earlier today is , if we just do this , we could wind up with a huge combinatoric input to the mode thing . and i but that 's what we have to do .   there are a variety of ways of doing it . let me just mention something that i don't want to pursue today which is there are technical ways of doing it , slipped a paper to bhaskara and about noisy or 's and noisy maxes and there 're ways to back off on the purity of your bayes net edness . if you co you could ima and i now i don't know that any of those actually apply in this case , but there is some technology you could try to apply .   and ,   what i was gonna say is good at this point is to try to informally not necessarily in th in this meeting , but to try to informally think about what the decision variables are . if you have some bottom line decision about which mode , what are the most relevant things . ","you just do "" this is what we did , and here 's the thing , and here 's some of the dialogue and forth . "" is , if we just do this , we could wind up with a huge combinatoric input to the mode thing . which is there are technical ways of doing it , slipped a paper to bhaskara and about noisy or 's and noisy maxes not necessarily in th in this meeting , but to try to informally think about what the decision variables are . what are the most relevant things . ",There are potential problems from a combinatorics perspective. These can be tackled either with technical adjustments or through careful knowledge engineering. 
Bed004.B,"and the other trick , which is not a technical trick , it 's knowledge engineering trick , is to make the n each node sufficiently narrow that you don't get this combinatorics . that if you decided that you could characterize the decision as a trade off between three factors , whatever they may be ,  then you could say "" aha , let 's have these three factors "" ,  and binary version f for each , or some relatively compact decision node just above the final one . and then the question would be if those are the things that you care about , can you make a relatively compact way of getting from the various inputs to the things you care about . that y that , you can try to do a knowledge engineering thing given that we 're not gonna screw with the technology and just always use orthodox bayes nets , then we have a knowledge engineering little problem of how do we do that .  and   something . robert has thought about this problem f for a long time , cuz he 's had these examples kicking around , he may have some good intuition about what are the crucial things . and , i understand where this the this is a way of playing with this abs source path goal trajector exp abstraction and sh displaying it in a particular way . i don't think our friends on wednesday are going to be able to they will . let me think about whether we can present this to them or not .   alright , le let me think about this some more , and see if we can find a way to present this to this linguists group that is helpful to them .   good . i 'm you 're you 're it was much too quick for me . let me see if i understand what you 're saying . i do understand that you can take the m three l and add not and it w and you need to do this , for we have to add , not too much about object types and and what you did is add some rules of the style that are already there that say "" if it 's of type "" landmark "" , then you take you 're gonna take a picture of it . "" f full stop , that 's what you do . ev every landmark you take a picture of , you enter you approach .  and certainly you can add rules like that to the existing smartkom system . and you just did , right ?   s and let 's think about this . that 's a that 's another baseline case , that 's another thing "" here 's a another minimal way of tackling this "" . add extra properties , a deterministic rule for every property you have an action , "" pppt ! "" you do that . ","and the other trick , which is not a technical trick , it 's knowledge engineering trick , is to make the n each node sufficiently narrow that you don't get this combinatorics . and then the question would be if those are the things that you care about , can you make a relatively compact way of getting from the various inputs to the things you care about . alright , le let me think about this some more , and see if we can find a way to present this to this linguists group that is helpful to them . i do understand that you can take the m three l and add not and it w we have to add , not too much about object types and and what you did is add some rules of the style that are already there that say "" if it 's of type "" landmark "" , then you take you 're gonna take a picture of it . "" that 's another thing "" here 's a another minimal way of tackling this "" . add extra properties , a deterministic rule for every property ",These can be tackled either with technical adjustments or through careful knowledge engineering. A base solution for the task would be to simply add some extra action-mode rules in the SmartKom system. 
Bed004.B,"then the question would be now , if that 's all you 're doing , then you can get the types from the ontology ,  because that 's all you 're using is this type the types in the ontology and you 're done . right ? we don't use the discourse , we don't use the context , we don't do any of those things . alright , but that 's and it 's again a one minimal extension of the existing things . and that 's something the smartkom people themselves would they 'd say "" that 's no problem no problem to add types to the ont "" right ?    "" approach "" , you called it , this time . that 's what you said that 's fine . but right . but it 's not construction there , it 's action . construction is a d is a different story . for for yes .  that i if you had the generalized "" go "" x schema and you wanted to specialize it to these three ones , then you would have to supply the parameters . and then although we haven't worried about this yet , you might wanna worry about something that would go to the gis and use that to actually get detailed route planning . where do you do take a picture of it and like that . but that 's not it 's not the immediate problem . but , presumably that functionality 's there when we the pro the immediate problem is back t to what you were what you are doing with the belief net . what are we going to use to make this decision  right . right . that actually is relatively easy in this case . the harder problem is we decide what we want to use , how are we gonna get it ? and that the that 's the hardest problem . the hardest problem is how are you going to get this information from some combination of the what the person says and the context and the ontology . the h that 's the hardest problem at the moment is where are you gonna how are you gonna g get this information .  and that 's getting back to here , we have a d a technical problem with the belief nets that we don't want all the com too many factors if we allow them to just go combinatorially . we wanna think about which ones we really care about and what they really most depend on , and can we c clean this up to the point where it right . we might . that 's certainly one thing we can do . it 's true that the way you have this , a lot of the times you have what you 're having is the values rather than the variable .   you  right , ","i if you had the generalized "" go "" x schema and you wanted to specialize it to these three ones , then you would have to supply the parameters . what are we going to use to make this decision the harder problem is we decide what we want to use , how are we gonna get it ? we have a d a technical problem with the belief nets that we don't want all the com too many factors if we allow them to just go combinatorially . ",There are potential problems from a combinatorics perspective. 
Bed004.B,"and then it would have values , "" tour "" , "" business "" , or hurried "" . but then but i it still some knowledge design to do , about i how do you wanna break this up , what really matters . it 's fine . we have to it 's iterative . we 're gonna have to work with it some . you could do that . and it 's perfectly to insist that , th they add up to one , but that there 's that it doesn't have to be one zero .  you could have the conditional p  the each of these things is gonna be a probability . whenever there 's a choice ,  like landmark ness and usefulness ,  right . and that you might want to then have those b th then they may have to be separate . they may not be able to be values of the same variable . that 's but again , this is the knowledge design you have to go through . right . it 's it 's great is , as one step toward toward where we wanna go .   that 's exactly right . there will be rules , but they aren't rules that come to final decisions , they 're rules that gather information for a decision process .  no that 's just fine .  they 'll they presumably there 'll be a thread or process that "" agent "" , "" agent "" , whatever you wan wanna say , that is rule driven , and can can do things like that . and there 's an issue about whether there will be that 'll be the same agent and the one that then goes off and carries out the decision , it probably will . my guess is it 'll be the same basic agent that can go off and get information , run it through a c this belief net that turn a crank in the belief net , that 'll come out with s more another vector ,  which can then be applied at what we would call the simulation or action end . you now you 're gonna do and that may actually involve getting more information . on once you pull that out , it could be that says "" now that we know that we gonna go ask the ontology something else . ""  now that we know that it 's a bus trip ,  we didn't need to know beforehand , how long the bus trip takes or whatever , but now that we know that 's the way it 's coming out then we gotta go find out more . think that 's    i confess , i 'm still not completely comfortable with the overall story .  i i this is not a complaint , this is a promise to do more work . 'm gonna hafta think about it some more . in particular ","there will be rules , but they aren't rules that come to final decisions , they 're rules that gather information for a decision process . my guess is it 'll be the same basic agent that can go off and get information , run it through a c this belief net that which can then be applied at what we would call the simulation or action end . and that may actually involve getting more information . ",
Bed004.B,"see what we 'd like to do , and this has been implicit in the discussion , is to do this in such a way that you get a lot of re use . what you 're trying to get out of this deep co cognitive linguistics is the fact that w if about source , paths and goals , and nnn all this that a lot of this is the same , for different tasks . and that there 's some important generalities that you 're getting , that you don't take each and every one of these tasks and hafta re do it . and i don't yet see how that goes . alright . u what are the primitives , and how do you break this y i 'm just there saying eee you i know how to do any individual case , right ? but i don't yet see what 's the really interesting question is can you use deep cognitive linguistics to get powerful generalizations . and  could .  i don't like the term either , have n i  i y w i it could be . i 'm not a i 'm not op particularly opposed to adding that or any other task , eventually we 're gonna want a whole range of them .  i 'm just saying that i 'm gonna hafta do some first principles thinking about this . at the moment don't know . h no . no the bayes nets the bayes nets will be dec specific for each decision . but what i 'd like to be able to do is to have the way that you extract properties , that will go into different bayes nets , be the general . that if you have sources , you have trajectors and like that , and there 's a language for talking about trajectors , you shouldn't have to do that differently for going to something , than for circling it , for telling someone else how to go there , whatever it is . that , the decision processes are gonna be different what you 'd really like is the same thing you 'd always like which is that you have intermediate representation which looks the same o over a bunch of inputs and a bunch of outputs . all sorts of different tasks and all sorts of different ways of expressing them use a lot of the same mechanism for pulling out what are the fundamental things going on . and that 's that would be the really pretty result . and pushing it one step further , when you get to construction grammar and what you 'd like to be able to do is say you have this parser which is much fancier than the parser that comes with smartkom , i that actually uses constructions and is able to tell from this construction that there 's something about the intent the actual what people wanna do or what they 're referring to and ","what you 're trying to get out of this deep co cognitive linguistics is the fact that w if about source , paths and goals , and nnn all this that a lot of this is the same , for different tasks . and that there 's some important generalities that you 're getting , and i don't yet see how that goes . but what i 'd like to be able to do is to have the way that you extract properties , that will go into different bayes nets , be the general . that if you have sources , you have trajectors and like that , you shouldn't have to do that differently for going to something , than for circling it , for telling someone else how to go there , what you 'd really like is the same thing you 'd always like which is that you have intermediate representation which looks the same o over a bunch of inputs and a bunch of outputs . ","For instance, the final combination of features used in the current study may form a representation of the ontology, general enough to employ in any task that includes trajectors and paths. "
Bed004.B,"in independent of whether it about what is this or where is it that you could tell from the construction , you could pull out deep semantic information which you 're gonna use in a general way . that 's the you might . you might . you might be able to say that this i this is the construction in which the there 's let 's say there 's a cont there the land the construction implies the there 's a con this thing is being viewed as a container .  just from this local construction that you 're gonna hafta treat it as a container you might as go off and get that information . and that may effect the way you process everything else . if you say "" how do i get into the castle ""  then or , "" what is there in the castle "" or there 's all sorts of things you might ask that involve the castle as a container and you 'd like to have this orthogonal that anytime the castle 's referred to as a container , you crank up the appropriate independent of what the goal is , and independent of what the surrounding language is . alright , that 's the that 's the thesis level  you have prepositional phrases that right . right . right . are we gonna be meeting here from now on ? i 'm happy to do that . we had talked about it , cuz you have th the display and everything , that seems fine . right .  no it 's worth it to ass to meet here to bring this , and assume that something may come up that we wanna look at . why not . she was good . litonya was good . right . right . and and she took it and l no , it was great .  click ? alright . ",,
Bed004.C," beat poetry . parts of it .  i should be free ,    because of l all the names , can i have a question . there 's no system , right ? like , there was a wizard for both both parts , is this right ?   and she didn't  isn't this obvious when it says "" now you 're talking to a human "" and then the human has the same voice ?  really ? it 's surprising . say exactly what 's on there ?  there 's no female equivalent of no , i don't know . not that i know of . that 's what i was thinking , but  right . right . that 's right . right . right .   ","like , there was a wizard for both both parts , ",
Bed004.D," i tried to go for the ee cummings feeling , but   no , i didn't see that movie . who did who made that ?   we 're having , a tiramisu tasting contest this weekend . no ? there was a fierce argument that broke out over whose tiramisu might be the best and we decided to have a contest where those people who claim to make good tiramisu make them , and then we got a panel of impartial judges that will taste do a blind taste and then vote . should be fun .  i was thinking if y you guys have plans for sunday ? we 're not it 's probably going to be this sunday , but we 're working with the weather here because we also want to combine it with some barbecue activity where we just fire it up and what whoever brings whatever can throw it on there . only the tiramisu is free , nothing else . you 're going to the west bay then ? no , south bay ? south bay . i 'll let they are gonna get more comfortable headsets . they already ordered them .  let 's get started . the should i go first , with the data . can i have the remote control .   on friday we had our wizard test data test and these are some of the results . this was the introduction . i actually even though liz was kind enough to offer to be the first subject , i felt that she knew too much , asked litonya . just on the spur of the moment , and she was kind enough to serve as the first subject . this is what she saw as part of as for instr introduction , this is what she had to read aloud . that was really difficult for her and the names and this was the first three tasks she had to master after she called the system , and then the system broke down , and those were the l i should say the system was supposed to break down and then these were the remaining three tasks that she was going to solve , with a human  there are here are the results .  and i will not we will skip the reading now . d and the reading was five minutes , exactly . and now comes the this is the phone in phase of  it was bo it both times the same person . one time , pretending to be a system , one time , to pretending to be a human , which is actually not pretending . i should no no . we u good question , but you just and see . it 's you 're gonna l learn . and the wizard sometimes will not be audible , because she was actually they there was some lapse in the wireless , we have to move her closer . they 're mispronouncing everything , but it 's ","on friday we had our wizard test data test and these are some of the results . this is what she had to read aloud . this was the first three tasks she had to master after she called the system , i should say the system was supposed to break down and then these were the remaining three tasks that she was going to solve , with a human the reading was five minutes , exactly . one time , pretending to be a system , one time , to pretending to be a human , which is actually not pretending . ",A test run of the data collection design was very successful. 
Bed004.D,"this is the system breaking down , actually . "" did i call europe ? "" this is it . if we there was a strange reflex . i have a headache . i 'm really out of it . the lessons learned . the reading needs to be shorter . five minutes is just too long . that was already anticipated by some people suggested that if we just have bullets here , they 're gonna not they 're subjects are probably not gonna going to follow the order . and she did not . she no . she jumped around quite a bit . and make it clear in the we need to that 's one thing . and we need a better introduction for the wizard . that is something that fey actually thought of a in the last second that sh the system should introduce itself , when it 's called . and another suggestion , by liz , was that we through subjects , switch the tasks . when they have task one with the computer , the next person should have task one with a human , and forth . we get data for that . we have to refine the tasks more and more , which we haven't done far , in order to avoid this rephrasing , where , even though w we don't tell the person "" ask blah blah "" they still try , or at least litonya tried to repeat as much of that text as possible . and my suggestion is we keep the wizard , because she did a wonderful job , in the sense that she responded quite nicely to things that were not asked for , "" how much is a t a bus ticket and a transfer "" this is gonna happen all the time , we d you can never be johno pointed out that we have grammatical gender problem there with wizard .  but there is witch and warlock , and  and some work needs to be done , but we can and this , and in case no you hadn't seen it , this is what litonya looked at during the while taking the while partaking in the data collection . i 'm completely clueless , but i 'm willing to learn . n student type worker , or ?   this is what i gave her , this is how to get to the student prison , and i didn't even spell it out here and in some cases i spelled it out a little bit more thoroughly , this is the information on the low sunken castle , and the amphitheater that never came up , and if we give her even more instruments to work with the results are gonna be even better .    she didn't explicitly state that  and told her that we gonna figure out a meeting time in the near future to refine the tasks and s look for the potential sources to find people . ","five minutes is just too long . that was already anticipated by some people suggested that if we just have bullets here , they 're gonna not they 're subjects are probably not gonna going to follow the order . she jumped around quite a bit . that is something that fey actually thought of a in the last second that sh the system should introduce itself , when it 's called . and another suggestion , by liz , was that we through subjects , switch the tasks . when they have task one with the computer , the next person should have task one with a human , and forth . we have to refine the tasks more and more , which we haven't done far , in order to avoid this rephrasing , and my suggestion is we keep the wizard , because she did a wonderful job , and told her that we gonna figure out a meeting time in the near future to refine the tasks and s look for the potential sources to find people . ","The group decided to hire the ""wizard"" and continue with the refinement of the design and recruitment of subjects. "
Bed004.D,"she also agrees that if it 's all just gonna be students the data is gonna be less valuable because of that  we 're already  however , we may run into a problem with a reading task there . and we 'll see .          sounds good . the other two things is we 've can have johno tell us a little about this and we also have a l little bit on the interface , m three l enhancement , and then that was it ,   what 's "" tourbook "" ?  this is still , ad hoc . this is th the second version and i look at this just as a , a whatever , uml diagram or , as just a screen shot , not really as a bayes net as john johno said .  but the that it just is a visual aid for thinking about these things which has comple clearly have to be specified m more carefully and ultimately we may w we regard this as an exercise in thinking about the problem and first version of module , if you wanna call it that , that you can ask , that you can give input and it 'll throw the dice for you , throw the die for you , because integrated this into the existing smartkom system in the same way as much the same way we can have this this thing . close this down . if this is what m three l will look like and what it 'll give us ,  and a very simple thing . we have an action that he wants to go from somewhere , which is some type of object , to someplace . and this these this changed now only it 's doing it twice now because it already did it once . we 'll add some action type , which in this case is "" approach "" and could be , more refined in many ways . or we can have something where the goal is a public place and it will give us then an action type of the type "" enter "" . this is just based on this one on this one feature , and that 's about all you can do . and in the f if this pla if the object type here is a m is a landmark , it 'll be vista "" . and this is about as much as we can do if we don't w if we want to avoid huge combinatorial explosion where we specify "" if it 's this and this but that is not the case "" , and forth , it just gets really messy .  exactly . every public place you enter , and statue you want to go as near as possible .  and it would do us no good . that ultimately . w  no .  no . and this is just in order to exemplify what we can do very , very easily is , ",she also agrees that if it 's all just gonna be students the data is gonna be less valuable because of that but the that it just is a visual aid for thinking about these things which has comple clearly have to be specified m more carefully because integrated this into the existing smartkom system in the same way as much the same way we can have this this thing . and it would do us no good . ,"It is not a working net yet, but identifying clusters of features that define the output mode provides a visual aid for further work. "
Bed004.D,"we have this silly interface and we have the rules that are as banal as of we just saw , and we have our content . now , the content i whi which is what we see here , which is the vista , schema , source , path , goal , whatever . this will be job to find ways of writing down image schema , x schema , constructions , in some form , and have this be in a in the content , loosely called "" constructicon "" . and the rules we want to throw away completely . and and here is exactly where what 's gonna be replaced with our bayes net , which is exactly getting the input feeding into here . this decides whether it 's an whether action the enter , the vista , or the whatever approach construction should be activated , ie just pasted in .  aspects of the x schema to add . object type ,  also it strikes me that we m may want to approach the point where we can try to find a a specification for some interface , here that takes the normal m three l , looks at it . then we discussed in our pre edu meeting how to ask the ontology , what to ask the ontology the fact that we can pretend we have one , make a dummy until we get the real one , and we may wanna decide we can do this from here , but we also could do it if we have a belief net interface . the belief net takes as input , a vector , right ? of and it  and it output is whatever , as but this information is just m three l , and then we want to look up some more in the ontology and we want to look up some more in the we want to ask the real world , you want to look something up in the grs , but also we definitely want to look up in the dialogue history some s some based on we have i was just made some examples from the ontology and we have some information there that the town hall is both a building and it has doors and like this , but it is also an institution , it has a mayor and forth and we get relations out of it and once we have them , we can use that information to look in the dialogue history , "" were any of these things that are part of the town hall as an institution mentioned ? "" , "" were any of these that make the town hall a building mentioned ? "" , and forth , and draw some inferences on that . this may be a process of two to three steps before we get our vector , that we feed into the belief net , and then    ","and the rules we want to throw away completely . and and here is exactly where what 's gonna be replaced with our bayes net , aspects of the x schema to add . the belief net takes as input , a vector , and then we want to look up some more in the ontology we want to ask the real world , you want to look something up in the grs , but also we definitely want to look up in the dialogue history some s some this may be a process of two to three steps before we get our vector , that we feed into the belief net , ","Action modes, however, can be inferred more efficiently by feeding a collection of features -from the ontology, discourse history, parsing, etc.- into Bayes-nets that would replace those rules. "
Bed004.D,"this is actually , s if we were to build something that is and , i had one more thing , the it needs to do  we come up with a code for a module that we call the "" cognitive dispatcher "" , which does nothing , but it looks of complect object trees and decides how are there parts missing that need to be filled out , there 's this is something that this module can do , something that this module can do and then collect sub objects and then recombine them and put them together . this is actually some useful tool that we can use to rewrite it , and get this part , then .  there 're no primitives upon which   we sho should we a add then the "" what 's this ? "" domain ? n we have to "" how do i get to x "" . then we also have the "" what 's this ? "" domain , where we get some slightly different johno , actually , does not allow us to call them "" intentions "" anymore . he dislikes the term . but i 'm the "" what 's this ? "" questions also create some interesting x schema aspects .    getting out of   it 's unfortunate also that english has got rid of most of its spatial adverbs because they 're really fancy then , in for these kinds of analysis . but but they 're easier for parsers . parsers can pick those up but the with the spatial adverbs , they have a tough time . because the mean the semantics are very complex in that .  i had one more thing . i don't remember . forgot it again . no .  b but an architecture like this would also enable us to throw this away and replace it with something else , or whatever , that we have that this is the representational formats we 're we 're talking about that are independent of the problem , that generalize over those problems , and are t of a higher quality than an any actual whatever belief net , or "" x "" that we may use for the decision making , ultimately . should be decoupled ,  liz also asks whether we 're gonna have presentations every time . i don't think we will need to do that but it 's far it was as a visual aid for some things and  and that was my  the she w she was definitely good in the sense that she showed us some of the weaknesses and also the the fact that she was a real subject is  think that mean , w looking just looking at this data , listening to it , what can we get out of it in terms of our problem , is , she actually m said she never s just spoke about entering , she just wanted to get someplace , and she said for buying nuh ? ","we come up with a code for a module that we call the "" cognitive dispatcher "" , which does nothing , but it looks of complect object trees and decides how are there parts missing that need to be filled out , and then collect sub objects and then recombine them and put them together . that we have that this is the representational formats we 're we 're talking about that are independent of the problem , that generalize over those problems , and are t of a higher quality than an any actual whatever belief net , or "" x "" that we may use for the decision making , ultimately . ",
Bed004.D,"this is definitely interesting , and and in the other case , where she wanted to look at the at the graffiti , also , not in the sentence "" how do you get there ? "" was pretty standard . nuh ? except that there was a anaphora , for pointing at what she talked about before , and there she was talking about looking at pictures that are painted inside a wall on walls ,  actually , you 'd need a lot of world knowledge . this would have been a classical tango "" , actually . because graffiti is usually found on the outside and not on the inside , but  the mistake would have make a mistake the system would have made a mistake here . ",,
Bed009.A,"   hi . to meet you .  yes . s   yes , very much yes . yes .  we 're here through sunday ,  all through friday would be fine .  yes .     at eleven ? thursday around eleven ?                 the obvious one would be if you envision this as a module within smartkom , where exactly would that sit ? that 's the d  makes perfect sense . yes . it 's supposed to do .    from my understanding of what the people at phillips were originally trying to do doesn't seem to quite fit into smartkom currently what they 're really doing right now is only selecting among the alternatives , the hypotheses that they 're given enriched by the domain knowledge and the discourse modeler and on . if this is additional information that could be merged in by them . and then it would be available to action planning and others . there 're two levels of giving an answer and on both levels i don't have any further questions . the two levels will be as far as i 'm concerned as standing here for the generation module and the other is my understanding of what smartkom is supposed to be and that fits in perfectly       yes .  yes .     my suggestion then is that you look into the currently ongoing discussion about how the action plans are supposed to look like . and they 're currently agreeing or in the process of agreeing on an x m l ification of something like a state transition network of how dialogues would proceed . and the these transition networks will be what the action planner interprets in a sense . marcus lerkult is actually implementing that and marcus and michael together are leading the discussion there ,   definitely .  yes .  no . no , in smartkom terminology that 's called a function that 's modeled by a function modeler . and it 's th that 's completely encapsulated from th the dialogue system . that 's simply a functionality that you give data as in a query and then you get back from that a functioning model which might be a planner or a vcr or whatever . some result and that 's then used .  in that sense yes , dialogue act ,    clearly . yes .    probably not enough , an another more basic point there is that the current tasks and therefore th the concepts in this ac what 's called the action plan and what 's really the dialogue manager . is based on slots that have to be filled and the values in these slots would be fixed things like the a time or a movie title like this whereas in the a tourist domain it might be an entire route . set based , or even very complex structured information in these slots and i 'm not if complex slots of that type are really being taken into consideration . that 's really something we  nothing 's being completely settled there ",my suggestion then is that you look into the currently ongoing discussion about how the action plans are supposed to look like . and they 're currently agreeing or in the process of agreeing on an x m l ification of something like a state transition network of how dialogues would proceed . what 's called the action plan and what 's really the dialogue manager . is based on slots that have to be filled whereas in the a tourist domain it might be an entire route . and i 'm not if complex slots of that type are really being taken into consideration . ,
Bed009.A,"this is really an ongoing discussion and that 's  yes .   right . yes .  that would b but that that point has been realized and it 's not really been defined yet but there 's gonna be some feedback and input from the action planner into all the analysis modules , telling them what to expect and what the current state of the discourse is . beyond what 's currently being implemented which is just word lists . of special interest . yes , the specifics aren't really there yet . yes . there 's work to do there .   and even on a more basic level the action planner actually needs to be able to have an expressive power that can deal with these structures . and not just say the dialogue will consist of ten possible states and th these states really are fixed in a certain sense . you have to that 'd be it oughta be called a dialogue manager . cuz that 's what everybody else calls it .  depends on who you talk to how . we 'll see . i 'll go check , completely agree .  and this is just for historical reasons within the preparation phase of the project and not because somebody actually believes it ought to be action planner . if there is resistance against changing it , that 's just because "" we don't want to change things . "" that not deep reason  marcus . wh where 's ? he 's he started think january . and he 's gonna be responsible for the implementation of this action planner . dialogue manager . no , no he 's completely gonna rewrite everything . in java . that 's interesting .  no . no , that 's gonna be phased out .     but that doesn't necessarily contradict an architecture where there really is a pers a def defined interface . and  yes  ye think that 's the concept that people have ,  and the underlying idea is that there is something like kernel modules with kernel functionality that you can plug certain applications like tourist information or the home scenario with controlling a vcr and on . and then extend it to an arbitrary number of applications eventually . wouldn't that 's an additional reason to have this defined interface and keep these things like tourist information external . and then call it external services . but the more complex      tubingen was at least involved in putting the chunks together i can't quite recall whether they actually produced the chunks in the first place . or wh right .  you s and especially you did some l was a learning based approach which learned from a big corpus of trees . and yes the it the chunk parser was a finite state machine that mark light originally w worked on in while he was in tuebingen and then somebody else in tuebingen picked that up . it was done in tuebingen ,  definitely . guess it 's similar .  ","it oughta be called a dialogue manager . and he 's gonna be responsible for the implementation of this action planner . no he 's completely gonna rewrite everything . in java . no , that 's gonna be phased out . and the underlying idea is that there is something like kernel modules with kernel functionality that you can plug certain applications like tourist information or the home scenario with controlling a vcr and on . that 's an additional reason to have this defined interface and keep these things like tourist information external . ",
Bed009.A,"n think there 's some misunderstanding here it 's morphix is not used on line . s the lexicon might be derived by morphix but what 's happening on line is just retrieval from the lexicon which would give all the stemming information it would be a full foreign lexicon .   right . think we 're expect there 's the practice talk . that 's what we were planning to do .             and how do you envision the this deep semantic to be worked with . would it be highly ambiguous if and then there would be another module that takes that highly underspecified deep semantic construction and map it onto the current context to find out what the person really was talking about in that context . or a    th             i see , really . alright . ",but what 's happening on line is just retrieval from the lexicon which would give all the stemming information ,
Bed009.B,"   ralf and tilman are here . made it safely .   and the way you do it is you just read the numbers not as each single , just like i do it .  first you read the transcript number . turn . two things we 'll introduce ourselves and what we do . and we already talked with andreas , thilo and david and some lines of code were already written today and almost tested and just gonna say we have again the recognizer to parser thing where we 're working on and that should be no problem and then that can be developed as needed when we get enter the tourism domain . we have talked this morning with the with tilman about the generator . and there one of our diligent workers has to volunteer to look over tilman 's shoulder while he is changing the grammars to english because w we have we face two ways . either we do a syllable concatenating grammar for the english generation which is starting from scratch and doing it the easy way , or we simply adopt the more in depth style that is implemented in the german system and are then able not only to produce strings but also the syntactic parse not parse not the syntactic tree that is underneath in the syntactic structure which is the way we decided we were gonna go because a , it 's easier in the beginning and it does require some knowledge of those grammars and some ling linguistic background . but it shouldn't be a problem for anyone . the ultimate goal is that before they leave we can run through the entire system input through output on at least one or two sample things . and and by virtue of doing that then in this case johno will have acquired the knowledge of how to extend it . ad infinitum . when needed , if needed , when wanted and forth . and also ralf has hooked up with david and you 're gonna continue either all through tonight or tomorrow on whatever to get the er parser interface working . they are thinning out and thickening out lattices and doing this to see what works best . should we already set a date for that ? might be beneficial while we 're all here . thursday morning sounds fine ? neither does thursday morning , no ? he will be in washington , though . but david is here and he 's actually knows everything about the smartkom recognizer .  facing to what we 've been doing here  for one thing we 're also using this room to collect data . not this type of data , no not meeting data but sort our version of a wizard experiment such not like the ones in munich but pretty close to it . the major difference to the munich ones is that we do it via the telephone even though all the recording is done here ","and just gonna say we have again the recognizer to parser thing where we 're working on and then that can be developed as needed when we get enter the tourism domain . either we do a syllable concatenating grammar for the english generation which is starting from scratch and doing it the easy way , or we simply adopt the more in depth style that is implemented in the german system for one thing we 're also using this room to collect data . no not meeting data but sort our version of a wizard experiment such ",The meeting was largely focused on SmartKom's decision making capacity and how to adapt this functionality to the tourist information domain. 
Bed009.B,"and it 's a computer call system that gives you tourist information tells you how to get places . and it breaks halfway through the experiment and a human operator comes on . and part of that is trying to find out whether people change their linguistic verbal behavior when first thinking they speak to a machine and then to a human . and we 're setting it up that we can we hope to implant certain intentions in people . we have first looked at a simple sentence that "" how do i get to the powder tower ? "" you have the castle of heidelberg and there is a tower and it 's called powder tower . and what will you parse out of that sentence ? probably something that we specified in m three l , that is @ @ "" action go to whatever domain , object whatever powder tower "" . and some model will tell us , some gps module , in the mobile scenario where the person is at the moment . and we 've gone through that once before in the deep mail project and we noticed that first of all what are i should 've brought some slides , but what our here 's the tower . think of this as a two dimensional representation of the tower . and our system led people here , to a point where they were facing a wall in front of the tower . there is no entrance there , but it just happens to be the closest point of the road network to the geometric center because that 's how the algorithm works . we took out that part of the road network as a hack and then it found actually the way to the entrance . which was now the closest point of the road network to geometric center . but what we actually observed in heidelberg is that most people when they want to go there they actually don't want to enter , because it 's not really interesting . they wanna go to a completely different point where they can look at it and take a picture . and what s you s let 's say a simple parse from a s from an utterance won't really give us is what the person actually wants . does he wanna go there to see it ? does he wanna go there now ? later ? how does the person wanna go there ? is that person more likely to want to walk there ? walk a scenic route ? and forth . there are all kinds of decisions that we have identified in terms of getting to places and in terms of finding information about things . and we are constructing and then we 've identified more or less the extra linguistic parameters that may f play a role . information related to the user and information related to the situation . ",and it 's a computer call system that gives you tourist information let 's say a simple parse from a s from an utterance won't really give us is what the person actually wants . ,
Bed009.B,"and we also want to look closely on the linguistic information that what we can get from the utterance . that 's part of why we implant these intentions in the data collection to see whether people actually phrase things differently whether they want to enter in order to buy something or whether they just wanna go there to look at it . and the idea is to construct suitable interfaces and a belief net for a module that actually tries to guess what the underlying intention was . and then enrich or augment the m three l structures with what it thought what more it got out of that utterance . if it can make a good suggestion , "" hey ! "" "" that person doesn't wanna enter . that person just wants to take a picture , "" cuz he just bought film , or "" that person wants to enter because he discussed the admission fee before "" . or "" that person wants to enter because he wants to buy something and that you usually do inside of buildings "" and forth . these these types of these bits of additional information are going to be embedded into the m three l structure in an subfield that we have reserved . and if the action planner does something with it , great . if not then that 's also something that we can't really at least we want to offer the extra information . we don't really we 're not too worried . s ultimately if you have if you can offer that information , somebody 's gonna s do something with it sooner or later . that 's part of our belief . right now i know the gis from email is not able to calculate these viewpoints . that 's a functionality that doesn't exist yet to do that dynamically , but if we can offer it that distinction , somebody will go ahead and implement it . surely nobody 's gonna go ahead and implement it if it 's never gonna be used ,  what have i forgotten about ?  how we do it , that 's the far i 've thought of it as adding it onto the modeler knowledge module . this is one that already adds additional information to the but it could sit anywhere in the attention recognition this is what attention recognition literally can     the michael is doing that , right ?     but they have i understood this right ? they govern more or less the dialogue behavior or the action it 's not really what you do with the content of the dialogue but it 's there is this interf i is it   rea   and it might actually  also because again in deep map we have faced and implemented those problems once already we can even shuffle some know how from there to markus and michael . and you don't know th i 'll talk to michael it 's what i do anyway . ",and the idea is to construct suitable interfaces and a belief net for a module that actually tries to guess what the underlying intention was . these these types of these bits of additional information are going to be embedded into the m three l structure in an subfield that we have reserved . far i 've thought of it as adding it onto the modeler knowledge module . ,"The Berkeley Even Deeper Understanding group discussed plans and concerns regarding the architecture of SmartKom, its proposed modules, and the types of interactions expected to take place between modules. "
Bed009.B,"who how far is the the m three l specification for the la natural language input gone on the i haven't seen anything for the tourist path domain . and you are probably also involved in that , right ? together with the usual gang , petra and jan because that 's those are the the true key issues is how does the whatever comes out of the language input pipeline look like and then what the action planner does with it and how that is specified . i didn't think of the internal working of the the action planner and the language the function model as relevant . because what they take is this fixed representation of a of an intention . and that can be as detailed or as crude as you want it to be . but the internal workings of the whether there 're dialogue action planners that work with belief nets that are action planners that work with state automata . that shouldn't really matter too much . it does matter because it does have to keep track of you we are on part six of r a route that consists of eight steps and forth      probably close to impossible . that 's external services .  think just the spatial planner and the route planner i showed you once the interac action between them among them in the deep map system printout of the communication between those two fills up i don't know how many pages and that 's just part of how do i get to one place . it 's really insane . and but this is definitely a good point to get michael into the discussion . or to enter his discussion , actually . that 's the way around . markus is he new in the ? is he gonna continue with the old thing ?  yes i was just that 's my next question whether we 're gonna stick to prolog or not .  but i do think the function modeling concept has a certain makes sense in a certain light because the action planner should not be or the dialogue manager in that case should not have to worry about whether it 's interfacing with something that does route planning in this way or that way  it j and it cant formulate its what it wants in a rather a abstract way , "" find me a good route for this . "" it doesn't really have to worry ab how route planner a or how route planner b actually wants it . this is seemed like a good idea . in the beginning .  a lot of ,   there is another philosophical issue that you can evade but , at least it makes sense to me that sooner or later service is gonna come and describe itself to you . and that 's what srini is working on in the daml project where you find a gis about that gives you information on berkeley , ",the true key issues is how does the whatever comes out of the language input pipeline look like and then what the action planner does with it and how that is specified . think just the spatial planner and the route planner printout of the communication between those two fills up i don't know how many pages whether we 're gonna stick to prolog or not . ,
Bed009.B,"and it 's gonna be there and tell you what it can do and how it wants to do things . and you can actually interface to such a system without ever having met it before and the function modeler and a self description of the external service haggle it out and you can use the same language core , understanding core to interface with planner a , planner b , planner c and forth . which is , utopian completely utopian at the moment , but slowly , getting into the realm of the contingent . but we are facing much more realistic problems . and language input is crucial also when you do the deep understanding analysis that we envision . then the what is it poverty of the stimulus , yet the m the less we get of that the better . and we 're thinking , how much syntactic analysis actually happens already in the parser . and whether one could interface to that potentially  a alan ? the from michael strube , i 've heard very good about the chunk parser that is done by forwiss , which is in embassy doing the parsing . this is came as a surprise to me that embassy s is featuring a parser but it 's what i hear . one could also look at that and see whether there is some synergy possible . and they 're doing chunk parsing and it 's give you the names of the people who do it there . but then there is more ways of parsing things . we threw out all the forms . we threw out all the forms because , english ,  there 's m i 'm there 's gonna be more discussion on that after your talk . we 're just gonna foreshadow what we saw that and first steps . and she 's gonna start in a minute . ",and language input is crucial also when you do the deep understanding analysis that we envision . ,
Bed009.C, testing channel two . two . ,,
Bed009.D,"hello ?  what 's hi .     very much                     no , it 's also a quantrant     it 's not defined yet .   there 's a meeting next week          are there currently is no syntactic analysis but in the next release there will be some . unless and it 's  you can access this  it 's to integrate and syntactic analysis . and add some more features like segmentation . then an utter more than one utterance is there there 's often pause between it and a segmentation occurs .   no it 's think it 's complicated for it 's just one person and have to keep the  and things must be simpler but miel syntactic analysis with finite state transducers . the problem is th that it has to be very fast because if you want to for more than one path anywhere what 's in the latches from the speech recognizer it 's speed is crucial .  and they are not fast enough . and they also have to be very robust . cuz of speech recognition errors and it 's that might , at tuebingen was do something about that ? in tub at  from stuttgart , also    that 's in this direction , yes it 's in this direction .  it would be very interesting ,      i 've looked at it but it 's no not much information available . i found , but it 's also finite state transducers , and and purely finite state transducers are not good for german since there 's the word order is not fixed  also it 's it 's yes , the choice between this processing and that processing and my template matcher . but it 's all in the lexicon . it 's th the information is available .   we can ,  we have knowledge bases from verbmobil system we can use and it  but it 's used for stem forms .  what ?    not yet but it 's planned to do that .  yes .  it 's think it 's yes , it 's possible to do list processing . and this is more adequate for english and in german set processing is used .  some extensions have to be made . for a english version    no . oder there was an talk ?          ",it 's to integrate and syntactic analysis . the problem is th that it has to be very fast and they also have to be very robust . cuz of speech recognition errors we have knowledge bases from verbmobil system we can use some extensions have to be made . for a english version ,
Bed009.E,"two , two . two .    thursday afternoon doesn't work for me , but thursday morning should be fine . i was just thinking i w i will have leavened by eleven . what was he saying ? ",,
Bed009.F," great . great . the what w we h have been doing i they would like us all to read these digits . but we don't all read them but a couple people read them . wanna give them all with german accents today or ?  let 's be done with this .  this is ami , who and this is tilman and ralf . hi .  we 're gonna try to finish by five people who want to can go hear nancy chang 's talk , downstairs . and you guys are g giving talks on tomorrow and wednesday lunch times , right ? that 's great . do y do what we 're gonna do ? that sounds good . johno , are you gonna have some time t to do that with these guys ? cuz y you 're the grammar maven . it makes sense , doesn't it ? good .  that 's probably the right way to do that . and an actually wanna f to find out about it too , but i may not have time to get in . that sounds great . great . you guys enjoy your weekend ? before you got put to work ? great . that 's one branch is to get us caught up on what 's going on . also it would be really to the plans are , in addition to what 's already in code . and we can d  w was there time when we were set up to do that ? it probably will work better if we do it later in the week , after we actually understand better what 's going on . when do you guys leave ?    anyt we 'll find a time later in the week to get together and talk about your understanding of what smartkom plans are . and how we can change them .   what does not work for me is thursday afternoon . do earlier in the day on thursday , or most of the time on friday , not all . wha but , johno , what are your constraints ? eleven ? eleven on thursday ? right . right . this is then out of deference to our non morning people .  and actually we can invite andreas as that 's true . he 's off on his trip already . thilo .  we 'll see if david could make it . that would be good . th no . it 's a good time to pause . i s i see questions on peoples ' faces , why don't let 's let 's hear that 's what it should do . right ,  let 's let 's that w that was one question . is there other things that cuz we wanna not pa pass over any questions or concerns that you have . right . let me s expand on that a little bit from the point of view of the generation . ",anyt we 'll find a time later in the week to get together and talk about your understanding of what smartkom plans are . ,
Bed009.F,"the idea is that we 've actually got this all laid out an and we could show it to you ig robert didn't bring it today but there 's a belief net which is there 's a first cut at a belief net that doesn't it isn't fully instantiated , and in particular some of the combination rules and ways of getting the conditional probabilities aren't there . but we believe that we have laid out the fundamental decisions in this little space and the things that influence them . one of the decisions is what we call this ave thing . do you want to access , view or enter a thing . that 's a discrete decision . there are only three possibilities and the what one would like is for this knowledge modeling module to add which of those it is and give it to the planner . but , th the current design suggests that if it seems to be an important decision and if the belief net is equivocal that it doesn't say that one of these is much more probable than the other , then an option is to go back and ask for the information you want . alright ? now there are two ways one can go a imagine doing that . for the debugging we 'll probably just have a drop down menu and the while you 're debugging you will just  but for a full system , then one might very formulate a query , give it to the dialogue planner and say this , ar are you are you planning to enter ? or whatever it whatever that might be . that 's under that model then , there would be a loop in which this thing would formulate a query , presumably give it to you . that would get expressed and then hopefully you 'd get an answer back . and that would the answer would have to be parsed . right and th that we probably won't do this early on , because the current focus is more on the decision making and like that . but while we 're on the subject wanted to give you a head 's up that it could be that some months from now we said "" we 're now ready to try to close that loop "" in terms of querying about some of these decisions .  d did this robert ? we ha we have to get in on that . because partly those are like x schemas . the transition diagrams . and it may be that we should early on make that they have the flexibility that we need . there 's ac there th the word "" action "" , is what 's ambiguous here . one thing is there 's an actual planner that tells the person in the tourist domain now , per tells the person how to go , "" first go here , first go there take a bus "" , ","one of the decisions is what we call this ave thing . that 's a discrete decision . but , th the current design suggests that if it seems to be an important decision and if the belief net is equivocal that it doesn't say that one of these is much more probable than the other , then an option is to go back and ask for the information you want . we probably won't do this early on , because the current focus is more on the decision making and like that . but while we 're on the subject wanted to give you a head 's up that it could be that some months from now we said "" we 're now ready to try to close that loop "" in terms of querying about some of these decisions . we ha we have to get in on that . ",The meeting was largely focused on SmartKom's decision making capacity and how to adapt this functionality to the tourist information domain. 
Bed009.F,"whatever it is . that 's that form of planning , and action , and a route planner and gis , all but that isn't what  that 's what action he action here means dia speech ac dialogue act .  tha it 's not going to that 's not going to be good enough . i don what what i meant by that . think the idea of having a , transition diagram for the grammar of conversations is a good idea .  and that we do hav definitely have to get in on it and find out but that when when you get to the tourist domain it 's not just an information retrieval system . right ? this i this is where this people are gonna have to think this through a bit more carefully . if it 's only like in the film and t v thing , you can do this . and you just get information and give it to people . but what happens when you actually get them moving and forth and on y your i d the notion of this as a self contained module th the functional module that interacts with where the tourism g is going probably is too restrictive . now how much people have thought ahead to the tourist domain in this   right .  right .  could you put a message into the right place to see if we can at least ask that question ? th there there are a lot of reasons why it matters .  that  the i it 's the action planner is going to take some spec and s make some suggestions about what the user should do . what the user says after that is going to be very much caught up with what the action planner told it . if the parser and the language end doesn't the person 's been told  th it 's you 're making your life much more difficult than it has to be . right ? if someone says the best t to go there is by taxi , let 's say . now the planner comes out and says you wanna get there fast , take a taxi .  and the language end doesn't know that . there 's all sorts of dialogues that won't make any sense which would be just fine .  but this is not the st this is not just the state of the discourse . this is actually the state of the plan . that 's why it z and s it 's great if people are already taking that into account . but one would have t have to see the details .  anyway , robert , that 's why i was thinking that  you 're gonna need we talked about this several times that the input end is gonna need a fair amount of feedback from the planning end . in one of these things which are much more continuous than the just the dialogue over movies and  ",action he action here means dia speech ac dialogue act . when when you get to the tourist domain it 's not just an information retrieval system . people are gonna have to think this through a bit more carefully . th the functional module that interacts with where the tourism g is going probably is too restrictive . we talked about this several times that the input end is gonna need a fair amount of feedback from the planning end . ,"The Berkeley Even Deeper Understanding group discussed plans and concerns regarding the architecture of SmartKom, its proposed modules, and the types of interactions expected to take place between modules. "
Bed009.F,"would there be any chance of getting the terminology changed that the dialogue planner was called a "" dialogue planner "" ? because there 's this other thing the o there 's this other thing in the tourist domain which is gonna be a route planner or it 's really gonna be an action planner . and i it i would think ,   s what would happen if we sent a note saying "" gee we 've talked about this and couldn't we change this th the whole word ? "" i have no idea how complicated these things are .  anyway . i if that c in persists then we 're gonna need another term . for the thing that actually does the planning of the routes and whatever we are doing for the tourist . but that 's not g tha that ha has all the wrong connotations . it 's it sounds like it 's stand alone . it doesn't interact , it doesn't that 's why i 'm saying . you can't it 's fine for looking up when t when the show 's on tv . you go to th but it 's really wrong headed for something that you that has a lot of state , it 's gonna interact co in a complicated way with the understanding parts . right .  i agree .  agree . there is there 's a logic to dialogue which is separable . i   it 's tricky . it 's tricky because one could imagine it will turn out to be the case that this thing we 're talking about , th the extended n knowledge modeler will fill in some parameters about what the person wants . one could imagine that the next thing that 's trying to fill out the detailed route planning , let 's say , will also have questions that it would like to ask the user . you could imagine you get to a point where it 's got a choice to make and it just doesn't know something . and you would like it t also be able to formulate a query . and to run that back through the dialogue manager and to the output module and back around . and a i a good design would allow that to happen . if if you can't make it happen then you do your best . i agree . but what it nee but th what the in that case the dialogue manager is event driven . the dialogue manager may think it 's in a dialogue state of one sort , and this one of these planning modules comes along and says "" hey , right now we need to ask a question "" . that forces the dialogue manager to change state .  it could be y it   how 's it s we looked at the e current pattern matching thing . and as you say it 's just a surface pattern matcher . what are the plans roughly ? the ","would there be any chance of getting the terminology changed that the dialogue planner was called a "" dialogue planner "" ? i if that c in persists then we 're gonna need another term . for the thing that actually does the planning of the routes and whatever we are doing for the tourist . the dialogue manager may think it 's in a dialogue state of one sort , and this one of these planning modules comes along and says "" hey , right now we need to ask a question "" . that forces the dialogue manager to change state . what are the plans roughly ? ",
Bed009.F,"the idea is to have a pa y a particular do you have a particular parser in mind ? is it partic d have you thought through ? is it an hpsg parser ? is it a whatever ?  you have to do it . you have to do it ,  i see ,  but the people at d f  people at dfki have written a fair number of parsers . other people over the years . have written various parsers at dfki . none of them are suitable ? i d i 'm asking . i don't know .     there was a chunk parser in verbmobil , that was one of the branchers . they d th i c there were these various competing syntax modules . and i know one of them was a chunk parser and i don't remember who did that . d i don't remember . i see . that 's right . there w that 's right . they w they had there were this was done with a two phase thing , where the chunk parser itself was pretty stupid and then there was a trying to fit them together that h used more context . right ? right . right . but is that the thing y it sounds like the thing that you were thinking of . what ?   but given th the constraints , that you want it to be small and fast and forth , my guess is you 're probably into some chunk parsing . and 'm not a big believer in this statistical cleaning up  it that seems to me last resort if you can't do it any other way .  but it may i may be that 's what you guys finally decide do .  and have you looked just again for context there is this one that they did at sri some years ago fastus ? a  it is .  it 's it was pretty ambitious . and it was english oriented ,  right . that 's all the morphology and and english is all th all word order . and it makes a lot more sense . and e  good point . in german you 've got most of this done with right . right . what about  did y like morfix ? a e y you 've got stemmers ? or is that something that but did you have that ?  i see . but you just connect to the lexicon and at least for german you have all of the the stemming information .  right . but it doesn't look like i you 're using it . i didn't n see it being used in the current template parser . i didn't see any we l actually only looked at the english . did we look at the german ? i don't remember . wha i right . right . and that 's what you have .  what didn't reme   it s 'd ","people at dfki have written a fair number of parsers . none of them are suitable ? but given th the constraints , that you want it to be small and fast and forth , my guess is you 're probably into some chunk parsing . ",
Bed009.F,"in german then you actually do case matching and things like in the pattern matcher or not ?  cuz i r i didn't reme i didn't saw it . have we looked at the german ? i haven  that 's getting it from the lexicon is just fine .  no problem with that .  and here 's the case where the english and the german might really be significantly different . in terms of if you 're trying to build some fast parser and forth and you really might wanna do it in a significantly different way . i don't know . you 've you guys have looked at this ? also ? in terms of w if you 're doing this for english as as german do you think now that it would be this doing it similarly ? set .   interesting . not easy . right . right . now actually ,  are you guys free at five ? or do you have to go somewhere at five o ' clock tonight ? w in ten minutes ? great . you 're going to that . that 's good , because that will tell you a fair amount about the form of semantic construction grammar that we 're using . th that probably as good an introduction as you 'll get . to the form of conceptual grammar that w we have in mind for this . it won't talk particularly about how that relates to what robert was saying at the beginning . but let me give you a very short version of this . we talked about the fact that there 're going to be a certain number of decisions that you want the knowledge modeler to make , that will be then fed to the function module , that does route planning . it 's called the "" route planner "" there are these decisions . and then one half of this we talked about at little bit is how if you had the right information , if you knew something about what was said and about th the something about was the agent a tourist or a native or a business person or young or old , whatever . that information , and also about the what we 're calling "" the entity "" , is it a castle , is it a bank ? is it a s town square , is it a statue ? whatever . all that information could be combined into decision networks and give you decisions . but the other half of the problem is how would you get that information from the parsed input ?  what you might try to do is just build more templates , saying we 're trying to build a templ build a template that w somehow would capture the fact that he wants to take a picture .  and we could you could do this . and it 's a small enough domain that probably you ,  you could do this . ","and here 's the case where the english and the german might really be significantly different . in terms of if you 're trying to build some fast parser and forth we talked about the fact that there 're going to be a certain number of decisions that you want the knowledge modeler to make , that will be then fed to the function module , that does route planning . and then one half of this we talked about at little bit is how if you had the right information , and about th the something about was the agent a tourist or a native or a business person and also about the what we 're calling "" the entity "" , all that information could be combined into decision networks and give you decisions . but the other half of the problem is how would you get that information from the parsed input ? ","The Berkeley Even Deeper Understanding group discussed plans and concerns regarding the architecture of SmartKom, its proposed modules, and the types of interactions expected to take place between modules. "
Bed009.F,"but from our point of view this is also a research project and there are a couple of people not here for various reasons who are doing doctoral dissertations on this , and the idea that we 're really after is a very deep semantics based on cognitive linguistics and the notion that there are a relatively small number of primitive conceptual schemas that characterize a lot of activity . typical one in this formulation is a container . this is a static thing . and the notion is that all sorts of physical situations are characterized in terms of containers . going in and out the portals and con  but also , importantly for lakoff and these guys is all sorts of metaphorical things are also characterized this way . you get in trouble and et cetera and what we 're really trying to do is to map from the discourse to the conceptual semantics level . and from there to the appropriate decisions . another one of these primitive , what are called "" image schemas "" , is goal seeking . this a notion of a source , path , goal , trajector , possibly obstacles . and the idea is this is another conceptual primitive . and that all sorts of things , particularly in the tourist domain , can be represented in terms of source , path and goal . the idea would be could we build an analyser that would take an utterance and say "" aha ! th this utterance is talking about an attempt to reach a goal . the goal is this , the pers the , traveller is that ,  the sor w where we are at now is this , they 've mentioned possible obstacles , et cetera . "" th the and this is an again attempt to get very wide coverage . if you can do this , then the notion would be that across a very large range of domains , you could use this deep conceptual basis as the interface . and then ,  the processing of that , both on the input end , recognizing that certain words in a language talk about containers or goals , et cetera , and on the output end , given this information , you can then make decisions about what actions to take . provides , they claim , a very powerful , general notion of deep semantics . that 's what we 're really doing . and nancy is going to her talk is going to be not about using this in applications , but about modeling how children might learn this deep semantic grammar . that 's that 's where the belief net comes in . th the idea is , let 's take this business about going to the powder tower . part of what you 'll get out of this will be the fact tha w if it works right , that this is an agent that wants to go to this place ","and the idea that we 're really after is a very deep semantics based on cognitive linguistics and the notion that there are a relatively small number of primitive conceptual schemas that characterize a lot of activity . what we 're really trying to do is to map from the discourse to the conceptual semantics level . and that all sorts of things , particularly in the tourist domain , can be represented in terms of source , path and goal . if you can do this , then the notion would be that across a very large range of domains , you could use this deep conceptual basis as the interface . ",
Bed009.F,"and that 's their goal and there will be additional situational information .  part of it comes from the ontology . the tower is this object . part of it comes from the user model . and the idea of the belief net is it combines the information from the dialogue which comes across in this general way , this is a goal seeking behavior , along with specific information from the ontology about the kinds of objects involved and about the situation about "" is it raining ? "" i don't know . whatever it is . and that 's the belief net that we 've laid out . and th the coupling to the situation comes in this model from , at th at the belief net , combining evidence from the dialogue with the ontology with the situation . but nancy isn't gonna talk about that , just about the right . the construction grammar . in a minute .  ","and the idea of the belief net is it combines the information from the dialogue which comes across in this general way , and th the coupling to the situation comes in this model from , at th at the belief net , combining evidence from the dialogue with the ontology with the situation . ",
Bed009.G,"is it i in , then , your place , in five a ? ",,
Bed016.A,"comfortable .  good . i know that he 's going to like , taiwan and other places to eat .   bye . it 's definitely not the most frustrating meeting i 've ever had . w we didn't yet specify with whom . but that 's why keith and i are going to be a little dazed for the first half m the meeting .  are very appreciative ,  what ? what ? really ? do we have to like , synchronize ? you 're kidding . and any rate ? that 's true .  you lose . are we gonna start all our meetings out that way from now on ? too bad . i kinda like it . it 's a ritual . we are ?  i haven't looked at it yet , but i will .   can i s  he sent it . you can keep it .  i 'm changing this . just but , anyway .    i will .   we can talk about it later . that 's not even ready ,  go on t to , whatever . i 'm making changes . "" don't worry about that . ""   go on .  anyway . and y email any time , but most usefully before the twenty first ? before the twenty ninth ,    easy parser .  i could hear it . this was an actual , subject ?   wh what is the s ?   i was like , "" where 'd you get that ? ""  "" looks familiar . ""    you might just wanna like , tack that on , as a comment , to something .   right . give you a more recent if you want that might have enough .  which even email you then , like there probably was a little few changes , not a big deal . you could steal anything you want , i don't care . which you 've already done ,   no , you shouldn't . that 's great . i 'm glad to see propagation .  yes . it 's certainly related ,  might wanna say . is it ? different level of analysis . what ? o what ? my god ! of what the building ? and give them more money . they just want a fun place for them to work . really ? does it exist yet ? they are w now building it ?  on that one ? in the presentation ? i 'll probably i c might have i 'll probably have comments for you separately , not important . anyway . that 's what he was talking about . metonymy and metaphor here , right ? that 's not about that , is it ? "" run into "" might even be more impact sense than , container sense .  all contact . there 's contact that doesn't social contact , whatever .  forceful . too bad . there 's lots of things you could make t shirts out of , but , this has gotten wh ","and y email any time , but most usefully before ",
Bed016.A,"we don't need the words to that . what ? no no no , we 're not going there .  w where it should illustrate wh when you say all this , do don't know , the related work as as , mappings ? did you ? join the club . i see . it 's a little it 's , we 've thought about it before , to use the examples in other papers , and it 's a little complicated . cuz you 're like , it 's a state of there 's resource , right , and like , what is film , the state you 're out of the state of having film , right ? and somehow film is standing for the re the resour the state of having some resource is just labeled as that resource .  it 's a little bit is film the trajector ? it 's weird . that or , "" having "" is also , associated with location , right ? if the film left , state is being near film .  but that 's from run ,  th that part is fine .  there was ? who ? you 're right .  and undoubtably there 's been reams of work about it in cognitive linguistics , but .  it 's not one of the y it 's more straightforward ones forward ones to defend , you probably don't want to use it for the purposes th these are you 're addressing like , computational linguists , right . or are you ? but more emphasis on the computational ? or emphasis on the linguist ?  i meant this , like  would try to i would stay away from one that involves weird construal it 's an obvious one but , around ?   we 've thought about that . right . right . nnn . no . what ? "" bakery "" can't be something you 're gonna eat .  where you can get baked goods .  it 's a lot of pragmatics , there , that might be beyond what you want to do . the s the steak wants to pay "" ?   how much does it cost ? to go in , that 's like that 's good . u ellipsis . like , "" it "" doesn't refer to "" thing , "" it refers to acti j thing standing for activ most relevant activity for a tourist you could think of it that way , but . no , i agree .  no , i 'm agreeing that this is a good ,   what ? i was like , "" it was here . "" like  or like its developmental state like that , you could you could get that .   state . right . you want a more exotic one version of that . i 'm really into do you really say that ? would you really say that ? i was gonna say , like a fixed expression , ","we 've thought about it before , to use the examples in other papers , and it 's a little complicated . would try to i would stay away from one that involves weird construal a fixed expression , ",
Bed016.A,"there 're too there 're all sorts of fixed expressions i don't like "" i 'm out of sorts now ! "" like "" i 'm in trouble ! ""  why don't you want to use any of those ? you don't wanna use one that 's "" i wanna go see the van gogh . "" anyway , i 'm location versus what ? instruction . directions ? that was definitely treated as an example of construal . right ? you want a lexical example .  that 's the first one , the very first one .   ",,
Bed016.B, actually ,,
Bed016.C," liz suggested we could start off by doing the digits all at the same time .  no , just start whenever you want .   just to save time . does matter for them . we could . we might . not rehearse , i have just not spent any time on it , can show you what i 've got , get your input on it , and some suggestions , that would be great . and the same is true for the proposal . i will have time to do some revision and some additional on various airplanes and trains .  i don't know how much of a chance you had to actually read it because but you could always send me comments per electronic mail and they will be incorporated . the it says , this is construal "" , and then it continues to say that one could potentially build a probabilistic relational model that has some general , domain general rules how things are construed , and then the idea is to use ontology , situation , user , and discourse model to instantiate elements in the classes of the probabilistic relational model to do some inferences in terms of what is being construed as what in our beloved tourism domain . but , with a focus on  i don't i , don't need it . actually this is the newest version after your comments , and    if you would have checked your email you may have received a note from yees asking you to send me the , up to d current formalism thing that you presented . but for this it doesn't matter . but , and and any type of comment whether it 's a spelling or a syntax or readability  interesting . twenty ninth . the twenty ninth . that 's when i 'm meeting with wolfgang wahlster to sell him this idea .  then i 'm also going to present a little talk at eml , about what we have done here and i 'm gonna start out with this slide , the most relevant aspects of our stay here , and then i 'm asking them to imagine that they 're standing somewhere in heidelberg and someone asks them in the morning the cave forty five is a known discotheque which is certainly not open at that time . and they 're supposed to imagine that , do they think the person wants to go there , or just know where it is ?  which is probably not , the case in that discotheque example , or in the bavaria example , you just want to know where it is . and forth . we can make a point that here is ontological knowledge but if it 's nine pm in the evening then the discotheque question would be , one that might ask for directions instead of just location . and forth and forth . that 's motivating it . then what have we done far ? ","not rehearse , can show you what i 've got , get your input on it , and some suggestions , and the same is true for the proposal . it says , this is construal "" , and then it continues to say that one could potentially build a probabilistic relational model that has some general , domain general rules how things are construed , and then the idea is to use ontology , situation , user , and discourse model to instantiate elements in the classes of the probabilistic relational model to do some inferences in terms of what is being construed as what in our beloved tourism domain . actually this is the newest version after your comments , if you would have checked your email you may have received a note from yees asking you to send me the , up to d current formalism thing that you presented . the twenty ninth . that 's when i 'm meeting with wolfgang wahlster to sell him this idea . then i 'm also going to present a little talk at eml , about what we have done here we can make a point that here is ontological knowledge but if it 's nine pm in the evening then the discotheque question would be , one that might ask for directions instead of just location . that 's motivating it . then what have we done far ? ","The thesis proposal, on the other hand, presents the idea of ""construal"" and makes claims as to how inferences are drawn in a probabilistic relational model by using information from the ontology, situation, user and discourse models. The latter will present the work that is currently being done at ICSI including examples of inference of user intentions and of the recordings of the on-going data collection. The meeting was taken up by discussion about a thesis proposal and a talk about to take place at EML. "
Bed016.C,"we had our little bit of , smartkom that we did ,  everth that 's the not the construction parser . that 's the , tablet based parser , and the generation outputter . that 's done . you have to change those strategies , right ? that 's , ten words ? twelve ? and , and fey is doing the synthesis as we speak . that 's all about that . then i 'm going to talk about the data , these things about actually i have an example , probably . two s can you hear that ? or should i turn the l volume on .  but they 're mimicking the synthesis when they speak to the computer , the you can observe that all the time , they 're trying to match their prosody onto the machine . you have to and forth and forth . i will talk about our problems with the rephrasing , and how we solved it , and some preliminary observations , also , i 'm not gonna put in the figures from liz , but it would interesting to , point out that it 's the same . as in every human telephone conversation , and the human computer telephone conversation is quite d quite different from , some first , observations . then feed you back to our original problem cuz , how to get there , what actually is happening there today , and then talk about the big picture here , e tell a little bit as much as about the ntl story . i wa i do wanna , i 'm not quite about this , whether i should put this in , that , you have these two different ideas that are or two different camps of people envisioning how language understanding works , and then , talk a bit about the embodied and simulation approach favored here and as a prelude , i 'll talk about monkeys in italy . and , srini was gonna send me some slides but he didn't do it , from but i have the paper , make a resume of that , and then i stole an x schema from one of your talks that 's bergen , chang , something , or the other . and that 's now i 'm not going to bring that . that 's what i have , far , and the rest is for airplanes . schemas , then , i would like to do talk about the construction aspect and then at the end about our bayes net . end of story . anything i forgot that we should mention ? the fmri should i mention the fact that , we 're also actually started going to start to look at people 's brains in a more direct way ? "" future activities "" something .    i do have it here .  and , the big picture is this bit . but , it would ","we had our little bit of , smartkom that we did , the generation outputter . and , and fey is doing the synthesis as we speak . then i 'm going to talk about the data , i will talk about our problems with the rephrasing , and some preliminary observations , and then talk about the big picture here , e tell a little bit as much as about the ntl story . and then , talk a bit about the embodied and simulation approach favored here schemas , then , i would like to do talk about the construction aspect and then at the end about our bayes net . the fmri ","The latter will present the work that is currently being done at ICSI including examples of inference of user intentions and of the recordings of the on-going data collection. The talk will also outline the theoretical (X-schemas, image schemas, Bayes-nets) and neural background. "
Bed016.C,"but i don't am capable of do pulling this off and doing justice to the matter . there is interesting in her terms of how language works , the emergentism story would be to be it would be to tell people how what 's happening there , plus how the , language learning works , but th that 's c that comes up to the x schema slide , 'm gonna steal that from nancy , one of nancy 's st i but i also have you trash you left over , your quals and your triple ai . i don't feel bad about it because you are on the , title . on the , you 're that 's see , that 's you .  propagated ? might even mention that this work you 're doing is also with the mpi in leipzig ,  because , eml is building up a huge thing in leipzig . it it 's on biocomputation . would  the offices are actually a little the , think of ramps , coming out of the double helix and then you have these half domes , glass half domes , and the offices are in the glass half dome . as a model . but i th if somebody has something to say . in the presentation here . i was ac actually worried about bibtex . no , that 's quite possible . that 's copy and paste from something . it did , there is a reference to srini    but i did not focus on that aspect but , ehhh , it 's just underneath , that reference to metaphor . it 's the last paragraph before two . on page two , the main focus but that 's really  why .  no , it doesn't say it no . even though one could argue what if there are basic cases , even . it seems like nothing is context free . but "" walked into the cafe and ordered a drink , "" and "" walked into the cafe and broke his nose , "" that 's     no .   you don't find that usage , i checked for it in the brown national corpus . the "" walk into it "" never really means , w as in walked smack but , y if you find "" walked smacked into the cafe "" or "" slammed into the wall ""  right . or you can run into an old friend , or run . pro probably not your marks in the kitchen , today . not your marks .  there actually the i what would have been really is to find an example for all of this , from our domain . if we w if we can make one up now , that would be c incredibly helpful . how w we have , a canonical use of something and y it 's , we have some constructions and then it 's construed as something , ","but i don't am capable of do pulling this off and doing justice to the matter . might even mention that this work you 're doing is also with the mpi in leipzig , because , eml is building up a huge thing in leipzig . it seems like nothing is context free . but "" walked into the cafe and ordered a drink , "" and "" walked into the cafe and broke his nose , "" the "" walk into it "" never really means , w as in walked smack the i what would have been really is to find an example for all of this , from our domain . w we have , a canonical use of something and y it 's , we have some constructions and then it 's construed as something , ","Several potential examples of polysemy were discussed in detail: ""walk/run into"", ""on the bus"", ""out of film"", ""where is X?"". Base constructions deal with the norm, while further general domain mechanisms determine how the constructions are invoked depending on the context. "
Bed016.C,"and then we may get the same constructions with a metaphorical use that 's also relevant to the domain .  i had two hours w with george on this , it ,  "" on the bus "" is a m is a metaphorical metonymy that relates some meta path metaphorically and you 're on that path and th w it 's he there 's a platform notion , right ? "" he 's on the standing on the bus waving to me . "" but th the regular as we speak "" j johno was on the bus to new york , ""  he 's that 's , what did i call it here , the transportation schema , something , where you can be on the first flight , on the second flight , and you can be , on the wagon .  but it 's unfortunately , this is not really something a tourist would ever say .   but in terms of the this we had initially we 'd started discussing the "" out of film . "" and there 's a lot of "" out of "" analysis ,  could we capture that with a different construal of running out of something is different from being out of somewhere . is the d the final state of running out of something is being out of it .   there 's gonna be four computational linguists , computer it 's more there 's going to be the just four computational linguists , by coincidence , but the rest is , whatever , biocomputing people and physicists . the thesis ! that 's computa should be very computational , and , someth the old bakery example might be "" is there a bakery around here "" . if you c we really just construe it as a no , it 's the bakery itself is it a building ? that you want to go to ? or is it something to eat that you want to buy ? and then  no . where is the castle ? how old is it ? how much does it cost ? s but as nancy just su suggested it 's probably ellipticus .  my argument here is it 's it 's the same thing as "" plato 's on the top shelf , "" i 'm con th that you can refer to a book of plato by using "" plato , "" and you can refer back to it , and you can castles have as tourist sites , have admission fees , you can say "" where is the castle , how much does it cost ? ""  "" how far is it from here ? ""  you 're also not referring to the width of the object , or www .  i i when , just f u the data that i 've looked at far that rec there 's tons of cases for polysemy . mak re making reference to buildings as institutions , as containers , as build whatever . ","and then we may get the same constructions with a metaphorical use that 's also relevant to the domain . we had initially we 'd started discussing the "" out of film . "" the old bakery example might be "" is there a bakery around here "" . where is the castle ? how old is it ? how much does it cost ? but as nancy just su suggested it 's probably ellipticus . my argument here is it 's it 's the same thing as "" plato 's on the top shelf , "" the data that i 've looked at far that rec there 's tons of cases for polysemy . ","Base constructions deal with the norm, while further general domain mechanisms determine how the constructions are invoked depending on the context. Several potential examples of polysemy were discussed in detail: ""walk/run into"", ""on the bus"", ""out of film"", ""where is X?"". "
Bed016.C,"ib in mus in museums , as a building or as something where pictures hang versus , ev something that puts on exhibits , forth . but    no , but this that 's what i have , started doing . metonymy , polysemy . but the argument should be can be made that , despite the fact that this is not the most met metaphorical domain , because people interacting with hti systems try to be straightforward and less lyrical , construal still is , completely , key in terms of finding out any of these things ,  we , with a i looked with a student i looked at the entire database that we have on heidelberg for cases of metonymy . hardly anything . not even in descriptions w did we find anything , relevant . but this is just something we 'll see ,  and deal with . the "" where is something "" question as a whole , can be construed as , u i locational versus instructional request . if we 're not talk about the lexic instruction .  but then you 're not on the lexical level , that 's one level higher . but i don't need it .  also it would be to get ultimately to get a mental space example , even temporal references are just in the spatial domain are rare . when you 're getting information on objects .   we can include that also in our second , data run . we c we can show people pictures of objects and then have then ask the system about the objects and engage in conversation on the history and the art and the architecture and forth . ","but the argument should be can be made that , despite the fact that this is not the most met metaphorical domain , the "" where is something "" question as a whole , can be construed as , u i locational versus instructional request . but then you 're not on the lexical level , that 's one level higher . also it would be to get ultimately to get a mental space example , even temporal references are just in the spatial domain are rare . we can include that also in our second , data run . ","However, none of them was an example of lexical polysemy resolved by construal straightforward enough to include in the proposal; the tourist domain is not metaphor rich. Several potential examples of polysemy were discussed in detail: ""walk/run into"", ""on the bus"", ""out of film"", ""where is X?"". "
Bed016.D,"on ? am i on ? 'm on ? good . good . you a you 're you remember you 're being recorded at this point . how di how d exactly did , that paper lead to anti lock brakes ? nah . i love that story . all at the same time . i don't know if i would get distracted and confused , probably . do we have t do we have to time them at the same time or just overlapping alright . it 's strangely satisfying . are we to r just to make 's going on , we 're talking about robert 's thesis proposal today ? is that true ? is yes , and that too . we can we can pass my , we can pass my extra copy around . er , actually , my only copy , now that about it , but . i already read half of it , it 's the version i didn't have that i mine the w did the one you sent on the email have the that was the most recent one ?  cuz i read halfway but i didn't see a castle thing . the twenty first i 'm assuming . what , today 's the twenty first ? man !  halfway done ?    i it , twelve . hear it . they might not hear it in the they will . i don't know . they 're building a building in the shape of dna , is that what you said ? y you definitely wanna w don't wanna waste that money on research ,  that 's horrible . does that mean instead of having tons and tons of rules in your context free grammar you just have these base constructs and then a general mechanism for coercing them .  right . with construal you don't have to have a construction for every possible thing that can fill the rule . you con you conditioned me with your first sentence , and thought , "" why would he walk into the cafe and then somehow break his nose ? ""  cars run into telephone poles all the time . you should get a t shirt that says that . it 's a speech act . about plato and the book ?  i 'm really into art .  i love van gogh . for some reason when you said "" feedback electronically "" of that you ever see the simpsons where they 're like the family 's got the buzzers and they buzz each other when they don't like what the other one is saying ? it was a very early one . i don't know if it 's the first one . ",,
Bed016.E," right . right .  right . i avoided that as long as i could for you guys , but , right . e you 're supposed to we can do this . everybody 's got different digits , right ? no . e the they have s they have the close talking microphones for each of us ,  there 's separate channels . when i say  right . no . you had s you said there were two things that you might wanna do . one was rehearse your i talk no i s i see this has got the castle in it , and like that .    no , this is the twenty first . whatever . you certainly can . y i i don't know right ,  the time to mention it , if you mention it , is when you talk about mirror neurons , then you should talk about the more recent about the kicking and , the  and that the plan is to see to what extent the you 'll get the same phenomena with stories about this , that and that we 're planning to do this ,  which , we are . that 's one thing .  depends . there is a , whole language learning story ,  which , actually , i even on your five layer slide , you 've got an old one that leaves that off .  right . anyway , i agree that 's not central . what you might wanna do is ,  and may not , but you might wanna this is rip off a bunch of the slides on the anal there the there we 've got various i generations of slides that show language analysis , and matching to the underlying image schemas , and , how the construction and simulation that ho that whole th  the quals w the quals slides would be fine . you could get it out of there , or some   it 's different , this is the , dna building , or someth the double helix building .  the it was it turns out that if you have multiple billions of dollars , y you can do all sorts of weird things , and roughly , including cr cross bridges , and you d you really now i spent the last time i was there i spent two hours hearing this story which is , right . right . no , y i there 's infinite money . see you th you then fill it with researchers . right . right .   that 's a good point , th that the date , the , a lot of the this is interacting with , people in italy but also definitely the people in leipzig and the the b the combination of the biology and the leipzig connection might be interesting to these guys ,    anyway ! enough of that , let 's talk about your thesis proposal .   no , no . did note ","you had s you said there were two things that you might wanna do . one was rehearse your i talk the time to mention it , if you mention it , is when you talk about mirror neurons , depends . there is a , whole language learning story , there the there we 've got various i generations of slides that show language analysis , and matching to the underlying image schemas , the b the combination of the biology and the leipzig connection might be interesting to these guys , let 's talk about your thesis proposal . ",The meeting was taken up by discussion about a thesis proposal and a talk about to take place at EML. 
Bed016.E,"i it looks like the , metaphor didn't get in yet . s reference is one thing , the question is there any place did you put in something about , the individual , we 'd talked about putting in something about people had ,   good . i see where you have it . the top of the second of pa page two you have a sentence . but , what i meant is , even before you give this , to wahlster , you should , unless you put it in the text , and i don't think it 's there yet , about we talked about is the , scalability that you get by , combining the constructions with the general construal mechanism . is that in there ? where is it , cuz i 'll have to take a look .   no , it s says it but it doesn't say it doesn't it d it doesn't give the punch line . cuz let me tell the gang what the punch line is , because it 's actually important , which is , that , the constructions , that , nancy and keith and friends are doing , are , in a way , quite general but cover only base cases . and to make them apply to metaphorical cases and metonymic cases and all those things , requires this additional mechanism , of construal . and the punch line is , he claimed , that if you do this right , you can get essentially orthogonality , that if you introduce a new construction at the base level , it should com interact with all the metonymies and metaphors that all of the projections of it also should work . and , similarly , if you introduce a new metaphor , it should then compose with all of the constructions . and it to the extent that 's true then it 's a big win over anything that exists .  that , in the metaphor case , that you have a direct idea of a source , path , and goal and any metaphorical one and abstract goals and all that you can do the same grammar . and it is the same grammar . but , the trick is that the the way the construction 's written it requires that the object of the preposition be a container . "" trouble "" isn't a container , but it gets constr construed as a c container . et cetera . that 's where this , right . 's it 's a very big deal , i in this framework , and the thesis proposal as it stands doesn't , i don't think , say that as clearly as it could . nothing is context free , but there are basic cases . that is , there are physical containers , there are physical paths , there  et cetera . it doesn't mean that they 're unambiguous . ","i it looks like the , metaphor didn't get in yet . the top of the second of pa page two you have a sentence . no , it s says it it doesn't give the punch line . which is , that , the constructions , that , nancy and keith and friends are doing , are , in a way , quite general but cover only base cases . and to make them apply to metaphorical cases and metonymic cases and all those things , requires this additional mechanism , of construal . and the punch line is , he claimed , that if you do this right , you can get essentially orthogonality , that if you introduce a new construction at the base level , it should com interact with all the metonymies and metaphors that all of the projections of it also should work . and , similarly , if you introduce a new metaphor , it should then compose with all of the constructions . nothing is context free , but there are basic cases . that is , there are physical containers , it doesn't mean that they 're unambiguous . ","Base constructions deal with the norm, while further general domain mechanisms determine how the constructions are invoked depending on the context. "
Bed016.E,"a cafe can be construed as a container , or it can be construed as a obstacle , or as some physical object . there are multiple construals . and that 's part of what has to be done . this is why there 's this interaction between the analysis and the construal . the b the double arrow . it doesn't magically make ambiguity go away . but it does say that , if you walked into the cafe and broke your nose , then you are construing the cafe as an obstacle . and if that 's not consistent with other things , then you 've gotta reject that reading . right .  but "" run into "" does . no , but "" run into "" does . because you will find "" run into , ""  or "" into the cafe "" for that m  "" his car ran into the cafe . "" you can "" run into "" in that sense too . but , right . but like , "" run into an old friend "" , it probably needs its own construction . george would have i 'm some exa complicated ex reason why it really was an instance of something else and it is , but , there are idioms and my guess is that 's one of them , but , don't know .  but it 's it 's right . i it 's more this is this motivated but mo for motivated , but then you can't parse on motivated .    anything else you want to ask us about the thesis proposal , you got we could look at a particular thing and give you feedback on it .  right r f let 's suppose you use "" in "" and "" on "" . that 's what you started with . in the bus "" and "" on the bus , "" that 's actually a little tricky in english because to some extent they 're synonyms .  what did he say . right . h that 's i believe all that , it 's just      right . that may or may not be what you want to do . you could do something much simpler like "" under the bus , "" where unless he was repairing it but but right . right .  or being out of something as , as running out of it "" definitely has a process aspect to it .  b that 's but the difference is right .  but , nob no one has in of the ,  professional linguists , they haven't there was this whole thesis on "" out of "" . there or there was a paper on it .  there was a it may be just "" out "" .  there was "" over "" but there was also a paper on "" out "" .  and all that but anyway . we 're not gonna do that between now and next week .   right .  ","but it does say that , if you walked into the cafe and broke your nose , then you are construing the cafe as an obstacle . but "" run into "" does . but like , "" run into an old friend "" , it probably needs its own construction . there are idioms anything else you want to ask us about the thesis proposal , you got in the bus "" and "" on the bus , "" right . that may or may not be what you want to do . ","Several potential examples of polysemy were discussed in detail: ""walk/run into"", ""on the bus"", ""out of film"", ""where is X?"". "
Bed016.E,"no no , but not for your talk . i 'm we 're worrying about the th the thes it 's just for one guy .  right . no , no . the question is d do you wanna construe do you wanna constr strue r exactly . it 's because do you wanna c do you want to view the bakery as a p a place that i if y th that 's one . you want to buy something . but the other is , yo you might have smelled a smell and are just curious about whether there 'd be a bakery in the neighborhood , or , pfff you wonder how people here make their living , and there 're all sorts of reasons why you might be asking about the existence of a bakery that doesn't mean , "" i want to buy some baked goods . "" but those are interesting examples but it 's not clear that they 're mainly construal examples . there 's all sorts of going on .  let 's let 's think about this from the point of view of construal . let 's first do a the metonymy thing is probably the easiest and a and actually the though , the one you have isn't quite n no not that one , that 's a the background . this is the t page five . no . just beyond that .  right . it 's not for sale .   can we think of a metaphorical use of "" where "" in the tourist 's domain ?  it 's you can sometimes use "" where "" f for "" when "" in the sense of ,  where wh where was , "" where was heidelberg , in the thirty years ' war ? ""  or some such thing .  essentially , but anyway th there are cases like that .    there certainly is that , "" where could i learn its opening hours , "" but that 's not metaphorical . it 's another we 're thinking about , or we could also think about ,  how about "" i 'm in a hurry "" ? it i but it 's a state and the issue is , is that it may be just a usage , that it 's not particularly metaphorical , i don't know . right .  how about i "" i 'm in a state of exhaustion "" ? like that , which a tourist w  a st you can certainly say , "" i 'm in overload . "" tu stur tourists will often say that . you can do that ? really ? that 's definitely a , that 's a , right . but . right .  right . right . right . as an institution ,  the castle the that old castle one is    right . that 's that 's a reasonable point , that it in this domain you 're gonna get less metaphor and more metonymy . ","and there 're all sorts of reasons why you might be asking about the existence of a bakery but it 's not clear that they 're mainly construal examples . the metonymy thing is probably the easiest can we think of a metaphorical use of "" where "" in the tourist 's domain ? "" where was heidelberg , in the thirty years ' war ? "" "" where could i learn its opening hours , "" but that 's not metaphorical . a st you can certainly say , "" i 'm in overload . "" ",
Bed016.E,"and polysemy , and like that .  alright . right . s see you . if anybody has additional suggestions , w   you might want both . we but it 's easy to make up plausible ones .  right , where r  what color was this in the nain nineteenth century . what was this p instead of wh what how was this painted , what color was this painted ,  was this alleyway open .   why don't we plan to give you feedback electronically . wish you a good trip . all success . ",why don't we plan to give you feedback electronically . ,
Bed016.F,"smooth . had one of the most frustrating meetings of my career .   i 'm just gonna sit here and growl .  for which we i know you were doing that , but , anyway . i could tell you had a rough day , man !  it 's a great story . my goodness . are you being silly ?  alright . alright . just plug one ear . bye ! that was a great meeting ! now , why ?  could we ? need a copy of this , yes . i is there an extra copy around ? alrigh  there 's only one "" s "" in "" interesting "" . there 's only one "" s "" in "" interesting "" . on page five . that 's better hurry up then !  you 've got the parser done .     i heard it . sounds like fey .  really . interesting . it 's pretty slow . the system breaking . that looks familiar . boy ! that 's brilliant ! hhh . and everybody gets a trampoline in their office . alright , let 's stop talking about this . you might want to , double check the spellings of the authors ' names on your references , you had a few , misspells in your slides , there . like i believe you had "" jackendorf "" . unless there 's a person called "" jackendorf "" ,  but that 's the only thing i noticed in there . in the presentation .       he slipped on the wet floor . depends . sudden surprising contact , right ? but no , it has a life of its own . it 's partially inspired by the spatial   right . in other news . out of film , in particular .  it 's  but and plus the fact that there 's also s can you say the film ran out ""  or , you could say something like "" the film is out "" like the film went away from where it should be , namely with you , right ?  the film is gone , right ?  i never really knew what was going on , find it little bit farfetched to say that "" i 'm out of film "" means that i have left the state of having film like that , but .    you got there . you got to out of it .   out . there was one on "" out "" or "" out of "" ?  lind susan lindner , right ? the "" the syrup spread out "" ? that thing ?  weird  sh    onward . a castle .  two hundred million dollars . that 's a good example , actually . shoot , isn't that that 's what figuring that out is what this is about .    o  like what side were they on , or ? there 's also things like s  could ask something like "" where can i find out about blah blah "" in a ","you 've got the parser done . you might want to , double check the spellings of the authors ' names on your references , you had a few , misspells in your slides , there . ",
Bed016.F,"doesn't nece i don't necessarily have to care about the spatial location , just give me a phone number and i 'll call them like that ?       fixed . geez . i have to go . ",,
Bmr005.A,"sounds like an initialization thing . tran go ahead . nonspeech sounds ? some of these that are the nonspeech overlapping events may be difficult even for humans to tell that there 's two there . if it 's a tapping sound , you wouldn't necessarily or , something like that , it 'd be it might be hard to know that it was two separate events .  three hundred overlapping speech   were you interrupting him or was he interrupting you ? but liz is saying why not get it out of the transcripts ? i did something almost identical to this at one of my previous jobs , and it works pretty i almost exactly what you described , an energy detector with a median filter , you look for runs . and you can you can get y you get them pretty close . and think doing that to generate these possibilities and then going through and saying yes or no on them would be a quick way to do it .  no . it was when i was working for the government . nah . he 's it doesn't take a long time . i have to remember . i 'll think about it , and try to remember . di dif different bandwidth . ten meetings that have been sent to ibm ? h how many total have we recorded now , altogether ? it was the morning one . w what is the the artifact you try to you 're trying to get rid of when you do that ? that would mean like if you were listening to the data that was recorded on one of those . just the raw data , you would you might hear an echo ? and then this noise cancellation would get clean up thing , that  when i would have meetings with the folks in cambridge when i was at bbn over the phone , they had a some special speaker phone and when they would first connect me , it would come on and we 'd hear all this noise . and then it was and then it would come on and it was very clear ,  three hours . would it help we 're already talking about two levels of detail in meetings . one is without doing the digits or , the full blown one is where you do the digits , and everything , and then talk about doing it without digits , what if we had another level , just to collect data , which is without the headsets and we just did the table mounted you do , i see , have they ever responded to you ? is the notion of recording any of chuck 's meetings dead in the water , or is that still a possibility ? even coming down from campus is big thing , but what about or what about people in the building ? there 's the state of california downstairs , and  ","h how many total have we recorded now , altogether ? ",
Bmr005.A,"what about joachim , he can you could get a lot of lively discussions from those radio ones . ",,
Bmr005.B,"and it looks like you 've found a way of mapping the location to the without having people have to give their names each time ? it 's like you have the that are you going to write down that i sat here ?   shall start ?  he was interested in the question of relating to his to the research he presented recently , of inference structures , and the need to build in , this mechanism for understanding of language . and he gave the example in his talk about how e a i 'm remembering it just off the top of my head right now , but it 's something about how i "" joe slipped "" "" john had washed the floor "" like that . and i don't have it quite right , but that thing , where you have to draw the inference that , there 's this time sequence , but also the causal aspects of the floor and how it might have been the of the fall and that it was the other person who fell than the one who cleaned it and it these sorts of things . i looked through the transcript that we have far , and fou identified a couple different types of things of that type and one of them was something like during the course of the transcript , w we had gone through the part where everyone said which channel they were on and which device they were on , and the question was raised "" should we restart the recording at this point ? "" and dan ellis said , "" we 're just far ahead of the game right now we really don't need to "" . now , how would you interpret that without a lot of inference ? the inferences that are involved are things like , how do you interpret "" ahead of the game "" ? it 's the it 's i what you int what you draw the conclusions that you need to draw are that space is involved in recording , that i that i we have enough space , and he continues , like "" we 're ahead of the game cuz now we have built in downsampling "" . you have to get the idea that "" ahead of the game "" is sp speaking with respect to space limitations , that that downsampling is gaining us enough space , and that therefore we can keep the recording we 've done far . but there are a lot of different things like that . it 's possible . he was he we met and he was gonna go and y look through them more systematically and then meet again . it 's , not a matter of a but , it was optimistic . that 's his major i mentioned several that w had to do with implications drawn from intonational contours and that wasn't as directly relevant to what he 's doing . ","he was interested in the question of relating to his to the research he presented recently , of inference structures , and the need to build in , this mechanism for understanding of language . i looked through the transcript that we have far , and fou identified a couple different types of things of that type ","Topics discussed by the Berkeley Meeting Recorder group included a potential collaboration with another ICSI member regarding the analysis of inference structures, efforts by speaker mn005 to detect speaker overlap, the current status on recordings and transcriptions, and future efforts to collect meeting data. "
Bmr005.B,"he 's interested in these knowledge structures , inferences that you draw i from i don't would make that leap , because i in narratives , mean , if you spell out everything in a narrative , it can be really tedious ,   that aspect .   i i had several that had to do with backchannels and this wasn't one of them . this one really does make you leap from he said , "" we 're ahead of the game , w we have built in downsampling "" . and the inference , i if you had it written down , would be  but there are others that have backchannelling , it 's just he was less interested in those . can we but you 'd have the you 'd have fainter wouldn't you get fainter reception out here ? i see . i am too . i am too .  and it is it is sensitive . i came up with something from the human subjects people that i wanted to mention . it fits into the m area of the mundane , but they did say i asked her very specifically about this clause of how , it says "" no individuals will be identified "" in any publication using the data . "" individuals being identified , let 's say you have a snippet that says , "" joe s thinks such and such about this field , but he 's wrongheaded . "" now we 're gonna be careful not to have the "" wrongheaded "" part in there , but let 's say we say , "" joe used to think and about this area , in his publication he says that but he 's changed his mind . "" or whatever . then the issue of being able to trace joe , because we know he 's known in this field , and all this and tie it to the speaker , whose name was just mentioned a moment ago , can be sensitive . think it 's really adaptive and wise to not mention names any more than we have to because if there 's a slanderous aspect to it , then how much to we wanna be able to have to remove ? my feeling on it was that it wasn't really important who said it ,  i understand . no was suggesting that it 's not a bad policy p potentially . we need to talk about this later .  depends on which one  does this ? if you had an overlap involving three people , how many times was that counted ? for that would j just be one .  but a th but a thousand events in twelve minutes , that 's but a thousand taps in eight minutes is a l in twelve minutes is a lot . silent .  i see .  b i would say time bin . my goal is to get words with reference to a time bin , beginning and end point . ","he 's interested in these knowledge structures , inferences that you draw i from and it is it is sensitive . i came up with something from the human subjects people that i wanted to mention . i asked her very specifically about this clause of how , it says "" no individuals will be identified we need to talk about this later . ","Topics discussed by the Berkeley Meeting Recorder group included a potential collaboration with another ICSI member regarding the analysis of inference structures, efforts by speaker mn005 to detect speaker overlap, the current status on recordings and transcriptions, and future efforts to collect meeting data. "
Bmr005.B,"and sometimes , it was like you could have an overlap where someone said something in the middle , but , w it just wasn't important for our purposes to have it that i disrupt that unit in order to have , a the words in the order in which they were spoken , it would have been hard with the interface that we have . now , my a adam 's working on a on a revised overlapping interface , but     another thing we discussed was that was that there m there was this already a script i believe that dan had written , that handle bleedthrough , cuz you have this close you have contamination from other people who speak loudly . some thought of having having that be a preprocessor and then run it through yours . that 's what we were discussing . is this proprietary ? is this something that we could just co opt , or is it ? no .  right . thought if it was tried and true , then and he 's gone through additional levels of development . can i ask one question about his statistics ? in the tw twelve minutes , if we took three hundred and divided it by four , which is about the length of twelve minutes , i i 'd expect like there should be seventy five overlaps . did you find more than seventy five overlaps in that period , or ? more than how many overlaps in your twelve minutes ? the overlaps .  i 'm not it 's an empirical question . we could find that out . i 'm not that the beginning had more . is brian kingsbury 's work related to that , or is it a different type of reverberation ? the a we 're gonna do a revised form ,  but once a person has signed it once , then that 's valid for a certain number of meetings . she wanted me to actually estimate how many meetings and put that on the consent form . i told her that would be a little bit difficult to say . think from a s practical standpoint , we could have them do it once every ten meetings , it won't be that many people who do it that often , but just , long as they don't forget that they 've done it , it 's also likely that people will cancel out afterwards . but i wanted to raise the kpfa idea .  we need to that there 's a possibility that the transcript will need to be adjusted afterwards , and es especially since these people won't be used to dealing with multi channel transcriptions . think that we 'll need to adjust some and also if we wanna add things like more refined coding of overlaps , then definitely we should count on having an extra pass through . i wanted to ask another a aspect of the data collection . ","and sometimes , it was like you could have an overlap where someone said something in the middle , but , w it just wasn't important for our purposes to have it that i disrupt that unit in order to have , a the words in the order in which they were spoken , it would have been hard with the interface that we have . the a we 're gonna do a revised form , think from a s practical standpoint , we could have them do it once every ten meetings , ",
Bmr005.B,"there 'd be no reason why a person couldn't get together several friends , and come and argue about a topic if they wanted to , right ? you could do this , you could . it seems like you could hold some meetings . you and adam ? you could hold some additional meetings , if you wanted . i agree . and mari also , we had this came up when she was here . that 's important . i do think eating while you 're doing a meeting is going to be increasing the noise . but i had another question , which is in principle , w i know that you don't want artificial topics , but it does seem to me that we might be able to get subjects from campus to come down and do something that wouldn't be too artificial . we could political discussions , or other , and i people who are because , there 's also this constraint . we d it 's like , the goldibears goldi goldilocks , it 's like you don't want meetings that are too large , but you don't want meetings that are too small . and and it just seems like we could exploit the subj human subject p pool , in the positive sense of the word . we could pay subjects .   that 's good to know . that 's good to know . ",,
Bmr005.C,"   but he can use text , he 's talking about just using text  or ?  there 's a lot of pronoun i believe it . actually to make it worse , morgan uses "" you "" and "" you "" with gaze and no identification , or wrote this down . actually . cuz morgan will say "" you had some ideas "" and he never said li he looked right , it 's great . this is really great because because he 's looking at the per even for addressees in the conversation , i bet you could pick that up in the acoustics . just because your gaze is also correlated with the directionality of your voice . that , to even know when if you have the p z ms you should be able to pick up what a person is looking at from their voice . right . put morgan always like this and but you don't have this problem . morgan is the one who does this most . even though you could pick up later on , just from the acoustics who you were t who you were looking at .   no , but that it 's interesting . but , then it won't if we if we we should do whatever 's natural in a meeting if we weren't being recorded . "" if person x "" no , you have to say , you still don't know who "" he "" is , with that prosody . it 's ambiguous , it 's and the downsampling must have been dan . it 's an inference . overlapping speech . there 's a lot of overlap .  but that can include taps . actually   alright . but why can't you use the combination of the close talking mikes , time aligned ? if you 're interested in speakers overlapping other speakers and not the other kinds of nonspeech , that 's not a problem , right ? but it 's known . the normalization you do is over the whole conversation isn't it , over the whole meeting . if you wanted to study people overlapping people , that 's not a problem . not only a word level , but actually you didn't need to show the exact point of interruption , you just were showing at the level of the phrase or the level of the speech spurt , or  right . now , why do you need to mark speaker overlap by hand if you can infer it from the relative energy in the you shouldn't need to do this p completely by hand , right ? i 'm  in the far field mike .  what is get it from the close talking mikes . a or ge get a first pass from those , and then go through it 'd be a lot faster probably to  right . that 's what i wonder , because or how bad it is , be because that would be interesting ","actually to make it worse , morgan uses "" you "" and "" you "" now , why do you need to mark speaker overlap by hand if you can infer it from the relative energy in the ",
Bmr005.C,"especially because the bottleneck is the transcription . right ? we 've got a lot more data than we have transcriptions for . we have the audio data , we have the close talking mike , mean it seems like one project that 's not perfect , but that you can get the training data for pretty quickly is , if you infer form the close talking mikes where the on off points are of speech , how can we detect that from a far field ?  i 'm missed the  right , by hand .  right . i 'm  it it 's definitely good to have somebody look at it . i was just thinking as a way to speed up the amount of  it looks good . i 'll be in touch .  definitely . they can ask about the data , like very straightforward question is where we are on the amount of data and the amount of transcribed data , just cuz i 'm i wanted to get a feel for that to be able to can be done first and like how many meetings are we recording and how many meetings is that ? like how many t ten it 's like ten meetings  and and we 're recording only this meeting , like continuously we 're only recording this one now ? or ?  do they meet every week , or every great . there 's probably there 's three to four a week , that we 're aiming for . and they 're each about an hour    right . actually i have o not really . it 's three to four per week . that 's what that that 's not a lot of hours .  is there i know this sounds tough but we 've got the room set up . was starting to think of some projects where you would use similar to what we talked about with energy detection on the close talking mikes . there are a number of interesting questions that you can ask about how interactions happen in a meeting , that don't require any transcription . what are the patterns , the energy patterns over the meeting ? and i 'm really interested in this but we don't have a whole lot of data . was thinking , we 've got the room set up and you can always think of , also for political reasons , if icsi collected two hundred hours , that looks different than forty hours , even if we don't transcribe it ourselves ,  is there are there any other meetings here that we can record , especially meetings that have some conflict in them or some deci that are less don't that have some more emotional aspects to them , or strong there 's laughter , 'm talking more about strong differences of opinion meetings , with manager types , or to be allowed to record them ?   if there is , anyway . with lapel mikes right . ","like very straightforward question is where we are on the amount of data and the amount of transcribed data , there 's probably there 's three to four a week , and they 're each about an hour ","Topics discussed by the Berkeley Meeting Recorder group included a potential collaboration with another ICSI member regarding the analysis of inference structures, efforts by speaker mn005 to detect speaker overlap, the current status on recordings and transcriptions, and future efforts to collect meeting data. "
Bmr005.C,"right . no , that 'd be great , if we can get more data . or they 're not as averse to wearing one of these head mount they 're on the radio , right ? that 'd be fantastic cuz those kinds of panels and those have interesting th that 's an a side of style a style that we 're not collecting here ,  it 'd be great . right . was mostly trying to think , "" if you start a project , within say a month , how much data do you have to work with . and you wanna s you wanna fr freeze your data for awhile right now and we don't have the transcripts back yet from ibm right ? do do we now ? not complaining , i was just trying to think , what kinds of projects can you do now versus six months from now and they 're pretty different , because  right . right , right . cuz i 'm not actually just logistically that spend i don't wanna charge the time that i have on the project too early , before there 's enough data to make good use of the time . and that 's and especially with the student this guy who seems  anyway , i shouldn't say too much , but if someone came that was great and wanted to do some real work and they have to end by the end of this school year in the spring , how much data will i have to work with , with that person . and it 's and we just don't know about the transcription part of that ,  it right . i 'm thinking , politically  or just if you 're if you ha if there are meetings here that happen that we can record even if we don't have them do the digits , or have them do a shorter digit thing like if it was , one string of digits , they 'd probably be willing to do . then , having the data is very valuable , cuz it 's politically better for us to say we have this many hours of audio data , especially with the itr , if we put in a proposal on it . it 'll just look like icsi 's collected a lot more audio data . whether it 's transcribed or not is another issue , but there 's there are research questions you can answer without the transcriptions , or at least that you can start to answer .  need the close talking mikes .  i 'm really scared or at least me personally ? i would i couldn't use that data .  it 's a great idea , and if it were true than i would just do that , but it 's not that bad like the room is not the bottleneck , and we have enough time in the room , ","not complaining , i was just trying to think , what kinds of projects can you do now versus six months from now i don't wanna charge the time that i have on the project too early , before there 's enough data to make good use of the time . but there 's there are research questions you can answer without the transcriptions , or at least that you can start to answer . ",
Bmr005.C,"it 's getting the people to come in and put on the and get the setup going . what if really ? it 's the amount of right . what about these lunch meetings i don't know , if there 's any way without too much more overhead , even if we don't ship it right away to ibm even if we just collect it here for awhile , to record two or three more meeting a week , just to have the data , even if they 're not doing the digits , but they do wear the headphones ? no , i meant , the meetings where people eat their lunch downstairs , they don't wanna be recorded , but just the ch the chatting . i actually think that 's useful data , the chatting , but  you don't wanna do it , cuz  alright . alright , 'll just throw it out there , if anyone knows of one more m or two more wee meetings per week that happen at icsi , that we could record , it would be worth it . what if we give people we cater a lunch in exchange for them having their meeting here  alright , alright . no , definitely . i was thinking , there 's all these other peo    alright ,  and they 're already they 're these things are already recorded , we don't have to ask them to even and i 'm not wh how they record it , but they must record from individual why not ? we can find out . i know mark liberman was interested in ldc getting data , and   right . great .  that 's a good way to end a meeting . ","if anyone knows of one more m or two more wee meetings per week that happen at icsi , that we could record , it would be worth it . ","In addition to weekly meetings by the BMR group, efforts are in progress to record meetings by other ICSI research groups, as well as routine discussions by non-ICSI members. "
Bmr005.D,"transcript .   to right . interesting .       i remind that me my first objective in the project is to study difference parameters to find a good solution to detect the overlapping zone in speech recorded . but tsk , ehhh in that way i begin to study and to analyze the ehn the recorded speech the different session to find and to locate and to mark the different overlapping zone . and was am transcribing the first session and i have found one thousand acoustic events , besides the overlapping zones , mean the breaths aspiration talk clap , don't is the different names you use to name the n speech   i do i don't need to to m to label the different acoustic , but i prefer because would like to study if i will find a good parameters to detect overlapping i would like to test these parameters with the another acoustic events , to nnn to to find what is the ehm the false the false hypothesis nnn , which are produced when we use the ehm this parameter mean pitch difference feature      ye i t i talk about acoustic events in general , but my objective will be to study overlapping zone . n in twelve minutes i found one thousand acoustic events . how many ? almost three hundred in one session in five in forty five minutes . alm three hundred overlapping zone . with the overlapping zone , overlapping speech what different duration . three people , two people . would like to consider one people with difference noise in the background , be    i consider one event for th for that for all the zone . this th i con i consider an acoustic event , the overlapping zone , the period where three speaker or are talking together . don't understand .  no . no . for me is the overlapping zone , because you have s you have more one more one voice produced in a moment .  if    i consider the , nnn the nnn , nnn the entirety all the time there were the voice has overlapped . this is the idea . but don't distinguish between the numbers of speaker . i 'm not considering the ehm the fact of what did you say ? at first two talkers are speaking , and a third person join to that . for me , it 's it 's all overlap zone , with several numbers of speakers is the same acoustic event . wi but without any mark between the zone of the overlapping zone with two speakers speaking together , and the zone with the three speakers . it one . one . with a beginning mark and the ending mark . because for me , is the zone with some distortion the spectral . i don't mind by the moment , by the moment . i don't but have to study . what will happen in a general way , i don't will happen with the    but  but ","i remind that me my first objective in the project is to study difference parameters to find a good solution to detect the overlapping zone in speech recorded . and was am transcribing the first session and i have found one thousand acoustic events , besides the overlapping zones , mean the breaths aspiration talk clap , almost three hundred in one session in five in forty five minutes . i consider the , nnn the nnn , nnn the entirety all the time there were the voice has overlapped . but don't distinguish between the numbers of speaker . ","Topics discussed by the Berkeley Meeting Recorder group included a potential collaboration with another ICSI member regarding the analysis of inference structures, efforts by speaker mn005 to detect speaker overlap, the current status on recordings and transcriptions, and future efforts to collect meeting data. "
Bmr005.D,"general . i con i consider acoustic events the silent too . silent , ground to bec to detect because i consider acoustic event all the things are not speech . in ge in a general point of view . in the per too much speech .  silent , i don't i haven't the would like to do a stylistic study and give you with the report from the study from the session one session . and i found that another thing . when w i was look at nnn , the difference speech file , if we use the ehm the mixed file , to transcribe , the events and the words , i saw that the speech signal , collected by the this mike of this mike , are different from the mixed signal we collected by headphone . and it 's right . but the problem is the following . the the i knew that the signal would be different , but the problem is we detected difference events in the speech file collected by that mike qui compared with the mixed file . and if when you transcribe only using the nnn the mixed file , it 's possible if you use the transcription to evaluate a different system , it 's possible you in the i and you use the speech file collected by the fet mike , to to nnn to do the experiments with the system , its possible to evaluate or to consider acoustic events that which you marked in the mixed file , but they don't appear in the speech signal collected by the mike .  it 's a good idea . it 's a good idea     and i say that or this only because c i in my opinion , it 's necessary to to put the transcription on the speech file , collected by the objective signal . the signal collected by the the real mike in the future , in the prototype to correct the initial segmentation with the real speech you have to analyze you have to process . because i found a difference .      i saw the nnn the but have any results . i saw the speech file collected by the fet mike , and signal to noise relation is low . it 's low . it 's very low . you would comp if we compare it with the headphone . and i found that nnn that ehm , pr probably , i 'm not by the moment , but it 's probably that lot of in the overlapping zone , on in several parts of the files where you can find smooth speech from one talker in the meeting , it 's probably in that in those files you can not find you can not process because it 's confused with noise . and there are a lot of  but i have to study with more detail . but my idea is to process only nnn , this nnn , this of speech . ","i con i consider acoustic events the silent too . and i say that or this only because c i in my opinion , it 's necessary to to put the transcription on the speech file , collected by the objective signal . because i found a difference . but my idea is to process only nnn , this nnn , this of speech . ",
Bmr005.D,"because it 's more realistic . i 'm not it 's a good idea , but   with by jane .    the transcription by jane , t i want to use to nnn , to put i it 's a reference for me . but the transcription i don't i 'm not interested in the in the words , transcription words , transcribed in follow in the in the speech file , but jane put a mark at the beginning of each talker , in the meeting , she nnn includes information about the zone where there are there is an overlapping zone . but there isn't any mark , time temporal mark , to c to heh , to label the beginning and the end of the ta i 'm we need this information to twelve minutes . twelve minutes . twelve . no , forty five minutes is the session , all the session .  all is the session . tw twelve hours of work to segment and label twelve minutes from a session of part of f  no no . i consider all the session because count the nnn the overlappings marked by jane , in the fin in the forty five minutes .  but , by the moment , i don't compare , my temporal mark with jane , but want to do it . because per perhaps i have errors in the marks , i and if i compare with jane , it 's probably correct and to get more accurately transcription in the file .   no , it 's        it 's a good work , but think we need more information . no , no . i have to go to i want wanted to compare the transcription . only .    i w i wanted to nnn , i don't understand very .   on only to mark overlapping zone , but       because i need a lot of time to put the label or to do that .           more than ? how many ? not @ @ i onl only i transcribe only twelve minutes from the but don't co don't count the overlap . i consider i the nnn the three hundred is considered only you your transcription . i have to finish transcribing .       ","but the transcription i don't i 'm not interested in the in the words , transcription words , transcribed in follow in the in the speech file , but jane put a mark at the beginning of each talker , she nnn includes information about the zone where there are there is an overlapping zone . but there isn't any mark , time temporal mark , to c to heh , to label the beginning and the end of the i consider all the session because count the nnn the overlappings marked by jane , on only to mark overlapping zone , but  ",
Bmr005.E," doesn't look like it crashed . that 's great . and start by giving the transcript number . you see , don , the unbridled excitement of the work that we have on this project . it 's just it doesn't seem like a bad idea to have that information . i 'd it 's some that 's do have a an agenda suggestion . we the things that we talk about in this meeting tend to be a mixture of procedural mundane things and research points and was thinking it was a meeting a couple of weeks ago that we spent much of the time talking about the mundane cuz that 's easier to get out of the way and then we drifted into the research and five minutes into that andreas had to leave . 'm suggesting we turn it around and we have anybody has some mundane points that we could send an email later , hold them for a bit , and let 's talk about the research y things . the one th one thing i know that we have on that is we had talked a couple weeks before about the the you were doing with attempting to locate events , we had a little go around trying to figure out what you meant by "" events "" but what we had meant by "" events "" was points of overlap between speakers . but i th i gather from our discussion a little earlier today that you also mean interruptions with something else like some other noise . yes ? that as an event also . at any rate you were you 've done some work on that and then the other thing would be it might be to have a preliminary discussion of some of the other research areas that we 're thinking about doing . especially since you haven't been in these meetings for a little bit , you have some discussion of some of the p the plausible things to look at now that we 're starting to get data , and one of the things i know that also came up is some discussions that jane had with lokendra about some work about i d i don't want to try to say cuz i 'll say it wrong , but anyway some potential collaboration there about the working with these data .   i don't know if we if this is like everybody has something to contribute thing , there 's just a couple people primarily but wh why don't actually that last one said we could do fairly quickly why don't you start with that . just explain what it was . i should interject to say this started off with a discussion that i had with him , we were trying to think of ways that his interests could interact with ours ","the one th one thing i know that we have on that is we had talked a couple weeks before about the the you were doing with attempting to locate events , but what we had meant by "" events "" was points of overlap between speakers . and then the other thing would be it might be to have a preliminary discussion of some of the other research areas that we 're thinking about doing . and one of the things i know that also came up is some discussions that jane had with lokendra but anyway some potential collaboration there about the working with these data . we were trying to think of ways that his interests could interact with ours ","Topics discussed by the Berkeley Meeting Recorder group included a potential collaboration with another ICSI member regarding the analysis of inference structures, efforts by speaker mn005 to detect speaker overlap, the current status on recordings and transcriptions, and future efforts to collect meeting data. "
Bmr005.E,"and thought that if we were going to project into the future when we had a lot of data , and such things might be useful for that in or before we invested too much effort into that he should with jane 's help , look into some of the data that we 're already have and see , is there anything to this is there any point which you think that , you could gain some advantage and some potential use for it . cuz it could be that you 'd look through it and you say "" this is just the wrong task for him to pursue his "" and got the impression from your mail that there was enough things like this just in the little sample that you looked at that it 's plausible at least .    anyway , that 's e a quite different thing from anything we 've talked about that , might come out from some of this . he certainly could use text , but we were looking to see if there is there something in common between our interest in meetings and his interest in this  i don't know , probably de probably depends on what the prepared writing was . but .  could be . that would be tou these i probably been affect no , i th 've been affected by too many conversations where we were talking about lawyers and talking about and concerns about "" gee is somebody going to say something bad ? "" and on . and 'm i 'm tending to stay away from people 's names even though   no , there 's no , it isn't sensitive i was just i was overreacting just because we 've been talking about it . it 's to b but i there 's that . but also to some extent it 's just educating the human subjects people , in a way , because there 's if there 's court transcripts , there 's transcripts of radio shows people say people 's names all the time . think it can't be bad to say people 's names . it 's just that you 're right that there 's more poten if we never say anybody 's name , then there 's no chance of slandering anybody , but  right , my behavior is probably not natural .   we really can't . but a actually , i 'm i really would like to push finish this off . it 's i di i didn't intend it an a policy though . it was just it was just unconscious semi conscious behavior . i sorta knew i was doing it but it was i do i don't remember who "" he "" is .  we were talking about dan at one point and we were talking about lokendra at another point . and i don't remember which part .    good  you could do all these inferences ,   i would like to move it into what jose has been doing ","and thought that if we were going to project into the future when we had a lot of data , and such things might be useful for that in or before we invested too much effort into that he should with jane 's help , look into some of the data that we 're already have and got the impression from your mail that there was enough things like this just in the little sample that you looked at that it 's plausible at least . but we were looking to see if there is there something in common between our interest in meetings and his interest in this but a actually , i 'm i really would like to push finish this off . i would like to move it into what jose has been doing ",
Bmr005.E,"because he 's actually been doing something . right . how many overlaps were there in it ? no , how many of them were the overlaps of speech , though ?  no , but what she 's asking is if at some particular for some particular stretch you had three people talking , instead of two , did you call that one event ? i see .  think we just wanted to understand how you 're defining it . then , in the region between since there is some continuous region , in between regions where there is only one person speaking . and one contiguous region like that you 're calling an event . is it are you calling the beginning or the end of it the event , or are you calling the entire length of it the event ?  got it . could . we just w again , that 's three hundred in forty five minutes that are speakers , just speakers .  that 's about eight per minute .   how many of those thousand were silence ? right . how many of those thousand were silence , silent sections ?       the far field ,  just just in that one s ten second , or whatever it was , example that adam had that we passed on to others a few months ago , there was that business where i g it was adam and jane were talking at the same time and in the close talking mikes you couldn't hear the overlap , and in the distant mike you could . it 's clear that if you wanna study if you wanna find all the places where there were overlap , it 's probably better to use a distant mike . on the other hand , there 's other phenomena that are going on at the same time for which it might be useful to look at the close talking mikes , it 's some of it 's masking masked . right .     no i it 'd be hard , but on the other hand as you point out , if your if i if your concern is to get the overlapping people 's speech , you will get that somewhat better . are you making any use you were working with th the data that had already been transcribed . does it yes . now did you make any use of that ? see i was wondering cuz we st we have these ten hours of other that is not yet transcribed . do you   right , she is right . the twelve you it took you twelve hours this included some time where you were learning about what you wanted to do , but it took you something like twelve hours to mark the forty five minutes , your s twelve minutes ! you did forty five minutes of you haven't done the whole session . this is just twelve minutes .  let me back up again . ","how many overlaps were there in it ? then , in the region between since there is some continuous region , in between regions where there is only one person speaking . and one contiguous region like that you 're calling an event . the far field , it 'd be hard , but on the other hand as you point out , if your if i if your concern is to get the overlapping people 's speech , you will get that somewhat better . ",
Bmr005.E,"the when you said there were three hundred speaker overlaps , that 's in twelve minutes ?   it 's three hundred in forty five minutes , but you have time marked twelve minute the overlaps in twelve minutes of it . got it .    i have i but i have a suggestion about that . this is very , very time consuming , and you 're finding lots of things which i 'm are gonna be very interesting , but in the interests of making progress , might i s how would it affect your time if you only marked speaker overlaps ? yes . do not mark any other events , but only mark speaker do you think that would speed it up quite a bit ? do y do you think that would speed it up ? speed up your marking ? it took you a long time to mark twelve minutes . now , my suggestion was for the other thirty three and my question is , if you did that , if you followed my suggestion , would it take much less time ?  then it 's a good idea . then it 's a good idea , because it we know that there 's noise . there 's continual noise from fans and forth , and there is more impulsive noise from taps and forth and something in between with paper rustling . we know that all that 's there and it 's a g worthwhile thing to study , but it takes a lot of time to mark all of these things . whereas th i would think that you we can study more or less as a distinct phenomenon the overlapping of people talking . then you can get the cuz you need if it 's three hundred it sounds like you probably only have fifty or sixty or seventy events right now that are really and you need to have a lot more than that to have any even visual sense of what 's going on , much less any reasonable statistics . let 's back up because you weren't here for an earlier conversation . the idea was that what he was going to be doing was experimenting with different measures such as the increase in energy , such as the energy in the lpc residuals , such as there 's a bunch of things increased energy is an obvious one .  and it 's not obvious , you could do the dumbest thing and get it ninety percent of the time . but when you start going past that and trying to do better , it 's not obvious what combination of features is gonna give you the the right detector . the idea is to have some ground truth first . and the i the idea of the manual marking was to say "" this , i it 's really here "" .  we t w we t we talked about that . we talked about that . ","it 's three hundred in forty five minutes , but you have time marked twelve minute the overlaps in twelve minutes of it . it took you a long time to mark twelve minutes . now , my suggestion was for the other thirty three and my question is , if you did that , if you followed my suggestion , would it take much less time ? then it 's a good idea . the idea was that what he was going to be doing was experimenting with different measures such as the increase in energy , such as the energy in the lpc residuals , such as the idea is to have some ground truth first . and the i the idea of the manual marking was to say "" this , i it 's really here "" . ","Topics discussed by the Berkeley Meeting Recorder group included a potential collaboration with another ICSI member regarding the analysis of inference structures, efforts by speaker mn005 to detect speaker overlap, the current status on recordings and transcriptions, and future efforts to collect meeting data. "
Bmr005.E,"s but it 's a bootstrapping thing and the idea was , i we thought it would be useful for him to look at the data anyway , and then whatever he could mark would be helpful , and we could it 's a question of what you bootstrap from . do you bootstrap from a simple measurement which is right most of the time and then you g do better , or do you bootstrap from some human being looking at it and then do your simple measurements , from the close talking mike . even with the close talking mike you 're not gonna get it right all the time .   right , we discussed that . it 's see , this is where we really need the meeting recorder query to be working , because we 've had these meetings and we 've had this discussion about this , and i 'm remembering a little bit about what we decided , but i couldn't remember all of it . it was partly that , give somebody a chance to actually look at the data and see what these are like , partly that we have e some ground truth to compare against , when he gets his thing going , and that was exactly the notion that we discussed .  s see ya .  but that 's a refinement and we wanna see try the simple thing first , cuz you add this complex thing up afterwards that does something good y yo you wanna see what the simple thing does first . but having somebody have some experience , again , with with marking it from a human standpoint , we 're i don't expect jose to do it for fifty hours of speech , but we if if he could speed up what he was doing by just getting the speaker overlaps that we had it , say , for forty five minutes , then at least we 'd have three hundred examples of it . and when adam was doing his automatic thing he could then compare to that and see what it was different . then everybody owns it . it 's the people . i he 's pretty close , anyway . it 's good enough for government work , as they say . i don't know , it if we want to we should move on to other things in limited time .   was gonna ask , about any other things that either of you wanted to talk about , especially since andreas is leaving in five minutes , that you wanna go with . right there 's this forty five minute piece that jane transcribed . that piece was then sent to ibm they could transcribe we have some comparison point . then there 's a larger piece that 's been recorded and put on cd rom and sent to ibm . right ? and then we don't know . that was about ten hours , and there was about   ","the idea was , i we thought it would be useful for him to look at the data anyway , and then whatever he could mark would be helpful , but we if if he could speed up what he was doing by just getting the speaker overlaps that we had it , say , for forty five minutes , then at least we 'd have three hundred examples of it . and when adam was doing his automatic thing he could then compare to that and see what it was different . right there 's this forty five minute piece that jane transcribed . ",
Bmr005.E,"that 's right , that had those have not been sent . we 're saying about twelve hours . no . no , the that 's the biggest one chunk far , but there 's at least one meeting recorded of the natural language guys . and then there they do . w and we talked to them about recording some more and we 're going to , we 've started having a morning meeting , today starting a w a week or two ago , on the front end issues , and we 're recording those , there 's a network services and applications group here who 's to have their meetings recorded , and we 're gonna start recording them . they 're they meet on tuesdays . we 're gonna start recording them next week . actually , we 're gonna h start having a pretty significant chunk and adam 's struggling with trying to get things to be less buggy , and come up quicker when they do crash and things like that , now that the things are starting to happen . right now , i th i 'd say the data is predominantly meeting meetings , but there are scattered other meetings in it and that amount is gonna grow that the meeting meetings will probably ultimately i if we 're if we collect fifty or sixty hours , the meeting meetings it will probably be , twenty or thirty percent of it , not eighty or ninety . but .   and th the other thing is i 'm not pos i 'm thinking as we 've been through this a few times , that i really don't know you wanna do it once for the novelty , but i don't know if in general we wanna have meetings that we record from outside this group do the digits . because it 's just an added bunch of weird and , we h we 're highly motivated . the morning group is really motivated cuz they 're working on connected digits , it 's    definitely s whoever we have working on the acoustics for the meeting recorder are gonna start with that .  one of the things i wanted to do , that i talked to don about , is one of the possible things he could do or m also , we could have someone else do it , is to do block echo cancellation , to try to get rid of some of the effects of the far field effects . we have the party line has been that echo cancellation is not the right way to handle the situation because people move around , and if it 's not a simple echo , like a cross talk echo , but it 's actually room acoustics , it 's it 's you can't really do inversion , and even echo cancellation is going to be something it may you someone may be moving enough that you are not able to adapt quickly ","we 're saying about twelve hours . but there 's at least one meeting recorded of the natural language guys . we 've started having a morning meeting , today starting a w a week or two ago , on the front end issues , and we 're recording those , there 's a network services and applications group here who 's to have their meetings recorded , i if we 're if we collect fifty or sixty hours , the meeting meetings it will probably be , twenty or thirty percent of it , whoever we have working on the acoustics for the meeting recorder are gonna start with that . one of the things i wanted to do , that i talked to don about , is one of the possible things he could do or m also , we could have someone else do it , is to do block echo cancellation , ","In addition to weekly meetings by the BMR group, efforts are in progress to record meetings by other ICSI research groups, as well as routine discussions by non-ICSI members. "
Bmr005.E,"and the tack that we 've taken is more "" lets come up with feature approaches and multi stream approaches and forth , that will be robust to it for the recognizer and not try to create a clean signal "" . that 's the party line . but it occurred to me a few months ago that party lines are always , dangerous . it 's good to test them , actually . and we haven't had anybody try to do a good serious job on echo cancellation and we should know how that can do . that 's something i 'd like somebody to do at some point , just take these digits , take the far field mike signal , and the close mike signal , and apply really good echo cancellation . there was a have been some talks recently by lucent on their b the block echo cancellation particularly appealed to me , trying and change it sample by sample , but you have some reasonable sized blocks . and th it 's it you have a direct what 's the difference in if you were trying to construct a linear filter , that would   that would subtract off the parts of the signal that were the aspects of the signal that were different between the close talk and the distant . guess in most echo cancellation you given that you 're trying to you 'd there 's a distance between the close and the distant mikes there 's a time delay there , and after the time delay , there 's these various reflections . and if you figure out what 's the there 's a least squares algorithm that adjusts itself adjusts the weight that you try to subtract essentially to subtract off different reflections . right ? let 's take the simple case where you just had you had some some delay in a satellite connection and then there 's a there 's an echo . it comes back . and you want to adjust this filter that it will maximally reduce the effect of this echo . i 'm i 'm saying that 's a simplified version of what 's really happening . what 's really happening is when i 'm talking to you right now , you 're getting the direct sound from my speech , but you 're also getting , the indirect sound that 's bounced around the room a number of times .  now , if you try to r you to completely remove the effect of that is impractical for a number of technical reasons , but i but not to try to completely remove it , that is , invert the room response , but just to try to eliminate some of the effect of some of the echos . a number of people have done this that , say , if you 're talking to a speakerphone , it makes it more like it would be , if you were talking right up to it . ","and the tack that we 've taken is more "" lets come up with feature approaches and multi stream approaches and forth , that will be robust to it for the recognizer and not try to create a clean signal "" . that 's the party line . that 's something i 'd like somebody to do at some point , just take these digits , take the far field mike signal , and the close mike signal , and apply really good echo cancellation . that would subtract off the parts of the signal that were the aspects of the signal that were different between the close talk and the distant . you 're trying to you 'd there 's a distance between the close and the distant mikes there 's a time delay there , not to try to completely remove it , that is , invert the room response , but just to try to eliminate some of the effect of some of the echos . ",
Bmr005.E,"this is the st the straight forward approach . you say i want to use this this item but i want to subtract off various kinds of echos . you construct a filter , and you have this filtered version of the speech gets gets subtracted off from the original speech . then you try to minimize the energy in some sense . and with some constraints . it 's a clean up thing . right . echo cancelling is , commonly done in telephony , and it 's the obvious thing to do in this situation if you if , you 're gonna be talking some distance from a mike .  right . it 's taking samples , it 's doing adaptation , it 's adjusting weights , and then it 's getting the sum . anyway that 's reasonable thing that i 'd like to have somebody try somebody look and the digits would be a reasonable thing to do that with . that 'd be enough data plenty of data to do that with , and i for that task you wouldn't care whether it was large vocabulary speech or anything .  brian 's kingsbury 's work is an example of what we did f from the opposite dogma . right ? which is what i was calling the "" party line "" , which is that doing that thing is not really what we want . we want something more flexible , where people might change their position , and there might be , there 's also  noise . the echo cancellation does not really allow for noise . it 's if you have a clean situation but you just have some delays , then we 'll figure out the right set of weights for your taps for your filter in order to produce the effect of those echos . but if there 's noise , then the very signal that it 's looking at is corrupted that it 's decision about what the right right delays are is , is right delayed signal is is incorrect . and in a noisy situation , also in a situation that 's very reverberant with long reverberation times and really long delays , it 's typically impractical . for those reasons , and also a c a complete inversion , if you actually i mentioned that it 's hard to really do the inversion of the room acoustics . that 's difficult because often times the the system transfer function is such that when it 's inverted you get something that 's unstable , and if you do your estimate of what the system is , and then you try to invert it , you get a filter that actually rings , and goes to infinity . it 's there 's there 's that technical reason , and the fact that things move , and there 's air currents there 's all sorts of reasons why it 's not really practical . ","echo cancelling is , commonly done in telephony , and it 's the obvious thing to do in this situation if you if , you 're gonna be talking some distance from a mike . somebody look and the digits would be a reasonable thing to do that with . ",
Bmr005.E,"for all those kinds of reasons , we concluded we didn't want to in do inversion , and we 're even pretty skeptical of echo cancellation , which isn't really inversion , and we decided to do this approach of taking just picking features , which were will give you more something that was more stable , in the presence of , or absence of , room reverberation , and that 's what brian was trying to do . let me just say a couple things that i was gonna bring up . let 's see . you actually already said this thing about the about the consent forms , which was that we now don't have to this was the human subjects folks who said this , or that ?  back on the data thing , there 's this one hour , ten hour , a hundred hour thing that we have . we have an hour that is transcribed , we have twelve hours that 's recorded but not transcribed , and at the rate we 're going , by the end of the semester we 'll have , i don't know , forty or fifty if we if this really  do we have that much ? let 's see , we have eight weeks , is eight weeks times three hours is twenty four , that 's like thirty hours ? but i don't think we 're gonna stop at the end of this semester . right ? i th that if we are able to keep that up for a few months , we are gonna have more like a hundred hours . people will get i was gonna mention that . i 'd mentioned to adam , and that was another thing i was gonna talk mention to them before that there 's it oc it occurred to me that we might be able to get some additional data by talking to acquaintances in local broadcast media . because , we had talked before about the problem about using found data , that it 's just set up however they have it set up and we don't have any say about it and it 's typically one microphone , in a , or and it doesn't really give us the characteristics we want . and do think we 're gonna continue recording here and record what we can . but it did occur to me that we could go to friends in broadcast media and say "" hey you have this panel show , or this this discussion show , and can you record multi channel ? "" and they may be willing to record it with they probably already use lapel , but they might be able to have it wouldn't be that weird for them to have another mike that was somewhat distant . it wouldn't be exactly this setup , but it would be that thing , ","let 's see . you actually already said this thing about the about the consent forms , we have an hour that is transcribed , we have twelve hours that 's recorded but not transcribed , i th that if we are able to keep that up for a few months , we are gonna have more like a hundred hours . i 'd mentioned to adam , and that was another thing i was gonna talk mention to them before that there 's it oc it occurred to me that we might be able to get some additional data by talking to acquaintances in local broadcast media . but it did occur to me that we could go to friends in broadcast media and say "" hey you have this panel show , or this this discussion show , and can you record multi channel ? "" ",
Bmr005.E,"and what we were gonna get from uw , assuming they start recording , isn't als also is not going to be this exact setup . i was thinking of looking into that . the other thing that occurred to me after we had that discussion , is that it 's even possible , since many radio shows are not live , that we could invite them to have like some of their record some of their shows here . right .  and the the other side to it was the what which is where we were coming from i 'll talk to you more about it later is that there 's the radio stations and television stations already have worked out presumably , related to , legal issues and permissions and all that . they already do what they do whatever they do . it 's it 's it 's another source . think it 's something we should look into , we 'll collect what we collect here hopefully they will collect more at uw also and and we have this other source . but think that it 's not unreasonable to aim at getting , significantly in excess of a hundred hours . that was our goal . the thing was , i was hoping that we could @ @ in the under this controlled situation we could at least collect , thirty to fifty hours . and at the rate we 're going we 'll get pretty close to that this semester . and if we continue to collect some next semester , we should , we don't even have it for this f forty five minutes , that was  was thinking right now it 's this exploratory where you look at the data , you use some primitive measures and get a feeling for what the scatter plots look like , and and meanwhile we collect , and it 's more like three months from now , or six months from now you can do a lot of other things .  i would think , exploratory things now . three months from now the transcriptions are a bit of an unknown cuz we haven't gotten those back yet as far as the timing , but as far as the collection , it doesn't seem to me l like , unreasonable to say that in january , ro roughly which is roughly three months from now , we should have at least something like , twenty five , thirty hours . that 's  if they really have something they wanna talk about as opposed to something @ @ what we 're trying to stay away from was artificial constructions , but if it 's a real why not ?     i b i don't think the transcriptions are actually , in the long run , such a big bottleneck . the issue is just that we 're blazing that path . right ? ","the other thing that occurred to me after we had that discussion , is that it 's even possible , since many radio shows are not live , that we could invite them to have like some of their record some of their shows here . think it 's something we should look into , but think that it 's not unreasonable to aim at getting , significantly in excess of a hundred hours . i would think , exploratory things now . three months from now but as far as the collection , it doesn't seem to me l like , unreasonable to say that in january , ro roughly which is roughly three months from now , we should have at least something like , twenty five , thirty hours . ",
Bmr005.E,"and do you have any idea when the you 'll be able to send the ten hours to them ?    early next week we send it to them , and then we check with them to see if they 've got it and we start , asking about the timing for it . think once they get it sorted out about how they 're gonna do it , which they 're pretty along on , cuz they were able to read the files and on . right ?  but they have they 're volunteering their time and they have a lot of other things to do , right ? but they but at any rate , they 'll once they get that sorted out , they 're making cassettes there , then they 're handing it to someone who they who 's who is doing it , and think it 's not going to be i don't think it 's going to be that much more of a deal for them to do thirty hours then to do one hour , it 's not going to be thirty it 's just getting it going . but the lunch meetings are one person getting up and we should also check with mari again , because they were really intending , just didn't happen , but they were really intending to be duplicating this in some level . then that would double what we had . and there 's a lot of different meetings at uw mean really m a lot more than we have here right cuz we 're not right on campus ,  they seem to have some problems with it . we can talk about that later . but , again , jerry is jerry 's open mean , we have two speech meetings , one network meeting , jerry was open to it but i s one of the things that is a little bit of a limitation , there is a think when the people are not involved in our work , we probably can't do it every week . that people are gonna feel are gonna feel a little bit constrained . now , it might get a little better if we don't have them do the digits all the time . and the then then they can just really try to put the mikes on and then just charge in and but we c but we get some scattered things from this and that . and i d i do think that we can get somewhere with the radio . have better contacts in radio than in television , but  n no , i 'm not talking about ones that are already recorded . i 'm talking about new ones because we would be asking them to do something different . right , that 's the found data idea . ","and do you have any idea when the you 'll be able to send the ten hours to them ? think once they get it sorted out about how they 're gonna do it , which they 're pretty along on , cuz they were able to read the files and on . and think it 's not going to be i don't think it 's going to be that much more of a deal for them to do thirty hours then to do one hour , we should also check with mari again , because they were really intending , just didn't happen , but they were really intending to be duplicating this in some level . one of the things that is a little bit of a limitation , there is a think when the people are not involved in our work , we probably can't do it every week . that people are gonna feel are gonna feel a little bit constrained . ",
Bmr005.E,"but what i 'm saying is if i talk to people that i know who do these th who produce these things we could ask them if they could record an extra channel , let 's say , of a distant mike . and u routinely they would not do this . since i 'm interested in the distant mike i wanna make that there is at least that somewhere and but if we ask them to do that they might be intrigued enough by the idea that they might be e willing to the i might be able to talk them into it . don't why don't we why d u why don't we turn them turn turning off the microphone made it crash .   ",,
Bmr005.F,"can i to interrupt . i f i 've @ @ d a minute several minutes ago , i briefly was not listening and who is "" he "" in this context ?  was just realizing we 've you guys have been talking about "" he "" for at least i don't know , three four minutes without ever mentioning the person 's name again . this is this is gonna be a big , big problem if you want to later do indexing , or speech understanding of any sort . you just wrote this ? right .  right , but i missed it . but it was  if you ha since you have to go over the transcripts later anyway , you could make it one of the jobs of the people who do that to mark right . i still don't know who "" he "" is .  but no . the inference was lokendra .  that makes sense , as opposed to the rest of us . not speech or too much speech . that 's good . can i ask whether you found how accurate jane 's labels were as far as did she miss some overlaps ? or did she n ? right . right . i 'm expect i 'm not expecting no , i expect you to find more overlaps than jane because you 're looking at it at a much more detailed level . and you can or you can set the threshold low and then weed out the false alarms by hand .  and it might be different for government people . they  i was these meetings i 'm someone thought of this , but these this reading of the numbers would be extremely helpful to do adaptation .        ciao . i 'm signing off . ","was just realizing we 've you guys have been talking about "" he "" for at least i don't know , three four minutes without ever mentioning the person 's name again . this is this is gonna be a big , big problem if you want to later do indexing , or speech understanding of any sort . ",
Bmr005.G,"think what 's causing it to crash is i keep starting it and then stopping it to see if it 's working . and think starting it and then stopping it and starting it again causes it to crash . i won't do that anymore . no . i 'm gonna collect the digit forms and write it down .  they should be right with what 's on the digit forms . 'll go ahead and start with digits . u and i should say that you just pau you just read each line an and then pause briefly . and i 'm surprised i 'm surprised i forgot that , but think that would be a good thing to add . after printed out a zillion of them . you wanna just go around ? metaphorically . do you think his interest is in using this as a data source , or training material , or what ?   wrong ,  and i imagine that transcripts of speech text that is speech probably has more of those than prepared writing . i don't know whether it would or not , but it seems like it would .  i 'm just thinking , when you 're face to face , you have a lot of backchannel and  and think it 's just easier to do that broad inference jumping if it 's face to face . if read that dan was saying "" we 're ahead of the game "" in that context , i might not realize that he was talking about disk space as opposed to anything else .   it would be the same . it 's in my notes . he 's doing that intentionally , aren't you ? that would be interesting . especially with morgan , with the way we have the microphones arranged . i 'm right on axis and it would be very hard to tell .  but if i 'm talking like this ? right now i 'm looking at jane and talking , now i 'm looking at chuck and talking , i don't think the microphones would pick up that difference . if i 'm talking at you , or i 'm talking at you . lawyers . and we did mention who "" he "" was . early in the conversation . do sh can i say or is that just too sensitive ? it 's not a meeting . we t we talked about this during the anon anonymization . if we wanna go through and extract from the audio and the written every time someone says a name . and that our conclusion was that we didn't want to do that . the inference structures was lokendra .   i don't think we 've been doing it at that level of detail .   it was you weren't talking about just overlaps were you ? you were just talking about acoustic events . someone starts , someone stops   god ! ugh . let 's ",,
Bmr005.G,"let 's say me and jane are talking at the same time , and then liz starts talking also over all of us . how many events would that be ? two people are talking , and then a third person starts talking . is there an event right here ? if two or more people are talking . but you could imagine that three people talking has a different spectral characteristic than two . you had to start somewhere .  that 's a lot of overlap ,  for forty five minutes . silence starting or silence ending  right . right . right . the reason that i generated the mixed file was for ibm to do word level transcription , not speech event transcription . agree that if someone wants to do speech event transcription , that the mixed signals here if i 'm tapping on the table , you it 's not gonna show up on any of the mikes , but it 's gonna show up rather loudly in the pzm .  if you use the combination of the close talking mikes , you would hear jane interrupting me , but you wouldn't hear the paper rustling . and if you 're interested in right . although the other issue is that the mixed close talking mikes i 'm doing weird normalizations and things like that .  right .   did you it 's more realistic but it 'll be a lot harder . twelve minutes . not just the overlaps , everything . also jane was doing word level . we weren't concerned with exactly when an overlap started and stopped . right .  right . always need more for but if it takes sixty to one and right . that 's that 's what i was gonna bring up . that 's his , i 'm working on a program to do that , and and i 've written a program to do that , and it , and but it 's doing something very , very simple . it just takes a threshold , based on the volume , and then it does a median filter , and then it looks for runs . and , it seems to work , i 've i 'm fiddling with the parameters , to get it to actually generate something , and i haven't i don't what i 'm working on was getting it to a form where we can import it into the user interface that we have , into transcriber . and told i said it would take about a day . i 've worked on it for about half a day , give me another half day and i we 'll have something we can play with . but   and i haven't tried using that . it would probably help the program that i 'm doing to first feed it through that . it 's a cross correlation filter . ","the reason that i generated the mixed file was for ibm to do word level transcription , not speech event transcription . agree that if someone wants to do speech event transcription , that the mixed signals here if i 'm tapping on the table , you it 's not gonna show up on any of the mikes , but it 's gonna show up rather loudly in the pzm . ",
Bmr005.G,"haven't tried that , but that if it might be something it might be a good way of cleaning it up a little . exactly .  it seemed like the right thing to do . that was with zero literature search . that 's good validation . do you have a patent on it ? just output . although if you have some parameters like what 's a good window size for the median filter that 's alright . i was doing pretty short , tenth of a second , sorts of numbers . i b i bet they 're more , because the beginning of the meeting had a lot more overlaps than the middle . middle or end . because i we 're dealing with the in the early meetings , we 're recording while we 're saying who 's talking on what microphone , and things like that , and that seems to be a lot of overlap .  what 's that ? something like that . and then we i haven't sent them yet because i was having this problem with the missing files . about twelve by now . twelve or thirteen . nope . jerry . that 's what we 're aiming for . although  we 'll find out tomorrow whether we can really do this or not . right . actually that 's something i wanted to ask , is i have a bunch of scripts to help with the transcription of the digits . we don't have to hand transcribe the digits because we 're reading them and i have those . and have some scripts that let you very quickly extract the sections of each utterance . but i haven't been ru i haven't been doing that . if i did that , is someone gonna be working on it ? is it something of interest ?  i 'm interested in it , don't have time to do it now .   i would really like someone to do adaptation . if we got someone interested in that , it would be great for meeting recorder . since it 's the same people over and over . we had some good ones earlier . it 's hard to record those . that 's a good idea . that 's that would be a good match . right , as we are . right . right . stage some political debates . we don't have to do the digits if we don't want to .  it seems like it 's a big part of this corpus is to have the close talking mikes . i 've been burning two c ds a day , which is about all do with the time i have . it 'll be early next week .   but who knows where they are . nope . you we can't complain . that 's probably true . it 's pipeline , pipeline issues . once the pipeline fills . and we 're just chatting ? ","about twelve by now . twelve or thirteen . and have some scripts that let you very quickly extract the sections of each utterance . if i did that , is someone gonna be working on it ? i would really like someone to do adaptation . it 'll be early next week . it 's pipeline , pipeline issues . ",
Bmr005.G,"we have a lot of those . the problem with that is i would would feel a little constrained to some of the meetings our "" soccer ball "" meeting ? none of you were there for our soccer ball meeting . that was hilarious . right .  really doubt that any of the state of california meetings would be recordable and then releasable to the general public . mean i talked with some people at the haas business school who are i who are interested in speech recognition and , they hummed and hawed and said "" we could have meetings down here "" , but then i got email from them that said "" no , we decided we 're not really interested and we don't wanna come down and hold meetings . "" it 's gonna be a problem to get people regularly .  we 're getting towards the end of our disk space , we should think about trying to wrap up here . leave them on for a moment until i turn this off , cuz that 's when it crashed last time . ",it 's gonna be a problem to get people regularly . ,
Bmr005.H, umh . i have to go . ,,
Bmr019.A,"now you 're all watching me . alright . this way . you 're all watching . this is terrible . i 'll get it .  it 's this thing 's this is too big for my head . no , my but this is too big for my head . it doesn't it 's sit  no this way .  right . i already tried to get it close .  actually if you run , though , on a close talking mike over the whole meeting , during all those silences , you get four hundred percent word error . or some high number .  where who the speaker is and there 's no overlap ? and you do just the far field for those regions ? right . i understand that . meant that you have three choices . there 's , you can use times where that person is talking only from the transcripts but the segmentations were synchronized . or you can do a forced alignment on the close talking to determine that , the within this segment , these really were the times that this person was talking and elsewhere in the segment other people are overlapping and just front end those pieces . or you can run it on the whole data , which is which is , a in the h l t paper we took segments that are channel time aligned , which is now h being changed in the transcription process , which is good , and we took cases where the transcribers said there was only one person talking here , because no one else had time any words in that segment and called that "" non overlap "" . yes . tho good the good numbers . the bad numbers were from the segments where there was overlap .  right . we can do that .  right . it might also depend on which speaker th it is and how close they are to the pzm ? i don't know how different they are from each other . to be best f  we would then use that one , too , or ? you could look at , that pzm and aren't these pretty bad microphones ?  remember you saying you got them to be cheap on purpose . cheap in terms of their quality .   i see .  right .   yes , we have i don't know , did you wanna talk about it , or ? give a i was just telling this to jane and w we were able to get some definite improvement on the forced alignments by looking at them first and then realizing the kinds of errors that were occurring and some of the errors occurring very frequently are just things like the first word being moved to as early as possible in the recognition , which is a was both a pruning problem and possibly a problem with needing constraints on word locations . and we tried both of these st things . ","in the h l t paper we took segments that are channel time aligned , and we took cases where the transcribers said there was only one person talking here , and called that "" non overlap "" . the bad numbers were from the segments where there was overlap . and w we were able to get some definite improvement on the forced alignments by looking at them first and then realizing the kinds of errors that were occurring ","While debugging efforts resulted in improved forced alignments, dealing with mixed channel speech and speaker overlap remains a key objective for future work. "
Bmr019.A,"we tried saying i don't know , i got this whacky idea that just from looking at the data , that when people talk their words are usually chunked together . it 's not that they say one word and then there 's a bunch of words together . they 're might say one word and then another word far away if they were doing just backchannels ? but in general , if there 's five or six words and one word 's far away from it , that 's probably wrong on average .  and then also , ca the pruning , was too severe . actually it was better with slightly better or about th it was the same with tighter pruning . it 's probably cuz the recognition 's just bad en at a point where it 's bad enough that you don't lose anything . right . it isn't always true , and what we really want is some clever way to do this , where , from the data or from some hand corrected alignments from transcribers that things like words that do occur just by themselves a alone , like backchannels that we did allow to have background speech around it those would be able to do that , but the rest would be constrained . we have a version that 's pretty good for the native speakers . i don't know yet about the non native speakers . and , we also made noise models for the different grouped some of the mouth noises together . and then there 's a background speech model . and we also there was some neat or , interesting cases , like there 's one meeting where , jose 's giving a presentation and he 's talking about , the word "" mixed signal "" and someone didn't understand , that you were saying "" mixed "" morgan . and your speech ch was s saying something about mixed signal . and the next turn was a lot of people saying "" mixed "" , like "" he means mixed signal "" or "" it 's mixed "" . and the word "" mixed "" in this segment occurs bunch of times . and chuck 's on the lapel here , and he also says "" mixed "" but it 's at the last one , and the aligner th aligns it everywhere else to everybody else 's "" mixed "" , cuz there 's no adaptation yet . there 's there 's some issues about u we probably want to adapt at least the foreground speaker . but , andreas tried adapting both the foreground and a background generic speaker , and that 's actually a little bit of a f funky model . like , it gives you some weird alignments , just because often the background speakers match better to the foreground than the foreground speaker . there 's some things there , especially when you get lots of the same words , occurring in the ","actually it was better with slightly better or about th it was the same with tighter pruning . and what we really want is some clever way to do this , where , from the data or from some hand corrected alignments from transcribers that things like words that do occur just by themselves a alone , like backchannels that we did allow to have background speech around it those would be able to do that , but the rest would be constrained . we have a version that 's pretty good for the native speakers . and then there 's a background speech model . we probably want to adapt at least the foreground speaker . but , andreas tried adapting both the foreground and a background generic speaker , and that 's actually a little bit of a f funky model . like , it gives you some weird alignments , just because often the background speakers match better to the foreground than the foreground speaker . ",
Bmr019.A,"right . in general we actually right now the words like partial words are reject models and you normally allow those to match to any word . but then the background speech was also a reject model , and this constraint of not allowing rejects in between it needs to differentiate between the two . just working through a bunch of debugging kinds of issues . and another one is turns , like people starting with "" think "" and someone else is "" how about "" . the word "" is in this segment multiple times , and as soon as it occurs usually the aligner will try to align it to the first person who says it . but then that constraint of proximity constraint will push it over to the person who really said it in general . right now it 's a kluge .   i looked at them . i spent two days in waves it was painful because the alignments share a lot in common ,  and you 're yo you 're looking at these segments where there 's a lot of speech . a lot of them have a lot of words . not by every speaker but by some speaker there 's a lot of words . no , not that if you look at the individual segments from just one person you don't see a lot of words , but altogether you 'll see a lot of words up there . and the reject is also mapping and pauses looked at them all in waves and just lined up all the alignments , and , at first it looked like a mess and then the more i looked at it , it 's moving these words leftward and "" it wasn't that bad . it was just doing certain things wrong .  but , i don't , have time to l to look of them and it would be really useful to have transcriber who could use waves , just mark the beginning and end of the foreground speaker 's real words like , the beginning of the first word , the end of the last word and then we could , do some adjustments .   if you can , if you wanna jane and i were just in terms of the tool , talking about this . sue had some reactions . interface wise if you 're looking at speech , you wanna be able to know really where the words are . and we can give you some examples of what this output looks like , and see if you can in incorporate it into the transcriber tool some way , or  like word start insights . right .    it wou the advantage would just be that when you brought up a bin you would be able if you were zoomed in enough in transcriber to see all the words , you would be able to have the words located in time , if you wanted to do that .   ","just working through a bunch of debugging kinds of issues . and it would be really useful to have transcriber who could use waves , interface wise if you 're looking at speech , you wanna be able to know really where the words are . and we can give you some examples of what this output looks like , and see if you can in incorporate it into the transcriber tool some way , it wou the advantage would just be that when you brought up a bin you would be able if you were zoomed in enough in transcriber to see all the words , you would be able to have the words located in time , ","While debugging efforts resulted in improved forced alignments, dealing with mixed channel speech and speaker overlap remains a key objective for future work. "
Bmr019.A,"on the hand marked , we only r hav i only looked at actually alignments from one meeting that we chose , mr four , just randomly , and not randomly it had average recognition performance in a bunch of speakers and it was a meeting recorder meeting .  but , we should try to use what you have . i did re run recognition on your new version of mr one . the one with dan ellis in it and eric .  that actually it wasn't the new , it was the medium new . but we would we should do the latest version . it was the one from last week . right . right . right . don has had he knows he can just read it like a play . "" and then she said , and then he said . ""  right . that 's interesting .  no , that 's really interesting . that 's interesting . actu when we looked at this  right . it 's but it 's interesting cuz , but there are fewer there are fewer "" huhs "" . just from we were looking at word frequency lists to try to find the cases that we would allow to have the reject words in between in doing the alignment . the ones we wouldn't constrain to be next to the other words . and "" is not as frequent as it would be in switchboard , if you looked at just a word frequency list of one word short utterances . and "" is way up there , but not "" . and was thinking thi it 's not like you 're being encouraged by everybody else to keep talking in the meeting . and that 's all , i 'll stop there , cuz what you say makes a lot of sense . but it was right . there 's just probably less backchannelling in general , even if you consider every other person altogether one person in the meeting , but we 'll find out anyway . we were the other thing we 're i should say is that we 're gonna , try compare this type of overlap analysis to switchboard , where and callhome , where we have both sides , that we can try to answer this question of , is there really more overlap in meetings or is it just because we don't have the other channel in switchboard and we don't people are doing . try to create a paper out of that . the one due tomorrow ? we 're still writing the scripts for doing the research , and we will yes , we 're gonna try . and i was telling don , do not take this as an example of how people should work . we will try . it 'll probably be a little late , but i 'm gonna try it . right . i 'm no we may be in the same position , ","we only r hav i only looked at actually alignments from one meeting that we chose , but there are fewer there are fewer "" huhs "" . if you looked at just a word frequency list of one word short utterances . and "" is way up there , we were the other thing we 're i should say is that we 're gonna , try compare this type of overlap analysis to switchboard , and callhome , where we have both sides , that we can try to answer this question of , is there really more overlap in meetings or is it just because we don't have the other channel in switchboard and we don't people are doing . ",Members also discussed efforts to produce forced alignments from a selection of Meeting Recorder data. 
Bmr019.A,"and i figured we 'll try , because that 'll at least get us to the point where we have this really database format that andreas and i were working out that it 's not very fancy . it 's just a ascii line by line format , but it does give you information it we 're calling these "" spurts "" after chafe . i was trying to find what 's a word for a continuous region with pauses around it ? they do ?   i would jus right ! it 's just defined by the acoustics . right . right . that 's what we were calling spurt ,  chafe had this wor it was chafe , or somebody had a the word "" spurt "" originally , and but tha that 's good to know . was thi it 's chafe ? it was sue ? y we have spurts and we have spurt ify dot shell and spurt ify and then it 's got all it 's a verb now . yes . right . it looks like a waves label file almost . right ? it 's just these are things that we had don don propagated the punctuation from the original transcriber whether it was question mark or period or , comma and things like that , and we kept the and disfluency dashes kept those in because we wanna know where those are relative to the spurt overlaps sp overlaps , or that 's actually really u useful also because even if you weren't studying overlaps , if you wanna get a transcription for the far field mikes , how are you gonna know which words from which speakers occurred at which times relative to each other ? you have to be able to get a transcript like this anyway , just for doing far field recognition .  it 's i thi it 's just an issue we haven't dealt with before , how you time align things that are overlapping anyway . i never thought about it before , but right . but you can't get it directly from the transcription . this is like a poor man 's ver formatting version . but it 's , it 's clean , it 's just not fancy .   just huge .  it 's to know , and also as a human don't always hear these in the actual order that they occur . can have two foreground speakers , morgan an and adam and jane could all be talking , and i could align each of them to be starting their utterance at the correct time , and then look where they are relative to each other , and that 's not really what i heard . cuz it 's just hard to do . y it 's you move things around until you get to a low information point and yo then you can bring in the other person . ","and i figured we 'll try , because that 'll at least get us to the point where we have this really database format that andreas and i were working out that it 's just a ascii line by line format , it we 're calling these "" spurts "" after chafe . i was trying to find what 's a word for a continuous region with pauses around it ? because even if you weren't studying overlaps , if you wanna get a transcription for the far field mikes , how are you gonna know which words from which speakers occurred at which times relative to each other ? you have to be able to get a transcript like this anyway , just for doing far field recognition . ",
Bmr019.A,"it 's actually not even possible , for any person to listen to a mixed signal , even equalize , and make that they have all the words in the right order . we 'll try to write this eurospeech paper . we will write it . whether they accept it late or not , i don't know . and the good thing is that we have it 's beginning of what don can use to link the prosodic features from each file to each other .  i might as we i ju otherwise we won't get the work done on our deadline .  right . forces you to do the work . exactly . right .  right .    we 'll submit to s actually    they 'll get s it won't be after this deadline extension . they 'll do d do not we are not setting a good example . this is not a anyway . but the good thing is this does "" beep "" "" bee "" are we meeting in here probably or ?   we won't have enough microphones , but there 's no way . depends how fast you can throw it . it 's just  we don't even have enough channel at the same time . we c that 's their initiation into our w our our can you send out a schedule once it , jus ? is there a r ? there 's a res is it changed now , or ?  and w we should get the two meetings from y i know about the first meeting ,  but the other one that you did , the nsa one , which we hadn't done cuz we weren't running recognition on it , because the non native speaker there were five non native speakers . but , it would be useful for the to see what we get with that one .  three . right .  n s a three , i don't they said but i know the number . they are hard to understand . they 're very , out there . i have no idea what they 're talking about . it 's the person 's fault . it 's morgan 's fault .  tha there are some cases like where the wrong speaker these ca not a lot , but where the wrong person the speech is addre attached to the wrong speaker and you can tell that when you run it . or at least you can get clues to it . these are from the early transcriptions that people did on the mixed signals , like what you have .  if you can get it to      right . why is it that read your mind ? you this is our reward if we do our digi  jose .  we could do digits while other people eat . it 's background crunching . we don't have background chewing . no , we don't have any data with background eating . i 'm serious . you i am serious .  ","tha there are some cases like where the wrong speaker these ca not a lot , but where the wrong person the speech is addre attached to the wrong speaker ",
Bmr019.A,"and it you have to write down while y what you 're what ch chocolate you 're eating cuz they might make different sounds , like n nuts chocolate with nuts , chocolate without nuts . that w they might . those ? they 're i don't know . this is this is a different speech , looking at chocolates , deciding it 's another style .  and you laughed at me , too , f the first time i said that . you laughed at me , too , the first time i sa said you really shouldn't , te you have to jose , if you haven't done this , you have to plug your ears while you 're t talking that you don't get confused ,  you 've done this one before ? together ? i 'm not we and you haven't done this either . i the first time is traumatic , but that 'd be good . we 'll give everybody the same sheet but they say different different digits but same groupings . they would all be  he 's try no , he 's trying to get good recognition performance . ",,
Bmr019.B," could you close the door ,  the only other thing , for which i  there 's digits , alignments , and , the other thing , which i came unprepared for , is , to dis s see if there 's anything anybody wants to discuss about the saturday meeting .  any not .     right . it was  with whatever it was , a month and a half ahead of time , the only time we could find in common roughly in common , was on a saturday . ugh .  no . but , h he probably has to go do something . right ?  r right . we have to we we have to equip him with a with a head mounted , cell phone and  it 's the bre the breath noises and the mouth clicks and forth like that , the lapel 's gonna be better on . the lapel is typically worse on the on clothes rustling , but if no one 's rustling their clothes , it 's it 's   right . in the digits , in most cases , there weren't other people talking .  there typically don't , no . they 're intended to be omni directional . and th it 's and because you don't know how people are gonna put them on ,  we actually talked about this in the , front end meeting this morning , too . much the same thing , and it was there the point of interest to the group was primarily that , the , the system that we had that was based on h t k , that 's used by , all the participants in aurora , was much worse than the s r and the interesting thing is that even though , yes , it 's a digits task and that 's a relatively small number of words and there 's a bunch of digits that you train on , it 's just not as good as having a l very large amount of data and training up a good big also you had the adaptation in the sri system , which we didn't have in this .  i s stephane , had seen them .   but one thing is that , i would presume hav have you ever t have you ever tried this exact same recognizer out on the actual ti digits test set ? it might be interesting to do that . cuz my sense ,   bu although i 'd be it 'd be interesting to just take this exact actual system that these numbers were comparable and try it out on ti digits .    cuz our sense from the other from the aurora , task is that cuz we were getting sub one percent numbers on ti digits also with the tandem thing . one there were a number of things we noted from this . one is , the sri system is a lot better than the htk this , very limited training htk system . ","there the point of interest to the group was primarily that , the , the system that we had that was based on h t k , that 's used by , all the participants in aurora , was much worse than the s r and the interesting thing is that even though , yes , it 's a digits task and that 's a relatively small number of words and there 's a bunch of digits that you train on , it 's just not as good as having a l very large amount of data and training up a good big also you had the adaptation in the sri system , which we didn't have in this . bu although i 'd be it 'd be interesting to just take this exact actual system and try it out on ti digits . one is , the sri system is a lot better than the htk ",The Berkeley Meeting Recorder group discussed efforts to train and test the Aurora group's HTK-based recognition system on ICSI's digits corpus. 
Bmr019.B,"but the other is that , the digits recorded here in this room with these close mikes , i are actually a lot harder than the studio recording ti digits . one reason for that , might be that there 's still even though it 's close talking , there still is some noise and some room acoustics . and another might be that , i 'd i would presume that in the studio , situation recording read speech that if somebody did something a little funny or n pronounced something a little funny or made a little that they didn't include it , they made them do it again .        it 's wide band , it 's we looked it up and it was actually twenty kilohertz sampling .   see w   the other thing would be to do it without the adaptation and compare to these numbers without the adaptation . that would  most of ti digits is connected digits , the we had a bellcore corpus that we were using . it was that 's that was isolated digits .  but mean , w when you it depends whether you 're ju were just using this as a starter task for to get things going for conversational or if we 're really interested i in connected digits . and the answer is both . and for connected digits over the telephone you don't actually want to put a whole lot of effort into adaptation because somebody gets on the phone and says a number and then you just want it . you don't , right . right . that 'd be anoth another interesting data point . 'm saying i don't know if we 'd want to do that as the as at any rate , i don't know if w  i don't know if we wanna use that as the too many adju too many adjustments . anyway , what i was saying is that probably wouldn't want to see that as like the norm , that we compared all things to . to , the to have all this ad all this , adaptation . but it 's an important data point , if you 're if   the other thing that , what barry was looking at was just that , the near versus far . and , the adaptation would get th some of that . but , even if there was , only a factor of two like i was saying in the email , that 's a big factor .  n  it 's great . where were we ?  adaptation , non adaptation , factor of two ,  i was go w no . it 's tha that we were saying , is how much worse is far than near , and it depends on which one you 're looking at , but for the everybody , it 's little under a factor or two . ","but the other is that , the digits recorded here in this room with these close mikes , i are actually a lot harder than the studio recording ti digits . but it 's an important data point , if you 're if the other thing that , what barry was looking at was just that , the near versus far . ",Performance in both tasks was adversely affected by the manner of recording conditions implemented and difficulties attributing utterances to the appropriate speakers. 
Bmr019.B,"i was thinking was that i we could actually t try at least looking at , some of the large vocabulary speech from a far microphone , at least from the good one . before we 'd get , a hundred and fifty percent error but if , if we 're getting thirty five , forty percent u  right . i understand . but doing the same limited thing  get all these insertions . but i 'm saying if you do the same limited thing as people have done in switchboard evaluations or as a  the same numbers that we got those graphs from . right ? do it with one of on but how did we get the how did we determine the links , that we 're testing on in the we reported ? and tha and that 's what we were getting those numbers from . right . we could start with the good ones . but anyway think that we should try it once with the same conditions that were used to create those , and in those same segments just use one of the p z and then , if we were getting , what , thirty five , forty percent , something like that on that particular set , does it go to seventy or eighty ? or , does it use up much memory we can't decode it ?   this is central . it 's but i would i 'd pick that one . it 'll be less good for some people than for other , but i 'd like to see it on the same exact same data set that we did the other thing on . right ? that 's probably one of the reasons . but the other is , it 's very , mean , even though there 's i 'm the f the sri , front end has some pre emphasis , it 's it 's , still , th it 's picking up lots of low frequency energy . even discriminating against it , i 'm some of it 's getting through .  but , you 're right . prob a part of it is just the distance . they 're bad . but , if you listen to it , it sounds u they 're twenty five cents or   but , people use those little mikes for everything because they 're really not bad . if you 're not doing something ridiculous like feeding it to a speech recognizer , they you can hear the sou hear the sounds just fine . it 's they i it 's more or less the same principles as these other mikes are built under , it 's just that there 's less quality control . they just , churn them out and don't check them .  that was that was i interesting result . like i said , the front end guys are very much interested in this is as and what we wanna do is we want to ","i was thinking was that i we could actually t try at least looking at , some of the large vocabulary speech from a far microphone , but i 'm saying if you do the same limited thing as people have done in switchboard evaluations or as a and that 's what we were getting those numbers from . we could start with the good ones . but anyway think that we should try it once with the same conditions that were used to create those , and in those same segments just use one of the p z but i 'd like to see it on the same exact same data set that we did the other thing on . ",
Bmr019.B,"and we 've talked about this in other contexts we want to have the ability to feed it different features . and then , from the point of view of the front end research , it would be s substituting for htk . that 's the key thing . and then if we can feed it different features , then we can try all the different things that we 're trying there . and then , also dave is thinking about using the data in different ways , to explicitly work on reverberation starting with some techniques that some other people have found somewhat useful , and right . right . h he 's back , but he drove for fourteen hours an and wasn't gonna make it in today .  right .  've i   the s the next thing we had on the agenda was something about alignments ?   g given i wa i was gonna ask you anyway , how you assessed that things were better .       if we e even just had a it sounds like w we almost do . if we have two .  just ha trying out the alignment procedure that you have on that you could actually get something , get an objective measure .     h i tell you , i say i say "" a lot , while people are talking to each other .  y you folks have probably already told me , but were you intending to do a eurospeech submission , or ?  do as i say , don't do as i do .  i know that th the telecom people use "" spurt "" for that . yes . and that 's i was using that for a while when i was doing the rate of speech because i looked up in some books and i found i wanna find a spurt in which and an because cuz it 's another question about how many pauses they put in between them . but how fast do they do the words within the spurt ?  here . just very locally , but that just    that 's the good thing about these pape   no , it 's that 's the good thing about these pape paper deadlines and , class projects , and things like that , because you really get g  now it 's out in the public , this secret information .  no .  th that 's true . that 's that 's true . by th this is unfair , you may feel , but the , the morning meeting folks actually have an extra month or there 's a special aurora session and the aurora pe people involved in aurora have till ma early may to turn in their paper . i if it w  i it has no , it wouldn't work . it 's not the aurora it 's actually the aurora task . it  this is not the aurora task . they just do a little grep for  ","we want to have the ability to feed it different features . and then , from the point of view of the front end research , it would be s substituting for htk . and then , also dave is thinking about using the data in different ways , to explicitly work on reverberation but were you intending to do a eurospeech submission , ",The group is additionally focused on a continued ability to feed different features into the recognizer and then train the system accordingly. 
Bmr019.B,"it 's a littl little far fetched . nah , aurora 's pretty closed community . the people who were involved in the only people who are allowed to test on that are people who made it above a certain threshold in the first round , in ninety nine and it 's it 's not like a you don't like htk ? no . this it 's the htk that is trained on a very limited amount of data .  i really think that 's true . and they i i but u i but , one of the reasons i have chuck 's messing around with the back end that you 're not supposed to touch for the evaluations , yes , we 'll run a version that hasn't been touched . but , one of the reasons i have him messing around with that , because it 's an open question that we don't know the answer to . people always say very glibly that i if you s show improvement on a bad system , that doesn't mean anything , cuz it may not be show because , it doesn't tell you anything about the good system . and i 've always felt that depends . that if some peopl if you 're actually are getting at something that has some conceptual substance to it , it will port . and most methods that people now use were originally tried with something that was not their absolute best system at some level . but sometimes it doesn't , port . think that 's an interesting question . if we 're getting three percent error on , u english , nati native speakers , using the aurora system , and we do some improvements and bring it from three to two , do those same improvements bring , th the sri system from one point three to to point eight ?  that 's something we can test .  anyway . we 've covered that one up extremely    tha we 'll you guys 'll have one . you and , and dan have a paper that 's going in . that 's pretty solid , on the segmentation  and the aurora folks here will definitely get something in on aurora ,   right . h i it got better .      let 's see . the only thing we had left was unless somebody else there 's a couple things . one is anything that , anybody has to say about saturday ? anything we should do in prep for saturday ?  everybody knows about u mari was asking was trying to come up with something like an agenda and we 're fitting around people 's times a bit . but , clearly when we actually get here we 'll move things around this , as we need to , but you can't count on it . but ,  that was my thought . this is u no . i hadn't in intended to . ","you and , and dan have a paper that 's going in . that 's pretty solid , on the segmentation and the aurora folks here will definitely get something in on aurora , ",
Bmr019.B,"we won we wanna they 're there 's gonna be , jeff , katrin , mari and two students . there 's five from there . and brian 's coming , that 's six .    i hadn't really thought of it , but part of it . part of it . at the same time .  i don't know . any   sent it around a little bit . but i hadn't heard back from mari after i u brought up the point abou about andreas 's schedule . when i get back there 'll be some mail from her . i 'll make a th that part 's definitely gonna confuse somebody who looks at these later . this is we 're recording secret nsa meetings ? it 's it 's network services and applications .  it 's always morgan 's fault .  th the other thing i had actually was , i didn't realize this till today , but , this is , jose 's last day .  i d jus   somebody else will come along and will be , interested in working on it and could start off from where you are also , they 'd make use of what you 've done .  it 's a very short time .     jose .    unless somebody has something else , we 'll read our digits and we 'll get our get our last bit of , jose 's digit i 'm keep it away from that end of the table .   we 're gonna do digits at the same   tha that 's that looks great . alright , in the interest of getting to the she 's serious . she is serious .  actually careful cuz i have a strong allergy to nuts , have to figure out one without th it 's hard to say . i don't know .   i may hold off . but if i was but 'll get some later .  why don't we ? he 's worried about a ticket . why don't we do a simultaneous one ? simultaneous one ?  i have to what ? i did , and now i love it much . w minute . w we want we want it synchronized .  we y bu    no , no . synchronized digits . yes . there 's many possibilities . why don't we go ? one two three go ! and andreas has the last word . ",,
Bmr019.C,"i see .   have we thought about having a conference call to include him in more of the meeting ? i don't know , if we had the telephone on the table i see . no . it 's not good . that 's not good . this is this that one 's better .     if you have a strong fe if you have a strong preference , you could use this . it 's just we think it has some spikes . we didn't use that one . but you could if you want . i don't know . and andre andreas , your microphone 's a little bit low .  if you see the picture and then you have to scr that looks good .   this would be we think that this has spikes on it , it 's not as good acoustically , but if you 'd rather have this one then it 's and there 's a screw that you can tighten . good . that looks good .      i i have to ask you something , is i does it have to be waves ? because if we could benefit from what you did , incorporate that into the present transcripts , that would help . and then , the other thing is , i believe that i did hand one of these transcripts was gone over by a transcriber and then i hand marked it myself that we do have , the beginning and ending of individual utterances . i didn't do it word level , but in terms for one of the n s a groups . and also i went back to the original one that i first transcribed and did it w utterance by utterance for that particular one . think you do have if that 's a sufficient unit , that you do have hand marking for that . but it 'd be wonderful to be able to benefit from your waves  i used it in transcriber and it 's in the that 's right . middle of the word , or i th i 'm thinking just ch e incorporating it into the representation . if it 's if it 's if you have start points , if you have time tags , which is what i assume . isn't that what you ? see , adam would be if it ?  you would know this more than i would . it seems like she if she 's g if she 's moving time marks around , since our representation in transcriber uses time marks , it seems like there should be some way of using that benefitting from that . we have two . good . good ! exactly .   yes . yes , i did . and furthermore , i found that there were a certain number where not a lot , but several times i actually moved an utterance from adam 's channel to dan 's or from dan 's to adam 's . ","since our representation in transcriber uses time marks , it seems like there should be some way of using that benefitting from that . ",
Bmr019.C,"there was some speaker identif and the reason was because i transcribed that at a point before before we had the multiple audio available f couldn't switch between the audio . i transcribed it off of the mixed channel entirely , which meant in overlaps , i was at a terrific disadvantage . in addition it was before the channelized , possibility was there . and finally i did it using the speakers of my , of off the cpu on my machine cuz i didn't have a headphone . it @ @ mean i in retrospect it would 've been good to ha have got i should 've gotten a headphone . but in any case , thi this is this was transcribed in a , less optimal way than the ones that came after it , and i was able to an and this meant that there were some speaker identif identifications which were changes .  fixed that .    that was fixed , before understood that pretty for mentioning . no , tha that went away a couple of versions ago , but it 's good to know . with under listening to the mixed channel , there were times when , as surprising as that is , i got adam 's voice confused with dan 's and vice versa not for long utterances , but jus just a couple of places , and embedde embedded in overlaps . the other thing that was w interesting to me was that i picked up a lot of , backchannels which were hidden in the mixed signal , which , you c not too surprising . but the other thing that i hadn't thought about this , but i thou i wanted to raise this when you were with respect to also a strategy which might help with the alignments potentially , but that 's when i was looking at these backchannels , they were turning up usually very often in w i won't say "" usually "" but anyway , very often , i picked them up in a channel w which was the person who had asked a question . s someone says "" an and have you done the and "" and then there would be backchannels , but it would be the person who asked the question . other people weren't really doing much backchannelling . and , sometimes you have the i it wouldn't be perfect , but it does seem more natural to give a backchannel when you 're somehow involved in the topic , and the most natural way is for you to have initiated the topic by asking a question .   exactly . exactly . exactly my point . an and this is the expectation thing that just the dyadic but in addition , if someone has done this analysis himself and isn't involved in the dyad , but they might also give backchannels to verify what the answer is that this that the answerer 's given there you go . ","fixed that . the other thing that was w interesting to me was that i picked up a lot of , backchannels which were hidden in the mixed signal , when i was looking at these backchannels , they were turning up usually very often in w i won't say "" usually "" but anyway , very often , i picked them up in a channel w which was the person who had asked a question . ",
Bmr019.C,"there you go .    that 's right . and that would an and what you say is the re o other side of this , which is that , th there are lots of channels where you don't have these backchannels , w when a question has been asked and these  that 's good news , really .   good . actually see , i know s sue wrote about spurts of development . but , in any case , it 's a good term , and , and ma chafe did . i know ch chafe dealt with chafe speaks about intonation units . but he speaks about spurts as and don't know . go ahead . great . that 's wonderful .  that 's right . what 's interesting is it 's exactly what , i in discussing with , sue about this , she , i indicated that that 's very important for overlap analysis . and that 's another thing she said . this is bever 's effect , when where in psy ps psycho linguistics you have these experiments where people have perceptual biases a as to what they hear , that not the best  superb . what i 'm thinking is  my  we can ha nah . and good ones , good ones , which sometimes means a little extra time .  i 'm looking forward to seeing your representation . that 'd be , i 'd like to see that .    i see .  great .  it 's , two thousand eleven twenty one thousand . great . i sent email when i finished the that one . that was son that 's right . that 's right . that 's much simpler . not that nsa . interesting . it does w  it also raises the possibility of , using that representation i don't know , this 'd be something we 'd wanna check , but using that representation for data entry and then displaying it on the channelized , representation , cuz it that the my preference in terms of looking at the data is to see it in this musical score format . and also , s sue 's preference as and but , this if this is a better interface for making these kinds of , lo clos local changes , then that 'd be fine , too . i don't i have no idea . this is something that would need to be checked .     great .   we have a time we have a s a time constraint .    that 's   very    hey , you 've done this before . haven't you ? you 've read digits together with us , haven't you at the same time ? you haven't !  and the groupings are important , yo you 're supposed to pause between the groupings . no . no . that 'd be good . and then we can sing them next time .   he had the h he had the long form . ",,
Bmr019.D,"forced align .  a cell phone ?  and with the kids in the background .   or the cross talk .   you don't move much during reading digits ,  other way .  it 's further away .             i will send you the final version , which is not     the last meeting ?   during during digits . no , no .  simultaneous digit chocolate task .   background crunch .   crunchy frogs .  that 's   ",,
Bmr019.E,"we 're on . everyone who 's on the wireless check that they 're on . our agenda was quite short .  two items , which was , digits and possibly on , forced alignment , which jane said that liz and andreas had in information on , but they didn't ,   right . digits and alignments . but  it 's forced alignment of people 's schedules .   ye we and we 'd have to force you to read lots and lots of digits , it could get real car noise . anyway , talk about digits . did everyone get the results or shall i go over them again ? that it was the only thing that was even slightly surprising was that the lapel did and in retrospect that 's not as surprising as it shouldn't have been as surprising as i felt it was . the lapel mike is a very high quality microphone . and as morgan pointed out , that there are actually some advantages to it in terms of breath noises and clothes rustling if no one else is talking .  right . a lot of people are just leaning over and reading the digits , it 's a very different task than the natural .  right . right . right . they have a little bit , but they 're not noise cancelling .  right . right . also , andreas , on that one the back part of it should be right against your head . and that will he keep it from flopping aro up and down as much .   everybody . no . or if you did , i didn't include them , cuz it was right . i bet it would do even slightly better . no problem . and try it with ti digits ? they didn't include it . whereas , i took out the ones that i noticed that were blatant that were correctable . that , if someone just read the wrong digit , i corrected it . and then there was another one where jose couldn't tell whether i couldn't tell whether he was saying zero or six . and i asked him and he couldn't tell either . just cut it out . just e edited out the first , i word of the utterance . there 's a little bit of correction but it 's definitely not as clean as ti digits . my expectations is ti digits would , especially ti digits is all american english . right ? it would probably do even a little better still on the sri system , but we could give it a try . wha what 's ti digits ?  it is wide band .  that 's right . i did look that up . i couldn't remember whether that was ti digits or one of the other digit tasks .  morgan , you 're getting a little breath noise . you might wanna move the mike down a little bit . ","two items , which was , digits and possibly on , forced alignment , that it was the only thing that was even slightly surprising was that the lapel did ",Members also discussed efforts to produce forced alignments from a selection of Meeting Recorder data. 
Bmr019.E,"i noticed the script that extracted it .   that i don't know . i don't know . i don't know how many speakers there are , and how many speakers per utterance . right . i strongly suspect that they have more speakers than we do .  right . we could probably do an extraction that was roughly equivalent .  although i know how to run it , there are a little a f few details here and there that i 'll have to dig out . right . i saw that . right . right . and that , right . i might have to do that anyway to do because we may have to do an extract to get the amount of data per speaker about right . the other thing is , isn't ti digits isolated digits ? or is that another one ? i 'm i looked through a bunch of the digits t corp corpora , and now they 're all blurring . cuz one of them was literally people reading a single digit . and then others were connected digits .  it 's the bell gram . bell digits . alright .  channel adapted . other way . liz it f it clips over your ears . there you go . it pivots . it like this .  these mikes are not working as as i would like . liz , you could also just use the other mike if you 're having problems with that one .  the to get that , pivoted this way , it pivots like this .  there you go . and then it right . if it doesn't bounce around too much , that 's actually good placement . but it looks like it 's gonna bounce a lot . digits . adaptation . could we do exactly the same thing that we 're doing now , but do it with a far field mike ? cuz we extract the times from the near field mike , but you use the acoustics from the far field mike . for this particular digit ones , picked that one .  actually i sh actually should 've picked a different one , because that could be why the pda is worse . because it 's further away from most of the people reading digits .   when you listen to it , the pzm and the pda th the pda has higher sound floor but not by a lot . it 's really pretty the same . th we wanted them to be typical of what would be in a pda . they are they 're not the pzm three hundred dollar type . they 're the twenty five cent , buy them in packs of thousand type . everything . that was gonna be my question .  we do we tend to do that anyway .  although you can pipe it as we tend to do it that way ","because we may have to do an extract to get the amount of data per speaker about right . could we do exactly the same thing that we 're doing now , but do it with a far field mike ? cuz we extract the times from the near field mike , but you use the acoustics from the far field mike . i sh actually should 've picked a different one , because that could be why the pda is worse . because it 's further away from most of the people reading digits . we do we tend to do that anyway . ",
Bmr019.E,"because that way you can concentrate on one block and not keep re doing it over and over . tha that 's exactly what the p file is for .  no gain . is the proximity constraint a hard constraint , or did you do some probabilistic weighting distance , or ? the ve level .  transcriber , outputs ctm .  right .   it is different . in previous years , eurospeech only had the abstract due by now , not the full paper . and all our timing was off . i 've given up on trying to do digits . don't think that what i have far makes a eurospeech paper . horrible . it 's gonna burst . spurt has the horrible name overloading with other with hardware at icsi .  i 've heard "" burst "" also . right .  y yes . s when i came up with the original data suggested data format based on the transcription graph , there 's capability of doing that thing in there . right .  strict . no . right . the aurora there 's a special aurora i could ! i could submit that to aurora . that would be pretty s that wouldn't work . it 's not aurora . aurora 's very specific . you meant this was just the digits section . i didn't know you meant it was aurora digits . i don't know . you could do a paper on what 's wrong with the aurora task by comparing it to other ways of doing it . different way .  pretty hokey .  it 's very specific . th it 's d it 's very specific . but they had they had something very specific in mind when they designed it . right ? and you can argue about that wasn't the right thing to do , but , they had something specific . zero . hey , that 's the same percent relative ,  twenty percent relative gain . and brian . and plus all of us . it seems like too many too much coming and going . make everyone read digits . at the same time . into our cult .   you 're not gonna be here tomorrow ? that 's right . tomorrow it 's off .  it was good having you .  six months is hard . year is a lot better . great . digits ? are we gonna do them simultaneously or ? we 've gotta until after di after we take the mikes off . are we gonna do digits simultaneously or what ? it 's just the rest of the digits are very clean , without a lot of background noise , 'm just not  remember to read the transcript number , everyone ready ?  hey , what a good idea . we could do the same sheet for everyone . have them all read them at once . or just same digits . see if anyone notices . ",,
Bmr019.E,did you read it twice or what ? and we 're off . ,,
Bmr019.F,"c we   we should do that second , because liz might join us in time for that . talk about aligning people 's schedules .  if we 're very  it 's pretty sad .  no , actually i have to shuttle kids from various places to various other places .  and i don't have and i don't , have a cell phone can't be having a conference call while driving . plus , it would make for interesting noise background noise .    i 'll let i 'd let i let , my five year old have a try at the digits ,  exactly . d do the lapel mikes have any directionality to them ? because i suppose you could make some that have that you have to orient towards your mouth , and then it would  it is against my head . and we know di did i send you some results without adaptation ? did , actually . there was a significant loss from not doing the adaptation .  a couple percent or some  i don't know it overall i don't remember , but there was a significant , loss or win from adaptation with adaptation . and , that was the phone loop adaptation . and then there was a very small like point one percent on the natives win from doing , adaptation to the recognition hypotheses . and i tried both means adaptation and means and variances , and the variances added another or subtracted another point one percent . it 's , that 's the number there . point six , i believe , is what you get with both , means and variance adaptation . this exact same recognizer ? no . but , i have people at sri are actually working on digits . i could and they are using a system that 's , h is actually trained on digits , but h otherwise uses the same , decoder , the same , training methods , and forth , and i could ask them what they get on ti digits .  adam knows how to run it , you just make a f         but remember , we 're using a telephone bandwidth front end here , on this , on this sri system , i was that that 's actually a good thing because it gets rid of some of the the noises , in the below and above the the , speech bandwidth and , i suspect that to get the last bit out of these higher quality recordings you would have to use models that , were trained on wider band data . and we can't do that or  right . but , i would  it 's easy enough to try , just run it on now , does one issue one issue with that is that the system has this , notion of a speaker to which is used in adaptation , variance norm both in , mean and variance normalization and also in the vtl estimation .  ","there was a significant loss from not doing the adaptation . but remember , we 're using a telephone bandwidth front end here , on this , on this sri system , i suspect that to get the last bit out of these higher quality recordings you would have to use models that , were trained on wider band data . ",
Bmr019.F,"do y ? is ? does th does , the ti digits database have speakers that are known ? and is there enough data or a comparable amount of data to what we have in our recordings here ?  right . but i 'm not much worried about the adaptation , actually , than the , the , vtl estimation . if you have only one utterance per speaker you might actually screw up on estimating the warping , factor .  right . but it 's not the amount of speakers , it 's the num it 's the amount of data per speaker . right . right .   the key th the system actually extracts the speaker id from the waveform names . and there 's a script and that is actually all in one script . there 's this one script that parses waveform names and extracts things like the , speaker , id that can stand in as a speaker id . we might have to modify that script to recognize the , speakers , in the in the , ti digits database . or you can fake names for these waveforms that resemble the names that we use here for the meetings . that would be the , probably the safest way to do  right . we can improve these numbers if we care to compr improve them by , not starting with the switchboard models but by taking the switchboard models and doing supervised adaptation on a small amount of digit data collected in this setting . because that would adapt your models to the room acoustics and f for the far field microphones , to the noise . and that should really improve things , further . and then you use those adapted models , which are not speaker adapted but acous channel adapted use that as the starting models for your speaker adaptation . i don't know . right . but , i my impression was that you were actually interested in the far field microphone , problem ,   you want to that 's the obvious thing to try . right ? then , because you don't have any that 's where the most m acoustic mismatch is between the currently used models and the r the set up here .   it is ?  i i already adjusted this a number of times . i can't quite seem to this contraption around your head is not working right .   your ears are too big . mine are too . e th everybody 's ears are too big for these things .  what k u wh what factor of two did you ?  th that factor of two .    you want to probably choose the pzm channel that is closest to the speaker .   but where is this now ? what 's where do we go from here ?  we we have a system that works pretty but it 's not , the system that people here are used to using to working with . ","right . but i 'm not much worried about the adaptation , actually , than the , the , vtl estimation . if you have only one utterance per speaker you might actually screw up on estimating the warping , factor . we might have to modify that script to recognize the , speakers , in the in the , ti digits database . we can improve these numbers if we care to compr improve them by , not starting with the switchboard models but by taking the switchboard models and doing supervised adaptation on a small amount of digit data collected in this setting . that 's where the most m acoustic mismatch is between the currently used models and the r the set up here . you want to probably choose the pzm channel that is closest to the speaker . what 's where do we go from here ? ",Performance in both tasks was adversely affected by the manner of recording conditions implemented and difficulties attributing utterances to the appropriate speakers. 
Bmr019.F,"what do we do now ?    alright .   the key thing that 's missing here is the ability to feed , other features i into the recognizer and also then to train the system .  and , es i don't know when chuck will be back but that 's exactly what he 's gonna  that 's one of the things that he said he would be working on .  just to make that we can do that and it 's the front end is f i tha that 's in the sri recognizer is very in that it does a lot of things on the fly but it unfortunately is not designed and , like the , icsi system is , where you can feed it from a pipeline of the command . the what that means probably for the foreseeable future is that you have to , dump out , if you want to use some new features , you have to dump them into individual files and give those files to the recognizer .   alright . the cumbersome thing is , is that you actually have to dump out little files . for each segment that you want to recognize you have to dump out a separate file . just like i th like th as if there were these waveform segments , but instead you have feature file segments . but ,  that 's actually interesting . the pruning was the same value that we used for recognition . and we had lowered that we had used tighter pruning after liz ran some experiments showing that , it runs slower and there 's no real difference in right . for free recognition , this the lower pruning value is better . you correct . right . but it turned out for to get accurate alignments it was really important to open up the pruning significantly . because otherwise it would do greedy alignment , in regions where there was no real speech yet from the foreground speaker . that was one big factor that helped improve things and then the other thing was that , as liz said the we f enforce the fact that , the foreground speech has to be continuous . it cannot be you cannot have a background speech hypothesis in the middle of the foreground speech . you can only have background speech at the beginning and the end .  the you can do better by cloning we have a reject phone . and you and what we wanted to try with once we have this paper written and have a little more time , t cloning that reject model and then one copy of it would be adapted to the foreground speaker to capture the rejects in the foreground , like fragments and and the other copy would be adapted to the background speaker . and  right . we didn't no . we w  we it 's straightforward to actually just have a penalty that doesn't completely disallows it but discourages it . ","the key thing that 's missing here is the ability to feed , other features i into the recognizer and also then to train the system . it 's the front end is f i tha that 's in the sri recognizer is very in that it does a lot of things on the fly the what that means probably for the foreseeable future is that you have to , dump out , if you want to use some new features , you have to dump them into individual files the cumbersome thing is , is that you actually have to dump out little files . for free recognition , this the lower pruning value is better . but it turned out for to get accurate alignments it was really important to open up the pruning significantly . that was one big factor that helped improve things as liz said the we f enforce the fact that , the foreground speech has to be continuous . and you and what we wanted to try with once we have this paper written and have a little more time , t cloning that reject model and then one copy of it would be adapted to the foreground speaker to capture the rejects in the foreground , and the other copy would be adapted to the background speaker . ",The group is additionally focused on a continued ability to feed different features into the recognizer and then train the system accordingly. 
Bmr019.F,"but , we just didn't have time to play with , tuning yet another parameter . and really the reason we can't do it is just that we don't have a we don't have ground truth for these . we would need a hand marked , word level alignments or at least the boundaries of the speech betw between the speakers . and then use that as a reference and tune the parameters of the model , to op to get the best performance .   no .  we don't care what tool you use . u whatever you use . we convert it to this format that the , nist scoring tool unders ctm . conversation time marked file . and then that 's the that 's what the right .  actually , not randomly . we knew that it had these insertion errors from     no . it 's actually what 's going on is backchannelling is something that happens in two party conversations . and if you ask someone a question , you essentially initiating a little two party conversation . then you 're and then you 're expected to backchannel because the person is addressing you directly and not everybody .   right . right . and it 's the spurt format .  we should talk   w w we what we 're doing this is just someone has s some ideas about how to do it better , but we we 're taking these , alignments from the individual channels . we 're from each alignment we 're producing , one of these ctm files , which essentially has it 's just a linear sequence of words with the begin times for every word and the duration . and right . but it has one the first column has the meeting name , it could actually contain several meetings .  and the second column is the channel . third column is the , start times of the words and the fourth column is the duration of the words . and then we 're ,  then we have a messy alignment process where we actually insert into the sequence of words the , tags for where sentence ends of sentence , question marks , various other things .  right .  right . those are actually retro fitted into the time alignment . and then we merge all the alignments from the various channels and we sort them by time . and then there 's a process where you now determine the spurts . that is actually , no , you do that before you merge the various channels . you id identify by some criterion , which is pause length you identify the beginnings and ends of these spurts , and you put another set of tags in there to keep those straight . and then you merge everything in terms of , linearizing the sequence based on the time marks . and then you extract the individual channels again , but this time where the other people start and end talking ","we would need a hand marked , word level alignments or at least the boundaries of the speech betw between the speakers . and tune the parameters of the model , to op to get the best performance . it 's the spurt format . from each alignment we 're producing , one of these ctm files , which essentially has it 's just a linear sequence of words with the begin times for every word and the duration . and the second column is the channel . third column is the , start times of the words and the fourth column is the duration of the words . then we have a messy alignment process where we actually insert into the sequence of words the , tags for where sentence ends of sentence , and then we merge all the alignments from the various channels and we sort them by time . ",
Bmr019.F,"where their spurts start and end . and you extract the individual channels , one sp spurt by spurt as it were . and inside the words or between the words you now have begin and end tags for overlaps . you have everything lined up and in a form where you can look at the individual speakers and how their speech relates to the other speakers ' speech . and   and we in right . this is just there 's lots of little things . it 's like there 're twelve different scripts which you run and then at the end you have what you want . but , at the very last stage we throw away the actual time information . all we care about is whether that there 's a certain word was overlapped by someone else 's word . you at that point , you discretize things into just having overlap or no overlap . because we figure that 's about the level of analysis that we want to do for this paper . but if you wanted to do a more fine grained analysis and say , how far into the word is the overlap , you could do that . it 's just it 'll just require more slightly different right .  plus , mayb i don't know , m u jane likes to look at data . you could look at this format and see if you find anything interesting . i don't know .   th the other thing that yo that you usually don't tell your graduate students is that these deadlines are actually not that , strictly enforced , because the because bec b nah i because these the conference organizers actually have an interest in getting lots of submissions . a monetary interest .  and good submission right .  that 's another issue , but  when   then you can just you can submit the digits paper on e for the aurora session .  but the people a paper that is not on aurora would probably be more interesting at that point because everybody 's sick and tired of the aurora task . no . if you have it 's to if you discuss some relation to the aurora task , like if you use the same  a relation other than negation ,   i don't know . how does an aurora system do on on digits collected in a in this environment ?    that 's why they don't f know that they have a crummy system . a crummy back end . no , mean , if you have a very no , i 'm no . i didn't mean anybody any particular system . i meant this h t k back end . if they i don't h i don't have any stock in htk or entropic or anything . right . but if you but you should , consider more using more data , or ","and you extract the individual channels , one sp spurt by spurt as it were . and inside the words or between the words you now have begin and end tags for overlaps . you have everything lined up and in a form where you can look at the individual speakers and how their speech relates to the other speakers ' speech . all we care about is whether that there 's a certain word was overlapped by someone else 's word . you at that point , you discretize things into just having overlap or no overlap . because we figure that 's about the level of analysis that we want to do for this paper . ",
Bmr019.F,"if yo if you hermetically stay within one task and don't look left and right , then you 're gonna right .        right .  whew ! actually this , there 's another paper . it 's a eurospeech paper but not related to meetings . but it 's on digits .  a colleague at sri developed a improved version of mmie training . and he tested it mostly on digits because it 's it doesn't take weeks to train it .  and got some very impressive results , with , discriminative , gaussian training . error rates go from i don't know , in very noisy environment , like from ,  i for now i now i have the order of magnit i 'm not about the order of magnitude . was it like from ten percent to eight percent or from e point from one percent to point eight percent ? it 's a it got better . that 's the important thing .  but it 's right . it 's , something in right .  are we recording it ?  but th  can use the oprah mike .  because it would be a different meeting , that 's what i 'm but just not the whole day but just , some part of it ?  the sections that are not right afte after lunch when everybody 's still munching and right .  not the   the th the  the the , th the other good thing about the alignments is that , it 's not always the machine 's fault if it doesn't work . you can actually find , problem proble you can find you can find , problems with the transcripts ,  and go back and fix them . but        have a good trip . keep in touch . no , we prefer to keep it for ourselves .        th it doesn't it won't leave this room .    chocolate adaptation .     right . that the grouping is supposed to be synchronized ? no ? no ? it 's like a greek like a greek choir ?  like  no . ","th the other good thing about the alignments is that , it 's not always the machine 's fault if it doesn't work . you can find , problems with the transcripts , ",
Bmr019.G,"alright . take advantage .  it 's g it probably the fact that it picks up other people 's speakers other people 's talking is an indication of that it the fact it is a good microphone .  i don't think that was the new version .  you did you adjust the utterance times , for each channel ? i know there were some speaker labelling problems , after interruptions . is that what you 're referring to ? cuz there 's this one instance when , you 're running down the stairs . i remember this meeting really right . it 's a i 've i 'm very acquainted with this meeting .  i know it by heart . there 's one point when you 're running down the stairs . right ? and there 's an interruption . you interrupt somebody , but then there 's no line after that . there 's no speaker identification after that line . is that what you 're talking about ? or were there mislabellings as far as the a adam was ? cuz let about that .   but you 're actually saying that certain , speakers were mis identified .   that 's r right . burst "" also ? isn't "" burst "" is used also ? that 's  ","i know there were some speaker labelling problems , after interruptions . but you 're actually saying that certain , speakers were mis identified . ",Performance in both tasks was adversely affected by the manner of recording conditions implemented and difficulties attributing utterances to the appropriate speakers. 
Bmr019.H," sh   ju here @ @     is my last day . my last meeting about meetings .  because , i leave , the next sunday . i will come back to home to spain . and i would like to say very much , to all people in the group and at icsi , because i enjoyed @ @ very much ,  and i 'm by the result of overlapping , because , i haven't good results , yet but , i pretend to continuing out to spain , during the following months , because i have , another ideas but , i haven't enough time to with six months it 's not enough to research , and e if , the topic is , difficult , in my opinion , there isn't   but , i will try to recommend , at , the spanish government but , the following @ @ scholarship , will be here more time , because i in my opinion is better , for us to spend more time here and to work more time i in a topic . no ? but , it is .  it 's difficult . you e you have , you are lucky , and you find a solution in some few tim months ,  but , it 's not , common . but , anyway , very much . i bring the chocolate , to tear , with you ,  i hope if you need , something , from us in the future , i will be at spain , to you help ,  and , very much .  you ye you prefer , to eat , chocolate , at the coffee break , at the ? or you prefer now , before after ?  it 's enough , for more peopl for more people after . but , to andreas , the idea is good . s to eat here .  is , a another acoustic event . are you ? they 're clean . take several .    no .  the grouping .    ",,
Bmr019.I, ,,
Bro018.A,"r r zero . what are your f frame error rates for this ? o fif fifty six percent accurate for v voice unvoice   should be in nineties somewhere . right .     timit canonical ma mappings . noisy timit . right .  mc mcdonald 's constant .   some of the progress , i 've been getting a getting my committee members for the quals . and far i have morgan and hynek , mike jordan , and i asked john ohala and he  'm need to ask malek . one more . tsk . then talked a little bit about continuing with these dynamic ev acoustic events , and we 're we 're thinking about a way to test the completeness of a set of dynamic events . completeness in the sense that if we pick these x number of acoustic events , do they provide sufficient coverage for the phones that we 're trying to recognize or the f the words that we 're gonna try to recognize later on . and morgan and i were discussing a form of a cheating experiment where we get we have chosen set of features , or acoustic events , and we train up a hybrid system to do phone recognition on timit . the idea is if we get good phone recognition results , using these set of acoustic events , then that says that these acoustic events are g sufficient to cover a set of phones , at least found in timit . it would be a measure of "" are we on the right track with the choices of our acoustic events "" . that 's going on . and also , just working on my final project for jordan 's class , which is    th for my class project i 'm 'm tinkering with support vector machines ? something that we learned in class , and just another method for doing classification . and 'm gonna apply that to compare it with the results by king and taylor who did these  using recurrent neural nets , they recognized set of phonological features  and made a mapping from the mfcc 's to these phonological features , 'm gonna do a similar thing with support vector machines and see if support vector machines are good with dealing with a less amount of data and if you give it less data it still does a reasonable job in learning the patterns . and   right . the simple idea behind a support vector machine is you have this feature space , right ? and then it finds the optimal separating plane , between these two different classes , and and what it i at the end of the day , what it actually does is it picks those examples of the features that are closest to the separating boundary , and remembers those and uses them to recreate the boundary for the test set . ","then talked a little bit about continuing with these dynamic ev acoustic events , and we 're we 're thinking about a way to test the completeness of a set of dynamic events . completeness in the sense that if we pick these x number of acoustic events , do they provide sufficient coverage for the phones that we 're trying to recognize or the f the words that we 're gonna try to recognize later on . and morgan and i were discussing a form of a cheating experiment where we get we have chosen set of features , or acoustic events , and we train up a hybrid system to do phone recognition on timit . ",
Bro018.A,"given these these features , or these examples , critical examples , which they call support f support vectors , then given a new example , if the new example falls away from the boundary in one direction then it 's classified as being a part of this particular class and otherwise it 's the other class .   let 's see .  that 's a good question . i  right . i it can be a reduced parameterization of the model by just keeping certain selected examples .   i don't know either . actually you don't get a number between zero and one . you get either a zero or a one .  there are pap it 's you get a distance measure at the end of the day , and then that distance measure is is translated to a zero or one .  that 's for classification , right . right . you have the distances to work with ,   they had a way to translate the distances into probabilities with the simple sigmoidal function .  there 's some there 's like one over one plus the exponential like that .  right .  i 'm not do i 'm not planning on doing speech recognition with it . i 'm just doing detection of phonological features . this feature set called the sound patterns of english is just a bunch of binary valued features . let 's say , is this voicing , or is this not voicing , is this sonorants , not sonorants , and like that .   haven't gone through the entire table , yet .  yesterday i brought chuck the table and i was like , "" this is the mapping from n to this phonological feature called coronal "" , is should it be shouldn't it be a one ? or should it be coronal instead of not coronal as it was labelled in the paper ? "" ha haven't hunted down all the mistakes yet , but right ,    show you i  our  is this the class project , or ?   right , right f for every phone there is a vector of ones and zeros f corresponding to whether it exhibits a particular phonological feature or not .   right , to come up with a mapping from mfcc 's or s some feature set , to to whether there 's existence of a particular phonological feature . and  it 's to learn a mapping from the mfcc 's to phonological features . is it did that answer your question ?  c   no , no . i 'm not planning to do any phoneme mapping yet . just it 's it 's really simple , detection of phonological features .  and cuz the king and taylor did this with recurrent neural nets , and this i their idea was to first find a mapping from mfcc 's to phonological features and then later on , once you have these phonological features , then map that to phones . 'm reproducing phase one of their ",,
Bro018.A,right . right . right .      ,,
Bro018.B,"s do you get some number between zero and one at the output ? barry , if you just have zero and ones , how are you doing the speech recognition ?     and  that 's as far as my goes ,  tried this mean subtraction method .  due to avendano , i 'm taking s six seconds of speech , 'm using two second fft analysis frames , stepped by a half second it 's a quarter length step and i take that frame and four f the four i take  i take the current frame and the four past frames and the four future frames and that adds up to six seconds of speech . and i calculate the spectral mean , of the log magnitude spectrum over that n . i use that to normalize the s the current center frame by mean subtraction . and i then i move to the next frame and i do it again . actually i calculate all the means first and then i do the subtraction . and the i tried that with hdk , the aurora setup of hdk training on clean ti digits , and it helped in a phony reverberation case where used the simulated impulse response the error rate went from something like eighty it was from something like eighteen percent to four percent . and on meeting rec recorder far mike digits , mike on channel f , it went from forty one percent error to eight percent error . right . and that was trained on clean speech only , which i 'm guessing is the reason why the baseline was bad . and actually adam ran the sri recognizer . on the far field also . he did one pzm channel and one pda channel . i 'm not it was about five percent error for the pzm channel . f   i 'm g i 'm guessing it was the training data . clean ti digits is pretty pristine training data , and if they trained the sri system on this tv broadcast type it 's a much wider range of channels and it   b you me ta   r right , guess this sri system is trained on a lot of s broadcast news or switchboard data . is that right ? do which one it is ?   o one thing i 'm wondering about is what this mean subtraction method will do if it 's faced with additive noise . cuz i it 's cuz i don't log magnitude spectral subtraction is gonna do to additive noise . that 's the  that 's that 's true . that 's a good point . it 's then it 's it 's reasonable to expect it would be helpful if we used it with the sri system and       sounds good . ","that 's as far as my goes , tried this mean subtraction method . due to avendano , i 'm taking s six seconds of speech , 'm using two second fft analysis frames , stepped by a half second and i calculate the spectral mean , of the log magnitude spectrum over that n . i use that to normalize the s the current center frame by mean subtraction . and the i tried that with hdk , the aurora setup of hdk training on clean ti digits , and it helped in a phony reverberation case where used the simulated impulse response the error rate went from something like eighty it was from something like eighteen percent to four percent . and on meeting rec recorder far mike digits , mike on channel f , it went from forty one percent error to eight percent error . ","There has been further work on voiced/unvoiced detection, along with spectral subtraction. "
Bro018.C," he 's not here , you get to   i 'm slightly confused . what feeds the the three output net ? no , what feeds it ? what features does it see ?       right . you wouldn't do like r one over r zero like that ? usually for voiced unvoiced you 'd do you 'd do something you 'd do energy but then you have something like spectral slope , which is you get like r one ov over r zero like that . r correlations . ye that 's the variance , but if you just say "" what is "" to first order , one of the differences between voiced , unvoiced and silence is energy . another one is but the other one is the spectral shape .  and one over r zero is what you typically use for that . no , i 'm saying that 's what people us typically use . see , because it because this is just like a single number to tell you does the spectrum look like that or does it look like that "" . right ? if it 's if it 's low energy but the spectrum looks like that or like that , it 's probably silence . but if it 's low energy and the spectrum looks like that , it 's probably unvoiced . if you just had to pick two features to determine voiced unvoiced , you 'd pick something about the spectrum like one over r zero , and r zero or i you 'd have some other energy measure and like in the old days people did like zero crossing counts . right . s s    but right , but it seemed to me that what you were getting at before was that there is something about the difference between the original signal or the original fft and with the filter which is what and the variance was one take on it . right . but it could be something else . suppose you didn't have anything like that . then in that case , if you have two nets , alright , and this one has three outputs , and this one has f whatever , fifty six , if you were to sum up the probabilities for the voiced and for the unvoiced and for the silence here , we 've found in the past you 'll do better at voiced unvoiced silence than you do with this one . just having the three output thing doesn't really buy you anything . the issue is what you feed it .  w that 's another way . that wasn't what i was saying but that 's certainly another thing to do . no i was just trying to say if you b if you bring this into the picture over this , what more does it buy you ? ","he 's not here , ","The group discussed one members attendance at a conference, and another groups code, which is proving hard to follow. "
Bro018.C,"and what i was saying is that the only thing that it buys you is based on whether you feed it something different . and something different in some fundamental way . and the thing that she was talking about before , was looking at something ab something about the difference between the log fft log power and the log magnitude spectrum and the filter bank . and the filter bank is chosen to integrate out the effects of pitch and she 's saying trying the particular measure that she chose was the variance of this m of this difference , but that might not be the right number . right ? there 's something about the variance that 's not enough or there 's something else that one could use , but that , for me , the thing that struck me was that you wanna get something back here , here 's an idea . what about it you skip all the really clever things , and just fed the log magnitude spectrum into this ? this is f you have the log magnitude spectrum , and you were looking at that and the difference between the filter bank and c computing the variance . that 's a clever thing to do . what if you stopped being clever ? and you just took this thing in here because it 's a neural net and neural nets are wonderful and figure out what they can what they most need from things , and that 's what they 're good at . mean you 're you 're trying to be clever and say what 's the statistic that should we should get about this difference but just feeding this in or feeding both of them in another way , saying let it figure out what 's the what is the interaction , especially if you do this over multiple frames ? then you have this over time , and both kinds of measures and you might get something better .  that 's another thing you could do    it seems to me , if you have exactly the right thing then it 's better to do it without the net because otherwise you 're asking the net to learn this say if you wanted to learn how to do multiplication . you could feed it a bunch of s you could feed two numbers that you wanted to multiply into a net and have a bunch of nonlinearities in the middle and train it to get the product of the output and it would work . but , it 's crazy , cuz we know how to multiply and you 'd be much lower error usually if you just multiplied it out . but suppose you don't really the right thing is . and that 's what these dumb machine learning methods are good at .   anyway . it 's just a thought .  it 's probably worth it . is that that 's accuracy ? ",,
Bro018.C,"voiced unvoiced hopefully would be a lot better . at the frame level for fifty six that was the number we were getting for reduced band width that 's all ? that 's pretty bad . aha ! aha !    but even i in in training . still ,  actually , this is a test that you should do then . if you 're getting fifty six percent over here , that 's in noise also , right ?  if you 're getting fifty six here , try adding together the probabilities of all of the voiced phones here and all of the unvoiced phones and see what you get then . i bet you get better than sixty three . but that 's a that is a good check point , you should do that anyway ,  given this regular old net that 's just for choosing for other purposes , add up the probabilities of the different subclasses and see how you do . and that anything that you do over here should be at least as good as that .  this is trained on timit .  but noisy timit ? i see .  there 's gonna be it looks like there 's gonna be a noisy some large vocabulary noisy too . somebody 's preparing .  i forget what it 'll be , resource management , wall street journal , something . some read task actually , that they 're preparing .  the the issue is whether people make a decision now based on what they 've already seen , or they make it later . and one of the arguments for making it later is let 's make that whatever techniques that we 're using work for something more than connected digits .  late think in the summer sometime .      at the front it says log energy is equal to the rounded version of sixteen over the log of two ""  times the this is natural log , and it has something to do with the fact that this is i have no idea . that 's what i was thinking , but then there 's the sixty four , i don't know . it 's pretty funny looking . i don't know . i right . sixteen over two .  if we ignore the sixteen , the natural log of t one over the natural log of two times the natu i don't know . somebody 'll think of something , but this is it may just be that they want to have for very small energies , they want to have some it says , since you 're taking a natural log , it says that when you get down to essentially zero energy , this is gonna be the natural log of one , which is zero . it 'll go down to to the natural log being the lowest value for this would be zero . you 're restricted to being positive . and this smooths it for very small energies . ",,
Bro018.C,"why they chose sixty four and something else , that was probably just experimental . and the constant in front of it , i have no idea .  mean it they probably have some fi particular s fixed point arithmetic that they 're using , and then it just   that they 're s probably working with fixed point or integer you 're supposed to on this anyway , and that puts it in the right realm somewhere .  given at the level you 're doing things in floating point on the computer , i don't think it matters , would be my guess , but .  and wh when did stephane take off ? he took off he was gone these first few days , and then he 's here for a couple days before he goes to salt lake city .    he 's going to icassp which is good . i don't know if there are many people who are going to icassp thought , make somebody go . people are less consistent about going to icassp and it 's still a reasonable forum for students to present things . it 's for engineering students of any kind , it 's if you haven't been there much , it 's good to go to , to get a feel for things , a range of things , not just speech .  but for dyed in the wool speech people , think that icslp and eurospeech are much more targeted .  and then there 's these other meetings , like hlt and asru there 's actually plenty of meetings that are really relevant to computational speech processing of one sort or another .  i mostly just ignored it because i was too busy and didn't get to it .  wanna talk a little bit about what we were talking about this morning ? just briefly , or anything else ? actually , let me hold that thought . let me back up while we 're still on it . the other thing i was suggesting , though , is that given that you 're talking about binary features , the first thing to do is just to count and count co occurrences and get probabilities for a discrete cuz that 'd be pretty simple because it 's just say , if you had ten events , that you were counting , each frame would only have a thousand possible values for these ten bits , and you could make a table that would say , if you had thirty nine phone categories , that would be a thousand by thirty nine , and just count the co occurrences and divide them by the occ count the co occurrences between the event and the phone and divide them by the number of occurrences of the phone , and that would give you the likelihood of the event given the phone . and then just use that in a very simple ",and wh when did stephane take off ? he 's going to icassp which is good . wanna talk a little bit about what we were talking about this morning ? ,"The group discussed one members attendance at a conference, and another groups code, which is proving hard to follow. "
Bro018.C,"and you could do phone recognition then and wouldn't have any of the issues of the training of the net or it 'd be on the simple side , but  if the example i was giving was that if you had onset of voicing and end of voicing as being two kinds of events , then if you had those a all marked correctly , and you counted co occurrences , you should get it completely right .  but you 'd get all the other distinctions , randomly wrong . there 'd be nothing to tell you that .  if you just do this by counting , then you should be able to find out in a pretty straightforward way whether you have a sufficient set of events to do the level of classification of phones that you 'd like . that was the idea . and then the other thing that we were discussing was how do you get the your training data . cuz the switchboard transcription project was half a dozen people , or working off and on over a couple years , and similar amount of data to what you 're talking about with timit training . it seems to me that the only reasonable starting point is to automatically translate the current timit markings into the markings you want . and it won't have the characteristic that you 'd like , of catching funny things that aren't there from these automatic markings , but it 's  and a short amount of time , just to again , just to see if that information is sufficient to determine the phones .  right . you can get a little feeling for it that way , that is probably right . my guess would be that this is since timit 's read speech that this would be less of a big deal , if you went and looked at spontaneous speech it 'd be more of one . and the other thing would be , say , if you had these ten events , you 'd wanna see , what if you took two events or four events or ten events or t and and and hopefully there should be some point at which having more information doesn't tell you really all that much more about what the phones are . you could , but what he 's talking about here is a translation to a per frame feature vector , there 's no sequence in that ,  it 's just a but we 're just talking about something simple here , to see if  just the idea is with a very simple statistical structure , could you at least verify that you 've chosen features that are sufficient . and you were saying something starting to say something else about your class project , or ?  it  they 're succinct , and they that 's another way of doing it . right ? it guess it 's it goes back to nearest neighbor thing , right ? ",,
Bro018.C,"i if is it when is nearest neighbor good ? nearest neighbor good is good if you have lots and lots of examples . but if you have lots and lots of examples , then it can take a while to use nearest neighbor . there 's lots of look ups . long time ago people talked about things where you would have condensed nearest neighbor , where you would you would pick out some representative examples which would be sufficient to represent to correctly classify everything that came in . support vector goes back to that thing .   and th the neural net approach or gaussian mixtures for that matter are fairly brute force kinds of things , where you you predefine that there is this big bunch of parameters and then you place them as you best can to define the boundaries , and as these things do take a lot of parameters and if you have only a modest amount of data , you have trouble learning them . guess the idea to this is that it is reputed to be somewhat better in that regard . but i don't know if people have done careful comparisons of this on large tasks or anything . they have . i don't know .  but that 's looking at it for classification for binary classification , right ? but you have the distances to work with . cuz actually mississippi state people did use support vector machines for speech recognition and they were using it to estimate probabilities .  and d did they use sigmoid or a softmax type thing ? and didn't they like exponentiate and then divide by the sum of them , or ? it i it is a sigmoidal .  alright . they 're i don't think they were earth shattering , but that this was a couple years ago , i remember them doing it at some meeting , and don't think people were very critical because it was interesting just to try this and it was the first time they tried it , the the numbers were not incredibly good but there 's it was th reasonable . i don't remember anymore . i don't even remember what the task was , it was broadcast news , i don't know .  but a as i was saying , people do get probabilities from these things , and we were just trying to remember how they do , but people have used it for speech recognition , and they have gotten probabilities . they have some conversion from these distances to probabilities . there 's you have the paper , right ? the mississippi state paper ? if you 're interested y you could look ,  i expect you could do that . that 's probably not what he 's going to do on his class project .  have you had a chance to do this thing we talked about yet with the  no actually i was going a different ",have you had a chance to do this thing we talked about yet with the ,
Bro018.C,"that 's a good question , too , but i was gonna ask about the changes to the data in comparing plp and mel cepstrum for the sri system . right . we talked on the phone about this , that there was still a difference of a few percent and you told me that there was a difference in how the normalization was done . and i was asking if you were going to do redo it for plp with the normalization done as it had been done for the mel cepstrum .   i agree , but that the normalization difference was one of the possibilities , right ?    i see .   that makes sense , to check all that . although really , a couple three percent difference in word error rate could easily come from some difference in normalization , i would think . but he 's probably off at his meeting now ,   but  the i sh think they should be roughly equivalent ,  again the cambridge folk found the plp actually to be a little better . it 's the other thing i wonder about was whether there was something just in the bootstrapping of their system which was based on but not , since they right . right . right .   anyway , there 's there to sort out .   let 's go back to what you thought i was asking you . ha !  you had the sa same answer anyway .    i don't think it 's in there , it 's in the the filters . the f t is on everything , but the filters  ignore the lowest bins and the highest bins . and what it does is it copies  the filter bank which is created by integrating over f t bins .  right .  it 's bark scale , and it 's it it actually copies the the second filters over to the first . the first filters are always and you can s you can specify a different number of features different number of filters ,  as i recall . you can specify a different number of filters , and whatever you specify , the last ones are gonna be ignored . that 's a way that you change what the bandwidth is . y you can't do it without changing the number of filters , but the idea is that the very lowest frequencies and typically the veriest highest frequencies are junk . and you just for continuity you just approximate them by the second to highest and second to lowest . it 's just a simple thing we put in . and if you h that 's a fixed thing . but see my point ? if you had ten filters , then you would be throwing away a lot at the two ends . and if you had fifty filters , you 'd be throwing away hardly anything . ","but i was gonna ask about the changes to the data in comparing plp and mel cepstrum for the sri system . we talked on the phone about this , that there was still a difference of a few percent and you told me that there was a difference in how the normalization was done . and i was asking if you were going to do redo it for plp with the normalization done as it had been done for the mel cepstrum . but that the normalization difference was one of the possibilities , ",
Bro018.C,"i don't remember there being an independent way of saying "" we 're just gonna make them from here to here "" . but i don't know , it 's actually been awhile since i 've looked at it . see i don't know feacalc but it calls rasta with some options , and but in i don't know . for some particular database you might find that you could tune that and tweak that to get that a little better , but that in general it 's not that critical . there 's you can throw away below a hundred hertz or and it 's just not going to affect phonetic classification it 's not precisely .    what you can do is you can definitely change the filter bank from being trapezoidal integration to a triangular one , which is what the typical mel cepstral filter bank does . and some people have claimed that they got some better performance doing that , you certainly could do that easily . but the fundamental difference , there 's other small differences  but , as opposed to the log in the other case . the fundamental d difference that we 've seen any difference from before , which is actually an advantage for the p l p i is that the smoothing at the end is auto regressive instead of being cepstral from cepstral truncation . it 's a little more noise robust . and that 's why when people started getting databases that had a little more noise in it , like broadcast news and on , that 's why c cambridge switched to plp  that 's a difference that i don't think we put any way to get around , since it was an advantage .  but we did we did hear this comment from people at some point , that it they got some better results with the triangular filters rather than the trapezoidal . that is an option in rasta . and you can certainly play with that . but you 're probably doing the right thing to look for bugs first . i don't know . could be .   he used the identical pruning thresholds even though the s the range of p of the likeli that 's a pretty good point right there .  i would think that you might wanna do something like look at a few points to see where you are starting to get significant search errors .   but you could if that looks promising you could , r run the overall test set with a few different pruning thresholds for both , and presumably he 's running at some pruning threshold that 's gets very few search errors but is relatively fast and but you may be in the wrong range for the p l p features for some reason .  just be different distributions and  that 's another possible thing . they should really shouldn't there 's no particular reason why they would be exactly behave exactly the same .     ",,
Bro018.C,"this was a little bit off topic , because i was thinking in terms of th this as being a core item that once we had it going we would use for a number of the front end things also .   wanna what 's on  that 's ac actually a little side point is that 's the first results that we have of any sort on the far field on the far field data for recorded in meetings . did he ? on the near field , on the ne did he ?  i didn't recall that . what numbers was he getting with that ? five . why were you getting forty one here ? is this no , but minute . i th he what am i saying here ?  that was the sri system . you 're right .  cuz it was getting like one percent it 's still this ratio . it was getting one percent on the near field . wasn't it ?  it was getting around one percent for the near for the n for the close mike . it was like one to five it 's still this ratio . it 's just  it 's a lot more training data .  probably it should be something we should try then is to see if is at some point just to take i to transform the data and then use th use it for the sri system . you 're you have a system which for one reason or another is relatively poor , and you have something like forty one percent error and then you transform it to eight by doing this work .  here 's this other system , which is a lot better , but there 's still this ratio . it 's something like five percent error with the distant mike , and one percent with the close mike . the question is how close to that one can you get if you transform the data using that system .   it 's not exactly the right thing but but you 've already seen that cuz there is added noise here .    as helpful  that 's the question . w we 're often asked this when we work with a system that isn't industry standard great , and we see some reduction in error using some clever method , then , will it work on a on a good system .  this other one 's it was a pretty good system . one percent word error rate on digits is digit strings is not stellar , but given that this is real digits , as opposed to laboratory  and it wasn't trained on this task . actually one percent is in a reasonable range . people would say "" i could imagine getting that "" . and the four or five percent is quite poor . if you 're doing a sixteen digit credit card number you 'll get it wrong almost all the time .  ",,
Bro018.C,"a significant reduction in the error for that would be great . and then ,      alright , i actually have to run . don't think do the digits , but 'll leave my microphone on ?   be out of here quickly . that 's have to run for another appointment . i t i left it on .  ",,
Bro018.D," i will try to explain the thing that i did this week during this week . that i work i begin to work with a new feature to detect voice unvoice . what i trying two mlp to the with this new feature and the fifteen feature from the bus base system no , satly the mes the mel cepstrum , the new base system the new base system . we the aurora system with the new filter , vad like that . and i 'm trying two mlp , one that only have t three output , voice , unvoice , and silence , and other one that have fifty six output . the probabilities of the allophone . and i tried to do some experiment of recognition with that and only have result with the mlp with the three output . and i put together the fifteen features and the three mlp output . and , the result are li a little bit better , but more or less similar . voice , unvoice , and si the feature the input ? the inputs are the fifteen bases feature . the with the new code . and the other three features are r , the variance of the difference between the two spectrum , the variance of the auto correlation function , except the first point , because half the height value is r zero and also r zero , the first coefficient of the auto correlation function . that is like the energy with these three feature , also these three feature .   no , r c no . auto correlation ? yes , the variance of the auto correlation function that uses that  i 'll the spectral shape ,  no , i don't use that i can't use         also th use this . bec because the result are a little bit better but we have in a point that everything is more or less the similar more or less similar . it 's not quite better .  i used this too .     i have  no     'm         not too much . one day or less . fifty f six no , the frame error rate ? fifty six percent . the accuracy .  no for , yes f i don't remember for voice unvoice , for the other one . for voiced . i don't reme better . for voice unvoice . this is for the other one . i should i can't show that . but that fifty five was for the when the output are the fifty six phone . that i look in the with the other nnn the other mlp that we have are more or less the same number . silence will be better but more or less the same . that that for the other one , for the three output , is sixty two , sixty three more or less . it 's  because it 's noise also . and we have i know .  will be  don't know , ","i will try to explain the thing that i did this week during this week . that i work i begin to work with a new feature to detect voice unvoice . what i trying two mlp to the with this new feature and the fifteen feature from the bus base system and i 'm trying two mlp , one that only have t three output , voice , unvoice , and silence , and other one that have fifty six output . the probabilities of the allophone . and i tried to do some experiment of recognition with that and only have result with the mlp with the three output . and , the result are li a little bit better , but more or less similar . ",
Bro018.D,"but i th that we i have the result more or less . i don't know . i don't i 'm not but i remember @ @ that i can't show that .   i will do that . but no . timit .  this for timit . noisy timit . we have noisy timit with the noise of the ti digits . and now we have another noisy timit also with the noise of italian database . this is the work that i did during this date and also h hynek last week say that if i have time to begin to study the france telecom proposal to look at the code and something like that to know exactly what they are doing because that we can have some ideas but not only to read the proposal . look insi look i carefully what they are doing with the program @ @ and i begin to work also in that . but the first thing that i don't understand is that they are using r the log energy that this quite i don't know why they have some constant in the expression of the lower energy . i don't that means .  this  then understand . because they 're the threshold that they are using on the basis of this value i don't know exactly , because th they have a meaning . but i don't is the meaning of take exactly this value . the e the effect i don't @ @ understand the effect of this , no ? because it 's to do something like that . no ?   i will look to try if i move this parameter in their code what happens , everything is they tres hole are on basis of this . i don't know .  i this more or less anything that stephane will arrive today or tomorrow .  he 's that he is in las vegas like that .   ",and also h hynek last week say that if i have time to begin to study the france telecom proposal to look at the code i begin to work also in that . but the first thing that i don't understand is that they are using r the log energy that this quite i don't know why they have some constant in the expression of the lower energy . that stephane will arrive today or tomorrow . ,"The group discussed one members attendance at a conference, and another groups code, which is proving hard to follow. "
Bro018.E," the mel cepstrum ? the  the aurora system .   what are the r 's ? i 'm missed it .  you 're saying take the features that go into the voiced unvoiced silence net and feed those into the other one , as additional inputs , rather than having a separate   don't don't do the division , but let the net have everything .  how long does it take , carmen , to train up one of these nets ?   the targets for the neural net , they come from forced alignments ?   really ? for what for aurora ?   when are they planning when would they do that ?  they have a constant in there , you said ? is that some base conversion , or ? experimental results . they 're taking the number inside the log and raising it to sixteen over log base two . does it have to do with those sixty fours , or ? i was just gonna say it has something to do with hardware , something they were doing . it just , puts it in the right range , or do have people stopped going to icassp in recent years ?        it 's probably a good place to start .    you could even then to get an idea about how different it is , you could take some subset and go through a few sentences , mark them by hand and then see how different it is from the canonical ones , just to get an idea a rough idea of h if it really even makes a difference .   right . right .  you could define other events as being sequences of these events too . unless you did like a second pass over it after you 've got your    i 'm adding complexity .  what 's the advantage of support vector machines ? what   does there some distance metric that they use or how do they for cla what do they do for classification ?      why save the examples ? why not just save what the boundary itself is ?  an equivalent .    i see . rather than doing nearest neighbor where you compare to every single one , you just pick a few critical ones , and    and you get that for each class , you get a zero or a one . did the did they get good results with that ?     did you find any more mistakes in their tables ? in your in the thing that you 're doing , you have a vector of ones and zeros for each phone ?  is that what you 're   and when you do your wh i 'm what is the task for the class project ? to come up with the phones ? or to come up with these vectors to see how closely they match the phones , or ?   'm not what you 're what you get out of your system . ",,
Bro018.E,"do you get out a vector of these ones and zeros and then try to find the closest matching phoneme to that vector , or ?  i see .     they had one recurrent net for each particular feature ? i see . i wo did they compare that what if you just did phone recognition and did the reverse lookup . you recognize a phone and which ever phone was recognized , you spit out it 's vector of ones and zeros .   no . insertion penalty ?  what i 've been "" changes to the data "" , i 'm not  right .  right , no i haven't had a chance to do that . what i 've been doing is trying to figure out it just seems to me like there 's a it seems like there 's a bug , because the difference in performance is it 's not gigantic but it 's big enough that it seems wrong . and but i don't i 'm not  don't think that the normalization difference is gonna account for everything . what i was working on is just going through and checking the headers of the wavefiles , to see if there was a certain type of compression that was done that my script wasn't catching . that for some subset of the training data , the features i was computing were junk . which would it to perform but the models would be all messed up . was going through and just double checking that think first , to see if there was just some obvious bug in the way that i was computing the features . looking the sampling rates to make all the sampling rates were what eight k , what i was assuming they were ,   was doing that first , before i did these other things , just to make there wasn't something  and hhh i 'm trying to remember but recall that andreas was saying that he was gonna run the reverse experiment . which is to try to emulate the normalization that we did but with the mel cepstral features . back up from the system that he had . he said he was gonna i have to look back through my email from him .  he 's gone now .  but right . see one thing that 's a little bit i was looking i 've been studying and going through the logs for the system that andreas created . and his the way that the s r i system looks like it works is that it reads the wavefiles directly , and does all of the cepstral computation on the fly . and , there 's no place where these where the cepstral files are stored , anywhere that go look at and compare to the plp ones , whereas with our features , he 's actually storing the cepstrum on disk , and he reads those in . but it looked like he had to give it ","no i haven't had a chance to do that . what i 've been doing is trying to figure out it just seems to me like there 's a it seems like there 's a bug , because the difference in performance is it 's not gigantic but it 's big enough that it seems wrong . don't think that the normalization difference is gonna account for everything . what i was working on is just going through and checking the headers of the wavefiles , ",
Bro018.E,"even though the cepstrum is already computed , he has to give it front end parameter file . which talks about the com computation that his mel cepstrum thing does , don't know if that it probably doesn't mess it up , it probably just ignores it if it determines that it 's already in the right format but the two processes that happen are a little different .     no and i didn't have a chance to do that .  i 've been i 've been working with jeremy on his project and then i 've been trying to track down this bug in the icsi front end features . one thing that i did notice , yesterday i was studying the the rasta code and it looks like we don't have any way to control the frequency range that we use in our analysis . we it looks to me like we do the fft , and then we just take all the bins and we use everything . we don't have any set of parameters where we can say "" only process from hundred and ten hertz to thirty seven fifty "" . at least i couldn't see any control for that . the filters ? which filters ?  when you get the mel when you go to the mel scale . i saw something about that looked like it was doing something like that , but i didn't quite understand it .    but the but that 's a fixed thing ? there 's nothing that lets you   use this analysis bandwidth i went through the feacalc code and then looked at just calling the rasta libs and thing like that . and i didn't i couldn't see any wh place where that thing was done . but didn't quite understand everything that i saw ,   right .  another thing i was thinking about was is there a i was wondering if there 's certain settings of the parameters when you compute plp which would it to output mel cepstrum . that , in effect , what i could do is use our code but produce mel cepstrum and compare that directly to    there 's a cubic root that happens , right ?     just it just seems like this behavior could be caused by some of the training data being messed up . you 're getting most of the way there , but there 's a started going through and looking one of the things that i did notice was that the log likelihoods coming out of the log recognizer from the plp data were much lower , much smaller , than for the mel cepstral and that the average amount of pruning that was happening was therefore a little bit higher for the plp features . since he used the same exact pruning thresholds for both , i was wondering if it could be that we 're getting more pruning .  right . right .   that 's right . ",,
Bro018.E,"what i was gonna do is i was gonna take couple of the utterances that he had run through , then run them through again but modify the pruning threshold and see if it affects the score .   right .  right . generally in these things you turn back pruning really far , didn't think it would be that big a deal because i was figuring you have it turned back far that it    and the the run time of the recognizer on the plp features is longer which implies that the networks are bushier , there 's more things it 's considering which goes along with the fact that the matches aren't as good . it could be that we 're just pruning too much .    right . right .  there 's lots of little differences .   trying to track it down .   on the real data , not with artificial reverb ?   or it wa a it was around one .  it 's trained on a lot of different things .  it 's trained on lot of switchboard , call home , bunch of different sources , some digits , there 's some digits training in there . and it wasn't trained on this task either .    that 'll work . ",,
