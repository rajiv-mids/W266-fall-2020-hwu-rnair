meeting,original,extractive,abstractive
Bdb001.A,"i remember seeing an example of this .   you 're essentially defining a lattice .  how that 's that 's actually very nicely handled here because you could all you 'd have to change is the , time stamps in the time line without , changing the i ds . except the time line is gonna be huge . if you say suppose you have a phone level alignment . you 'd have you 'd have why  but why not use it for phone level ? it 's just a matter of it being bigger . but if you have barring memory limitations , or w this is still the m no . you would use it only for purposes where you actually want the phone level information , i 'd imagine . you  or you just compre i like text formats .  b you can always , g zip them , and , c decompress them on the fly if y if space is really a concern . right ,  i would say frame level is probably not a good idea . but for phone level it 's perfectly like phones , or syllables , or anything like that . but most of the frames are actually not speech .  people don't v look at it , words times the average number of phones in an english word is , i don't know , five look at it , t number of words times five . that 's not that not exactly .  i 've used them . i don't their structure is . i 've forgot what the str   th we have actually , we use a generalization of the sphere format .  but there is something like that but it 's , probably not as sophist they ha it has its own entropic has their own feature format that 's called sd or some sf like that .  right .  do they already have tools ? as long as each tag is on one line .  if we want to do they already have something that 's that would be useful for us in place ? we should find out . it 's a hassle if if it 's conceptually close , and they already have or will have tools that everybody else will be using , it would be crazy to do something s separate that it seems to me you want to keep the frame level separate . and then now how would you represent , multiple speakers in this framework ? were you would just represent them as you would have like a speaker tag    is i ? channel or speaker or whatever . it doesn't right . but how in the nist format do we express a hierarchical relationship between , say , an utterance and the words within it ? how do you tell that these are the words that belong to that utterance ?    here 's the thing .  hhh . the thing ","you 're essentially defining a lattice . that 's actually very nicely handled here because you could all you 'd have to change is the , time stamps in the time line without , changing the i ds . except the time line is gonna be huge . suppose you have a phone level alignment . do they already have something that 's that would be useful for us in place ? if it 's conceptually close , and they already have or will have tools that everybody else will be using , it would be crazy to do something s separate that it seems to me you want to keep the frame level separate . now how would you represent , multiple speakers in this framework ? but how in the nist format do we express a hierarchical relationship between , say , an utterance and the words within it ? ",
Bdb001.A,"that some something may be a part of one thing for one purpose and another thing of another purpose .  s   s let 's ta let 's  y @ sup suppose you have a word sequence and you have two different segmentations of that same word sequence . f say , one segmentation is in terms of , sentences . and another segmentation is in terms of , i don't know , prosodic phrases . and let 's say that they don't nest . a prosodic phrase may cross two sentences i don't know if that 's true or not but let 's as right .  you want to be s you want to say this word is part of that sentence and this prosodic phrase . but the phrase is not part of the sentence and neither is the sentence part of the phrase . you would have to have two different pointers from the word up one level up , one to the sent right . right .  the o the other issue that you had was , how do you actually efficiently extract , find and extract information in a structure of this type ? you gave some examples like no , that 's not clear . you c you can do it , but can you do it it y you gotta do this you 're gonna want to do this very quickly or else you 'll spend all your time searching through very complex data structures  you want grep that 's that works at the structural on the structural representation . but it 's not clear that 's that 's relative to the structure of the xml document , not to the structure of what you 're representing in the document . right . right . be because here you 're specifying a lattice . the underlying that 's the underlying data structure . and you want to be able to search in that lattice . that 's different from searching through the text .  hhh .  but  but this is i 'm still , not convinced that you can do much on the text on the flat file that the text representation . e because the text representation is gonna be , not reflecting the structure of your words and annotations . it 's just it 's no . you have to what you have to do is you have to y you can use perl to read it in and construct a internal representation that is essentially a lattice . but , the and then right . but that 's what you 'll have to do . bec be    ma you should actually look at it yourself too to get a sense of what it is you 'll be dealing with , because , adam might have one opinion but you might have another ,  the more eyes look at this the better .  is there an ip api ?  there used to be a problem that they get too large , ","f say , one segmentation is in terms of , sentences . and another segmentation is in terms of , i don't know , prosodic phrases . and let 's say that they don't nest . ",
Bdb001.A,"and the the filesystem wouldn't you could extend the api to , support , like splitting up , conceptually one file into smaller files on disk that you can essentially , have arbitrarily long f   what does the p stand for anyway ? no , p files were around way before quicknet . p files were around when w with , rap . right ? you worked with p files . i worked with p files . no .  j there 's    it would be  gr this is regarding it 's related but not directly germane to the topic of discussion , but , when it comes to annotations , you often find yourself in the situation where you have different annotations of the same , say , word sequence .  and sometimes the word sequences even differ slightly because they were edited s at one place but not the other . once this data gets out there , some people might start annotating this for , i don't know , dialogue acts or , topics or what the heck .  there 's a zillion things that people might annotate this for . and the only thing that is really common among all the versi the various versions of this data is the word sequence , or approximately . or the times . but , see , if you 'd annotate dialogue acts , you don't necessarily want to or topics you don't really want to be dealing with time marks . you 'd it 's much more efficient for them to just see the word sequence , right ? most people aren't as sophisticated as we are here with , time alignments and   right .   the p my point is that you 're gonna end up with , word sequences that are differently annotated . and you want some tool , that is able to merge these different annotations back into a single , version .  and we had this problem very massively , at sri when we worked , a while back on , on dialogue acts as as , what was it ?  utterance types . there 's , automatic , punctuation and like that . because we had one set of annotations that were based on , one version of the transcripts with a particular segmentation , and then we had another version that was based on , a different s slightly edited version of the transcripts with a different segmentation . we had these two different versions which were you could tell they were from the same source but they weren't identical . it was extremely hard to reliably merge these two back together to correlate the information from the different annotations . no . no . but once you have a file format , imagine writing not personally , but someone writing a tool that is essentially an alignment tool , that mediates between various versions , and like th you have this thing in unix where you have , diff . ","but , when it comes to annotations , you often find yourself in the situation where you have different annotations of the same , say , word sequence . and sometimes the word sequences even differ slightly because they were edited s at one place but not the other . but , see , if you 'd annotate dialogue acts , you don't necessarily want to or topics you don't really want to be dealing with time marks . and you want some tool , that is able to merge these different annotations back into a single , version . but once you have a file format , imagine writing not personally , but someone writing a tool that is essentially an alignment tool , that mediates between various versions , ",
Bdb001.A,"there 's the , diff that actually tries to reconcile different two diffs f based on the same original . something like that , but operating on these lattices that are really what 's behind this this annotation format .  somewhere in the api you would like to have like a merge or some function that merges two versions . right . is exactly . right . just to let what we where we kluged it by , doing by doing hhh . both were based on words , bo we have two versions of the same words intersp sprinkled with different tags for annotations . and we did diff . exactly ! and that 's how  but , it had lots of errors and things would end up in the wrong order , and forth .   if you had a more  it was a kluge because it was reducing everything to to textual alignment .   and you 're gonna get that because if the data gets out , people will do all kinds of things to it . and , s several years from now you might want to look into , the prosody of referring expressions . and someone at the university of who knows where has annotated the referring expressions . you want to get that annotation and bring it back in line with your data .   right . time times are ephemeral .     or she .     for th for the benefit of science we 'll read the digits . ",,
Bdb001.B,"channel two .    true . i 've used the p file , i 've looked at it at least , briefly , when we were doing s something . in there . where are those annotations coming from ? ",,
Bdb001.C,"we had a long discussion about how much w how easy we want to make it for people to bleep things out .  morgan wants to make it hard . did it ? i didn't even check yesterday whether it was moving .  channel three ? channel three ?   it has a little indicator on it on the af .  test . what ? did you see hannibal recently  i 'm familiar with that . we i already have developed an xml format for this and the only question is it the thing that you want to use or not ? have you looked at that ? i had a web page up .  this am gonna be standing up and drawing on the board . it definitely had that as a concept . tha it has a single time line , and then you can have lots of different sections , each of which have i ds attached to it , and then you can refer from other sections to those i ds , if you want to . that ,  that you start with a time line tag . "" time line "" . and then you have a bunch of times . i don't e i don't remember exactly what my notation was , but it  "" t equals one point three two "" ,  and then i also had optional things like accuracy , and then "" id equals t one , one seven "" . and then , i also wanted to be i to be able to not specify specifically what the time was and just have a stamp . these are arbitrary , assigned by a program , not by a user . you have a whole bunch of those . and then somewhere la further down you might have something like an utterance tag which has "" start equals t seventeen , end equals t eighteen "" . what that 's saying is , we know it starts at this particular time . we don't know when it ends . right ? but it ends at this t eighteen , which may be somewhere else . we say there 's another utterance . we don't the t time actually is but we know that it 's the same time as this end time . thirty eight , whatever you want .  yes , exactly . and then , and then these also have i ds . right ? you could have some other tag later in the file that would be something like , i don't know , "" noise type equals door slam "" .  and then , you could either say "" time equals a particular time mark "" or you could do other sorts of references . or you might have a prosody "" prosody "" right ? d ? t ? d ? t ? t ? you like the d ? that 's a good d .  you could have some type here , ","we i already have developed an xml format for this tha it has a single time line , and then you have a bunch of times . and then , i also wanted to be i to be able to not specify specifically what the time was and just have a stamp . and then somewhere la further down you might have something like an utterance tag which has "" start equals t seventeen , what that 's saying is , we know it starts at this particular time . you could have some other tag later in the file that would be something like , i don't know , "" noise type equals door slam "" . and then , you could either say "" time equals a particular time mark "" or you could do other sorts of references . ","On the one hand, a bespoke XML structure that connects transcriptions and annotations (down to the word-level) to a common timeline. "
Bdb001.C,"and then you could have ,  the utterance that it 's referring to could be u seventeen like that .  right . that 's , the who that 's why you do that extra level of indirection . that you can just change the time line . yes . this i don't would do this for phone level . for phone level you want to use some binary representation because it 'll be too dense otherwise . i would use just an existing way of doing it . it 's parsing limitations . i don't want to have this text file that you have to read in the whole thing to do something very simple for . right . you 'd y i am imagining you 'd have multiple versions of this depending on the information that you want .  i 'm just what i 'm wondering is whether for word level , this would be for word level , it 's alright . for lower than word level , you 're talking about much data that don't know . i don't know if that for something like that i would use p file or any frame level would use p file . that 's a like it . it 's ics icsi has a format for frame level representation of features .  right . right . or there 's a particular way in xml to refer to external resources . you would say "" refer to this external file "" .  that external file wouldn't be in more compact , which is better . if you did it at this you don't want to do it with that anything at frame level you had better encode binary or it 's gonna be really painful . but if you 're talking about one per frame , you 're talking about gigabyte size files . you 're gonna actually run out of space in your filesystem for one file . right ? because you have a two gigabyte limit on most o ss .  think it 's debatable whether you want to do phone level in the same thing . but a anything at frame level , even p file , is too verbose . i would use something tighter than p files .  it 's whatever you want , actually . that what 's about the p file it i built into it is the concept of frames , utterances , sentences , that thing , that structure . and then also attached to it is an arbitrary vector of values . and it can take different types . it th they don't all have to be floats . you can have integers and you can have doubles , and all that  right ? and it has a header format that describes it to some extent .  the only problem with it is it 's actually storing the utterance numbers and the frame numbers in the file , even though they 're always sequential . ","it 's parsing limitations . i don't want to have this text file that you have to read in the whole thing to do something very simple for . for word level , this would be for lower than word level , you 're talking about much data that don't know . or any frame level would use p file . it 's ics icsi has a format for frame level representation of features . or there 's a particular way in xml to refer to external resources . more compact , because you have a two gigabyte limit on most o ss . think it 's debatable whether you want to do phone level in the same thing . but a anything at frame level , even p file , is too verbose . it 's whatever you want , actually . built into it is the concept of frames , utterances , sentences , that thing , that structure . and then also attached to it is an arbitrary vector of values . ","On the one hand, a bespoke XML structure that connects transcriptions and annotations (down to the word-level) to a common timeline. The respective frame-level representation can be handled by P-files, a technology developed at ICSI, which also comes with a library of tools. Separation of levels of analysis makes files more compact and manageable. Phone-level analysis can be included in the same structure, or in a separate, linked file. "
Bdb001.C,"and it does waste a lot of space . but it 's still a lot tighter than ascii . and we have a lot of tools already to deal with it .  there 's a ton of it . man pages and , source code , and me . it 's not standard . it 's something that we developed at icsi . but , but it 's been used here and , we have a configured system that you can distribute for free , and what does h t k do for features ? or does it even have a concept of features ? i 'm just wondering , would it be worth while to use that instead ? they generate their own . right . right . and a if you have a if you have a two hour long meeting , that 's gonna they 'd be emo enormous . right .  right . the other thing we should look at atlas , the nist thing , and see if they have anything at that level . i 'm not what to do about this with atlas , because they chose a different route . i chose something that th there are two choices . your file format can know about know that you 're talking about language and speech , which is what i chose , and time , or your file format can just be a graph representation . and then the application has to impose the structure on top . what it looked like atlas chose is , they chose the other way , which was their file format is just nodes and links , and you have to interpret what they mean yourself . because i knew that we were doing speech , and it was better if you 're looking at a raw file to be t for the tags to say "" it 's an utterance "" , as opposed to the tag to say "" it 's a link "" . but  they 're reasonably compatible .   the other thing is if we choose to use atlas , which we should just do , we should just throw this out before we invest a lot of time in it .   the only thing  i chose this for a couple reasons . one of them is that it 's easy to parse . you don't need a full xml parser . it 's very easy to just write a perl script to parse it . exactly . exactly . which i always do . i have it structured . right ? each type tag has only particular items that it can take .  if you have more information . what nist would say is that instead of doing this , you would say something like "" link start equals , some node id , end equals some other node id "" , and then "" type "" would be "" utterance "" . it 's very similar . write a translator . ","and we have a lot of tools already to deal with it . man pages and , source code , and me . it 's something that we developed at icsi . and , we have a configured system that you can distribute for free , we should look at atlas , the nist thing , th there are two choices . your file format can know about know that you 're talking about language and speech , which is what i chose , and time , or your file format can just be a graph representation . and then the application has to impose the structure on top . what it looked like atlas chose is , they chose the other way , which was their file format is just nodes and links , and you have to interpret what they mean yourself . and it was better if you 're looking at a raw file to be t for the tags to say "" it 's an utterance "" , as opposed to the tag to say "" it 's a link "" . i chose this for a couple reasons . one of them is that it 's easy to parse .  what nist would say is that instead of doing this , you would say something like "" link start equals , some node id , end equals some other node id "" , and then "" type "" would be "" utterance "" . ","The respective frame-level representation can be handled by P-files, a technology developed at ICSI, which also comes with a library of tools. Two main options were discussed as to the organisation of the collected data. On the other hand, the ATLAS (NIST) technology offers a very similar, but more generic organisational scheme based on nodes and links. Its advantages are that it is easier to read, parse, map onto the Transcriber format and to expand with extra features. These are labeled with domain specific types, like ""utterance"" or ""speaker"". "
Bdb001.C,"but it se since they are developing a big they 're developing a big infrastructure . and it seems to me that if we want to use that , we might as go directly to what they 're doing , rather than the i looked at it the last time i looked at it was a while ago , probably a year ago , when we first started talking about this . and at that time at least it was still not very complete . and specifically they didn't have any external format representation at that time . they just had the conceptual node annotated transcription graph , which i really liked . and that 's exactly what this is based on . since then , they 've developed their own external file format , which is , this this thing . and they 've also developed a lot of tools , but i haven't looked at them . should . th what would what would worry me is that we might miss a little detail that would make it very difficult to translate from one to the other . we might as  'll take a closer look at it . and right . the  the other thing the other way that i established this was as easy translation to and from the transcriber format .  but  it 's almost the same . with this , though , is that you can't really add any supplementary information . right ? if you suddenly decide that you want  you 'd have to make a different type . right . right .  right . right . huge .  there 's a spea speaker tag up at the top which identifies them and then each utt the way i had it is each turn or each utterance , i don't even remember now , had a speaker id tag attached to it . and in this format you would have a different tag , which would , be linked to the link . somewhere else you would have another thing that would be ,  let 's see , would it be a node or a link ?  and this one would have , an id is link seventy four like that . and then somewhere up here you would have a link that , was referencing l seventy four and had speaker adam .  like that . this isn't quite right . i have to look at it again . you would have another structure lower down than this that would be saying they 're all belonging to this id . right . and then each utterance could refer to a turn , and each turn could refer to something higher up . that 's why i didn't call it "" sentence "" .   you would have yet another tag . you 'd have another tag which says this is of type "" sentence "" . and , what right . you would have another tag somewhere . ","they 're developing a big infrastructure . the last time i looked at it was a while ago , probably a year ago , and specifically they didn't have any external format representation at that time . they just had the conceptual node annotated transcription graph , since then , they 've developed their own external file format , and they 've also developed a lot of tools , but i haven't looked at them . should . th what would what would worry me is that we might miss a little detail 'll take a closer look at it . the other thing the other way that i established this was as easy translation to and from the transcriber format . with this , though , is that you can't really add any supplementary information . there 's a spea speaker tag up at the top which identifies them the way i had it is each turn or each utterance , i don't even remember now , had a speaker id tag attached to it . you would have another structure lower down than this that would be saying they 're all belonging to this id . ","This option offer well-developed infrastructure and flexibility as to the type of data storage (flat XML files or relational database). Its advantages are that it is easier to read, parse, map onto the Transcriber format and to expand with extra features. "
Bdb001.C,"it 's there 're two ways of doing it . you could have some link type type equals "" sentence "" , and id is "" s whatever "" . and then lower down you could have an utterance . the type is "" utterance "" equals "" utt "" . and you could either say that no . i don't know i take that back . can you say that this is part of this , or do you say this is part of this ?   right . 'm i had better look at it again because i 'm there 's one level there 's one more level of indirection that i 'm forgetting . right . i 'm pretty that you can do that , but i 'm forgetting the exact level of nesting . what you would end up having is a tag saying "" here 's a word , and it starts here and it ends here "" . and then lower down you would say "" here 's a prosodic boundary and it has these words in it "" . and lower down you 'd have "" here 's a sentence , and it has these words in it "" .  think that 's that would wor let me look at it again .   right . that 's gonna be is the rising pitch a feature , or is it gonna be in the same file ? but the that 's gonna be hard regardless , right ? because you 're gonna have to write a program that goes through your feature file and looks for rising pitches .  in that case you would add that to this format r right . you have that . there 's a standard again in xml , specifically for searching xml documents structured x xml documents , where you can specify both the content and the structural position . you use it as a tool . you use it as a tool , not an end user . it 's not an end user thing . it 's you would use that to build your tool to do that search . it 's a graph , but  no , no . the whole point is that the text and the lattice are isomorphic . they represent each other completely . that th but that 's gonna be the trouble no matter what . right ? no matter what format you choose , you 're gonna have the trou you 're gonna have the difficulty of relating the frame level features  right . transfer . the , one of the things that atlas is doing is they 're trying to define an api which is independent of the back store , that , you could define a single api and the storage could be flat xml files or a database . ","'m i had better look at it again i 'm pretty that you can do that , but i 'm forgetting the exact level of nesting . there 's a standard again in xml , specifically for searching xml documents structured x xml documents , where you can specify both the content and the structural position . it 's you would use that to build your tool to do that search . no matter what format you choose , you 're gonna have the trou you 're gonna have the difficulty of relating the frame level features one of the things that atlas is doing is they 're trying to define an api which is independent of the back store , that , you could define a single api and the storage could be flat xml files or a database . ",XML standards offer libraries that can be used for the development of search tools. This option offer well-developed infrastructure and flexibility as to the type of data storage (flat XML files or relational database). 
Bdb001.C,"my opinion on that is for the s that we 're doing , i suspect it 's overkill to do a full relational database , that , just a flat file and , search tools i bet will be enough . but that 's the advantage of atlas , is that if we actually take decide to go that route completely and we program to their api , then if we wanted to add a database later it would be pretty easy .  'm just a little hesitant to try to go whole hog on the whole framework that nist is talking about , with atlas and a database and all that cuz it 's a big learning curve , just to get going . whereas if we just do a flat file format , it may not be as efficient but everyone can program in perl and use it . right ? as opposed to if it 's not representing it , then how do you recover it ? it 's representing it . that 's the whole point .  that was a different point . right ? what i was saying is that for perl if you want to just do perl . if you wanted to use the structured xml query language , that 's a different thing . and it 's a set of tools that let you specify given the d ddt dtd of the document , what sorts of structural searches you want to do . you want to say that , you 're looking for , a tag within a particular tag that has this particular text in it , and , refers to a particular value . and the point isn't that an end user , who is looking for a query like you specified , wouldn't program it in this language . what you would do is , someone would build a tool that used that as a library . that they that you wouldn't have to construct the internal representations yourself .  right . right .  that there are quick and dirty solutions , and then there are long term , big infrastructure solutions . and we want to try to pick something that lets us do a little bit of both .  right . and it seems to me that i have to look at it again to see whether it can really do what we want , but if we use the atlas external file representation , it seems like it 's rich enough that you could do quick tools just as i said in perl , and then later on if we choose to go up the learning curve , we can use the whole atlas inter infrastructure , which has all that built in .  i wouldn't for the formats , because anything you pick we 'll be able to translate to another form . hi , jane . can you   we 're about done . ","my opinion on that is for the s that we 're doing , i suspect it 's overkill to do a full relational database , that , just a flat file and , search tools i bet will be enough . 'm just a little hesitant to try to go whole hog on the whole framework that nist is talking about , with atlas and a database and all that cuz it 's a big learning curve , just to get going . if you wanted to use the structured xml query language , that 's a different thing . what you would do is , someone would build a tool that used that as a library . i have to look at it again to see whether it can really do what we want , but if we use the atlas external file representation , it seems like it 's rich enough that you could do quick tools just as i said in perl , and then later on if we choose to go up the learning curve , we can use the whole atlas inter infrastructure , ",XML standards offer libraries that can be used for the development of search tools. 
Bdb001.C,"the other thing we might want to look at is alternatives to p file . th the reason i like p file is i 'm already familiar with it , we have expertise here , and if we pick something else , there 's the learning curve problem . but , it is just something we developed at icsi . and  there 's an api for it . and , a bunch of libraries , p file utilities . that 's gonna be a problem no matter what . you have the two gigabyte limit on the filesystem size . and we definitely hit that with broadcast news .  most of the tools can handle that . that we didn't do it at the api level . we did it at the t tool level . that most many of them can s you can specify several p files and they 'll just be done sequentially .   if you do "" man p file "" or "" apropos p file "" , you 'll see a lot . i have no idea . i didn't de i didn't develop it . it was it was dave johnson . it 's all part of the quicknet library . it has all the utilities for it . were they ?  but there are ni they 're the quicknet library has a bunch of things in it to handle p files , it works pretty neither do i . it 's a phil file ? i 've been meaning to look at the atlas again anyway . just keep it w and , w as i said , i what i did with this based it on theirs . it 's just they hadn't actually come up with an external format yet . now that they have come up with a format , it doesn't it seems pretty reasonable to use it . but let me look at it again . as i said , that there 's one level there 's one more level of indirection and i 'm just blanking on exactly how it works . i gotta look at it again . i 've seen it .  easy to map .  right . is that it doesn't . that not for the topic of this meeting . should we mention some names on the people who are n ?  i don't see any way that file formats are gonna help us with that . it 's all a question of semantic .  diff .   there 's actually a diff library you can use to do things like that you have different formats . it 's gonna be very hard . any structured anything when you try to merge is really , really hard because you ha i the hard part isn't the file format . the hard part is specifying what by "" merge "" . and that 's very difficult . but this is exactly what is that the problem i  exactly . ","th the reason i like p file is i 'm already familiar with it , but , it is just something we developed at icsi . there 's an api for it . a bunch of libraries , p file utilities . i don't see any way that file formats are gonna help us with that . the hard part isn't the file format . the hard part is specifying what by "" merge "" . ","The respective frame-level representation can be handled by P-files, a technology developed at ICSI, which also comes with a library of tools. "
Bdb001.C,"the problem is saying "" what are the semantics , what do by "" merge "" ? ""  and then you did diff .  that 's just what that 's just wh how i would have done it .  a textual  right . but unfortunately they 've also hand edited it .   what if they haven't notated with them , times ? imagine his example is a good one . imagine that this person who developed the corpus of the referring expressions didn't include time . he included references to words . he said that at this word is when it happened . or she .  but what if they change the words ?  but they could have changed it a little . that they may have annotated it off a word transcript that isn't the same as our word transcript , how do you merge it back in ? i understand what you 're saying . and the answer is , it 's gonna be different every time . it 's j it 's just gonna be i it 's exactly what i said before , which is that "" what do by "" merge "" ? "" in this case where you have the words and you don't have the times , what do by "" merge "" ? if you tell me what write a program to do it . right . and that 's about all you can do . in this one you would have to do a best match between the word sequences , extract the times f from the best match of theirs to yours , and use that . right . right , exactly . it could get very , very ugly .  more digits , the better .  this is right . ",,
Bdb001.D,"it doesn't it didn't move yesterday either when i started it . don't know if it doesn't like both of us i discovered something yesterday on these , wireless ones . you can tell if it 's picking up breath noise and  if you if you breathe under breathe and then you see af go off , then it 's p picking up your mouth noise . can i see it ? lattices are big , too . but what 's the advantage of doing that versus just putting it into this format ?  i was thi i was thinking the advantage is that we can share this with other people . but , minute , p file for each frame is storing a vector of cepstral or plp values , right ? right . it must be the equivalent of whatever you guys used to store feat your computed features in , right ?  and there 's  but , people don't typically share this right ?   is the sharing part of this a pretty important consideration or does that just thing to have ? you could probably translate between them . it probably wouldn't be a waste . it would mean that at some point if we wanted to switch , we 'd just have to translate everything . but that 's i don't think that 's a big deal .  see , that 's the question . how stable is their are they ready to go , or ?  each thing refers to the utterance that it belongs to . it 's not hi it 's bottom up . you would just have a r you would refer up to the sentence . what about what about , the idea of using a relational database to , store the information from the xml ? you would have xml would  you could use the xml to put the data in , and then when you get data out , you put it back in xml . use xml as the transfer format , but then you store the data in the database , which allows you to do all kinds of good search things in there .       no . i don't remember what the "" p "" is , though . probably stands for "" phil "" . phil kohn .  that 's my guess . don't quite understand what these things are .  th overlap codes . i 'm not what that @ @ it probably doesn't matter . no , i d what 's wrong with doing times ? i but can they change the words without changing the time of the word ? scratch that . ","but what 's the advantage of doing that versus just putting it into this format ? p file for each frame is storing a vector of cepstral or plp values , what about , the idea of using a relational database to , store the information from the xml ? which allows you to do all kinds of good search things in there . ",
Bdb001.E,"are you talking about the overlap a annotations ?  what i was imagining was dave says we can have unlimited numbers of green ribbons . and put , a green ribbon on for an overlap code . and since we w we it 's important to remain flexible regarding the time bins for now . and it 's to have however , you want to have it , time located in the discourse .   if we tie the overlap code to the first word in the overlap , then you 'll have a time marking . it won't it 'll be independent of the time bins , however these e evolve , shrink , or whatever , increase , or also , you could have different time bins for different purposes . and having it tied to the first word in an overlap segment is unique , anchored , clear . and it would just end up on a separate ribbon . the overlap coding is gonna be easy with respect to that . you look puzzled .  what , the codes themselves ? or the ? we don't have to go into the codes . we don't have to go into the codes . but let me just no . w the idea is just to have a separate green ribbon ,  and let 's say that this is a time bin . there 's a word here . this is the first word of an overlapping segment of any length , overlapping with any other , word i segment of any length . and , then you can indicate that this here was perhaps a ch a backchannel , or you can say that it was , a usurping of the turn , or you can any number of categories . but the fact is , you have it time tagged in a way that 's independent of the , sp particular time bin that the word ends up in . if it 's a large unit or a small unit , or we sh change the boundaries of the units , it 's still unique and , fits with the format , flexible , all that .    is it s diff ?  can i ask one question ? it seems to me that , we will have o an official version of the corpus , which will be only one version in terms of the words where the words are concerned . we 'd still have the merging issue if coding were done independently of the but then then the i agree . that was what i was wondering . time is unique . you were saying that you didn't think we should andreas was saying  ach ! then but then couldn't you just indirectly figure out the time tied to the word ? not  but you 'd have some anchoring point . he couldn't have changed all the words .  ","if we tie the overlap code to the first word in the overlap , then you 'll have a time marking . it won't it 'll be independent of the time bins , however these e evolve , shrink , or whatever , ",
Bdb001.E,but it could be that they just it could be that they chunked they lost certain utterances and all that or  that 's interesting . o three ,,
Bdb001.F,"that 's good . cuz we have a lot of breath noises . if you listen to just the channels of people not talking , it 's like "" @ @ "" . it 's very disgust  exactly . it 's very disconcerting .   i was gonna try to get out of here in half an hour ,  cuz i really appreciate people coming , and the main thing that i was gonna ask people to help with today is to give input on what kinds of database format we should use in starting to link up things like word transcripts and annotations of word transcripts , anything that transcribers or discourse coders or whatever put in the signal , with time marks for words and phone boundaries and all the we get out of the forced alignments and the recognizer . we have this , starting point is clearly the channelized output of dave gelbart 's program , which don brought a copy of ,  which right .  i actually mostly need to be able to link up , or i it 's a question both of what the representation is and   you should , definitely .  right , right . right .  it 's an o instead of an i , but the d is good .    that seems g great for all of the encoding of things with time and ,  my question is more , what d what do you do with , say , a forced alignment ? you 've got all these phone labels , and what do you do if you just conceptually , if you get , transcriptions where the words are staying but the time boundaries are changing , cuz you 've got a new recognition output , or s what 's the , sequence of going from the waveforms that stay the same , the transcripts that may or may not change , and then the utterance which where the time boundaries that may or may not change ?  and you 'd be able to propagate all of the information ?  especially at the phone level . the we have phone level backtraces .   if you were doing that and you had this companion , thing that gets called up for phone level , what would that look like ? how would you ? h you could have some file that configures how much information you want in your xml  cuz th it does get very bush with right .   definitely . we actually have one thing that don is doing , is we 're running for every frame , you get a pitch value , and not only one pitch value but different kinds of pitch values depending on meaning ?  that you could call that you would tie into this representation with like an id . and  that might work . these are long meetings and with for every frame ,  these are big files . these are really  and th it 's phones are every five frames though ,  ","and the main thing that i was gonna ask people to help with today is to give input on what kinds of database format we should use in starting to link up things like word transcripts and annotations of word transcripts , anything that transcribers or discourse coders or whatever put in the signal , with time marks for words and phone boundaries and all the we get out of the forced alignments and the recognizer . and what do you do if you just conceptually , if you get , transcriptions where the words are staying but the time boundaries are changing , cuz you 've got a new recognition output , or s what 's the , sequence of going from the waveforms that stay the same , the transcripts that may or may not change , and then the utterance which where the time boundaries that may or may not change ? that you could call that you would tie into this representation with like an id . these are long meetings these are big files . ",Two main options were discussed as to the organisation of the collected data. 
Bdb001.F,"like that .  but we actually pause phones take up a lot of the long pause phones .   that 's true . but you do have to keep them in there . y    do you are you familiar with it ? i haven't seen this particular format , but   that sounds about what i w you do ?  is there some documentation on this somewhere ?  great .  that sounds good . i was just looking for something i 'm not a database person , but something standard enough that , if we start using this we can give it out , other people can work on it , or is it ? but it 's been used here and people 've    th this is exactly the decision it 's just whatever actually , we 've done this on prosodics and three or four places have asked for those prosodic files , and we just have an ascii , output of frame by frame . which is fine , but it gets unwieldy to go in and query these files with really huge files . we could do it . i was just thinking if there 's something that where all the frame values are  they 're fair they 're quite large . and these are for ten minute switchboard conversations , and it 's doable , it 's just that you can only store a feature vector at frame by frame and it doesn't have any  i don't know enough about what we 're gonna do with the data . but it would be good to get something that we can that other people can use or adopt for their own kinds of encoding . and just , we have to use some we have to make some decision about what to do . and especially for the prosody work , what it ends up being is you get features from the signal , and those change every time your alignments change . you re run a recognizer , you want to recompute your features , and then keep the database up to date . or you change a word , or you change a utterance boundary segment , which is gonna happen a lot . and wanted something where all of this can be done in a elegant way and that if somebody wants to try something or compute something else , that it can be done flexibly .  it doesn't have to be pretty , it just has to be , easy to use , and   and why did you not choose that type of approach ?   but other than that , are they compatible ? you could you could that 's w   i don't this is what the meeting 's about , just how to cuz we need to come up with a database like this just to do our work . and i actually don't care , as long as it 's something useful to other people , what we choose . it 's oth ","but something standard enough that , if we start using this we can give it out , other people can work on it , but it would be good to get something that we can that other people can use or adopt for their own kinds of encoding . and especially for the prosody work , what it ends up being is you get features from the signal , you want to recompute your features , and then keep the database up to date . or you change a word , or you change a utterance boundary segment , which is gonna happen a lot . and wanted something where all of this can be done in a elegant way and that if somebody wants to try something or compute something else , that it can be done flexibly . it just has to be , easy to use , and ","In either case, it is important for the chosen format to allow for fast searches, flexible updates and, if possible, be reusable in future work. "
Bdb001.F,"if you have any idea of how to choose , cuz i don't . and you can have as much information in the tag as you want , right ? can you but you can add to those structures if you   why would it be a waste to do it this way if it 's similar enough that we can always translate it ? but it but that sounds as long as it is would the tools run on something like this , if you can translate them anyway ? that it 's a question that     actually , it 's that would really be the question , is just what you would feel is in the long run the best thing . cuz once we start , doing this i don't we don't actually have enough time to probably have to rehash it out again and s right . right . i like this . this is intuitively easy to actually r read , as easy it could as it could be . but , i suppose that as long as they have a type here that specifies "" utt "" ,  it 's close enough that you have to make a different type .  if you look at it and in my mind i don't know enough jane would know better , about the types of annotations and but i imagine that those are things that would you guys mentioned this , that could span any it could be in its own channel , it could span time boundaries of any type , it could be instantaneous , things like that .  and then from the recognition side we have backtraces at the phone level . if it can handle that , it could handle states or whatever . and then at the prosody level we have frame like cepstral feature files , like these p files or anything like that . and that 's the world of things that i and then we have the aligned channels , and  i definitely agree and i wanted to find actually a f a nicer format or a more compact format than what we used before . just cuz you 've got ten channels or whatever and two hours of a meeting . it 's a lot of  actually , it 's the channel , that w channel is what the channelized output out but and what if you actually have right now what you have as utterance , the closest thing that comes out of the channelized is the between the segment boundaries that the transcribers put in or that thilo put in , which may or may not actually be s it 's usually not the beginning and end of a sentence , say .  right . it 's like a segment  ",can you but you can add to those structures if you you have to make a different type . ,"Its advantages are that it is easier to read, parse, map onto the Transcriber format and to expand with extra features. "
Bdb001.F,"i assume this is possible , that if you have someone annotates the punctuation or whatever when they transcribe , you can say , from for from the c beginning of the sentence to the end of the sentence , from the annotations , this is a unit , even though it never actually i it 's only a unit by virtue of the annotations at the word level . and then that would get a tag somehow .   but it 's just not overtly in the cuz this is exactly the that should be possible as long as the but , what i don't understand is where the where in this type of file that would be expressed . s it would just be floating before the sentence or floating after the sentence without a time mark . see , cuz it 's it 's s but they 're they 're actually overlapping each other , you have to have another type then ,    it 's definitely true with the segment . that 's what i exactly what i meant by the utterances versus the sentence could be   right . an right . you would be able to go in and say , "" give me all the words in the bound in the prosodic phrase and give me all the words in the ""    that 's good .  and , you guys might i don't know if this is premature because i suppose once you get the representation you can do this , but the kinds of things i was worried about is ,   if it i can't do it , but  right . you 'd need a p paradigm for how to do it . but an example would be "" find all the cases in which adam started to talk while andreas was talking and his pitch was rising , andreas 's pitch "" . that thing . the rising pitch will never be hand annotated . the all the prosodic features are going to be automatically they 're gonna be in those  right . normally what we would do is we would say "" what do we wanna assign rising pitch to ? "" are we gonna assign it to words ? are we gonna just assign it to when it 's rising we have a begin end rise representation ? but suppose we dump out this file and we say , for every word we just classify it as , w rise or fall or neither ?  we would be taking the format and enriching it with things that we wanna query in relation to the words that are already in the file , and then querying it .  if  but as long as the but it seems like as long as the features that that 's true if the features from your acoustics or whatever that are not explicitly in this are at the level of these types . that if you can do that that 's right . that 's true . ","we would be taking the format and enriching it with things that we wanna query in relation to the words that are already in the file , ",
Bdb001.F,"that 's why i was trying to figure out what 's the best format for this representation . and it 's still gonna be it 's still gonna be , not direct . it or another example was , where in the language where in the word sequence are people interrupting ?  that one 's actually easier .  it seems like the thing you 'd do if i don't know , if people start adding all kinds of s bells and whistles to the data . and that might be it 'd be good for us to know to use a format where we know we can easily , input that to some database if other people are using it . something like that .   is a see , the kinds of questions , at least in the next to the end of this year , are there may be a lot of different ones , but they 'll all have a similar nature . they 'll be looking at either a word level prosodic , an a value , like a continuous value , like the slope of something . but we 'll do something where we some data reduction where the prosodic features are sort o either at the word level or at the segment level , like that . they 're not gonna be at the phone level and they 're no not gonna be at the frame level when we get done with giving them simpler shapes and things . and the main thing is just being able the two goals . one that chuck mentioned is starting out with something that we don't have to start over , that we don't have to throw away if other people want to extend it for other kinds of questions , and being able to at least get enough , information out on where we condition the location of features on information that 's in the file that you put up there . and that would do it , for me . in the between , right . and especially that the representation doesn't have to be thrown away , even if your tools change .  that sounds good to me . i don't  if you would l look at that and let us you think . we 're guinea pigs , cuz i want to get the prosody work done but i don't want to waste time , getting the   definitely . especially if there 's , e if someone can help with at least the setup of the right hi . the right representation , then , i i hope it won't we don't actually need the whole full blown thing to be ready ,   if you guys can look at it and see what ,  we 're we 're actually just  wrapping up , but ,   it 's a short meeting , but , i don't know . is there anything else , like that helps me a lot , but   ","the two goals . one that chuck mentioned is starting out with something that we don't have to start over , that we don't have to throw away if other people want to extend it for other kinds of questions , and being able to at least get enough , information out on where we condition the location of features on information that 's in the file that you put up there . ",
Bdb001.F,"if you and don can if you can show him the p file and see . this would be like for the f zero it 's like the history of icsi . like  and that isn't really , as important as the main i don't you call it , the main word level   that 's really useful . this is exactly the thing that i wanted to settle .   great .  it 's also political deci if you feel like that 's a community that would be good to tie into anyway , then it 's sounds like it 's worth doing .  great . cuz we actually can start we can start with , this input from dave 's , which you had printed out , the channelized input . cuz he has all of the channels , with the channels in the tag and like that . that would be i directly ,   and then it would just be a matter of getting making to handle the annotations that are , not at the word level and , t to import the right now , i g jane would   any annotation that isn't already there . anything you can envision . right . or the time .   all the switchboard in it .   w diff or diff .  you could definitely do that with the but the one thing that would work here actually for i that is more reliable than the utterances is the speaker ons and offs . if you have a good ,   you just have to know wha what to tie it to . and right , right . but , d isn't that something where whoever if the people who are making changes , say in the transcripts , cuz this all happened when the transcripts were different ye if they tie it to something , like if they tied it to the acoustic segment if they what then or if they tied it to an acoustic segment and we had the time marks , that would help . but the problem is exactly as adam said , that you get , y you don't have that information or it 's lost in the merge somehow ,  but they 've also exactly . and that 's exactly what we should somehow when you distribute the data , say that that have some way of knowing how to merge it back in and asking people to try to do that . time is the time is passing !  he 's a language modeling person , though . but still they exactly .   you only know the boundaries of the right . right . you can merge at the level of the representation that the other person preserved and that 's it . and beyond that , all is relative ordering and sometimes even that is wrong .  and then infer that their time marks are somewhere in between . exactly . definitely . definitely . alright . w i didn't want to keep people too long ",,
Bdb001.F,"and adam wanted t people i 'll read the digits . if anyone else offers to , that 'd be great . and if not , lot . it 's really helpful . adam and don will meet and that 's great . very useful . go next . ",,
Bmr001.A," we 're somewhere in between . we have some sheets for some standard doohickies to this is february second , two thousand , this is meeting number one with adam and dan and morgan , about five o ' clock in the afternoon . a range of microphones . what 's this one here ? this one is has a couple of cheezy electrettes and that 's connected too , or ? that 's connected . it 's got two to both channels .    this is  i have no idea which one i 'm on . one ! i 'm number one . which is a l a lapel , it 's sticking through my lapel . listening to this is gonna be like watching somebody 's home movies .  what do we do with the on top ? but i do we say it after we what are we why are we writing it down ?  that 's good . don't need to fill that out right now . we should just say it . then we 're not spending the time writing it out . that we 're spending the time talking . i 'm just concerned about a bunch of dead time while we all sit here and fill out the things . right ?  right . this is morgan . i 'm going to read some numbers now . that 's my group .  i don't know if i said mine was transcript zero , but it was . good .  that 's a little bit . where are we in this ? let 's see , we now have a few mikes that work . how long did it take you to set this up ? are we gonna is it gonna be over there , or is it gonna be in there ? that 's what 's gonna happen . mean , i don't know . did we s did we spend our the budget already that we had ? how much are we talking about here ? we can spend under a thousand dollars without worrying about it . 'm more worried about things being kept in a funky state long enough that gets broken or  and there 's also the minor matter , it 'd be to able to bring people in and say "" yes , this is where we do such and such "" , and then be able to see some it 's less important than doing what we 're doing right now but  we should be able to just go buy some preamps , i would think .  are we ?  'd figured that jim would do that at some point . right ?   if it 's too noisy and if there 's something we can buy , again for , moderate amount of price , even if it takes a couple boxes we should just do it . and then later we can replace it with because there may be other considerations that will go into the design . ",,
Bmr001.A,"our getting some experience with this may help to determine some of things that are i don't know might change this design , there was statement made which i don't think is right , but there was a statement made at the darpa communicator meeting i was at recently that microphone multiple microphones at a distance of less than three feet like that were useless , completely irrelevant .  for nois noise cancelling . my counter argument is an a white rat . which has th it 's two microphones exceedingly close together and it works pretty but right . but that if my point is if you have a a volume in between the two sensors and you do something cleverer , there clearly are ways to get more out of it .   there are various points in meeting where people were making very strong statements like one shouldn't even question it and this was one of them that was funny . but i what i take it to mean is doing the dumb thing with two microphones would be very difficult to get too much out of it but it will be interesting to do other things that aren't dumb . still think it 's potentially interesting to do that . although we 'll have to be aware of this if we 're writing proposals about it , wherever , that there may be reviewers who will say , "" everyone knows that you can't get anything out of it if it 's close "" . that is an interesting point .  certainly you can get some  hopefully . we 're getting some right now . someone might be interested in it .  but on the other hand , suppose that you 're the only one who is advanced enough in this thinking to actually bring such a pda to a meeting and therefore you bring it in , and you probably want it to be as near to people as possible you might shove it to the middle of the table .   we should . at least with two . right ? because one of the th one of the fantasies that was at least fun to talk about was that you th you 're the range of things you can do with multiple microphones is limited if they 're a few inches apart , but what if you have two of these things ? and we have this idea of the handshake back and forth and say "" i 'm here , i 'm here "" "" we 're now an array . ""  where are we now ? we 've just we 're doing this recording we show we can we 're capable of doing recording there 's little more wiring to do to have more if we had more people participating in the meeting we 'd wouldn't quite be ready for that .    little bit of futzing , there 's the issue about a cabinet , we might want to change some pre amps . ",,
Bmr001.A,"we can do some more recordings but there 's a little bit of ramp up on that over the next month , say . we were talking about that a little bit over coffee today , that if you downsample it sounded like it came it sounded like it was something like a gig gigabyte an hour if you didn't downsample and once you downsampled then it was something like four hundred megabytes an hour , if you used all if you used all no , if you used all the channels . something like that ? it was one gigabyte . it couldn't be twelve . how 'd you cut it ? that 's two gigabytes . and then right . but that 's at forty four kilohertz with sixteen channels . you can right , you can we 'll do the higher math later , but it 's like a gig or two a an hour , but that is a bit more than this 'll take some thought cuz we have we if we are gonna have forty or fifty hours at some point and we wanna ha have part of our work be on feature extraction , it means that we need to have waveforms available somehow . what would you do ?  what would we do for training ? if we 're training distant mi we 'd just use one of them ?  although we wanted to get alignments from the close mike right . but you don't want to be constantly take putting that on disk and off disk and on disk .  it 's really not very expensive right now . it 's more of an issue of structuring it with the sys admin folks we don't panic them and figuring out where it goes . we don't it doesn't need to be backed up .  the only one using it has been javier , but at this point it 's he 's only been using it for features that he calculated quite a while ago , if nobody else is doing feature calculation pardon ? how much space is that using up ? do you have any idea ? couple hours ! anyway for this recording we 're fine cuz we 're only how many mikes are we recording right now ?  that we can do something about .  what 's it do ?  think initially we should take up more space until we 've analyzed this and get a better sense of it because we don we 're not talking about forty or fifty hours at this point we 're talking about a half hour of speech and we should look at this carefully but i was interested when i saw the twenty four on there . that 's probably eight bits of noise .    it 's some oversampling thing i imagine , right ? didn't we already get that ? cuz you can't have component tolerances that are sixteen million one in sixteen million parts ,  i 'm s    ",,
Bmr001.A,"but we can ftp over , right ? it 's connected .     one suggestion i have is that think this we should just read some more you made more of these , right ? we should read some more because this is very f we need to work the the talkers more because we 're not gonna have that many meetings and this is a pretty tiny amount of data . we should do another number list and  this is us . we 'll have a fair amount of annoyance think  can we do another set ? are we are we we talked out about what we 're  right . they would . and also he 's he 's got at least one woman . and we 're we have a little problem of no women , when l when liz shriberg starts coming , then there 's another woman although she  that 's right . that was it .   no , actually we could have jane jane 's interested and curious about this she could attend one of probably not the decoder meeting but some of the other she would be interested enough and have her read   think that one of the neat things about having this little pilot thing from today is we should try it a couple different ways , we should try to do it internally , ask jane if we could get her to do it or have her supervise a linguistics student or somebody and see how long it takes , and multiply out the cost , and then send the same thing out , or split it in halves like that to a to an outside service and see what that costs and how much hassle that is . and then we can assess it . no . no . right . this was the point of having near zero skew . right ? you just pick one , with the best sounding one , and give it to somebody and they transcribe it . right . you could do fancy things , but it seems like that 's enough . but don't know . this meeting , say it 's going to be a half hour and we 've heard estimates ranging between ten and twenty times real time to do this transcription in principle then it 'll take somebody a day for somebody to deal with this . and we 'll see which one of those seems closest to right and if they ramped up , if towards the end it was faster get some sense from them from whoever does it and then like i say , check it out with an external service and see if it 's faster , cheaper , better , worse , whatever . then we 'll go from there . i don't know . i do i don't know the answer to that . i don't know . there 's this cyber transcriber service , right ? ",,
Bmr001.A,"and at least supposedly the way they work is by feeding them what is the output of the recognizer . it depends on what the software tools are like . if it 's if they can easily flip through and get to the right thing , or do you point , or i don't know . there 's supposed to be some out of work shepherders in scotland but the internet .  inexpensive . we 're degenerating , right . are we done with mr business , or ? what 's we should what are our action items ? there 's the continuing process of cleaning up the and making it easier to do that . there 's taking the results of this meeting and putting it in some decent form , probably getting some single channel merged sum data that you can give a simple sound file of some sort to a transcriber to deal with it rather than this massive thing . that 's a little bit of to do . right ? although it may be separating out these numbers from the rest .  and then and right . with this next   how many more you got ? let 's do some more while we got them here . it 's not , but there 's just two more .      i 'd say we 're done . is it 's going to disk , or is this and how much disk do we have ? ",,
Bmr001.B,"we 're live . are we live or are we memorex ? right . is that alright ?   both channels . although the gain is pretty low . for the read numbers task , i have extracted these  right and i 'm now talking on microphone number two , the wireless microphone number two . i 'm actually , i yes , it 'll be pretty horrible . what i have on these forms here is for the read numbers read digits tasks and it 's extracted directly from aurora and what i was thinking is we could start just by filling it out and then reading the numbers on the form . fill it out . no , you don't need to . that when we transcribe the data we can figure out who said it and their gender and the date and the time and what mike they were on and all that thing . w why don't you want to fill it out right now ? just that  and you have to be to pause between each line , since we 're going to be segmenting it and then doing it that way . definitely wasn't pausing enough between them . that 'll be an issue .   right and that included a fair amount of fiddling around , since it 's more or less the first time we 've tried to do it . ev eventually we 'll want to like tape that over and run them up through the center that wires aren't people aren't tripping over the wires and on . right . do we have like a cabinet on order or do we just need to do that ? help them get done one question is budget . do we have any money that we can go out and spend on things like cabinets or a hard drive or things like that . our intention at this point is when we 're not using it to record a meeting we 'll coil them all up and put them under that people will not be tripping over them and on .  right . not have it ultimately we 're gonna need to build one anyway .  because we 're gonna have to put it in a pda . right ? if we have microphones in a pda it 's gonna need bias and a pre amp .   right . for noise cancelling , or ? do they mean omnidirectional , is that their point ? all the noise cancelling mikes , they 're they 're a few m millimeters away from each other pointing in different directions . but . i see . it 's they 're not talking about how far apart the mikes are , they 're talking about how far they are from the speaker .  do they believe you can get speaker location out of it ? cuz that 's one way we could sneak it in .  for location ?  depends on who 's working on it . right . ",,
Bmr001.B,"but someone has to write some software to actually do it . someone might . that 's i was just thinking one thing we may wanna do is put the fake pda right in front of someone instead of in the middle of the table like we have it now . on the thought that my vision of it is each of us will have our little pda in front of us and the acoustics you might want to try to match the acoustics . no , and i don't need to meet with those people .  right . right . that 's right . three , right ? guess this a pretty dense group but it 's getting a lot higher . i 'm trying to be .  except i s got a pda way before was doing hand i was doing wearable computers at boeing , guess i count . but .  five with wireless . we could have eight . nine . excuse me , nine . five with wireless and four without , and four with wired . we don't have headsets though . we just have to c wander around and collect them up .  there 's one in my office .  we 'll just have to see if that works . right and also i would like to work out some of the software issues a little more completely . we 're gonna want to resample and con and bring them over to another machine and organize the how we 're gonna store it all . it was more than that . we said , four gigabytes would give us twenty minutes before we did anything else . and then we cut in half , by that 's forty minutes six gigabytes .  i came out at the gig an hour , at one point . that 's one computation i did for sixteen channels , sixteen bit . is it two gig an hour ? i 'm off by an order of magni that 's alright . order of two . factor of two . how much here would we have to reformat the drive in there to get some of the more space cuz it it 's a nine gig drive and there 's four gig on sc on scratch and there 's about three gig unused , it looked like , on the home directory . don't know enough about linux . how hard is it to repartition ? it 's a pain .  right . 've already created a "" u , doctor speech , data , mr "" directory , or had jane do it and but there 's not a lot of free space around . it has currently about four gig on the drive that she 's going to put it on and we need we definitely need to go buy forty gig fifty gig of drive space . that 's true . i hadn't even thought about that , although it 'd be interesting . ",,
Bmr001.B,"it 's pretty horrible . it might be four . right ? but it wouldn't be sixteen . but that 's a separate training . no more disk is better .  my preference would be to get ourselves a hundred gig of disk . and just not bother . and back up . right , then it doesn't need to be backed up . we were talking about that . i 'm not if anyone 's still using it . i 'll send mail to speech local . i 'll send mail to speech local and see if anyone 's still using it . that would last us for a while . right now we don't have any choice . it r still records all sixteen channels . it 's just most of them are all zeroes . that 's on our list too .  it 's mostly a question of user interface . how do we specify which ones are on ? we don't store any of our audio formats compressed in any way do we ? these large sections when you guys aren't talking run what on those ?  p z  it 's something that we definitely need to look at with this . we shouldn't 've subsampled it down to sixteen bits for our first try . right . we might wanna see if the low sixteen bits on the p z ms are better than the middle sixteen bits . regardless , w i was just noticing on the there 's a view meter , software view meter and the pzm gain is real low .    that 's right . we 've got lots of bits of noise . right the other thing another issue is just getting a sound card up here . i assumed that we could just put a sound blaster in if we want sound output . it 's just not working .  that way we don't we can't listen to it on this machine . right . and we 've looked at it we know it 's working . you can see the little squiggles , and it looks like speech you just can't listen . right .    right did ten per page i could easily do twenty per page . it 's just a question of of how much annoyance i wanted to put people going to meetings through .   us , to begin with . that 's the intention . think , certainly us , meeting recorder . us other groups . it just depends on how many meetings we 're having .  jerry also said it would be he would be willing to have his group , some of the ai meetings do it as and exactly . there are enough incidental meetings for us to do this . and if we can get it set up it is convenient enough , then you can just do spontaneous meetings as which i 'm interested in . ",,
Bmr001.B,"that 's one of the things , the whole reason i want a pda as opposed to a wired room is for spontaneous meetings . right . that 's right . that 's why i put ten on here instead of thirty or forty or fifty . right . i bet they would be willing to do it the first few times , just for the novelty . that 's a good point ! boy , that 's abs i had never i hadn't even thought about that . man ! we should have the reading group here and force jane to come .  it 's a different style . but that 's alright . we were joking about having lunch up here but eating with the microphones i had another question briefly about transcription . are we going get an external service or are we gonna do it ? who 's gonna generate the transcripts ?   right . the problem is that it 's in this meeting it 's three four five six seven eight , it 's nine transcripts , potentially . you 're right , . right . the only thing we 'll have to be careful with is that they 're what are they listening to ? they 're going to have to make speaker assignments , and wh and which recording are they gonna listen to ? that would be interesting .     yet . that that 's one chunk of work and just segmenting for this is gonna be another chunk of work .   right .  one of the things i was thinking with transcript is that if we take the near field and we do an initial recognition pass , is it easier for a transcriber to correct a transcript , if the near field mike does a reasonably good job ? i bet it isn't , unless it 's really close to right . right . some errors , not in scotland . not in scotland . they sheep they s they speak cheap english , right ?   right . and then do some segmenting and recognition initial recognition would be interesting to do . that 's what just doing a digits on it connected digits . you wanna read ? on i did ten but have a script to generate them automatically .  that 's why ,  go ahead . go ahead and read it and then fill it out .  ",,
Bmr001.C,"that 's  you 're going to sit there ?  'll put this thing here then .  that 's the dummy pda . it is . hang on . it is at the moment .  hang on , let 's let 's just name the microphones . 'm speaking on the ear mounted wired headset thing .   you 're on one .  yes . this is the pzm nearest the the machine room end of the table . then there 's i know , but it 's number three , it says , but we 'll be able to figure it out . this is at the middle of the table this further down the table . and this one is right at the end of the table ,  and then we 've got the this is the left side of the dummy pda and this would be the right side . very exciting . no . just write it down .  how about you give me one of those and we can fill it out and morgan can read and then we can do it like that .  this is these are things we will find out .  can i have something to write on the back of ?   it didn't doesn't take as you see we haven't really set it up that but it doesn't take long to set up . we just came up here one night after recording it took like twenty minutes something like that . it 's the equipment right . the equip me and adam went through it yesterday , just looked at everything . but it 's all here and set up , it 's just a question of turning it all on . and , running the program . right . it 's gonna b it 's for reasons because of the microphones runs we want that chunk there . there 's more equipment in there . but there 's the idea is that there are these microphones on the table , there are some cables coming down under a mat , and then that 's they a bunch of them get converged with digital there . and the idea is that this gets replaced by a cabinet with doors , that it 's not open to fiddling . that 's we need to do that . it 's on a list of things to do . i keep on hoping that they 're gonna get done but they don't . i   i don't know . a cabinet is probably going to cost a hundred dollars , two hundred dollars something like that .    but , we should get to a working state of our set up as quickly as possible .   there 's one big issue with the equipment still , which is ultimately we 're gonna the idea is to have any number of these wired headsets , but there 's this amplification problem . i built this thing , it 's that 's it 's very noisy . ",,
Bmr001.C,"we 're actually recording i 'm going through it at the moment , but it 's noisy that i am not using for this . it 's designed to be used for the desktop meeting as but i 'm using running that through my damp machine as a pre amp as an alternative .  it 's just it you see how clumsy this is right ? i have to use these batteries to bias them . and i 'm only get two channels and there 're a bunch of there are like three connectors in the circuit . it 's not s it 's not that the thing doesn't exist commercially , but there isn't one unit which does the whole thing in one swoop . it seemed like it was a good idea to make one . and i 'm still not probably know how to fix this . probably build it better it doesn't have such noise , but it 's buy . we could just    jim is busy at the moment . that 's the problem . i was hoping that jim was going to build this box . but but he hasn't had time . he is quite interested in doing it . but .      this happened . mean , my guess is that means it 's just that if it 's near field , the mathematics of beam steering is different . if the f if the wavefronts are not approximately planar then you can't just do delay and sum and expect it to work .      right , right . the the weird thing is that actually delay in some beam forming is not the clever thing to do . the underwater guys do this which is different . and it actually means that you should get the microphones as close together as possible . rather than trying to get them far apart you can get separation , you you want them very close . and the math is too difficult for me to understand but it 's there .     we could by the time we 'll have data we can actually demonstrate that .  right . right . but    for those we can make several more of these and then we can have actual recording with three p d    right , right .  and that seems very easy to believe scenario , given the number of palm pilots we 've got on the table right now ,  but that it 's we 're not , even , it 's we 're just it 's not like we may be technical , but we 're not particularly pda people . it 's that 's just how it is . i know . that 's true .   right . we 've got right now we could have two more people on wireless , with a trip to leo 's audio we could get a third extra person on wireless , ",,
Bmr001.C,"and right now we could have three more people wearing mikes like this , and that would just work . 'm not how good the quality is on this mike but it 's going to be we could actually have eight people with headset mikes with , no extra effort .  nine .    we have the the ones we 've been using , the ones we got for the pc .  we have three of those . and the h right , right . they don't all work , but the ones , the plan plantronic ones work .       per channel , or ? we figured out that it was t twelve gig twelve gigabytes an hour ? for all the channels ? was that with or without the cuz no , we 've only no , we 've only got four gigabytes and that  right . and then we cut it in half . but by s saving sixteen bits on instead of thirty two . no it 's four gigabytes for forty minutes . forty eight kilohertz , we can actually triple that . hang on that would think it 's two gig an hour . cuz like , we don't we don't need to save all channels , right ? on average . we could we don't we wouldn't use all the channels , necessarily .   i 'm  it 's a pain . because cuz we 've got data on "" user "" , right ? and then we 'd have to back it all up and copy it back on again .   no .    we don't need all we don't necessarily need it all on line . it will be different subsets . you won't , do all sixteen channels in a single  you typically train you 'd have fi you 'd have fifty hours we 'd only use one of the pzm channels , something like this , and that would you wouldn't have to use all sixteen channels at once . but it 's painful for because if we put them on c ds then each cd will have all the channels for one recording , and then when you want to build the p files , you just want to get one of those files off each of the sessions and  two of them , but we wouldn't use we 'd only use the distant mikes , right ?  right if we burn it all on cd rom , then , we could we could throw away the broadcast news and put it on there like that . somebody used it recently .  it 's twenty c ds , that 's twelve gigabytes .    probably , we could probably just run shorten on them and it will get a big win . that 's a good shorten . tony robinson 's lossless compression thing . it does ar modeling ",,
Bmr001.C,"and it looks at a section , it runs an ar model to w to whiten it and then quantizes the residual with a with the three bits it can get away with . something like that . think it on each block it 'll compress if there 's load on in any range it 'll use ratio bits . it does that .  it 's it 's only the first try . i what i 'm thinking is we can do the we can choose any sixteen bits from the twenty four , we can just have different gain things that we use per channel .  probably the bottom four bits are not any good , right ? although it claims they are . but probably the     these theories things are pretty amazing . and there 's help they seem good though they seem to be god knows .  right . right . that card that machine 's got sound they 've got a sound blaster built into it . disabled it cuz i wanted to find out how the sound infrastructure would deal with both at once but that 's , probably it will be fine . there 's no , for a couple of reasons . but the @ @ there are two ways we could listen to it . there 's a sound there 's actually sound output built into this thing . but the driver i haven't the driver may not support it yet . and then there 's also the sound or the sound card built in . but i don't know how to i don't know how the operating system would like having two sound cards .     no , the question i still have about what we 're going to do is what we can get the equipment set up that we 're in a situation where we can with , ten minutes of preparation , we can bring nine people in here and do a multi channel recording .  what are wh when are we going to do that ? who are they going to be ? what meetings are we going to record ? which meetings what meetings do we have ? like "" us "" being the meeting recorder people or "" us "" being anything that speech local does .  and we should have like we should have decoder meetings and that 's the thing . it 's to g right .  right . we 've got to make it really easy to start it going then in that case . cuz that 's the real goal . right . but if we want jerry 's group to use it then we probably @ @ won't ask them to read any numbers , right ? cuz .   that 's great . i know . i know , it 's a disaster . it 's alright she doesn't mind as long as we don't video her , right ?   we could have the reading group in here .   it 's great .    ",,
Bmr001.C,"except that you wouldn't transcribe them all individually , right ? you would send transcriber is used i don't know , assume presumably a transcriber transcribes a single meeting , right ? and they just have to indicate that the speaker changes . right ?  they 're gonna have to make speaker assignments like this . for one of @ @ . or we could mix the headset mikes , just to make a single high q high quality and we could do all kinds of weird things like having squelch that you only , you only you cut it out when there 's no energy . you don't @ @ noise .  there 's it 's if we do something which is have a little bit of human input to get the words then we can leverage that a lot by some clever cross thing to figure out which channel they really belong to and like this , probably .  and as much work as you want .       i have just because it 's such an un the transcribing is something imagine doing , whereas having this distraction of having something that looks like it might be right but has got some very wrong bits in is less easy thing to do . i 'm the professional transcribers don't have any use for that 's true , that 's true . by fixing up transcripts . but  they should all be in india right now . that 's where the good , but the cheap english speakers are . i 'm they don't speak such clear english     what fun it is . it 's interesting that it m it 's not clear whether it 's better to have them written as words or figures . but , to get zero and "" o ""s distinguished we you have to do it . but it 's weird to read .   i wonder if we ran out of disk space yet . ",,
Bmr002.A,"channel one . off by one . right . go ahead . can we can do them again ?  i 'm on channel one mike one , channel zero , probably . channel zero . head restraint system ?    this is pzm two . and this is pzm one . which  he 's ? right . second . no , i was looking for the ones  then , fine . see if we care .  right . but before w before we before that . do you wanna read next , or d ?   this is eric on mike one , the wireless lapel , channel zero .  right .    it 's fine . i 'm just curious how h how exactly you got roped into this .   good .  that would be m that would be my fault . right . right .    you 're gonna do the actual transcription yourself .  right .  one th the other thing is that we might be  that 's what i was gonna say , is that adam has foot pedals that we could probably try and rig something up to except for the fact that we would have to unplug it and pow and change it w does it lose the memory once you 've unpowered it ? right . right , this is the pilot data .  awesome . what happened with switchboard was at least , the output was that they had speaker turns and they analyzed it in terms of , "" this is where this speaker change came in "" and that gets really difficult when you 're talking about this is some of the that you were talking about in your lunch talk , is that you get backchannels and like that , disrupt the the segment the segmentation . right . right .  we we should look at the the tools that mississippi state has . because , i d i know that they published annotation tools , for their ins      we can hear all your conversations along the way . right , but we can do automated alignment . that 's not a problem  i th to get the r to get the actual transcript , we 'll do because of the separate channels . right . right . right . know that the mississippi state tools , at least th what the produce does not come out in stm format . they give they subdivide into wave files and then they give for each , they give a one a wave file that g indicates where the start and stop times are , and then and then give the whatever the sentence information . but ni i it as you said , it was easy to convert back and forth between that file and stm format , what i did is i took the mississippi state data , and just made stm files out of it .  looks like work packages . must be a european project . ",,
Bmr002.A,"they 're using the alembic workbench , from mitre .  i don't know .  this is , i see . they 're reviewing , and i see . mitre , but that thing we would probably want to extract automatically . e this is , the this is a conversation that we should have with liz . right ,  because she 's going to be the one who 's the most concerned about this thing . and she may have some ideas . on that particular issue .  can i see that ? right . this 'd this w is probably what the l d c uses . they do a lot of transcription at the l d i could ask my contacts at the ldc what it is they actually use . i know , 've got contacts up there ,    no . right . we 're very good at time alignments . right .  uses what ? it 's very interest it 's interesting that one of the coordinators on that is mark liberman from the ldc which means that i don't coordinator "" means in terms of that .  what is what is this web page from ?  i see . right . right .    right . actually what i would have come up with was w "" what was the web address of that thing "" , which we didn't we didn't record that . right . slash capital cta slash , l   right . i see . right . no , right , i didn't mean to imply that we shouldn't discuss this now , but i 'm just saying that right .  they 're coming in april . right . but , we may or may not talk before then on that . we won't probably talk until we have more data , i would think . right ?  right .  cuz you 'd get you get right !  you would sound like you 'd have like in this e big head . right . right . part i w we also need to d do this in terms of smartkom , we 're collecting this as to build general english acoustic models . that can be that they can say "" here 's the vocabulary and here 's the here are the pronunciations . and go to it . ""   no . dan 's got an open notebook , too . right . are you certain ? i hear what you 're saying . i asked if somebody else wanted the lapel mike . somebody else can take it next time . that 's it ! right . right . yes .  how much space do we have left ? really .  this is eric on microphone number one , channel zero ",,
Bmr002.B,"  i 'm on i 'm talking on mike two .  which channel is that ? mike number two , i 'm talking right now on ? mike number two ? channel one ? is that channel one or channel zero ? which is zero based or one based ? we 're not going to do that .  wh that 's why i wanted to write it down , but dan just doesn't want to do that .  now , that means if i 'm going to be standing in there looking , then someone else has to write them down . because i won  fine . let 's not try to do anything too easy . testing .  they 're in the folder right there . you may . jane , can you talk into your mike ? you said it 's mike four ? i 'm glad you like it . eric , what mike are you ? mike one looks like it . s talk again ?   can you do taps on the p d and the p z and you have to actually check what the nu the start with p z  i can't tell .   f  and pda , left , right ? i don't see anything .   all  did we just record all that ? should we start it over ?  the ones that aren't filled out are the ones you want to hand out . i threw the ones out , that we already recorded but we didn't record . right . the first task is to read some digits . 'll go ahead and start . and this is adam on mike number two , if you could just fill out the form , and then later on we 'll read it , with pauses between . and we 're session two . let her fill it out and go ahead and read . you wanna pause briefly between each one that the person transcribing can tell where one ends and one begins . a short sentence between each line . you can intone it however you want . imagine that you 're reading a number phone number to someone .  good .  we 'll probably do another one at the end of the meeting . just to get some more digits . and ,  what 's your mike number , jane ? dan doesn't remember what sex he is . that 's true , it 's really difficult . don't you i wrote a scanner program that scans these forms in . anyway . why did i call you all here ? what i 'd like to talk about is , the transcription . as part of this project , we need to transcribe these meetings . to do training and test and on . and , we need word transcripts and , speaker change identification . speaker id . and , 'd like to know who 's going to do that , hi jane , and what tools to use , ",,
Bmr002.B,"what other resources you might need , and also what we things like just the data format and how we 're going to do it . really ? cuz morgan said he asked you .  and one of the first questions is , "" do you need help ? "" that 's not the first question . right . that 's i was saying before we don't really have to worry about people being surprised by it . play .  i actually have some foot pedals for the p c . keyboard . and they generate keystrokes . there 's a little program that downloads into it .  but the program probably only runs in windows , although i bet we could program it once and then put it on another machine and it would work . i haven't used them . i don't know . i don't think it does . i 'm not using them anymore . i used to use them . they 're currently set up for shift , control , and alt . but i r i don't use them . they 're not even plugged in . and tha if that would help , 'm certainly willing to donate them . and it is a pc connection , it would have to go on a p c somewhere .  you are generating it . that was part of the question , is that if , for if we 're doing this regularly imagine we 're doing a couple of hours a week of transcripts of recording , i wouldn't expect you to do it all . the question is do of resources that we could use . are there grad students or undergrads or just commercial services ? really ? we only have to give them credits , we don't have to give them money ? you do have to pay them .   we need to find out how much that will cost , can pass that on to morgan , cuz right now we have almost no money . the cheaper we can do it , the better .  right .   if in terms of transcripts , but in terms of speaker change it might be to get the actual time . right . in terms of data format , what are we going to do about that ? you have the s t m format , where you have every phrase , every utterance is a single speaker . is that the right way to do it ? or is that the right way to do it ?  that means that for each utterance , we 'll need the time marks , the start and end of each utterance .  x waves have some as but they 're pretty low level . they 're designed for for phoneme level although , they actually have a tool for that could be used for speaker change marking .  ha have you looked at it already ?  a is this ",,
Bmr002.B,"these are p particularly for time alignment ? right . are they just for time alignment or are they for transcription as th i it 's wireless . it won't  don't talk to yourself too much . for the digits for the d right .  i 'm not if we can do automated alignment or not . e especially in e with speaker change in a meeting like this , where we 're overlapping much , i don't think we 're gonna have a prayer . that 's true . right . we could just do it through these . i hadn't even thought about that .  in terms of data formats , what i did for the digits was just to hand rolled my own . that looks like this form . it 's just something that 's easy to parse in perl . probably for the full one , we 'll want to do something like s t some format that our tools already work with . presumably . that 's true .  "" mate mark up framework "" .  no ! it has the word "" x m l "" in it ! is that free ? but it doesn't have enough pictures . it will require too much reading to understand whether this is anything that we can easily use . "" tei "" is ?  xml makes some amount of sense . i 'm not actually familiar with it but it seems to be the thing that this would be good for . but  right . right , but it 's for the initial task , just getting the word transcripts and speaker change is highest on my list .   think that it sounds like you 're at least a little familiar with these tools , jane , are y do you feel comfortable just picking one ? because  signed language is interesting . how should we proceed on picking a tool ? jane , do you want to pick a few and we 'll download them and try them out ? is that the right thing to do ? no , we 're not going to do time alignment . right , and but , in terms of what the transcriber needs to do , they 're not going to have to do time alignment . except for word speaker change , but then we 'll have to use it . no question . boy , the recognition on what you just mumbled is going to be really horrible .  it 's called "" transcriber "" you said ? gacks   wrote down the french site and i will check it and try to download it and see what it looks like . they have a i vaguely recall that they have a pages tools page somewhere , with like lists and lists of various and assorted tools .  we 'll start with "" transcriber "" ",,
Bmr002.B,"and if it looks like that 's not gonna do what we need , we 'll move on to the mississippi state and if it doesn't look like that 's going to work , we 'll look at something else .   also , i wanted to mention just in passing that another thing that we 're going to want to start collecting is queries for the meetings . if over the next couple of days you find yourself wondering what we talked about in the meeting , write down the query you 'd like to make . do you understand what imagine that we had meeting recorder all done , and you had one , what might you do with it ?  if they occur to you . right . that 's a good one . send m if you could just email me them . except we didn't record .  it 's www dot etca dot fr . s l slash lots of other when is she showing up ? april .   right , since we have almost none right now , let 's we need to move forward from there . but it 's o k . and then , there 's also just the general question of will it handle multiple channels or should we just dan and i spoke about this briefly , do we want to try to combine channels somehow to make the transcriber 's job easier ? i was listening to some of it and like , if you just listen to the far p z m the person sitting at this end of the table you can hardly hear on the transcript , there may be it may be worthwhile to at least try a little bit to combine the channels .  neat ! that would be interesting as to do that . i bet if you used this one the two s most separated p z not . big ears . right .  do we have anything else to talk about with transcribes ? and we 'll run a train a neural net and create a recognizer and do information retrieval and that 's my interest . other people have different interests ,  that 's what i want . right . right . what the the reason we 're doing near field as is if that doesn't work we wanna back we want some something that will work . right . right .  why ? y the question is , "" is it will it work enough to do information retrieval ? "" w will the application the meeting recorder application , work ? is part of the research is is fifty percent accuracy enough to do an useful information retrieval ? "" it might be . that 's right , but we have to try . we could simply not do the project . but that 's a bad solution . i didn't know that .  he has the open piece of paper . open notebook . i have one ",,
Bmr002.B,"but i 've carefully covered it that it doesn't to some extent with things like the stress and the other prosodic things an and tighter time alignments that we can do we should probably do those but only once we have a consumer of that data ' right now we have a consumer of the word transcripts and the speaker change . me . i want those things to work . and would like to get that done as quickly as possible . and if liz or someone else wants to do some work on prosody and on stress and on then we can go back to the data and generate the the transcripts that we need . even for an undergrad ?   right . accuracy ? certainty , islands of certainty .  no .   all caps . anything else ? i 'm gonna go download "" transcriber "" and jane and i will look at it  think the answer is we need to record as many as we can . right ? i don't see any reason not to try to record a meeting or two a week .  more if we can . and wanna wanna start by in the next couple weeks just doing the speech group until we get to the point where we 're fairly comfortable with the hardware and the software and everything works . and then 'll also jerry volunteered to have his group do a few . i 'll try to get those as we have five of the wireless . and then we were going to be getting a bunch of wired ones as notice that n your you stood up and walked around . none of the rest of us have . and we could have wired mikes and i wouldn't be a big deal . for bigger meetings .  it really makes you feel like you 're doing real work when you get all this hardware .  why ? i had noticed that you were talking quietly , and i was actually going to ask you . i was going to ask you to speak up . but i didn't want you to feel self conscious .  i 've been trying to rotate it through . dan will get it next time . do you feel like a television star ? that makes sense , right ? cuz he 's not heavily encumbered with this n you should have run it under your sweater , though . we 're there .  he changed the downsampling . this is adam , on mike number two , wireless headset  very much . just control c , dan ? ",,
Bmr002.C,"that 's recording now . do it again . that 's that 's in channel one . channel one . let me make there are no there 's only one connection element . it 's zero based . unfortunately the mikes are this has the disadvantage of needing to put the numbers on the mikes . consistently not equal to the numbers on the channels . you can write it down . write down whatever you like . i don't know . you can do whatever any way you like . the weird thing is that it means that it varies when you move your head around but it 's probably the better solution .  do we have the numbers ? the sheets , that we did from last time ? we can do them again ? great . i 'm on mike three . this is mike three , coming in here . it 's moving around as i move my head backwards and forwards . that 's just the way it goes . that 's life . that 's just what it does . that 's right .  p z ms ? or not p z because this is pzm number three . let 's list them in order . pzm number three was the furthest away . this is the next one in , which is pzm number four , pz what can you see other happening ? this is pzm number four . which is closest to the machine room . don't know . it 's all hopeless . this is one side of pda , we could actually give these sides names , right ? this would be left , wouldn't it . i know , but i 'm just asking . i wasn't asking you . this is pda left . you getting something there ? and this is pda right . they will vary in future . because it depends which one of these shows more consistency then . no . we 're w we 're ahead of the game now , cuz we 've got built in downsampling now . we 've got built in downsampling . and it 's only recording sixteen kilohertz data , and we 've got we 're not select we 're not recording the empty channels . what about the ones that we didn't record ?  fine . then it doesn't matter , does it . before that .  this is dan on mike three , wireless headset , i 'm wearing it around my neck . which may be different than wearing it on the head . and great . it 's weird . that was great , what you did .  cuz i figure no one 's going to be able to figure it out from the from my name .   right , right . hang on .  do you do you what are we talking about ? that you 're gonna do transcriptions ? you 're going to listen to these things and  ",,
Bmr002.C,"d i and do you have a clear is that do you are you going to have to make up what you do or do you have a very clear idea of what you 're going to do ? mean , is it is this l is it like something you 've done before ? or  and ,   because as people are going to be listening to it afterwards and saying "" listen to her . she couldn't even speak true english sentences ! "" you 're meant to speak naturally . you 're meant to say "" i didn't realize we were being recorded ! "" it 's just jewelry .     the problem is the thing about transcribers is they have foot pedals ,  i see . i actually have one . sarah has one because she does a lot of transcribing of interviews . but the crazy thing is we 'd have to convert the s we 'd have to dump the audio files onto cassette . to use it . given that we 've already got them digitally it would be it 's quite tempting to use some software thing . but then there 's the question of the ergonomic interface , that  what do they connect to ? that 's now how do you decide which keystrokes they generate ?  and this is windows ?  hang on . you have these foot pedals but you d you 're not using them .   that 's   the d the the the part that 's not wonderful is someone has to write the software .  right .      what 's her name ?     the p what i 'm hearing is that the problem of starting off with some recordings and trying to get word transcripts is it 's not a it 's not an unfamiliar problem . that that that there are standard solutions and we should just adopt them and it 's going to cost however much it 's going to cost , there 's we 're probably not going to have a lot of flexibility in bringing down the cost cuz probably the low cost solution 's already been established . and that 's just whatever it is . that 's how we 'll do it . see what    whatever they people who have had to do this the only thing is i wonder if our requirements are different from mean there 's than what 's been done in the past than discourse analyzers because we have different requirements in terms of time align how much time aligned detail we need and how much detail in terms of people . i don i don't know how much ti i don't think we do need any time aligned detail . we just have one text file which runs from beginning to end . but .  but not if it costs more .  right .  right , the it 's it 's a little in some sense it 's a little bit easier with it with switchboard ",,
Bmr002.C,"because the telephone is actually people are less flexible in what they do . in this situation where we 've got nonverbal channels then there 's a lot of overlap and there 's just that it 's not a very good model . every utterance is a single speaker , right ? it 's just that utterances can overlap .   mean , when i 'm when like , eric made a s made a sentence , and that should be like one utterance and then i had a couple of backchannels in there and they should be just overlapping things that i don't think that we should break eric 's sentences for those . we 'll have to go in from somewhere but we can't necessarily we may be able to get the transcriber to give them to us if we give them software but we may not in which case we 'll have to get them some other way , like with forced alignment later , all this can be done .  phoneme transcriptions .  there 's a there are there 's a whole bunch of tools . there 's a some web page , where they have a list of like ten of them no , no . there 's some there are a lot of @ @ these things . eagles . that 's the european one .      right . you don't just take the thing with you . i don't will happen , but you may as  my my s be just   that 's true . you can leave it behind as if you want . i assume that these are projects where they do the whole thing , right ? they probably will have tools to address the actual the transcriber support and then automated alignment of what the transcribers give you , which is , exactly the problem we have . right . right . but then again we don't have to do it . and we are . we 've got individual microphones .    yes , although that might @ @ presumably we 'll have one we 'll have several formats that you can interconvert between . when we want to do recognition we 'll do stm , but if we 're rather than designing our own format , we 'll just take whatever comes out of the tools that we can find to use , i i 've got no idea what that 'll look like . but on our speaker phones . right .     good . right . good . it must be fundable then .   alembic ? no .  i don't think    because the transcriber 's put in intonational tags ? or not .     who 's it from ? right . is it the french one ? u penn . that i 've heard of this one . it was the one that steve renals mentioned .  can i see ? we are going to do time alignment . but we 'll probably do it ourselves , right ? ",,
Bmr002.C,"we 're not concerned about getting about buying and or bringing in tools . we 're not very good but we 're proud of ourselves . we 're very proud of our time alignment . right . it 's not a bad look ! it uses snack !  it uses snack . that 's a tcl audio thing that i had some involvement with .  if i have to use it i 'm it 's a tcl based thing . i 'm it 's just wonderful . yes , t "" transcriber was developed with the scripting language tcl tk and c extensions . it relies on the snack sound extension , which allows support for most common audio formats . ""  it 's the french one . no , i but i 've never downloaded it . someone mentioned it to me . and that 's probably why they mentioned it to me , because they thought i would be excited because it 's tcl based . deliverable d three point one "" ,  transcriber   that 's a fine question .  this thing , this deliverable d three point one of the mate project is a review of a lot of different tools . they 're actually , they seem to be more the tool the main focus of the tools is you 've already got a transcription but you 're trying to tag the different turns transi transcriptions with discourse roles and things like that . but lot them are tools that will also do transcription as and i could be wrong . right . i the did , i combined pairs of these into stereo pairs , listened to them in stereo . and i was very impressed by how you could hear separate speakers , but i haven't done very extensive tests . you get a certain amount of spatial information . it 's not consistent but it 's gives you some noise  you 'd get wide coverage . right . right . but but you would you 'd get good pick up at both ends of the table .  what is the goal ? again ? we 're going to end up with some ultimately , we 're going to end up with transcriptions of these meetings . what , and then we 'll be done ,   there are different kinds of recos we 're going to actually train a recognizer based on these far field mikes cuz what we that 's the problem we 're trying to solve .  we need a lot of and also the near field will allow us to do the time alignment accurately .    close mikes .  i feel like that what we 're actually going to do with these data is very unclear to me because i don't think that 's a that 's not going to work . right ? we 're going to get horrible performance on that .   we know the answer to that , but unfortunately , will we get fifty percent p accuracy ?  ",,
Bmr002.C,"and are they specifically far field mikes ?   that would be tremendously useful information assuming that we actually pursue it , but we 've got a huge problem , because if we ge if we want train a recognizer we need tens of hours of labelled data . and it 's just it 's very frightening .  who , eric ? outrageous ! laying out his folders .    lea ? i see .  if you think it won't slow you down  that 's great . no , presumably there 's a an annotation standard for prefix characters like that . that 's what they 're using here .  exactly . exactly . exactly .  what is the plan ? we 're gonna how many how many meetings ? what about r our recording schedule ? how many meetings are we going to record ?  which ones are we going to transcribe ?  do we     five .    if we can do anything with it , i don't feel like you 're speaking unnaturally quietly . feel like it 's all quite normal .  eric 's really got it easy cuz he 's got the lapel mike , which is unobtrusive . they 're much more expensive . i which i don't understand but there it is . right , it 's because they make people feel like television stars . you can charge more for it . that 's it . that must be it .   i don't mind . we should read some more numbers , then . are we are we there ? are we at that point ? more space than you can we 've got two hours of space now .  in theory . assuming it 's recording anything .   ",,
Bmr002.D," write down that poem . let us know when you 're done , though cuz we want to start the meeting . now , how do you do the mike ? i keep getting it in my nose .  this is good . i like this . i like this . i like this , this is much more comfortable . i could have it more at the midline . boy ! it 's very adjustable now . i 'm on number four . may i pass the folder to dan ?  i 'm mike i 'm on mike four . and it 's a very microphone , very modern . i like it very much . you didn't get the s head restraint with your system ? i did modify my mike distance from my speaking apparatus . slightly . that 's a good way . should i draw a map ?  he 's labelling right now . now .  we have what ? what do we have ? done . done . you 're probably wondering why i brought you all here today .  good . shall i n i 'd like to hear one i 'd like to hear one more . could i hear you next ?  they 're like sentences but with n numbers instead of words .  i 'm on number four with the microphone around my neck and i will read these .  it really sounds like sentences . your intonation sounds like somewhat like sentence intonation .     if i were to be dictating a phone number , i would have done that more slowly , but which would have been easier for the for the machine . but . was that an pace ?  just as long as it 's with within the constraints . number four .  and the voice . just no way . yes . you did .  because my name was mentioned when i wasn't around , but i 'm most happy . he did . and i approved . but that i was proposed before i was asked ? and that doesn't matter cuz there was probably an a an indication that i was interested in advance and , in which case , i  i 'm going to provide i 'm going to be once i 'm given the data , i will provide w word level transcripts with indication of speakers , and speaker change in any case , speaker id , and words .   i 've transcribed a lot . but the there are always ways of doing things more efficiently or more in a more technical technically sophisticated way ? do you have to speak true english sentences when you do this ? "" she can't speak ! "" "" it 's terrible ! ""   "" no one told me that . "" "" this microphone , what 's this doing around my neck ? "" ",,
Bmr002.D,"typically , what i w in what i 've done before is i have a tape recorder , with a reverse button . and you just , if it 's word level e you do a e a r hit the r re the rewind button every couple of words and type what i know and then at the end do a breeze through to be that everything 's correct . however , they do have software these days which with a digitized record you can have control over replay through some an interface . i 've never used one of those . i know it would be an a wonderful idea . it 's just i haven't transcribed in awhile .  foot pedals ? i 've used transcribing machines . that 's fine . but i frankly didn't find it any more use to me than my hand held taperecorder . however , if we have a transcribing machine i would accept it . the other thing is , having getting hold of a transcriber . that cogsci has one . and i could probably borrow one . you have one yourself ? i see ! super ! i see .   i kn that 'd be super . this is great . this sounds wonderful . i 'm open to that 's true .  now , we 're at a pilot phase right now , and what i was told is that beginning , that the pilot data would be something like half hour of or f half hour to forty minutes of running text . and for the pilot thing , this would be useful . and i w i wou i 'm assu i 'm assuming that i would not be transcribing all of it .  no . no , no . yes . now i 've been involved with some of that . at cogsci , susan e susan ervin tripp , who would typically , and i 've done this too , supervise undergrads to do this thing and they c you can give them like if you give them a little bit of instruction and make it interesting for them they can do it as a two ninety eight or s or , not two ninety eight , what is it , one whatever , undergraduate research credit . because what you do is , you can build it into some you have to be you give them compensation for of some sort . what is it 's not necessarily monetary . but if they feel like they 're getting something out of it , sometimes you can do it that way . and otherwise , as part of a grant , you can do it . some minimal wage .    you also want to get quality . someone 's going to have to pass through either a higher level person will have to pass through , or you have to be you get good quality to begin with . ",,
Bmr002.D,"but that 's quite we 've that 's been done . ask susan ervin tripp what she would recommend on that . she 's really she 's done of the people that i know , she 's the one who 's supervised the most of those things locally . doctor susan ervin tripp . faculty member in psychology , recently retired , and very known in discourse analysis . it 's very common .  there 's always this question of the trade off between paying more for the first pass , and then h and then editing less later . or paying less the first pass and editing more later .  but that 's a s    i should 've yes . are you speaking about mississippi state per se ? or are y  actually , i wanted to mention there are two projects , which are international , huge projects focused on this thing , actually . one of them 's mate , one of them 's eagles . and and both of them have i saw i know about the big book . you got it as a prize got a surprise . and and they have a lot of and mate is a project which is being run out of denmark and they have a lot big e they 're trying to set up a work bench or other . and they have a whole bunch of tools that are associated with them . there are things that in terms of like the time alignment issue you guys are more expert on that , than i am , but i want to say that i know for a fact , i keep running across these , and those would be my first two choices of looking at . eagles and mate . and i have the documentation downstairs . i didn't think to bring it . i have , but i wasn't interested in that particular issue . we 're talking now , once you have words how do you time align it . and that 's . these are tools mate and eagles are both within the called language engineering branch , and they 're intended for this comp compu s computer science application type of approach . these are not discourse types of tools . they can i be excused , and i 'll go down and get my because do think are you serious ? i but what mean , can you spare like a minute or two of a  and i go get my books and i 'll be right back . i didn't think of bringing this . do i need this ? i need my keys .   i need my card key . i 'll try not to say , "" dear , boy ! that 's itching there ! ""    "" specification of coding workbench "" , that 's one o thing , and then , back in here "" kcm file formats "" , this is the it is european . ",,
Bmr002.D,"both of these are eur european , but they have american contributions , and  but you see they have a whole bunch of things . what they 're doing is trying to bring together and they rate things . i wasn't focused on that didn't let me show y have you seen this one , dan ? and i 'll try to get one for you , too . you 've got one . what are you looking at here ? he 's got the mark up framework .  different coding schemes .  what they 're doing is they 're comp comparing all these existing things that have been submitted and it includes , this one includes the tei and it 's pretty broad based . these things do seem to be that 's the text encoding initiative . that 's a way of marking mark up . but focus on tools to do this i do have a file also in addition to those things , but it 'll take me just a second here  if you start with a basic transcription and a good filter . you can that 's my feeling about it , that you should be able to translate between an xml and non xml version cuz most at least , with a focus on discourse , mostly . i wanted to this approach here this is uli heid from stuttgart is query language for research in phonetics where he wants to build in tobi tags and you can determine wanted to mention this to you . i was going to come by and ask you about this . do about the stuttgart people ? because he 's saying if you represent he says that in german "" selbst "" is used in two different ways you have it either means himself "" or it means "" even "" and you can tell the difference in terms of intonation . they have the recordings such that they can locate things with by searching for part of speech and also intonational tags . anyway , that 's that . this is true . this is true . which is another issue . exactly and then i have one more thing i need to find . and then i 'll be  yes .    i w i  that 's what morgan mentioned to me , too . if in terms of the t the type but you asked me about tools and things and there 's this one this is called "" transcriber "" . binary distribution for linux and solaris and sgi and windows "" . "" transcriber is a tool for assisting creation of speech corpora . "" "" it allows to manually segment , label and transcribe speech signals "" and , let 's see , where did i get this ? i got this from u penn . but it is possible . it could be french . i can't really tell . i 've never used any of them . ",,
Bmr002.D,"and think it would be something that we should work together with , in terms of seeing how this here 's another thing i got .   good idea . great idea . excellent idea . "" automatic annotation of prosody in verbmobil . "" this is the other think that this is part of eagles , but but here again , it 's focusing on representation rather than the tools to do this . why do i feel like i 'm whispering ?  that would be lovely . now , are we talking about the stage of simply the word stage ? or are you talking about tools that would allow the time alignment as      good . good , fine .  very       there . there you go . i love it when they c did you see this one ? the , did you see this one here ?  whoa !  i i roam around on topics like this and got this off the u penn and it does cite a french site , they have some an arrangement . good . you can access it through through the , whatever i can't remember which aspect of u penn i was following , but it must have been the ldc . i bet you anything .   yes . there 's they have a special project , as i 'm remembering , and usually it doesn't deal with much that has to do with discourse , but they they show up in resources . i like that very much , and i like the idea of also doing one that 's tied in with these larger corp corpus projects . that , the fact that , it 's u penn and all that .  good idea . it 's like the pda thing . like "" did the french system use tcl ? "" if anyone wants to know . but you could get it through the u penn yes ! there you go . exactly . my impression i really thought of these resources in the context of you asking about time aligning the what would you need to indicate and were there tools for that because suspect that would be pretty time intensive . i also wanted to say , in terms of like disc if there are discussions about intonation contours i do have a certain amount of background in that and i really would be i 'd like to be involved in that .  not right now , but in the future . at this meeting with liz i i do i 'd like to i like that these are near field ? there  if we were to add in addition , and i 'm offering this , to the word level , also the stressed words , within utterances i do think that would help the information retrieval .  good point . do you think are you familiar with this the mars the marsec project ? i 'll put this over here , ",,
Bmr002.D,"cuz he seems to be the chairman .  he 's not ?   he  he can y discuss among yourselves . this is a project that has time aligned spoken data which is see it as in between these fields because a lot of the time when people do rich intonational and stress oriented transcription they don't have the digital record at the same time and the don't have it time aligned . i don't know how large this is , actually . but was thinking that 'm and it 's british and       i 'm d   one thing about that is that in the process of doing the word level ? it really is just as easy to put the stress in at that point . simply the stressed  see in my pilot in the half hour or that i 'm doing . i 'd just as soon put it in , because i do think that you 'd find that those would be words rosaria 's pursuing this area but i really do think from everything that i 've run across that you should get gain in terms of the what you were saying , the information retrieval aspects from that . and i wouldn't be too surprised it 's like don't know how reliable lea is , but if this idea of islands of for di whatever they are . r islands of reliability or whatever it is . the stressed w stressed words . is that it ?   the claim that words that get stressed are easier to recognize . it c there 's be benefit with very minimal input . cuz when you listen to a sentence , you can tell if it 's contrastive stress you say "" that word was stressed "" and why the heck not put it in at the word level ? the part that i 'm doing , i 'm really happy to supply that without any cuz it 's just it 's there . it 's not it doesn't take any thinking . i 'm not going to talk about , trying grade them in any careful way , but just indicate if th if there 's a prominent word , to indicate it . whatever . whatever . people people do different ways , a and just as long as it 's systematic in my view , you can always filter it into some other format . how many of these do you have , these near mikes ?    i see .  i see . interesting . very interesting .  i 'm just really impressed by this ,  this is , compared to the way people normally do discourse it 's like you got your they 've gotten away from w reel to reel tapes , but and they do have dat recorders , you do have but this is just wonderful , the added level of compactness in the channels . i do find myself whispering . i suspect my normal s . i don't know why . ",,
Bmr002.D,"it 's bizarre . this is not really my normal pattern . the problem is that i 'm afraid that i 'm talking into someone 's ear . i really do . it 's like and i realize now that you have volume control . but  good .  good . i 'm glad . good . that 's great . are these more expensive or less expensive than this kind ?  it would be like the television . effect that 's probably why he was the chairman . good . good . good . here , here ! this is jane .  alrighty . ",,
Bmr008.A,"i do it my head 's too big , also . it 's too ba that 's true . course that 's true of a lapel as can you just write something like "" position "" ? and people can fill in their own "" post doc "" or "" visitor "" or whatever .  can you repeat the categories you had ? they 're fine . that , that 's fine except the one thing is there are a lot of icsi v like i don't would be here , just i 'm not a professor i 'm not a anything that , like a visitor r icsi visitor or , icsi y visiting s researcher or whatever . if we can put something that then what you have is great . for that purpose and or just you could say what 's a phd ? like , if you have a phd and you 're hanging around here , and you 're not a professor and you 're not a post doc , then that 's like what we are there 's a bunch of people like that . right . right . right .  you can say post phd researcher or what if there 's one more category that 's general like that . you you could keep professor , but you could say post phd researcher no , instead of post doc or post phd , just wrap all the people that are post phd and non professors together . professors probably want it i don't care .  the post phd one is the one that can be , like post doc or post phd researcher or whatever .  then it 'd be fine . it 's fine .  why is that optional ? i don't know . it would be very good to get age for a lot of purposes . lot of corpora we ca we have these age ranges like no , not every most corpora have that , information . that 's age or approximate age . somebody can say "" thirties "" if they 're thirty nine . those who don't give it we will be estimating your age for you you 'll prefer to people can leave it blank if they people in speech are gonna wanna they can always lie . in some sense you could say that "" leave blank but don't lie . "" right . they might leave it blank if they didn't care about their age being known but it says "" optional "" they might not . anyway , it 's fine i don't know .  it 's as long as we put it high enough up that it doesn't get lost in the optional , if there are a lot of other optional things on the form . that 's the only optional thing ,  what does region mean and like if i see this form i wouldn't be quite what by region . ",,
Bmr008.A,"do you want to have give choices and have them circle one , or ,  but not for the others , because there aren't going to be enough people to really group them and when you talk about dialects in england , that 's really every block of london has a different  my fair lady 's i there are huge differences in the others it might be better to just do it for the you could leave region for the others but have circled choice for the american english . right . actually that is true for them but it means that you 're gonna get a bunch of different level levels of resolution in your survey , it 'll be more of a pain later ,  it depends . that 's good but if you have it free form first of all some people take you and some people would give you more specific information than others and that 's a waste because you can only use the least common denominator of specificity and generally . i don't know later on , if somebody just says midwest , now all these other people who said area then that 'll have to become your category . and it 's harder later on , i it 's easier for the person but it 's harder for the r it actually less informative for us because you can't enforce any minimum level of specificity . it 's or their parents live  and their parents if we release this corpus , what do we want , if you do this free form the free form solution where some questions are very open ended then you need someone needs to enter that , and they 'll be notes and it will be very difficult for somebody later actually use that without mapping it . it 's but it 's   what you really want , is if there 's some information you wanna know we want some rough idea of their dialect , then we should have some question where it 's not free form , except for these people who are who have non american english accents . there we probably have to have a category "" non american english "" and then a few choices . and we should have something that 's simple , that people can circle , like these timit regions that we have something that minimally you can cuz a lot of times if you give the data out that 's what people are gonna use . they 're gonna want some small set of places , and then , but anything additional people can fill out , and we can put it in as a note but if we don't have that , someone 's gotta sit there and figure out i 've got twenty people who said midwest , and i 've got a few people who said something else and these don't overlap or these  as long as you have ",,
Bmr008.A,"in the home , the influence of the home is much lower age than that , once you go beyond the age five or six then it 's the school influence as and  in the home it 's your phonetic first level , it 's it starts to get complicated . right . right .  most of but most of those people don't rely on the self evaluations , anyway . they 'll probably listen to the speech ,  but even in switchboard , i remember looking really carefully at they have information like timit i don't know it 's how they categorized , but they had north atlantic , mid atlantic , and texas was definitely out on most of the people from cer certain places in the south were from specific texas locations , but other than that you had a huge range of people would say boston , and they had nothing like what i would call a boston accent . it was no , the question was really geared towards trying to get people 's self evaluation of their dialect region . and minnesota midwest is different than michigan midwest which is these were all settled by very different type people , it 's general help but that anyone who 's doing phonetics wouldn't rely on that , they would probably use it as a first pass we do need to make about the f the non native accents because those are , but we don't need to ha be really specific about the others , because it won't be very w helpful anyway . we should , because other databases do . it 's political thing . and there are some general like , you will find more new yorkers in the new york category . but it 's not right . but other is there , and people will fill that out . they 'll see by example . that 's that 's fine , they 'll say i 'm not one of these , i 'm canadian , or right . even like cal la is different than you really can't we could ask them for more information , but i don't think it 's necessary and it 's not going to solve this problem .  the question on regions is really to ask people how did they define their dialect region now , di the whether they picked it up at the one age or another . most people will know whether they have a southern accent or not . but they may have lived in other places , too . if we ask the question about dialect regions , it makes no sense to say where do you live now . right ? you ask how would you best define your accent or your dialect style .  or you could say to somebody , how do you define your the accent that you have . and then you can ask these other questions as ",,
Bmr008.A,"but what we don't want them to think is that they 're living in a certain place and that therefore they 're nowadays hardly anybody from california has a native californian accent ,   as long as it 's clear .       sounds good .  sounds good . it gets into a can of worms . the more you ask , the more you realize that you 're not getting great answers to what you 're asking and  what about proficiency in english ? as i you don't want to do it for political reasons , 'm no i wasn't thinking about that , i was just thinking , "" gee , i 'd like to know actually ""   that 's we shouldn't ask it , i don't know . what about something like "" how comfortable are you in a meeting conducted in english ? "" , or "" how easy is it for you ? "" , like that where it 's that 's a good one . something wha what do you think , what 's it  how  how long have you been in an english speaking country .  how about their birthday ? i don't know . not the year not the year not the year but just their birthday . i don't know , what are the chances of people having the same name . they thi isn't this an open ended , like notes column ? you can imagine wanting you should be able always to attach some notes to is this the place where we would do that , or is there another place . that starts to there 's definitely some clear cases , but there are a lot of gray areas , where the context happens just in that meeting , or , where you don't wanna have to make a distinction between a pre existing relationship , or but there are some that generalize over many meetings and there are some that don't , and there are some things that happen in between meetings , and this one needs to be open ended , completely open ended , and the only concern i would have is if there 's something we wanna be able to say and we can't put it in that field . like is there a way that we can add keywords or sub i don't you would call them , but little labels for things that we decide are useful things to have but as long as we have this one place where it can all be stored , then we 're fine , and those 'll probably occur to us , we 'll think of a few of them , some other researcher will think of some different keyword . y it 's it 's gonna change it 's gonna change , and we wanna regroup things under different labels later , if we figure out that these pairwise things are ",,
Bmr008.A,"but are we assuming that you could know the energy for a speaker when there 's no overlap ? can imagine a model where you say , 'm gonna give myself it 's cheating , but not completely if they 're often not overlapping and normalized for the speaker or is that not allowed . what 's the right right right , right . right . that 's what makes it seem difficult , because you 're already left with a high standard deviation and they 're already roughly that each person 's hearable , right ? equally loud , perceptually anyway . like two hundred milliseconds or twenty to twenty five frames , or or voiced regions , can we tell ? can we mean , is it known whether something 's voiced here , or is it roughly estimate estimateable ? like if one speaker 's voicing and the other one isn't and they 're overlapping , do we know that the first speaker 's voicing , or not ?  but will we be able t to detect the voicing when there 's overlap ? that 's what wondered .  if we could , or if you could do some of it ,  then voiced regions would be probably more informative , for energy because and pi and pitch for that matter . it 's the fifth page , it has to tell you . it has to give you at least a zero , one , binary  you can also look at just the voiced regions later . that would be the most sensitive measure . because if you 're normalizing for voiced , and then you look at regions that are voiced with the same robustness in estimation of what voicing is , you should be much more sensitive to the overlaps then if you if you normalize but you look everywhere at fricatives you won't really know anything . mean assuming if it 's true that the overlap regions are long enough that there 's some voicing in each of them , by each of the speakers , then you should do very if you do this . but you 'll only know that in the re voiced regions but those are close enough to the there 's enough voicing going on and off that if you can capture the voicing and if you can capture it when there 's overlap then you should do quite there . also the harmonics would be very important . if you can find voiced regions and if you have two speakers and they 're both voicing unless they have very similar , pitch , you should be able to see the difference in harmonics pretty clearly just by counting them ,  even if you 're not exactly when the overlap starts and ends because there 's some non voiced regions , at least you can have these islands of reliability where you 're pretty right , and you could put an estimate , a fuzzy start and end time . ",,
Bmr008.A,"it 's good , though , if you 're for your accuracy . gives you a little more time to try to detect them . something somethin something like that too . ",,
Bmr008.B," let 's let 's discuss agenda items . what did we have ? you were announce some things forms is one thing there 's status on the transcription discussion which will take us about thirty seconds and then jose as usual the one among us who 's actually doing a bunch of things on this he has this and we can have some i was just glancing through it , think we have something to discuss about . and we just sent in that nsf pre proposal but i don't think there 's much to say about that except we 've sent it in and we 'll see what happens anybody ? anything ? anything else going on ? no .  why don't we do it in that order ? go ahead . how fine a resolution do you need on that for this ? not much . p prone .  no , no . less . do you think there 's i don't really know . were you thinking , that it would be useful for some research later to know say , you said undergrad undergrad versus grad , do you think that 's important ?   i see . i dtd ?   see   right . how about how about post phd researcher right ?  for me there 's a there are people this got very tricky when we got involved with the spanish program actually because when we said , in our original forms , "" post doc "" what we were used to , from the german program and from the us standard , when you say "" post doc "" it meant somebody who had just gotten a phd who was doing one year someplace . but when we did the spanish call , many people said "" want to be have a post doc slot "" and they were twenty years out because they were "" post "" their "" doc ""  that it might be hard to do a finer thing than that because whether somebody is going to be dominant in a meeting is really it 's going to be clouded by everything else someone who 's just gotten their phd could be very strongly opinionated about something and somebody who 's been twenty years out could be shy , s what 's "" other "" ? you want professor to be in a separate category , you think think we i 'm te i 'm tending to push toward simpler even though i know that more detailed means more potential information for someone later who 's doing research in this area i the thing making me lean toward simpler where possible is that the more a thing many of the meetings that we record may be the kind where we just record somebody once even though we want to get a lot of data that has many meetings with the same people . ",,
Bmr008.B,"and the more forms we have and the more lines in the forms that 's th the more overhead for that one time thing makes it harder to do . right . that 's what we 've done far . right . and 'm saying i expect us to do both kinds . yes . 'm saying there are going to be what i imagine once we 've collected a lot of data , a chunk of it will be the same people many times and another chunk of it will be people random meetings that we got with from different people and it 's use we 've talked about this before , it 's useful to have both kinds of data .   minute , it 's not illegal or anything right , it 's not pushing on anything unethical or illegal , whatever , to ask for their age , right ?  i suggest you ask for their age and if they say i don't want to give it say i see . o opt age is optional but those who don't give it will be given the uncomfortable microphones ? the mean of the estimates from the group will be used they might lie anyway . i don't know . the peop the people i 've known who 've lied about it would just lie about it .  hey , jack benny was thirty nine for forty years . kinder and gentler . i don't think it matters . i don't think it matters . if it makes you more comfortable , put optional i don't think it 's then i don't think it 's important but i also don't think it 's an important point the other way and i don't want to make you do it some different way than you want to do it .  now what was this thing that who was telling was it steve ? somebody was telling us about asking about  i i 'm you 're saying just missed something , though . are you saying that you have both ? that you 're saying , what is your      and henry higgins could say which block you were from . right ? that 's what what about just doing the the steve suggestion , as an add on to it , right ? rather than saying region , just say "" where did you live between the ages of here and here ? "" just and then they could s right they could say it different ways . they could say cincinnati or they could say midwest or somebody 's gonna have to do some data but that but the good thing about it is it frees you from coming up with exactly what the right categories are . right ?  i see . but that if you 're going to have it be general the idea again was , you might wanna also know if they grew up in germany or if they grew up ",,
Bmr008.B,"and think you wanna the idea the motivation for this being suggested before was that it did cover a range of these cases that might if you say your native language was english but you grew up in germany , think this and the question is how extensive this gets . but what about the phrasing that chuck used , which was in relation to the question i was trying to formulate of where did you what what was that what w how did you phrase it ? "" what language was spok "" , it 's not where did you grow up , but what language was spoken in the home between the ages of , what would it be , five and twelve like that ? cuz he does make a good point about the region not necessarily again , if you 're on the army base or  for now , right it 's again , we are hoping to expand this out ,  and somebody might . right .  internally , we have texas and other .  are you suggesting that you put something in about childhood in there . you could distinguish between pre five and five t five to twelve , right ? depending on what someone 's interest was in the formation of the phonetic kinds of categories or whether you 're talking more about their linguistic speech patterns ,   but , again , it depends how fine we wanna get , but we could say where did you live before you were five ? "" , "" where did you live after you were five ? "" , i don't know .  right . right .  why don't we try it out . and see what responses we get from people . anyway . d i  i i wasn't thinking no , no . i wasn't thinking political i was just saying , looking at applications of people over the years for post docs here . they 're r generally not very good at assessing their own abilities . but that could be . that could be . yes . good , bad . how b how about "" how long have you been in an english speaking country ? ""  really ?  yes . we done ?  there 's another form . no , you got what 's the other form ? in case people what ?  the other thing is that potentially if this is done over a period of time , someone 's email could change . that 's bad .  i see . then , you don't hafta ask the age .  social security number . i was missing something but this is something one would try to infer , but how do how would you freeze that information about what , we already have these things about someone 's a professor and someone 's a student , but would you some person would be writing this person was leading the meeting and that was or is that what or what ",,
Bmr008.B,"you 're just putting preexisting relationships that are i see .  i m right , but that example was not  for today , this is the second meeting recorded today . the first meeting was a front end meeting , and in that one , the basic form of that was i was the leader , and i was saying "" what are the results you 've gotten in the last week ? "" and they were and one person was taking the lead , in describing what the results were , and then chuck was taking the role of saying , "" what did by that ? "" , he was like the out s semi outsider , asking curiosity questions . and then it would come back to me with saying "" you showed me that but you should do this in the future , "" it was very much leader "" and and "" led "" relationship . and the guy i was primarily doing this with is a visiting researcher , in this l meeting , you are my graduate student , but it 's not taking that role right ? you 're you 're actually leading the meeting for the most part , most of this meeting , it 's whatever . don't know , you 're suggesting right , cuz it seems like it 's exactly . it 's research question , you 're analyzing the meeting and you 're deciding , "" there 's this structure to it . ""  it sounds like having the facility is great , and then over a period of time as the research happens on this we might develop some of these categories that would be generally useful and it sounds like a good thing to do . almost all of the meetings that we have are recorded with roughly this group and and a fair minority with the group that we have in the morning , this is not a lot of people . we could easily there 's just a couple other meetings that  we 're running late , we 'll probably wanna zip through some other things , do some more time on jose 's later , status of transcription , we recently woke up our friends and guess you 've sent off this the cd roms and you got some response from ibm about  was there some suggestion that they might soon , or  mccoond  great , that was that one .  and we should just look at this thing from you , off line jose cuz it 's getting late but the bottom line just glancing through it is that there 's a lot of overlap , in just energy related things and you need something else . that 's right ? and what the 'd the residual error ? this is post bug fix . good , had two thought just glancing through this . one is that that we might wanna talk about normalization . i don't normalizations you use . ",,
Bmr008.B,"sometimes things have more overlap before you 've done some normalization and we might think about what different kinds of normalizations are possible . and the other thing is that , if that isn't @ @ much of the issue , then probably residual lpc energy and just plain energy are very closely related , even though they 're different and you really may need to go to something that looks at i in some sense harmonicity , or relationship to or fit to pitch tracks on on either side of it , if there 's really bad fit between where the pitch is going in this suppose hypothesized region of overlap , and the and one or the other side , then this might suggest a excuse me ? i if you have two if you have two people speaking and there 's an overlap , then the first thing is that there should be a mixture of harmonics during overlapped voice sections anyway . and the any a measure that you have of how much of the energy is due to your best guess at a particular harmonic sequence , it 's also going to be a smaller fraction . this is , related to the harmonicity thing . and then the other thing i 'm saying is that if you look at the temporal evolution of the pitch there should be something like a discontinuity there . now , there 's other places where you 'll have discontinuities in pitch and speech , but it 'll have something to have a different character . but it seems like energy tells you something , but if unless this is a normalization problem , it looks from your results like there 's much overlap that certainly you need something that isn't energy like , in addition to it , at least . the question is would some normalization help . i it could be that if you normalized by the overall energy for some longer period of time that there would be more of a distinction . i don't know . which is the intuition , un unfortunately there 's a standard deviation of like ten , for each one ,  that 's what i was suggesting , that y you wanna do some longer time normalization with the even if you make a mistake occasionally , that i is roughly i is there some corresponding to that speaker , that if you , if if you because that 's gonna spread out these distributions really a lot , to not do any normalization , and that could mask the effect somewhat . that 's why it doesn't add up down i have another thought . this is frame energy , frame frames have a lot of variance to them because different sounds are different loudnesses . mean , what if you took one second chunks like that . or not even a second , quarter of a second that you would typically have two or three syllable length  right . ",,
Bmr008.B,"then you 'll something ,  mean , two hundred , three hundred four hundred mill some longer chunk of time , and then you looked at the amount of energy in that . and how does that vary over these different cases . or voiced regions . you could do a you could first determine that something was voiced or not . the overlaps are typically more than just a tiny little bit of time and there could be voiced and non voiced pieces during the overlap . i don't know , because it 's this has to do with these questions of harmonicity , and forth , right ?  right , you could do something like , but  but what will be easy for him to do would be to do this thing of looking over a large enough region of time . cuz if you look over a large enough region of time , most of the time you 'll have some voiced a fair amount of voiced energy in it . and think that would be is it ? what ? are you using a pitch detector in this yet , in your experiments ? do you have a pitch detector that you 're using ? do you have a pitch detector that you are using in these experiments ?  does it have a voiced , unvoiced detector in it ,  it doesn't . it just finds the pi it just finds the pitch even when it 's unvoiced ? it must have some it has to tell you something , right ?   right . ordinarily in these things , it does tell you that it 's voiced with a pitch of such and such . and it will i it will say something like zero or it 'll have something that it says when it 's when it can't find a good period , right ? it 's looking for some periodic behavior , and if it can't find a period it tells you for most things like that . mean , this is , getting back to what liz was suggesting which actually is good , the more of it , that for normalization you could do something like take voiced sections and normalize to equalize the energy in that . i 'm just still going back to normalization , that even though it 's roughly normalized , for overall gain , it 's it may not be normalized enough . for both ,    think @ @ this is something to experimentally determine , but if as i understand it , you have some regions that are marked , as you have training data that you 're trying to find a threshold , right ? and if you take all the things all the speak things marked "" spk "" , and look for the voiced energy in them , and just in each case , take a take a frame , take the  if it 's voiced , include it , ",,
Bmr008.B,"just separate out from the normal things , separate out voiced . right ? then you 're gonna end up with mean standard devia deviation , and forth . and then do your normalization based on that . and once you do that just for voiced ,  you 'd  right . right . right . w  you could do that ,  be i and if they still overlapped , i the but that this is a good first thing , to just see . and what this says is that th that without any special normalization at least , this is there 's a lot of overlap here . and mean coming back to jose 's question , there 's still this issue of how much time  what do you look at in order to normalize ? dur you get some data in , you don't know which it is , how do you w what period of time do you look over to normalize it by ? and that 's something to think about and experiment with . yes . right , that 's what we were talking about before with harmo with harmonicity measure .     good .  and i i don't know . i wanna think about it and you should think about it . i didn't want to just pop out an answer because i realized i hadn't thought about it enough . i 'm not what he 's saying is that the typecasting could be the issue , for f seek . cuz in in general f seek works , it 's    anyway , anyway , we 're missing snacks here , let 's let 's do our let 's do our digits and  ",,
Bmr008.C,"   is the question .     dtd .     it 's possible .       right .           is not it 's not necessary to put optional "" . people decide in that moment . because if you put "" optional , "" you give                   is better . it 's better .     not the year . the pin !  and and  interesting . role ,           i found the error , and i repeated the experiments and here , you can find the new results with       another side . an alteration in th in the tracking way . that you ehm i understand that to study the alteration between the tracking of the pitch if we compare the overlapping zone with a speaker zone . in the co in the context .        i don't normalicized in these er experiments . by the moment . i don't normalicize .  nnn .  the different zone .         the product of the deviation is the vari is the variance .    but   no . it 's a pu pure overlapping zone . that overlapping between two , three , four speaker . th   because they 're    say this graphic ?  i use the mixed signal without normalization , but  i don't study the single channel yet but is an idea . to begin to work with the with the one single channel . now .           here in the it 's a new diapositive with information about the context for overlapping zone .  how define ? i j my ? i 'm working now with pitch detector . i 'm working now , but haven't results yet . but at this moment i prepare , i am preparing the pitch tracking . pitch tracker algorithm that i have but no . i  it 's based on correlation between frame the utterance but don't is ehm because it 's no my algorithm . is    for most @ @ .  for b for both , for the frame energy and residular lpc energy too . for both . but test different normalization i what normalization ? i this is                       but this is very short .   is a problem to detect . but it 's a problem to identify and to detect , too , with the javier system ,  it 's a problem .  what  what happened with the different contexts because you are talking about the period or the duration of the window to the long of the window to consider normalization no ? but we have different contexts . the period the length of the window to normalize the energy is in the context of the overlapping zone ? is in the left context as in th in the right context , considering the these frames ?    because the problem is that we have different contexts . different situation , and  what the bu the bug . the bug of was the f seek function in c . ",,
Bmr008.C,"because doesn't work when you you try to ass n to do an a dated access to a file , a big file , moving the head of the in the hard disk , forward and backward a lot of time in a moment f seek function doesn't work . and i had an problem . yes , this is it 's incredible . i do the same in another way and i haven't problem . i don't know , but think the position in the file doesn't work in long file , a very long file . the typecast .  it 's ehm no , it 's unsigned . signed . i don't know i don't know but solved the problem with similar way and i haven't problem but don't know because it doesn't happen to me before . but have the same codes in different parts , and had to change all the points in the code , to substitute for another way , but is    ",,
Bmr008.D,"or , i like it , also , like this . you see the  i should have brought more i have a couple things about speaker form about forms in general .   i probably should have printed out more of these . one of the things that i 've been doing with the digits forms is i 've been adding more and more speaker specific information to them and it 's getting pretty crowded and you have to fill it out each time . what was , it would be to have a single speaker form that you fill out once . and then , on the digits form you just have to put your name down and you can look it up from the speaker form . i had a first pass of it , and i spoke with jane a bit about how to specify what language and education and that and have a first pass at it . and i was just wondering if people had any comments on information that should or shouldn't be on it . and i only did one copy which was really stupid of me . 'll just say what it 's on and then hand it around . the top of it is name , sex email or other contact information . and i put the contact information just in case we have people with the same name , that you can distinguish them , and then also just to have a separate contact from the consent form . and then , we talked a little bit about whether to do how we get at the background . and we could do profession , but it 's uniform that we figured what was more important was actually the education level . at least that would get at some idea of their background . have a and s and relevant to status . that what i have is have five things that you can circle , undergrad , grad , post doc , professor , and then other , with a colon and a place where you can fill in if there 's some other . think the problem with that is that there 's not a necessarily easy equivalent for our visitors , who are not used to the us education levels . and may need some help to translate what that means .  the problem with that is the same as the problem of profession . that it will be there will be a tendency all for everyone to put down "" speech researcher "" at that granularity . don't think there 's a problem asking the education level , i th at least i don't feel like there is . think the only question is whether the what categories should there be . less . right . one of the criteria i had for designing this form , is that i didn't want a separate instruction sheet . ",,
Bmr008.D,"and we 'll get to that in a moment when we talk about language also . is i did not want to have to , come down and quiz each person and have a social dynamics expert being the one who 's filling out the answers . i want it to be self evaluating . you can give it to them and they can understand what you 're asking .  that 's a separate question . we 'll get to that in a moment . and this particular form i know . this particular form is speaker is dependent only on the speaker , not on the meeting . you could imagine then having another form that you might want to do during a meeting to get out the relationships but then that 's interfering with the meeting . what i like about this information is you give it to them once , and they fill it out once , and then you have that information . not the fact that one person 's an undergrad and the other 's a full professor is interesting . the question is how much of this information can y  but you want to have that information . right ? if you don't have that information , how are you gonna do anything ? what would you suggest ? undergrad , grad , post doc , professor , other that 's right , was saying "" professor "" .  when i said "" professor "" , what i was thinking in my mind was more "" phd but not post doc "" . and or post doc change "" post doc "" to "" phd "" ? because phd and professor are d are distinct aren't they ? someone who has a phd . undergrad , grad , post phd and other ? other if i instead of instead of professor or instead of post doc ? as i said undergrad undergrad , grad , post phd , professor , other ? right . the whole reason that i 'm doing it this way is my experience far has been the exact reverse . that right . we could have another type of form for less frequent . think that if we 're planning to do that , then we should probably have another set of forms . a single form that 's the consent form and the speaker information form and not have them do digits . this is a topic i want to bring up after i get through this . that that 's another form that i want to discuss . with the digits forms . s can we get  that 's what i want to talk about in a i 'm i have that as a topic , also . let 's finish with the speaker form and then we 'll get over o get over to that one . education level , undergrad , grad , post phd , professor , other .  ",,
Bmr008.D,"and then i put "" optional "" with a big "" optional "" in parentheses , age . because lot of people are sensitive to it and won't want to write it down . don't want to make them feel like they have to . but if someone doesn't want to write it down i don't want them to say you can't record me that just having on the form saying optional , age , again means i don't have to be sitting here and explaining the form every time we do this . and having a little instruction sheet and say "" if you 're in this age range do this , and if you 're in this rage do that . ""  right .  that 's because no one here is sensitive about their age . but , i would rather let them leave it blank than lie . that 's why i want to put s "" optional , age "" , that if they don't want to put it , they leave it blank . but if you put "" optional "" , won't they just leave it blank rather than lie ?  you don't think they 'd just leave it blank if it says has a big "" optional "" right next to it ? it it 's better to put "" optional "" . that 's why i put it there , s but it seems like you disagree .  didn't mark anything else as specifically optional ,  and then the next are two sections one indented separately . one 's for native english speakers and one for non native english speakers . for the native english speaker it asks for a variety of english with three circle boxes american , british , indian and other , for write in . jane and i discussed this , and it was again the same problem that it 's gonna be a self evaluation anyway , and don't want to have to be standing over the person and asking them "" do that your native an l an language was british when you were born , and then it changed to american when you were two , and then it changed to "" and on . right . th there 's room on the form to put al a line of instruction , but i 'm just not what it re should really be . the for the non na for the native english speakers we have variety of english and region . and that 's it . and then we have another form later down which is list other language influences . right , neither would i . i don't think we can do that because it would be different for if you 're american english it would be region of the us . that that 's why i didn't have circle forms . because it would be different depending on what your language is .  it it would be however you would identify your own . ",,
Bmr008.D,"and , as i said i don't really see a way of doing a circle fill in , because there would be there would have to be one for american english , one for british english , one for one for each type . but that would mean i would have to do generate a different form for circles , if you 're american english or british english or indian english .  don't to do about the other varieties of english . that 's why i wanted to just leave it something that you could write it down . there could be a circle one . right ? you could say "" what region did you grow up in from these years ? "" and have a set of circ of six or seven circles  what language was spoken in the home ? depends of who you ask , what the age range is . this is why i th the way it 's phrased right now , it 's clearly asking about language . and what it 's trying to get at is what you think you speak . now , that taken that sometimes people are wrong about what they think they speak . but , other than having a trained linguist interview them and ask these very specific questions , i don't see a way around it . because as you said , what you 're gonna have to stay say is "" list the languages that your parents spoke when you were in home and how good they were at it and how long they spoke it , and now list the ones in preschool and now list the ones in first grade and now list the ones your friends speak "" right . want to try to keep the complexity someone can fill out this form at the beginning of a meeting without taking f forty five minutes . think that adding the timit categories is a good idea , because that 's very easy for a person to fill out . but we still have this problem of is it gonna be a self evaluation ? or are we gonna ask them "" what was it when you were four years old , or what was it when you were six years old , or what wher "" w what 's the best way of phrasing the question ? or adapta or adaptation . should we just then we shouldn't just shouldn't ask . for the native english speakers we shouldn't even ask the region if it 's that unreliable . the other thing also is that i 'm asking for the variety of english , and i did just put american , british , indian and other . i didn't put canadian , australian , and all the other varieties . e but do you think those three are  that for the eng native english speakers , we 'll do variety of english , regions from the timit labels , and another field . ",,
Bmr008.D,"and then this was be fast . air conditioning . right . right , the way the form reads now , it 's pretty clear that 's what we 're asking cuz it says "" native english speakers , variety of english , american , british , indian , other , region "" . and then we 'll have southern english , whatever the timit categories are . if you look at this fr right . right , it seems to me that if you read this form , i w it 's pretty obvious that it 's a subcategory of the language that you think you speak , not where you live . i don't say anything about where you live on the form . it 's just in the section talking about language .  and then as jane said , the last question is "" list other language influences , bilingual dialects , et cetera . "" and that 's just and open ended place for them to do . and then and then the bottom of the form is for not for them to fill out , but for us to fill out , for the aliases and database speaker database that the person is in , since we 'll eventually anonymize and this will be a form a place for us to connect the two . and then the meetings that they attended , because there 'll be one form for each person .  'll fiddle around yet again with the language right . there 's another area which is non native english speakers which asks for native language , region , and variety of english . and that 's it . proficiency . that 's a good idea . do you think that 's also because they know that it 's a re important for them to be good at it . don't you think they overrate rather than underrate ? but no , proficiency is actually a good thing to have on this form . the question are what would the categories be ? i 'm i don't know . being monolingual , i 'm not the right person to ask , to talk about this but it just seems to me that doesn't the length of time doesn't really get at what we 're asking . right ? it seems to be that asking about the proficiency , even if it 's self rated , is what we wanna know .   with that form . shall we for other forms later , or you keep going more form the other form is a modified digits form . and it 's pretty sim this one 's pretty simple , it 's very much what like the digits forms in front of us , except it doesn't ha ask for sex or native language . it 's name , email , time , date , seat , session , mike number , channel , mike type . in case people have the same name . wanted ",,
Bmr008.D,"have the same name . i 'm particularly sensitive to this cuz a good friend of mine in s in seattle was named scott smith and there were fourteen of them in at boeing . we could drop email . that 's not a big deal , it 's just right . the other way i was thinking about it was assigning them an id but i hate it when people do that to me , when they say , here 's you id , don't forget it . i wanted just something that would give us a hint of who the person is if the name field isn't readable or it 's a duplicate . your mother 's maiden name social security number , although the email will change , that 's a good way of doing it . we 'll be able to backtrack from email . and then the other thing i was thinking about and it probably wouldn't be on the digits form , but it is something that some form about the individual meeting . now , the problem i have with that is i don't know who would be filling it out . just to pick up an arbitrary an example . right . th the sorts of questions i had were one who 's gonna fill it out , and who 's gonna take responsibility for filling it out in each meeting , will we re will we require it .   and that was my other question , which is what information do we want to record ? think pairwise relationships are pretty easy . source , destination , relation . are there other sorts of things that might we might want to record ? right . that fits in with the whole meeting map mapping meetings concept is that 's another way of looking at it . are there anything other than pairwise ?  yes , shirt certainly . i 've been thi i it seems to be that there is we could attach more structure if we wanted to . especially because a lot of these relationships are pairwise power relationships . just as an example , it would be , "" source , adam janin "" , "" destination , morgan "" , "" relationship , advisor "" . that are relevant .  right , my example was not a good one , because that 's right . it 's just cuz it 's my turn . the d t ds mean we can do whatever however we want it . but what i was thinking the reason that i didn't want to make it completely open ended is that it does seems like there is some structure which is common . especially with these pairwise ones , where you can describe them and pairwise . and you might want a tool that used that information .  right . right think being in a common organization was one i hadn't thought of , that ",,
Bmr008.D,"you 're football league was a good one . the ones i 've been thinking of are all power , responsibility . husband wife is yet another one . ach !    some more .  nope . what i have right now is all pairwise , that 's probably not sufficient . not .  that in a lot of the meetings people won't be filling this out anyway . really what i want to have is a place that if a researcher wants that information , they can add it . right . right . it we can regenerate a lot of this information . but even if we can't , generate it , it 's alright to have some of the sections in your database blank , that this information was not collected for this meeting . and there 's just not gonna be a way around that . that 's just gonna happen like the n s a meeting , the networks meeting . i don't think they 're gonna want to fill out that information .  enough on forms . they haven't received them yet , but i did get a response from them saying "" yes we 're still alive , we haven't done anything yet . "" and  they 've transferred the responsibility to someone else . i can't remember his name mccoond ? mccoond ? something like that , but and he sent me email and said he 's gonna be starting to work on it , and i haven't received anything else .  tomorrow i 'll send a email and just ask if he received it , he should be getting it today . actually he should have gotten it yesterday . but . give him a day .  and did is this from the mixed signal ? there is some normalization already , in that they 've been volume equalized over the entire signal . right . right . but the mixed signal already has a normalization in it . it 'll be worse , right , the mixed or window it hamming window .  right . and he has on his graph something like forty percent . it looked like fifty percent or more are point two seconds or longer overlap it 's li the last page . nope , not the last page . where was it ? it was one of the tables . fifth page . it 's seventy five percent ! and the length it seems like with the overlaps being fairly long , that should make it easier . that r that was an interesting statistic . that they 're much longer than i expected . ninety percent of them are over two m two hundred milliseconds . it is good , but it 's but it surprised me . yes .  two hundred milliseconds , hamming window .  did you typecast to long ? or size t or whatever it is ? i don't remember what it is . ",,
Bmr008.D,"one of the problems , if the file is large , and you 're cast to the wrong type . right , if you 're sending at an integer instead of a long . typecast from integer , "" int "" int or long or unsigned long . it 's  it 's one possibility .    shall we do digits ?  are we done ? yes , we are going off . ",,
Bmr008.E,"just tried it . my head is too big .  the distance isn't status ? stats status , student , non student . sitting . how about you could say , if you 're giving a talk , how likely are you to be challenged ? sounds like you really need to know something like that . you need to know bas in this meeting , what is your social status ? but it 's gonna depend on who 's    i g it seems to me like trying to deduce information about the person 's status from the meeting independent form will be useless because but , that will depend on what the meeting 's about , right ? let 's say the undergrad was an expert in physics , and  'm wondering how can you make a conclusion based on that , if you don't know about the meeting ? i don't know . i 'm just that 's why i was wondering about if you can put something about the d for the european  no , i like the idea of putting down the status information because you probably can get a lot of interest there can be a lot of interesting research on that . i 'm wondering could we add something to the form that gets filled out at each meeting that would somehow   guess i was thinking how you were taking information off of the digits and putting it onto that ? could we put one more thing on here  cuz you said separate forms thought  right .  how about how about "" optional but highly desirable "" ? if not given we will estimate .  they 're very strong willed .  people he you can put "" optional "" it 's not gonna people who lie about it ? it 's people will put it , i   where you lived between the ages of  which is more objective . than somebody evalu saying , speak this or that . i was just gonna ask the same thing . region does that mean region of region of the us , or region of the world  do state , or do more broad than the state level ? like southern us , or northeastern or if you wanted to get regions for american english you could copy what they did in timit . they had divided things up into regions . no , no . it would only be f if you said american english then you 'd put the regions . for the others , you would just leave it .  we wouldn't have enough to really make them difference on those . it 's like six regions of the country very just a limited number and then if you 're american you would just circle the region where  you 'd just leave them . you don't even ask . ",,
Bmr008.E,"one good reason to use the timit ones is if anybody asks about the data later on you can say "" chose these based on timit "" , and and that would apply to everybody then ?  and then you could map those to the timit regions later , if people wanted to .  that 's more general .  that 's true . a lot of post processing . y there is actu you made me think about another wrinkle in this whole thing , which is that just asking them where they grew up between certain ages isn't enough , because somebody could grow up in germany but live on an army base speaking english . you have to say what languages were spoken in the home between the ages of that 's     like as soon as you get to the cases on the edge , the complexity just shoots up . the other thing , too , is that it seems like th one of the reasons you would gather real detailed information about their native language is if you were gonna do fine grained phonetic analysis and i don't that 's what i was gonna ask , is that were they putting down where they lived at the moment they m recordings were made ? is that why ? rather than where they grew up ?   then we probably don't need the fine grained information .   it can't be relied on only . those are good .  i don't think you really have to do all that much .  n right . n detec and then there will be people who live in an english speaking country , but all their meetings are held in another language .  yochai 's company is like that . everybody speaks hebrew . pin . what about all of the meetings that have been recorded far that without this ? will somebody go back and fill that in , or we just won't have it , or  it wouldn't be that hard to go back and    what about that error that the supposed lub no , the supposed bug that was that we were we were guessing you had a bug before because you went through and you concatenated all of these things together  are the things in the from these charts , are i 'm just trying to remember where we were , but were you were interested in finding out if you can tell the difference between overlap and single speakers by looking at the e energy , like say , the mean of the energy . was that the idea ?  if you look at on this page that has frame energy , you look at the mean for the overlap , that 's forty four point sixty two versus the mean for the speakers , thirty nine point sixty two , there seems to be more energy when there 's overlapping which makes sense , but  different than standard deviation .  the just one more clarifying question ",,
Bmr008.E,"on the overlap category , is that overlapping of speakers only ? it doesn't include some of the other sounds ?    just out of curiosity , what was the bug ? what was the bug that you found ? the bug from last meeting ?    it was positioning randomly ? ",,
Bmr008.F,"and there is a problem that you can hear it come and go , cuz when you turn your head , then you drift away from the microphone . yes . that 's it . and it 's also relevant to status . i c insert that . which might in af affect the discourse aspects . go ahead . his  categories . think undergrad is useful .  that did are were you suggesting that it should be more fine grained than this ? less ? what would you suggest as a change ?  i do , and the reason is because that having been a grad student as , a as others here , at berkeley , that , there 's almost like a quantum leap from undergrad to grad in terms of like the status . you notice it in various ways , like simply trying to meet with a professor during office hours . in my department it was always the case grad students had a huge amount of different priority , and were treated as equals , g and help helpers , in research , roles and things that they in terms of like the s the social dynamics of interactions , i would expect them to be less deferent . and less assertive of their own views and things like that . i don't think that we 're going to have a lot of undergrads , unless we branch out to different types of meetings , but this is the dimension . this is the dimension . but one dimension .   and it 's non threatening , this compared to , wh exactly what level of professorship , and i agree with him , though . i  but i agree that this is that w the rea the motivation was things that could affect social dynamics in ways that are relevant to the research without being threatening to the person . and we also discussed the idea of having the separate d t ds would handle s specific meeting specific things that might be relevant . the data , that , his xml thing ? you got the data type definition the document type definition p part that it 's can s be used for relational things ,  where 'd this is just we 're talking at a general level of description . you can always get more specific . and , it may be change would we change "" post doc "" to "" post phd researcher "" ?  that 's true . it 's just to allow . it could be st it could be that 's true . one thing , you understand he d he wants you to do this only once for each person ?        it in like the london lund they the researchers themselves estimate the age afterw after the fact . they say , middle thirties , fifties or sixties , and they just they estimate for the person but  and it isn't that boldf  ",,
Bmr008.F,"and it 's and it isn't really that prominent . it 's his "" optional "" is not really boldface , but  actually , "" approximate "" ? that 's right . the thing abou the reason , one reason for putting "" optional "" might be if it made the form seem gentler and k and not as intrusive thing . i noticed , i was afraid you 'd i shouldn't say that . they that , i if you say "" optional "" then it 's if people who get nervous about the age question then they realize that "" but they 're not trying to ask me lots of things . "" i like it . it 's softening .  let 's see . that 's the only other one . that 's the only one . also , you he has a sep separate subject for region . and it 's a self assessment of what you think your closest variety is of english . and then following that , a characterization of region . now , we discussed indicating a t a time frame . "" where did you live during your , childhood and adolescence ? "" which would be yes . although mean a lot of people there won't be , e much difference , but    and that 's partly to pick up  s we when we discussed it was where you lived during your childhood and adolescence . it 's w it 's where you lived .  and also  i haven't seen what they did in timit . are you s do they have a bunch of options like i see .  that 's the concept ,   that 's right . that that was the concept of having the region thing , i it would be no problem to change it to options if if that were desirable . although for different that 's true . indian english i wouldn't know f what that is that was the concept of region . and it 's just the wording of it . there 's a there is another problem .   or someone could in geor in new york and have , any number of different types of speech patterns . we have this we hafta he hasn't given you the overview , but you have the native speaker category , the non native speaker category , and then you have other language influences , bilingual dialects , th things like that . now there 's this issue of not wa like you 're saying , you don't want the forms to be hugely complicated and take half the meeting to complete . it 's trying to e there 's this trying to hold this balance between the amount of information needed and not taking too much meeting time , and then in addition , add to it the third level of the balance , this issue of not being too intrusive , asking in a way that they don't mind . ",,
Bmr008.F,"rea that we need to remember that we have first of all , it 's not all free form . we have several categories that are specifically constrained , and in terms of the more open ones , we have the we 're in the enviable position of having the contact information and also knowing most of the people who will be participating in the meeting data . we can find it we can resolve certain issues later , if  that 's it . isn't it that we 're going a little bit in a circle , because i like the timit suggestion very much , and it 's a question of how to ge incorporate it , and we 've already suggested it 's come up in this discussion , that the suggestion that we could have the timit categories for the american , and then make the choice or not , as to whether we do it for british , w we discussed one way or the other , and it doesn't matter to me . i don't know if adam has a preference , but we could have a sub a sub categorization for american , we could even use the timit subcategorization . i don't know if it has one for british , or whatever , but just have it a short simple form that you can categorize yourself in a systematic way . it 's a good idea . and the peers . that 's one part though . it 's that 's not a problem though , that would be a good question to ask , and then you could add a question . would among your peers "" .  specify the age range . that 's right . and we 're and then we like i said , we have the enviable benefit of knowing most of these people . and being able to ask them follow ups if we need to . for now . that 's true . washington and that 's true . it 's i i w i was thinking of it as e that 's a good point , but i was thinking with reference to the language model issue , which and it could be done inductively , but if you have a bunch of , say , r less dialects and if they  interesting .  but you have a lot of stratification in any region . interesting .    that 's what the final the fin the third category was designed to do , because you have a bunch of different types of accents in new york  native speaking new yorkers , as a function of their social groups and their ethnic identifications and their there are lots of things that are very identifiable as other aspects , which is why we have this third category . we wanted to certainly distinguish american versus british , and other types at that level , and then allow people to self identify if there are other specific things , ",,
Bmr008.F,"and then in addition , this issue of regions with some time frame for the re region because that if you live in massachusetts now versus in childhood and as adolescence if you lis if you  region with respect to a time frame is what i would suggest . "" where did you live ? "" what you said . "" where wh where did you live ? "" , or what you were saying , "" languages in the home "" . but that time frame on the region would be useful instead of "" region now "" , say . it 's a little bit unbounded . there 's this issue of what age is relevant for the formation of your speech patterns , whatever they are . and that 's interesting . that 's interesting . from five to fifteen is a    g  i don't think it was ever the intent to talk about the region now , because it 's a sub categorization .   that 's to handle that unusual percent or two .  it 's very efficient . you  y you didn't really talk about the non english speaker categories . because it used to be that germans would learn british english , and now there 's , is a certain percentage of them who 've @ @ to tend toward american english . that 's hard though , for self identification i agree . e i 'd i 'd have to i 'd wanna relate it back to training . "" how many years did you study english "" , or , "" have you lived in the america in a c an english country before "" . but it seems like that 's that if a person who that 'd be i like that . i like that . that 's non threatening , and it 's also an i a good indicator . and there are people who haven't ever lived in an english speaking country and who are superb . however , that 's do think it 's a pretty good indicator . that 's true too . or even , some people who just don't change much in their except that you have some many biasing factors , you have people who are highly confident when they really should be a little bit less confident , and then you have , other people who are just the reverse , and it many things that vary i and also we wanna keep it simple and non evaluative . why do we need that much information , why do we need the email address , i see . how often would that happen ? i see . the only it 's an interesting identifier , i now that i realize the und the reason for it . the that 's true too .  that 's interesting . good idea . it 's the age question again . that 's right . and a bank where you frequent .   i like that . ",,
Bmr008.F,"i never thought of that as an identifier . that makes sense .  that someone internal to the meeting could do after the fact . and this would and we discussed this , this is with reference to like the dtd , what you would put in the dtd that 's meeting specific . and it could be something like , "" the guy giving the presentation today is the student of the professor who whatever "" . speaker a is his professor and they and he 's preparing for his quals or some such thing like that . or it could be "" and and and are married "" . we this wouldn't be relevant all the time but if there 's a big discussion on the best way to move house , then and these people are talking a whole lot , then it might be interesting information to say they 're married , or i don't mean , i would tend to leave that e spontaneous , that e at the stage of sc scanning the transcripts after they 've been produced by our by ibm , at that point , that some of these dynamics will appear to be important , and you could spend a lot of time enumerating all the different relationships that people have .   i ju i was just thinking , with reference to things that have that bear on the content or the status relations , would be the things without being exhaustive , by any means , but just like i said , if there 's a k a certain topic that comes up in the meeting , and that knowing their relationship will clarify it , or if there 's a certain dynamic that comes up a person is asked a whole bunch of questions , more than you 'd usually think they 'd be asked , and it turns out it 's because he 's being prepared for a job interview like that , then it 's useful to know that relationship . but , not to be exhaustive . interesting . you could have people who are all part of the same football league , or or chess club , or  realize , w this was the idea was that this would be meeting specific . otherwise , they would it would be possible to have a higher level thing . that 's true . that 's true . the there 's @ @ i g you 're the expert on the d t but   and in discourse analysis you get things like @ @ the role . you have a role in relationships and it has to do with your negotiating your how you 're perceived and how y and how the other @ @ and there are various things you negotiate . and i 'm wondering if we might be able to do it s in loose way , but e with by having a searchable field like "" role "" ",,
Bmr008.F,"and then within this context this person has the following roles "" , and it could be very loose , but then it would be possible to do something as simple as a grep across a database and if you 're interested in which ones this person serves as an advisor in and versus l whatever , a leader , speaker , whatever , you could just grep for "" role "" and some particular value . and interesting . good . and systematize also the encoding of it if as we find some are useful and some are not useful . you don't need to have that much structure built in , and that would be less time consuming to do it this way first , and then find out what structure 's needed .   what about doing it with just the single channels ? what about ,  i 'm thinking they 're raising the question about the fact that if you use the mixed signal , there 's already been a i 'm wo exactly . what i 'm wondering is what about doing some of this with the single channel recordings . interesting . that 'll also lessen the standard deviation . pitch . i 'm wondering about if there i suppose this is still just that one data sample , right , that one meeting ? but it seems like to have it seems like a very hard test to have it be looking at the energy of all the speakers combined rather than taking s two extreme speakers out of the mix and seeing if it 's promising with respect to that type of analysis . if you take like a target speaker , and if there 's enough data , two two target speakers and then compare that to the mixture of all the speakers . that 's hard .  that 's true . that 's complicated . that 's interesting , and it didn't give you good error messages .  digits .  ",,
Bmr009.A,"we 're live we 've got a good intro here  we can edit that out if you want .  this time the form discussion should be very short , right ?  good point . hi jane ! we just started . could you take that mike there ?  no , took over the entire s entire channel sampled ten minutes randomly .  this was quite quick and dirty , and it was just for listening . and for listening it seems to work really  but , it 's not a good measure . yes , except that it 's hard to judge this because the they 're not normalized . it 's just number of frames . but even interesting and i was just going to say that right now we 're just exploring . what you would imagine eventually , is that you 'll feed all of these features into some discriminative system . and even if one of the features does a good job at one type of overlap , another feature might do a good job at another type of overlap . no prayer . that was a great overlap but that 's what i was saying about different types of overlap . right . mind if i turned that light off ? the flickering is annoying me . tone but tone might be very you 're "" tone is going to be very different . you could imagine doing specialized ones for different types of backchannels , if you could if you had a good model for it . your "" detector . right .  it would be interesting , though , to talk , not at the meeting , but at some other time about what are the classes . it would be interesting .   we 're also talking about a couple of different things . one is your analysis window and then the other is any normalization that you 're doing . and the and they could be quite different .  we 're not any time soon going to get a forced alignment .  if it 's not hand marked then we 're not going to get the times . we could do a very bad one with broadcast news . that might be good enough .  it 'd be worth a try . it would be interesting to see what we get .  if ibm doesn't right . forms next iteration of forms .  nope . one 's a digit form , one 's a speaker form . one is a one time only speaker form and the other is the digits . don't fill these out . this is just the suggestion for what the new forms would look like . they incorporate the changes that we talked about . on which one ? on the digit form ? because the user fills out the first three fields and i fill out the rest . it was intentional . it 's an interesting observation , but it was intentional . ","and i was just going to say that right now we 're just exploring . what you would imagine eventually , is that you 'll feed all of these features into some discriminative system . and even if one of the features does a good job at one type of overlap , another feature might do a good job at another type of overlap . ",
Bmr009.A,"because the date is when you actually read the digits and the time and , excuse me , the time is when you actually read the digits , but i 'm filling out the date beforehand . if you look at the form in front of you ? that you 're going to fill out when you read the digits ? you 'll see i 've already filled in the date but not the time . i 've noticed that in the forms . the reason i put the time in , is that the person who 's extracting the digits , meaning me , will know where to look in the meeting , to try to find the digits . i know . and i haven't said anything .  no , it 's about fifty . actually it 's about one third each . about one third of them are blank , about one third of them are when the digits are read , and about one third of them are when the meeting starts .  i could put instructions ? nah . but if i 'm not at the meeting , i can't do that . but that is the reason name , email and time are where they are . and then the others are later on .  what ? what which form are you talking about ? you 're talking about the digit form . the digit form doesn't the digit no , that 's alright . the digit form doesn't have a "" for official use only "" line . it just has a line , which is what you 're supposed to read . on the digits form , everything above the line is a fill in form and everything below the line is digits that the user reads . no , either way is fine you just started talking about something , and i didn't know which form you were referring to . right .  just as as i have for all the others . that 's because the one , the digit form that has native language is the old form not the new form . this was the problem with these categories , i picked those categories from timit . i don't those are . with timit ,  i was gonna ask wh w what accent are we speaking ? western ? you could call it whatever you want . for the foreign language we couldn't classify every single one . just left it blank and you can put whatever you want .  'm not what to do about the region field for english variety . when i wrote i was writing those down , i was thinking , "" these are great if you 're a linguist "" . but i don't know how to i don't know how to categorize them .  guess my only question was if you were a south midland speaking region , person ? would it ? is that what you would call yourself ?  ","this was the problem with these categories , i picked those categories from timit . 'm not what to do about the region field for english variety . but i don't know how to i don't know how to categorize them . ","Participants also reviewed the latest iteration of speaker forms, and discussed recent changes to the Transcriber tool. "
Bmr009.A,"we we don't want to get that level of detail at this form . that 's alright if we want to follow up . but . picked these regions cuz we had talked about timit , and those are right from timit .  i certainly don't . i was saying i don't even speak . am i speaking western ? northwest ? this is a real problem . i don't to do about it . i c at the first level , we speak the same . our dialects or whatever you region are the same . but i don't it is .  a techno speak accent ? a geek region ? no problem . there are hardly any subjects from "" beep "" really . we i like the idea of asking "" what variety of english do you speak "" as opposed to where you 're from because th if we start asking where we 're from , again you have to start saying , "" is that the language you speak or is that just where you 're from ? "" and would say germany am i speaking with german accent i don't think   could try to put squeeze in a little map . there 's not a lot of r of room of those , northern is the only one that i don't even they 're meaning . ye i don't think the northwest people speak any differently than i do . that 's exactly what we 're arguing about . we don't know . some of them are very obvious . if you talk to someone speaking with southern drawl , or boston , but is boston new england ? w that 's the problem with these categories . i propose , take out northern add , don't know . you want to change the instructions also not just say region ? i don't know if i read this form , they 're going to ask it they 're going to answer the same way if you say , "" what 's variety of english do you speak ? region . "" as if you say "" what variety of region do you speak ? characterize your accent ? "" they 're going to answer the same way . i see . what we talked about with that is that they would understand the granularity . that 's what i had before , and you told me to list the regions to list them .  had it wide open last week and you said timit . that 's what the "" other "" is for . won't they answer the same thing ? right . that 's why i put the "" other "" in .  mean , the way i had it last time was region was blank , it just said region colon . and that 's the best way to do it , because of the problems we 're talking about ",,
Bmr009.A,"but what we said last week , was no , put in a list , put in a list . should we go back to certainly dropping "" northern "" is right , because none of us that is . is "" midwest "" one word ? and but that 's true of new england too . only one i shouldn't say that . i have no clue . i was going to say the only one that doesn't have a huge variety is new york city . but i have no idea whether it does or not . that was what happened with timit , was that it was an analyst . new england no . "" other "" , it goes under "" other "" , definitely under "" other "" .  another suggestion . rather than have circle fill in forms , say "" region , open paren , e g southern comma western comma close paren colon . "" actually , we do one non english one as southern , cockney ? is that a real accent ? how do you spell it ? n e we 'll do it that way . actually , i like that a lot . because that get 's at both of the things we were trying to do , the granularity , and the person can just self assess and we don't have to argue about what these regions are .   just which one . that 's fine .  did you guys get my email on the multitrans ? that  i have a version also which actually displays all the channels . but it 's hideously slow . the what the ones i applied , that you can actually do are dan 's , because it doesn't slow it down . just uses a lot of memory . no , the one that 's installed is fine . it 's not slow i wrote another version . which , instead of having the one pane with the one view , it has multiple panes with the views . but the problem with it is the drawing of those waveforms is slow that every time you do anything it just crawls . it 's really bad .  as you play , as you move , as you scroll . just about anything , and it was slow it was not usable . that 's why i didn't install it and didn't pursue it . that the one dan has is usable enough . it doesn't display the others . it displays just the mixed signal . but you can listen to any of them . no , he suggested that , but he didn't it 's not installed . no . no . not if we 're going to use tcl tk at least not if we 're going to use snack . you would have to do something ourselves . why don't we see how dan 's works and if it if we really need the display  ","did you guys get my email on the multitrans ? i have a version also which actually displays all the channels . the what the ones i applied , that you can actually do are dan 's , because it doesn't slow it down . no , the one that 's installed is fine . it 's not slow i wrote another version . which , instead of having the one pane with the one view , it has multiple panes with the views . but the problem with it is the drawing of those waveforms is slow that every time you do anything it just crawls . just about anything , and it was slow it was not usable . that the one dan has is usable enough . it doesn't display the others . it displays just the mixed signal . but you can listen to any of them . not if we 're going to use tcl tk at least not if we 're going to use snack . ",
Bmr009.A,"we could do that but that would mean changing the code . this isn't a program we wrote . this is a program that we got from someone else , and we 've done patches on .   not easily . yes we could do that . you could you can write widgets in c . and try to do it that way but don't think it let 's try it with dan 's and if that isn't enough , we can do it otherwise . it is , cuz when i was playing with it , the mixed signal has it all in there . and it 's really it 's not too bad to find places in the stream where things are happening . don't think it 'll be bad . and if depends on how much work they did . if one of us sat down and coded it , that it could be displayed fast enough i 'm they would be quite willing to incorporate it . but it 's not a trivial task .  anyway , shall we do digits ?   you want to go first ? or . do you wanna go do digits or do you wanna just skip digits ? then alright . you go ahead . why don't you read the digits ? don't read the old one .  and ","and it 's really it 's not too bad to find places in the stream where things are happening . if one of us sat down and coded it , that it could be displayed fast enough i 'm they would be quite willing to incorporate it . but it 's not a trivial task . ",
Bmr009.B,"i had the same intuition last week . it 's to start with it 's your idea of simplifying , starting with something that you can see without the extra layers of  what ? you don't have to study everybody individually but just simple case and the one that has the lot of data associated with it . or what if the equipment what if the equipment adjusts somehow , there 's some equalizing in there ?  saturation .  i wanted to ask just s something on the end of this top topic . when i presented my results about the distribution of overlaps and the speakers and the profiles of the speakers , at the bottom of that i did have a proposal , and i had plan to go through with it , of co coding the types of overlaps that people were involved in s just with reference to speaker style with reference and said that on my in my summary , that it 's like people may have different amounts of being overlapped with or overlapping but that in itself is not informative without knowing what types of overlaps they 're involved in was planning to do a taxonomy of types overlaps with reference to that . but it it 's like it sounds like you also have something in that direction . is it interesting . we can    it seems like we also s with reference to a purpose , too , that we 'd want to have them coded .  do that .   i see this as a prototype , to use the only the already transcribed meeting as just a prototype .  it may be correlated .     it is an empirical question , it seems like .  it 's possible to try it both ways , isn't it ? in this small  great .   i agree .  coming off of the other good . it wouldn't be i wasn't planning to label the time marks . i was thinking that would come from the engineering side ,  there you go . good . good . great ! good , good .  it would be very inefficient .  good .  good . let 's do that later .    good , how it 's two pages per person ?  i see . alright . date and time . why did you switch the order of the date and time fields ? this is rather a low level , but on the new one , time comes first and then date , but this is rather a low level question , but it used to be date came first . see . how would the user know the time if they didn't know the date ?  i always assumed the time is supposed to be pretty exact , because i 've just been taking beginning time of the meeting . dear . we 've been messing up your forms . i was saying if we started the meeting at two thirty , ","when i presented my results about the distribution of overlaps and the speakers and the profiles of the speakers , at the bottom of that i did have a proposal , and i had plan to go through with it , of co coding the types of overlaps that people were involved in s just with reference to speaker style with reference that it 's like people may have different amounts of being overlapped with or overlapping but that in itself is not informative without knowing what types of overlaps they 're involved in was planning to do a taxonomy of types overlaps with reference to that . ",Participants discussed alternate strategies for examining energy and the importance of categorizing types of speaker overlap. 
Bmr009.B,"i 'd put two thirty , and e everyone was putting two thirty , and i didn't realize there was "" 'm about to read this and i should "" this would be a radical suggestion but ei either that or you could write down when people start reading digits on that particular session . i know , that 's a good point . i see . good point good point .  alright . i rest my  w seat and session . actually you could that does raise another question , which is why is the "" professional use only "" line not higher ? why doesn't it come in at the point of date and seat ? because we 're filling in other things . because if y your professional use , you 're gonna already have the date , and the s 'm comparing the new one with the old one . this is the digit form . i wasn't supposed to  that  about that .    alright s but i didn't mean to derail our discussion here , you really wanted to start with this other form . alright i was comparing th this is was looking at the change first . it 's like we started with this and now we 've got a new version of it wi with reference to this . the digit form , we had one already . now the f the fields are slightly different . what and there 's an addition of the native language , which is a bit redundant . this one has native language and this one does too .  there we go .  i 'll catch up here . i see . that 's the old and that 's the new .   no , that 's not bad .  i was thinking you could have ma multiple ones and then the amount of time roughly . you could say , ten years on the east coast , five years on the west coast "" or other .   lot of people  i wouldn't know how to characterize mine either . and would would say , i 've got a mix of california and ohio .  geek region . i 'm wondering about a question like , "" where are you from mostly ? "" i agree . i agree . i agree . scandinavian , the minnesota area 's north .   just rule them out . it 'd be pretty simple , where are you from mostly ?   see , i 'm thinking "" where are you from mostly "" because , then you have some subjective amount of time factored into it .   i or boston . i can't do it , but they do . agree . i agree . and they 're proud of it .  it 's identity thing . we ca why can't we just say characterize something like char characterize your accent and would say , "" i don't know "" . ",,
Bmr009.B,"but someone from boston with a really strong coloration would know . and would an r less maine  good .   i would say more sweepingly , "" how would you characterize your accent ? "" this discussion has made me think that 's something to consider .  i was not that i i was suggesting not having the options , just having them yes , but if , as liz is suggesting , people who have strong accents know that they do and are i know . that 's true .  that 's fine . they might say "" other "" for region because they don't category to use but they might have something because it is easier to have it open ended . we thought about it .  we just we thought , "" yes , "" y at the last meeting , my recollection was that we felt people would have less that there are many types and varieties of these other languages and we are not going to have that many subjects from these different language groups and that it 's a huge waste of space . that 's what   i don't think that 's what they mean . it does seem i would think that these categories would be more w would be easier for an analyst to put in rather than the subject himself .   they were part of the one of the midlands .   fine by me , fine by me .  be easier on the subjects . that 's fine . no .  i like that . i like that . i do .  that 's fine .  alright . pure that 's right . and it 's easy on the subjects . now i have one suggestion on the next section . you have native language , you have region , and then you have time spent in english speaking country . now , i wonder if it might be useful to have another open field saying "" which one parenthesis s paren closed parenthesis "" . cuz if they spent time in britain and america it doesn't have to be ex all exact , just in the same open field format that you have .  with a with an s "" which one sss , optional s .  that 's good . isn't that wonderful !  excellent !  you this is n dan 's patches , dan ellis 's patches . fantastic !  that 's a consideration . and this 'll be a hav having the multiwave will be a big help cuz in terms of like disentangling overlaps and things , that 'll be a big help .  that 's excellent . he also has version control which is another e you e the patches that you it was in one of those patches .  alright . or use the one that crawls .  and it 's also the case that this multi wave thing is proposed to the dan proposed it to the transcriber central people , ",and this 'll be a hav having the multiwave will be a big help ,
Bmr009.B,"and it 's likely that and they responded favorably looks as though it will be incorporated in the future version . they said that the only reason they hadn't had the multi the parallel stream one before was simply that they hadn't had time to do it . and it 's likely that this may be entered into the ch this central @ @ . that 's that 's true , too . this is a useful thing for us . no . mean that it 's that his this one that we now have does have the status of potentially being incorporated l likely being incorporated into the central code . now , tha now , if we develop further then , y i don't it 's it 's a feature to have it set that way .   like the idea of it being something that 's , tied back into the original , that other people can benefit from it .  however . i also understand that you can have widgets that are very useful for their purpose and that you don't need to always go that w route .     should we e should we switch off the g ke turn it off . but till he  ",,
Bmr009.C,"starts no . no . there 's another i don't know . it starts with a p i forget the word for it , but it 's typically when you 're ab r starting around forty for most people , it starts to harden and then it 's just harder for the lens to shift things and th the symptom is typically that you have to hold further away to see it . my brother 's a gerontological psychologist and he came up with an body age test which gets down to only three measurements that are good enough st statistical predictors of all the rest of it . and one of them is the distance that you have to hold it at .   about how old i am .  no , that 's it also should be later . because jane is not here yet . and she 'll be most interested in that . she 's probably least involved in the signal processing we can just i don't think we should go though an elaborate thing , but jose and i were just talking about the speech e energy thing , and i we didn't talk about the derivatives . but the i if if you don't mind my speaking for you for a bit , right now , that he 's not really showing any distinction , but but we discussed a couple of the possible things that he can look at . and one is that this is all in log energy and log energy is compressing the distances between things . another is that he needs to play with the different temporal sizes . he was taking everything over two hundred milliseconds and he 's going to vary that number and also look at moving windows , as we discussed before . and and the other thing is that the doing the subtracting off the mean and the variance in the and dividing it by the standard deviation in the log domain , may not be the right thing to do . between no . between neither . it 's between the pauses for some segment . and his he 's making the constraint it has to be at least two hundred milliseconds . and you take that . and then he 's measuring at the frame level still at the frame level , of what and then just normalizing with that larger amount . and but one thing he was pointing out is when he looked at a bunch of examples in log domain , it is actually pretty hard to see the change . and you can see that , because of j of just putting it on the board that if you have log x plus log x , that 's the log of x plus the log of two and it 's just , it diminishes the effect of having two of them .  yes , right . what i was suggesting to him is that actually , a pdf . ","but jose and i were just talking about the speech e energy thing , right now , that he 's not really showing any distinction , but but we discussed a couple of the possible things that he can look at . and one is that this is all in log energy and log energy is compressing the distances between things . another is that he needs to play with the different temporal sizes . he was taking everything over two hundred milliseconds and he 's going to vary that number and also look at moving windows , as we discussed before . and and the other thing is that the doing the subtracting off the mean and the variance in the and dividing it by the standard deviation in the log domain , may not be the right thing to do . it 's between the pauses for some segment . and his he 's making the constraint it has to be at least two hundred milliseconds . and then he 's measuring at the frame level and then just normalizing with that larger amount . and but one thing he was pointing out is when he looked at a bunch of examples in log domain , it is actually pretty hard to see the change . what i was suggesting to him is that actually , a pdf . ",The Berkely Meeting Recorder group discussed efforts by speaker mn005 to measure energy levels in cases of speaker overlap in which the time window analyzed was 200 milliseconds or greater. Preliminary results were presented showing that log domain analyses did not reveal a significant difference in mean energy levels for windows of overlapping versus non-overlapping speech. 
Bmr009.C,"but , but , either way .  eith but also u good first indicator is when the researcher looks at examples of the data and can not see a change in how big the signal is , when the two speaker then , that 's a problem right there . you should at least be able , doing casual looking and can get the sense , "" hey , there 's something there . "" and then you can play around with the measures . and when he 's looking in the log domain he 's not really seeing it .  and when he 's looking in straight energy he is , that 's a good place to start . that was the discussion we just had . the other thing actually we ca had a question for adam in this . when you did the sampling ? over the speech segments or s or sampling over the individual channels in order to do the e the amplitude equalization , did you do it over just the entire everything in the mike channels ? you didn't try to find speech ? right , then that means that someone who didn't speak very much would be largely represented by silence . and someone who would be the normalization factor probably is i is     but that 's right . th  there 's a good chance then given that different people do talk different amounts that there is still a lot more to be gained from gain norm normalization with some sort if we can figure out a way to do it . but we were that in addition to that there should be s related to pitch and harmonics and forth . we didn't talk about the other derivatives , but again just looking at liz has a very good point , that it would be much more graphic just to show actually , you do have some distributions here , for these cases . you have some histograms , and they don't look very separate . separated .     "" number ""  but and in these he 's got that . he 's got some pictures . but he doesn't in the he i just in derivatives , but not in the but he d but he doesn't but he didn't h have it for the energy . he had it for the derivatives .   that that 's a good q did you have this thing , for just the l r the unnormalized log energy ?  she 's right . that 's a  that 's cuz i 'd mentioned scatter plots before but she 's right , even before you get the scatter plots , just looking at a single feature looking at the distribution , is a good thing to do . but what she 's saying is , which is right , is le let 's start with the ","but also u good first indicator is when the researcher looks at examples of the data and can not see a change in how big the signal is , when the two speaker and when he 's looking in the log domain he 's not really seeing it . and when he 's looking in straight energy he is , that 's a good place to start . there 's a good chance then given that different people do talk different amounts that there is still a lot more to be gained from gain norm normalization with some sort but we were that in addition to that there should be s related to pitch and harmonics and forth . actually , you do have some distributions here , for these cases . and they don't look very separate . separated . ","Preliminary results were presented showing that log domain analyses did not reveal a significant difference in mean energy levels for windows of overlapping versus non-overlapping speech. In contrast, raw energy analyses were successful in showing the two groups to be distinct. "
Bmr009.C,"before we get complicated , let 's start with the most basic wh thing , which is we 're arguing that if you take energy if you look at the energy , that , when two people are speaking at the same time , usually there 'll be more energy than when one is right ? that 's that hypothesis . and the first way you 'd look at that , she 's , right , is that you would just take a look at the distribution of those two things , much as you 've plotted them here , but just do it in this case you have three . you have the silence , and that 's fine . with three colors or three shades or whatever , just look at those distributions . and then , given that as a base , you can see if that gets improved , or worsened by the looking at regular energy , looking at log energy , we were just proposing that it 's it 's harder to see with the log energy , and also these different normalizations , does a particular choice of normalization make it better ? but i had made it too complicated by suggesting early on , that you look at scatter plots because that 's looking at a distribution in two dimensions . let 's start off just in one , with this feature . that 's probably the most basic thing , before anything very complicated . and then we w we 're that pitch related things are going to be a really likely candidate to help . but since your intuition from looking at some of the data , is that when you looked at the regular energy , that it did usually go up , when two people were talking , that 's you should be able to come up with a measure which will match your intuition . and she 's right , that a that having a having this table , with a whole bunch of things , with the standard deviation , the variance and forth , it 's it 's harder to interpret than just looking at the same picture you have here .     there 'll be some cases for which but , the qu they 'll be this is i w want to point to visual things , but they there 'll be time there 'll be overlap between the distributions , but the question is , "" if it 's a reasonable feature there 's some separation . ""   right . the reason i had suggested the scatter f p features is i used to do this a lot , when we had thirteen or fifteen or twenty features to look at . because something is a good feature by itself , you don't really know how it 'll behave in combination and it 's to have as many together at the same time as possible in in some reasonable visual form . ","before we get complicated , let 's start with the most basic wh thing , which is we 're arguing that if you take energy if you look at the energy , that , when two people are speaking at the same time , usually there 'll be more energy than when one is that 's that hypothesis . is that you would just take a look at the distribution of those two things , but i had made it too complicated by suggesting early on , that you look at scatter plots let 's start off just in one , with this feature . and then we w we 're that pitch related things are going to be a really likely candidate to help . but since your intuition from looking at some of the data , is that when you looked at the regular energy , that it did usually go up , when two people were talking , that 's you should be able to come up with a measure which will match your intuition . ","In contrast, raw energy analyses were successful in showing the two groups to be distinct. "
Bmr009.C,"there 's graphic things people have had sometimes to put together three or four in some funny way . but it 's true that you shouldn't do any of that unless that the individual ones , at least , have some some hope   right .  no we don't have that . but .  would s actually still recommend that he do the overall thing because it would be the quickest thing for him to do . he could you see , he already has all his in place , he has the histogram mechanism , he has the that subtracts out and all he has to do is change it from log to plain energy and plot the histogram and look at it . and then he should go on and do the other bec but this will   hm  but was just saying that right now from the means that you gave , i don't have any sense of whether even , there are any significant number of cases for which there is distinct and i would imagine there should be some there should be the distributions should be somewhat separated . and i would still guess that if they are not separated that there 's some there 's most likely something wrong in the way that we 're measuring it . but wouldn't expect that it was very common overall , that when two people were talking at the same time , that it would that it really was lower , although sometimes , as you say , it would .    no . it could it probably does happen sometimes .     e what they what difference there was would be lost in taking the log ,  as no , if it 's if i if it 's it won't be as big . if you 're a my point is , if you 're doing essentially a linear separation , taking the log first does make it harder to separate . it 's if you i if there close to things it does it 's a nonlinear operation that does change the distinction . if you 're doing a non if you 're doing some fancy thing then  and right now we 're essentially doing this linear thing by looking across here and saying we 're going to cut it here . and that 's the indicator that we 're getting . but anyway , we 're not disagreeing on any of this , we should look at it more more finely , but think that this often happens , you do fairly complicated things , and then you stand back from them and you realize that you haven't done something simple . if you generated something like that just for the energy and see , and then , a as liz says , when they g have smaller more coherent groups to look at , that would be another interesting thing later . ","if you generated something like that just for the energy and see , and then , a as liz says , when they g have smaller more coherent groups to look at , that would be another interesting thing later . ",
Bmr009.C,"and then that should give us some indication between those , should give us some indication of whether there 's anything to be achieved f from energy and then you can move on to the more pitch related   but then the have you started looking at the pitch related or ? pitch related ? harmonicity and on ? preparing to   that 's not what i meant . no , no . i i we certainly should see this but that the harm i certainly wasn't saying this was better than the harmonicity and pitch related things i was just saying  i was just saying   but all these derivatives and second derivatives and all these other very fancy things , would just look at the energy and then get into the harmonicity as a suggestion .  since w we 're trying to compress the meeting , i know adam had some form he wanted to talk about and did you have some ?     you want it around the overlapping part . you want it to include something that 's not in overlapping but   i 'm not that 's necessarily true . because it because again if you 're just compensating for the gain , the fact that this gain thing was crude , and the gain wh if someone is speaking relatively at consistent level , just to give a an extreme example , all you 're doing is compensating for that . and then you still s and then if you look at the frame with respect to that , it still should change  right . this was where we were last week . but , anyway we 'll have to look at some core things . yes . again for the close mike we could come up take a s take the switchboard system and just , low pass filter the speech and  there 's something we should talk about later but not just now . but , should talk about our options as far as the transcription but . w but we 'll do that later . we 'll talk about it later .  "" forms "" . you had something on forms .   why what were you putting in ?  he 's been setting up and going away . for some reason he doesn't want to sit through every meeting that 's   what ? digit . digit form . the main thing that the person fills out is the name and email and time ? you do the rest ? right . "" south midland , north midland "" is south midland like kansas ? and north midland like illinois , or ? by definition ?  if you 're if e if y if you 're a ti or mit from nineteen eighty five .  ","and then that should give us some indication between those , should give us some indication of whether there 's anything to be achieved f from energy and then you can move on to the more pitch related would just look at the energy and then get into the harmonicity as a suggestion . ",
Bmr009.C,"if you 're talking if you 're thinking in terms of places , as opposed to names different peop names people have given to different ways of talking , i would think north midwest , and south midwest would be more common than saying midland , right , i went to s  but what if you moved five times and we don't really know . what is northern ? and what 's northern ? but i 'm s i 'm now that you mentioned it though , i am really am confused by "" northern "" . i really am . if you 're in new england , that 's north . if you 're i if you 're that 's but that 's also north midland , right ? and oregon and washington are western , but they 're also northern . idaho ? montana ? we should put a little map and say "" put an x on where you 're from "" , let 's  we could always ask them if they 're from i 'd say , "" boston , new york city , the south and regular "" . that 's a joke . that 's "" do you come from the louisiana purchase ? ""  boston 's @ @ , too . how it wasn't that long ago that we had somebody here who was from texas who was that he didn't have any accent left . and had he had a pretty noticeable drawl . right . right . right . last week i was arguing for having it wide open , but then everybody said "" no , but then it will be hard to interpret because some people will say cincinnati and some will say ohio "" . and .  w this is just a small thing but it says "" variety "" and then it gives things that e have american as one of the choices . but then it says "" region "" , but region actually just applies to us , right ?  s  yes u unless you 're from midland , kansas . but .  there 's a or midland is it midland , texas or midland , kansas ? i forget . but there 's a town . in there . i forget what it is @ @ .  y and colorado , right across the border , would be north midland . but you do in the others , too .  u minute . where does d w where 's where does new york west of new york city and pennsylvania and n no , it 's not . no . no , no . no . pennsylvania is not pennsylvania pennsylvania is not new england . and new jersey is not new england and maryland is not new england and none of those are the south . that 's good . i like that . we 're all sufficiently tired of this that we 're agreeing with you .  you like it ?  good . ",,
Bmr009.C,"cockney ? co  liverpuddlian .   yes .  we we done ?  e any other open mike topics or should we go right to the digits ?  cou i e y if there was some is there some way to have someone write patches in something faster and link it in , or is that  they may have not had much demand for it .  let 's do digits , and then we 'll turn off the mikes , and then i have one other thing to discuss .   we 'll talk to you about it why don't you read the digits and then you can go .   ",,
Bmr009.D,"no . that 's a different thing .   give someone a piece of paper and then they that 's optional .  are these the long term means ? like , over the whole the means of what ? all the frames in the conversation ? or of things that   right . it 's not log distributed . but you could do like a c d f there instead ? we don't know that the distribution here is normally . just some simple pdf  something like that where it 's data driven .   what log energy .  frame energy .   w what i meant is , even if you use linear , raw measures , like raw energy or whatever , we shouldn't make any assumptions about the distribution 's shape , and just use use the distribution to model the mean , or what y rather than the mean take some    right . we don't they look like on the , tsk for the raw .   there might be something there . i don't know .  it might be just good to it looks like . cuz  right . especially locally . locally . and the other thing is i  i especially for normalizing . it 's really important to pick a normalization that matches the distribution for that feature . and it may not be the same for all the types of overlaps or the windows may not be the same . e actually , i was wondering , right now you 're taking a all of the speech , from the whole meeting , and you 're trying to find points of overlap , but we don't really know which speaker is overlapping with which speaker , right ? mean another way would just be to take the speech from just , say , morgan , and just jane and then just their overlaps , like but by hand , by cheating , and looking at if you can detect something that way , because if we can't do it that way , there 's no good way that we 're going to be able to do it . that there might be something helpful and cleaner about looking at just individuals and then that combination alone . plus , it has more elegant e the m the right model will be easier to see that way . if i don't know , if you go through and you find adam , cuz he has a lot of overlaps and some other speaker who also has e enough speech and just look at those three cases of adam and the other person and the overlaps ,  and just look at the distributions , there is a clear pattern but we just can't see it because there 's too many combinations of people that can overlap .  just seems complex . right . cuz if energy doesn't matter there , like i don't think this is true , but what if  to study the simplest case to get rid of extra ",are these the long term means ? ,
Bmr009.D,"right . cuz what if it 's the case and i don't think this is true what if it 's the case that when two people overlap they equate their there 's a conservation of energy and everybody both people talk more softly ? i don't think this happens or they get louder . or  there are different types , and within those types , like as jose was saying , that sounded like a backchannel overlap , meaning the kind that 's a friendly encouragement , like "" "" , "" great ! "" ,  and it doesn't take you don't take the floor . but , some of those , as you showed , can be discriminated by the duration of the overlap .  it actually the s new student , don , who adam has met , and he was at one of our meetings he 's getting his feet wet and then he 'll be starting again in mid january . he 's interested in trying to distinguish the types of overlap . i don't know if he 's talked with you yet . but in honing in on these different types and it might be something that we can help by categorizing some of them and then , look at that .   no . i didn't mean that for you to do that , but i was thinking if don and i are trying to get categories and we label some data for you , and we say this is what we think is going you don't have to worry about it . and here 's the three types of overlaps . and we 'll do the labelling for you .  that we would be working on anyway . then you can try some different things for those three cases , and see if that helps , or  no , that was a jok or a a case where you would never know that unless you actually go and look at two individuals .  it might the case , though , that the significant energy , just as jose was saying , comes in the non backchannel cases . because in back most people when they 're talking don't change their own energy when they get a backchannel , cuz they 're not really predicting the backchannel . and sometimes it 's a nod and sometimes it 's an "" . and the "" is really usually very low energy . those don't actually have much difference in energy . but all the other cases might . and the backchannels are easy to spot s in terms of their words or just listen to it .  it would be lost no matter what you do . it just even if you take the log , you can your model just has a more sensitive measures .   right . right .   that 'd be great . i remem right . that would be great . that would be really great . we have nothing ",,
Bmr009.D,"we got his environment set up . he 's a double e it 's mostly that , if we had to label it ourselves , we would or we 'd have to , to get started , but if it would be much better if you can do it . you 'd be much better at doing it also because i 'm not i don't have a good feel for how they should be sorted out , and i really didn't wanna go into that if i didn't have to . if you 're w willing to do that or  that 's a research effort in and of itself , because you can read the literature , but i don't know how it 'll turn out and , it 's always an interesting question . that 'd be great . that 'd be really great . and we 'd still have some funding for this project , like probably , if we had to hire some like an undergrad , because don is being covered half time on something else he we 're not paying him the full ra ship for all the time . if we got it to where we wanted we needed someone to do that i don't think there 's really enough data where  but definitely . that 's true . the window shouldn't be larger than the backchannel .  it 's a sliding window , right ? if you take the measure in the center of the overlapped piece , there 'd better be some something . but if your window is really huge then you 're right you won't even the portion of the backchannel won't effect anything . but you   you shouldn't be more than like you should definitely not be three times as big as your backchannel . then you 're gonna w have a wash . and hopefully it 's more like on the order of yea it depends how different your normalization is , as you slide your window across . that 's something we don't know . was talking about the n normalization window .   that 's true .  but that 'd be great if you 're marking those and but it is definitely true that we need to have the time marks , and i was assuming that will be inherited because , if you have the words and they 're roughly aligned in time via forced alignment or whatever we end up using , then this student and i would be looking at the time marks and classifying all the frames inside those as whatever labels jane gave i don't think you need to . that should be linked to the words which are linked to time somehow , right ? not now . it 's something that w we wouldn't be able to do any work without a forced alignment anyway , somehow if once he gets going we 're gonna hafta come up with one and  whatever you would label would be attached to the words , ","but it is definitely true that we need to have the time marks , and i was assuming that will be inherited because , if you have the words and they 're roughly aligned in time via forced alignment or whatever we end up using , then this student and i would be looking at the time marks we wouldn't be able to do any work without a forced alignment anyway , somehow if once he gets going we 're gonna hafta come up with one ",
Bmr009.D,"cuz there 's a lot of work you can't do without that , how would you you 'd have to go in and measure every start and stop point next to a word is y if you 're interested in anything to do with words .  anyway that 'd be great . do we hafta turn are we supposed to keep recording here ? me too . you should call it digits start time "" . or . "" for official use only "" that 's he 's very professional . actually , the only way i know is from working with the database and having to figure it out .  nor probably western , actually even if you t this wasn't developed by th these regions weren't  i don't know . now the usage we can give them a li like a little map ? with the regions and they just no , i 'm serious . because it takes less time , and it 's cute there 's no figure . just a little it doesn't have all the detail , but you no , but you 're categorized . that 's the same as i said , i don't think there 's a huge benefit to this region thing . it gets the problem is that for some things it 's really clear and usually listening to it you can tell right away if it 's a new york or boston accent , but new york and boston are two they have the nyc , but new england has a bunch of very different dialects and and does do other places . right . and these would be satisfying like a speech research community if we released the database , but as to whether subjects know where they 're from , i 'm not because know that they had to fill this out for switchboard . this is i almost exactly the same as switchboard regions or very close .  and i don't know how they filled that out . but th if midland midland is the one that 's difficult also northwest you 've got oreg washington and oregon now which people don't know if it 's western or northern . it 's like northwest originally it was north northwest but  i don't know . you have a like techno speak accent  it 's you can identify it f it 's not that 's but that we could leave this and see what people choose and then let them just fill in if they don't don't else we can do , cuz that 's north midland .  that 's very different from michigan , or there are hardly any subjects from idaho . there 's only a few people in idaho .  no , that 's we could ask where they 're from .  but we went back to that . we went around this and then a lot of people ended up saying that it  right . right . ",,
Bmr009.D,"it gives us good information on where they 're from , but that doesn't tell us anything enough about their like right . i don't know . let 's make it up . s who cares . right ? we can make up our own we can say "" northwest "" , "" rest of west ""  "" west "" and it doesn't even exactly . that 's not really a region . we could take out "" north "" "" northern "" . that 's w it 's in it 's harder in america anywhere else , and those people , if you ask them to self identify their accent they know . they know very they know they don't speak the same as the day o exactly . and they 're glad to tell you . depends who you ask , i suppose . but that 's why they have new york city but or "" characterize your accent if you can . ""  right , which probably means you have a very and that 's actually good . i was thinking of something along that line because if you don't know , then , ruling out the fact that you 're inept if somebody doesn't know , it probably means their accent isn't very strong compared to the midwest standard . w each one has pros and cons we what if we put in both ? and would people no , what if we put in both ways of asking them ? one is region and the another one is "" if you had to characterize yourself your accent , what would you say ? "" they might only answer only one of the questions but if  actually right . it just and we we might learn from what they say , as to which one 's a better way to ask it . but i cuz i really don't know . we can make the list a little smaller . cuz , and keeping "" other "" , and then this north midland , we call it "" north midwest "" . south midwest , or just south midwest . does that make sense ? that would help me  cuz midland i don't know where midland is y one w  but , kansas would be south midland . right ? and wouldn't  th i 'm from kansas , actually .  colora right . and then , the dropping north , it would be western . it 's just one big shebang , where , you have huge variation in dialects , but do you   i don't know how it came from . that 's new england  pennsylvania has a pretty strong dialect and it 's different than   let 's just and we 'll see what we get . and you could say liverpool . actually , liverpool doesn't l  it 's i 'm s i ha it 's really great . m when you say "" slow "" , does that mean to  ",,
Bmr009.D,"it 's it 's the redrawing of the w  w as you move .   is there any hope for actually displaying the wave form ?   i 'm i probably would be trying to use the whatever 's there . and it 's useful to have the  i wonder i 'm just wondering if we can display things other than the wave form . suppose we have a feature stream . and it 's just , a uni dimensional feature , varying in time . and we want to plot that , instead of the whole wave form . that might be faster . right ?   i 'll talk to you about it and we can see but it 's definitely great to have the other one . that 's right .   they could do it and it would be fast enough if they do it ? or ?    i actually have to leave . had to leave at three thirty , can for the digits but i can't stay for the discussion i c i have to make a call .   no , do digits if but i don't wanna butt in , but if there 's something on the rest of the i 'm i 'll be around just have to make call before quarter of .   or we can talk about it . alright . this is the new one . alright . the and the time is .  ",is there any hope for actually displaying the wave form ? ,
Bmr009.E,"    the @ @  hi .  no .        how            this is the first derivate of log of frame energy without any normalization . these the these are the first experiments with comment   here i in no i haven't the result but it 's the the following .   catal combining the different possibilities of the parameters . the scatter plot combining different n two combination . combination of two , of energy and derivate  that 's right .          i agree ,      but   but it 's curious but f i found it in the mixed file , in one channel that in several several times you have an speaker talking alone with a high level of energy in the middle zone of overlapping with less energy and come with another speaker with high energy and the overlapping zone has less energy . because there reach very many   just locally ,     this is the          to study individual ? to study individual ? the but consider    i don't consi now i don't consider that possibility . this is a s a general studio of the overlapping we 're studying the i   consider different class of overlap ? if there 's time .   this is the thing i comment with you before , that we have a great variation of th situation of overlapping . and the behavior for energy is , log energy , is not the same all the time . and             but       this is a good idea . not consider the log energy . the ? i 'm preparing the program but i don't begin because saw your email and i agree with you it 's better to i suppose it 's better to consider the energy this parameter bef i go on with the pitch , aha ! i understood that had to finish by the moment with the and concentrate my energy in that problem .  i go on with the pitch .      i would think it 's interesting ,     another parameter we c we can consider is the duration . another e m besides the class of overlap , the duration . because is possible some s some classes has type of a duration , a duration very short when we have overlapping with speech . is possible to have . and it 's interesting , to consider the window of normalization , normalization window . because if we have a type of , a overlap , backchannel overlap , with a short duration , is possible to normali i that if we normalize with consider only the window by the left ri side on the right side overlapping with a very small window the if the fit of normalization is bigger in that overlapping zone very short i me i understand . that you have you have a backchannel , you have a overlapping zone very short and you consider all the channel to normalize this very short  and the energy is not height ","this is the thing i comment with you before , that we have a great variation of th situation of overlapping . this is a good idea . not consider the log energy . another parameter we c we can consider is the duration . because is possible some s some classes has type of a duration , that you have you have a backchannel , you have a overlapping zone very short ",
Bmr009.E,"think if you consider all the channel to normalize and the channel is bigger compared with the overlapping duration , the effect is stronger that the e effect of the normalization with the mean and the variance is different that if you consider only a window compared with the n the duration of overlapping . not    i don't know . is s if   this is the idea , to consider only the small window near the overlapping zone .        give you my transcription file , no ?  yes    it 's the same . no . is new is i  me too .  but i am put i am putting the beginning of the meeting . in on there .     and the seat is this number ? "" use only ""       what  what i  and for simple for me ? is mean my native language spanish ? the original is the center of spain and the beca because is different , the span the spanish language from the north of spain , of the south , of the west and the but .  i at this in that side of the paper .  a techno is different . is different .       and is in those and if you put  if you put the state ?       and and usually here people here is their lang english language ? here is easy for people to know ? because you have n m or boston ?  style .     south midwest ? southern midland .                    ",that the e effect of the normalization with the mean and the variance is different that if you consider only a window compared with the n the duration of overlapping . ,
Bmr010.A,"we seem to be recording . about not not pre doing everything . the lunch went a little later than i was expecting , chuck .   no . we don't want anything too practical . that would be we have steps forward . i have a little bit of iram but i 'm not if that 's of general interest or not . iram . iram , bigram ,  what 's the interesting and did you hand label who was loud and who was quiet , or did you just ? right . right . this would work for , pauses and utterance boundaries and things like that . but for overlap i imagine that doesn't work that you 'll have plenty of s sections that are but  it was is two . we should get it and if it 's good enough we 'll arrange windows machines to be available .   no , no . praat isn't praat 's multi platform .  what our decision was is that we 'll go ahead with what we have with a not very fine time scale on the overlaps . and do what we can later to clean that up if we need to . and did you , forward morgan brian 's thing ? you did ? you probably did get that .  and dave gelbart did volunteer , and since he 's not here , i 'll repeat it to at least modify transcriber , which , if we don't have something else that works , that 's a pretty good way of going . and we discussed on some methods to do it . my approach originally , and i 've already hacked on it a little bit it was too slow because i was trying to display all the waveforms . but he pointed out that you don't really have to . that 's a good point . that if you just display the mix waveform and then have a user interface for editing the different channels , that 's perfectly sufficient . no . they can only display one , but they can listen to different ones . but only to listen to , not to look at . the waveform you 're looking at doesn't change .  right . right . we should definitely get with them then , and agree upon a format . though i don't remember email on that . was i not in the loop on that ?  that 's right . just , right . it 's important both for the notation and the machine representation to be the same .   cross correlation .  although the using the close talking would be much better . wouldn't it ?  right . right . and i hope that if we do a forced alignment with the close talking mike , that will be enough to recover at least some of the time information of when the overlap occurred . who knows ? u ibm was going to .  and i imagine they still plan to ","right . this would work for , pauses and utterance boundaries and things like that . we should get it and if it 's good enough we 'll arrange windows machines to be available . no , no . praat isn't praat 's multi platform . what our decision was is that we 'll go ahead with what we have with a not very fine time scale on the overlaps . no . they can only display one , we should definitely get with them then , agree upon a format . cross correlation . and i hope that if we do a forced alignment with the close talking mike , that will be enough to recover at least some of the time information of when the overlap occurred . ","The Berkeley Meeting Recorder group talked about the ongoing transcription effort and issues related to the Transcriber tool, which despite its limitations for capturing tight time markings for overlapping speech, will continue to remain in use. "
Bmr010.A,"but , i haven't spoken with them about that recently . i 'll do that .  right . is he on the mailing list ? the meeting recorder mailing li ? we should add him . add him .  one thing is that i did look on sony 's for a replacement for the mikes for the head m head worn ones cuz they 're uncomfortable . but need someone who knows more about mikes than i do , because i couldn't find a single other model that seemed like it would fit the connector , which seems really unlikely to me . does anyone know stores or know about mikes who would know the right questions to ask ?   when i looked , i they listed one microphone and that 's it as having that type of connector . but my guess is that sony uses a different number for their connector than everyone else does . and it seems really unlikely to me that there 's only one . as i said , who knows ?  i have it downstairs . i don't remember off the top of my head . and then , just in terms of how you wear them i had thought about this before . when you use a product like dragondictate , they have a very extensive description about how to wear the microphone and on . but i felt that in a real situation we were very seldom gonna get people to really do it and it wasn't worth concentrating on . but  that 's true .  right . i 'll dig through the documentation to dragondictate and ste s see if they still have the little form . that 's the it seemed to me when i was using dragon that it was really microphone placement helped an in , an enormous amount . you want it enough to the side that when you exhale through your nose , it doesn't the wind doesn't hit the mike . and then , everyone 's adjusting their microphones , and then just close enough that you get good volume . wearing it right about here seems to be about the right way to do it .  when it 's on , you can see it . you can definitely see it .   and i 've sat here and watched sometimes the breathing , and the bar going up and down , and i 'm thinking , i could say something , but i don't want to make people self conscious . stop breathing ! right .  and then also the position of the mike also . if it 's more directly , you 'll get better volume . yours is pretty far down below your mouth . i don't know why that is . i 've been eating a lot .  mark them ? great . against they could do forced alignment . i didn't know that . that would be a really interesting prosodic feature , when right . ","one thing is that i did look on sony 's for a replacement for the mikes for the head m head worn ones cuz they 're uncomfortable . it seemed to me when i was using dragon that it was really microphone placement helped an in , an enormous amount . you want it enough to the side that when you exhale through your nose , it doesn't the wind doesn't hit the mike . and then just close enough that you get good volume . ","Recording equipment and procedures were discussed, with a focus on audible breathing and the need for standards in microphone wear and use. "
Bmr010.A,"are do you treat breath and laughter as phonetically , or as word models , or what ?  mouth how would we do that with the hybrid system ? train a phone in the neural net ? it does ? right . in the hybrid system we could train the net with a laughter phone and a breath sound phone . do whatever you want . to go on forever ? and how do you handle it in the language model ? it 's just a word in the language model .    can you hand me your digit form ? wanna mark that you did not read digits . i was noticing that with dan in the one that we , we hand tran hand segmented , that th he has these little chuckles as he talks . speech researchers ? cuz they 're gonna be transcribing it in a few days . that 's a good idea . good . no . is that good or bad ?  you 'll self repair .   where were they when we needed them ? this was something that we were talking about . we could get a very detailed overlap if they were willing to transcribe each meeting four or five times . right ? one for each participant . they could by hand   is two thousand one ? calendar year or ?  full time .   i don't see how someone could do forty hours a week on transcription . it would be we 'd have to mark them . it would also be interesting to have , a couple of the meetings have more than one transcriber do , cuz i 'm curious about inter annotator agreement . wrong . it just whoever is interested can do that . if someone wants to use that data we could skip the digits . we don't have to read digits each time .  with what ? scale .  with that 's right . but javier 's javier 's might be able to . it doesn't have the same gaus h m modeling , which is drawback . but , does it ?  and then he ch you choose optimal splitting . 'm misremembering , but i did not think it had a markov  i didn't think  and think it would work fine for detecting overlap . it 's just , that i it he has the two pass issue that what he does is , as a first pass he p he does , a guess at where the divisions might be and he overestimates . and that 's just a data reduction step , that you 're not trying at every time interval . and those are the putative places where he tries . and right now he 's doing that with silence and that doesn't work with the meeting recorder . if we used another method to get the first pass , it would probably work . it 's a good method . ","it would also be interesting to have , a couple of the meetings have more than one transcriber do , cuz i 'm curious about inter annotator agreement . ",
Bmr010.A,"as long as the len as long the segments are long enough . that 's the other problem . right .  javier 's ? what do i i had tried doing it by hand at one point with a very short sample , and it worked pretty but i haven't worked with it a lot . what i d i took a hand segmented sample and i added ten times the amount of numbers at random , and it did pick out pretty good boundaries . but this was just very anecdotal thing . right . if we fed the hand segmentation to javier 's and it doesn't work , then we know something 's wrong . that 's probably worthwhile doing . whether it 'll work or not .   y do where his software is ? have you used it   i have as if you need help let me know .  uuh and we are ","right . if we fed the hand segmentation to javier 's and it doesn't work , then we know something 's wrong . that 's probably worthwhile doing . ",
Bmr010.B,"chuck was telling too many jokes ,  since , since i have to leave as usual at three thirty , can we do the interesting first ? the work that 's been done on segmentation would be most  w what ? what front end processing did you do ?   but you s but about the need for transcription , don't we didn't we previously decide that the ibm transcripts would have to be checked anyway and possibly augmented ? having a good tool is worth something no matter what . who 's gonna do that ? who 's gonna do forced alignment ?   he asked for more work . it 's interesting ,  i talked to some ibm guys , last january , i was there . and people who were working on the on their viavoice dictation product . and they said , the breathing is really a terrible problem for them , to not recognize breathing as speech . anything to reduce breathing is a good thing .  right .  but , just to , one more remark , concerning the sri recognizer .  it is useful to transcribe and then ultimately train models for things like breath , and also laughter is very , very frequent and important to model .  if you can in your transcripts mark mark very audible breaths and laughter especially ,      it 's not don't think it 's , as long as there is an indication that there was laughter somewhere between two words that 's sufficient , because actually the recognition of laughter once you kn is pretty good . as long as you can stick a a t a tag in there that indicates that there was laughter , that would probably be , sufficient to train models .   right . the thing that you is hard to deal with is whe when they speak while laughing . and that 's , don't think that we can do very with that .  but , that 's not as frequent as just laughing between speaking ,  we tried both . currently , we use special words . there was a there 's actually a word for it 's not just breathing but all kinds of mouth mouth and then laughter is a special word . same thing ?  you ha and each of these words has a dedicated phone . the mouth noise , word has just a single phone , that is for that .   and the pronun the pronunciations are l are somewhat non standard . they actually are it 's just a single , s a single phone in the pronunciation , but it has a self loop on it , it can r can go on forever . it 's just a word . we train it like any other word .  we also tried , absorbing these both laughter and actually also noise , and , yes .  anyway . we also tried absorbing that into the pause model the model that matches the between words . ","anything to reduce breathing is a good thing . one more remark , concerning the sri recognizer . it is useful to transcribe and then ultimately train models for things like breath , and also laughter is very , very frequent and important to model . the thing that you is hard to deal with is whe when they speak while laughing . ","Recording equipment and procedures were discussed, with a focus on audible breathing and the need for standards in microphone wear and use. "
Bmr010.B,"and , it didn't work as  ",,
Bmr010.C," i would prefer this . which is ?   speech nonspeech ?  what we did far was using the mixed file to detect s speech or nonspeech portions in that . and what i did far is used our old munich system , which is an ba based system with gaussian mixtures for s speech and nonspeech . and it was a system which used only one gaussian for silence and one gaussian for speech . and now i added , multi mixture possibility for speech and nonspeech . and i did some training on one dialogue , which was transcribed by we did a nons s speech nonspeech transcription . adam , dave , and i , we did , for that dialogue and i trained it on that . and i did some pre segmentations for jane . and i 'm not how good they are or what the transcribers say . they can use it or ?   that was one thing , why i added more mixtures for the speech . saw that there were loud loudly speaking speakers and quietly speaking speakers . and did two mixtures , one for the loud speakers and one for the quiet speakers . i did that for five minutes of one dialogue and that was enough to train the system . and it adapts , on while running .  hopefully . it 's just our old munich , loudness based spectrum on mel scale twenty critical bands and then loudness . and four additional features , which is energy , loudness , modified loudness , and zero crossing rate . it 's twenty four features .    you can specify the minimum length of speech or and silence portions which you want . and did some modifications in those parameters , changing the minimum length for s for silence to have , er to have ,  to have more or less , silence portions in inserted .      that 's it .   no . no . w we originally we did that but we saw , when we used it , f for our close talking microphone , which for our recognizer in munich we saw that w it 's not it 's not necessary . it works as with without , a lda   yes . i talked with , munich guys from ludwi ludwig maximilians university , who do a lot of transcribing and transliterations . and they said they have , a tool they developed themselves and they can't give away , f it 's too error prone , and had it 's not supported , a and but , susanne bur burger , who is at se cmu , he wa who was formally at in munich and w and is now at with cmu , she said she has something which she uses to do eight channels , trans transliterations , eight channels simultaneously , but it 's running under windows . 'm not if we can use it . she said she would give it to us . ","what we did far was using the mixed file to detect s speech or nonspeech portions in that . and what i did far is used our old munich system , which is an ba based system with gaussian mixtures for s speech and nonspeech . and it was a system which used only one gaussian for silence and one gaussian for speech . and now i added , multi mixture possibility for speech and nonspeech . and i did some training on one dialogue , which was transcribed by we did a nons s speech nonspeech transcription . and i did some pre segmentations for jane . and i 'm not how good they are or what the transcribers say . saw that there were loud loudly speaking speakers and quietly speaking speakers . and did two mixtures , one for the loud speakers and one for the quiet speakers . it 's just our old munich , loudness based spectrum on mel scale twenty critical bands and then loudness . and four additional features , which is energy , loudness , modified loudness , and zero crossing rate . you can specify the minimum length of speech or and silence portions which you want . changing the minimum length for s for silence to have more or less , silence portions in inserted . no . w we originally we did that for our recognizer in munich we saw that w it 's not it 's not necessary . it works as with without , a lda susanne bur burger , who is at se cmu , he wa who was formally at in munich and w and is now at with cmu , she said she has something which she uses to do eight channels , trans transliterations , ",Speaker mn014 explained his efforts to pre-segment the signal into speech and non-speech portions for facilitating transcriptions. 
Bmr010.C,"it wouldn't be a problem . and i 've got some manual down in my office .  but then i 'm not that 's the right thing for us . no . no , praat   that 's not praat . it 's called "" trans transedit "" the , the tool from susanne .      cross            no . no .    but i 'm not too if we can really represent overlap with the s detector i used up to now , the to speech nonspeech as it 's only speech or it 's it 's nonspeech .    i could have a look at it .             i 'm not about , adding , another class too . but it 's not too easy , the transition between the different class , to model them in the system i have now . but it could be possible , in principle .    i had the impression .         ","about , adding , another class too . ",
Bmr010.D,"number four . we talk about the results of use iram . bi bigram .     nnn ,     jose .       right .       what are the different , classes to code , the overlap , you will use ? what you   look like , you t you explaining in the blackboard ? the ?      we hope .                 it 's frequent in the meeting .  no .     speech research .            what do you want ?  it 's prepared . it 's fast , because , i have the results , of the study of different energy without the law length .  in the measurement , the average , dividing by the , variance . i th i the other , the last w meeting i don't know if you remain we have problem to with the parameter with the representations of parameter , because the valleys and the peaks in the signal , look like , it doesn't follow to the energy in the signal . and it was a problem , with the scale . the scale . and i change the scale and we can see the variance .   the distribution is similar .                     that , the possibility , can be that , thilo , working , with a new class , not only , nonspeech and speech , but , in the speech class , dividing , speech , of from a speaker and overlapping , to try to do , a fast a fast , experiment to prove that , nnn , this fea general feature , can solve the problem , and wh what nnn , how far is and , i have prepared the pitch tracker now . and i hope the next week i will have , some results and we will show we will see , the parameter the pitch , tracking in with the program . and , nnn no .            javier ja javier program ? no , javier di doesn't worked with , a markov he on only train it was only gaussian . this is the idea .             to overrule ,    one . but , what did you think about the possibility of using the javier software ? the , the bic criterion , the t to train the gaussian , using the mark , by hand , to distinguish be to train overlapping zone and speech zone . that an interesting , experiment , could be , th to prove that , if s we suppose that , the first step the classifier what were the classifier from javier or classifier from thilo ? w what happen with the second step ? what happen with the , the , clu the , the clu the clustering process ? using the gaussian .  that is enough , to work to , separate or to distinguish , between overlapping zone and , speaker zone ? because th if we , nnn , develop an classifier and the second step doesn't work we have another problem . n nnn ,   but is if ","what are the different , classes to code , the overlap , you will use ? because , i have the results , of the study of different energy without the law length . the other , the last w meeting we have problem to with the parameter with the representations of parameter , because the valleys and the peaks in the signal , look like , it doesn't follow to the energy in the signal . and it was a problem , with the scale . and i change the scale and we can see the variance . and , i have prepared the pitch tracker now . and i hope the next week i will have , some results and we will show we will see , the parameter the pitch , tracking in with the program . but , what did you think about the possibility of using the javier software ? using the mark , by hand , to distinguish be to train overlapping zone and speech zone . ","And, finally, it was determined that speaker mn005's efforts to detect speaker overlap using energy should instead be focussed on pitch- and harmonicity-related features or be guided by a non-featural, statistical approach, i.e. via the use of Markov models. "
Bmr010.D,"but it 's possible with my segmentation by hand that we have information about the overlapping ,  the n no . the demonstration by hand . segmentation by hand is the fast experiment . we can prove that the this kind o emph emphasises parameter and gaussian i have . i have .  ","but it 's possible with my segmentation by hand that we have information about the overlapping , ",
Bmr010.E,"  specify . meeting recorder . did something happen , morgan , that he got put on this , or was he already on it , or ?  you couldn't find the right connector to go into these things ?  turn the mikes off and let 's talk . are they working full time now , or ?  ",,
Bmr010.F,"i 'm i sent a couple of items . they 're practical . i don't know if you 're if that 's too practical for what we 're focused on .  give you an update on the transcription effort . raise the issue of microphone , procedures with reference to the cleanliness of the recordings . and then ask , th these guys . the we have great , p steps forward in terms of the nonspeech speech pre segmenting of the signal . it 's a big improvement . i beg your pardon ? i beg your pardon ? that would be a good thing to start with .  do i hear you didn't   they think it 's a terrific improvement . and , it real it just makes a world of difference . and , y you also did some something in addition which was , for those in which there was , quiet speakers in the mix . and you also provided me with several different versions , which i compared . and you change parameters . what do you wanna say something about the parameters that you change ?  that 's true . but it saves much time the transcribers just enormous , enormous savings . fantastic .   but then there 's another thing that also thilo 's involved with , which is , and also da dave gelbart . there 's this problem of and w and we had this meeting . th the also adam , before the before you went away . we , regarding the representation of overlaps , because at present , because of the limitations of th the interface we 're using , overlaps are , not being encoded by the transcribers in as complete and , detailed a way as it might be , and as might be desired would be desired in the corpus ultimately . we don't have start and end points at each point where there 's an overlap . we just have the overlaps encoded in a simple bin . @ the limits of the over of the interface are such that we were at this meeting we were entertaining how we might either expand the interface or find other tools which already do what would be useful . because what would ultimately be , ideal in my view and mean , i had the sense that it was consensus , is that , a thorough going musical score notation would be the best way to go . because you can have multiple channels , there 's a single time line , it 's very clear , flexible , and all those things .  i spoke i had a meeting with dave gelbart on and he had , excellent ideas on how the interface could be modified to do this representation . but , he in the meantime you were checking into the existence of already , existing interfaces which might already have these properties . do you wanna say something about that ? under windows .   ","give you an update on the transcription effort . raise the issue of microphone , procedures with reference to the cleanliness of the recordings . the we have great , p steps forward in terms of the nonspeech speech pre segmenting of the signal . it 's a big improvement . they think it 's a terrific improvement . but it saves much time the transcribers because at present , because of the limitations of th the interface we 're using , overlaps are , not being encoded by the transcribers in as complete and , detailed a way as it might be , we don't have start and end points at each point where there 's an overlap . we just have the overlaps encoded in a simple bin . @ the limits of the over of the interface are such that we were at this meeting we were entertaining how we might either expand the interface or find other tools which already do what would be useful . because what would ultimately be , ideal in my view and mean , i had the sense that it was consensus , is that , a thorough going musical score notation would be the best way to go . because you can have multiple channels , there 's a single time line , it 's very clear , flexible , and all those things . ","The Berkeley Meeting Recorder group talked about the ongoing transcription effort and issues related to the Transcriber tool, which despite its limitations for capturing tight time markings for overlapping speech, will continue to remain in use. Recording equipment and procedures were discussed, with a focus on audible breathing and the need for standards in microphone wear and use. Speaker mn014 explained his efforts to pre-segment the signal into speech and non-speech portions for facilitating transcriptions. "
Bmr010.F,"we could potentially i also wanted to be i 've seen the this is called praat , which means spee speech in dutch but in terms of it being windows versus but i 'm just wondering , is ? i see . i see . praat may not be it 's a different one . i see . i see . alright .    and i was just thinking that , if it were possible to bring that in this week , then when they 're encoding the overlaps it would be for them to be able to specify when the start points and end points of overlaps . th they 're making really quick progress . and , my goal was w m my charge was to get eleven hours by the end of the month . and it 'll be i 'm i 'm clear that we 'll be able to do that . i sent it to ,  who did i send that to ? i sent it to a list and sent it to the e to the local list . you saw that ? brian did tell me that what you said , that , that our that they are making progress and that he 's going that they 're going he 's gonna check the f the output of the first transcription and and that 's this is a new development .  super . super . great .  isn't that great ? yes . that 's true .  good .   exactly . and just keep those things separate . and , dan ellis 's hack already allows them to be able to display different waveforms to clarify overlaps and things , that 's already yes , but yes , but what is that , from the transcriber 's perspective , those two functions are separate . and dan ellis 's hack handles the , choice the ability to choose different waveforms from moment to moment .  that 's true .  but that 's cuz they 're , they 're focused on the ear anyway . and then and then the hack to preserve the overlaps better would be one which creates different output files for each channel , which then would also serve liz 's request of having , a single channel , separable , cleanly , easily separable , transcript tied to a single channel , audio . not directly . i 'm trying to think if i could have gotten it over a list . i don't think this was from before december .   that 's right .  i 'm keeping the conventions as simple as possible .  n there was also this , email from dan regarding the speech non nonspeech segmentation thing . i don't know if ,  we wanna ,  and dan gel and dave gelbart is interested in pursuing the aspect of using amplitude as a as a basis for the separation . cross    fantastic . ","this is called praat , which means spee speech in dutch and i was just thinking that , if it were possible to bring that in this week , then when they 're encoding the overlaps it would be for them to be able to specify when the start points and end points of overlaps . th they 're making really quick progress . and , dan ellis 's hack already allows them to be able to display different waveforms to clarify overlaps and things , yes , but what is that , from the transcriber 's perspective , those two functions are separate . and dan ellis 's hack handles the , choice the ability to choose different waveforms from moment to moment . the hack to preserve the overlaps better would be one which creates different output files for each channel , which then would also serve liz 's request of having , separable , cleanly , easily separable , transcript tied to a single channel , audio . i 'm keeping the conventions as simple as possible . and dan gel and dave gelbart is interested in pursuing the aspect of using amplitude as a as a basis for the separation . ",
Bmr010.F,"cuz there is one thing that we don't have right now and that is the automatic , channel identifier . that , that would g help in terms of encoding of overlaps . the transcribers would have less , disentangling to do if that were available . but .     to code d types of overlap ? at a meeting that wasn't transcribed , we worked up a typology . and , yes , exactly . that hasn't changed .  it i the it 's two tiered structure where the first one is whether the person who 's interrupted continues or not . and then below that there 're subcategories , that have more to do with , is it , simply backchannel or is it , someone completing someone else 's thought , or is it someone in introducing a new thought . one would that 'd be i i 've this is wonderful to have a direct contact like that . th lemme ask you this . it occurs to me one of my transcribers t told me today that she 'll be finished with one meeting , by she said tomorrow but then she said but the , let 's just , say the day after just to be s on the safe side . i could send brian the , the transcript . i know these are er , i could send him that if it would be possible , or a good idea or not , to try to do a s forced alignment on what we 're on the way we 're encoding overlaps now . good .  super . super .   i don't know for that would be like that 'd be like him . he 's great . that 'd be great . and there 's no adaptor for it ? seems like there 'd be a     is  that 's interesting . what i wondered is whether it 's possible to have to use the display at the beginning to be able to judge how correctly have someone do some routine whatever , and then see if when they 're breathing it 's showing . i don't know if the if it 's can you see the breathing ? cuz i   good . i that 's true . it just seems like i if something l simple like that can be tweaked and the quality goes , dramatically up , then it might be worth doing . but  my feedback from the transcribers is he is always close to crystal clear and just fan fantastic to you you 're also your volume is greater . but still , they say i it makes their job extremely easy .   i could say something about the i don't you wanna do . about the transcribers or anything or ? i don't know . they are . they 're putting in curly brackets they put "" inhale "" or "" breath "" . it they and then in curly brackets they say "" laughter "" . ","cuz there is one thing that we don't have right now and that is the automatic , channel identifier . that , that would g help in terms of encoding of overlaps . the transcribers would have less , disentangling to do if that were available . types of overlap ? it i the it 's two tiered structure where the first one is whether the person who 's interrupted continues or not . and then below that there 're subcategories , that have more to do with , is it , simply backchannel or is it , someone completing someone else 's thought , or is it someone in introducing a new thought . they 're putting in curly brackets they put "" inhale "" or "" breath "" . it they and then in curly brackets they say "" laughter "" . ",
Bmr010.F,"now they 're not being awfully precise , m they 're two types of laughter that are not being distinguished . one is when sometimes s someone will start laughing when they 're in the middle of a sentence . and then the other one is when they finish the sentence and then they laugh . i did s i did some double checking to look through you 'd need to have extra e extra complications , like time tags indicating the beginning and ending of the laughing through the utterance . and that and what they 're doing is in both cases just saying "" curly brackets laughing "" a after the unit . good .    then and let me ask y and i gotta ask you one thing about that .  if they laugh between two words , you 'd get it in between the two words . but if they laugh across three or four words you get it after those four words . does that matter ?  he 's right .    good . you did get me to thinking about i 'm not really which is more frequent , whether f laughing it may be an individual thing . some people are more prone to laughing when they 're speaking . but i can't    the i 'm really very for i 'm extremely fortunate with the people who , applied and who are transcribing for us . they are , really perceptive and very , and i 'm not just saying that cuz they might be hearing this . no , they 're super . they 're the they very quick . i know . i am i 'm serious . they 're just super . e i brought them in and , trained them in pairs because people can raise questions i the they think about different things and they think of different and i trained them to , f on about a minute or two of the one that was already transcribed . this also gives me a sense of use that later , with reference to inter coder reliability issues . but the main thing was to get them used to the conventions and , the idea of the th the size of the unit versus how long it takes to play it back these th calibration issues . and then , set them loose and they 're they all have e a already background in using computers . they 're , they 're trained in linguistics . they got they 're very perce they 'll one of them said "" he really said "" n "" , not really "" and "" , what should i do with that ? "" and i said , "" for our purposes , i do have a convention . if it 's an a noncanonical p "" that one , we with eric 's work , i figure we can just treat that as a variant . ",,
Bmr010.F,"but i told them if there 's an obvious speech error , like i said in one thing , and i gave my example , like i said , "" microfon "" in instead of "" microphone "" . didn't bother i knew it when i said it . i remember s thinking "" that 's not correctly pronounced "" . but it but it 's not worth fixing cuz often when you 're speaking everybody knows what but i have a convention that if it 's noncanonical pronunciation a speech error with wi within the realm of resolution that you can tell in this native english american english speaker , that i didn't mean to say "" microfon . "" then you 'd put a little tick at the beginning of the word , and that just signals that , this is not standard , and then in curly brackets "" pron error "" . and , and other than that , it 's w word level . but , the fact that they noticed , the "" nnn "" . "" he said "" nnn "" , not "" and "" . what shall i do with that ? "" they 're very perceptive . and s several of them are trained in ipa . c they really could do phonetic transcription if we wanted them to .  and i 'm also thinking these people are a terrific pool . if , told them that , we don't know if this will continue past the end of the month and i also m i think they know that the data p source is limited and i may not be able to keep them employed till the end of the month even , although i hope to . and that 'd be super . they would be terrific . that 's right . and with the right in interface  that 'd be great .   wonderful .  wonderful . and then school will start in the sixt on the sixteenth . some of them will have to cut back their hours at that point . but some of them are .  why do i wouldn't say forty hour weeks . no . but what is i shouldn't say it that way because that does sound like forty hour weeks . no . i th i would say they 're probably they don't have o they don't have other things that are taking away their time . but it 's you can't . no . you 're right . it 's i it would be too taxing . but , they 're putting in a lot of and i checked them over . i haven't checked them all , but just spot checking . they 're fantastic .  and i also thought , y liz has this , and i do also , this interest in the types of overlaps that are involved . these people would be great choices for doing coding of that type if we wanted , or whatever .    ","and i also thought , y liz has this , and i do also , this interest in the types of overlaps that are involved . these people would be great choices for doing coding of that type if we wanted , ",
Bmr010.F,"th that 'd be that 's a good idea . there 's also , the e in my mind , an andreas was leading to this topic , the idea that , we haven't yet seen the type of transcript that we get from ibm , and it may just be , pristine . but on the other hand , given the lesser interface cuz this is , we 've got a good interface , we 've got great headphones , m  something like that . that 's true . al although you have to s don't you have to start with a close enough approximation of the verbal part to be able to ?     excellent .   excellent . there 's another aspect , too , and i don't know this is very possibly a different , topic . but , just let me say with reference to this idea of , higher order organization within meetings . like in a the topics that are covered during a meeting with reference to the other , uses of the data , being able to find where and talked about such and such , then , e i did rough pass on encoding episode like level things on the , transcribed meeting already transcribed meeting . and i don't know if , where that i if that 's something that we wanna do with each meeting , like a , it 's like a manifest , when you get a box full of or if that 's , i don't level of detail would be most useful . i don't if that 's something that i should do when i look over it , or if we want someone else to do , or whatever . but this issue of the contents of the meeting in an outline form .   that 's fine . i 'm finished .  yes .  k scale .      he has this on his board actually . don't you have , like those several different categories on the board ?  ",,
Bmr010.G,"alright ! we 're not crashing .  does anybody have an agenda ? somebody had . that 's right . we only want th useless things .  no , why don't we talk about practical things ?  great . transcription , microphone issues  yes .    you have some   bigram ? iram . m let 's see where we are at three thirty .   th now you get to tell us what 's the interesting part . but  and , the other thing , which i 'll just say very briefly that relates to that a little bit , which is that , one of the suggestions that came up in a brief meeting i had the other day when i was in spain with , manolo pardo and javier , ferreiros , who was here before , was , why not start with what they had before but add in the non silence boundaries . in what javier did before when they were doing , h he was looking for , speaker change points .  as a simplification , he originally did this only using silence as , a putative , speaker change point . and , he did not , say , look at points where you were changing broad sp phonetic class , and for broadcast news , that was fine . here it 's not . and , one of the things that they were pushing in d in discussing with me is , w why are you spending much time , on the , feature issue , when perhaps if you deal with what you were using before and then just broadened it a bit , instead of just ta using silence as putative change point also ? then you 've got you already have the super structure with gaussians and h simple h m ms and forth . and you might there was a little bit of a difference of opinion because that it was it 's interesting to look at what features are useful . but , on the other hand i saw that the they had a good point that , if we had something that worked for many cases before , starting from there a little bit because ultimately we 're gonna end up with some s su structure like that , where you have some simple and you 're testing the hypothesis that , there is a change .  anyway , reporting that . but , why don't we do the speech nonspeech discussion ?        that 's great . just qu one quickly , still on the features . you have these twenty four features . a lot of them are spectral features . is there a transformation , like principal components transformation just  no , i was j curious . i don't think it 's a big deal for this application , but it 's a     excuse me .  the other thing , to keep in mind , mean , we 've been very concerned to get all this rolling ","is there a transformation , like principal components transformation ",
Bmr010.G,"that we would actually have data , but , our outside sponsor is actually gonna kick in and ultimately that path will be smoothed out . don't know if we have a long term need to do lots and lots of transcribing . we had a very quick need to get something out and we 'd like to be able to do some later because just it 's inter it 's interesting . but as far a with any luck we 'll be able to wind down the larger project . right .  right .   that 's great . that 's great .  it 's all the difference in the world . he 's on it now . this is it 'll happen . it 's just saying that one of our best people is on it , who just doesn't happen to be here anymore . someone else pays him .    s that 's a good point .      have , folks from nist been in contact with you ?  holidays may have interrupted things , cuz in they seem to want to get clear on standards for transcription standards and forth with us . right . because they 're presumably going to start recording next month .  i don't mailed anybody . told them to contact jane that , if they had a if , that , as the point person on it . but 'll , ping them a little bit about it to get that straight . is it cuz with any luck there 'll actually be a there 'll be collections at columbia , collections at uw dan is very interested in doing some other things , and collections at nist .   he was talking we he had cross correlation . i had mentioned this a couple times before , the c the commercial devices that do , voice , active miking , look at the amp at the energy at each of the mikes . and you compare the energy here to some function of all of the mikes .  by doing that , rather than setting any , absolute threshold , you actually can do pretty good , selection of who 's talking .  and those systems work very people use them in panel discussions and forth with sound reinforcement differing in  and , those if boy , the guy i knew who built them , built them like twenty years ago , they 're it 's the techniques work pretty   think , you can look at some p you have to play around a little bit , to figure out what the right statistic is , but you compare each microphone to some statistic based on the overall and we also have these we have the advantage of having distant mikes too . that , you cou yo i don't know . it 'd be if i was actually working on it , i 'd sit there and play around with it , and get a feeling for it . the the ,  but , ","have , folks from nist been in contact with you ? they seem to want to get clear on standards for transcription standards and forth with us . i had mentioned this a couple times before , the c the commercial devices that do , voice , active miking , look at the amp at the energy at each of the mikes . and you compare the energy here to some function of all of the mikes . by doing that , rather than setting any , absolute threshold , you actually can do pretty good , selection of who 's talking . ",
Bmr010.G,"you certainly wanna use the close talking , as a at least . i don't know if the other would add some other helpful dimension or not . my suggestion now is on all of these things to , contact brian .     just talk to him about it . he 's he just studies , he 's a colleague , a friend , and , they and , the organization always did wanna help us . it was just a question of getting , the right people connected in , who had the time .    no , i , p it oc i h it 's something happened . i don't but he 's on it now . right .  where are we ? brief let 's why don't we talk about microphone issues ? that was a i probably would . my knowledge is twenty years out of date but some of it 's still the same .  we c we can take a look at that .  let 's look at it together and who are we buying these from ? that 'd be   we can try and look at that together . that 's a good back off position . that 's what i was saying earlier , th that , we are gonna get some recordings that are imperfect and , hey , that 's life . but that it doesn't hurt , the naturalness of the situation to try to have people wear the microphones properly , if possible , because , the natural situation is really what we have with the microphones on the table . in the target applications that we 're talking about , people aren't gonna be wearing head mounted mikes anyway . this is just for u these head mounted mikes are just for use with research . and , it 's gonna make if an andreas plays around with language modeling , he 's not gonna be m wanna be messed up by people breathing into the microphone . it 's , but it does happen . right ? and any    i remember when i was when i used , a prominent laboratory 's , speech recognizer about , this was , boy , this was a while ago , this was about twelve years ago and , they were perturbed with me because i was breathing in instead of breathing out . and they had models for they had markov models for br breathing out but they didn't have them for breathing in .  i  i  it 's going to be imperfect . you 're not gonna get it perfect . and you can do some , first order thing about it , which is to have people move it , a away from being just directly in front of the middle but not too far away . and then , there 's not much because you can't al interfere w you can't fine tune the meeting that much , it 's   and then there 's mass . anyway . ","let 's why don't we talk about microphone issues ? but that it doesn't hurt , the naturalness of the situation to try to have people wear the microphones properly , if possible , ","Recording equipment and procedures were discussed, with a focus on audible breathing and the need for standards in microphone wear and use. "
Bmr010.G,"about what ? the other why don't we do that ?  is it ? same thing . no  it 's it 's always the same thing . right ? you could say let we now think that laughter should have three sub units in the three states , different states . and then you would have three it 's u    say hi for me .   i 'm it 's very individual . and one thing that c that we 're not doing , is we 're not claiming to , get be getting a representation of mankind in these recordings . we have this very , very tiny sample of  and r right . who knows .  why don why don't we just since we 're on this vein , why don't we just continue with , what you were gonna say about the transcriptions and ?    yes .   right . it might be something we 'd wanna do with some , s small subset of the whole thing . we certainly wouldn't wanna do it with everything .  the other thing we could do , actually , is , use them for a more detailed analysis of the overlaps . right ? that 's one way to do it . but i 've been saying the other thing is just go through it for the overlaps . right ? given that y and do instead of doing phonetic , transcription for the whole thing , which we know from the steve 's experience with the switchboard transcription is , very time consuming . and it took them i don't know how many months to do to get four hours . and that hasn't been really our focus . we can consider it . but , the other thing is since we 've been spending much time thinking about overlaps is get a much more detailed analysis of the overlaps . but anyway , i 'm open to c our consideration . i don't wanna say that by fiat . i 'm open to every consideration of what are some other kinds of detailed analysis that would be most useful . and , this year we actually , can do it . it 's a we have due to @ @ variations in funding we have we seem to be doing , very on m money for this year , and next year we may have much less . don't wanna hire a calendar year two thousand one . it 's it 's we don't wanna hire a bunch of people , a long term staff , because the funding that we 've gotten is big chunk for this year . but having temporary people doing some specific thing that we need is actually a perfect match to that funding .     i i remember when we were transcribing berp , ron volunteered to do some of that . and , he was the first he did was transcribing chuck . and he 's saying "" i always thought chuck spoke really ""    ","the other thing we could do , actually , is , use them for a more detailed analysis of the overlaps . ",
Bmr010.G,"it could be that they will theirs will end up being a fir first pass an elaborate one , cuz again they probably are gonna do these alignments , which will also clear things up . tha that 's debatable . right ? the argument is that if your statistical system is good it will clean things up . right ? it 's got its own objective criterion . and , in principle you could start up with something that was rough to give an example of , something we used to do , at one point , back when chuck was here in early times , is we would take , da take a word and , have a canonical pronunciation and , if there was five phones in a word , you 'd break up the word , into five equal length pieces which is completely gross . right ? th the timing is off all over the place in just about any word . but it 's o k . you start off with that and the statistical system then aligns things , and eventually you get something that doesn't really look too bad . think using a good aligner , actually can help a lot . but , they both help each other . if you have a better starting point , then it helps the aligner . if you have a good alignment , it helps the , th the human in taking less time to correct things .        meaning really isn't my thing .  we 're running a little short here . we , cou trying to was p the thing i 'm concerned about is we wanted to do these digits and i haven't heard , from jose yet .    it another bunch of digits . more data is good . 'd like to do that . but do you ,  did you prepare some whole thing you wanted us just to see ? or what was that ?  how long a ?  yes . right .  but the bottom line is it 's still not , separating out very right ?  that 's that 's enough then .  no , that there 's no point in going through all of that if that 's the bottom line , really . we have to start there 's two suggestions , really , which is , what we said before is that ,  it looks like , at least that you haven't found an obvious way to normalize that the energy is anything like a reliable , indicator of the overlap . i 'm still a little f think that 's a little funny . these things l @ @ seems like there should be , but you don't want to keep , keep knocking at it if it 's if you 're not getting any result with that . but , the other things that we talked about is , pitch related things and harmonicity related things , ","but the bottom line is it 's still not , separating out very but you don't want to keep , keep knocking at it if it 's if you 're not getting any result with that . but , the other things that we talked about is , pitch related things and harmonicity related things , ","And, finally, it was determined that speaker mn005's efforts to detect speaker overlap using energy should instead be focussed on pitch- and harmonicity-related features or be guided by a non-featural, statistical approach, i.e. via the use of Markov models. "
Bmr010.G,"which we thought also should be some reasonable indicator .  but , a completely different tack on it wou is the one that was suggested , by your colleagues in spain , which is to say , don't worry much about the , features . that is to say , use , as you 're doing with the speech , nonspeech , use some very general features . and , then , look at it more from the aspect of modeling . have a couple markov models and and , try to indi try to determine , w when is th when are you in an overlap , when are you not in an overlap . and let the , statistical system determine what 's the right way to look at the data . i , it would be interesting to find individual features and put them together . that you 'd end up with a better system overall . but given the limitation in time and given the fact that javier 's system already exists doing this thing , but , its main limitation is that , again , it 's only looking at silences which would that 's a better place to go .       i see . ha h have you ever looked at the , javier 's , speech segmenter ? you could , you kn show thilo that . cuz again the idea is there the limitation there again was that he was only using it to look at silence as a as a p putative split point between speakers . but if you included , broadened classes then in principle you can cover the overlap cases .  n it 's has a simple one . right ? it 's it 's just a isn't it just a gaussian for each ?  it doesn't have any temporal , it  i gues don't remember either . it 's been a while .  he 's just he just computes a gaussian over potential i see . i see . and o k let me go back to what you had , though .  the other thing one could do is couldn't it 's you have two categories and you have markov models for each . couldn't you have a third category ? you have , nonspeech , single person speech , and multiple person speech ? right ? and then you have a markov model for each ? i see . i see . i this is all pretty gross . the th the reason why , i was suggesting originally that we look at features is because we 're doing something we haven't done before , we should at least look at the space and understand it seems like if two people two or more people talk at once , it should get louder , and , there should be some discontinuity in pitch contours , ","a completely different tack on it wou is the one that was suggested , by your colleagues in spain , which is to say , don't worry much about the , features . that is to say , use , as you 're doing with the speech , nonspeech , use some very general features . and , then , look at it more from the aspect of modeling . have a couple markov models and , try to indi try to determine , w when is th when are you in an overlap , when are you not in an overlap . and let the , statistical system determine what 's the right way to look at the data . you have , nonspeech , single person speech , and multiple person speech ? and then you have a markov model for each ? ","And, finally, it was determined that speaker mn005's efforts to detect speaker overlap using energy should instead be focussed on pitch- and harmonicity-related features or be guided by a non-featural, statistical approach, i.e. via the use of Markov models. "
Bmr010.G,"and , there should overall be a , smaller proportion of the total energy that is explained by any particular harmonic sequence in the spectrum . those are all things that should be there . far , jose has been i was told i should be calling you pepe , but by your friends , but anyway ,  the has , been exploring , e largely the energy issue and ,  as with a lot of things , it is not like this , it 's not as simple as it sounds . and then there 's , is it energy ? is it log energy ? is it lpc residual energy ? is it is it , delta of those things ? what is it no just a simple number absolute number isn't gonna work . it should be with compared to what ? should there be a long window for the normalizing factor and a short window for what you 're looking at ? or , how b short should they be ?  th he 's been playing around with a lot of these different things and far at least has not come up with any combination that really gave you an indicator .  i still have a hunch that there 's it 's in there some place , but it may be given that you have a limited time here , it just may not be the best thing to focus on for the remaining of it . pitch related and harmonic related , i 'm somewhat more hopeful for it . but it seems like if we just wanna get something to work , that , their suggestion of th they were suggesting going to markov models , but in addition there 's an expansion of what javier did . and one of those things , looking at the statistical component , even if the features that you give it are not ideal for it , it 's just this general filter bank or cepstrum eee it 's in there somewhere probably .   let 's read some digits . ","far , jose has been the has , been exploring , e largely the energy issue as with a lot of things , it is not like this , it 's not as simple as it sounds . and then there 's , is it energy ? is it log energy ? is it lpc residual energy ? is it is it , delta of those things ? should there be a long window for the normalizing factor and a short window for what you 're looking at ? and far at least has not come up with any combination that really gave you an indicator . but it may be given that you have a limited time here , it just may not be the best thing to focus on for the remaining of it . but it seems like if we just wanna get something to work , that , their suggestion of th they were suggesting going to markov models , but in addition there 's an expansion of what javier did . and one of those things , looking at the statistical component , even if the features that you give it are not ideal for it , it 's just this general filter bank ","And, finally, it was determined that speaker mn005's efforts to detect speaker overlap using energy should instead be focussed on pitch- and harmonicity-related features or be guided by a non-featural, statistical approach, i.e. via the use of Markov models. "
Bmr011.A,"why is it cold in here ? i had a just a quick question but i know there was discussion of it at a previous meeting that i missed , but just about the wish list item of getting good quality close talking mikes on every speaker . that was we started running recognition on one conversation but it 's the r isn't working yet .  but if anyone has the main thing would be if anyone has , knowledge about ways to , post process the wave forms that would give us better recognition , that would be helpful to know about . ri the and actually in addition to that , that the close talking mikes are worn in such a way as to best capture the signal . and the reason here is just that for the people doing work not on microphones but on like dialogue and forth , or and even on prosody , which don is gonna be working on soon , it adds this extra , vari variable for each speaker to deal with when the microphones aren't similar . and i also talked to mari this morning and she also had a strong preference for doing that . and she said that 's useful for them to know in starting to collect their data too .  but we have more than one type of you 're right . but if we could actually standardize , the microphones , as much as possible that would be really helpful . but y we could just record these signals separately and time align them with the start of the meeting . right . for short term research it 's just there 's just much effort that would have to be done up front n uniformity would be great . jane would know more about the transcribers . right . does the recognizer . even if you 're talking on someone else 's mike it 's still you w right . right . that 's great , great . great , very much . it 's makes our job a lot easier . you just search for adam 's voice on each individual microphone , you know where everybody 's sitting .  right , right .  right . it seems it seems to me that there 's there are good political reasons for doing this , just getting the data , because there 's a number of sites like right now sri is probably gonna invest a lot of internal funding into recording meetings also , which is good , but they 'll be recording with video and they 'll be it 'd be if we can have at least , make use of the data that we 're recording as we go since it 's this is the first site that has really collected these really impromptu meetings , and just have this other information available . if we can get the investment in just for the infra infrastructure and then , i don't know , ","and actually in addition to that , that the close talking mikes are worn in such a way as to best capture the signal . it adds this extra , vari variable for each speaker to deal with when the microphones aren't similar . but if we could actually standardize , the microphones , as much as possible that would be really helpful . it seems to me that there 's there are good political reasons for doing this , it 'd be if we can have at least , make use of the data that we 're recording as we go since it 's this is the first site that has really collected these really impromptu meetings , and just have this other information available . if we can get the investment in just for the infra infrastructure ","The discussion was largely focused on efforts to facilitate transcriptions, including the improvement of strategies for transcribing overlapping speech, and achieving greater uniformity in the type of equipment used during recordings and the manner in which recording devices are worn by speakers. "
Bmr011.A,"save it out or have whoever 's interested save that data out , transfer it there , it 'd be g it 'd be good to have the recording . if even if we 're not i 'm not about video . that 's an video has a little different nature since right n right now we 're all being recorded but we 're not being taped . but it definitely in the case of microphone arrays , since if there was a community interested in this , then   if there 's a way to say time to solve each of these f those suppose you can get an array in because there 's some person at berkeley who 's interested and has some equipment , and suppose we can as we save it we can , transfer it off to some other place that holds this data , who 's interested , and even if icsi it itself isn't . and it seems like as long as we can time align the beginning , do we need to mix it with the rest ? i don't know . the   it 's just it 's worth considering as once you make the up front investment and can save it out each time , and not have to worry about the disk space factor , then it mi it might be worth having the data . right . i see .   right , at least they 'd have the data and the transcripts , and right .  right , just it 'd be if we have more information on the same data .  and but it 's if it 's impossible or if it 's a lot of effort then you have to just balance the two ,  right . right . internally , but i know there is interest from other places that are interested in looking at meeting data and having the video . it 's just right , that 's true .  you 're on recor you 're being recorded and  can you explain what the atlas i 'm not familiar with this atlas system .     it 's hard just playing the just having played the individual files . and i know you . i your voice sounds like . i 'm familiar with it 's pretty hard to follow , especially there are a lot of words that are reduced phonetically that make sense when what the person was saying before . it depends where you are in  actually , are th are they giving any time markings ? in other words , if  cuz  actu mar mari asked me the same question as   whether to this is a , and actually i should say this is what don has b he 's already been really helpful in , chopping up these first of all you for the sri front end , we really need to chop things up into pieces that are f not too huge . ","it 'd be g it 'd be good to have the recording . but it definitely in the case of microphone arrays , since if there was a community interested in this , then but i know there is interest from other places that are interested in looking at meeting data and having the video . there are a lot of words that are reduced phonetically that make sense when what the person was saying before . for the sri front end , we really need to chop things up into pieces that are f not too huge . ",
Bmr011.A,"but second of all , in general because some of these channels , i 'd say don't know , at least half of them probably on average are g are ha are have a lot of cross ta some of the segments have a lot of cross talk . it 's good to get short segments if you 're gonna do recognition , especially forced alignment .  don has been taking a first stab actually using jane 's first the fir the meeting that jane transcribed which we did have some problems with , and thilo , told me why this was , but that people were switching microphones around in the very beginning ,  the sri re and they they were not  we have to normalize the front end and forth , and have these small segments . we 've taken that and chopped it into pieces based always on your , cuts that you made on the mixed signal . and that every speaker has the same cuts . and if they have speech in it we run it through . and if they don't have speech in it we don't run it through . and we base that knowledge on the transcription . the problem is if we have no time marks , then for forced alignment we actually don't know where in the signal the transcriber heard that word . and if it 's a whole conversation and we get a long , par paragraph of talk , i don't know how they do this . we actually don't know which piece goes where . and , with no , we used the fact that when jane transcribes them the way she has transcribers doing this , whether it 's with the pre segmentation or not , they have a chunk and then they transcribes the words in the chunk . and they choose the chunk or now they use a pre segmentation and then correct it if necessary . but there 's first a chunk and then a transcription . then a chunk , then a transcription . that 's great , cuz the recognizer can right , and it helps that it 's made based on heuristics and human ear th but there 's going to be a real problem , even if we chop up based on speech silence these , the transcripts from i b m , we don't actually know where the words were , which segment they belonged to . that 's what i 'm worried about right now . if you do a forced alignment on something really even if you do it on something really long you need to know you can always chop it up but you need to have a reference of which words went with which , chop .   they have some actually there is some , even if they 're not fine grained , the transcribers i don't know , it 's saved out in pieces that would help . but , ","but second of all , in general because some of these channels , some of the segments have a lot of cross talk . it 's good to get short segments if you 're gonna do recognition , especially forced alignment . we have to normalize the front end and forth , and have these small segments . we 've taken that and chopped it into pieces based always on your , cuts that you made on the mixed signal . and that every speaker has the same cuts . the problem is if we have no time marks , then for forced alignment we actually don't know where in the signal the transcriber heard that word . th but there 's going to be a real problem , even if we chop up based on speech silence these , the transcripts from i b m , we don't actually know where the words were , which segment they belonged to . ",
Bmr011.A,"it 's just an unknown right now .  right . but the it is true that the segments i haven't tried the segments that thilo gave you but the segments that in your first meeting are great . that 's a good length . right , cuz y and actually as you get transcripts just , for new meetings , we can try the more data we have to try the alignments on , the better . it 'd be good for just to know as transcriptions are coming through the pipeline from the transcribers , just to we 're playing around with parameters f on the recognizer , cuz that would be helpful . especially as you get , en more voices . the first meeting had just four people ,  great , great .    right .  this is like gestural these g right .  right . but is the goal there to have this on meeting data , like that you can do far field studies of those gestures or or is it because you think there 's a different actual production in meetings that people use ? or ? i see .  right .  right . that would be good . right . that 's true . wanted to , make a pitch for trying to collect more meetings .  i actually i talked to chuck fillmore and they 've what , vehemently said no before but this time he wasn't vehement and he said "" liz , come to the meeting tomorrow and try to convince people "" . 'm gonna try . go to their meeting tomorrow and see if we can try , to convince them because they have and they have very interesting meetings from the point of view of a very different type of talk than we have here and definitely than the front end meeting , probably .  yes and in terms of the fact that they 're describing abstract things and , just dialogue wise , right . 'll try . and then the other thing is , i don't know if this is useful , but i asked lila if go around and talk to the different departments in this building to see if there 's any groups that , for a free lunch , if we can still offer that , might be willing non icsi , non academic , like government people , i don't know .  is it in these departments ? right , and then we could also we might try advertising again because it 'd be good if we can get a few different non internal types of meetings and just also more data .  actually wrote to him and he answered , "" great , that sounds really interesting "" . but i never heard back because we didn't actually advertise openly . we a i told i d asked him privately . and it is a little bit of a trek for campus folks . it 's still worthwhile .  exactly , and ","wanted to , make a pitch for trying to collect more meetings . because it 'd be good if we can get a few different non internal types of meetings ",
Bmr011.A,"and i was thinking  plus we could also get a s a student . and i 'm willing to try to learn . i 'm i would do my best . the other thing is that there was a number of things at the transcription side that , transcribers can do , like dialogue act tagging , disfluency tagging , things that are in the speech that are actually something we 're y working on for language modeling . and mari 's also interested in it , andreas as if you wanna process a utterance and the first thing they say is , "" , and that "" is coded as some interrupt u tag . and things like that ,  th a lot of it can be done great . lot of this there 's a second pass and i don't really would exist in it . but there 's definitely a second pass worth doing to encode some kinds of , is it a question or not , or that these transcribers could do .   that 'd be great .  that we could .  that all these people had said "" no "" twice already . if that 's not the case then just  right . right . that was a big fear .   it one thing that would be and this it sounds bizarre but , i 'd really like to look at to get some meetings where there 's a little bit of heated discussion , like ar arguments and or emotion , and things like that . and was thinking if there 's any like berkeley political groups that 'd be perfect . some group , "" yes , we must "" something   no , but stu student , groups or , film makers , or som something a little bit colorful . and i don't mean that they 're angry but just something with some more variation in prosodic contours and forth would be neat . if anyone has ideas , i 'm willing to do the leg work to go try to talk to people but i don't really know which groups are worth pursuing . or that 's i was thinking , knowing the , n national institute of standards , it is all   exactly , that 's what i was something where there is actually discussion where there 's no right or wrong answer but it 's a matter of opinion thing . anyway , if you have ideas we could i 'm actually serious because , we have the set up here and that has a chance to give us some very interesting fun data .  if anyone has ideas , if any groups that are m student groups c like clubs , things like that . not  "" if you 're really angry at someone use our conference room . ""  really . or people who are really h far field mikes can pick up where they threw on the wall . right . think that was just ","the other thing is that there was a number of things at the transcription side that , transcribers can do , like dialogue act tagging , disfluency tagging , things that are in the speech that are actually something we 're y working on for language modeling . ","The Berkeley Meeting Recorder group discussed recording equipment and setup issues, recent developments in the transcription effort, other potential types of tagging to be assigned to transcribers, and the post-processing of waveforms. "
Bmr011.A,"i already asked thilo but that , it would be helpful if stay in the loop somehow with , people who are doing any post processing , whether it 's to separate speakers or to improve the signal to noise ratio , or both , that we can try out as we 're running recognition . i is that who else is work dan ellis and you and dave .   i don't know . i 'm bad it 's like it doesn't seem like big room acoustics problems to my ear but i 'm not an expert . it seems like a problem with cross talk . that may be true . but i don't know how good it can get either by those the those methods that 's true . i don't know . all i meant is just that as as this pipeline of research is going on we 're also experimenting with different asr , techniques . and it 'd be w good to know about it . r right , although if they 're not talking , using the inhouse transcriptions , were k because the t no one transcribed any words there and we throw it out . but if they 're talking and they 're not talking the whole time , you get some speech and then a "" , and some more speech , that whole thing is one chunk . and the person in the middle who said only a little bit is picking up the speech around it , that 's where it 's a big problem . the energy , right . exactly .   we try to find as close of start and end time of as we can to the speech from an individual speaker , because then we 're more guaranteed that the recognizer will for the forced alignment which is just to give us the time boundaries , because from those time boundaries then the plan is to compute prosodic features . and the more space you have that isn't the thing you 're trying to align the more errors we have . that it would help to have either pre processing of a signal that creates very good signal to noise ratio , which i don't know how possible this is for the lapel , or to have very to have closer , time synch times , around the speech that gets transcribed in it , or both . and it 's just open world right now of exploring that . just wanted to see , on the transcribing end from here things look good . the ibm one is more it 's an open question right now . and then the issue of like global processing of some signal and then , before we chop it up is yet another way we can improve things in that .  right . you can , the problem is just that the acoustic ","but that , it would be helpful if stay in the loop somehow with , people who are doing any post processing , all i meant is just that as as this pipeline of research is going on we 're also experimenting with different asr , techniques . r right , although if they 're not talking , using the inhouse transcriptions , were k we try to find as close of start and end time of as we can to the speech from an individual speaker , because then we 're more guaranteed that the recognizer will for the forced alignment which is just to give us the time boundaries , because from those time boundaries then the plan is to compute prosodic features . and the more space you have that isn't the thing you 're trying to align the more errors we have . ",
Bmr011.A,"when the signal to noise ratio is too low , you 'll get , a an alignment with the wrong duration pattern or it it 's not the fact that you have like what he did is allow you to have , words that were in another segment move over to the at the edges of segmentations . right , things near the boundaries where if you got your alignment wrong cuz what they had done there is align and then chop . and this problem is a little bit j more global . it 's that there are problems even in inside the alignments , because of the fact that there 's enough acoustic signal there t for the recognizer to eat , as part of a word . and it tends to do that . s  but we probably will have to do something like that in addition . anyway . bottom line is just i wanted to make can be aware of whoever 's working on these signal processing techniques for , detecting energies , because that 'll really help us . ","because of the fact that there 's enough acoustic signal there t for the recognizer to eat , as part of a word . but we probably will have to do something like that in addition . because that 'll really help us . ",
Bmr011.B,"are we on ? we 're on .     we haven't sent around the agenda .  i any agenda items anybody has , wants to talk about , what 's going on ? it 's on ? agenda item one , introduce don . we did that .  let 's let 's just do agenda building right now . let 's talk about that a bit . @ @ tuss close talking mikes , better quality . we can talk about that . you were gonna starting to say something ? no , that 's we can we can ta nist is nist folks are coming by next week and we can talk about that .  john fiscus and , george doddington will be around as we can talk about that . just hear about how things are going with , the transcriptions . that 's right . that would sorta be an obvious thing to discuss .  an anything else , strike anybody ?      alright , that seems like a good collection of things . and we 'll undoubtedly think of other things . under the nist meeting .  alright , why don't we start off with this , u the order we brought them up seems fine .  better quality close talking mikes . the one issue was that the , lapel mike , isn't as good as you would like . and it 'd be better if we had close talking mikes for everybody . right ? is that the point ?   right , one th one thing i was gonna say was that , i we could get more , of the head mounted microphones even beyond the number of radio channels we have because whether it 's radio or wire is probably second order . and the main thing is having the microphone close to you , u although , not too close .  is . yes . right . how am i d  it doesn't hurt to have a few extra microphones around , why don't we just go out and get an order of if this microphone seems to people , i 'd just get a half dozen of these things .   no , but my point is r right right now , we 've got , two microphones in the room , that are not quote unquote standard . why don't we replace those however many we can plug in . if we can plug in three , let 's plug in three . also what we 've talked before about getting another , radio , and then that would be , three more . we should go out to our full complement of whatever we can do , but have them all be the same mike . the original reason that it was done the other way was because , it w it was an experimental thing and i don't think anybody knew whether people would rather have more variety or , more uniformity , but @ @ but sounds fine .     ","the one issue was that the , lapel mike , isn't as good as you would like . and it 'd be better if we had close talking mikes for everybody . one thing i was gonna say was that , i we could get more , of the head mounted microphones why don't we just go out and get an order of i 'd just get a half dozen of these things . we should go out to our full complement of whatever we can do , but have them all be the same mike . the original reason that it was done the other way was because , it w it was an experimental thing and i don't think anybody knew whether people would rather have more variety or , more uniformity , ","The discussion was largely focused on efforts to facilitate transcriptions, including the improvement of strategies for transcribing overlapping speech, and achieving greater uniformity in the type of equipment used during recordings and the manner in which recording devices are worn by speakers. "
Bmr011.B,"when we 're doing  now , this is locking the barn door after the horse was stolen . we do have thirty hours , of speech , which is done this way . but but , for future ones we can get it a bit more uniform . probably to the store we talked about and that      second item was the , nist visit , and what 's going on there . something didn't put in the list but , on that , same day later on in or it 's no , actually it 's this week , dave gelbart and i will be , visiting with john canny who i is a cs professor , who 's interested in ar in array microphones .  and we wanna see what commonality there is here . they 'd wanna stick an array mike here when we 're doing things or it 's not a specific array microphone they want but they might wanna just , you could imagine them taking the four signals from these table mikes and trying to do something with them i also had a discussion w we 'll be over there talking with him , after class on friday . we 'll let what goes with that . also had a completely unrelated thing . i had a , discussion today with , birger kollmeier who 's a , a german , scientist who 's got a fair sized group doing a range of things . it 's auditory related , largely for hearing aids and on . but but , he does with auditory models and he 's very interested in directionality , and location , and , head models and microphone things . and he 's he and possibly a student , there w there 's , a student of his who gave a talk here last year , may come here , in the fall for , five month , sabbatical . he might be around . get him to give some talks and on . but anyway , he might be interested in this right . a little bit , he didn't do a very extreme thing but just it was just e given that , the block of wood with the two mikes on either side , if i 'm speaking , or if you 're speaking , or someone over there is speaking , it if you look at cross correlation functions , you end up with a if someone who was on the axis between the two is talking , then you get a big peak there . and if someone 's talking on , one side or the other , it goes the other way . and then , it even looks different if th t if the two people on either side are talking than if one in the middle . it actually looks somewhat different ,   right . you have to the appropriate normalizations are tricky , and are probably the key . ","dave gelbart and i will be , visiting with john canny who i is a cs professor , who 's interested in ar in array microphones . they 'd wanna stick an array mike here when we 're doing things but they might wanna just , you could imagine them taking the four signals from these table mikes and trying to do something with them if i 'm speaking , or if you 're speaking , or someone over there is speaking , it if you look at cross correlation functions , you end up with a if someone who was on the axis between the two is talking , then you get a big peak there . and then , it even looks different if th t if the two people on either side are talking than if one in the middle . it actually looks somewhat different , ",
Bmr011.B,"we 've switched positions recently you can't anyway .  those are just a little couple of news items . yes . right . probably not but i 'll i 'll know better after i see him this friday what level he wants to get involved . he might be excited to and it might be very appropriate for him to , or he might have no interest whatsoever . really don't know . that 's what they 're starting up . no , that 's what all this is about . they haven't done it yet . they wanted to do it think they 've instrumented a room but i don't think they haven't started recordings yet . they don't have the t the transcription standards . they don't have the   they are . i 'm i 'm not all i know is that they 've been talking to me about a project that they 're going to start up recording people meet in meetings . and , it is related to ours . they were interested in ours . they wanted to get some uniformity with us , about the transcriptions and on . and one notable difference u actually i can't remember whether they were going to routinely collect video or not , but one , difference from the audio side was that they are interested in using array mikes . i 'll just tell you the party line on that . the reason i didn't go for that here was because , the focus , both of my interest and of adam 's interest was in impromptu situations . and we 're not recording a bunch of impromptu situations but that 's because it 's different to get data for research than to actually apply it . and for scientific reasons we thought it was good to instrument this room as we wanted it . but the thing we ultimately wanted to aim at was a situation where you were talking with , one or more other people i in an p impromptu way , where you didn't actually the situation was going to be . and therefore it would not it 'd be highly unlikely that room would be outfitted with some very carefully designed array of microphones . it was only for that reason . it was just , yet another piece of research and it seemed like we had enough troubles just no . there 's there 's a whole range of things there 's a whole array of things , that people do on this .  the , the big arrays , places , like rutgers , and brown , and other places , they have , big arrays with , i don't know , a hundred mikes and there 's a wall of mikes . and you get really , really good beam forming with that thing . and it 's and , ","they wanted to do it think they 've instrumented a room but i don't think they haven't started recordings yet . all i know is that they 've been talking to me about a project that they 're going to start up recording people meet in meetings . and , it is related to ours . they were interested in ours . they wanted to get some uniformity with us , about the transcriptions and on . but one , difference from the audio side was that they are interested in using array mikes . the reason i didn't go for that here was because , the focus , both of my interest and of adam 's interest was in impromptu situations . we 're not recording a bunch of impromptu situations but the thing we ultimately wanted to aim at was a situation where you were talking with , one or more other people i in an p impromptu way , where you didn't actually the situation was going to be . and therefore it would not it 'd be highly unlikely that room would be outfitted with some very carefully designed array of microphones . ",
Bmr011.B,"at one point we had a proposal in with rutgers where we were gonna do some of the per channel signal processing and they were gonna do the multi channel but it d we ended up not doing it . but it 's r it 's really neat and then they had the little ones , our block of wood is unique . but the but the no , there are these commercial things now you can buy that have four mikes and ,  there 's there 's a range of things that people do . if we connected up with somebody who was interested in doing that thing that 's a good thing to do . whenever i 've described this to other people who are interested on the with the acoustic side that 's invariably the question they ask . just like someone who is interested in the general dialogue thing will always ask "" are you recording video ? "" right ? and the acoustic people will always say , "" are you doing , array microphones ? "" it 's a good thing to do , but it doesn't solve the problem of how do you solve things when there 's one mike or at best two mikes in this imagined pda that we have . we 'll do some more of it . if ninety nine percent of what you 're doing is c is shutting off most of the mikes , then going through the but if you get somebody who 's who has that as a primary interest then that put then that drives it in that direction . at some level at some level . but then , there 's it there 's there 's i don't they 're going to do and i don't know how big their array is . if you were gonna save all of those channels for later research you 'd use up a lot of space . and , th   but for optimum flexibility later you 'd want to save each channel . but in practical situations you would have some engine of some sort doing some processing to reduce this to some to the equivalent of a single microphone that was very directional . right ?  see the problem is it took , it took at least six months for dan to get together the hardware and the software , and debug in the microphones , and in the boxes . and it was a really big deal . and think we could get a microphone array in here pretty easily and , have it mixed to one channel of some sort . but , e for how we 're gonna decide for maximum flexibility later you really don't want to end up with just one channel that 's pointed in the direction of the p the person with the maximum energy like that . you want actually to have multiple channels being recorded that you can ","it 's a good thing to do , but it doesn't solve the problem of how do you solve things when there 's one mike or at best two mikes in this imagined pda that we have . we 'll do some more of it . and think we could get a microphone array in here pretty easily and , have it mixed to one channel of some sort . but , e for for maximum flexibility later you really don't want to end up with just one channel that 's pointed in the direction of the p the person with the maximum energy like that . you want actually to have multiple channels being recorded that you can ",
Bmr011.B,"and to do that , it we 're going to end up greatly increasing the disk space that we use up , we also only have boards that will take up to sixteen channels and in this meeting , we 've got eight people and six mikes . and there we 're already using fourteen . e   think you 'd need a separate set up and the assumption that you could time align the two . i 'm not much worried about disk space actually . i mentioned that , b as a practical matter , but the real issue is that , there is no way to do a recording extended to what we have now with low skew . you would have a t completely separate set up , which would mean that the sampling times and forth would be all over the place compared to this . it would depend on the level of pr processing you were doing later , but if you 're d i the person who 's doing array processing you actually care about funny little times . and you actually wou would want to have a completely different set up than we have , one that would go up to thirty two channels  or a hun  i 'm kinda skeptical , but think that i don't think we can share the resource in that way . but what we could do is if there was someone else who 's interested they could have a separate set up which they wouldn't be trying to synch with ours which might be useful for them . and then we can offer up the room , we can o offer the meetings , and the physical space , and the transcripts , and on .  thi the thing will be , u in again , in talking to these other people to see what what we can do . we 'll see . right , we have we it 's , people getting shy about it . there 's this human subjects problem . there 's the fact that then if i i 've heard comments about this before , "" why don't you just put on a video camera ? "" but it 's like saying , "" we 're primarily interested in some dialogue things , but , why don't we just throw a microphone out there . "" once you actually have serious interest in any of these things then you actually have to put a lot of effort in . and , you really want to do it right . think nist or ldc , or somebody like that is much better shape to do all that . we there will be other meeting recordings . we won't be the only place doing meeting recordings . we are doing what we 're doing . and , hopefully it 'll be useful .   we we don't , we don't perform electro shock during these meetings , and   transcriptions . ","i 'm not much worried about disk space actually . but the real issue is that , there is no way to do a recording extended to what we have now with low skew . but if you 're d i the person who 's doing array processing you actually care about funny little times . and you actually wou would want to have a completely different set up than we have , one that would go up to thirty two channels i 'm kinda skeptical , but what we could do is if there was someone else who 's interested they could have a separate set up which they wouldn't be trying to synch with ours which might be useful for them . we can o offer the meetings , and the physical space , and the transcripts , and on . there 's this human subjects problem . once you actually have serious interest in any of these things then you actually have to put a lot of effort in . think nist or ldc , or somebody like that is much better shape to do all that . ",
Bmr011.B,"if they hear something off in the distance they don't they just go are you ? but they 're not giving f really fine time markings . it 's historical .  some point ago we thought that it "" boy , we 'd really have to ramp up to do that "" , like we just did , and , here 's , a , collaborating institution that 's volunteered to do it . that was a contribution they could make . in terms of time , money , and it still might be a good thing but     we 'll see . th they they 've proceeded along a bit . let 's see what comes out of it , and , have some more discussions with them .   that they are ,  i 'm they will and we have to have a dialogue with them about it . it sounds like liz has some concerns and that 's great . the other thing , i can't remember if we discussed this in the meeting but , i know you and i talked about this a little bit , there was an issue of , suppose we get in the , it 's enviable position although it 's just saying where the weak link is in the chain , where we ,  we have all the data transcribed and we have these transcribers and we were we 're the we 're still a bit slow on feeding at that point we 've caught up and the , the weak link is recording meetings .   two questions come , is what how do we it 's not really a problem at the moment cuz we haven't reached that point but how do we step out the recorded meetings ? and the other one is , is there some good use that we can make of the transcribers to do other things ? i can't remember how much we talked about this in this meeting but there was right , think we talking about three level three things . one was we had s had some discussion in the past about some very high level labelings , types of overlaps , and forth that someone could do . second was , somewhat lower level just doing these more precise timings . and the third one is , just a completely wild hair brained idea that i have which is that , if , if we have time and people are able to do it , to take some subset of the data and do some very fine grained analysis of the speech . marking in some overlapping potentially overlapping fashion , the value of , ar articulatory features . just say , it 's voiced from here to here , there 's it 's nasal from here to here , and forth . as opposed to doing phonetic phonemic and the phonetic analysis , and , assuming , articulatory feature values for those things . that 's extremely time consuming .  but , ","some point ago we thought that it "" boy , we 'd really have to ramp up to do that "" , and , here 's , a , collaborating institution that 's volunteered to do it . that was a contribution they could make . in terms of time , money , that they are , and we have to have a dialogue with them about it . but how do we step out the recorded meetings ? and the other one is , is there some good use that we can make of the transcribers to do other things ? right , think we talking about three level three things . one was we had s had some discussion in the past about some very high level labelings , types of overlaps , and forth that someone could do . second was , somewhat lower level just doing these more precise timings . and the third one is , just a completely wild hair brained idea that i have which is that , if , if we have time and people are able to do it , to take some subset of the data and do some very fine grained analysis of the speech . marking in some overlapping potentially overlapping fashion , the value of , ar articulatory features . ","The Berkeley Meeting Recorder group discussed recording equipment and setup issues, recent developments in the transcription effort, other potential types of tagging to be assigned to transcribers, and the post-processing of waveforms. "
Bmr011.B,"we could do it on some small subset .   but also it 's just the issue that when you look at the u w u when you look at switchboard very close up there are places where whether it 's a consonant or a vowel you still have trouble calling it a particular phone at that point because it 's there 's this movement from here to here and it 's  describe it . now i 'm suggesting articulatory features . there 's even a better way to do it but it but that 's , traditional way of describing these things , and actually this might be a g neat thing to talk to  it 's still some categories but something that allows for overlapping change of these things and then this would give some more ground work for people who were building statistical models that allowed for overlapping changes , different timing changes as opposed to just "" click , you 're now in this state , which corresponds to this speech sound "" and on . something like that . actually if we get into that it might be good to , haul john ohala into this and ask his views on it no , it 's for that purpose i 'm just viewing meetings as being a neat way to get people talking naturally . and then you have i and then it 's natural in all senses , in the sense that you have microphones that are at a distance that one might have , and you have the close mikes , and you have people talking naturally . and the overlap is just indicative of the fact that people are talking naturally , right ? think that given that it 's that corpus , if it 's gonna be a very useful corpus if you say w we 've limited the use by some of our , censored choices , we don't have the video , we don't and forth , but there 's a lot of use that we could make of it by expanding the annotation choices . and , most of the things we 've talked about have been fairly high level , and being bottom up person we 'd , do some of the others .   and hopefully someone would make use of it . people didn't people have made a lot of use of timit and , due to its markings , and then the switchboard transcription thing , think has been very useful for a lot of people .    cuz they have something like three or four different meetings , right ?  yes . great .  he 's supposed to be trained to do it .  they 're open to it . all these things are there 's we should go beyond , icsi but , there 's a lot of happening at icsi that we 're not getting now that we could . it 's just the no , no . no . ","and then this would give some more ground work for people who were building statistical models that allowed for overlapping changes , different timing changes as opposed to just "" click , no , it 's for that purpose i 'm just viewing meetings as being a neat way to get people talking naturally . and then you have i and then it 's natural in all senses , in the sense that you have microphones that are at a distance that one might have , and you have the close mikes , and you have people talking naturally . and the overlap is just indicative of the fact that people are talking naturally , ",
Bmr011.B,"th there was the thing in fillmore 's group but even there he hadn't what he 'd said "" no "" to was for the main meeting . but they have several smaller meetings a week , and , the notion was raised before that could happen . and it just , it just didn't come together but  mean there 's possibilities there . jerry 's group , yes . there 's there 's , the networks group , i don't do they still meeting regularly or ? but ha have they said they don't want to anymore or ? i  they 're down to three or four people but three or four people is   with potential use from the defense department .  th there 's a problem there in terms of , the commercial value of st it turned out to be a bit of a problem .  of all nat all native speakers . why ? i don't i don't think if he didn't say that i bet he did . i remember wh i remember a study i remember a study that bbn did where they trained on this was in wall street journal days they trained on american english and then they tested on , different native speakers from different areas . and , the worst match was people whose native tongue was mandarin chinese . the second worst was british english . it 's , t the german was much better , it was swiss w it 's think , if he 's thinking in terms of recognition technology he would probably want , american english ,  it unless we 're gonna train with a whole bunch of      it 's pretty tough , this group . what about people who involved in some artistic endeavor ? film making like that . you 'd think like they would be i know you are .  put a little ad up saying , "" come here and argue "" . they could have a discussion about te about tax cuts now that is not actually what we but we don't want them to throw the far field mikes is the thing . anyway . i had as my fourth thing here processing of wave forms . what did we mean by that ? remember @ @ ?  you already did that . and dave gel gelbart again , he 's interested we 're look starting to look at some echo cancellation things . which  let 's w i isn't that what you want t no , no , i w wha what you want when you 're saying improving the wave form you want the close talking microphone to be better . right ? and the question is to w to what extent is it getting hurt by , by any room acoustics or is it just given that it 's close it 's not a problem ?  it 's  o k ,  tea has started out there i suggest we c run through our digits and ,   ","think , if he 's thinking in terms of recognition technology he would probably want , american english , ",
Bmr011.B,we 're done . ,,
Bmr011.C,"now , we 're working more on it but , it 's not finished .     what i 'm doing right now is i 'm trying to include some information about which channel , there 's some speech in . but that 's not working at the moment . i 'm just trying to do this by comparing energies , normalizing energies and comparing energies of the different channels . and to give the transcribers some information in which channel there 's speech in addition to the thing we did now which is just , speech nonspeech detection on the mixed file . 'm relying on the segmentation of the mixed file but i 'm trying to subdivide the speech portions into different portions if there is some activity in different channels . but               no , th no . they were not switching them but what they were adjusting them ,  and aft after a minute or it 's way better .    i 'm have some but that 's the one where we 're , trai training on , that 's a little bit it 's a little bit at odd to  four speakers ,       the all native . ooo , ooo . american english ? ooo , ooo .  dan ,    ","what i 'm doing right now is i 'm trying to include some information about which channel , there 's some speech in . i 'm just trying to do this by comparing energies , normalizing energies and comparing energies of the different channels . to give the transcribers some information in which channel there 's speech in addition to the thing we did now which is just , speech nonspeech detection on the mixed file . 'm relying on the segmentation of the mixed file but i 'm trying to subdivide the speech portions into different portions if there is some activity in different channels . ",
Bmr011.D," one , two u   we went  is i it 's not cor it 's correct ?         is fixed .     right .                      no , close talk .   no , just   talk      film maker . is    a film maker . yes . department .  computer sci    the fa    energy .  c may i only display the different colors for the different situation . but , for me and for my problems , is is enough . because , it 's possible , in a simp sample view , to , nnn , to compare with c with the segment , the assessment what happened with the different parameters . and only with a different bands of color for the , few situation , i consider for acoustic event is enough to @ @ . i see that , you are considering now , a very sophisticated , ehm , @ @ set of , graphic s ehm , si symbols to transcribe . no ? because , before , you are talking about the possibility to include in the transcriber program a set of symbols , of graphic symbol to t to mark the different situations during the transcription during the transcription . no ?  the s the symbols , you talk of before . no ? to mark      ",,
Bmr011.E,"is it on ? what meeting ? who 's coming ? wha what about , is there anything new with the speech , nonspeech  can we get these , wireless ? is it because you 're saying the for dialogue purposes , that means that the transcribers are having trouble with those mikes ? is that what or ? especially for people with big heads .  that would be that would be really neat . that reminds me , i had a thought of an interesting project that somebody could try to do with the data from here , either using , the mikes on the table or using signal energies from the head worn mikes , and that is to try to construct a map of where people were sitting , based on did he ? that 's interesting . and you could plot out who was sitting next to who and   was just thinking , as i was sitting here next to thilo that when he 's talking , my mike probably picks it up better than your guys 's mikes . if you just looked at looked at the energy on my mike and you could get an idea about who 's closest to who . and are they going to do video as  there 's no like portable array of mikes ?  i 've seen demonstrations of the microphone arrays . it 's amazing how they can cut out noise .  to save that data you have to have one channel recording per mike in the array ? is that what you save , if you 're going to do research with it .    i see . saving the result of the beam forming . is there an interest in getting video recordings for these meetings ?   there 's not enough interest to overcome all of  you were here at a meeting before .  usually . how big is the data set ?    is this the project that 's between , nist and , a couple of other places ? the  y right ,  the p the people the folks that they 're , subcontracting out the transcription to , are they like court reporters or   like medical transcriptionist type people but aren't they 're they 're hiring them , they 're coming . it 's not a service they send the tapes out to .   i gotcha . i see . i see .   each person gets one of these channels  but there could be problems , right ? with that . if you 're tran if you got that channel right there  that 's right . just out of curiosity , given all of the effort that is going on here in transcribing why do we have i b m doing it ? why not just do it all ourselves ?    i 'm just wondering now i 'm wondering now if it 's  you would need to like a forced alignment before you did the chopping , right ? why not do a forced alignment ? ","that reminds me , i had a thought of an interesting project that somebody could try to do with the data from here , and that is to try to construct a map of where people were sitting , and you could plot out who was sitting next to who is there an interest in getting video recordings for these meetings ? there 's not enough interest to overcome all of but there could be problems , right ? with that . given all of the effort that is going on here in transcribing why do we have i b m doing it ? why not just do it all ourselves ? ",
Bmr011.E,"that would be really valuable you 're saying r remove the high level constraints and go bottom up . then just say  acoustic features versus psychological categories .   just a source of data ? in terms of the topic topics ?  does john ohala have weekly phonetics lab meetings ? and the other thing too is when they originally said "" no "" they didn't know about this post editing capability thing .  did he mean , did he mean and non british ? he said british was knowing the application a any department that calls itself science the problem is like , on the microphone of somebody who 's not talking they 're picking up signals from other people and that 's causing problems ?  what about increasing the flexibility of the alignment ? do you remember that thing that michael finka did ? that experiment he did a while back ? that 's the problem , is the signal to noise ratio .  or even words inserted that weren't there .   ","the problem is like , on the microphone of somebody who 's not talking they 're picking up signals from other people and that 's causing problems ? ",
Bmr011.F,"hello .  i was i was here i was here before once .   did i ? i don't know .  can i verbally consent ?  i don't care . you can do whatever you want with it . that 's fine .  i don't think the more political argumentative ones would be willing to exactly . we can just discu we can just have a political discussion one day . i could make that pretty i know i i heard that at cal tech they have a special room someone said that they had a special room to get all your frustrations out that you can go to and like throw things and break things . we can like post a no , not to that extent but ,    ",,
Bmr011.G,"i c i could talk about the meeting .  you , already know about the meeting that 's coming up and i don't know if this is appropriate for this . i don't know . it 's something we should handle outside of the meeting .     i had thought under my topic that i would mention the , four items that i , put out for being on the agenda f on that meeting , which includes like the pre segmentation and the developments in multitrans . under the nist thing .   and that 's true . i we did discuss this . and a couple times , the transcribers notice and there 're some where , ugh there 's it 's the double thing . it 's the equipment and also how it 's worn . and he 's always they just rave about how wonderful adam 's channel is . and then ,  but it 's not just that , it 's also you it 's also like n no breathing , no it 's like it 's it 's really it makes a big difference from the transcribers ' point of view and also from the research s point of view .  and there was some talk about , the h headphones that are uncomfortable for people , to  good .   jonathan fiscus is coming on the second of february and i 've spoken with , u a lot of people here , not everyone . and , he expressed an interest in seeing the room and in , seeing a demonstration of the modified multitrans , which i 'll mention in a second , and also , he was interested in the pre segmentation and then he 's also interested in the transcription conventions . and , it seems to me in terms of like , i it wou  the room , it 's things like the audio and c and audi audio and acoustic properties of the room and how it how the recordings are done , and that thing . and , in terms of the multi trans , that 's being modified by dave gelbart to , handle multi channel recording .   that 's we 'll and it 's t and it looks really great . he has a prototype . i , @ @ didn't see it , yesterday but i 'm going to see it today . and , that 's that will enable us to do tight time marking of the beginning and ending of overlapping segments . at present it 's not possible with limitations of the , original design of the software . and i don't know . in terms of pre segmentation , that continues to be , a terrific asset to the transcribers . do you i know that you 're al also supplementing it further . do you want to mention something about that c thilo , or ?  this is good . excellent , this 'd be like w e providing also speaker id potentially . ","it 's the equipment and also how it 's worn . it 's really it makes a big difference from the transcribers ' point of view and , in terms of the multi trans , that 's being modified by dave gelbart to , handle multi channel recording . and , that 's that will enable us to do tight time marking of the beginning and ending of overlapping segments . at present it 's not possible with limitations of the , original design of the software . in terms of pre segmentation , that continues to be , a terrific asset to the transcribers . ","The discussion was largely focused on efforts to facilitate transcriptions, including the improvement of strategies for transcribing overlapping speech, and achieving greater uniformity in the type of equipment used during recordings and the manner in which recording devices are worn by speakers. "
Bmr011.G,"wonderful . wonderful .  can i ask one thing ?  jonathan fiscus expressed an interest in , microphone arrays . is there and i also want to say , his he can't stay all day . he needs to leave for from here to make a two forty five flight from oakland . it makes the scheduling a little bit tight but do you think that , that , i john canny should be involved in this somehow or not . i have no idea . it 's premature . fine . good .  one thing i don't know . i know that having an array of i would imagine it would be more expensive to have a an array of microphones . but couldn't you approximate the natural sis situation by just shutting off channels when you 're later on ? it seems like if the microphones don't effect each other then couldn't you just , record them with an array and then just not use all the data ? i see . fine .  w although i m i have to u mention the human subjects problems , that i increase with video .   i it occurred to me , has don signed a human subject 's form ? a permission form ? you were here at a meeting before . did you sign a form ?   you don't have to leave for it . but  o transcriptions , about there are three aspects of this . first of all , i 've got eight transcribers . seven of them are linguists . one of them is a graduate student in psychology . each i gave each of them , their own data set . two of them have already finished the data sets . and the meetings run , let 's say an hour . sometimes as man much as an hour and a half . it 's what is one meeting . each person got their own meeting . i didn't want to have any conflicts of , of when to stop transcribing this one or wanted to keep it clear whose data were whose , and and , meetings , that they 're they go as long as a almost two hours in some cases . that means if we 've got two already finished and they 're working on right now all eight of them have differe additional data sets . that means potentially as many as ten might be finished by the end of the month . hope but the pre segmentation really helps a huge amount . and , also dan ellis 's innovation of the , the multi channel to here really helped a r a lot in terms of clearing up h hearings that involve overlaps . but , just out of curiosity i asked one of them how long it was taking her , one of these two who has already finished her data set . ","first of all , i 've got eight transcribers . seven of them are linguists . one of them is a graduate student in psychology . and , meetings , that they 're they go as long as a almost two hours in some cases . but the pre segmentation really helps a huge amount . and , also dan ellis 's innovation of the , the multi channel to here really helped a r a lot in terms of clearing up h hearings that involve overlaps . just out of curiosity i asked one of them how long it was taking her , one of these two who has already finished her data set . ","The discussion was largely focused on efforts to facilitate transcriptions, including the improvement of strategies for transcribing overlapping speech, and achieving greater uniformity in the type of equipment used during recordings and the manner in which recording devices are worn by speakers. "
Bmr011.G,"she said it takes about , sixty minutes transcription for every five minutes of real time . it 's about twelve to one , which is what we were thinking . it 's in the range . these still , when they 're finished , that means that they 're finished with their pass through . they still need to be edited and all but it 's word level , speaker change , the things that were mentioned . now i wanted to mention the , teleconference i had with , jonathan fiscus . we spoke for an hour and a half and , had an awful lot of things in common . he , he in indicated to me that they 've that he 's been , looking , spending a lot of time with i 'm not quite the connection , but spending a lot of time with the atlas system . and that i need to read up on that . and there 's a web site that has lots of papers . but it looks to me like that 's the name that has developed for the system that bird and liberman developed for the annotated graphs approach . what he wants me to do and what we will do and is to provide them with the u already transcribed meeting for him to be able to experiment with in this atlas system . and they do have some software , at least that 's my impression , related to atlas and that he wants to experiment with taking our data and putting them in that format , and see how that works out . i explained to him in detail the , conventions that we 're using here in this word level transcript . and , i explained , the reasons that we were not coding more elaborately and the focus on reliability . he expressed a lot of interest in reliability . it 's like he 's really up on these things . he 's very independently he asked , "" what about reliability ? "" he 's interested in the consistency of the encoding and that thing .  at this point adam 's read more in more detail than i have on this . i need to acquaint myself more with it . but , there is a way of viewing whenever you have coding categories , and you 're dealing with a taxonomy , then you can have branches that have alternative , choices that you could use for each of them . and it just ends up looking like a graphical representation .   including ldc .  then there 's their web site that has lots of papers . and i looked through them and they mainly had to do with this , this , tree structure , annotated tree diagram thing . and , in terms of like the conventions that i 'm a that i 've adopted , it there 's no conflict and he was , very interested . ","she said it takes about , sixty minutes transcription for every five minutes of real time . which is what we were thinking . it 's in the range . but it 's word level , speaker change , the things that were mentioned . now i wanted to mention the , teleconference i had with , jonathan fiscus . he , he in indicated to me that they 've that he 's been , but spending a lot of time with the atlas system . but it looks to me like that 's the name that has developed for the system that bird and liberman developed for the annotated graphs approach . and what we will do and is to provide them with the u already transcribed meeting for him to be able to experiment with in this atlas system . and that he wants to experiment with taking our data and putting them in that format , and see how that works out . ",
Bmr011.G,"and , "" and how 'd you handle this ? "" and i said , "" this way "" and we had a really conversation . now i also wanted to say in a different direction is , brian kingsbury . i corresponded briefly with him . i , c i he still has an account here . i told him he could ssh on and use multi trans , and have a look at the already done , transcription . and he did . and what he said was that , what they 'll be providing is will not be as fine grained in terms of the time information . and , that 's , i need to get back to him and , explore that a little bit more and see what they 'll be giving us in specific , but haven't had time yet . what ? yes . get the sense they 're like that . like it 's like a pool of somewhat secretarial i don't think that they 're court reporters . i don't think they have the special keyboards and that type of training . i get the sense they 're more secretarial . and that , what they 're doing is giving them   up to now it 's been monologues , as far my understood . and what they 're doing is brian himself downloaded adam sent them a cd and brian himself downloaded cuz , we wanted to have it that they were in familiar f terms with what they wanted to do . he downloaded from the cd onto audio tapes . and he did it one channel per audio tape . each of these people is transcribing from one channel . and then what he 's going to do is check it , a before they go be beyond the first one . check it and , adjust it , and all that . i don't know . i have t i , it would be difficult to do it that way . i really d in my case yes . th i would think that it would be hard to come out with i agree . and especially since a lot of these we have . except say that my transcribers use the mixed signal mostly unless there 's a huge disparity in terms of the volume on the mix . in which case , they wouldn't be able to catch anything except the prominent channel , then they 'll switch between . but really   i have to ask him . and that 's my email to him . that needs to be forthcoming . but the , did want to say that it 's hard to follow one channel of a conversation even if the people , and if you 're dealing furthermore with highly abstract network concepts you 've never heard of one of these people was transcribing the , networks group talk and she said , "" i don't really lot of these abbreviations are , "" ","now i also wanted to say in a different direction is , brian kingsbury . i told him he could ssh on and use multi trans , and have a look at the already done , transcription . and he did . and what he said was that , what they 'll be providing is will not be as fine grained in terms of the time information . he downloaded from the cd onto audio tapes . and he did it one channel per audio tape . each of these people is transcribing from one channel . except say that my transcribers use the mixed signal mostly unless there 's a huge disparity in terms of the volume on the mix . in which case , they wouldn't be able to catch anything except the prominent channel , then they 'll switch between . ",
Bmr011.G,""" but put them in parentheses cuz that 's the convention and cuz if you don't know   it 's very a real benefit having brian involved because of his knowledge of what the how the data need to be used and what 's useful to have in the format .  good . good . now wasn't that one of the proposals was that ibm was going to do an initial forced alignment , after they  i need to write to him . it 's like i got over taxed with the timing .  a good size . good . i was thinking it would be fun to if you wouldn't mind , to give us a pre segmentation . you have one already of that first m of the meeting that the first transcribed meeting , the one that i transcribed . do you have a could you generate a pre segmentation ? i see . darn .     excellent , good .  liz and i spoke d w at some length on tuesday and i was planning to do just a preliminary look over of the two that are finished and then give them to you .  and there is one use that also we discussed which was when , dave finishes the and it 's already finished the modification to multi trans which will allow fine grained encoding of overlaps . then it would be very these people would be very good to shift over to finer grain encoding of overlaps . it 's just a matter of , providing if right now you have two overlapping segments in the same time bin , with the improvement in the database in the , in the interface , it 'd be possible to , just do a click and drag thing , and get the the specific place of each of those , the time tag associated with the beginning and end of each segment .  the types of overlaps   also if you 're dealing with consonants that would be easier than vowels , wouldn't it ? i would think that , being able to code that there 's a fricative extending from here to here would be a lot easier than classifying precisely which vowel that was . vowels are harder .   i 'm i know . that 's  excellent . it 's a balance . that would be really to offer those things with that wide range . really    good .   also it does seem like it takes us way out of the demographic . it seems like we had this idea before of having like linguistics students brought down for free lunches and that 's a idea .    that 's right . some of that can be li done lexically . and i also they are doing disfluency tagging to some degree already .   they 'd be really good . they 're very they 're very consistent . i wanted to whi while we 're to return just briefly to this question of more meeting data , ","now wasn't that one of the proposals was that ibm was going to do an initial forced alignment , ",
Bmr011.G,"have two questions . one of them is , jerry feldman 's group , they , are they i know that they recorded one meeting . are they willing ?   that 's important . joe sokol ? we might be able to get the administration i see that lila has a luncheon meeting in here periodically . i don't know   there is this problem though , that if we give them the chance to excise later we e might end up with like five minutes out of a f of m one hour of yes . really . there was this k p f a but    and i had one other aspect of this which is , jonathan fiscus expressed primar a major interest in having meetings which were all english speakers . now he wasn't trying to shape us in terms of what we gather but that 's what he wanted me to show him . 'm giving him our , our initial meeting because he asked for all english . and we don't have a lot of all english meetings right now . that 's what he doesn't care . no . british is but  different varieties of english . native speaking . native speaking english . yes . really . that 's funny . alright . and that would make sense . i didn't have the context of that . all america , that the feldman 's meetings tend to be more that way , aren't they ? i feel like they have it 's be fun . we could get julia child . i know . it 'd be fun to get like a p visit from the  pre processing . this does like seem like it would relate to some of what jose 's been working on as the encoding of the and he also , he was i was t i was trying to remember , you have this interface where you i you ha you showed us one time on your laptop that you had different visual displays as speech and nonspeech events .  i w you 're saying symbols for differences between laugh , and sigh , and slam the door and or some other thing ? i wouldn't say symbols much . the main change that i see in the interface is just that we 'll be able to more finely c time things . but i also st there was another aspect of your work that i was thinking about when i was talking to you which is that it sounded to me , liz , as though you and , didn't q understand this , but it sounded to me as though part of the analysis that you 're doing involves taking segments which are of a particular type and putting them together . and th if you have like a p a s speech from one speaker , then you cut out the part that 's not that speaker , ","which is , jonathan fiscus expressed primar a major interest in having meetings which were all english speakers . ",
Bmr011.G,and you combine segments from that same speaker to and run them through the recognizer . is that right ?    cuz i    ,,
Bmr011.H,"does everyone has everyone met don ?   dome it sounds like a topic of conversation . right .  right , actually the way jose is wearing his is c correct . the good way . you want to th that 's good . it 's towards the corner of your mouth that breath sounds don't get on it . and then just about , a thumb or a thumb and a half away from your mouth . and this one isn't very adjustable , this about as good as get cuz it 's a fixed boom .  the onl the only problem with that is right now , some of the jimlets aren't working . the little the boxes under the table . and w i 've only been able to find three jacks that are working .  i 'm not 'm follow . say that again ? just two .  right . right . sounds like uniformity wins .    couple times . what can i say . really ? i 'm not surprised . "" baaah ! "" it 's an advantage when you don't breath . that the point of doing the close talking mike is to get a good quality signal . we 're not doing research on close talking mikes . we might as get it as uniform as we can .  think just do a field trip at some point .   as i said , we 'll do a field trip and see if we can get all of the same mike that 's more comfortable than these things , which are horrible .  and , we 're researchers , we all have big heads .  i should 've i was just thinking i should have invited him to this meeting . i forgot to do it .   hcc . he 's doing array mikes . that would be neat . dan had worked on that . dan ellis ,  that 's the cross correlation was doing b beam forming . no , he did start on it .  that 's another cl cue , that 's true . or who talks the loudest .  just morning . is he involved in ach ! i 'm blanking on the name of the project . nist has done a big meeting room instrumented meeting room with video and microphone arrays , and very elaborate software . is he the one working on that ?   i had read some papers that looked like they had already done some work .  cuz what i had read was , they had a very large amount of software infrastructure for coordinating all this , both in terms of recording and also live room where you 're interacting the participants are interacting with the computer , and with the video , and lots of other   alright . xerox . and then they have little ones too but but they don't have our block of wood , right ? ","it 's towards the corner of your mouth that breath sounds don't get on it . and then just about , a thumb or a thumb and a half away from your mouth . that the point of doing the close talking mike is to get a good quality signal . we 're not doing research on close talking mikes . we might as get it as uniform as we can . as i said , we 'll do a field trip and see if we can get all of the same mike that 's more comfortable than these things , which are horrible . dan had worked on that . dan ellis , that 's the cross correlation was doing b beam forming . nist has done a big meeting room instrumented meeting room with video and microphone arrays , and very elaborate software . ","The discussion was largely focused on efforts to facilitate transcriptions, including the improvement of strategies for transcribing overlapping speech, and achieving greater uniformity in the type of equipment used during recordings and the manner in which recording devices are worn by speakers. "
Bmr011.H,"it 's just a lot of infrastructure that for our particular purpose we felt we didn't need to set up . that 's right , if someone came in and said we really want to do it , we don't care . that would be fine , buy more disk space . i usually do a mix . their software infrastructure had a very elaborate design for plugging in filters , and mixers , and all sorts of processing . that they can do in real time and not save out each channel individually . it was , to actually get a microphone array and do that ? and video and but we need a researcher here who 's interested in it . to push it along . and we actually only have fifteen . one of them 's details . but fifteen , not sixteen . and y it 'd certainly gets skew . just or a hundred thirty two . yes , but it 's exactly the same problem , that you have an infrastructure problem , you have a problem with people not wanting to be video taped , and you have the problem that no one who 's currently involved in the project is really hot to do it .  i know .  probably not . has don have you s did you si you did actually . didn't you read a digit string ? and you signed a form . i 'm pretty 'll get another one before the end of the meeting .  can't , i 'm wired in . or  it 's pretty good .   is is atlas the his annotated transcription graph i don't remember the acronym . the one the what you 're referring to , they have this concept of an annotated transcription graph representation . and that 's what i based the format that i did i based it on their work almost directly , in combination with the tei and it 's very , very similar . and it 's a data representation and a set of tools for manipulating transcription graphs of various types .  right . nu it 's mostly it 's for their speech recognition products , that they 've hired these people to do . they do send it out but my understanding is that 's all this company does is transcriptions for ibm for their speech product . most of it 's viavoice , people reading their training material for that .  exactly .  right . right . but that 's because , you 'll do all them and then combine them . no , no . we 're talking about close talking , not the desktop . i hope it 'd be really foolish to do otherwise . one side . but we had this we 've had this discussion many times . and the answer is we don't actually know the answer because we haven't tried both ways .   right . think that might change if you wanted really fine time markings .  ","to actually get a microphone array and do that ? yes , but it 's exactly the same problem , that you have an infrastructure problem , you have a problem with people not wanting to be video taped , and you have the problem that no one who 's currently involved in the project is really hot to do it . the one the what you 're referring to , they have this concept of an annotated transcription graph representation . and it 's a data representation and a set of tools for manipulating transcription graphs of various types . but we had this we 've had this discussion many times . and the answer is we don't actually know the answer because we haven't tried both ways . ",
Bmr011.H,"right . i 'd be curious to look at that . they also all have h heavy accents . the networks group meetings are all we can talk about more details later .  liz , with the sri recognizer , can it make use of some time marks ? don't that means . adjusting . on just on the marks . right ? i see , it 's for the length . i see . i understand . it 's already chunked . it 's all pretty good sized for the recognizer also . right . that 's what she 's saying , is that you can't . got six sixty minutes of but we 'll have to talk to brian . february sixteenth  we had spoken with them about it . which one . but just saying what the just features .   right . non icsi ? you can try but the problem is much of their is confidential . it would be very hard for them . tha that 's her point . and if we could get  you might give them a free lunch . but , it would be if we got someone other than me who knew how to set it up and could do the recording i didn't have to do it each time . next week you 're going to do it all . it 's not that hard .  i don't know if they meet regularly or not but they are no longer recording . ugh , what was his name ?  when with him gone , it sorta trickled off . they and they stopped   he was my contact , just need to find out who 's running it now .  who 's willing to get recorded and distributed ?  of beeps ,  no that 's legal .  if he meant and non british we have zero . british is english ? i bet he meant native speaking american . why would he care ? i wonder if we have any .   and there are a few of with us where it was dan wasn't there and before jose started coming , and  rasta . plp . rasta . plp . like computer science . that that 's got a ticket . had asked some of the students at the business school . i could the business school . the business school might be good . i actually spoke with some students up there and they expressed willingness back when they thought they would be doing more with speech . but when they lost interest in speech they also stopped answering my email about other  we should probably bleep that out . th that 's not what we want . that 's right . "" throw everything in that direction . "" padded cell . there was a dorm room at tech that , someone had coated the walls and the ceiling , and , the floor with mattresses . the entire room . ","liz , with the sri recognizer , can it make use of some time marks ? ",
Bmr011.H,"liz wanted to talk about methods of improving accuracy by doing pre processing .  i am not how much that 's an issue with the close talking mikes , but who knows ? right . e i bet with the lapel mike there 's plenty , room acoustic but the rest is cross talk .  think it 's just , what you said , cross talk .  ",,
Bmr012.A,"there was a bug . i it wasn't using the proper it wasn't adapting anything .  because when it estimates the transformer pro produces like a single matrix there were no counts hello , hello .    may i make one suggestion ? instead of age put date of year of birth because age will change , but the year of birth changes , stays the same , usually .  if ten years from now you look at this form knowing that don't know . anyway .     it was interesting , suddenly the overall error rate when we first ran it was like eighty percent but i looking at the first sentences looked much better than that and then suddenly it turned very bad and then we noticed that the reference was always one off with the it was actually recognized    we have everything recognized but we scored only the first whatever , up to that time to  and i have      there are a fair number of errors that are , where got the plural s wrong or the inflection on the verb wrong . if       it 's the it 's  that 's those are the only we ones there are ,  right .   i should say that the language model is not just switchboard it 's also there 's actually more data is from broadcast news but with a little less weight because  right . just for fun we also ran , our complete system starts by doing ge a gender detection just for the heck of it i ran that and it might be reassuring for everybody to know that it got all the genders right .   yes . clearly there are with just a small amount of actual meeting transcriptions thrown into the language model you can probably do quite a bit better because the not that much the vocabulary actually we have to see but it 's we talked about setting up the sri recognizer here . that 's if there are more machines here plus people can could run their own variants of the recognition runs  certainly doable .    u   u actually i had a question about the downsampling , don't know who , how this was done but is there are there any issues with downsampling because i know that the recognizer that we use h can do it on the fly  we wouldn't have to have it do it explicitly beforehand . and is there any are there other d sev is there more than one way to do the downsampling where one might be better than another ?  right .  the th the other thing we should try is to just take the original wave forms , segment them but not downsample them . and feed them to the sri recognizer and see if the sri front end does something .  right and it doesn't is no more work for for us . but they 're only twice as big  it 's just a mean it would be it would probably take about ","suddenly the overall error rate when we first ran it was like eighty percent but i looking at the first sentences looked much better than that and then suddenly it turned very bad and then we noticed that the reference was always one off with the we have everything recognized but we scored only the first whatever , up to that time to there are a fair number of errors that are , where got the plural s wrong or the inflection on the verb wrong .  i should say that the language model is not just switchboard there 's actually more data is from broadcast news but with a little less weight our complete system starts by doing ge a gender detection and it might be reassuring for everybody to know that it got all the genders right . clearly there are with just a small amount of actual meeting transcriptions thrown into the language model you can probably do quite a bit better we talked about setting up the sri recognizer here . that 's if there are more machines here plus people can could run their own variants of the recognition runs the other thing we should try is to just take the original wave forms , segment them but not downsample them . and feed them to the sri recognizer and see if the sri front end does something . ",
Bmr012.A,"minus the transfer time it would take ten minutes to try and and if for some reason we see that it works better then we might investigate why and , what   right . right . at some point someone might have optimized whatever filtering is done for the actual recognition performance . in other words right ,  mel cepstrum . that 's what i would assume but you never know ,   actually , no . don't stop . don't stop at that part because we 're actually using the entire conversation to estimate the speaker parameters , shouldn't use you should s get right .  right .     they 're less animated . like like jerry springer thing ,   do you have to hand it around and if you have two pieces of pretty soon . gotta go . ",and if for some reason we see that it works better then we might investigate why mel cepstrum . ,
Bmr012.B,"let 's see , i should be two . la is this channel one ? gee , yes .   what do you do , you do it higher ?   you wanna close this , or we 're recording , right ?   that 's a good idea . i shouldn't run the meeting .  good idea . s haven't seen the email , what was the score ?    un unsurprisingly adam is the golden voice , you see this here ?   we don't even that means ,   we 're in better shape than we were say when we did had the ninety three workshop and we were all getting like seventy percent error on switchboard .    one thing didn't get the language model was straight from bigram from switchboard the acoustic models were also from switchboard or they didn't have anything from this acoustic data in yet ?   right .  but for broadcast news when we played around between the two there wasn't a huge loss .  good point .    i would bet on that too cuz he certainly in that when as a burp user he was a pretty strong one .  sheep .  sheep is good .  have to add pzm and on but  i r   which i would which there 's still just the w the percentages and , they 're not a as we 've talked about before there 's probably overlaps there 's probably overlaps in in fair number in switchboard as  but there 's other phenomena , it 's a meeting , it 's a different thing and there 's lots of to learn with the close talking mikes but certainly i 'd like to see as soon as we could , get some of the glitches out of the way but soon as we could how it does with say with the p z ms or even one of the and see if it 's , is it a hundred twenty percent or it 's not if with some adaptation you get this down to fifty percent or forty five percent and then if for the pzm it 's seventy like that that 's actually something we could work with a little bit   and certainly if the recognition as opposed to training ,  seems reasonable . we just have to go through this process of having people approve the transcriptions , say it 's we , once we get all this streamlined it may be sh it hopefully it will be fairly quick but we get the transcriptions , people approve them and on it 's just that we 're it 's gonna be a rare thing that there 's a bleep for the most part . you just train just different filters and you 're just wondering whether the filter is right . are you using mel cepstrum or plp over there ? probably doesn't matter . but it wouldn't hurt to try ,   no the reason i say this ","the acoustic models were also from switchboard or certainly i 'd like to see as soon as we could , get some of the glitches out of the way but soon as we could how it does with say with the p z ms or even one of the we just have to go through this process of having people approve the transcriptions , are you using mel cepstrum or plp over there ? ","It was decided that close-talking data should be downsampled and fed to the SRI recognizer to compare recognition performance, and that data from the far-field microphones should be tested on the recognizer as soon as possible. "
Bmr012.B,"plp uses auto regressive filtering and modeling and it can be sensitive to the filtering that you 're doing but mel cepstrum might not b you wouldn't expect to be much but this is being recorded at forty eight kilohertz . which is more that anybody needs   it 's a digital audio orientation for the board it 's in the monitor it 's  for telephone it 's it 's just that they were operating from switchboard which was a completely telephone database and that was a standard for that sixteen s sixteen is more common for broadband that isn't that isn't music and isn't telephone ,  i don't know . no actually i would think that you would get better you 'd get better high frequencies in the local mike . but who knows ? we do we we wanna find all this out , we don't know .   weren't we gonna do something with a pad at one point ?  what i was just suggesting is we have these this cross pad just for this purpose and just use that and if we sink it in the other thing is i don't know if this or if it 's a question for the mail to dan but is this thing of two eight channel boards a maximum for this setup or could we go to a third board ? it is one board . but that 's a question because that would if it was possible cuz it is i already we have a group of people in this room that cannot all be miked and it 's not just cuz we haven't been to the store , right it 's it might be a hard limitation , one thing is it the whole thing as i said is all structured in terms of forty eight kilohertz sampling that pushes requirements up a bit but   at least w we got the good ones .   there isn't this some thing that plugs in , you actually have to go and do the soldering yourself ? no i understand . the reason i ask is these handmade wiring jobs fall apart in use the other thing is to see if we can get them to do a custom job and put it together for this .  no they 'll just charge us more , it 's this not before having one come here and have some people try it out . because there 's no point in doing that if it 's not gonna be any better .  and see if it 's preferable and if it is then we 'll get more .  right . it 's we 're in this for the long term ,  just order it . we 'll do this off line , right cuz one is for the daisy chain that 's fifteen instead of sixteen and there 's six on the table that 's nine .  that 's a good idea . that 's not a dumb question , it 's a good idea ,  ","this is being recorded at forty eight kilohertz . which is more that anybody needs sixteen is more common for broadband that isn't that isn't music and isn't telephone , but is this thing of two eight channel boards a maximum for this setup or could we go to a third board ? already we have a group of people in this room that cannot all be miked just order it . ",
Bmr012.B,"no that no that 's a very if we can't get another board and even if we can i have a feeling they 'll be some work . let 's figure that we have eight which are set up and then there 's a ninth which is passed around to that 's a good idea right . rules out overlap but  no no that 's no . yes . no it no it depends on the hand held but hand many hand helds are built wi with anti shock things that it is less susceptible to hand noises . if you hold the lapel mike i you just get all k sorts of junk .   they have what ? no that 's you need a transmitter . see . get a different radio ,   but you need a ra but it has to correspond to the receiver . no right , this is a good point , you have these mikes with a little antenna on the end right ? i don't know . you 'll have to check with them ,  but that 's a great idea and then just have that as the and then you can have groups of twenty people or whatever and right . off you go ,  pretty close , that 's good . super idea . now you have eight transcribers and there 's ten of us how do we do this , is the only thing .  we could they could have a meeting more or less without us that to do this and we should record it and then one or two of them could come to one of these meetings and could could tell us about it .   super .    but the nine o ' cl nine o ' clock will be i be in here .  just adds good . do digits and recess ?   no i don't think it 's confusing . it doesn't confuse me .  that 's fine .  he 's in the cour two five d course .    let 's do digits .  ",if we can't get another board and even if we can i have a feeling they 'll be some work . you have these mikes with a little antenna on the end but that 's a great idea and then just have that as the and then you can have groups of twenty people or whatever we could they could have a meeting more or less without us that to do this and we should record it ,
Bmr012.C,"who 's channel b ?  no i  you 're channel b . can you talk a bit ? it might be too   a actually , minute , shouldn't it be the other way around ? on the other side ,  o w we don't care how they old they really are . i still don't see the problem . what time do we have to leave ? three thirty ?   i sent out an email s couple hours ago  with andreas ' help andreas put together a no frills recognizer which is gender dependent but like no adaptation , no cross word models , no trigrams a bigram recognizer and that 's trained on switchboard which is telephone conversations . and to don 's help wh who don took the first meeting that jane had transcribed and separated used the individual channels we segmented it in into the segments that jane had used and don sampled that eight k and then we ran up to the first twenty minutes , up to synch time of one two zero is that 's twenty minutes or because there 's some , and don can talk to jane about this , there 's some bug in the actual synch time file that i 'm we 're not where it came from but after that was a little messier . anyway it 's twenty minutes and i actually  there 's a  that actually  if it was twenty minutes in then i don't know wel no actually it was it was a complicated bug because they were sometimes one off and then sometimes random    that 's what we have but that will be completely gone if this synch time problem you guys know .  here 's the actual copy of the email  does this glitch occur at other  right . and is it only once that happens ?  there 's the previous page has some more information about what was wrong but  that 's actually it y it 's  no what happens is it actually affects the script that don if we know about it then it could always be checked for it but they  the synch time the synch numbers have more significant digits than they should , right ? there 's things that are l in smaller increments than a frame . and then , you look at that and it 's got more than three significant digits in a synch time then that can't be right anyway it 's just that 's why we only have twenty minutes but there 's a significant amount of that was fine . that was that would really be a problem ,  anyway these are just the ones that are the prebug for one meeting . and what 's which this is really encouraging cuz this is free recognition , there 's no the language model for switchboard is different you can see some like this trent lott which mean these are funny ones , ","with andreas ' help andreas put together a no frills recognizer which is gender dependent but like no adaptation , no cross word models , no trigrams a bigram recognizer and that 's trained on switchboard which is telephone conversations . don took the first meeting that jane had transcribed and separated used the individual channels we segmented it in into the segments that jane had used anyway it 's twenty minutes and i actually it was a complicated bug because they were sometimes one off and then sometimes random but that will be completely gone if this synch time problem the synch time the synch numbers have more significant digits than they should , there 's things that are l in smaller increments than a frame . anyway these are just the ones that are the prebug for one meeting . this is really encouraging cuz this is free recognition , ",The Berkeley Meeting Recorder group discussed recognition results generated for 20 minutes of close-talking microphone data. 
Bmr012.C,"there 's a lot of perfect ones and good ones and all the references , you can read them and when we get more results you can look through and see but it 's pretty good . guess we can generate  there 's no those are actually a lot of the errors are out of vocabulary , is it like pzm is three words , it 's pzm , there 's nothing there 's no language model for pzm or  no language model , those there 's all kinds of other like jimlet and anyway there but this is really encouraging because the bottom line is even though it 's not a huge amount of data it should be reasonable to actually run recognition and be like within the scope of r reasonable s switchboard this is like h about how we do on switchboard two data with the switchboard one trained mostly trained recognizer and switchboard two is got different population of speakers and a different topic and they 're talking about things in the news that happened after switchboard one there was @ @ that 's great .   this is really , and to andreas who , this is a   and what al also this means is that  there 's a bunch of things in this note to various people especially with jane that would help for since we have this new data now in order to go from the transcripts more easily to just the words that the recognizer would use for scoring . i had to deal with some of it by hand but lot of it can be automated s by  no . and actually we actually used switchboard telephone bandwidth models which that 's the on that 's the only acoustic training data that we have a lot of and ramana , guy at sri said that there 's not a huge amount of difference going from it 's not like we probably lose a huge amount but we won't know because we don't have any full band models for s conversational speech .  right . right , it 's  wou that 's good .  like trent lott must have been from switchboard was before  the j  but jane and adam have you kn about equal performance and and that 's interesting cuz the their language models are quite different  and i 'm pretty from listening to eric that , given the words he was saying and given his pronunciation that the reason that he 's much worse is the lapel . it 's now if we can just eliminate the lapel one when we get new microphones that would be worth it   he sounded to me just from he sounded like a , what 's it a sheep or a goat ? sheep , right . sounded good . right guess the good news is that this is without a lot of the bells and whistles that we c can do with the sri system ","a lot of the errors are out of vocabulary , the bottom line is even though it 's not a huge amount of data it should be reasonable to actually run recognition and be like within the scope of r reasonable s switchboard this is like h about how we do on switchboard two data with the switchboard one trained mostly trained recognizer and switchboard two is got different population of speakers and a different topic and actually we actually used switchboard telephone bandwidth models ",
Bmr012.C,"and we 'll have more data and we can also start to adapt the language models once we have enough meetings . this is only twenty minutes of one meeting with no tailoring  the voca the vocabulary especially    it 's pretty good then pzm and then there 's things like for the transcription i got when someone has a digit in the transcript i don't know if they said , one or eleven and i don't know if they said tcl or tcl . there 's things like that where , the we 'll probably have to ask the transcribers to indicate some of those kinds of things but in general it was really good and i 'm hoping and this is good news because that means the force alignments should be good and if the force alignments , it 's good news anyway but if the force alignments are good we can get all kinds of information . about , prosodic information and speaker overlaps and forth directly from the aligned times . that 'll be something that actually in order to assess the forced alignment we need s some linguists or some people to look at it and say are these boundaries in about the right place . because it 's just gonna give us time marks  for forced alignment . ye right . right . this would be like if you take the words and force align them on all the individual close talk close talking mikes then how good are these in reality and then i was thinking it  or i have someone look at the alignments linguist who can say roughly if these are and how far away they are . but it 's gotta be pretty good because otherwise the word recognition would be really b crummy . it wouldn't necessarily be the other way around , if the wor word recognition was crummy the alignment might be but if the word recognition is this good the alignment should be pretty good . that 's about it . this i  this is not that good . right .  no it 's really , this way we least have a baseline we know that the transcripts are very good once you can get to the words that the recognizer which is a total subset of the things you need to understand the text they 're pretty good and it 's converting automatically from the xml to the chopping up the wave forms and forth it 's not the case that the end of one utterance is in the next segment and things like that which we had more problems with in switchboard that 's good . and let 's see there was one more thing i wanted to mention i can't remember  can't remember . anyway it 's it was , really didn't do this myself andreas set up this recognizer and the recognizer all the files i 'm moving to sri and running everything there brought back just these result files ","and we 'll have more data and we can also start to adapt the language models once we have enough meetings . this is only twenty minutes of one meeting with no tailoring and this is good news because that means the force alignments should be good but if the force alignments are good we can get all kinds of information . about , prosodic information and speaker overlaps and forth directly from the aligned times . actually in order to assess the forced alignment we need s some linguists or some people to look at it and say are these boundaries in about the right place . this would be like if you take the words and force align them on all the individual close talk close talking mikes then how good are these in reality but it 's gotta be pretty good because otherwise the word recognition would be really b crummy . it 's not the case that the end of one utterance is in the next segment and things like that which we had more problems with in switchboard ","The Berkeley Meeting Recorder group discussed recognition results generated for 20 minutes of close-talking microphone data. Recognition performance was very good, indicating promising results for forced alignment procedures and the ability to analyze other important signal information, e.g. prosody and overlapping speech. "
Bmr012.C,"and people can look at them  from the outside world or   we have n no names . although i sh de audio data itself ? can protect my directories through there . right now they 're not they 're in the speech group directories which will i didn't know that actually .  right that 's true . actually the bleeps are also an issue don did this . re ref  missing all the vowels . some of the vowels , almost all the vowels , that 's the hard part . we could try that and compare  we can try it . i only downsampled them first cuz i was  they 're just bigger to transfer , that 's why i s downsampled them before but mean that was if it 's the same then we can downsample here but if it 's  we could try that . it takes more disk space too was just we could try that with this particular twenty minutes of speech and see if there 's any differences . it 's just as easy to give you the sixteen k individual , it was just more disk space for storing them  we could try . could easily try  we can try it if you generate like the same set of files just up to that point where we stopped anyway and just sti stick them somewhere and i 'll rerun it with  right . right . corrected all hand edited the whole meeting that can be run it 's just once we get the bug out . and that 's actually said in your meeting , that 's how i know that . i it 's like are we downsampling to sixteen ? right . thank god it 's not more than that . and if you 're comparing like if you wanna run recognition on the pzm you would want you don't want to downsample the wh that right ? don if it 's any better  we could try it .    there was just one more thing i wanted to say which is unrelated to the recognition except that  it 's related but good news also got chuck fillmore to record meetings but he had too many people in his meetings and that 's too bad cuz they 're very animated and but jerry also we 're starting on but he has fewer he won't have more than eight and it 's a meeting on even deeper understanding , edu , that sounds interesting . as a compliment to our front end meeting and that 's gonna start monday and one of the things that i was realizing is it would be really great if anyone has any ideas on some time synchronous way that people in the meeting can make a comment to the person whose gonna transcribe it or put a push a button when they wanna make a note about "" boy you should probably erase those last few "" or want this not to be recorded now "" like that s ","we could try that with this particular twenty minutes of speech and see if there 's any differences . and but jerry also we 're starting on and it 's a meeting on even deeper understanding , edu , and one of the things that i was realizing is it would be really great if anyone has any ideas on some time synchronous way that people in the meeting can make a comment to the person whose gonna transcribe it ","The collection of Meeting Recorder data is ongoing, and will include meetings by the Berkeley Even Deeper Understanding research group and, possibly, an organized discussion by members of the transcriber pool. "
Bmr012.C,"cuz i was thinking if the person who sets up the meeting isn't there and it 's a group that we don't know and this came up talking to jerry also that is there any way for them to indicate to make that the qu request that they have that they make explicitly get addressed somehow don't know if anyone has ideas or you could even write down "" it 's about three twenty five and "" that would be great . that be great . for each ? the tuner is four thirty for each .  comfort . cuz the microphones are it 's just the could make our own handbands and it 's a lot of money for a handband . can i ask a really dumb question ? is there any way we can have like a wireless microphone that you pass around to the people who the extra people for the times they wanna talk that  mean but but there might be a way to say that there are gonna be these different people and i don't know identifying somehow ? was just thinking of jerry springer . for the few times that you might wanna have that . or also for if people are not no not the lapel . i don't know but i d i know the lapel is really suboptimal . right . the ones they really pass around must be just these ones that they pass around with no wireless right . because there 's only as andreas pointed out actually in the large the larger the group the less interaction the less people are talking over each other it just there might be a lot of people that speak once or twice and it 's great i j and this i got this email from jane at like two in the morning it 's really great it 's really great . that 's a great idea . that 's a great idea cuz i 'd like to g have it recorded that we can remember all the little things , that 's a great idea . or just have them talk amongst themselves . and have that would be great . that 's a great idea . be great .  it 's they will get to transcribe their own meeting but they also get paid for having a break and that 's a good idea , get them involved . that 's a great idea . i 'm really have to g no i have to go as ",is there any way we can have like a wireless microphone that you pass around to the people who the extra people for the times they wanna talk that that 's a great idea . ,A tentative decision was also made to integrate the use of a hand-held wireless microphone to help compensate for the lack of available close-talking microphones. 
Bmr012.D,"up high high as you can get . adam 's just trying to generate good data for the recognizer there . it was .  that 's interesting . why didn't you get the same results and the unadapted ? why didn't you get the same results and the unadapted ? o see . i see , i see . i see what california . not for me . but there 's no other date on the form .  trent lott . it 'll get those though . i was just gonna say ,  it 's probably not as bad as going f using full band models on telephone band speech right ? but i wonder if this is a good thing or a bad thing though , if we 're pr if we 're producing a database that everybody 's gonna do on the real value of the database is these ? telephone . what is the limit on each of those f fiber channels , is it the it just it 's eight channels come in , does it have do with the sampling rate ? i was just wondering if that could change . if we could drop that .   and they 'd probably want quantity too , they 'd  like at conferences nail the chairs down . the springer mike . infinite expansion . liz hates the lapel .  you wouldn't want it to hook there you 'd just want it to hook into the receiver in the other room , right ? is th isn't that built into the mike ? have a little antenna coming out the bottom . but then the mike has to h it 's just a frequency .   if we got them to talk about this meeting , it would be a meta meeting . have them have their own meeting . do digital ones ? does it mess up the forms ? the on switch is here on the top there . welcome . ",,
Bmr012.E,"as close to your mouth as you can get it . for people wearing the wireless mikes , like this one , i find the easiest way to wear it is sorta this sorta like that . it 's actually a lot more comfortable then if you try to put it over your temples ,  and then also , for all of them , if your boom is adjustable , the boom should be towards the corner of your mouth , and about a thumb to a thumb and a half distance away from your mouth , about like i 'm wearing it now . jane , you could actually do even a little closer to your mouth , but  channel five , s speak again . that 's alright . we could up the gain slightly if you wanted to . but channel b is probably liz .  it 's alright . the gain isn't real good .  we are recording . everyone should have at least two forms possibly three in front of you depending on who you are . we 're doing a new speaker form and you only have to spea fill out the speaker form once but everyone does need to do it . and that 's the name , sex , email , et cetera . we had a lot of discussion about the variety of english and on if you don't to put just leave it blank . designed the form and i don't to put for my own region ,  california .   birth year ? guess it depends on how long the corpus is gonna be collected for . either way think age is alright and then there will be attached to this a point or two these forms that you 'll be able to extract the date off that anyway . and then you also have a digits form which needs to be filled out every time , the speaker form only once , the digit form every time even if you don't read the digits you have to fill out the digits form that we know that you were at the meeting .  and then also if you haven't filled one out already you do have to fill out a consent form . and that should just be one person whose name i don't know .    should we do agenda items ? have i wanna talk about new microphones and wireless and i 'm liz and andreas wanna talk about recognition results . anything else ? why don't you go first then . or  i was that did that recording have the glitch in the middle ? i don't remember when it is . no . that was just a parsing mismatch . alright . the glitch  th the  there there 's an acoustic glitch that occurs where the channels get slightly asynchronized the that problem has gone away in the original driver believe it or not when the ssh key gen ran the driver paused for a fraction of a second ",have i wanna talk about new microphones and wireless and i 'm liz and andreas wanna talk about recognition results . there there 's an acoustic glitch that occurs where the channels get slightly asynchronized the that problem has gone away in the original driver believe it or not when the ssh key gen ran the driver paused for a fraction of a second ,The group also discussed recording setup and equipment issues. The Berkeley Meeting Recorder group discussed recognition results generated for 20 minutes of close-talking microphone data. 
Bmr012.E,"and the channels get a little asynchronous and if you listen to it in the middle there 's a little part where it starts doing click sounds . but  it right once in the middle . but that shouldn't affect anything  "" bah "" the acoustic one shouldn't do anything . but i do remember i do remember seeing once the transcriber produce an incorrect xml file where one of the synch numbers was incorrect . where they weren't monotonic .  that 's sounds like a bug . the other one i saw was that it  the other one i saw was non monotonic synch times and that definitely indicra indicates a bug . that 's very encouraging . i and as i said i would like to look at the lattices because it sounded like even the ones it got wrong it got it right ? sounds likes ?  and who cares ? and there were lots the "" s , "" in on "" s "" of s . right . ri right . did you say there 's no language for pzm ? do every time someone says pzm it 's an error ? we shouldn't say pzm in these meetings . that 's right , jimlet . that 's right . right . excellent . especially for the very first run , you the first run i ran of switchboard i got a hundred twenty percent word error but not switchboard , broadcast news . that 's great .  right , it was not a big deal . although combining worked and it said a hundred percent male ? it did ? it got all two genders ? right . sheep . a sheep . baah . or just dictionary . and i have to try it on the far field mike  we 've done that for one meeting .  f not for words i 'm just for overlaps is we did it for not for words . right . we might want to take twenty minutes and do a closer word level transcription . actually mark the word boundaries . right , right . that we 're starting don't worry about it w d that 's the close talking mikes . try it on the p z ms and abso no but it 's really good . it 's human subjects issues , i told you about that . that 's not the issue , it 's just the audio data itself , until people have a chance to edit it . it 's us . alright we need to work at a system for doing that approval that we can send people the transcripts and get back any bleeps that they want i don't think we even know which one i assume you 're using syncat to do it ? or sound resample ? resample . and dan 's archaic acronyms . not all of them . and a few of the consonants . i suspect that 's premature optimization , but   ",i do remember seeing once the transcriber produce an incorrect xml file where one of the synch numbers was incorrect . and i have to try it on the far field mike we need to work at a system for doing that approval that we can send people the transcripts ,"It was decided that close-talking data should be downsampled and fed to the SRI recognizer to compare recognition performance, and that data from the far-field microphones should be tested on the recognizer as soon as possible. "
Bmr012.E,"it 's about a fifty minute drive , right ? it just seems to me that , small changes to the language model and the vocabulary will swamp that it may be premature to worry about that . one is a half a percent better than the other i don't think that gives you any information .    there 's one level that 's already happening right here . right . and it gets downsampled to sixteen .  and i have no idea what filter it 's using ,  telephone . sixteen seems to be pretty typical for with this thing . that isn't music . why is that ? all the way around i 'd think .  we 're gonna have plenty of low frequency on the p z ms with the fans . dot edu ? we could do it with the cross pads . and use that . not a bad idea . i don't know . i don't know . i 'll send mail to dan and ask . that it 's the maximum we can do without a lot of effort because it 's one board with two digital channels . e eight each . it takes two fibers in to the one board . and if we wanna do that more than that we 'd have to have two boards , and then you have the synchronization issue . right . eight . it 's eight . i have no idea . but each fiber channel has eight channels and there are two ch two fibers that go in to the card .   then we 'd also have to get another add and another mixer and all that 'll send a mail to dan and ask him . on the are we done with that ? the oth topic is getting more mikes and different mikes , got a quote  we can fit we have room for one more wireless and the wireless , this unit here is three fifty three hundred fifty dollars , it i didn't realize but we also have to get a tuner the receiver the other end , that 's four thirty and then also  and we just need one more  that 's something like seven hundred eighty bucks for one more of these . and then also it turns out that the connector that this thing uses is proprietary of sony believe it or not and sony only sells this headset . if we wanna use a different set headset the solution that the guy suggested and they lots of people have done is sony will sell you the jack with just wires coming out the end and then you can buy a headset that has pigtail and solder it yourself . and that 's the other solution and the jacks are forty bucks apiece and the he recommended crown cm three eleven ae headset for two hundred bucks apiece . ","there 's one level that 's already happening right here . and it gets downsampled to sixteen . we could do it with the cross pads . that it 's the maximum we can do without a lot of effort because it 's one board with two digital channels . it takes two fibers in to the one board . and if we wanna do that more than that we 'd have to have two boards , and then you have the synchronization issue . the oth topic is getting more mikes and different mikes , we can fit we have room for one more wireless ",
Bmr012.E,"becau the reason is the only thing you can get that will plug into this is this mike or just the connector . 'm they would , they would just charge us ,  my question is should we go ahead and get na nine identical head mounted crown mikes ?  why don't we get one of these with the crown with a different headset ? and see if that works .  right , it 's just they 're not comfortable to wear . and he said they don't have any of these in stock but they have them in la and it will take about a week to get here . to just go order ?  and who is the contact if i wanna do an invoice cuz that 's how we did it before .  and then nine channels is the maximum we can do ,  without getting more right . probably . i 'm just not how we would handle that in the somehow . it 's not a bad idea . a hand held ,  we could just hand around the lapel . rather than get a do you want a handset ? mean is the hand held really any better ?  is awful ?  wonder if they have one that will hook up . i wonder if they have one that will hook up to this or whether again we 'll have to wire it ourselves . what ? it 's gonna be much easier to get one of these and just plug in a mike , isn't it ?  and do you think you would be able to use the same receiver ? 'll ask .   guess people who have to leave can leave and do we have anything else to discuss or should we just do digits ?   that 's good .  that 'd be very interesting . i 'd love to hear what they have to say . i 'd like to hear what they s say . give us a status . that would be weird . where you 're gonna meet ? i assume we 're not gonna try to record it ? alright . unless there 's anything else ? should y we make him wear andreas ' mike or would that just be too confusing ? just don't know how we would do that ,  other than free form . and just clip it to your collar . great . and are you staying at berkeley or is are you just here a semester ? second and last ,  good . digits ? and stop . ",why don't we get one of these with the crown with a different headset ? i 'd like to hear what they s say . ,
Bmr012.F,"test . channel five , channel five . test , test . test . adam , i 'm not looks kinda low on channel five no ? not . hello ? it 's is this  do you want this adam ? was it twenty minutes in ,  that might be that might be my fault . i 'm not i was pretty certain that it worked up until that time ,   i don't know exactly what affected it but i 'll talk to you about it , i 'll show you the point . that 's what happened . there was   non zero ? there are like more cuz there 's a lot of zeros i tacked on just because of the way the script ran , but there were there was a point .    there are lots of w there are lots of ways to do the downsampling different filters to put on , like anti aliasing no , i 'm using sn snd are resample . rsmp . i don't really . found it . that 's that 's just one line that 's one line of code to comment at   although those eighty meg files take a while to copy into my directories  but no , it 's not i it wouldn't be a problem if you 're interested in it it would   in the front end we could do that . i imagine it would be guess there 's some  there 's your answer . it 's really not a problem . keep going .  'll i have to do is the reference file would stay the same , it 's just the individual segments would be approximately twice as long and i could just replace them with the bigger ones in the directory , that 's not a problem .   is eight kilohertz is eighty kilohertz generally accepted as like standard for voice ? that 's what i was gonna say , like  i see ,   right .  it 's a long time to get from la . that 's like the conch . see , look .   we were just talking about something like this yesterday or yesterday with liz . about doing some of the echo cancellation or possibly the spectroanalysis over the overlaps ,   ","i was pretty certain that it worked up until that time , there are lots of w there are lots of ways to do the downsampling different filters to put on , ",
Bmr012.G," on your upper lip . we 're supposed to that 's right . i could can this be adjuste like this ? is that @ @ ?  hello . channel eight , eight . although on course on the other hand you could you view it as the age at the time of the yes , but what we care about is the age at the recording date rather than the yes . unless we wanna send them a card . that 's true .  i 'm puzzled by that . i i see . there was a glitch somewhere . i forgot about that . they but i was able to can transcribe   that 's not good .  and the only glitch  the we should say something about the glitch . he can say something about the glitch . cuz it 's it 's h it 's very small very small .  s and it i agree . i agree .  it had no effect on my transcription , had no trouble hearing it and having time bins but there was a   interesting .    right . that 's amazing . that 's amazing . that 's i 'm glad . that makes a lot of sense ,  very possible .  congratulations is really great . i need t i need to ask one question . which is this issue of the legalistic aspects of the pre sent pre adapted what is  the the data that you take into sri , first question , you 're maintaining it in a place that wouldn't be publicly readable that right ? by people who are not associated with this project . exactly . exactly .  great . we had to get them to approve and then i cuz the other question i was gonna ask is if we 're having it 's but this meeting that you have , no problem cuz speak for myself but that we didn't do anything that but anyway wouldn't be too concerned about it with respect to that although we should clear it with eric and dan but these results are based on data which haven't had the haven't had the chance to be reviewed by the subjects and i don't know how that stands , if you get fantastic results and it 's involving data which later end up being lessened by , certain elisions , then i don't know but i wanted to raise that issue , that 's all . great .  just one question which is i had the impression from this meeting that w that i transcribed that that there was already automatic downsampling occurring , is that that in order to it was it 's like there 's already down    that 's exactly , and that 's how i know it . the cross pads ?  of some extra a couple of extra things i 'd like to mention . one of them is to give you a status in terms of the transcriptions far . ","one question which is i had the impression from this meeting that w that i transcribed that that there was already automatic downsampling occurring , one of them is to give you a status in terms of the transcriptions far . ",
Bmr012.G,"as of last night 'd assigned twelve hours and they 'd finished nine and my goal was to have eleven done by the end of the month , that by tomorrow we 'll have ten . they 're still working . it 's working out ,  and then also an idea for another meeting , which would be to have the transcribers talk about the data it 's little bit   exa exactly nested several layers , but that 's what i 'm thinking ,  have them talk about the data and they 've made observations to me like they say this meeting that we think has much overlap , it does but there are other groups of similar size that have very little , it 's part of it 's the norm of the group and all that and they have various observations that would be fun ,    good .  what that 's right . exactly ,  great . great . and then i wanted to also say something about the fiscus john fiscus visit tomorrow . and which is to say that w it 'll be from nine to one that i 'm going to offer the organization allow him to adjust it if he wishes but to be in three parts , the acoustic part coming first which would be the room engineering aspects other things and he 'll be also presenting what nist is doing and then number two would be the transcription process this would be a focus on like presegmentation and the modifications to the multitrans interface which allows more refined encoding of the beginnings and ends of the overlapping segments which dave gelbart 's been doing and then and the presegmentation thilo 's been doing and then the third part would he has some that 's i relevant with respect to nist and then the third one would be focus on transcription standards at nist he 's interested in this establishment of a global encoding standard would say and i want it ,   see what they 're doing and also present what we 've chosen as ours and discuss that thing . and but he 's only here until one and actually we 're thinking of noon being lunch time hoping that we can get as much of this done as possible before noon . s and everybody who wants to attend is welcome .   here mostly but i 've also reserved the barco room to figure out how that works in terms of like having a live demonstration .   think that would be hard ,  though ,     when we do this in the key in the key it has to indicate that channel change , right ? have a time mark .  then you go back to norway , that 's  ","as of last night 'd assigned twelve hours and they 'd finished nine that by tomorrow we 'll have ten . and then also an idea for another meeting , which would be to have the transcribers talk about the data ","The collection of Meeting Recorder data is ongoing, and will include meetings by the Berkeley Even Deeper Understanding research group and, possibly, an organized discussion by members of the transcriber pool. "
Bmr012.H,"channel one . this is chan channel one two three it 's not always possible .   channel b i am channel b . no , channel b .   channel b , one two three four five .   california .     ",,
Bmr012.J,"my name is espen eriksen . i 'm a norwegian . this is my second semester at berkeley . currently i 'm taking my first graduate level courses in dsp and when i come back to norway i 'm gonna continue with the more of a research project work work . this semester i 'm starting up with a small project through dave gelbart which i 'm taking a course with i got in touch with him and he told me about this project . with the help of dan ellis i 'm gonna do small project associated to this . what i 'm gonna try to do is use ech echo cancellation to to handle the periods where you have overlapping talk . to try to do something about that . currently i 'm 'm just reading up on echo cancellation , s looking into the theory behind that and then hopefully i get some results . it 's a project goes over the course of one semester . 'm just here today to introduce myself . tell about i 'll be working on this . this is my second semester and last . leave i 'm in morgan 's course ,    ",my name is espen eriksen . i 'm a norwegian . with the help of dan ellis i 'm gonna do small project associated to this . what i 'm gonna try to do is use ech echo cancellation to to handle the periods where you have overlapping talk . ,
Bmr016.A,"     overlapping digits !    the aurora theater . pairwise . just pairwise , or  that 's german ,  these  your asr results were run on the channels synchronized ,           there were several speakers in it ,      should it i 've actually done some experiments with cross correlation and it seems to work pretty to get rid of those overlaps ,    in another way ,    'm working on it . no , with the transcriber tool , it 's no problem . just to load a transcription takes a long time , but not for the wavefile . the wavefile is there immediately .  i 'm tr talking about transcriber .  whew ! it 's the castle of h the transcription or ooo no .  the question marks , what are those ?   what is the difference between "" papers rustling "" and "" rustling papers "" ?  seems now it 's at least six times , seven hundred eighty five instances . tickle ? to the language model .  "" tickle "" is pronounced "" tickle "" ?  to head . that 's the training data .  great . great .    thought we sh perhaps we should try to start with those channelized versions just to try it . give it give one tr transcriber the channelized version of my speech nonspeech detection and look if that 's helpful for them , or just let them try if that 's better or if they can   ","no , with the transcriber tool , it 's no problem . that 's the training data . thought we sh perhaps we should try to start with those channelized versions give it give one tr transcriber the channelized version of my speech nonspeech detection and look if that 's helpful for them , ",
Bmr016.B,"what about putting a hyphen between the numbers in the group ? hey liz , what do the groupings represent ? you said there 's like ten different groupings ?  are the patterns like are they based on anything or     like adam ? parallel . it 's the p make of digit reading . i couldn't understand a single thing you guys were saying . performance art . it 's gonna require some coordination . it 's great for the germans . if if there was a segment of speech this long and and someone said "" "" the whole thing was passed to the recognizer ? that 's why there 's many insertion errors ? early on ,   the idea is that you would take this big hunk where somebody 's only speaking a small amount in it , and then try to figure out where they 're speaking based on the other peopl we were just gonna move the boundaries in . right . why do you want to do echo cancellation ?  it would be  do what he 's already what he 's trying to do . i s i see .  i see .  this also ties into one of the things that jane is gonna talk about too . the sri front end won't take a an a large audio file name and then a list of segments to chop out from that large audio file ? they actually have to be chopped out already ?  i don't think that 's really right . you can give waves a start and an end time . and middle . no , i 'm not suggesting you load a long wave file , i 'm just saying you give it a start and an end time . and it 'll just go and pull out that section . i 'm to interrupt you could back up a little bit and you 're doing these the whole process is that the transcribers get the conversation and they do their pass over it . and then when they 're finished with it , it comes to you , and you begin these sanit these quality checks .   i don't remember .  that was part of the spell check , or was that was after the spell check ?  then it just an ending curly brace there , or is there something else in there .  on the m on the middle t in the first case that gloss applies to the word to the left . but in the middle two th it 's not applying to anything , right ?   right , meant the middle two ones ,  except for now ! we 're gonna never recognize this meeting . that 's "" versus "" ? they were the canadians , right ? morgan can make a song out of it . where 's that ? minute , w s was that somewhere where they were gonna say "" new speaker "" ",you said there 's like ten different groupings ? if there was a segment of speech this long the sri front end won't take a an a large audio file name and then a list of segments to chop out from that large audio file ? ,
Bmr016.B,"there 's no tilde in front of it ,  it 's just comment about what they said . they didn't mean "" tickle "" as in elmo , they meant "" tickle "" as in add what , liz ? what are you saying ? how w there 'd be a problem for doing the language modeling then with our transcripts the way they are .   there will be a "" nums "" tag on those lines ?  right . right . that would argue for changing the other ones to be "" digits ""  i suppose what you could do is just make that you get rid of everything that has "" curly brace nums curly brace "" . that would be the right . and it makes it the thing about  right . liz , what does the recognizer do ,  what does the sri recognizer output for things like that ? "" seven point five "" . does it output the word right , the word "" seven "" ? the number "" seven "" ? the word "" seven "" ,     two or more . two or more different functions . right . that has implications for your script . right now the what you 're doing is you 're taking the the o original version and you 're channelizing yourself , right ?  right . right . th probably the way it 'll go is that , when we make this first general version and then start working on the script , that script @ @ that will be ma primarily come from what you 've done , we 'll need to work on a channelized version of those originals . and it should be identical to what you have t except for the one that they 've already tightened the boundaries on .   and then probably what will happen is as the transcribers finish tightening more and more , that original version will get updated and then we 'll rerun the script and produce better versions . but the the ef the effect for you guys , because you 're pulling out the little wave forms into separate ones , that would mean these boundaries are constantly changing you 'd have to constantly re rerun that ,           i can't think of any of the other ones . ","th probably the way it 'll go is that , when we make this first general version and then start working on the script , that script @ @ that will be ma primarily come from what you 've done , we 'll need to work on a channelized version of those originals . and then probably what will happen is as the transcribers finish tightening more and more , that original version will get updated and then we 'll rerun the script and produce better versions . but the the ef the effect for you guys , because you 're pulling out the little wave forms into separate ones , that would mean these boundaries are constantly changing you 'd have to constantly re rerun that , ",
Bmr016.C,"dueling digits . round . nein ! you scream it . it only sounds w good when you scream it , though .    where you were sitting probably affected it .   alright . you 've compiled the list of , speaker names ? not names , but i ds .     that was my fault .  then disregard it then .  i had some general questions just about the compression algorithms of shortening waveforms and i don't know exactly who to ask . that you would be the person to talk to . is it a lossless compression when you compress ,  it just uses entropy coding ?  my question would be is got this new eighteen gig drive installed .  which is i 'm not exactly how they partitioned it . but i don't 's typical here , but it 's local though ,  but  alright . how do you do that ? eighteen . see .  alright , i did know that .  right .  right . right . all of this can be regenerated , it 's just a question   right .  th the other question was then , should we shorten them , downsample them , or keep them in their original form ?  right .  do you think that 'd be to downsample them ?  the only argument against downsampling is to preserve just the original files in case we want to experiment with different filtering techniques . right . r  those are gonna be kept . right . alright . i could just u do a du on it right ? and just see which how much is on each      i replace the "" cuz "" with "" because "" if it 's glossed . and right . it 's like the z zapruder film . jane , can i ask you a question ? what 's that very last one correspond to ? i don't even know how to pronounce that . is that like someone 's like burning or some such thing ? like their hair 's on fire ? it looks like that . right . but that 's not really like no one really says "" argh , "" it 's not  there 's another word error . cha ching .   that 's true .  all the "" 's i 've seen have been like that . they 've been like "" like that have bee has been transcribed to "" . and sometimes it 's stronger , like "" eeh "" which is like closer to "" . but . i know . we should go off line .     we don't have that many acronyms comparatively in this meeting . it 's not bad .  that 's not bad . there 's a lot of "" 's "" .   is this after like did you do some replacements for all the different form of "" to this ?  although , what 's there 's one with a slash after it . that 's disturbing . anyway .  that 's alright . ",those are gonna be kept . ,
Bmr016.C,"i 'm just pointing that out . there 's  sh shouldn't it be "" qual tickle "" like it 's not    see .   it 's not something you wanna replace with but it 's just disturbing . that 's great .   you need a lot of you need a lot of qualification adam . subtext . that was in the first meeting . right . there 's a "" numbers "" tag i 'm 'm i didn't follow that last thing . right .    have those e the vis the ten hours that have been transcribed already , have those been channelized ? and i 've seen @ @ i 've seen they 've been channelized , but have they have they been has the time have the time markings been adjusted , p on a per channel  i don't know if we should talk about this now , or not , but i i know . no , but my question is like should i until all of those are processed , and channelized , like the time markings are adjusted before i do all the processing , and we start like branching off into the our layer of transcripts . right .  no i know that adjusting those things are gonna is gonna make it better . 'm about that , but do you have like a time frame when you can expect like all of it to be done , or when you expect them to finish it , or   i don't doubt it .  i 'm doing it myself . if the time markings aren't different across channels , like the channelized version really doesn't have any more information . i was just originally i had done before like the channelized versions were coming out .  and it 's a question of like what   right .  i know . right . no .  as long as it can all be done automatically , then that 's not a concern . if have to run three scripts to extract it all and let it run on my computer for an hour and a half , or however long it takes to parse and create all the reference file , that 's not a problem .   as long as we 're at that point . and i know exactly like what the steps will work what 's going on , in the editing process ,   ","have those e the vis the ten hours that have been transcribed already , have those been channelized ? no i know that adjusting those things are gonna is gonna make it better . but do you have like a time frame when you can expect like all of it to be done , ",
Bmr016.D,"and we already got the crash out of the way . it did crash , feel much better , earlier .  i did collect an agenda . 'm gonna go first . mwa ha ! it shouldn't take too long . we 're out of digits . we 've gone once through the set . the only thing i have to do that 's right . just have to go through them and pick out the ones that have problems , and either correct them or have them re read . we probably have like four or five more forms to be read , to be once through the set . i 've also extracted out about an hour 's worth . we have about two hours worth . i extracted out about an hour 's worth which are the f digits with for which whose speaker have speaker forms , have filled out speaker forms . not everyone 's filled out a speaker form . extracted one for speakers who have speaker forms and for meetings in which the "" key "" file and the transcript files are parsable . some of the early key files , it looks like , were done by hand , and they 're not automatically parsable and i have to go back and fix those . what that means is we have about an hour of transcribed digits that we can play with .  liz   yes , it 's just a question of a little hand editing of some files and then waiting for more people to turn in their speaker forms . i have this web based speaker form , and i sent mail to everyone who hadn't filled out a speaker form , and they 're slowly s trickling in . it 's for labeling the extracted audio files . by speaker id and microphone type . no , i spoke with jane about that and we decided that it 's probably not an issue that we edit out any of the errors anyway . right ? the there are no errors in the digits , you 'll always read the string correctly . can't imagine why anyone would care . the other topic with digits is liz would like to elicit different prosodics , and we tried last week with them written out in english . and it just didn't work because no one grouped them together . it just sounded like many more lines instead of anything else . in conversations with liz and jane we decided that if you wrote them out as numbers instead of words it would elicit more phone number , social security number like readings . the problem with that is it becomes numbers instead of digits . when i look at this , that first line is "" sixty one , sixty two , eighteen , eighty six , ten . "" and the question is does anyone care ? ","we 're out of digits . just have to go through them and pick out the ones that have problems , and either correct them or have them re read . we have about two hours worth . what that means is we have about an hour of transcribed digits that we can play with . it 's just a question of a little hand editing of some files and then waiting for more people to turn in their speaker forms . and i sent mail to everyone who hadn't filled out a speaker form , and they 're slowly s trickling in . it 's for labeling the extracted audio files . by speaker id and microphone type . the other topic with digits is liz would like to elicit different prosodics , and we tried last week with them written out in english . and it just didn't work because no one grouped them together . ","Approximately two hours of digits have been recorded, half of which have been extracted. The Berkeley Meeting Recorder group discussed digits data, recent ASR results, the status of transcriptions, and disk space and storage format issues. "
Bmr016.D,"i 've already spoken with liz and she feels that , correct me if i 'm wrong , that for her , connected numbers is fine , as opposed to connected digits . two hours is probably fine for a test set , but it may be a little short if we actually wanna do training and adaptation and all that other the six dash one , right .  we could just , put in the instructions "" read them as digits "" . how about "" o "" versus "" zero "" ? just let them read it how they read it . can just add to the instructions to read it as digits not as connected numbers . right .  cognitively it 's much easier . and is the spacing alright or do you think there should be more space between digits and groups ? or is that alright ?  and there are about ten different gouping patterns isn't that right , liz ? that we did .  right . right . right . right . that trying to duplicate , spending too much effort trying to duplicate the existing ti digits probably isn't too worthwhile because the recording situation is different . it 's gonna be very hard to be comparable . mean read versus not . and not just that , the the corpus itself . we 're collecting it in a read digit in a particular list , and i 'm that they 're doing more specific if i remember correctly it was like postman reading zipcodes and things like that .  was it read ? i may be . i haven't ever listened to ti digits . don't really know how it compares . but regardless it 's gonna it 's hard to compare cross corpus .  and which group appears is picked randomly , and what the numbers are picked randomly . unlike the previous one , which i d simply replicated ti digits , this is generated randomly .   all we have for some people is digits . you 're not . see . that 's true , that would be interesting to see whether that helps . do you think that would help adapting on  i have a real problem with that . right . same acoustics , same microphone , same channel .  good . we talked about that a couple times . the problem i see with trying to do overlapping digits is the cognitive load . no it 's not stupid , it 's just try to do it . here , let 's try it . you read the last line , i 'll read the first line . you read the last line , i 'll read the first line . guess if you plug you 're ears you could do it , but then you don't get the same effects .  see . we could try . we could try doing some . let 's try it . ","just let them read it how they read it . can just add to the instructions to read it as digits and which group appears is picked randomly , and what the numbers are picked randomly . unlike the previous one , which i d simply replicated ti digits , this is generated randomly . ",
Bmr016.D,"you do the last line , i 'll do the first line . o . that 's not bad . the poor transcribers they 're gonna hate us . a round .   if we wanted to do that we would do it as a separate session , something like that rather than doing it during a real meeting and do two people at a time then three people at a time and things like that .  see what dan thinks . right . this was gonna be fast .  not after i "" eight "" though .  nein ! you have to be german ,   for something like that we 'd be better off doing like timit .  are we done with digits ?  we have asr results from liz , transcript status from jane , and disk space and storage formats from don . does do we have any prefer preference on which way we wanna go ?  why don't you , if you have a hard copy , why don't you email it to the list . it 's in the paper .  then , it 's already been mailed . horrible ? and someone said "" in the front in the middle . i noticed that chuck was wearing the lapel a lot . probably how you wear it wore it i would guess .  right . and he said , "" lots lots . "" that 's with the hand but how would you do that automatically ? that 's the thing that you would do .   i also wanted to say i have done all this chopping up of digits , have some naming conventions that we should try to agree on . let 's do that off line , we don't need to do it during the meeting . and i have scripts that will extract it out from "" key "" files and do all the naming automatically , you don't have to do it by hand .   names in the names to i ds , you and it does all sorts of matches because the way people filled out names is different on every single file it does a very fuzzy match .   th i now have a script that you can just say look up morgan , and it will give you his id .   alright . do we don , you had disk space and storage formats . is that something we need to talk about at the meeting , or should you just talk with chuck at some other time ?  entropy coding .  and i assume half of it is scratch and half of it is ? probably , that doesn't matter . you can access it from anywhere in icsi . n n slash n slash machine name , slash x a in all likelihood . the only question is how much of it the distinction between scratch and non scratch is whether it 's backed up or not . ","if we wanted to do that we would do it as a separate session , we have asr results from liz , transcript status from jane , and disk space and storage formats from don . and someone said "" in the front in the middle . don , you had disk space and storage formats . ","The Berkeley Meeting Recorder group discussed digits data, recent ASR results, the status of transcriptions, and disk space and storage format issues. "
Bmr016.D,"what you wanna do is use the scratch for that you can regenerate .  the that isn't backed up is not a big deal because disks don't crash very frequently , as long as you can regenerate it . then put it all on scratch because we 're icsi is bottlenecked by backup . we wanna put it just depends on your tools . because it 's not backed up and it 's just on scratch , if your sc tools can't take shortened format , i would leave them expanded , you don't have to unshorten them every single time you wanna do anything . as i said , since that 's it 's regeneratable , what i would do is take downsample it , and compress it however you 're e the sri recognizer wants to take it in . right .  and that 's the whole point about the naming conventions is that you could run all the english speaking , all the native speakers , and all the non native speakers , and all the men , and all the women .  "" that 's just not right , man . "" the point what if you wanted to run all the native speakers . right , if you did it that way you would have to generate a program that looks in the database somewhere , extracts out the language , finds the time marks for that particular one , do it that way . the way they 're doing it , you have that already extracted and it 's embedded in the file name . and you just say y you just say asterisk e asterisk dot wave "" , and you get what you want . rather than doing seeks through the file . this is all just temporary access , don't it 's all just it 's fine .  fine to do it however is convenient . and they don't . two gig ? yes you can . i th w the transcribers didn't have any problem with that did they jane ? they loaded the long files into x waves . are you talking about transcriber or x waves ? because i we used x waves to do the digits . and they were loading the full mixed files then , and it didn't seem to be any problem .  seemed really fast . regardless , it 's and , it 's no problem , right ? because it 's not backed up . we just if we don't have a spare disk sitting around we go out and we buy ourselves an eighty gigabyte drive and make it all scratch space . it 's not a big deal . remind me afterward and i 'll and we 'll look at your disk and see where to put  each partition . and you wanna use , either xa or scratch . question mark , anything starting with x is scratch . two digits , right , xa , xb , xc .  ",and that 's the whole point about the naming conventions ,
Bmr016.D,"jane ? on the fifth page , seven down and then you gloss them ?  and your list here , are these ones that actually occurred in the meetings ? whew ! we are acronym loaded . except right there .  but they have the gloss . you have the gloss form you always replace it . if that 's how what you wanna do .  can ca are we done with acronyms ? cuz i had a question on what this meant . 'm a comment , they 're impulsive . the "" qual "" can be the "" qual "" is applying to the left .  "" while laughing "" . good . it 's a small list . that 's known as "" found data "" . it 's much easier .    yes , that 's right . we 're gonna have a big problem when we talk about that . in monty python you say "" argh "" a lot .  or if you 're a c programmer . you say arg c and arg v all the time . it does .  he died while dictating .  just the single letter "" a "" as in the particle ? article .  i 'm just these poor transcribers , they 're gonna hate this meeting . them canadians .  see . i didn't get that ,  it 's good ,  and just listen to them ?  performance art , just extract them all . see . o how about question mark ?  they it 's "" plp ? "" p make is that 's a good one . that 's correct . i know ! i was saying that lot of them are the networks meeting . i see a few . although i see plenty of that 's pretty close . count .  i wonder what it is . 'm we 've said xml more than five times . yes , it 's very bad . yes . that 's right .  and that 's an underestimate cuz they 're  we 'll have to look at it 'll just i was just looking at the bottom of page three there , is that "" to be "" or "" not to be "" . anyways , "" try to stay on topic , adam . "" on some of these quals , are they really quals , or are they glosses ? like there 's a "" qual tcl "" .  see , i see . it 's not gloss . i see . it wasn't said "" tcl "" .   we 'll probably add it to the language model .  what did i say ? both . we can go on lan add it to both dictionary and language model . tickle "" was pronounced "" tickle "" . right ? it 's pronounced the same as the verb . think it 's the language model that makes it different . see . right . right . right . ",,
Bmr016.D,"and you 'll ha you 'll have to do it sychronously . right , whoever 's creating the new models , will have to also go through the transcripts and change them synchronously . you can correct it .  these are funny to read . you add it to the dictionary . right .    it 's this , "" rrre rrre "" . it was me . a lot of these are me the "" beep is said with a high pit high pitch and lengthening . "" that was the i was imitating beeping out what i meant was "" beep "" .  anyway . they 're vocalization , glosses .  on on the glosses for numbers , it seems like there are lots of different ways it 's being done . there 's a "" ooo . "" "" nums "" ,   what 's to the left of these ?  that 's what i was asking . right . point five , good . now , the other example is , in the glosses right there , "" gloss one dash one three zero "" . what 's to the left of that ?  good . label it . right master copies of superset . good .  the numbers ? we might wanna just a separate tag that says it 's read .   are we done ? we 're not done .  we did that for one meeting , right , you have that data don't you ? all ten hours ? great . it 's just we 're missing tea .  oop ! man ! ","on the glosses for numbers , it seems like there are lots of different ways it 's being done . "" nums "" , you have that data don't you ? ",
Bmr016.E,"interesting .      i agree .    and i actually it 's no more artificial than what we 've been doing with words . i 'm people can adapt to this , read it single . the spaces already bias it toward being separated . and i 'm gonna find this easier than words . that i it 's fine . i it to me it looks like you 've got the func the idea of grouping and you have the grou the idea of separation and , it 's just a matter of u i the instructions , that 's all . i did  go ahead .  i also would like to argue for that cuz it seems to me that , there 's a real strength in having the same test replicated in a whole bunch of times and adding to that basic test bank .  cuz then you have , more and more , u chances to get away from random errors . and the other thing too is that right now we have stratified sample with reference to dialect groups , and it might be there might be an argument to be made for having for replicating all of the digits that we 've done , which were done by non native speakers that we have a core that replicates the original data set , which is american speakers , and then we have these stratified additional language groups overlapping certain aspects of the database . except that if you have the stimuli comparable , then it says something about the contribution of setting and  what 's an example of a of m some of the other differences ? any other a difference ?   fine .  great . it was numbers , but i 'm not you have to have a similar pace . c can i have an another question w about this ? there are these digits , which are detached digits , but there are other words that contain the same general phon phoneme sequences . like "" wonderful "" has "" one "" in it and victor borge had a piece on this where he inflated the digits . i wonder if there 's , an if there would be a value in having digits that are in essence embedded in real words to compare in terms of like the articulation of "" one "" in "" wonderful "" versus "" one "" as a digit being read . there you go . nein . wanted to offer that as a possible task because , if we were to each read his embedded numbers words in sent in sentences cuz it 's like an entire sketch he does and i wouldn't take the inflated version . he talks about the woman being "" two derful "" , and and a but , if it were to be deflated , just the normal word , it would be like a little story that we could read . ",the spaces already bias it toward being separated . ,
Bmr016.E,"i don't know if it would be useful for comparison , but it 's embedded numbers . i see .     very good point .  what 's th u w in what respect ? in the in   it was also true of the digits task which was x waves .  very quickly . i agree . you 're right about the backup being a bottleneck . it 's good to think towards scratch .  with two digits . got a little print out here . three on this side , three on this side . and i stapled them .  alright first of all , there was a an interest in the transcribe transcription , checking procedures and tell you first , to go through the steps although you 've probably seen them . as you might imagine , when you 're dealing with , r really c a fair number of words , and @ @ natural speech which means s self repairs and all these other factors , that there 're lots of things to be , s standardized and streamlined and checked on . and , i did a bunch of checks , and the first thing i did was spell check . and at that point i discovered certain things like , "" accommodate "" with one "" m "" , that thing . and then , in addition to that , i did an exhaustive listing of the forms in the data file , which included n detecting things like f faulty punctuation and things     yes . that 's right . exactly . i do these checks .  exactly .   and i do a an exhaustive listing of the forms actually , i will go through this in order , if we could and stick keep that for a second cuz we 're not ready for that . exactly ! exactly ! alright a spelling check first then an exhaustive listing of the , all the forms in the data with the punctuation attached and at that point i pick up things like , word followed by two commas . and th and then another check involves , being that every utterance has an identifiable speaker . and if not , then that gets checked . then there 's this issue of glossing s w called "" spoken forms "" . there mo for the most part , we 're keeping it standard wo word level transcription . but there 's w and that 's done with the assumption that pronunciation variants can be handled . for things like "" and "" , the fact that someone doesn't say the "" d "" , that 's not important enough to capture in the transcription because a good pronunciation , model would be able to handle that . however , things like "" cuz "" where you 're lacking an entire very prominent first syllable , and furthermore , it 's a form that 's specific to spoken language , ","alright first of all , there was a an interest in the transcribe transcription , checking procedures and the first thing i did was spell check . and then , in addition to that , i did an exhaustive listing of the forms in the data file , which included n detecting things like f faulty punctuation and things and th and then another check involves , being that every utterance has an identifiable speaker . then there 's this issue of glossing s w called "" spoken forms "" . mo for the most part , we 're keeping it standard wo word level transcription . however , things like "" cuz "" where you 're lacking an entire very prominent first syllable , ","Transcription checking procedures were reviewed, and efforts to coordinate the channelization and presegmention of data with the tightening of time bins were discussed. "
Bmr016.E,"those are r reasons f for those reasons i kept that separate , and used the convention of using "" cuz "" for that form , however , glossing it that it 's possible with the script to plug in the full orthographic form for that one , and a couple of others , not many . wanna "" is another one , "" going "" "" gonna "" is another one , with just the assumption , again , that this th these are things which it 's not really fair to a c consider expect that a pronunciation model , to handle . and chuck , you in you indicated that "" cuz "" is one of those that 's handled in a different way also , didn't you ? did i  it might not have been you , but someone told me that cuz "" is treated differently in , i u in this context because of that r reason that , it 's a little bit farther than a pronunciation variant . after that , let 's see ,  when i get the exhau the spell check picks up those words because they 're not in the dictionary . it gets "" cuz "" and "" wanna "" and that  run it through i have a sed do sed script saying whenever you see "" gonna "" "" convert it to gonna "" , "" gloss equals quote going to quote "" ,  and with all these things being in curly brackets they 're always distinctive . i also wrote a script which will , retrieve anything in curly brackets , or anything which i 've classified as an acronym , and a pronounced acronym . and the way i tag ac pronounced acronyms is that i have underscores between the components . if it 's "" acl "" then it 's "" a "" underscore "" c "" underscore "" l "" . and the th yes . now . and a  yes , but not the reverse . sometimes people will say "" because "" in the meeting , and if they actually said "" because "" , then it 's written as "" because "" with no w "" cuz "" doesn't even figure into the equation .  that 's a good point . that 's fine . don has a script . exactly .  and don knows this , and he 's bee he has a glo he has a script that yes . and that 's why there 're different tags on the glosses , on the different types of comments , which we 'll see in just a second . the pronounceable acronyms get underscores , the things in curly brackets are viewed as comments . there 're comments of four types . this is a good time to introduce that . the four types . w and we 'll expand that but the comments are , of four types mainly right now . ","those are r reasons f for those reasons i kept that separate , and used the convention of using "" cuz "" for that form , however , glossing it that it 's possible with the script to plug in the full orthographic form for that one , and the way i tag ac pronounced acronyms is that i have underscores between the components . the things in curly brackets are viewed as comments . there 're comments of four types . ",
Bmr016.E,"one of them is , the gloss type we just mentioned . another type is , i 'm still doing the overview . i haven't actually gotten here yet . gloss is things like replacing the full form u with the , more abbreviated one to the left . then you have if it 's there 're a couple different types of elements that can happen that aren't really properly words , and wo some of them are laughs and breathes , we have that 's prepended with a v a tag of "" voc "" . and the non vocal ones are like door slams and tappings , and that 's prepended with a no non vocalization . this would let 's just take one example . and then the no non vocalization would be something like a door slam . they always end . it 's like they 're paired curly brackets . and then the third type right now , is m things that fall in the category of comments about what 's happening . it could be something like , "" referring to and , "" talking about such and such "" , "" looking at and .  and this gets substituted here .  no , they 're events . they 're actually they have the status of events . and actually , it is true that , with respect to "" laugh "" , there 's another one which is "" while laughing "" , and that is , i an argument could be made for this tur turning that into a qualitative statement because it 's talking about the thing that preceded it , but at present we haven't been , coding the exact scope of laughing , and to have "" while laughing "" , that it happened somewhere in there which could mean that it occurred separately and following , or , including some of the utterances to the left . haven't been awfully precise about that , but i have here , now we 're about to get to the to this now , i have frequencies . you 'll see how often these different things occur . but , the very front page deals with this , final c pa aspect of the standardization which has to do with the spoken forms like "" and "" ha "" and "" and all these different types . and , someone pointed out to me , this might have been chuck , about , about how a recognizer , if it 's looking for "" with three m 's , and it 's transcribed with two m 's , that it might that it might increase the error rate which is which would really be a shame because i p i personally w would not be able to make a claim that those are dr dramatically different items . right now i 've standardized across all the existing data with these spoken forms . i should say ","one of them is , the gloss type we just mentioned . then you have if it 's there 're a couple different types of elements that can happen that aren't really properly words , and then the third type right now , is m things that fall in the category of comments about what 's happening . i have frequencies . you 'll see how often these different things occur . but , the very front page deals with this , final c pa aspect of the standardization which has to do with the spoken forms like "" and "" ha "" and "" and all these different types . right now i 've standardized across all the existing data with these spoken forms . ",
Bmr016.E,"all existing data except thirty minutes which got found today . i 'm gonna i 'm gonna check  acsu actually i got it was stored in a place i didn't expect , and w we , sh yea reconstructed how that happened . and this is this 'll be great . 'll be able to get through that tonight , and then everyth i actually later today probably . and then we 'll have everything following these conventions . but you notice it 's really rather a small set of these kinds of things . and i made it that these are , with a couple exceptions but , things that you wouldn't find in the spell checker that they 'll show up really easily . and ,  now that s only occurs once , and i 'm thinking of changing that . i haven't listened to it don't know . i haven't heard it actually . i n i need to listen to that one . did she hear the th did she actually hear it ? cuz i haven't heard it .  'm curious to se hear what it is , but i didn't know wanna change it to something else until i knew . sss , hhh .  that 's right .  that 's right . that 's right .    that 's partly a nonnative native thing , but i have found "" in native speakers too . but it 's mostly non native   that 's right . exactly .  that 's right .   we 're not doing length . that 's right . this makes sense . think you 've  that makes sense . and th i have there are some , americans who are using this "" too , and i haven't listened to it systematically , with some of them , they 'd end up being "" 's "" but , i my spot checking has made me think that we do have "" in also , american e data represented here . but any case , that 's the this is reduced down from really quite a long a much longer list , and this is functionally pretty , also it was fascinating , i was listening to some of these , two nights ago , and it 's just hilarious to liste to do a search for the "" 's "" . and you get "" and diff everybody 's doing it . just i wanted to say i w think it would be fun to make a montage of it because there 's a ""   it 's really fun to listen to . all these different vocal tracts , but it 's the same item . it 's very interesting .  then the acronyms y and the ones in parentheses are ones which the transcriber wasn't of , and i haven't been able to listen to clarify , but you can see that the parenthesis convention makes it very easy to find them ",,
Bmr016.E,"cuz it 's the only place where they 're used . question mark is punctuation . it they said that @ @ "" dc ? "" exactly . exactly . the only and i do have a stress marker here . sometimes the contrastive stress is showing up , and , the parenthesized is something that the transcriber thought was ann , but wasn't entirely 'd need to go back or someone needs to go back , and say , yes or no , and then get rid of the parentheses . but the parentheses are used only in that context in the transcripts , of noti noticing that there 's something uncertain . that 's true .  nsa , a lot of these are coming from them . i listened to some of that .  i agree . and robustness has a fair amount , but the nsa group is just very many .  that 's interesting . right and sometimes , you see a couple of these that are actually "" 's "" it 's may be that they got to the point where it was low enough understandable understandability that they weren't entirely the person said "" "" it isn't really necessarily a an undecipherable acronym , but just n needs to be double checked . now we get to the comments . this number of times out of the entire database , w except for that last thirty minutes i haven't checked yet . i 'd have to listen . i agree . i w i 'd like to standardize these down farther but , to me that sounds equivalent . but , i 'm a little hesitant to collapse across categories unless i actually listen to them . then , at least now .  six .  but did you notice that there were seven hundred and eighty five instances of "" ? and that 's just without the without punc punctuation . extra forty one if it 's questioned . on the page two of acronyms .  of "" , yes .  that 's the single existing convention for "" . that 's  that 's i looked for that one . i actually explicitly looked for that one , and that , i 'm not exactly about that . no , i looked for that , but that doesn't actually exist . and it may be , i don't i can't explain that . i it 's the only it 's the only pattern that has a slash after it , and it 's an epiphenomenon .  that 's cute . that 's funny .   there is th one y no , that 's r that 's legitimate . now , comments , you can see they 're listed again , same deal , with exhaustive listing of everything found in everything except for these final th thirty minutes .  "" tcl "" . where do you see that ?  the reason is because w it was said "" tickle "" .  ",,
Bmr016.E,"on the in the actual script in the actual transcript , i s i this happens in the very first one . i actually wrote it as "" tickle "" . because we they didn't say "" tcl "" , they said "" tickle "" . and then , following that is "" qual tcl "" . qual qualifier . comment . comment or contextual comment .  now the tannen corre the spelling c change . that 's what gets i picked those up in the frequency check .  "" icsi "" is one of those that sometimes people pronounce and sometimes they say "" icsi . "" those that are l are listed in the acronyms , i actually know they were said as letters . the others , e those really do need to be listened to cuz i haven't been able to go to all the ic icsi things , and until they 've been listened to they stay as "" icsi "" . it was ! it was !  he s he said get that 's it . perfect . that 's it . that 's it . that 's been changed . that 's been changed . exactly , that 's where the lengthening comment c came in . s chan brought it down . and those get picked up in the frequency check because you see "" beep "" and mean it gets kicked out in the spelling , and it also gets kicked out in the , freq frequency listing . i have the there 're various things like "" breathe "" versus "" breath "" versus "" inhale "" and , hhh , i don't know . they don't have any implications for anything else it 's like i 'm tempted to leave them for now an and it 's easy enough to find them when they 're in curly brackets . we can always get an exhaustive listing of these things and find them and change them . but i don't actually remember what it was . but that was eric did that .  something like that . that 'd qualify .   interesting question . yes . now first of all ooo ! very important . chuck led to a refinement here which is to add "" nums "" if these are parts of the read numbers . now you already that i had , in places where they hadn't transcribed numbers , i put "" numbers "" in place of any numbers , but there are places where they , it th this convention came later an and at the very first digits task in some transcripts they actually transcribed numbers . and , d chuck pointed out that this is read speech , and it 's to have the option of ignoring it for certain other prob things . and that 's why there 's this other tag here which occurs a hundred and five or three hundred and five times right now which is just "" nums "" by itself ",qual qualifier . comment or contextual comment . ,
Bmr016.E,"which means this is part of the numbers task . i may change it to "" digits "" . i with the sed command you can really just change it however you want because it 's systematically encoded , have to think about what 's the best for the overall purposes , but in any case , "" numbers "" and "" nums "" are a part of this digits task thing . now th then i have these numbers that have quotation marks around them . i didn't want to put them in as gloss comments because then you get the substitution . and actually , th the reason i b did it this way was because i initially started out with the other version , you have the numbers and you have the full form and the parentheses , however sometimes people stumble over these numbers they 're saying . you say , "" seve seventy eight point two "" , or whatever . and there 's no way of capturing that if you 're putting the numbers off to the side . you can't have the seven and the left is i example the very first one , it would be , spelled out in words , "" point five "" . only it 's spelled out in words . this is also spelled out in words . "" point five . "" and then , in here , "" nums "" , it 's not going to be mistaken as a gloss . it comes out as "" nums quote dot five "" .  now in that case it 's people saying things like "" one dash and or they 're saying two zero "" whatever . and in that case , it 's part of the numbers task , and it 's not gonna be included in the read digits anyway , m in the there is .  i 've added that all now too . gloss in the same line that would have "" gloss quote one dash one thirty "" , you 'd have a gloss at the end of the line saying , "" curly bracket nums curly bracket "" . if you did a , a "" grep minus v nums "" and you get rid of anything that was read . yes .  good .  this is more because  these are all these , the "" nums point "" , this all where they 're saying "" point "" something or other . and the other thing too is for readability of the transcript . if you 're trying to follow this while you 're reading it 's really hard to read , "" in the data column five has "" , "" one point five compared to seventy nine point six "" , it 's like when you see the words it 's really hard to follow the argument . ","which means this is part of the numbers task . these are all these , the "" nums point "" , this all where they 're saying "" point "" something or other . and the other thing too is for readability of the transcript . ",
Bmr016.E,"and this is just really a way of someone who would handle th the data in a more discourse y way to be able to follow what 's being said . this is where chuck 's , overall h architecture comes in , where we 're gonna have a master file of the channelized data . there will be scripts that are written to convert it into these t these main two uses and th some scripts will take it down th e into a f a for ta take it to a format that 's usable for the recognizer an other scripts will take it to a form that 's usable for the for linguistics an and discourse analysis . and , the implication that i have is that th the master copy will stay unchanged . these will just be things that are generated , and e by using scripts . when things change then the script will cham change but the but there won't be stored copies of in different versions of things . except   ex exactly . exactly . that was my motivation . and i these can be changed , like i said . as i said i was considering changing it to "" digits "" . and , it just i it 's just a matter of deciding on whatever it is , and being the scripts know . the other thing is you can get really minute with these things and increase the size of the files and the re and decrease the readability to such an extent by simply something like "" percent "" . now i could have adopted a similar convention for "" percent "" , but somehow percent is not hard , i it 's just when you have these points and you 're trying to figure out where the decimal places are and we could always add it later . percent 's easy to detect . point however is word that has a couple different meanings . and you 'll find both of those in one of these meetings , where he 's saying "" the first point i wanna make is and and he goes through four points , and also has all these decimals .  wanted to say also regarding the channelized data , that , thilo requested , that we ge get some segments done by hand to e s reduce the size of the time bins wh like was chuc chuck was mentioning earlier that , if you said , "" and it was in part of a really long , s complex , overlapping segment , that the same start and end times would be held for that one as for the longer utterances , and and he requested that there be , similar , samples done for five minute stretches c involving a variety of speakers and overlapping secti sections . he gave me he did the very he did some shopping through the data and found segments that would be useful . ","and this is just really a way of someone who would handle th the data in a more discourse y way to be able to follow what 's being said . where we 're gonna have a master file of the channelized data . there will be scripts that are written to convert it into these t these main two uses and th some scripts will take it down th e into a f a for ta take it to a format that 's usable for the recognizer an other scripts will take it to a form that 's usable for the for linguistics an and discourse analysis . and , the implication that i have is that th the master copy will stay unchanged . that , thilo requested , that we ge get some segments done by hand to e s reduce the size of the time bins and he requested that there be , similar , samples done for five minute stretches c involving a variety of speakers and overlapping secti sections . ",
Bmr016.E,"and at this point , all four of the ones that he specified have been done . in addition the i 've i have the transcribers expanding the amount that they 're doing actually . right now , i know that as of today we got an extra fifteen minutes of that type , and i 'm having them expand the realm on either side of these places where they 've already started . but if and i and he 's gonna give me some more sections that he thinks would be useful for this purpose . because it 's true , if we could do the more fine grained tuning of this , using an algorithm , that would be much more efficient . and , this is gonna be useful to expand this . to start from scratch f in a brand new transcript ? that 'd be excellent . that 'd be really great . as it stands we 're still in the phase of cleaning up the existing data getting things , in i m more tight tightly time aligned . i also wanna tell i also wanted to r raise the issue that there 's this idea we 're gonna have this master copy of the transcript , it 's gonna be modified by scripts t into these two different functions . and actually the master two or more . and that the master is gonna be the channelized version . right now we 've taken this i initial one , it was a single channel the way it was input . and now , to the advances made in the interface , we can from now on use the channelized part , and , any changes that are made get made in the channelized version thing . but i wanted to get all the finished all the checks yes , they have . except for the missing thirty minutes . for a total of like twenty m f for a total of let 's see , four times total of about an thirty minutes . that 's been the case . and plus the training , whatever you have . the problem is that some of the adjustments that they 're making are to bring are to combine bins that were time bins which were previously separate . and the reason they do that is sometimes there 's a word that 's cut off . and i it 's true that it 's likely to be adjusted in the way that the words are more complete . and , it 's gonna be a more reliable thing and i 'm not  partly it depends on how how e effective it will be to apply an algorithm because i this takes time , it takes a couple hours t to do , ten minutes .      but that  that 's could there were other checks that i did , ","if we could do the more fine grained tuning of this , using an algorithm , that would be much more efficient . yes , they have . the problem is that some of the adjustments that they 're making are to bring are to combine bins that were time bins which were previously separate . and the reason they do that is sometimes there 's a word that 's cut off . and i it 's true that it 's likely to be adjusted in the way that the words are more complete . it takes a couple hours t to do , ten minutes . ",
Bmr016.E,"but it 's that we 've unless you think there 's anything else , that i 've covered it .  great . ",,
Bmr016.F," will you get the door , and ?  you collected an agenda , no there 's only ten .  you think two hours is the total that we have ? and you think we th i didn't quite catch all these different things that are not quite right , but you think we 'll be able to retrieve the other hour , reasonably ?  the relevance of the speaker form here , s  wasn't like whether they were giving us permission to use their digits   do you want different prosodics , if you always had the same groupings you wouldn't like that ? is that correct ? no but , i was asking if that was something you really cared about because if it wasn't , it seems to me if you made it really specifically telephone groupings that people wouldn't , go and do numbers much . if it 's some , but i probably not much . right ? if you have if you go six dash two nine three one . that 's what i was asking ,  right . the other thing is we could just bag it because it 's it 's i 'm not worrying about it because we do have digits training data that we have from from ogi . i 'm digits numbers training that we have from ogi , we 've done lots and lots of studies with that . and  no , what i 'm saying is that to some extent we could just read them have them read how they read it and it just means that we have to expand our vocabulary out to that we already have .  we can go back to the other thing later . we s we 've we can do this for awhile and then go back to digits for awhile , or do yo do you want this do you need training data or adaptation data out of this ? how much of this do you need ? with the  if you pre    let 's try it . we have  i was just gonna say , we have in the vicinity of forty hours of recordings now . and you 're saying two hours , is digits , that 's roughly the ratio then , something like twenty to one . which makes sense . if we did another forty hours of recordings then we could get another couple hours of this . like you say , couple hours for a for a test set 's it 'd be to get , more later because we 'll we might use this up , in some sense , but  no it 's not the same . a little bit , but the other differences are major . they 're such major sources of variance that it 's it 's individual human glottis is going to be different for each one , it 's just there 's many things . it 's it and enunciation . ti digits was ? it was read . ","but you think we 'll be able to retrieve the other hour , reasonably ? the relevance of the speaker form here , s i was just gonna say , we have in the vicinity of forty hours of recordings now . and you 're saying two hours , is digits , something like twenty to one . like you say , couple hours for a for a test set 's ","Approximately two hours of digits have been recorded, half of which have been extracted. "
Bmr016.F,"the reading zipcode you 're thinking of would be ogi . no ti digits was read in th in read in the studio i believe .   but it but it 's different people is the core thing . and they 're different circumstances with different recording environment and forth , it 's it 's really pretty different . but the idea of using a set thing was just to give you some framework , that even though you couldn't do exact comparisons , it wouldn't be s valid scientifically at least it 'd give you some frame of reference . it 's not    mean , for the acoustic research , for the signal processing , farfield i see it as the place that we start . but , th it 'd be to have twenty hours of digits data , but the truth is i 'm hoping that we through the that you guys have been doing as you continue that , we get , the best we can do on the spontaneous nearfield , and then we do a lot of the testing of the algorithms on the digits for the farfield , and at some point when we feel it 's mature and we understand what 's going on with it then we have to move on to the spontaneous data with the farfield .  let 's try it . sixty one . no , i 'll p see , y  no , do it . alright , let 's try three at once you pick one in the middle . go . like a round , like in a  row , row your boat .    i don't think we 're gonna collect vast amounts of data that way , but having a little bit might at least be fun for somebody like dan to play around with ,   spend the whole time reading digits with different qu quantities . that 's "" two "" bad .  they don't all work as do they ?  what does nine work in ?  in german ,  that 's right ! everybody 's a little punchy here today . yes .  don't know . think the question is what the research is , mean , i presume that the reason that you wanted to have these digits this way is because you wanted to actually do some research looking at the prosodic form here .  if somebody wanted to do that , if they wanted to look at the difference of the phones in the digits in the context of a word versus the digits a non digit word versus in digit word , that would be a good thing to do , but someone would have to express interest in that . to if you were interested in it then we could do it , it 's the same thing ? it 's the same thing i mailed to every everybody that w where it was ,  that 's why i only used the part from use ","but the truth is i 'm hoping that we through the that you guys have been doing as you continue that , we get , the best we can do on the spontaneous nearfield , and then we do a lot of the testing of the algorithms on the digits for the farfield , and at some point when we feel it 's mature and we understand what 's going on with it then we have to move on to the spontaneous data with the farfield . but having a little bit might at least be fun for somebody like dan to play around with , ",
Bmr016.F,"which we had about the alt over all the channels or mixed channel rather mixed signal .  it just to r to remove cross talk .  dave is , also gonna be doin usin playing around with echo cancellation for the nearfield farfield we 'll be  no , i didn't notice that actually .  that 's typical , this is an eighteen gig drive , or is it a thirty six gig drive with eighteen  i i 'm l over all our data , we want to not downsample .      ye  i 'm as as long as there is a form that we can come from again , that is not downsampled , then , uuu  then it 's fine . but for fu future research we 'll be doing it with different microphone positions and on we would like to  it just depends how big the file is . if the file sits in memory you can do extremely fast seeks but .     but in our meetings people don't say "" hey cuz how you doing ? ""  i wanna work with lost data . you just did .   arg . arg max , arg min ,  canadians , . quick thilo , do a filled pause for us .  i 'm i got lost here . what w what 's the difference between the parenthesized acronym and the non parenthesized ?   i don't recognize a lot of these . i   the number to the left is the number of incidences ?  cts is really big here ,   ip , i ip is .  s six now , wh the self referential aspect of these p no , i didn't .  th  seven hundred eighty . now we 're up to seven hundred and eighty eight . what 's a qual ? i f i forget , what 's qual ?  right .  right . don and i were just noticing , love this one over on page three , "" vocal gesture mimicking sound of screwing something into head to hold mike in place . "" beep .  "" sings finale type song "" that 's good .  tah dah ! i don't know . something like that    'd i 'd like to talk about point five "" .  right .   ","it just to r to remove cross talk . l over all our data , we want to not downsample . as as long as there is a form that we can come from again , that is not downsampled , then , what 's qual ? ",
Bmr016.G,"we actually figured out a way to the groupings are randomly generated . they may still do it ,  and i it might help , i would like to g get away from having only one specific grouping . if that 's your question , but it seems to me that , at least for us , we can learn to read them as digits if that 's what people want . i 'm don't think that 'd be that hard to read them as single digits .  and it seems like that might be better for you guys since then you 'll have just more digit data , and that 's always a good thing . it 's a little bit better for me too because the digits are easier to recognize . they 're better trained than the numbers . right . right , read them as single digits , sixty one w is read as six one , and if people make a mistake we but it 's to get it in this room with the acous for it 's right . that 's fine with me as long as it 's just that i didn't want to the people who would have been collecting digits the other way to not have the digits .    it 's actually unclear right now . thought we 're if we 're collec collecting digits , and adam had said we were running out of the ti forms , it 'd be to have them in groups , and probably , all else being equal , it 'd be better for me to just have single digits since it 's , a recognizer 's gonna do better on those anyway , and it 's more predictable . we can know from the transcript what the person said and the transcriber , in general . but if they make mistakes , it 's no big deal if the people say a hundred instead of "" one oo "" . and also w we can just let them choose "" zero "" versus "" o "" as they like because even the same person c sometimes says "" o "" and sometimes says "" zero "" in different context , and that 's interesting . don't have a specific need cuz if i did i 'd probably try to collect it , without bothering this group , but if we can try it right , and you can give an example like , "" six sixty one would be read as six one "" . and people will get it . right , right . it 's just easier to read . right .  i also had a hard time with the words , but then we went back and forth on that . let 's give that a try and what do other people think cuz you guys are reading them .  great . let 's give it a try . ","but it seems to me that , at least for us , we can learn to read them as digits don't think that 'd be that hard to read them as single digits . because the digits are easier to recognize . they 're better trained than the numbers . thought we 're if we 're collec collecting digits , and adam had said we were running out of the ti forms , it 'd be to have them in groups , and probably , all else being equal , it 'd be better for me to just have single digits and also w we can just let them choose "" zero "" versus "" o "" as they like ",
Bmr016.G,"righ right , and you just they 're randomly generated and randomly assigned to digits . right , just groupings in terms of number of groups in a line , and number of digits in a group , and the pattern of groupings . roughly looked at what kinds of digit strings are out there , and they 're usually grouped into either two , three , or four , four digits at a time . and they can have , actually , things are getting longer and longer . in the old days you probably only had three sequences , and telephone numbers were less , and forth . there 's between , if you look at it , there are between like three and five groups , and each one has between two and four groupings and i purposely didn't want them to look like they were in any pattern .  right . but it 'd be great i to be able to compare digits , whether it 's these digits or ti digits , to speakers , and compare that to their spontaneous speech , and then we do need fair amount of digit data because you might be wearing a different microphone and , it 's to have the digits replicated many times . especially for speakers that don't talk a lot .  for adaptation . no , i 'm serious , we have a problem with acoustic adaptation , and we 're not using the digit data now , but not for adaptation , nope . v w we 're not we were running adaptation only on the data that we ran recognition on and i 'd as soon as someone started to read transcript number , that 's read speech and we 're gonna do better on that , that 's not fair to use "" . but , it might be fair to use the data for adaptation ,  those speakers who are very quiet , shy r right it sh it 's the same micropho see we have that in the same meeting , and you don't get right , and still like the idea of having some digit data . the only thing that we don't have , i know this sounds weird , and it 's completely stupid , but we don't have any overlapping digits . an yea i know it 's weird , but alright everybody 's laughing .  i 'm just talkin for the that like dan ellis is gonna try , cross talk cancellation .  it these are all the same forms . but you plu you plug your ears . what is actually no not the overlaps that are governed linguistically , but the actual fact that there is speech coming from two people and the beam forming stuf all the acoustic that like dan ellis and company want to do . digits are and behaved ,  anyway , it 's just a thought . it would go faster . ","right , just groupings in terms of number of groups in a line , and number of digits in a group , and the pattern of groupings . roughly looked at what kinds of digit strings are out there , and they 're usually grouped into either two , three , or four , four digits at a time . i purposely didn't want them to look like they were in any pattern . and , it 's to have the digits replicated many times . especially for speakers that don't talk a lot . we have a problem with acoustic adaptation , but we don't have any overlapping digits . ",
Bmr016.G,"it would take one around amount of ti that 's right . i mea i 'm i was serious , but i really , i 'm i don't feel strongly enough that it 's a good idea ,  a and that prosody was great , it sounded like a duet ,  i 'm i 'm mean it 's doable , i 'm just we could have a round like where you do two at a time , and then the next person picks up when the first guy 's done , like a , what do you call it ? li a r like like that . then it would go like h twice as fast , or a third as fast . anyway , it 's just a thought . i 'm actually serious if it would help people do that kind o but the people who wanna work on it we should talk to them .    can try it out . if we have nothing if we have no agenda we could do it some week .  i 'm all "" four "" it .  right , was actually gonna skip the asr results part , in favor of getting the transcription talked about since that 's more important to moving forward , but morgan has this paper copy and if people have questions , it 's pretty preliminary in terms of asr results because we didn't do anything fancy , but just having the results there , and pointing out some main conclusions like it 's not the speaking style that differs , it 's the fact that there 's overlap that causes recognition errors . and then , the fact that it 's almost all insertion errors , which you would expect but you might also think that in the overlapped regions you would get substitutions and forth , leads us to believe that doing a better segmentation , like your channel based segmentation , or some echo cancellation to get back down to the individual speaker utterances would be probably all that we would need to be able to do good recognition on the close talking mikes . that 's about the summary but this is morgan has this paper . he it 's that paper .  we did a lot of work on that and it 's let 's see , th the other neat thing is it shows for that the lapel , within speaker is bad . and it 's bad because it picks up the overlapping speech . yes , cuz that 's all that w had been transcribed at the time ,  but as we wanted to here more about the transcription . if we can get the channel asynchronous or the the closer t that would be very interesting for us because we right . that 's cuz that 's right . pulled out a couple classic examples in case you wanna u use them in your talk of chuck on the lapel , ","but the people who wanna work on it we should talk to them . it 's pretty preliminary in terms of asr results like it 's not the speaking style that differs , it 's the fact that there 's overlap that causes recognition errors . and then , the fact that it 's almost all insertion errors , but you might also think that in the overlapped regions you would get substitutions and forth , leads us to believe that doing a better segmentation , like your channel based segmentation , or some echo cancellation to get back down to the individual speaker utterances would be probably all that we would need to be able to do good recognition on the close talking mikes . the other neat thing is it shows for that the lapel , within speaker is bad . and it 's bad because it picks up the overlapping speech . ",Researchers doing ASR are looking into methods for generating a better channel-based segmentation to improve recognition results for close-talking microphone data. 
Bmr016.G,"chuck wore the lapel three out of four times .  and i wore the lapel once , and for me the lapel was still and i don't know why . i 'm but for you it was or who was next to me like that . right , but when chuck wore the lapel and morgan was talking there 're a couple really long utterances where chuck is saying a few things inside , and it 's picking up all of morgan 's words pretty and the rec there 're error rates because of insertion insertions aren't bounded , with a one word utterance and ten insertions you got huge error rate . and that 's where the problems come in . this is what we expected , but it 's to be able to show it . and also wanted to mention briefly that , andreas and i called up dan ellis who 's still stuck in switzerland , and we were gonna ask him if there 're what 's out there in terms of echo cancellation and things like that . not that we were gonna do it , but we wanted to would need to be done . and he we 've given him the data we have far , these sychronous cases where there are overlap . and he 's gonna look into trying to run some things that are out there and see how it can do because right now we 're not able to actually report on recognition in a real paper , like a eurospeech paper , because it would look premature . right . or who 's at any point in time who 's the foreground speaker , who 's the background speaker .  there 's like ther there 's  exactly , it 's a it would be techniques used from adaptive echo cancellation which i don't know enough about to talk about .  but , right , and that would be similar to what you 're also trying to do , but using more than energy i don't exactly would go into it . the idea is to run this on the whole meeting . and get the locations , which gives you also the time boundaries of the individual speak right . except that there are many techniques for the kinds of cues , that you can use to do that .  and espen ? this is is he here too ? may also be working it would just be ver that 's really the next step because we can't do too much , on term in terms of recognition results knowing that this is a big problem until we can do that processing . and once we have some of yours , and @ @ we 'll move on .  right .  right . definitely and don should  great . that 's it for the speakers and  great . right . at this point we can finalize the naming , and forth , ","and the rec there 're error rates because of insertion insertions aren't bounded , with a one word utterance and ten insertions you got huge error rate . this is what we expected , and also wanted to mention briefly that , andreas and i called up dan ellis who 's still stuck in switzerland , and we were gonna ask him if there 're what 's out there in terms of echo cancellation and things like that . because right now we 're not able to actually report on recognition in a real paper , because it would look premature . the idea is to run this on the whole meeting . and get the locations , which gives you also the time boundaries of the individual speak right . except that there are many techniques for the kinds of cues , that you can use to do that . that 's really the next step because we can't do too much , on term in terms of recognition results knowing that this is a big problem until we can do that processing . at this point we can finalize the naming , and forth , ",
Bmr016.G,"and we 're gonna re rewrite out these waveforms that we did because as you notice in the paper your "" m o in one meeting and "" m o two "" in another meeting and it 's we just need to standardize the  no it 's that 's why those comments are s are in there .  right .  great , great . terrific . eigh eighteen . it was a spare that dave had around it 's the  'd leave all the transcript shouldn't should be backed up , but all the waveform sound files should not be backed up , the ones that you write out . we can downsample them ,   we get the same performance . the r the front end on the sri recognizer just downsamples them on the fly ,  that 's if fe you 'd you wanna not .  we 're what we 're doing is we 're writing out this is just a question . we 're writing out these individual segments , that wherever there 's a time boundary from thilo , or jane 's transcribers , we chop it there . and the reason is that we can feed it to the recognizer , and throw out ones that we 're not using and forth . and those are the ones that we 're storing .    we can't shorten them , but we can downsample them .  th  that 's why we need more disk space cuz we 're duplicating the originals ,  no . we always have the original long ones . it 's better if they 're chopped out , and it will be y we could probably write something to do that , but it 's actually convenient to have them chopped out cuz you can run them , in different orders . you c you can actually move them around . you can get rid of it 's a lot faster . right . you can grab everything with the word "" the "" in it , and it 's that 's a lot quicker than actually trying to access the wavefile each time , find the time boundaries and in principle , you could do that , but it 's but it 's these are long these are long  this is an hour of speech . we that 's that 's part of it is right . and the other part is just that once they 're written out it is a lot faster to process them .  otherwise , you 're just accessing right . right . the other thing is that , believe it or not we have some we 're also looking at these in waves like for the alignments and forth . you can't load an hour of speech into x waves . you need to s have these small files , and even for the transcriber program if you try to load s really long waveform into x waves , you 'll be waiting there for  loading the long ","and we 're gonna re rewrite out these waveforms that we did the r the front end on the sri recognizer just downsamples them on the fly , we can't shorten them , but we can downsample them . that 's why we need more disk space it 's better if they 're chopped out , cuz you can run them , in different orders . you can't load an hour of speech into x waves . you need to s have these small files , ",
Bmr016.G,"it takes a very long ti right . it takes a l very long time .  actually , you 're talking about transcriber , right ?  we have a problem with that , time wise on a it 's a lot slower to load in a long file , and also to check the file , if you have a transcript , it 's overall you could get everything to work by accessing the same waveform and trying to find two the begin and end times .  but it 's more efficient , if we have the storage space , to have the small ones . it 's  it 's just right . these wouldn't be backed up , the right . and can i ask a question about the glossing , before we go on ? for a word like "" because "" is it that it 's always predictably "" because "" ? is "" cuz "" always meaning "" because "" ? beca because right . right . from the point of view of the only problem is that with for the recognition we map it to "" because "" , and if we know that "" cuz "" but , we don't s right . but , if it 's  but then there are other glosses that we don't replace , right ? because then it 's fine .   right . actually we gave this to our pronunciation person , she 's like , "" i don't that is either "" .  no , we just gave her a list of words that , weren't in our dictionary and it picked up like this , and she just didn't listen she didn't know . we just we 're waiting on that just to do the alignments . it 's "" argh "" ?  right , no one say  but it has a different prosody . jane , what 's the d i have one question about the "" versus like the "" and the "" .  s "" "" right , cuz there were some speakers that did definite "" 's "" but right now we it 's actually probably good for us to know the difference between the real "" and the one that 's just like "" or transcribed "" aaa "" cuz in like in switchboard , you would see e all of these forms , but they all were like "" . no , like the "" , or the "" , "" , "" were all the same . and then , we have this additional non native version of like "" eeh "" . right . but you 're a native german speaker it 's not a issue for it 's only onl  no , only if you don't have lax vowels , right . it 's like japanese and spanish and this is great . this is really helpful . right . right . mean cuz they have no idea , right . if you hear ctpd , they do pretty ","it 's actually probably good for us to know the difference between the real "" and the one that 's just like "" or transcribed "" aaa "" ",
Bmr016.G,"but it 's how are they gonna know ?  right . the recognizer , it is funny . kept getting pta for pda . this is close , right , and the pta was in these , topics about children , anyway . is the p pta working ? i 'm wai this is exactly how people will prove that these meetings do differ because we 're recording , right ? y no normally you don't go around saying , "" now you 've said it six times . now you 've said ""  there 's not @ @ . right .  but at some point we probably shoul but we should add it to the dictionar no , to the pronunciation model . language , lan we it 's in the language model , w but it it 's the pronunciation model that has to have a pronunciation of "" tickle "" . i 'm  what i meant is that there should be a pronunciation "" tickle "" for tcl as a word . and that word in the in , it stays in the language model wherever it was . you never would put "" tickle "" in the language model in that form ,  right . there 's actually a bunch of cases like this with people 's names and yes .  th there 's a few cases like that where the the word needs to be spelled out in a consistent way as it would appear in the language , but there 's not very many of these . tcl 's one of them .  y right . right . we have this there is this thing i was gonna talk to you about at some point about , what do we do with the dictionary as we 're up updating the dictionary , these changes have to be consistent with what 's in the like spelling people 's names and forth . if we make a spelling correction to their name , like someone had deborah tannen 's name mispelled , and since we know who that is , we could correct it , but but we need to make we have the mispel if it doesn't get corrected we have to have a pronunciation as a mispelled word in the dictionary . things like that .  right . right . if there 's things that get corrected before we get them , it 's not an issue , but if there 's things that we change later , then we always have to keep our the dictionary up to date . and then , in the case of "" tickle "" we would just have a , word "" tcl "" which which normally would be an acronym , "" tcl "" but just has another pronunciation .  right , exactly . right . there is something spelled out "" beeeeeep "" in the old  because he was saying , "" how many e 's do i have to allow for ? "" right ,  ","we have this there is this thing i was gonna talk to you about at some point about , what do we do with the dictionary as we 're up updating the dictionary , but if there 's things that we change later , then we always have to keep our the dictionary up to date . ",
Bmr016.G,"right . right . right . right .    you could do "" grep minus v nums "" . that 's the  there wouldn't be something like i if somebody said something like , "" boy , i 'm really tired , "" and then started reading that would be on a separate line ? great . cuz i was doing the "" grep minus v "" quick and dirty and looked like that was working but great . now why do we what 's the reason for having like the point five have the "" nums "" on it ? is that just like when they 're talking about their data or these are all like inside the spontaneous  i see .  'd have one request here which is just , to make it more robust , th that the tag , whatever you would choose for this type of "" nums "" where it 's inside the spontaneous speech , is different than the tag that you use for the read speech . that way w if we make a mistake parsing , we don't see the "" point five "" , or it 's not there , then we a just an and actually for things like "" seven eighths "" , or people do fractions too you you want one overall tag for that would be similar to that , or as long as they 're sep as they 're different strings that we that 'll make our p processing more robust . cuz we really will get rid of everything that has the "" nums "" string in it .  it would probably be safer , if you 're willing , to have a separate tag just because then we know for and we can also do counts on them without having to do the processing . but you 're right , we could do it this way , it should work .  but it 's probably not hard for a person to tell the difference because one 's in the context of a a transcribed word string , and  "" seven point five "" . the word .  and actually , the language it 's the same point , actually , the p the word "" to "" and the word y th "" going to "" and "" to go to "" those are two different "" to 's "" and there 's no distinction there . it 's just the word "" point "" has every word has only one , one version even if it 's a actually even like the word "" read "" and "" read "" those are two different words . they 're spelled the same way , right ? and they 're still gonna be transcribed as read .  i like the idea of having this in there , was a little bit worried that , the tag for removing the read speech because i what if we have like "" read letters "" ","now why do we what 's the reason for having like the point five have the "" nums "" on it ? ",
Bmr016.G,"or , i don't know , like "" read something "" like "" read ""  but other than that i it sounds great . but that 's not hard . the harder part is making that the transc the transcription if you b merge two things , then that it 's the sum of the transcripts , but if you split inside something , you don't where the word which words moved . and that 's wh that 's where it becomes a little bit having to rerun the processing . the cutting of the waveforms is pretty trivial . right . ","if you b merge two things , then that it 's the sum of the transcripts , but if you split inside something , you don't where the word which words moved . the cutting of the waveforms is pretty trivial . ",
Bmr021.A,"we 're on . we pre crashed , think we 're it should be a really short meeting , i hope . agenda items , number one , i wanna talk since we were just discussing that is microphone issues . what the heck are we gonna do about microphones ? got passed on that the edu group doesn't like the crown mikes . i do . i l find them very comfortable . but it seems to depend on your head shape . that 's right .   right . they like it has one good effect , that people are trying to get there early because the people who get there early get to pick the mike . people who show up late have to use these . we should probably get different mikes . the question is , the easiest thing to do is certainly to just get two more , sony mikes . just two more of those , and that 's easy and that will certainly work . the other option is to try yet another mike . find one we like and potentially get six , all the same . these are better , if they 're worn correctly . definitely .   they 're not a lot better , but they are a little better . they 're more directional , a little better error noise cancellation , and also you can really get it right in front of your mouth , like this , whereas that one , to avoid breath noise , you really have to put it at to the side . you seem to get better signal with this one . i don't know , but in random polling  that 's the other option , is that we could switch the form it 's more obvious the distinction between channel and mike , and then get duplicates . there 's no problem with that . it 's just what should we get just more sony ones ? i hate the sony ones . b the one you 're wearing . because it pinches the temples too much . if you wear it around the back , it 's not too bad . but i right . right . we could try another mike . but then we have the wiring issue , and don't to do . what do what do people think ? the plug is proprietary . that 's why i was saying getting more sony ones is trivial , because we can just go out and buy them . any other ones we have to buy them in pigtail versions and get them wired . yes . the only possibilities from sony are that one and the lapel mike . this isn't sony . this is crown . the one we 're wearing . and we had these wired for us . and that 's probably the right first step is just get two more immediately , and have them available . ",,
Bmr021.A,"right . and just make that you write down "" crown "" or "" sony "" on the mike number , which i 'll change to mike type , like that .  it 'll be me it 'll be whoever 's setting up the meeting , who fills out the key file ,  it has the same potential for error as everything else . no , we definitely would not have the user fill it out . it would be me , chuck , or liz , depending on which meeting it is . we 'll de definitely go ahead and do that . couple hundred .  it depends on how good the mike is . the crown ones were like two fifty . those are like one ninety . but . right . no . good mikes are expensive .   eighty or ninety for the shures .  the sony ones are expensive because they 're proprietary , they can charge whatever they want . these are expensive because they 're quite high quality .  we should buzz that out if we send the data to sony . i 'm just joking . you do not have to bleep that out . i don't mind if sony knows my opinion .   also , we 're pro i wanna double check with morgan , he did say yes before i went to japan on buying another wireless system that we can go all wireless , instead of the mix of wired and wireless . and that 's the right thing to do . and i 'm   four more wireless .  and also i 'm gonna re probably replace the andrea mike with a shure , but i 'll test it , sometime today or tomorrow to make the shure one really works , cuz i have an extra shure in my office . it 's had some problems . it 's this one . in the meantime , right , because it 'll probably take a couple weeks to get it delivered from sony anyway .  really ?  cuz everyone 's been out of town . probably over the summer it 'll be the same cuz it tends to be less , fewer people .  file done with microphone issues , if you want . and this way we can get a door slam in the in the transcript file .  no not quite a slam . the door slam phone ? and then we could have the phone , for when the phone rings .  file reorganization . this is something we were talking about before i left and saying we should probably until after i 'm back , and now i 'm back , we should do that at some point . we should get ourselves a list of everything we wanna do to reorganize the file structure and anything else .   shorten . is that the same as shorten ? it 's built into the sri , because we have the same thing with shorten in the sound tools .  ",,
Bmr021.A,"it 's just a question of what decompression is built into your tools . really ? i didn't know that . that 's not a sound tool , right . right .  shortening everything on the fly . you had another process running that was shortening it .  did you have to re one of the processes to make that "" shorten "" ? watching the disk meter . the list ,  start end . the way feacalc calc does it . it would be easy . it wouldn't be hard someone just needs to d sit down and do it who has some time . and that way we wouldn't have multiple versions floating around . about the only difficulty with that is if it 's compressed . then you really do have to decompress it first . right ? because the pointers are y you don't know how much it 's comp it doesn't compress it by a fixed amount . and mean , that it it just depends on how much disk space is a problem . the what you could do is decompress it to a temporary place and then operate on it and then delete it . but . that 's true .  it seems like just shortening them is a good short term solution we don't have to do any coding .  no , it was i was still here . it was the day i left . no if i had done it on purpose i would have timed it right after i left .  there was something else going on , because dave johnson said that dd was getting accessed frequently . and it shouldn't be . right ? that data never gets touched , because we write it once and then we never touch it again . the wave files . he was saying gigabytes . and it has to be the wave files . asked dave about it and he hasn't looked into it yet , but we should definitely double check on it . every night . at any rate , for file reorganization we need to first decide what we 're gonna do and then when we 're gonna do it . 'm not who isn't involved with that . certainly me , chuck and jane . anyone else care ? right . we should do that not during this meeting but s another time , and just get a list of everything we 're gonna do .  just update all the naming conventions and put all the files where they really belong , on one disk , and then leave everything in place until the back up until the next full back up and then delete the old ones .  both need to be reorganized .  various paths , th this is why we have to do it in a synchronized way , because yes , exactly . that too . ",,
Bmr021.A,"that 's what i was saying . we need to get a list of all that that we wanna do . and i didn't really get any responses from the naming conventions that i sent out , assume that 's alright with everyone .  and then i should have made that as an agenda item . right . how you choose to do it the naming is up to you .   right . i actually i was gonna do a global search replace on all entries at icsi to change mr to mrm places at icsi . y you shouldn't say that on re record . there was a typo in some of the contracts that morgan got that someone , one of our sponsors , did a global sear search and replace for between "" sponsor "" and their name . and it was saying , anyway , i won't i 'm not whether that 's right . one can imagine the problems that would engender .  right .  thilo , you had you wanted to talk about the you should probably talk to a sys admin and get it put in some central place . that it 'll work on all the nt machines . right . assume tcl tk wasn't already on the machine , you had to install it .    w what features did you use ? not rasta , just plp .  who cares ? no , just would be a sign change . how many iterations ?    this is just combination at the utterance level . why do you think the icsi front end is much worse ? that seems really odd to me . right . right , right . ca can you run the sri just as an experiment , run the sri front end without vocal tract norma normalization , and see how much difference it makes ? if we could figure out how . but the they won't they don't correspond one to one though .   right .  right . it gets pretty big . and m my experience with that in broadcast news was usually combining at other levels works better .  for whatever that 's worth .     it was mostly msg , plp , rasta . the feature sets we had available . and it was almost always better to combine at the probability level . we 'd run the neural nets and combine the probabilities .  you 'd also have to do some normalization afterwards that they 're orthogonal . you 'd wanna do a linear transform also .  vocal tract thing ,  i was thinking about tandem system let 's not talk about it here , but i had some thoughts about the tandem system . should we do digits ? do we have any other topics ? let 's do them one at a time instead of simultaneous since we actually have time . why don't we let don go first before his battery dies ? you can really tell from the prosody where it goes . ",,
Bmr021.A,"after digits , i don't know . go ahead .  probably . we could probably build that in to the front end . i don't know , fff . what would you like it to do when that happens ? if an unblacked out channel is zero , is actually spitting out zeros , you can be pretty it 's off . because it doesn't spit out zeros , it spits out epsilons . right ? cuz there 's little background noise . the question is , when the software detects it , what do you want it to do ? it it we already have visual feedback , right ? you can see whether your mike is working or not .   turn off the screen saver during the meeting . i d i don't to do other than there 's no sound out right now . that would be good . we can think about what to do about it , but it 's pretty clear we can detect it ,  are we done ? ",,
Bmr021.B,"who does ? i see . they don't work for me very i much prefer these .  l liz said something that leaves me believing that nobody likes them . they are ver right . pretty  come on .  get a special phone for that .  no , we could add one .  can mention something ? the file regards reorganization . also , another issue there is disk space probably , right ?  i know that the files that you 've been cutting up for us f for the recognition experiments , one way one really brain brain dead way of not causing any trouble , but saving disk space is to , use the s the sphere , the nist , w encode program . to encode , to compress them . but it does it s it happens that the program that reads the waveforms does the unshortening transparently . y but it  it 's actually built into the sphere library that nist delivers ,  right . and actually , s the sound tools don't understand that . for the at least feacalc doesn't .  but since these files are made to be used with the sri recognizer , and the sri front end uses the sphere library which in turn does this transparently that will be a quick and easy way to just , get be able to use more but that 's gonna be only temporary . you should do that too , probably , but as you do that you can also just run the actually , the th what you do is you run now i have another use for the the way i recently used it , and there might be better ways the program 's called w encode . and the type , y you say think dash t and then there are different encoding methods , but if you wanna use the shorten one , you say d "" minus t shorten "" , and then the old wavefile and the new wavefile , and then  and then i check , if this works , you can use the shell "" and "" operator then move the new wavefile to the , to the old wavefile , and then you have replaced the old one with one that behaves identically as long as your programs that use it know how to decode it on the fly . and that just saved my butt because i actually was running on a different experiment , i had segmented i was processing the whole switchboard two corpus , which is two hundred eighty hours of speech , and i was noticing , as i was almost finishing the processing , that i was running out of disk space . and i had this flash of inspiration of just the same disk had the segmented waveforms on them , while this other thing was still going on , i was run i was running this thing . ",,
Bmr021.B,"and low and behold i gained three g three gig of space and no , no . actually it was fast enough . this is very fast . this really runs quickly . and that 's that was very suspenseful . that was the most excitement i had all weekend . boy , it came out just fine .  right , the only reason we do this is because the sri front end doesn't have a way to go into a l a longer file with indices . suppose someone could try to put a hack like that into the  but there 's also some  that 's true . exactly . right right . i don't think no , no . if you th the the if you can operate on the full if you don't have to segment it , then there would be less of a reason to do the compression , because you don't have that wasted that extra copy .  right . right . the segmentation also saves you space in the sense that you cut out all the nonspeech regions . and if you have , twenty channels and only five speakers , then it 's    no . i don't know about the naming , th these names that we 've been using far are with  i wouldn't just wanna change them without some advance notice . th that 's all these segment names that we 've been using . i would rather not mess with them until we have some closure on some of the things we are currently dealing with ,  right . right .  great . actually someone got an email this week from someone as to anant ? i 'm  who did you talk to ? anant ? anant venkataraman ?  great .  great . .    actually wasn't whether this is the right meeting for it , because it has very little to do with meeting recordings , but @ @ i did run some recognition experiments with icsi front end .  and this is the j joint work with chuck , and first , we had we figured out sometime last week how to and chuck wrote this really little script perl script that takes a waveform , runs the feature calculation and then dumps it out into the into f c called cepstra file , which is what the sri system uses to read features . it 's essentially nist headered waveform . it looks like a waveform except instead of samples you have feature vectors following the header . and that 's all done by the script , and it works great . and first trained up two systems , because it 's gender dep the sri system is gender dependent to be comparable , i trained on a sh on a called short training set male system and a female system , and ",,
Bmr021.B,"also for debugging purposes , and for the heck of it , i trained trained on the same training set standard system with the sri front end from scratch , and compared the two we used , twelve plp just plp and actually that one of the questions i had was what the rasta would possibly buy us . but we 'll talk about that later . the the baseline system w the sri system was used also used t twelve mel cepstra based on a twenty four filter bank analysis .  i do not the f the bandwidth of the sri front end is from hundreds hertz to th thirty se thirty seven fifty like that . and i do not the icsi front end would do . what the bandwidth is .  but the results are such that let 's see  the sri system also does vocal tract length normalization and we couldn't figure out how to do that yet with the icsi features . that 's one difference . and the other difference is that in the , in the sri system , the th the first the c zero , the energy feature is normalized slightly differently from the rest . and what they do is they d they subtract the maximum for each waveform segment they subtract the maximum of th over that waveform segment from the values of for that waveform . which is a automatic gain control , that is localized they subtract right , right . and then , after but after they done this waveform based normalization , they then do a conversation length normalization just like all the other features . it 's their two stage normalization . now , i understand that the common practice here has been to just do c standard mean subtraction , on the waveform .  right . but in what we 've done far , because we didn't have any special provision for c zero , we just treat it as any of the other features , we 've done standard mean subtraction over the whole conversation side . since both sri and icsi use this local normalization for c zero that 's presumably , someone has done some experiments to and found out that works better . that 's another difference , and that might account for some of the discrepancies in the results . but the results are  where should i start ? the there 's a two i tried it with and without .  without and with adaptation . for the adaptation ? y we always do three iterations to and it 's this it 's this quick and dirty the phone loop adaptation which doesn't actually require prior recognition paths and this is not the best you can do with adaptation , but it gives you first idea of what you could gain with it . and then , we have the sri front end and the icsi front end and other than that the system configuration was identical . ",,
Bmr021.B,"it was the same they came up with same number of gaussians per state cluster same the clustering used the same information loss threshold , which actually led to roughly the same number of gaussians overall . that the system configuration is comparable . and the without adaptation , you had forty nine p this is error rate in percent . and with adaptation it 's forty seven point one and this was fifty two point six . and fifty one point three and then , when i combined them actually combine them with something like rover . it 's actually more sophisticated than rover but it 's here i got forty eight point five and here i got forty six point five .  at the utterance level , right . good question . that 's fine . one percent i would attribute to the lack of vtl , about one percent .  and then another up i don't know how much the c zero normalization business really matters i can't it see , can't see it the i could . i could certainly do that .  we could also do the vocal tract length normalization with the icsi features . that 's something we wanted to do  we could i was actually thinking we could use the warping factors that we compute for the mfcc 's and just try them with the icsi front end . because we already have the capability to apply the warping to the to the plp c dan added the  no , but they should be close , since this the anyway . but certainly try the sri front end without vtl . that sh that 's certainly quick to do . and and then there 's all these  the number of this front end u had a fair amount of experimentation going into it . how many filter banks do you use , what bandwidth do you use , and like that . and we could play the same games with the icsi front end . actually , the analysis bandwidth played a very crucial role . we used to use a narrow bandwidth and that hurt us . this is , and this is we 've now used roughly what everybody else is using .  there 's some room for improvements , i figure , in this in the icsi front end .  but the good news is that even with this with the icsi system being that much worse , you still get a win out of combining the two . that gives some hope for the future .  unfortunately however this seems to be reduced with adaptation ,  also interestingly the the difference actually widens . i would actually expect it or hope that the adaptation reduces the difference because it might remove some of the  som if you have some difference in the front end processing that is suboptimal , but can be possibly remedied by moving the moving the models around . but that doesn't really ",,
Bmr021.B,"actually the difference becomes larger ,  anyway . right now what i 'm doing is there 's several things going on . one is that chuck is working on getting the tandem features into a form that we can train the tandem the system on the tandem features . that would actually be the more interesting experiment . the other thing is i 'm training retraining the models on the large training set that we usually use to build our evaluation models and then we can and i actually want to do the system combination with our eval system on some subset of the data at least , probably only for the males , because i don't have time to train both males and females , but and it does get pretty big . you tried that on broadcast news ? concatenating different feature sets ?  did you try i see . i see .  alright .  and it does become unwieldy to have these very large feature vectors . and that would blow up the  right . right . the and then we could start experimenting a little bit to try to get the icsi front end to perform better . and as a preliminary just diagnostic experiment we can certainly run a sri system without vtl just to get wh  and that 's quick to do .   but things are moving ahead ,  digits . poetic reading of digits . s meeting . i actually have one more thing that i don't know if it 's i if it 's allowed to bring up after the dis anyway . but it might be important . for liz remarked that she had recorded a meeting where it was later found that several of the s microphones were turned off ,  and this must become a problem especially with non speech meetings .  is there a way that the software could warn you if it gets zeros from some of the channels , or ? because it it 's really annoying if you go through all that trouble and then the meetings aren't useable because even i don't they do . the batteries went dead , or th they just didn't they played with the thing and it didn't leave it in the "" on "" position or whatever . no , if you you always there 's never gonna be a signal from all the channels , right ? because or rarely . but right . exactly . that 's a good question . i don't know . but is there some we can collectively think of some mechanism that might reduce the risk of just right . right . it 's just to admonish people to actually look at the screen at the beginning of the meeting to make they get a signal . something . that 's a good one .   alright . ",,
Bmr021.C,"it 's probably the p z  do i . have you listened to them ?   those .  but the problem is again the plug , or ? wh       student discount .   that 's causing problems ,  the wired one .    just silences ,   i had one short point . i have just installed a transcriber version on one of our nt machines it 's available under windows now . re responded to sh i have already responded to him . i don't he what the problem was . it was really straightforward , really easy . there was some guy from sri who wanted to install   and he sent an email that he couldn't install it and described him , what i did and it was really straightforward ,  it 's the channeltrans , the things that dave gelbart  i 've i could do that . i had i to install it , that 's error rate or recognition rate ?    just no . why ? i no i gotta write , think .  ",,
Bmr021.D,"if you 're popular . right . me too . th those are intimidating . are they more directional , the microphones , as far as  which ones are those ? the one i 'm wearing ?    for one of these ? god .     the other thing i could do to relieve some of the pressure is just move everything to my eighteen gig disk , which is local . i don't know it is temporary solution . to shorten everything .    to be and segment on the fly .   but we 've had there was a big disk crash when you were gone and was that the day you left ? that 's suspicious .  leave to japan the day the disk crashes . but , chuck helped me out in , r regenerating all the cha the different channel files for like a few meetings for like six meetings . think they 're split up even further . it 's even more disorganized now since we moved some of the meetings to different directories . they 're on a different disk even , right ? you didn't you expand them to xe on abbott ? no , you the ones that you put them on when you put them on xe . you put them on xe .     no .  i 'm right .  it should probably be eventually should probably be consistent with what you 're doing but , i agree with andreas , like i 'm a little bit i looked at the naming conventions and they look fine to me , but at the same time it was just like to rename everything would be no but just to be consistent we should also , have the same conventions , just in case you want it 's only gonna affect my work .  it 's not gonna i assume you 're not gonna go into , my directories and change my file names .    that 'd be great . really enjoy that . right .  it can beep if one of the channels dies while recording .  never mind .  that 's not a bad idea . ",,
Bmr021.E,"one two three four five six i 'm on seven . you guys need to start going to the edu meetings . i prefer these , but i don't mind using those . those are better than the sonys ? that 's why i was saying if we could just unplug them and plug them in . it s it seems like right now if u what they 're complaining are those , if we just got two more of these  and then they can just unplug those from the transmitter .   how much is it just to buy the mike ? really . that 's way more than i   is there any educational discount ? and when i was at computer motion we used shure , the sm ten a 's , and they were only like eighty bucks  but they were they seemed pretty good .  right , right . then all those red channels there would become wireless ones ?  the andrea mike ? which one is the andrea mike ? a wired one ? if you 're gonna go to all wireless , in the meantime . i see .  i haven't in the meetings that i recorded s it 's always been at most six people , 've never had to recently i haven't had to used any of the wired ones  there 's some knocks .  you have a special phone ? we could add one , like at least feacalc doesn't .   what would be a u i don't know if this would mess other things up , but it seems like pain to have all these split up files around . what would be easier would be like pointers . lists like "" original wavefile , start , end "" . this is is there is there a nist routine which can seek in a compressed file but with uncompressed indices ? right . right we the original switchboard files are not compressed , right ? we could leave those as they are . assuming you 'd assuming that you then off load the original switchboard files .  he did it on purpose . are they ? i don't remember where i put them now .  physical disk . after each meeting we copy the data to there was something weird about that . like the same meeting shortened , files that we pull off of popcorn when we 're done doing the recording , looked , to the backup software , as if they had been written , every single night , i for f a week in a row , which is really weird .    next week if we could . i 'm trying to finish up some that sounds like a good idea .  we should also at the same time try to , convert over to your new naming conventions . that 'd be good .  i actually haven't looked at it yet . i haven't had a chance ,  these if we ",,
Bmr021.E,"if we change things , it won't really affect what you 're doing , will it ? you but you can switch that any time you want , right ? if we everybody will use it . fine slash u slash star . andreas , would it be appropriate to ask how the experiments are going ?  just plp . thirty seven fifty . there 's one other slight difference , right ? or two differences . do they subtract the max from each i one or do they subtract each one from the max ? doesn't matter ? except you get a lot of negatives the other way .  for the c zero . dan added that in , but what about ta concatenating the two feature vectors into a single one ?   what are people doing , they 're switching their mikes off test tell them to test their mikes , or ",,
Bmr021.F," pre crashed .  i do . i do too . interesting . i have a question about this . are the auditory quality is it , much different between this kind and the fancy ones ? they are .  the other thing is , is it just a few people who don't like them in the edu group ? cuz gosh , cuz i much prefer them , they 're a whole lot , multiple levels , better . it seems a shame t to discard them if they 're better auditory quality and there 're only a few people who dis who object . and i hate it because it 's hard to adjust the microphone . i spend all this time fumbling around with it and still not reasonable ,  n now may don't know this but , are the only two possibilities from sony the two that we 've tried ? or is there another i see .  i see . isn't that something .  i see . i remember that now .  it might be good to double check at the end of the meeting too , cuz that would be an easy place for , an error in the data . for it to be forgotten . it 's just i 'm just thinking that if it 'd be but i know but to have the user fill it out wouldn't be as reliable as have the good , perfect . perfect , is that more or less than you thought ?  we should keep a list of things we 're gonna bleep out and the conditions under which it was over here sometimes . should we close the door ? i 'm thinking i don't know about the acoustics . that 's all i was wondering about . that 's right , we gotta get the obligatory door slam .  right , the door slam phone . that 's an idea .   that must have been suspenseful . xf . different ones ? what we found out was that the disk that crashed was it w with a meta disk allocation , you had both c t transcripts and the shortened files and the expanded files were all on xe were on the same  different partitions of the same physical disk . and it 's conceivable i don't was told that it 's possible that might have , caused additional wear on it . caused it to go bad sooner .  why not ? it does . except that the wavefiles , or anything because the transcripts are there as gigabytes . i see . that 's right .  is that right . that 's very strange . i didn't realize that .  and i and i 'd like , in terms of the conventions , to also , s send a bit to dan ellis to see if it 's if there 's any get his input on it . i don't think that 'll be    i 'd like to ",,
Bmr021.F,"now and you 're just you 're not talking about the s the x disks the x partitions , just the backed up space , or ?   i haven't either .  i will by next week , though . you 're talking about different files . this with no advance warning .  no , no .  one can imagine that might be problematic . but this name change affects a subset , doesn't need to reflect everything ,  isn't that great ? and this is not  and this is not just the transcriber , this is the channeltrans , right ? excellent . excellent . as it stands , see what it 'll be on the unix side but accessible through the h drive .   wi without what ? without vtl .  do you wanna say that one again ? that last one ? or did you correct the whole one ? he did ? never mind . good . alright .  they sh it should give the electric shock to the person recording the meeting .  ",,
Bmr022.A,"here we go .  definitely have to go to tea .  that too , but  only a couple of agenda items , since no one sent me email for agenda items . the first is the ibm transcripts . i 'd like to mention i s i spoke with several of you about this , but just to brainstorm a little bit about what we can do with it . we got back the ibm transcript , and the accuracy looks there are there are areas which are clearly wrong and there are a lot of areas where they put question marks , where the acoustics weren't very good . and that 's fine . putting it in question marks is better than doing it wrong . the big problem was , they had the wrong number of beeps in it . it didn't align . and that 's exactly what i was afraid of . and i went in , and more or less by hand , corrected it , by loading it i wrote a script that will convert it to the multi the channeltrans format , looked at it in channeltrans and found the places where it got a unsynchronized , and then either and in this case only had to remove beeps , because that was th always the error , is that they put in it extraneous beeps . but it 's not easy to do , because the whole thing gets offset , and it 's assigning the wrong speaker to the text , and it all gets unaligned . it 's very difficult to do . it took me several hours just to do that .  it took me a couple hours to write the scripts , and then it probably took me forty five minutes , just going through it . now it will be a lot faster from now on , because now i understand how it works . but , if we had some way some tool that made it easier to insert and delete beeps it would make it a lot easier . cuz one of the problems is that it takes a very long time when you make a change to load it back up in the channel transcriber . and there may be i didn't just say that , no . th this is the o the other approach which is , what do we do in the future , to try to make this less common ? but it 's still gonna happen .  we don't their process is . had two ideas . the first was to provide them a text template that had both the beeps in it and the speaker i ds . just "" male female "" , "" english nonenglish "" , "" one two three four "" .  and they just filled it in . it was like a hundred twenty , and they had a hundred twenty three like that . is that right ? don't remember .   ",,
Bmr022.A,"how would that help ? just break the one hour into a few chunks . i 'm they would prefer it one hour . that just naming schemes will get we can definitely do that . one question is , are there good places in the files where we can really do that ? someone will have to go through them and listen to them and pick a place to break them . they are played from the individual . actually put the wavefile in with beep in it . and pu and have a beep model . yes , it would be , cuz it 's very , very regular .  you have to may add some jitter to it . it 's just in this case they were not . think chuck had a good explanation for it which i liked , which is these they 're listening to it and they write something down , and let 's say they miss it , they rewind . they hear the beep again . was that beep , or was that a different beep ? that 's why chuck was suggesting different tones . my original thought was , you could have a different tone for each speaker . there 's plenty of tone space . and that might help cue the transcriptionist . give them a little cue about where they are . what do that 's what i was saying . is that you could have each speaker could have their own tone . and since there are no more than , ten speakers or per meeting , there 's plenty of tone space .  bo eep be oop . th i see .   chuck 's suggestion of just two beeps is because then you could have them actually transcribe "" h beep "" or "" l beep "" , "" high beep "" or "" low beep "" . it would be much easier .  we can , do , one for each ca one for each person in the meeting , you can only hire people who have perfect pitch , and they can say "" a flat "" "" b "" .   think , certainly , doing two beeps is no brainer . and then the other question is , if they can if they do something on a computer in a format we can handle , we could give them a text file that was a template with speaker id and beeps already in it . and then they could just fill that in . right . as i said , we don't actually know , but chuck 's hypothesis was a good one , which is , you re r you listen to something , you write down what you thought you heard , but you want to listen to it again , you r rewind . and then you hear the beep again , and then you say "" is that beep , or is that a new beep ? ",,
Bmr022.A,"i don't remember . "" and a couple times they got it wrong . we could . we could , but then that starts getting pretty long . they would have to have a mark . it 's sequential . right , you would go sequential . unless you got pretty unlucky , what the person was saying and the number beep number . the it 's just getting pretty long . the utterances are very short . and you 're gonna be talking beep , number , "" yes ! "" beep , number , "" no "" . and when they transcribe this meeting it 's gonna be really impossible .  it 's not a bad idea . that would help get them synchronized . it would be , because they would know their place .  they would know their place , darn it ! those transcriptionists need to know their place . the numbers are a good idea . othe other than lengthening the transcript , it would be very helpful . you don't have to you could keep them short by not s or just go one through ten , one through ten , or one through twenty .   single digit numbers that also appeals to me . that you don't have to , "" one hundred twenty four "" "" beep . one thousand three hundred forty two ""  i don't remember . chuck was saying there was more than that . more beeps than that . was it that many ? don't recall .  easy enough to figure out . we have all that data . you 're right . it had to have been more than that . it was a forty five minute meeting ,  and it certainly was not a minute a chunk , it was a few seconds a chunk . 'm just mis remembering . i 'm just mis remembering .  it might make the transcript faster w wel a quick conversation with brian would be good ,   and other than that  right .  right . that 's what we want to avoid . but that won't work because it 's but , all we 'll get right , you need but you need the text to tell it where it got it wrong .  because you have to know which ones match which . and we can do that with wordcount . right ? we already know that we 're three short . and if we just did spee beep and non beep all you would get is that you have three mistakes , but you wouldn't tell you which ones were wrong . you need some of the words in there , that you can say "" this segment matches this one , this segment matches this one , and this one doesn't match unless we insert a beep "" . actually , there 's an even easier way . we don't really need a beep model . just extract the segments and do a forced alignment , ",,
Bmr022.A,"and if the score is good , then you say it matches right . the numbered ones would make it a lot easier , cuz you could then really localize where the error is .  we could certainly break the meetings we could certainly break the meetings into pi pieces . just that 's true , that was chuck .  it does look good . i found several errors , but they were not significant . they were all things that i could easily listen to and sometimes convince myself they said one thing and sometimes the other ,    we still haven't really sat down and talked about file reorganization , and directory reorganization . we still have to do that . but i don't think we need to do that in this meeting . but , it is something that needs to get done , and i wanna also coordinate it with dave that we do a level zero backup right after . we don't waste a lot of tapes . but , let 's try to do that sometime ,  ch  we also still have to make a decision about mike issues , what we wanna do with that . and just swap them in and out ? we could certainly do that . morgan , just to since you weren't at the meeting last week , bunch of the edu fe folks really hate this style mike . that 's that 's a fairly strong indication of dislike .  the crown . what i was thinking is , we could get a few more of the sony ones and just unplug them and plug them in . and the only thing is that when you fill out the digit forms , you have to be to indicate which mike was actually used . that 's easy to do .  it moves us away from this uniform , all the mikes are the same , which some people had said was a benefit . but it is .   th we abs th we have lots o of choices of microphones .    right . right . we can go microphone shopping , and get more microphones . it 's just w i 'm just not what we should do .  i i agree with that , and my feeling is , we should get mikes that people like . and my feeling is , going out and buying a few more mikes is fine . should go do that ?  and then also , should we go ahead and get another wireless system ? for whatever it 's gonna be , no , actually , get we need another box . because each box in the back room can only take six . we could   'll just go d i 'll do that .   then i will just go do that , and send the bill to what 's her name . whoever will pay . you .  this it 's a cell phone jack . th d  ",,
Bmr022.A,"except that one 's even bigger than most of the ones i 've seen . most of the ones are just a little boom .  the biggest issue is the stupid cable that sony the connector that sony has , that , it 's non standard , and you can't just plug something in . you need to get it wired . right . right . i wonder if you could do an adaptor . i don't know if you can or not . an adaptor might be a better idea than do redoing the wiring all the time . right .   demo .  what i was envisioning was a pda with a cellular link in it . with one of the r short range wireless . and let th just do capture the audio on the pda and send the audio over the wireless net . but . bluetooth is shorter range , but you could use bluetooth . wh whatever the network guys already have hooked up for this floor . i don't remember what it 's called . then another issue on file reorganization is , making data available to people outside icsi . specifically , the u w folks have been wanting to get access to it . think the right thing to do for that , is figure out how to do cvs without compromising security . some pass ssh tunneled cvs , and then give them access . yes , except that the command has to not take a password . because it 's non interactive . and the only way to do that is with , hosts , which is insecure . we still have to look at it a little bit . i 'm it 's been solved , and haven't found the solution yet . but i am that people have done it because it 's gonna be a problem a lot of people have . but , n not really , because then we have the coordination issue . one thing they could do that 's true . they could simply log in to icsi and do everything locally . except they could share one . the , the ssh accounts , and the user accounts don't have to be similar .  there are lots of ways of doing it , but w but if we can't figure out a remote way of doing it , just letting them log in to icsi might be the intention was to put everything except the audio files themselves under revision control . and the audio files , it 's not worth doing cuz they 're too big . you 're never gonna be copying them around and making working copies of them . and then the other issue jane and i spoke of briefly is just general permission issues . that right now , lots of people create the files and then we have group "" meeting recorder "" . but that means anyone in the meeting recorder group can overwrite the files . ",,
Bmr022.A,"and that 's a pretty coarse level of granularity . we might wanna think about doing a meeting recorder user owner for those files , and then doing group slightly differently . but what we have now another option is to m make a non make it owned by a not real user , and then root will be able to do it . but root is pretty tightly controlled here . th i don't think that 's a good solution . yes , but if you do that , then someone who isn't the owner can't unchange it . as i said , it 's just a question of , do you wanna have to track down root if you have to make any change . you have security issues with that .  no , with doctor speech , it 's just a group . there 're lots of different owners of i of the files , but the group is always doctor speech . or real , usually . nnn do you ?  i 'm not too worried , because the group 's pretty small . but and just you , then , also just have the general problem of permission on the other files , that , do you want people checking out a transcript file when they find an error , and correcting it , or do they wa do you want it to go through you ? but that means that you 're gonna have to be available for people , all the time , who say "" there 's an error here "" , rather than just them just going in and correcting it . but you have a choice . either you let people do it themselves , or you don't . right . right , you could get email . send email to jane that someone has done a revision . you don't have to release it to the world until you 're ready to . the question is s w you would keep it in a separate file structure until you were ready to put it in the repository . or just keep the lock on it . until you 're  cuz it 's not remote . the thing about cvs is , you can be on a different machine . no , because uw wants to have access to these files . that 's the whole point . if they k en if they record a meeting , and they create a "" key "" file , and they find an error in their "" key "" file , they shouldn't have to tell us about that that they can create correct an error in one of their files . that 's why i wanna do it different than what ?  b but , the meetings are gonna be the same way . uw records a meeting , we transcribe it . a few months later they listen to it ",,
Bmr022.A,"and they say "" ope ! they got that acronym wrong . "" why sh  the p the point here is that it would be for there to be one repository . and if we don't let them modify their own data , they 're not gonna store their data in our repository . or if we make it inconvenient for them to change their data . i 'm just looking at it the other way around . let 's say we k ye i don't see a real difference between rcs and any other system . it 's just mechanisms . the thing about cvs is that you can have multiple people modifying and if the changes don't overlap each other , they can just do it . the problem with rcs is that if two people want to modify a file at the same time they can't , because the granularity of locking is at the file level . there 're lots of different policies for dealing with it .  at the repository level , there certainly is . you can mark a file as "" you can't check this out "" .  it 's just like source code , right ? that , when you 're developing it and it 's really rough , you don't put it in the repository . you to the point when you 're ready to release it , and then you put it in the repository and if other people wanna copy .  i 'm just imagine that we reverse this and they were keeping the repository and we were d collecting meetings and sending them to them . if i found an error , and i sent them email and said "" here 's this error "" , and i didn't get a response for a couple weeks , i would stop sending them the my data and i would start collecting it here and we would end up with two corpora . and i don't want that to happen . we have to make it convenient for them to make changes that they wanna make .   don't s i don't see that this is e  can you write "" unread "" on that ?  probably not transcripts , but it would be to have one mechanism for all the files . and they 're certainly gonna wanna change tools . and it 's the same as source code . you release source code at some point . and , either you have to do everything or you share responsibility .  right . you can back everything out . right , but what i want to avoid is ending up with two corpora . and if you make it too hard for them to check back in , they 'll check it out once , they 'll make all the changes , they 'll never tell us about the changes , and we 'll get two different corpora . right ? nope . shall we do some digits ? ",,
Bmr022.A,i wasn't planning on doing it simultaneously . oop ! ouch ! ,,
Bmr022.B,"c i definitely have to leave at three thirty today for whatever . that 's they 're having birthday cake and such and can't miss that . i 'm a may birthday , have to  this is this is one it 's one hour of speech ? and it took you a few hours to do it . he said that ?  hunh . can how many beeps are there , and how many do we were they d were off ? alright . and is it a and it was a hundred ish . if you get one excuse me . if you get one off , it t everything is off cuz of the alignment right ? and this is all in one file that 's continuous . why don't you make it multiple files ? because then if they have one off , then it would only screw up that file .  it seems now , if you just ha make one mistake then everything is off .  just say , "" is "" ten minutes is "" there 's other things to do that are more clever , but this just seemed to be the the obvious thing because , again , if you make one mistake , then everything after that mistake is off . and ,  low variance , wouldn't that be ? you might end up with some infinities there , but can i see that ? where 's the case ? is this a seven or what is it ? m one hundred . or you could have ascending tones , or no , thi i don't know . if you have a hundred just move them up i mu up a half tone for each one , and then was it ?  see , i should listen .  the only that might work too . i was just thinking that actually temporally just , an increasing tones that they would really have a sense of whether they were going , forward or backward or   it 's a thought .   that 's probably better ,  s scratch my other idea .    great idea ,  no , two is probably better than what i was suggesting , because what i was suggesting , in order to make it through a reasonable range for the whole thing , you 'd have to have the tonal differences between the two small , and actually you want them large .   what  what 's going wrong on the other end ? what are they doing ? what ,  s cuz they 're s distinguishing between twenty three that 's your indicator there , and twenty three that somebody happens to say in a meeting . but they might miss that , right ? having a beep too is good . w we 're saying "" beep "" . but it sounds like a k a short conversation with brian might be helpful to get a sense of what 's going on . th although ",,
Bmr022.B,"you 're saying i it 's about an hour meeting , and there were a hundred and twenty three  i was just wondering what the average length thing was .   right .  right , but my point was , if it 's a big difference to me if there 's a thousand or there 's a hundred . if there 's a thousand , then that means that this is only happening three times out of a thousand . which means , even just splitting it up into a few files would probably take nearly all the time , there would be no w if it 's a hundred , then that 's not the issue , but if it 's a hundred , then , the average length of each one is pretty long and having a little thing at the front of it is no big deal . that 's why i was curious .  you 're still talking a forced al with the beep models , is what 's really you 'd have really g it would be really good though .  it 's p it 's really just doing , a keyword , like a spotting for beep with  again , especially if there 's hundred many hundreds or thousands i still think it would cut the incidence of this a lot if it was possible to break it into a couple files . cuz it , it 's r you 've already broken them into chunks , if you have a th if you have a thousand chunks then make ten things of a hundred , or and then it will be , this eve every now and then there 'll be a beep missing . which one is these ? the  there are many things about this that are non uniform that having some modicum of uniformity is a good thing , but you 're just not going to we 've  jus just the fact that people sit in different positions , different times , the exactly where they put it with respect to their mouth is different each time .  don't we 're getting rid of major differences like we 're not using the lapel anymore , an and forth . but the other is just gonna some variability we 're gonna have to accept .  see i happen to like the old one better . but  and some people do , but here 's another argument against worrying too much about uniformity . we have something like forty five hours of data collected . and , we 're also gonna be integrating in this corpus that 's being done at uw , with entirely different microphones . think , getting away from the lapel , having close mounted mikes , having people adjust them as they 're most as comfortable as they can that 's the big deal .    another wireless system . another transmitter ? or to get r to get rid of the wired things . yes ,  ",,
Bmr022.B,"because cuz we 've had with the exception of forgetting to change the batteries from time to time , we 've really had no tr no trouble with this right ? and the wired is just gonna continue to degrade as , and nobody will remember how to nobody will remember how to repair a jimbox or a jimlet or a it 's  whoever will pay ,   do the kind that hang from the ear , thing , or the but i don't know that one . what 's that mean ? is this just this little they have little headsets ? or what do they you 've got one . where does how do you wear that ? what does that over the corner of the ear  that i 've seen .   but what why would it be i 'm you 're talking about that as a possible thing to plug into the sonys . no ? some people will ,  another s an another side to that is that , in principle , if it all comes together , supposedly we 're gonna get two iram boards . little later on in the year . and we 're gonna wanna be thinking in terms of some wireless connection to it .  we have , some little something , and , we have a wireless connection , this board , that 's doing the computation for the f the , the recognition . and we wanna be able to show off to somebody , we have a base station somewhere , and you 're wandering around , hands free , and no , what i 'm saying is that we 're gonna have to put together some little superstructure , d some demo box that it that doesn't do a whole lot , but it somehow connects to remotely to this iram board which will be doing the real computation . in other words , we 're not gonna attempt to build , it do the real work of building a portable device that 's little , that is doing all the computation we wanna do for the recognition and the far field mike , compensation and all that we 're gonna do all that on this powerful board , and , have some wireless connection to it . and then the question is what does it look like , does it look like something that you hold like this , or do we make a big deal out of it that you hold it arm at arm 's length th that you can see some display , or , do we have one of these i don't know . it th these are all possibilities . is bluetooth the thing that 'd be ,  who we 're s talking about a fairly limited group , are is it a small enough group that they would could just have accounts ? does that solve anything ?  but that 's not right .   what does cvs do if they do overlap ? ",,
Bmr022.B,i   gotta go . ,,
Bmr022.C,"you 're a may birthday , right ? barbara told me . barbara peskin . and this is the mixed signal ? the other thing you can the other thing you can do this is on the mixed signal , or are these the individual the ones with the beeps that they 're getting , that they made mistakes on is the mixed one ? or they 're indivi if it 's individual , c we can probably run a forced alignment , where you c include the beeps as words and figure out where the errors are . i don't think we could do it on the mixed signal , cuz it but on the individual channels that would probably work , if they have enough words in the transcript . that 's pretty quick to run . it 's , we could try it . cuz if a beep is treated as a unique word , "" beep "" put in put "" beep "" in as a word . the beep model actually , you could train a beep model . that 's a good idea .    that might actually that might actually work , because you 'll the trick is figuring out , where it doesn't align ? but if it 's a problem of extra beeps , rather than missing beeps , then that 's easier and it might work .    you could have , each speaker in the meeting say "" beep "" and record it and that will be their pro   but yo you 'd still get the mistake that you mentioned , because the person if that 's some of the errors , those would probably stay the same , regardless . you have like a sanity check on them . that 's a good idea . alternating . that 's a good error checking approach , there must be . because otherwise , you 're going a whole that was at least forty five minutes , right ? that 's the shortest meeting we have . most of them are double that , or  if there are in the hundreds and thou or thousands of these it must be in the high hundreds of them , at least . that 's getting a little cumbersome for them to type five hundred ? but if they recycle through  right . that 's what i it 'd be a lot of overhead to type . i   actually , if it is u it 's not a bad idea to try the alignment . if there 's only like three of them , then if you align , the first point at which things get messed up is the location of the first problem . and then , the second p you could do it that way , or you could it 's it 's it would be able to handle any errors . ",,
Bmr022.C,"if they make , on the average , that many , and it costs them more time to do something different than what they 're doing , which i don't know , but if it does , then we could try doing that as a post process , and , have a student or a transcriber run this alignment , or we can do it and then you can iteratively figure out where the problems are . it would take a little work , but not any real human not a lot of human work . the for the forced alignment will run fa otherwise it 'll take forever . to really run recognition ? or ? right . then we just map it to a reject model . in and that 's what we do now . cuz there 's cases , even after jane listens , where , we have an expert can't even tell what they 're talking about . that 's just map that to reject and the forced alignment might not work then , although we can try it .  right . right . but it 'll grab the next beep , in other words . it 'll be you 'll get back another offset . mean , i was thinking of then i and then i realized "" the recognizer will just go along and line up all the beeps , and then there 'll be all the extra beeps at the end if there were more beeps then you wanted . "" you need the word to c control the relative location . it will tell you  you do care about it . unless you wanna know if they 're right . otherwise you just count up the total number of beeps .  right . the only thing i 'm worried about with that approach is that if we need to figure out the beep alignment problem before the transcribers do the corrections here , then we 're in trouble . in other words , if the transcripts aren't good enough that the aligner constraints are good enough to show you where the errors are , then it wouldn't work . but it might work . it might work to do this if their transcripts are pretty close on the words that usually get recognized correctly , which are the , function words , the common words . right , you can also that 's what we do right . the individual segments between the beeps if beeps were like the segments that we get from the transcription tool already , that 's what we have done , and it works very you can see these segments align and these don't . then you just have to go back in and figure out where the endpoints of those segments are , cuz some of them will be wrong . because the bi the beeps were missing , by definition . it might actually work . you ca you get , ",,
Bmr022.C,"definitely when they don't align it fails . that 's how we found a lot of problems before , with , words being on the wrong place failed alignment is a very good indicator that the words don't match up .  is , it right . it can't match up the that 's why you actually need the text . in order to force you to try to match something that gives you a model to match against .  it 's just an idea , if it turns out that i also like this idea of high and low beeps , or but it if suppose we get one or two errors , still , per per transcript , then we z we might wanna try some approach like that . where it is . right . if if that doesn't add time for them , that 'd be great . like we have to ask them . also even for the transcribers , it 's quicker to load a smaller file into the t for the checking problem . into twenty minutes chunks or i haven't looked at these ,  cuz i was gone last week , but don had told me that there 's a difference in some of the conventions ? but those are all easy things , right ?   we can just map map them to great .  i wouldn't it they didn't say "" hate "" but they c they come on time to their meetings in order to not be left the last person who has to sit by those mikes . there were a few people you , and like , three or four people who really like them . and e and th all the others really don't . what about just a different headband thing ? or even if we could attach two headband like , i don't mind those , but it they bounce around . can we keep the microphones , and just somehow attach a more comfortable thing over your head ? that 's my problem with this one . the ear thing comes out to here . it doesn't even fit over my ear . and for some of the others , it 's their ears were shaped in a way that didn't hold the what about these another one just bit the dust . there 's a problem with this one . i have a quick question about microphones ,  i got this crazy idea that , i in the future , people will just walk around with the microphones that they use for their cell phones ? these little boom ones , like , and really go to meetings with close talking mikes . if they 're their own personal microphone . and 'm wondering if we can get a couple of tho i don't know how good quality they are , but it would be really interesting to see if they 're good enough . ",,
Bmr022.C,"the k kind that guys that like to look like they 're really at airports wear . you can't miss it . you cannot miss it . they 're the guys going around they 're probably talking to nobody , but yes . they wear the heads e there you go . yes . that 's that it looks like that . whatever people wear to use l something like tha with their cell phones , it 'd be really great , if we can argue t that people like that . are they ?  it 's they 're not compatible ?  just as an example for , the future , of the fact that people will wear those microphones , or some people might , to meetings ,  not a i 'm not saying there 's not a far field microphone , application , but if we have a choi i 've always wondered how they would work . right . they could use the anyway , it 's just an idea .    can you just do sux to modify if you just have one user that  but it doesn't have to be root . it could be some other user that we all can sux to .  tha that 's what i meant , it just some user like "" meeting root "" i don't know .  you can  is cvs , like just keep the lock on . just check it out and don't let anyone check it out  it it doesn't .   why not use rcs at that point ? just at that stage ? it 's not remote . but at that point we only want , probably , jane to be in control anyway , and she it 's just an i but not to modify them , right ? just to read them . i don't know , mean then they should send that through it 's not really a question about permissions , but more of procedure . either those all go through jane , or through someone , or they all don't . but it 's and if they all do , then there isn't a problem , right ? cuz once they give us the data , it 's ours , and if they wanna make changes ours to transcribe and annotate . and if they wanna make changes , they can do that . then if they do have acc what if they have accounts here , and they use rcs , at that point , where you can l really lock a file . i 'm worried . if you can't lock a file , this to me sounds very scary .  and if they have accounts here and they 're modifying it if they 're ac if they 're closely linked that they 're actually modifying transcripts and "" key "" files , then they could do it by , secure shelling into icsi , under rcs , at that point .  ",,
Bmr022.C,"there is a way in cvs to effectively lock something if you don't want people to make any changes ?    then you could use cvs and , just f have remote access , but then it 's up to whoever is , responsible for that level of transcription to decide how and when to put these locks , or  right . if that 's at an it depends on jane 's  if that 's if that model works for the transcripts , then that 's fine . but if that pr @ @ allows someone to come in and modify while you 're modifying , and they turn out to be changes that , would have been better to until your version came out , then that 's really up to you , not up to the software , that 's what i would be worried about too . right . i like that idea because even a casual user can always send email to whoever 's in charge , and say , "" we 'd like these changes "" and , hopefully we 'll give them a response . and if they really do it a lot , and they say "" we 're a casual user but we want a chance to change the transcripts "" then we can face that if it happens , but i don't really see the people at uw that i know of right now making huge amoun investing huge amounts of time in changing transcripts . but i could be wrong .  right . right . and there 's some happy medium and we don't that is yet until we get feedback from people , but what if it 's to just handle it with person in charge of the philosophy behind the changes , and some people with permissions , by request , to make changes , that we don't just give people permissions if they 're not gonna make changes . because i 've overwritten a file by mistake , not wanting to have done that cuz i didn't had permission , when i did . and then just seeing if that is enough to handle the transcript changes . i 'm just worried about letting everybody go in and make changes , cuz it 's real easy when you 're trying to , i don't know , run alignments and there 's a word you wanna fix , to go in and do that and then mess up other things , if you don't know , the overall philosophy behind the conventions .  right . exactly . or just , start by make it a really tight control and then as people really need the control you can ascertain whether or not to right . right . we 're already gonna there 's already some chance that different annotations , different places , but you can control that by knowing you 're making two corpora ",,
Bmr022.C,"or knowing that you 're adding annotations on one version and you don't have the latest corrections at that point . and then you finish the project and you realize that there were corrections made on your originals and then you have to merge them . and the b the thing that makes it ea to do that , is knowing where the synch time boundaries are . cuz you can automatically merge things if you 've only got twenty words or in an utterance . it 's when you get the whole meeting and the synch times ch have changed , or you can't correspond to a previous version with synch times , that you get in trouble .  was there anything else on your list ? now , are we doing them simultaneously or one at a time ? alright . ",,
Bmr022.D,"  inserted ones . for one meeting .  for   individual channels .  in the end ?       that 's funny .  or just just instead of the sequential number , for perhaps just the speaker id just say speaker one or spea or just one , two , three , four for four speakers pppt ! could be helpful .    it should be more ,  it 's    why not ?  that 's right .   it just ha just hangs down there .    to decide which one is   ",,
Bmr022.E,"is it on ? one of the things that adam said that would be a good idea would be , if we g used different beeps . if we alternated between two beeps , a high and a low . th in some email that , we had . because then  text template , but i don't know how we can do that . l it was a lot more than that . they were three off ,  the only question about that i have is , brian has to put all this onto a tape . don't know whether can he send them he could send them multiple tapes   the only other issue is we 'd have to worry about reassembling them in the proper order .  individual channels . we that 's we we have the original wavefile with all the beeps . it would be very good . very low . it could t it could there could be some missing ones . but increasingly high higher frequencies . and then when we get them back , if we see two l beeps in a row and it would it seems like it would help them , if they just finished a long passage and they heard one beep and then they hear it again , they know it 's the same beep . versus if they heard a slightly different one .  should write to brian and tell him what the problem was and what our proposed solutions are . see what he thinks would work best with them . and there are some and there are some cases where there 's , very little speech before you hear a beep . you hear a little bit of speech , beep , a little bit of speech , beep . three of those in a row , and was that three beeps , was that two beeps ? see , they have th brian said the setup that they have is ,  they 've got headphones and then they have a computer , and they have a foot pedal which lets them quickly scan back and forth through the tape . i t i s makes the tape go real fast forward or fast backward . and they can hear something , then step on the pedal and quickly rewind and go back and hear it again . and they 're they 're probably going over and over f sections . and then they get confused about whether they 've already put that beep , or if they heard , three beeps in a row , was that three or two , and that 's an interesting idea . no , no . but what we have instead of a beep is a , synthesized number . and they put the number in when they hear it . inst replacing the beep with "" twenty three "" , "" twenty four "" , "" twenty five "" ",,
Bmr022.E,"and then they have to transcribe what that number is each time . just a "" two three , two four "" , that would be there 'd be some mark in front of it . it would have t it would have to be either s sounding synthesized , little  or a beep and the number . right . we could put it at the beginning of each utterance . we could say "" beep one "" . and then they 'll hear the speech . or a number beep   and u it would i actually , i thi i like that . it would  but see that would definitely keep  keep things from getting out of sequence . if they heard it over again they would know . it would be obvious from their transcript whether they did that one or not .  and we have plenty of digits data ,  we i 'll i 'll write him an  i 'll talk to brian , and see what he  i was thinking there was on the order of fifteen hundred segments , but 'm of a segment that they 're hearing ? i don't know . i don't know .  if we did mod ten , then    actually , what all that we would liz , all we would re if in terms of the alignment , actually , all we would need is we wouldn't even need words . we would need a general speech model and a beep model . cuz all we 're really concerned about is missing beeps or too many beeps . if we had a  what i 'm thinking of is that w that a lot of times there will be they 'll put in question marks , that represent some unknown amount of speech , we 're gonna have to have some right , h  right . what i was thinking is , map all the speech to the reject model . and then you have a beep model . the beep model is gonna match really no , i 'm not sug i 'm not suggesting that we don't have anything between the beeps . but i what i 'm saying is , what 's between the beeps we don't really care about . do you get a score for each alignment ? is that what you get ?   i 'm just wondering when wha what it means to fail . is it the likelihood scores below some threshold just just accumulate it till you get twenty minutes worth ? there 's one file . i 'll i 'll talk to him . really ? you do . there 's another kind which s goes in your ear and it hangs down . there 's a little b bulb that hangs has the mike on it . how standard are these ? it is an interesting idea . if we could build an adaptor that went from cuz mine looks like this too . ",,
Bmr022.E,"if we had this style plug that went to that , then we 'd just have adaptors and people would plug them in . you could use they could use their own . i don't understand . there 's a mike that plugs in you 're saying there 's a mike that plugs in to the iram board ? or i see . i was i was reading through some of the cvs documentation and you can just substitute cvs for your r s h command .   they 're gonna have to have accounts if they use ssh they have to have an account anyways . that 's what we do with doctor speech though , right ? but there is a user doctor speech . right ? i sux to doctor speech w when i need to make a directory on , one of the with cvs , though , you don't actually have to do it that way . what i 'm saying is that it can be the case that people can do it themselves and it can be reviewed . right ? it 's not like it 's one or the other . we can do both . right . no , it does not the cvs doesn't work that way . there 's no lock when you check something out , not like rcs . in other words , everybody can check out anything . the c stands for "" concurrent "" . but typically a person has to , mediate which changes actually get go through . cvs is pretty good . the w in the the model it 's a little bit different in cvs . when you check something out , you actually create your own directory with copies of everything in it , and that 's what you work on . until you 're ready to check it in , nobody sees anything you 've done . and then when you check it in , it puts , every change that you 've done is goes into the central there would have to be somebody to enforce the consistency .   there are probably ways that you can say that , only certain users are allowed to change things . we can probably restrict it to be f casual users who are just browsing can just r get it read only , can't check in to the archive . whereas we could say "" other people "" , "" these people are allowed to actually submit changes "" . one thing that 's probably everybody would agree on is that there will never be a point where we can say that for there 's no problems with any of the transcripts . there 's , something 's going to get overlooked at some point , or somebody 's gonna wanna make a change somehow . we need to have some mechanism for , handling changes in the future . exactly .  right .  good point .   that 's a good point .    ",,
Bmr022.E,"mean a lot of the open source pro projects face this same problem . p anybody can check out the code , but not everybody can check it in .  then there is also the possibility remember , in cvs , when we talk about making changes , there 's two types that can be made . to your local , or to the global . and people can make changes to their local and if they screw those up , that 's , in their that 's only on them . it 's w it 's the checking in part that r we really care about , and that we can control with , who can check things in and we can we can do this .  they can still check it out cuz they can still check out full copies and make whatever changes they want to their local copies . and it won't affect the g the global , official , ones yes . definitely .    lee , you liked that l  ",,
Bmr022.F,"    that 's true . i 've noticed that . which makes sense . on the email .  and then the other possibility was e that we provide them with a file that already has the beeps in it wasn't that what you said ?        but you th just r truly chron chromatically up all the way through the entire meeting . interesting . it 'd be impossible to r to misorder them .  it 's pretty simple , pretty simple . interesting .  "" high "" , "" low "" is pretty straightforward ,  you 'd have to they 'd have to have the acoustics of dogs t hear into the high ranges .   it 's a shame we can't really give a number . it would be a number and a beep . e it 's a shame we can't do that . that 'll work . that 'd also be shorter to type . interesting . that 's true . or could it be a click and the number . or a beep and the number , and then you just do the num th you do it as a d a digit . if it saves time ,  it might actually help them in terms of their place holding .  and it might be helpful to them in terms of d act know no no .  i and then also , if we i don't their setup is , but your template idea might be a way of we could actually build the numbers into a template .  that 's a good idea . very simple . it 's forty five minutes . forty five minutes for that one . it 's possible . that 's right . it was forty five minutes . interesting . with just one digit though ,  and the other thing is , the numbers would help them keep their place in the transcript and speed the process     it would save them time . it would help them keep the track of it . interesting ,  someone 's gonna talk to brian .  i also looked thr over the text and i was impressed by the accuracy , it looks really good . it 's there .  yes . but this is not important . it 's systematic ,  and brian actually forwarded me in advance . he wor he very nicely worked out a set of conventions which is intermediate between ours and the ones that they 're used to . which is really a good way to do it . no problem . we can do it this week .  we were going to get two more of the ones can i c i i actually really like them though . i do . the other thing , too , is th y you said that the acoustic pra q quality of the one that you 're wearing , the fancy one , is actually somewhat better than don't know if it 's a noticeable difference , but it is ",,
Bmr022.F,"i p i personally really prefer that model , think we 've got this problem of people having different preferences .   it 's i understand , that 's fine with me . i g would say that i find this model easier to adjust , that 's one of the reasons i don't like these , cuz i keep m bending it , and then it 's n and i never really know you do ?    then they have to be rewired though , don't they ? specially .   you put it over the corner of your ear . i can't i 'm having competing microphone headphone problems here . this one . it 's an interesting idea . the acoustics the acoustics on this are really s m better than when i talk into it directly . works with this . i don't know . i had another thought . would w would it be possi there are scripts that run , and when it 's finished compressing , would it be possible for the script to change the permissions on the file to be more strict ? have them but after the meeting 's done , would they want to ? that 's true . that 's true . also it seems like once it 's been stored that night , it 's possible to recover from backups , that the main risk is avoiding it being accidentally deleted during the day that it was recorded .  and i 'd prefer it to go through me . p at this point   w  i wanna also say that , this is a my view on this is that once it 's in a final version and i 'm working toward all these being final versions , then it can go into this next ro this next realm . but it 's counter productive to have changes made which i would be making if i 'd just gotten that far in the file . it 's it 's ,  that 's right . and then after that , then this would probably work .  good , good . the "" key "" file is ke "" key "" file 's different . "" key "" fi "" key "" file has the extra attributes that if you notice that there are lots of spikes on channel and it 's useful as a repository for putting that there . and also if you notice that there was an extra speaker , and didn't get mentioned in the "" key "" file , but they were only there for a second , but it 's t useful to mention that they were there . th that the "" key "" file is usefu for notations related to the meeting , but it 's different from the transcript .      that 's interesting .    i also think , that the type of change ch varies an it 's a very good point . ",,
Bmr022.F,"because what if the what if one set of changes one person was making was with reference to some typographical convention . and the other person n unkn n quite unknowingly , was changing it the other way around . then you could end up with a real mess , in terms of consistency of conventions across a file , there is an argument to be made for having a single editor editing at that level . but i like b i like what liz is saying about that 's right . and i also like i l also like liz 's k phraseology of "" at this level of "" i don't remember how you put it , but this "" at this level of transcription "" or whatever . it 's like there are different layers of whatever and different types of conventions , and if it were an acronym , then i would that it would make sense f for them to have input into that level of things , but i wouldn't want them to be changing     i agree .  i see now , we 're k back into the same situation as when we were , talking about a allowing people to edit the transcripts before they become public . there 's a question of how easy or how hard to modify , and how that impacts the amount of changing that 's done . and that it 's , i have received some suggestions for change , which i 've made . and with an acronym , that 's a clear case where it would be an easy change to incorporate . but it would worry me to have people , having free reign to change these things , because of the need to have consistent conventions . and people who are only just visiting the data might not have a sense of the larger system .    i agr i agree but i have to also add one other thing which i before i forget it , which is adam 's point about when you were reviewing the ibm transcripts . u this was mentioned at the beginning of the meeting . you said that there were some places where it wasn't what y was written already , but you could see how they might have thought that 's what it said . there it 's not just a right and wrong thing . sometimes there tru there are stretches where there is no k if you were at the meeting and you could ask the person , m they could they could 've told you , but five minutes later they might not have been able to tell you , even if they were listening to it . sometimes it isn't right and wrong , sometimes it 's multiple interpretations , and now but this does raise the possibility of allowing , an extra annotation for , alternative interpretations of a stretch . but wanted to say it isn't simply right or wrong . ",,
Bmr022.F,"or overlooked or not overlooked . sometimes they 're truly ambiguous , and to have a notation for that , but .   and als it also    ooo ! ",,
Bmr023.A," they sound really good .  it sounds like a radio announcer 's voice . really .  that 's right . now actually , we 're are we handling ? we the transcribers have continued to work past what i 'm calling "" set one "" , which was the s the set that i 've been , talking about up to this point , but , they 've gotten five meetings done in that set . right now they 're in the process of being edited . the , let 's see , i hired two transcribers today . i 'm thinking of hiring another one , which will because we 've had a lot of attrition . and that will bring our total to  it 's various things . one of them had a baby . one of them really w wasn't planning one of them , had never planned to work past january . it 's th all these various things , cuz we , we presented it as possibly a month project back in january and it makes sense . through attrition we 've we 're down to two , but they 're really solid . we 're really lucky the two that we kept . and , i don't mean anything against the others . what is we 've got a good good core . no . we had a good core but still . i d it 's just a matter of we w we 're we 've got , two of the ones who , ha had been putting in a lot of hours up to this point and they 're continuing to put in a lot of hours , which is wonderful , and excellent work . and then , in addition , i hired two more today and i 'm planning to h hire a third one with this within this coming week , but the plan is just as , morgan was saying we discussed this , and the plan right now is to keep the staff on the leaner side ,  rather than hiring eight to ten right now , because if the ibm thing comes through really quickly , then , we wouldn't wanna have to , lay people off and  and this way it 'll i got really a lot of response for my notice and could hire additional people if i wish to . yes . good .  the pre segmentations are much are s extremely helpful . now there was , i g guess a couple weeks ago i needed some new ones and it happened to be during the time that he was on vacation f for just very few days you were away . but it happened to be during that time i needed one , started them on the non pre segmented and then switched them over to yours and , they , they always appreciate that when they have that available . and he 's , usually , they really appreciate it . ","we the transcribers have continued to work past what i 'm calling "" set one "" , but , they 've gotten five meetings done in that set . i hired two transcribers today . i 'm thinking of hiring another one , which will because we 've had a lot of attrition . the pre segmentations are much are s extremely helpful . ","Specifically, the group would like to have transcripts available, which would mean resolving legal issues for data use and on the basis of feedback from IBM get more transcription underway. "
Bmr023.A,"but i was gonna say that they do adjust it once in a while . once in a while there 's something like , and e actually you talked to them . didn't you ? did you ? have you ? and she was and i asked her they 're very perceptive . i really want to have this meeting of the transcribers . i haven't done it yet , but i wanna do that and she 's out of town , for a couple of weeks , but i wanna do that when she returns . cuz she was saying , in a span of very short period we asked it seems like the ones that need to be adjusted are these things , and she was saying the short utterances , the , you 're aware of this . but actually i it 's correct for much of the time , that it 's an enormous time saver and it just gets tweaked a little around the boundaries .  it 'd be interesting to combine these . you could do it . it 's complicated in that hhh , i hhh , i there is a there is one problem with that and that is when they start part way through then what i do is i merge what they 've done with the pre segmented version . it 's not a pure condition . wha what you 'd really like is that they started with pre segmented and were pre segmented all the way through . and , @ i , the it wasn't possible for about four of the recent ones . but , it will be possible in the future because we 're ,  interesting idea . in principle , i would say yes , although i still am doing some the final pass editing , trying to convert it over to the master file as the being the channelized version and it 's it seems like i get into that a certain way and then something else intervenes and i have to stop . cleaning up the things like the , places where the transcriber was uncertain , and doing spot checking here and there . it would make sense to until th that 's done , but  yes . it 'll certainly be done by then .  that 's right . that 's right . that 's right . that   see , this is the issue . subtleties . the other thing , too , is there can be subtleties where a person uses this word instead of that word , which @ @ could 've been transcribed in the other way . and no and they wouldn't have been slanderous if it had been this other word .    i agree . i agree . ","but actually i it 's correct for much of the time , that it 's an enormous time saver and it just gets tweaked a little around the boundaries . wha what you 'd really like is that they started with pre segmented and were pre segmented all the way through . ",
Bmr023.A,"it 's just , a question of , if the person is using the transcript as the way of them judging what they said and whether it was slanderous , then it seems like it 's i it needs to be more correct than if we could count on them re listening to the meeting . because it becomes , in a way a f a legal document i if they 've to that . if it 's only the transcript , though th this is my point , that then it becomes if it 's just the audio   that would be simpler , if we could count on them listening . unfortunately , in the sign thing that they signed , it says "" transcripts "" . "" you 'll be provided the transcripts when they 're available . ""   yes . yes . it 's done , ready , available . good . mine 's identical to yours . is that correct ? i see . i see .  ","unfortunately , in the sign thing that they signed , it says "" transcripts "" . "" you 'll be provided the transcripts when they 're available . "" ",
Bmr023.B,"there we go .  camera one , camera two .  come on . that 's   sometimes not . sometimes positions in sentences or in spurts , was helpful . i don't know if that 's cheating , too . right . right . would they give you the same number of words , though ? but ra somewhat ? ti just p time position , like when the word starts ? i don't know if that was in the start . there 's all these things to do . like , there 's a lot of different features you could just pull out . right .    ","like , there 's a lot of different features you could just pull out . ",
Bmr023.C,"what channel am i on ? channel two . unison . greek chorus . are you implying that it 's currently disorganized ?  we 're improving .  actually it looks like it 's getting better . but it 's not with age . but , that 's not d directly related to me . doesn't mean we can't talk about it . it seems it looks l i haven't the it 's the experiment is still not complete , but , it looks like the vocal tract length normalization is working beautifully , actually , w using the warp factors that we computed for the sri system and just applying them to the icsi front end .  just had to take the reciprocal of the number because they have different meanings in the two systems .  but one issue actually that just came up in discussion with liz and don was , as far as meeting recognition is concerned , we would really like to , move , to , doing the recognition on automatic segmentations . because in all our previous experiments , we had the we were essentially cheating by having the , the h the hand segmentations as the basis of the recognition . and now with thilo 's segmenter working we should consider doing a doing     right .  we should consider doing some extra things retraining or adapting the models for background noise to the to this environment ,  right . where 'd you get the digits from ? and do you splice them into the waveform ? or ? right .  that was an unfor unforeseen side effect of and they don't have to approve , th an edited version , they can just give their approval to whatever version bu but th the editing will continue . presumably if s errors are found , they will be fixed , but they won't change the content of the meetings .  tha that 's how about having them approve the audio and not the transcripts ? that 's o k . we just have to give them a chance to listen to it , and if they don't , that 's their problem . no , i 'm serious . really ?  spurts wouldn't be . right ? no have you tried using just time , as opposed to number of words ?  no , time position relative to the beginning of the spurt .  that wouldn't be cheating because you can detect pause pretty within the time .  w wh better in what sense ? i tried that . it didn't , help dramatically . the there were a little the relative number of there were a higher number of deletions , actually . you , actually it preferred to have a positive er , negative insertion penalty , which means that , but , it didn't change th the by adjusting that the , the error changed by probably one percent or but , given that word error rate is high , that 's not a ","it looks like the vocal tract length normalization is working beautifully , actually , because in all our previous experiments , we had the we were essentially cheating by having the , the h the hand segmentations as the basis of the recognition . and now with thilo 's segmenter working we should consider doing a we should consider doing some extra things retraining or adapting the models for background noise to the to this environment , and they don't have to approve , th an edited version , they can just give their approval to whatever version but th the editing will continue . presumably if s errors are found , they will be fixed , that wouldn't be cheating because you can detect pause pretty within the time . ","PLP results for the front-end look good, with the group also reporting progress in segmentation: Thilo's segmenter will now be used and ways of improving performance investigated; "
Bmr023.C,"that 's not the problem . no . but , we s just ,  chuck and i talked and the @ @ next thing to do is probably to tune the the size of the gaussian system , @ @ to this feature vector , which we haven't done we just used the same configuration as we used for the standard system . and , dan @ @ dan just sent me a message saying that cmu used , something like ten gaussians per cluster each mixture has ten gaussians and we 're using sixty four , that 's big difference and it might be way off and give very poorly trained , gaussians that way , an and poorly trained mixture weights . we have the turn around time on the training when we train only the a male system with , our small training set , is less than twenty four hours , we can run lots of just brute force , try a whole bunch of different settings . and , with the new machines it 'll be even better .   but the plp features work continue to improve the ,  as i said before , the using dan 's , vocal tract normalization option works very @ @ i ran one experiment where we 're just did the vocal tract le normalization only in the test data , didn't bother to retrain the models and it improved by one percent , which is about what we get with with , just @ @ actually doing both training and test normalization , with , the , with the standard system . in a few hours we 'll have the numbers for the for retraining everything with vocal tract length normalization and that might even improve it further . it looks like the p l fea p features do very now with after having figured out all these little tricks to get it to work .  exactly . right . a right . and what that suggests also is that the current switchboard mlp isn't trained on very good features . because it was trained on whatever , was used , last time you did hub five which didn't have any of the  but if you add them all up you have , almost five percent difference now . and now we have another percent with the v t actually , and it 's ,  what 's actually qu interesting is that with you m prob another half percent if you do the vtl in training , and then interestingly , if you optimize you get more of a win out of rescoring the , the n best lists , and optimizing the weights , than   right .          he made it a parameter . it 's called , h hpf . u and but hpf , when you put a number after it , uses that as the hertz value of the cut off .      ","chuck and i talked and the @ @ next thing to do is probably to tune the the size of the gaussian system , @ @ to this feature vector , which we haven't done we just used the same configuration as we used for the standard system . and , dan @ @ dan just sent me a message saying that cmu used , something like ten gaussians per cluster each mixture has ten gaussians that 's big difference and give very poorly trained , gaussians that way , the turn around time on the training when we train only the a male system with , our small training set , is less than twenty four hours , but the plp features work continue to improve the , as i said before , the using dan 's , vocal tract normalization option works very @ @ i ran one experiment where we 're just did the vocal tract le normalization only in the test data , didn't bother to retrain the models which is about what we get with with , just @ @ actually doing both training and test normalization , with , the , with the standard system . in a few hours we 'll have the numbers for the for retraining everything with vocal tract length normalization it looks like the p l fea p features do very now with after having figured out all these little tricks to get it to work . right . and what that suggests also is that the current switchboard mlp isn't trained on very good features . but if you add them all up you have , almost five percent difference now . ","PLP results for the front-end look good, with the group also reporting progress in segmentation: Thilo's segmenter will now be used and ways of improving performance investigated; Work on the front end continues, with improvements of 3-5% being made. "
Bmr023.C,"but , again , after completing the current experiments , we 'll we can add up all the differences and an y right .  that 's what i meant , do we expect ? at this point i 'm as i 'm wondering is it can we expect , a tandem system to do better than a properly trained a gaussian system trained directly on the features with , the right ch choice of parameters ? right .   right .  but there the main point is that , it took us a while but we have the procedure for coupling the two systems debugged now and there 's still conceivably some bug somewhere in the way we 're feeding the tandem features either generating them or feeding them to this to the sri system , but it 's  and i 'm wondering how we can debug that . how  i 'm actually f quite that the feeding the features into the system and training it up , that that 's this that 's essentially the same as we use with the ce with the p l p fe features . and that 's working great . i there we could the another degree of freedom is how do you generate the k l t transform ? right ? we to  right . right . no . the sri system does it .  there 's there is room for bugs that we might not have discovered , but right . they 're optimized for phone discrimination , not for  do y but and there 's a mismatch in the phone sets . you 're using a l a long a larger phone set than what  we already talked about that . el  no , but we when i first started corresponding with dan about how to go about this , that was one of the things that we definitely went there .  and i does it help ?   and do you do a klt transform on the con on the combined feature vector ? do you d you do a klt transform on the combined feature vector ?  because you end up with this huge feature vector , that might be a problem , a unless you do some form of dimensionality reduction .   actually , i have to run .  ","at this point i 'm as i 'm wondering is it can we expect , a tandem system to do better than a properly trained a gaussian system trained directly on the features with , the right ch choice of parameters ? but there the main point is that , it took us a while but we have the procedure for coupling the two systems debugged now and there 's still conceivably some bug somewhere in the way we 're feeding the tandem features either generating them or feeding them to this to the sri system , that that 's this that 's essentially the same as we use with the ce with the p l p fe features . ","Work on the front end continues, with improvements of 3-5% being made. "
Bmr023.D,"i saw her earlier .   she 'll probably come up . i 've got a couple of things to talk about . ibm and , just getting meeting information organized . in my mind . now the you saw the note that the plp now is getting the same as the mfcc . right ? talked with brian and gave him the alternatives to the single beep at the end of each utterance that we had generated before . and  the chuck chunks . right . and he talked it over with the transcriber and the transcriber thought that the easiest thing for them would be if there was a beep and then the nu a number , a digit , and then a beep , at the beginning of each one and that would help keep them from getting lost . and , adam wrote a little script to generate those style , beeps and we 're i came up here and just recorded the numbers one through ten .  does it sound we just used those . he then he d i recorded actually , i recorded one through ten three times at three different speeds and then he picked . he liked the fastest one , he just cut those out and spliced them in between , two beeps . does it ? with my that 'll throw them ,   and she said it wasn't gonna the transcriber said it wouldn't be a problem cuz they can actually make a template , that has beep , number , beep . for them it 'll be very quick to put those in there when they 're transcribing . we 're gonna send them one more sample meeting , and thilo has run his segmentation . adam 's gonna generate the chunked file . and then , i 'll give it to brian and they can try that out . and when we get that back we 'll see if that fixes the problem we had with , too many beeps in the last transcription . our s our on our side ? or including ibm 's ? i don't know . the last one seemed like it took a couple of weeks . even three . that 's just the i b m side . our side is quick . i don't know . how long does your ?    right .  i i hope @ @ we can get a better estimate from this one that we send them .  i don't know yet how long that 'll take .   right . right . burn out . jane and adam and i had a meeting where we talked about the reorganization of the directory structure for all of the meeting no . for all the meeting recorder data . we should have . and we 've got a plan for what we 're gonna do there . ","now the you saw the note that the plp now is getting the same as the mfcc . and he talked it over with the transcriber and the transcriber thought that the easiest thing for them would be if there was a beep and then the nu a number , a digit , and then a beep , at the beginning of each one and , adam wrote a little script to generate those style , beeps we 're gonna send them one more sample meeting , and thilo has run his segmentation . adam 's gonna generate the chunked file . and then , i 'll give it to brian and they can try that out . and when we get that back we 'll see if that fixes the problem we had with , too many beeps in the last transcription . the last one seemed like it took a couple of weeks . even three . that 's just the i b m side . jane and adam and i had a meeting where we talked about the reorganization of the directory structure for all of the meeting for all the meeting recorder data . ","PLP results for the front-end look good, with the group also reporting progress in segmentation: Thilo's segmenter will now be used and ways of improving performance investigated; Specifically, the group would like to have transcripts available, which would mean resolving legal issues for data use and on the basis of feedback from IBM get more transcription underway. "
Bmr023.D,"and then , jane also s prepared a started getting all of the meetings organized , she prepared a spreadsheet , which i spent the last couple of days adding to . went through all of the data that we have collected far , and have been putting it into , a spreadsheet with start time , the date , the old meeting name , the new meeting name , the number of speakers , the duration of the meeting , comments , what its transcription status is , all that and the idea is that we can take this and then export it as html and put it on the meeting recorder web page we can keep people updated about what 's going on . i 've gotta get some more information from jane cuz i have some gaps here that i need to get her to fill in , but far , as of monday , the fourteenth , we 've had a total number of meeting sixty two hours of meetings that we have collected . and , some other interesting things , average number of speakers per meeting is six .  and i 'm gonna have on here the total amount that 's been transcribed far , but i 've got a bunch of that 's what i have to talk to jane about , figuring out exactly which ones have been completed and forth . but , this 'll be a thing that we can put up on the web site and people can be informed of the status of various different ones . and it 'll also list , like under the status , if it 's at ibm or if it 's at icsi , or if it 's completed or which ones we 're excluding and there 's a place for comments , we can , say why we 're excluding things and forth .  content , really . talk . could it have to do with the lower frequency cut off on the switchboard ?  were they out of balance ? i didn't notice .  we 're using sixty four , right ?  than you do with the standard ? that was combined with the triangular . right ? right . the low frequency cut off . what is the parameter ? is it , just the f lower cut off that you want ?   one experiment we should we 'll probably need to do though when at some point , is , since we 're using that same the net that was trained on plp without all these things in it , for the tandem system , we may wanna go back and retrain ,  for the tandem . we can see if it what effect it has on the tandem processing . we but we may not . if it doesn't perform as we may not know why . right ? cuz we need to do the exact experiment . ","and then , jane also s prepared a started getting all of the meetings organized , she prepared a spreadsheet , which i spent the last couple of days adding to . been putting it into , a spreadsheet with start time , the date , the old meeting name , the new meeting name , the number of speakers , the duration of the meeting , comments , what its transcription status is , all that and the idea is that we can take this and then export it as html and put it on the meeting recorder web page we can keep people updated about what 's going on . but far , as of monday , the fourteenth , we 've had a total number of meeting sixty two hours of meetings that we have collected . some other interesting things , average number of speakers per meeting is six . and i 'm gonna have on here the total amount that 's been transcribed far , and it 'll also list , like under the status , if it 's at ibm or if it 's at icsi , or if it 's completed or which ones we 're excluding could it have to do with the lower frequency cut off on the switchboard ? we 're using sixty four , ",
Bmr023.D,"morgan , an another thing that andreas and i were talking about was , @ in the first experiment that he did we just took the whole fifty six , outputs and that 's , compared to a thirty nine input feature vector from either mfcc or plp . but one thing we could do is through the regular tandem outputs . through the klt . all that kinda that 's what we did . right ? one thing we were wondering is , if we did principal components and , say , took out just thirteen , and then did deltas and double deltas on that we treated the th first thirteen as though they were standard features . did dan do experiments like that to ?    cuz in a sense , the net 's already got quite a bit of context in those features , if we did deltas and double deltas on top of those , we 're getting even more .     there could be a bug in the somewhere before that .  right . i 'm doing what eric e eric coached me through then that part of it , 'm pretty confident in that . the only slight difference is that i use normalization values that , andreas calculated from the original plp , which is right . n  i u i do we actually don't do that normalization for the plp , do we ? for the st just the straight plp features ? s r i system does that . right . that 's another    it 's hard with features , cuz you don't they should look like . you can't just print the values out in ascii and , look at them , see if they 're another huge experiment we could do would be to take the tandem features , do sri forced alignments using those features , and then re do the net with those .    did he try to ? he always ended up with a feature vector that was twice as long as either one of the ?  ","there could be a bug in the somewhere before that . it 's hard with features , cuz you don't they should look like . you can't just print the values out in ascii and , look at them , see if they 're ",
Bmr023.E,"channel . channel . channel whatever . what am i ? channel four ? this number four ?  but anyway , they won't be identical as somebody is saying zero in some sometimes , saying o , and it 's not i not identical .   we but anyway .  that 's what i wanted to do anyway , we should just get together and       we should do that .  it will be funny  it will be funny when you 're really reading digits , and then there are the chunks with your digits in ?   it should @ @ be finished today that was a thing i planned working on , is , to use the transcriptions which are done by now , and to use them as ,   and to use them for training a or for fo whatever . to create some speech nonspeech labels out of them , and but that 's a thing w was w what i 'm just looking into .    i talked to helen .      actually , when they create new new segments it will be , not that easy but one could do that .    that would be great , to know that .   it would .       y   ",it should @ @ be finished today ,
Bmr023.F,"channel five ? channel five . i 'm on channel five . little low ? channel five . channel five .  is it ?  it should be a little higher . it 's not showing much . test , test , test , test , test , test . that seems better ?  good . that 's good . that 's ahh . had a question for adam . have we started already ?  is jane around or ?  right . great idea . i was gonna ask adam to , say if he thought anymore about the demo because it occurred to me that this is late may and the darpa meeting is in mid july . but i don't remember w what we i know that we were gonna do something with the transcriber interface is one thing , but there was a second thing . anybody remember ?  right .  alright . anyway , you have to sort out that out and get somebody going on it cuz we 're got a month left    what are we g else we got ? you got you just wrote a bunch of    that 's the choice is , which do we want more , the comparison , of everybody saying them at the same time or the comparison of people saying the same digits at different times that ? i know that . but , which opportunity should we exploit ? unison . we 'll see it 's dependent on how long we go and how good the snack is out there . get some advance intelligence . we 'd have to train . we 'd have to get s get some experience .  really boring chorus . do we have an agenda ? adam usually tries to put those together , but he 's ill .   ju what might those be ? meeting info organized .   is there that 's happened about , the sri recognizer et cetera , tho those things that were happening before with ? y you guys were doing a bunch of experiments with different front ends and then with is that still where it was , the other day ? we 're improving . right . right .  just with age ,   that 's pretty funny .   that 's always good to do .      y think you think we should increase the error rate . good .   good . why don't we , do the ibm you had some thing about that ? right . the , chuck chunks .   we should have you record a , b , c for those  do w do what do you have any idea of the turn around on those steps you just said ?  including ibm 's .  i meant the overall thing . e u the reason i 'm asking is because , jane and i have just been talking , and she 's just been doing . e a , further hiring of transcribers . ","i was gonna ask adam to , say if he thought anymore about the demo because it occurred to me that this is late may and the darpa meeting is in mid july . i know that we were gonna do something with the transcriber interface is one thing , is there that 's happened about , the sri recognizer et cetera , y you guys were doing a bunch of experiments with different front ends and then with do w do what do you have any idea of the turn around on those steps you just said ? e u the reason i 'm asking is because , jane and i have just been talking , and she 's just been doing . e a , further hiring of transcribers . ","Additionally they would also like to have the question answering mock-up and transcriber interface ready for then. A pressing concern for the group is the DARPA meeting in July, which is only a short time away, and for which they would like to have some progress. PLP results for the front-end look good, with the group also reporting progress in segmentation: Thilo's segmenter will now be used and ways of improving performance investigated; Specifically, the group would like to have transcripts available, which would mean resolving legal issues for data use and on the basis of feedback from IBM get more transcription underway. "
Bmr023.F,"and we don't really know exactly what they 'll be doing , how long they 'll be doing it , and forth , because right now she has no choice but to operate in the mode that we already have working . and , it 'd be good to get that resolved , soon as we could , and then   in particular i would really hope that when we do this darpa meeting in july that we have we 're into production mode , somehow that we actually have a stream going and we know how it does and how it operates . that would certainly be a very good thing to know .   before we do the meeting info organize thing , you could say relevant about where we are in transcriptions . they die off after they do this for a while .  no backs .  an and the other thing is , in the unlikely event and since we 're far from this , it 's a little hard to plan this way in the unlikely event that we actually find that we have , transcribers on staff who are twiddling their thumbs because , there 's , all the that was sitting there has been transcribed and they 're faster the pipeline is faster than than the generation ,  i in the day e event that day actually dawns , i bet we could find some other for them to do . think that , a as we were talking , if we hire twelve , then we could , run into a problem later . we also just couldn't sustain that forever . but , for all sorts of reasons but if we hire f f we have five on staff five or six on staff at any given time , then it 's a small enough number we can be flexible either way . good .  u you were saying something about organizing the meeting info ? did you record it ? now would the ones that , are already transcribed we h we have enough there that c we 've already done some studies and forth and shouldn't we go through and do the business es u of having the , participants approve it , for approve the transcriptions for distribution and forth ? le let me put in another milestone as i did with the , the pipeline . we are gonna have this darpa meeting in the middle of july , and it w it 'd be given that we 've been we 've given a couple public talks about it already , spaced by months and months , it 'd be pretty bad if we continued to say none of this is available .  right . we can s we wanna be able to say "" here is a subset that is available right now "" and that 's has been through the legal issues and forth .   by before july . ","and we don't really know exactly what they 'll be doing , how long they 'll be doing it , and forth , because right now she has no choice but to operate in the mode that we already have working . in particular i would really hope that when we do this darpa meeting in july that we have we 're into production mode , somehow that we actually have a stream going and we know how it does and how it operates . but if we hire f f we have five on staff five or six on staff at any given time , then it 's a small enough number we can be flexible either way . le let me put in another milestone as i did with the , the pipeline . we are gonna have this darpa meeting in the middle of july , given that we 've been we 've given a couple public talks about it already , spaced by months and months , it 'd be pretty bad if we continued to say none of this is available . right . we can s we wanna be able to say "" here is a subset that is available right now "" and that 's has been through the legal issues and forth . ","Specifically, the group would like to have transcripts available, which would mean resolving legal issues for data use and on the basis of feedback from IBM get more transcription underway. A pressing concern for the group is the DARPA meeting in July, which is only a short time away, and for which they would like to have some progress. "
Bmr023.F,"in principle , yes . but , i if somebody actually did get into some legal issue with it then we  i it there is a point at which i agree it becomes ridiculous because , you could do this final thing and then a year from now somebody could say , that should be a period and not a question mark . right ? and you don't you there 's no way that we 're gonna go back and ask everybody "" do you approve this , this document now ? ""  think what it is that the thing that they sign i haven't looked at it in a while , but it has to be open enough that it says "" from now on now that i 've read this , you can use do anything you want with these data . "" and , but , we wanna assuming that it 's in that wording , which i don't remember , we just wanna have enough confidence ourselves that it 's close to the final form it 's gonna be in , a year from now that they 're  i forget how we end right . i forget how we ended up on this , but i remember my taking the position of not making it easy for everybody to observe everything and adam was taking the position of having it be really straightforward for people to check every aspect of it including the audio . and i don't remember who won , adam or me , but the that 's why i 'm bringing this up again , because i can't remember how we ended up . that it was the transcrip he wanted to do a web interface that would make it that would give you access to the transcript and the audio . that 's what adam wanted . and i don't remember how we ended up . you decided you were whispering satanic incantations under your breath when you were they disappeared from view .   w anyway , haven't we 've gone down this path a number of times . i know this can lead to extended conversations and not really get anywhere , let me just suggest that off line that , the people involved figure it out and take care of it before it 's july . that in july we can tell people "" yes , we have this and you can use it "" .  let 's see . what else we got ? don did a report about his project in class and , an oral and written version . that was he was doing with you .  the dominant features , including everything , were those quasi cheating things . right ? where these are right . on the average .  how about time position normalized by speak         great . ","in principle , yes . but , i if somebody actually did get into some legal issue with it then we i it there is a point at which i agree it becomes ridiculous let me just suggest that off line that , the people involved figure it out and take care of it before it 's july . ",
Bmr023.F,"has , we just just talked about this the other day , but h has anybody had a chance to try changing , insertion penalty things with the , using the tandem system input for the ?    that that 's not the problem .     we get twelve of those ,    great .  good .  then we 'll have our baseline to compare the currently hideous , new thing with . but  right . but all of these effects were j like a couple percent . right ? y the add all of them . one was one point five percent and one was point eight . that 's three point three . but the part that 's actually adjustment of the front end per se as opposed to doing putting vtln in is it was a couple percent . right ? it was there was one thing that was one and a half percent and one that was point eight . and let me see if i remember what they were . one of them was , the change to , because it did it all at once , to from bark scale to mel scale , which i really feel like saying in quotes , because @ @ they 're essentially the same scale but the but any i individual particular implementation of those things puts things in a particular place . that 's why i wanted to look i still haven't looked at it yet . i wanna look at exactly where the filters were in the two , and it 's probably something like there 's one fewer or one more filter in the sub one kilohertz band and for whatever reason with this particular experiment it was better one way or the other . it could be there 's something more fundamental but it i don't know it yet . and the other that was like one and a half and then there was point eight percent , which was what was the other thing ? those two were together . we d weren't able to separate them out cuz it was just done in one thing . but then there was a point eight percent which was something else . do you remember the ? that was , that one claim credit for , i in terms of screwing it up in the first place . that someone e until someone else fixed it , which is that , i never put when i u we had some problems before with offsets . this inf this went back to , wall street journal . we had , ea everybody else who was doing wall street journal knew that there were big dc offsets in th in these data in those data and nobody happened to mention it to us , and we were getting these really terrible results , like two , three times the error everybody else was getting . ","has , we just just talked about this the other day , but h has anybody had a chance to try changing , insertion penalty things with the , using the tandem system input for the ? ","PLP results for the front-end look good, with the group also reporting progress in segmentation: Thilo's segmenter will now be used and ways of improving performance investigated; Work on the front end continues, with improvements of 3-5% being made. "
Bmr023.F,"and then in casual conversation someone ment mentioned "" you 're taking care of the offsets . "" i said "" what offsets ? "" and at that point , we were pretty new to the data and we 'd never really looked at it on a screen and then when we just put it on the screen and wroop ! there 's this big dc offset . in plp no . it 's just , it 's not uncommon for recorded electronics to have different , dc offsets . it 's it 's , no big deal . it 's you could have ten , twenty , thirty millivolts , whatever , and it 's consistently in there . most people 's front ends have pre emphasis with it , with zero at zero frequency , that it 's irrelevant . but with p l p , we didn't actually have that . we had the equivalent of pre emphasis in a , fletcher munson style weighting that occurs in the middle of p l but it doesn't actually have a zero at zero frequency , like , typical simple fr pre emphasis does . we had something more fancy . it was later on it didn't have that . at that point i reali "" sh we better have a high pass filter "" just , just take care of the problem . put in a high pass filter at , ninety hertz or for a sixteen kilohertz sampling rate . and i never put anything in to adjust it for different sampling rates . and the code doesn't know anything about that and this is all at eight kilohertz and it was at forty five hertz instead of at ninety .  i don't know if dan fixed it or , what he he made it a parameter . if he did it right , he did fix it and then it 's taking care of sampling rate , which is great . he had a h does hpf on his feat feature .  frankly , we never did that with the rasta filter either , the rasta filter is actually doing a different thing in the modulation spectral domain depending on what sampling rate you 're doing , which is another old bug of mine . but , that was the problem there was th we had always intended to cut off below a hundred hertz and it just wasn't doing it , now it is . that hep that helped us by eight tenths of a percent . it still wasn't a big deal .  but , my point was that , the hybrid system thing that we did was , primitive in many ways . and agree with you that if we fixed lots of different things and they would all add up , we would probably have a competitive system . but not that much of it is due to the front end per se . ","and agree with you that if we fixed lots of different things and they would all add up , we would probably have a competitive system . but not that much of it is due to the front end per se . ","Work on the front end continues, with improvements of 3-5% being made. "
Bmr023.F,"couple percent of it is , as far as see from this . unless you call if you call vtl the front en front end , that 's , a little more . but that 's more both , right ? but .  that 's what we 're seeing in other areas . yes . right ? it 's  the reason to think it should is because you 're putting in the same information and you 're transforming it to be more discriminative .  now in some databases i wouldn't expect it to necessarily give you much and part of what i view as the real power of it is that it gives you a transformational capability for taking all sorts of different wild things that we do , not just th the standard front end , but other things , like with multiple streams and forth , and allows you to feed them to the other system with this through this funnel . think that 's the real power of it . i wouldn't expect huge in huge improvements . but it should at least be roughly the same and little better . if it 's , like way worse then ,   let me just ask you something . when you say take the fifty six outputs , these are the pre final nonlinearity outputs and they 're and through the klt .  and then you u do you use all fifty six of the klt or ?  yes . yes .  talk with stephane . he did some things like that . it was either him or carmen . i forget . these were all different databases and different in htk and all that , it may not apply . but my recollection of it was that it didn't make it better but it didn't make it worse . but , again , given all these differences , it 's more important in your case that you not take a lot of these low variance , components .  which could be good or not .  worth trying . there might be , cuz that 's a pretty big difference . but  what if ? that 's and another one is the normalization of the inputs to the net . these nets are trained with particular normalization and when that gets screwed up it can really hurt it .  right . you might e  i would actually double check with stephane at this point , cuz he 's probably the one here he and dan are the ones who are at this point most experienced with the tandem thing and there may be some little bit here and there that is not being handled right . not unless you had a lot of time and that 's right . the other th the you actually are . but it but in an indirect way . wha w what an and you may not be in this case , come to think of it , ","couple percent of it is , as far as see from this . i would actually double check with stephane at this point , not unless you had a lot of time ","Work on the front end continues, with improvements of 3-5% being made. "
Bmr023.F,"because , you 're just taking something that 's trained up elsewhere . what you do in the full procedure is you , have an embedded training . you the net is trained on , a , viterbi alignment of the training data that comes from your full system . and that 's where the feedback comes all around , that it is actually discriminant . you can prove that it 's a ,  if you believe in the viterbi assumption that , getting the best path , is almost equivalent to getting the best , total probability , then you actually do improve that by , by training up on local , local frames . but , we aren't actually doing that here , because we did that for a hybrid system , and now we 're plugging it into another system and it isn't i it wouldn't quite apply here .   another thing is since you 're not using the net for recognition per se but just for this transformation , it 's probably bigger than it needs to be . that would save a lot of time . actually all those things could , could affect it as the other thing , just to mention that stephane this was an innovation of stephane 's , which was a pretty neat one , and might particularly apply here , given all these things we 're mentioning . stephane 's idea was that , discriminant , approaches are great . even the local ones , given , these potential outer loops which , you can convince yourself turn into the global ones . however , there 's times when it is not good . when something about the test set is different enough from the training set that , the discrimination that you 're learning is not a good one . his idea was to take as the input feature vector to the , gaussian mixture system , a concatenation of the neural net outputs and the regular features .   i 'm that stephane wasn't the first to think of it , but actually stephane did it and it helped a lot .  that 's our current best system in the , in the aurora thing .  i , missed what you said .  actually , i , you should check with him , because he tried several different combinations . i , th what i don't remember is which came out best . he did one where he put o put e the whole thing into one klt , and another one , since the plp things are already orthogonalized , he left them alone and just did a klt on the on the net outputs and then concatenated that . and i don't remember which was better . no . i don't know , i don't know . you have to check with him . i 'm into big ideas these days . not to mention the fact that we 're missing snacks .    ","the other thing , just to mention that stephane this was an innovation of stephane 's , which was a pretty neat one , and might particularly apply here , given all these things we 're mentioning . stephane 's idea was that , discriminant , approaches are great . even the local ones , given , these potential outer loops which , you can convince yourself turn into the global ones . however , there 's times when it is not good . when something about the test set is different enough from the training set that , the discrimination that you 're learning is not a good one . his idea was to take as the input feature vector to the , gaussian mixture system , a concatenation of the neural net outputs and the regular features . ",
Bmr023.F,"i g given that we 're in a hurry for snacks , we should do them together . it 's it 's not it 's not gonna work out but we could just , see if we find a rhythm ,  what o 's or zeroes , we wanna agree on that ? but if we were a singing group , we would wanna decide . right ? we might wa these are excellent . why don't we do zer i anyone have a problem with saying zero ? is zero  one and a two and three . once more with feeling . no , just k just kidding . it was . ","it 's it 's not it 's not gonna work out but we could just , see if we find a rhythm , ",
Bmr023.G,"make to turn your microphone on . there 's a battery .  your channel number 's already on this blank sheet . you just if you can the gai the gain 's up at it what it usually is , but if you think it 's it 's default . but set it higher if you like .  we started recording , but she can just walk in , or since we 're starting late i figured we 'd better just start . we were gonna do a mock up question answering that was separate from the interface . do you remember ? remember asking questions and retrieving , but in a pre stored fashion . that was the thing we talked about , before the transcriber come on in . you like these . right ? good . no . that was all , previously here . i was writing the digits and then i realized i could xerox them , because i didn't want people to turn their heads from these microphones .  we all , have the same digit form , for the record .   it 's just cuz i didn't have any more digit sheets .   it actually it might be good to have them separately and have the same exact strings . we could use them for normalizing but it goes more quickly doing them in unison . i don't know . see how long we go . right . right . we 'd be like a chorus . yes . you just need to copy over to this one .  and even the good thing is that since you , have high recall , even if you have low precision cuz you 're over generating , that 's good because we could train noise models in the recognizer for these kinds of , transients and things that come from the microphones , but i know that if we run recognition unconstrained on a whole waveform , we do very poorly because we 're getting insertions in places what that you may be cutting out . we do need some pre segmentation .   and , using thilo 's , posteriors or some or right now they 're discrete , yes or no for a speaker , to consider those particular speaker background models .  there 's lots of ins interesting things that could be done .  that 's a great idea . right . great . they won't hear this since they 're going . they won't be transcribing this meeting . it 'd be great , too , if , we can we might need some help again getting the tighter boundaries or some hand to experiment with , to have a ground truth for this segmentation work , which you have some already that was really helpful , and we could probably use more .  the new ones with the tighter boundaries .   that 's great . is there actually a record of where they change ? ","we were gonna do a mock up question answering and even the good thing is that since you , have high recall , even if you have low precision cuz you 're over generating , that 's good but i know that if we run recognition unconstrained on a whole waveform , we do very poorly because we 're getting insertions in places what that you may be cutting out . we do need some pre segmentation . and , using thilo 's , posteriors or some or ","Additionally they would also like to have the question answering mock-up and transcriber interface ready for then. PLP results for the front-end look good, with the group also reporting progress in segmentation: Thilo's segmenter will now be used and ways of improving performance investigated; "
Bmr023.G,"you can compare , do a diff on the just that we knew if we keep a old copy of the old time marks just that if we run it we know whether we 're which ones were cheating and which one would be good .  that 's great . as long as we have a record , of the original automatic one , we can always find out how we would do fr from the recognition side by using those boundaries .  a completely non cheating version . also if you need someone to record this meeting , i 'm happy to for the transcribers i could do it , or chuck or adam . great . i if jane is clarifying question , then , how can they agree to it before they know her final version ? thing with the web interface it 's interesting , because you could allow the person who signs to be informed when their transcript changes , like that . and , i would say "" no "" . like , i don't wanna know , but some people might be really interested and then y in other words , they would be informed if there was some significant change other than typos and things like that . i don't happened to the small heads thing , but i j i 'm just saying that you can say that any things that are deemed anyway . i agree that at some point people probably won't care about typos but they would care about significant meaning changes and then they could be asked for their consent , if those change . cuz assumi assuming we don't really distribute things that have any significant changes from what they sign anyway . my god . but no one will listen to the hours and hours of you d that 's like  that 's a lot to ask for people that have been in a lot of meetings .  it 's one thing we 're learning is that the amount we have eight meetings there because we couldn't use the non native all non native meetings and it 's , probably below threshold on enough data for us for the things we 're looking at because the prosodic features are very noisy and you need a lot of data in order to model them . we 're starting to see some patterns and we 're hoping that with , i don't know , double or triple the data with twenty meetings or that we would start to get better results . but we did find that some of the features that , i gue jane would know about , that are expressing the distance of , boundaries from peaks in the utterance and some local , range pitch range effects , like how close people are to their floor , are showing up in these classifiers , which are also being given some word features that are cheating , cuz they 're true words . ","as long as we have a record , of the original automatic one , we can always find out how we would do fr from the recognition side by using those boundaries . because we couldn't use the non native all non native meetings and it 's , probably below threshold on enough data for us for the things we 're looking at because the prosodic features are very noisy and you need a lot of data in order to model them . we 're starting to see some patterns but we did find that some of the features that , i gue jane would know about , that are expressing the distance of , boundaries from peaks in the utterance and some local , range pitch range effects , like how close people are to their floor , are showing up in these classifiers , which are also being given some word features that are cheating , cuz they 're true words . ","The classifier segmentation is progressing well, especially in the use of prosody for identifying interruption. "
Bmr023.G,"these are based on forced alignment . word features like , word frequency and whether or not something 's a backchannel and forth . we 're starting to see , some interesting patterns . it depends what you 're looking at , a actually . right .  spurts is not cheating except that the real words , but roughly speaking , the recognized words are gonna give you a similar type of position . it 's either early or late . not exactly , but i y it should be . we don't know and actually that 's one of the things we 're interested in doing , is a     we didn't try it , but it 's right . and it depends on speaking rate speaking rate . that 's actually why i didn't use it at first . but we one of the interesting things was you reported on some te punctuation type finding sentence boundaries , finding disfluency boundaries , and then i had done some work on finding from the foreground speech whether or not someone was likely to interrupt , where if i 'm talking now and someone and andreas is about to interrupt me , is he gonna choose a certain place in my speech , either prosodically or word based . and there the prosodic features actually showed up and a neat thing even though the word features were available . and a neat thing there too is i tried some putting the speaker i gave everybody a short version of their name . the real names are in there , which we couldn't use . we should use i ds and those don't show up . that means that overall , it wasn't just modeling morgan , or it wasn't just modeling a single person ,  but was trying to , get a general idea the model the tree classifier was trying to find general locations that were applicable to different speakers , even though there are huge speaker effects .  the but the main limitation now is i because we 're only looking at things that happen every ten words or every twenty words , we need more data and more data per speaker .  it 'd also be interesting to look at the edu meetings because we did include meeting type as a feature ,  whether you were in a r meeting recorder meeting or a robustness meeting did matter to interrupts because there are just fewer interrupts in the robustness meetings . and the classifier learns more about morgan than it does about the average person , which is not bad . it 'd probably do better than but it wasn't generalizing . it 's and don , we have a long list of things he 's starting to look at now over the summer , where we can and he 'll be able to report on more things in the future . ","these are based on forced alignment . spurts is not cheating except that the real words , you reported on some te punctuation type finding sentence boundaries , finding disfluency boundaries , and then i had done some work on finding from the foreground speech whether or not someone was likely to interrupt , where if i 'm talking now and someone and andreas is about to interrupt me , is he gonna choose a certain place in my speech , either prosodically or word based . and there the prosodic features actually showed up even though the word features were available . and a neat thing there too is i tried some putting the speaker i gave everybody a short version of their name . that means that overall , it wasn't just modeling morgan , or it wasn't just modeling a single person , ",
Bmr023.G,"but it was great that we could at least go from the jane 's transcripts and the , recognizer output and get it to this point . and it 's something mari can probably use in her preliminary report like , "" we 're at the point where we 're training these classifiers and we 're just reporting very preliminary but suggestive results that some features , both word and pro prosodic , work . "" the other thing that was interesting to me is that the pitch features are better than in switchboard . and that really is from the close talking mikes , cuz the pitch processing that was done has much cleaner behavior than the switchboard telephone bandwidth . first of all , the pitch tracks are m have less , halvings and doublings than switchboard and there 's a lot less dropout , if you ask how many regions where you would normally expect some vowels to be occurring are completely devoid of pitch information , in other words the pitch tracker just didn't get a high enough probability of voicing for words for , five word there are much fewer than in switchboard . the missing we had a big missing data problem in switchboard and , the features weren't as reliable cuz they were often just not available . that 's actually good . ma the tele we had telephone bandwidth for switchboard and we had the an annoying telephone handset movement problem that may also affect it . we 're just getting better signals in this data . which is  anyway , don 's been doing a great job and we hope to continue with , andreas 's help and also some of thilo 's help on this , to try to get a non cheating version of how all this would work . deletions ? you improve one percent over a system that doesn't have any v t l in it already ?  why did that cha ?  there was a like a or some or when they recorded it ? or just ?    and also they 're not as i understand it , you don't have a way to optimize the features for the final word error . right ? these are just discriminative , but they 're not , optimized for the final right . it there 's always this question of whether you might do better with those features if there was a way to train it for the word error metric that you 're actually right . it 's indirect , you don't know exactly . exactly . that you can optimize it for the word error .  that didn't you did you do that already or ? that makes a lot of sense .  that makes sense . as you should never do worse .  we need to close up cuz i need to save the data and , get a call . right . did people wanna do the digits or , do them together ? ","the other thing that was interesting to me is that the pitch features are better than in switchboard . and that really is from the close talking mikes , cuz the pitch processing that was done has much cleaner behavior than the switchboard telephone bandwidth . first of all , the pitch tracks are m have less , halvings and doublings than switchboard and there 's a lot less dropout , if you ask how many regions where you would normally expect some vowels to be occurring are completely devoid of pitch information , in other words the pitch tracker just didn't get a high enough probability of voicing for words ma the tele we had telephone bandwidth for switchboard and we had the an annoying telephone handset movement problem that may also affect it . we 're just getting better signals in this data . to try to get a non cheating version of how all this would work . ",
Bmr023.G,"i don't know . should we just ?  are we trying to do them in synchrony ? that might be fun . adam 's not here , he 's not here to tell me no .  just whatever people would naturally do ? i don't know . be harmony .  set up and we didn't have enough digit forms xeroxed the same one seven times . no . e and th ",are we trying to do them in synchrony ? that might be fun . ,
Bmr024.A," files and directories ? and crucial part of that is the idea of not wanting to do it until right before the next level zero back up that there won't be huge number of added ,    excellent . good . i 'm you 've been what ? showing them ? sharing them .    as long as they have one number , and they know that there 's only one beep maximum that goes with that number . actually , are we having them but are we having them do digits ?    that 'd be great . that 'd be what i 'm having the transcribers here do , cuz it can be extracted later .  we 're doing i hire i 've hired two extra people already , expect to hire two more . and , i 've prepared , a set of five which i 'm calling set two , which are now being edited by my head transcriber , in terms of spelling errors and all that . she 's also checking through and mar and monitoring , the transcription of another transcriber . she 's going through and doing these kinds of checks . and , i 've moved on now to what i 'm calling set three . if i do it in sets groups of five , then have parallel processing through the current . and you indicated to me that we have a g a goal now , for the for the , the , darpa demo , of twenty hours . i 'm gonna go up to twenty hours , be that everything gets processed , and released , and that 's what my goal is . package of twenty hours right now , and then once that 's done , move on to the next .  good . i 'm hiring people who , really are they would like to do it full time , several of these people . and i don't think it 's possible , really , to do this full time , but , that what it shows is motivation to do as many hours as possible . and they 're really excellent .  got a good core group now . again .  and i i 've also d discovered with the new transcriber i 'm   lemme say that my ,   at present , the people have been doing these transcriptions a channel at a time . and , that is useful , and t and then once in a while they 'll have to refer to the other channels to clear something up .  i realize that , w i we 're using the pre segmented version , and , the pre segmented version is extremely useful , and wouldn't it be , useful also to have the visual representation of those segments ? and 've i , i 've trained the new one the new the newest one , to , use the visual from the channel that is gonna be transcribed at any given time . ","and crucial part of that is the idea of not wanting to do it until right before the next level zero back up that there won't be huge number of added , i hire i 've hired two extra people already , expect to hire two more . which are now being edited by my head transcriber , in terms of spelling errors and all that . she 's also checking through and mar and monitoring , the transcription of another transcriber . and , i 've moved on now to what i 'm calling set three . if i do it in sets groups of five , then have parallel processing through the current . and you indicated to me that we have a g a goal now , for the for the , the , darpa demo , of twenty hours . i 'm gonna go up to twenty hours , be that everything gets processed , and released , and that 's what my goal is . i realize that , w i we 're using the pre segmented version , and , the pre segmented version is extremely useful , and wouldn't it be , useful also to have the visual representation of those segments ? and 've i , i 've trained the new one the new the newest one , to , use the visual from the channel that is gonna be transcribed at any given time . ","In particular, the group discuss their preparation of materials for the transcriptions of digits by IBM, and also the human transcribers who are working towards preparing the set of 20 for the DARPA meeting. "
Bmr024.A,"and that 's just amazingly helpful . because what happens then , is you scan across the signal and once in a while you 'll find a blip that didn't show up in the pre segmentation . and that 'll be something like i it 's ver it 's interesting . once in a while it 's a backchannel . sometimes it seems to be , similar to the ones that are being picked up . and they 're rare events , but you can really go through a meeting very quickly . you just you just , yo you s you scroll from screen to screen , looking for blips . and , that we 're gonna end up with , better coverage of the backchannels , but at the same time we 're benefitting tremendously from the pre segmentation because there are huge places where there is just no activity and , the audio quality is good    think that 's gonna , also speed the efficiency of this part of the process . it it 'd be preceded by "" i 'm reading transcript and ? if they 're processing it at  that 's a good idea . this this   it 's it because i ha i have an extra point , which is the naturalness issue . because we have meetings that have a reason . that 's one of the reasons that we were talking about this . and those and this sounds like it 's more of an experimental setup . it 's got a different purpose .    would it be ?  they you saying nw archive ? and if you did that during the day it would never make it to the nightly back ups . and then there wouldn't be this extra load . but you can have it nw archive to you can have , a non backed up disk nw archived , and it 'll never show up on the nightly back ups .  sixteen to eighteen , roughly .  ","because what happens then , is you scan across the signal and once in a while you 'll find a blip that didn't show up in the pre segmentation . and , that we 're gonna end up with , better coverage of the backchannels , but at the same time we 're benefitting tremendously from the pre segmentation because we have meetings that have a reason . and those and this sounds like it 's more of an experimental setup . but you can have it nw archive to you can have , a non backed up disk nw archived , ","A number of issues regarding the management of data are addressed by the group: The inclusion of different data types in the corpus, and the storage and back-up of the group's data. "
Bmr024.B,"that said we said this before just that we met and we talked about it and we have a plan for getting things organized and right . that was it . not much @ @ we should just go ahead and get everything ready , and  i listened to probably , five or ten minutes of it from the beginning .  and and the main thing will be if we can align what they give us with what we sent them . that 's the crucial part . and we 'll be able to do that at with this new beep format .  right .  one interesting note is or problem if this was just because of how i play it back , i say , snd play and then the file , every once in a while , @ @ like a beep sounds like it 's cut into two beeps . and if that 's an , artifact of playback bu i don't think it 's probably in the original file . but ,  but with this new format , that hopefully they 're not hearing that , and if they are , it shouldn't throw them .   that 's what i it 's probably just , somehow the audio device gets hung for a second , or  right . right . th we didn't cut those out . we can ignore it when we get it back ,   brian i sent bresset sent brian a message about the meeting and i haven't heard back yet . i g hope he got it and hopefully he 's he 's gone ,  he didn't even reply to my message . i should probably ping him just to make that he got it . they can , scroll through that pretty quick ? that 's great . you 're talking about as a pre processing step . right , morgan ? is that what you 're ?  it 'll only be a problem for m for mine .  it does all the work for you .  it 'll give you a lot more data , too . won't it ? great . it 's a lot more believable , too , if you tell them that they 're the computer part is running on a windows machine . and the whole breakdown thing kinda makes sense . where does this ? there 's a couple other questions that i have too , and one of them is , what about , consent issues ? and the other one is , what about transcription ? are ?  we don't have to worry about transcribing it ? i bet that sounds good ,   if you want that .  are we only half ? we were more than that . when i was looking for space for thilo , i found one disk that had , it was nine gigs and another one had seventeen . and everything else was sorta committed .  those were non backed up . s ",and the main thing will be if we can align what they give us with what we sent them . ,
Bmr024.B,"you 're talking about backed up . i haven't looked to see how much of that we have . the file server could become an issue as we get a whole bunch more new compute machines . and we 've got , fifty machines trying to access data off of abbott at once . wear out after what amount of time ? what you what 'd be is a system that re burned the c ds every year .  what kinda tape drive ? it 's probably gonna n and we should probably make that part of the procedure for recording the meetings . no , no . he 's saying get a whole different drive . that sounds good . n i 'm successfully , increasing the error rate .   'm just playing with , the number of gaussians that we use in the recognizer , and yes , i 'm using tandem features . and that was on males . hub five . the likelihoods were lower for the plp .  was just looking through the log files , and    that 's what i was wondering . if you have one threshold that works because the range of your likelihoods is in this area  ","n i 'm successfully , increasing the error rate . 'm just playing with , the number of gaussians that we use in the recognizer , and ","Other discussion focuses on the re-evaluation of recognition without cheating on segmentation, and also how SRI recognition can be improved, especially for the female group. "
Bmr024.C,i haven't done it . alright .   ,,
Bmr024.D,"here 's the thing . why don't we s again start off with ,  i 'll get it . i 'll get the door . we want to start off with the agenda . and then , given that , liz and andreas are gonna be ten , fifteen minutes late , we can try to figure out what we can do most effectively without them here . one thing is , talk about demo , ibm transcription . what else ? what 's smartkom ? smartkom ? what are we collecting here ? right . right .  reorganization status . files and directories .  right .  let 's see . the a certainly the segmentation and recognition we wanna focus on when an andreas is here since that was particularly his thing . smartkom also , andreas . absinthe , also he has been involved in a lot of those things .    they 'll be inter i 'll be interested in all this , but , probably , if we had to pick something that we would talk on for ten minutes or while they 're coming here . or it would be , you think , reorganization status , or ?   since that was a pretty short one , we should talk about the ibm transcription status . someone can fill in liz and andreas later .   le let 's talk about it , because that 's something that i know andreas is less interested in than liz is ,  it 's good actually , one relate more related thing in transcription . that 's the ibm we 've got that sorted out . how 're we doing on the rest of it ?    twenty hours . but the other thing is that , that 's kinda twenty hours asap because the longer before the demo we actually have the twenty hours , the more time it 'll be for people to actually do things with it .     that 's good . the the difference if , if the ibm works out , the difference in the job would be that they p primarily would be checking through things that were already done by someone else ? is that most of what it ? correcting .        let 's talk about the digits , since they 're not here yet . forced alignment would be one thing . what about just actually doing recognition ? no , they make mistakes . right .  i 'm not quite what i 'm talking about .  we 're talking about digits now . and there 's a bunch of that hasn't been marked yet .  and , there 's the issue that they we was said , but do we ? because people make mistakes and i was just asking , just out of curiosity , if with , the sri recognizer getting one percent word error , would we do better ? ","but , probably , if we had to pick something that we would talk on for ten minutes or while they 're coming here . or it would be , you think , reorganization status , since that was a pretty short one , we should talk about the ibm transcription status . but the other thing is that , that 's kinda twenty hours asap because the longer before the demo we actually have the twenty hours , the more time it 'll be for people to actually do things with it . the the difference if , if the ibm works out , the difference in the job would be that they p primarily would be checking through things that were already done by someone else ? forced alignment would be one thing . what about just actually doing recognition ? i was just asking , just out of curiosity , if with , the sri recognizer getting one percent word error , would we do better ? ","Progress has been made in naming conventions, with file reorganisation to be done at a later date, however this was not discussed fully due to Chuck's absence. In particular, the group discuss their preparation of materials for the transcriptions of digits by IBM, and also the human transcribers who are working towards preparing the set of 20 for the DARPA meeting. "
Bmr024.D,"if you do a forced alignment but the force but the transcription you have is wrong because they actually made mistakes , or false starts , it 's much less c it 's much less common than one percent ? we should be able to . right ?  that 's just my question . i 'm not saying it should be one way or the other , but it 's if  it 's y you raised a point , euphemistically but , m it is a serious problem . ho what will they do when they go hear "" beep seven three five two "" you think they 'll we 'll get ?     that 's if they are going to transcribe these things , certainly any process that we 'd have to correct them , or whatever is needs to be much less elaborate for digits than for other why not ?  that was it ?  we wanna have them . i i in berkeley , you have to go a little early , right ? at twenty alright . le let 's make we do the ones that , saved you . there was some in adam 's agenda list , he had something from you about segmentation this last recognition ?  another one that we had on adam 's agenda that definitely involved you was s something about smartkom ? minute . wanted to understand it , cuz i 'm hadn't quite followed this process . it 's wizard in the sen usual sense that the person who is asking the questions doesn't know that it 's , a machi not a machine ?   you might wanna try collecting it the other way around sometime , saying that th the computer isn't up yet and then then you can separate it out whether it 's the beginning or end effects . but ,  s  what is the purpose of this recording ? this is to get acoustic and language model training data for smartkom  why not ? we 've never signed anything that said that we couldn't use anything that we did .  no that 's not a problem . i l look , it seems to me that if we 're doing it anyway and we 're doing it for these purposes that we have , and we have these distant mikes , we definitely should re should save it all as long as we 've got disk space , and disk is pretty cheap . should we save it ? now th  we save it because it 's potentially useful . and now , what do we do with it is a s separate question . anybody who 's training something up could choose to put it to u include this or not . i would not say it was part of the meetings corpus . it isn't . but it 's some other data we have , and if somebody doing experiment wants to train up including that then they can . right ? ","if you do a forced alignment but the force but the transcription you have is wrong because they actually made mistakes , or false starts , it 's much less c it 's much less common than one percent ? i 'm not saying it should be one way or the other , but it 's if i would not say it was part of the meetings corpus . ",
Bmr024.D,"it 's th think the idea of two or more people conversing with one another is key . nnn , no , it doesn't . right ? it has  it is a s   it 's scenario based , it 's human computer interface it 's really pretty different . but i have no problem with somebody folding it in for some experiment they 're gonna do , but i don't it doesn't match anything that we 've described about meetings . whereas everything that we talked about them doing at uw and forth really does . they 're actually talking you can you can again , as andreas was saying , if you wanna use the same tools and the same conventions , there 's no problem with that . it 's just that it 's , different directory , it 's called something different , it 's  it is different . you can't just fold it in as if it 's digits are different , too . right ? i don i wouldn't call reading digits "" meetings "" . right ? we were doing  i don't care what directory tree you have it under . right ? that 's just a  o you can use whatever procedure you want that 's p convenient for you . all i 'm saying is that there 's no way that we 're gonna tell people that reading digits is meetings . and similarly we 're not gonna tell them that someone talking to a computer to get travel information is meetings . those aren't meetings . but if it makes it easier for you to pu fold them in the same procedures and have them under the same directory tree , knock yourself out .  alright .  good point . good point . but i 'm no one would have a problem with our folding it in for some acoustic modeling or some things .  do we h do we have , american born folk , reading german , pla place names and forth ? is that ? great .   right . heidelberg i be pretty good .  anytime we need a disk , we can get it at the rate that we 're you really shouldn't be saying da we had allowed dave to listen to these , recordings .  i me and there 's been this conversation going on about getting another file server , and we can do that . we 'll take the opportunity and get another big raft of disk , soon . year or two ?  all the l ldc all the ldc distributions are on cd rom . we have all sorts of cd roms from a long time ago .  i see .  would think the b th the at least the once tha that you put it on , it would kill that .  wh the o the one that we have ? the no , we have s we don't we have our own ? ","it 's th think the idea of two or more people conversing with one another is key . it 's scenario based , it 's human computer interface it 's really pretty different . it 's just that it 's , different directory , it 's called something different , it 's i don i wouldn't call reading digits "" meetings "" . i don't care what directory tree you have it under . ","The inclusion of different data types in the corpus, and the storage and back-up of the group's data. A number of issues regarding the management of data are addressed by the group: "
Bmr024.D,"something wi th that doesn't that isn't used by the back up gang ? don't we have something downstairs ? just in ?  that 's what i was gonna say , is that a disk is cheap it 's es essentially , close to free . and the only thing that costs is the back up issue , to first order . and we can take care of that by putting it on non back up drives and just backing it up once onto this tape .   good . it 's good . he i dave has promoted this in the past . don't think he 's actually against it .      another , thing on the agenda said sri recognition experiments ? what 's that ?  who 's that ? i got confused by the results . it sai because the meeting before , you said "" we got it down to where they 're within a tenth of a percent "" .  it 's the women are the problem .     no . aha !  but you see , now , between the males and the females , there 's certainly a much bigger difference in the scaling range , than there is , say , just within the males . and what you were using before was scaling factors that were just from the m the sri front end . and that worked fine . but now you 're looking over a larger range and it may not be fine .       no . i remember that . you 're this is lemme ask a q more basic que is this , iterative , baum welch training ? or is it viterbi training ? or ? baum welch training . and how do you determine when to stop iterating ? or you 're doing one too many . it 's there can be .  it d if you remember some years ago bill byrne did a thing where he was looking at that , and he showed that you could get it .  but but ,  and in each case , ho i 'm in each case how do you determine , the usual fudge factors ? the , the , language , scaling , acoustic scaling ,   and the pru the question he was asking at one point about pruning ,  remember that one ? he was he 's it looked like the probabil at one point he was looking at the probabilities he was getting out at the likelihoods he was getting out of plp versus mel cepstrum , and they looked pretty different , as i recall . and there 's the question but , still it 's a question if you have some threshold somewhere in terms of beam search or ? but , you 're only talking about a percent or two . right ? here we 're we 're saying that we there gee , there 's this b there 's this difference here . and it ","but you see , now , between the males and the females , there 's certainly a much bigger difference in the scaling range , than there is , say , just within the males . or you 're doing one too many . he was he 's it looked like the probabil at one point he was looking at the probabilities he was getting out at the likelihoods he was getting out of plp versus mel cepstrum , and they looked pretty different , but , you 're only talking about a percent or two . ",
Bmr024.D,"see cuz , i there could be lots of things . right ? but but , let 's suppose just for a second that , we 've taken out a lot of the major differences , between the two . we 're already using the mel scale and we 're using the same style filter integration , and , we 're making that low and high before we i th with straight plp , it 's trapezoidal also . but then we had a slight difference in the scale .  coup couple tenths of a percent right .  right . the oth the other thing that f i we 've always viewed it , anyway , as the major difference between the two , is actually in the smoothing , that the that the , plp , and the reason plp has been advantageous in , slightly noisy situations is because , plp does the smoothing at the end by an auto regressive model , and mel cepstrum does it by just computing the lower cepstral coefficients .   could be .   now the other que related question , though , is , what 's the boot models for these things ?  right . mis for making things better .  but , this for making things worse . this it migh th the thought is possible another possible partial is if the boot models used a comple used a different feature set , that which you got from a different feature set . those features look at the data differently , actually . they will find boundaries a little differently , though all th all that thing is actually slightly different . i 'd expect it to be a minor effect , but    right . right . not . but it i st still see it as there 's a history to this , too , but i i don't wanna go into , but i th it could be the things that it the data is being viewed in a certain way , that a beginning is here rather than there and forth , because the actual signal processing you 're doing is slightly different . but , it 's that 's probably not it .  at some point you also might wanna take the same thing and try it on , some broadcast news data else that actually has some noisy components , we can see if any conclusions we come to holds across different data .   is there something quick about absinthe that you ? we 'll just go buy them , probably just throw away the old ones , and for the box , and i 'll just go buy their process .   is liz coming back , do or ?   you don't .  alright . alright . see you .  alright .  they 're having tea out there . guess the other thing that we were gonna talk about is , demo . and , these are the demos for the july , meeting and , darpa mee ","we 've always viewed it , anyway , as the major difference between the two , is actually in the smoothing , that the that the , plp , and the reason plp has been advantageous in , slightly noisy situations is because , plp does the smoothing at the end by an auto regressive model , is there something quick about absinthe that you ? guess the other thing that we were gonna talk about is , demo . and , these are the demos for the july , meeting and , darpa mee ","Other discussion focuses on the re-evaluation of recognition without cheating on segmentation, and also how SRI recognition can be improved, especially for the female group. Finally, Absinthe is now up and running with improved performance. Discussion of demos for the July DARPA meeting were left to the individuals concerned. "
Bmr024.D,"it 's july fifteenth . is that it ? sixteenth , eighteenth .  we talked about getting something together for that , but we 'll just put that off for now , given that but we should have a sub meeting , probably , adam and , chuck and me should talk about should get together and talk about that sometime soon . something like that . we 'll involve dan ellis at some level as  the tea is going , i suggest we do , a unison .  gets our  that 'll be interesting .   no . we 're done . ","but we 'll just put that off for now , given that but we should have a sub meeting , probably , adam and , chuck and me should talk about should get together and talk about that sometime soon . ",Discussion of demos for the July DARPA meeting were left to the individuals concerned. 
Bmr024.E,"the data . the data which we are collecting here . data ? the smartkom data ?  and also the smartkom thing should b and we have done that on the automatic segmentations .   into two pieces .   i recognize that , too .    some latency     they are not transcribed yet .      ch  and how do we find the transcripts for those that ?  the references for those segments ? it 's not that   you give some time constraints for the references and for the hypothesis , and      i 'm just in progress of doing that .    it 's s eight meetings which i 'm using , and , it 's before it was twenty minutes of one meeting . should be a little bit better .  but   we 'll see that . there were the false alarms .      i 'll can make an can make a c comparison of the old system to the new one , and then     actually , it 's changed to a synthesis for the first part now .   it 's a human operator .  yes .  no . projector we were not saying we are not doing it . we wer we just wanted to do   the english system ?  b  but i 'm not about the legal aspect of that . is there some contract with smartkom about the data ? what they or , is that our data which we are collecting here , or ?     th that was the question . if ?     it it  transcription is done in munich .     you can do that if you want . non back up .    just before .  ",and we have done that on the automatic segmentations . the references for those segments ? ,
Bmr024.F,"we 're on . and , somewhere is my agenda . the most important thing is morgan wanted to talk about , the arpa demo .   ibm transcription status , we wanna talk about if w if we wanna add the data to the mar meeting recorder corpus . why don't we have that on the agenda and we 'll get to it and talk about it ? reorganization status .   absinthe , which is the multiprocessor unix linux . it was andreas wanted to talk about segmentation and recognition , and update on sri recognition experiments . and then if ti if there 's time i wanted to talk about digits , but it looked like we were pretty full , can till next week . at least ,  he 'll t he 'll probably be interested . but .  chuck was the one who added out the agenda item . i don't really have anything to say other than that we still haven't done it .  right . although dave said that if we wanna do it , just tell him and he 'll do a d level zero then .   we do need to talk a little bit about we don't need to do it during this meeting . we have a little more to discuss . but , we 're ready to do it . and , i have some web pages on ts more of the background . naming conventions and things like that , that i 've been trying to keep actually up to date .  and i 've been sharing them with u d uw folks also . sharing them with the uw folks .  we , we did another version of the beeps , where we separated each beeps with a spoken digit . chuck came up here and recorded some di himself speaking some digits , and it just goes "" beep one beep "" and then the phrase , and then "" beep two beep "" and then the phrase . and that seems pretty good . they 'll have a b easier time keeping track of where they are in the file . and we did it with the automatic segmentation , and i don't think we ne we didn't look at it in detail . we just sent it to ibm . we sorta spot checked it . really ?  i sorta spot checked here and there and it sounded pretty good . it 'll work . and , we 'll just hafta see what we get back from them .  right .  it 's also they are much less likely to d have errors . the problem wi last time is that there were errors in the transcripts where they put beeps where there weren't any , or and they put in extraneous beeps . and with the numbers there , it 's much less likely . ha . that 's interesting . i didn't hear that . we better listen to it again , make ","chuck was the one who added out the agenda item . i don't really have anything to say other than that we still haven't done it . naming conventions and things like that , that i 've been trying to keep actually up to date . and i 've been sharing them with u d uw folks also . we , we did another version of the beeps , where we separated each beeps with a spoken digit . chuck came up here and recorded some di himself speaking some digits , they 'll have a b easier time keeping track of where they are in the file . we just sent it to ibm . ","Progress has been made in naming conventions, with file reorganisation to be done at a later date, however this was not discussed fully due to Chuck's absence. In particular, the group discuss their preparation of materials for the transcriptions of digits by IBM, and also the human transcribers who are working towards preparing the set of 20 for the DARPA meeting. "
Bmr024.F,"but , certainly the software shouldn't do that ,  hiccups .  the only part that might be confusing is when chuck is reading digits . "" seven four eight beep seven beep eight three two "" . yes . because , we don't we didn't in order to cut them out we 'd have to listen to it . and we wanted to avoid doing that , we they are transcribing the digits . although we could tell them , if you hear someone reading a digits string just say "" bracket digit bracket "" and don't bother actually computing the di writing down the digits .  and then i wanted to talk about but as i said i we may not have time what we should do about digits . we have a whole pile of digits that haven't been transcribed .  do we have anything else to say about transcription ? about ibm  alright . we have a whole bunch of digits , if we wanna move on to digits .  it 'll keep your accuracy up .  and correcting . correcting . we 'll expect that they 'll have to move some time bins and do some corrections . right . i see what a backchannel , or  we have a whole bunch of digits that we 've read and we have the forms and on , but only a small number of that ha not a small number only a subset of that has been transcribed . and we need to decide what we wanna do . and , liz and andreas actually they 're not here , but , they did say at one point that they thought they could do a pretty good job of just doing a forced alignment . and , again , i don't think we 'll be able to do with that alone , because , sometimes people correct themselves and things like that . but i was just wondering what people thought about how automated can we make the process of finding where the people read the digits , doing a forced alignment , and doing the timing . we they read , because we have the forms . right . but , that we wanna get a set of clean digits . one option i but that 's pretty uncommon . if we could really get one percent on guess if we segmented it , we could get one percent on digits . but , there 're a couple different of doing it . we could use the tools i 've already developed and transcribe it . hire some people , or use the transcribers to do it . we could let ibm transcribe it . they 're doing it anyway , and unless we tell them different , they 're gonna transcribe it . or we could try some automated methods . and my tendency right now is , if ibm comes back with this meeting and the transcript is good , just let them do it . ","i was just wondering what people thought about how automated can we make the process of finding where the people read the digits , doing a forced alignment , and doing the timing . guess if we segmented it , we could get one percent on digits . hire some people , or use the transcribers to do it . we could let ibm transcribe it . or we could try some automated methods . and my tendency right now is , if ibm comes back with this meeting and the transcript is good , just let them do it . ",
Bmr024.F,"it 's pretty distinct . the beeps are pre recorded . yes . it 'll be it will be in the midst of a digit string .  it there might be a place where it 's "" beep seven beep eight beep "" . but , they 're gonna macros for inserting the beep marks . and i don't think it 'll be a problem . we 'll have to see , but i don't think it 's gonna be a problem . right . that was it . just , what do we do with digits ? we have many of them , and it 'd be to actually do something with them . anything else ? your mike is a little low there .  i could hand ones . right . rob porzel porzel ? and the , porzel and the , smartkom group are collecting some dialogues . they have one person sitting in here , looking at a picture , and a wizard sitting in another room somewhere . and , they 're doing a travel task . and , it involves starting i believe starting with a it 's always the wizard , but it starts where the wizard is pretending to be a computer and it goes through a , speech generation system . synthesis system . and then , it goes to a real wizard and they 're evaluating that . and they wanted to use this equipment , and the w question came up , is here 's some more data . should this be part of the corpus or not ? and my attitude was yes , because there might be people who are using this corpus for acoustics , as opposed to just for language . or also for dialogue of various sorts . it 's not a meeting . right ? because it 's two people and they 're not face to face . at the beginning . but they don't know that it 's the same person both times .  "" i have to go now . you can talk to the computer . "" "" no ! "" abort abort , retry , fail ? this was the question . they were saying they were not going to , and i said , "" that 's silly , if we 're gonna try to do it for a corpus , there might be people who are interested in acoustics . "" i see no reason not to do all of them . that if we have someone who is doing acoustic studies , it 's to have the same for every recording . right . for their usage , they don't need anything . right ? and then right . it 's it it the begs the question of what is the meeting corpus . if , at uw they start recording two person hallway conversations is that part of the meeting corpus ? this has two or more people conversing with each other . ","and the , porzel and the , smartkom group are collecting some dialogues . they have one person sitting in here , looking at a picture , and a wizard sitting in another room somewhere . and , they 're doing a travel task . but it starts where the wizard is pretending to be a computer and it goes through a , speech generation system . should this be part of the corpus or not ? and my attitude was yes , because there might be people who are using this corpus for acoustics , as opposed to just for language . but they don't know that it 's the same person both times . and i said , "" that 's silly , if we 're gonna try to do it for a corpus , there might be people who are interested in acoustics . "" it 's it it the begs the question of what is the meeting corpus . this has two or more people conversing with each other . ","A number of issues regarding the management of data are addressed by the group: The inclusion of different data types in the corpus, and the storage and back-up of the group's data. "
Bmr024.F,"they 're just not face to face . that was my intention . that was my intention . part of the reason that i wanted to bring this up is , do we wanna handle it as a special case or do we wanna fold it in , we give everyone who 's involved as their own user id , give it session i ds , let all the tools that handle meeting recorder handle it , or do we wanna special case it ? and if we were gonna special case it , who 's gonna do that ? i don't see why not . it 's just a different topic .   what does that mean for how we are gonna organize things ? but those are folded in , and it 's just you just mark the transcripts differently . one option is you fold it in , and just simply in the file you mark somewhere that this is this type of interaction , rather than another type of interaction . but , i put it under the same directory tree . it 's in "" user doctor speech data mr "" . other .  my preference is to have a single procedure that i don't have to think too much about things . and , just have a marking . if we do it any other way that means that we need a separate procedure , and someone has to do that . right . w we will hafta worry about format .   i didn't realize that . that 's a  they even have a reading list . it 's pretty funny .  disk might eventually be an issue we might need to , get some more disk pretty soon . we 're about half halfway through our disk right now . we 're probably a little more than that because we 're using up some space that we shouldn't be on . once everything gets converted over to the disks we 're supposed to be using we 'll be probably , seventy five percent .  were those backed up or non backed up ? right . that 's different . i 'm much more concerned about the backed up . the non backed up ,  i is cheap . if we need to we can buy a disk , hang it off a s workstation . if it 's not backed up the sysadmins don't care too much .  but that 's that 's risky .   that 's right . beep that out .  it 's really the back up issue rather than the file server issue .  my understanding is , the issue isn't really the file server . we could always put more disks on . it 's the back up system .  which is near saturation ,  we 're alright for now because the network 's slow .  that was me . i was the one who said it was not reliable . the they wear out .  the th   no . ","we give everyone who 's involved as their own user id , give it session i ds , let all the tools that handle meeting recorder handle it , or do we wanna special case it ? and just simply in the file you mark somewhere that this is this type of interaction , rather than another type of interaction . but , i put it under the same directory tree . we 're about half halfway through our disk right now . once everything gets converted over to the disks we 're supposed to be using we 'll be probably , seventy five percent . i 'm much more concerned about the backed up . ","A number of issues regarding the management of data are addressed by the group: The inclusion of different data types in the corpus, and the storage and back-up of the group's data. "
Bmr024.F,"read and write don't hurt them too much unless you scratch them . but the r the write once , and the read writes , don't last . you don't wa you don't wanna put ir un reproduceable data on them . year or two .  i don't know many people who do it on cd . they 're the most fo they 're on cd , but they 're not tha that 's not the only source . they have them on disk . and they burn new ones every once in a while . but if you go k  th the pressed ones last for not forever , they 've been finding even those degrade . but , the burned ones when i say two or three years what i 'm saying is that i have had disks which are gone in a year . on the average , it 'll probably be three or four years . but , you don't want to per p have your only copy on a media that fails . and they do . if you have them professionally pressed , y they 're good for decades . th  we can already put them on tape . and the tape is hi is very reliable . the only issue is then if we need access to them . that 's fine f if we don't need access to them .  you 're just saying put them on c ds for normal access .  you can do that but that 's pretty annoying , because the c ds are slow . the c ds are an op the cd is an alternative to tape . icsi already has a perfectly good tape system and it 's more reliable . for archiving , we 'll just use tape . regardless first of all there was , a problem with the archive in that i was every once in a while doing a chmod on all the directories an or recursive chmod and chown , because they weren't getting set correctly every once in a while , and i was just , doing a minus r star , not realizing that caused it to be re backed up . but normally you 're correct . but even without that , the back up system is becoming saturated . but we still have enough changed that the nightly back ups are starting to take too long . it has nothing to do with the meeting . it 's just the general icsi back up system is becoming saturated . why don't you have this have a this conversation with dave johnson tha rather than with me ? actually , we could do that just with the tape with the current tape . but it 's an automatic robot it 's very convenient . you just run a program to restore them .   but no , but andreas 's point is a good one . and we don't have to do anything ourselves to do that . ","when i say two or three years what i 'm saying is that i have had disks which are gone in a year . but , you don't want to per p have your only copy on a media that fails . icsi already has a perfectly good tape system and it 's more reliable . for archiving , we 'll just use tape . but even without that , the back up system is becoming saturated . ",
Bmr024.F,"they 're already right now on tape . right . your point is , and it 's a good one , that we could just get more disk and put it there .  that 's not a bad idea . once it 's on tape that 's a good idea .  i 'll talk to dave , and see what th how what the best way of doing that is . there 's a little utility that will manually burn a tape for you , and that 's probably the right way to do it .  we 're g we 're gonna automate that . my intention is to do a script that 'll do everything . no . it 's all tape robot , you just sit down at your computer and you type a command .  but y but you would be anyway . right ? because but there 's no reason to do that . it we already have it there and it 's no , we won't . he 'll say "" if that means that it 's not gonna be backed up standardly , great . ""  it 's definitely no problem . it 's just it 's just a utility which queues up . it just queues it up and when it 's available , it will copy it . and then you can tell it to then remove it from the disk or you can , do it a few days later or whatever you wanna do , after you confirm that it 's really backed up . nw ? nw archive . that 's what it is . right . right . right . and then it never right . which i 'm would make ever the sysadmins very happy . that 's a good idea . that 's what we should do . that means we 'll probably wanna convert all those files filesystems to non backed up media .  that wasn't me . that 's good . you are ?  that was a quick response . no . it 's , swi hub five .   it 's much worse .  that 's what too . what 's are the freq ?  you can try each one on a cross validation set , can't you ? do you ? what ? and what 's the top frequency of each ?  exp one 's triangular , one 's trapezoidal .     it 's not just losing some frequency range .  just what we were talking about before , which is that i ported a blass library to absinthe , and then got it working with fast forward , and got a speedup roughly proportional to the number of processors times the clock cycle . that 's pretty good . i 'm in the process of doing it for quicknet , but there 's something going wrong and it 's about half the speed that i was estimating it should be , and i 'm not why . but i 'll keep working on it . ","you can try each one on a cross validation set , and got a speedup roughly proportional to the number of processors times the clock cycle . ","Finally, Absinthe is now up and running with improved performance. "
Bmr024.F,"but the what it means is that it 's likely that for net training and forward passes , we 'll absinthe will be a good machine . especially if we get a few more processors and upgrade the processors . there 're five now . it can hold eight . and it 's also five fifty megahertz and you can get a gigahertz .  i don't think we 'd have to do all  we 'd have to get a almost certainly have to get a , netfinity server . they 're pretty specialized . july what ? early july ? late july ? over a cappuccino tomorrow ?  a unison digits ? which is gonna be a little hard for a couple people because we have different digits forms . we have a i found a couple of old ones . have you done digits before ?  the idea is just to read each line with a short pause between lines , not between and , since we 're in a hurry , we were just gonna read everyone all at once . if you sorta plug your ears and read first read the transcript number , and then start reading the digits .  one , two , three . and ","but the what it means is that it 's likely that for net training and forward passes , we 'll absinthe will be a good machine . especially if we get a few more processors and upgrade the processors . ","Finally, Absinthe is now up and running with improved performance. "
Bmr024.G,"  the start of your speech and the end of it , or like that .  actually , i had a question about that . if you find that you can lower the false alarms that you get where there 's no speech , that would be useful for us to know .   r right now you get f fal false , speech regions when it 's just like , breath like that , and i 'd be interested to know the wha if you retrain  do those actually go down or not ? because of just to see if by doing nothing in the modeling of just having that training data wh what happens . did they actually save the far field data ? cuz at first they weren't sa   or  right . nnn .  we can have him vary the microphones , too , or they 're different s speakers . what if we just give it a name like we give these meetings a name ? and then later on some people will consider it a meeting and some people won't , and just give it a title . can we just have a directory called other ? and or , and just , store it there .   like but we have like thirty from ten years ago ? no .  ten years ago . ninety one , and they 're still all fine . both . i 've burned them and they 're still usually they 're that 's what i see  h everytime it was a "" gonna "" "" gonna die "" . just before they be before it goes bad , it burns them in .  but who 's gonna do these back ups ? the people that collect it ? s  that 's what i 'm wondering , if  you don't have to physically put a tape in the drive ? or s ? s ? it 's just  but not at the same time . what about if the times overlap with the normal back up time ?   lift the herve approach . let 's just say that men are simple . i 'm rehearsed . is there less training data ? we don this is on just digits ?   this is on  what 's the standard ? thought the performance was actually a little better on females than males . right . i 'm just wondering if that if you have any indication of your standard features , if that 's also different or in the same direction or not . cuz  ",,
Bmr024.H,"st  that 's better . were they burned or were they pressed ?  you just archive it on the tape , and then put it on cd as        ",,
Bmr024.I,"there 're more than ten ? stay till about , three forty .    this is just partly to inform everybody , and to get , input . we had a discussion don and liz and i had discussion last week about how to proceed with , with don 's work , and and , one of the obvious things that occur to us was that we 're since we now have thilo 's segmenter and it works , amazingly we should actually re evaluate the recognition , results using without cheating on the segmentations . and , that should be fairly  there 's actually why do you ask ? no , actually , nist has , a fairly sophisticated scoring program that you can give a , time , you just give two time marked sequences of words , and it computes the the , the th it does all the work for you . it we just and we use that actually in hub five to do the scoring . what we 've been using far was simplified version of the scoring . and we can handle the type of problem we have here . we ha  right . right . do right . it does time constrained word alignment .  that should be possible . that shouldn't be a problem . that was the one thing , and the other was that ,  what was the other problem ?  that thilo wanted to use the recognizer alignments to train up his , speech detector . that we could use , there wouldn't be much hand labelling needed to , to generate training data for the speech detector . and you 're in the process of doing that . you can you can  right . that won't be perfect the alignments aren't perfect , but , it 's probably still better to have all this extra data , than   porzel . porzel . right . actually , w the we do this who came up with it , but it 's a really clever idea . we simulate a computer breakdown halfway through the session , and then after that , the person 's told that they 're now talking to a , to a human . we collect both human computer and human data , essentially , in the same session . that 's an idea .  o just reboot it .   no , the question is do we save one or two far field channels or all of them ?   it 's to be traini to b training data and development data for the smartkom system .  right . right .  we weren't supposed to collect any data . this was all    right .  it makes sense to handle it with the same infrastructure , since we don't want to duplicate things unnecessarily . but as far as distributing it , we shouldn't label it as part of this meeting corpus . we should let it be its own corp it might also be potentially confusing . right . ","and and , one of the obvious things that occur to us was that we 're since we now have thilo 's segmenter and it works , amazingly we should actually re evaluate the recognition , results using without cheating on the segmentations . no , actually , nist has , a fairly sophisticated scoring program that you can give a , time , you just give two time marked sequences of words , and it computes the the , the th it we just and we use that actually in hub five to do the scoring . what we 've been using far was simplified version of the scoring . it does time constrained word alignment . that thilo wanted to use the recognizer alignments to train up his , speech detector . that we could use , there wouldn't be much hand labelling needed to , to generate training data for the speech detector . we simulate a computer breakdown halfway through the session , and then after that , the person 's told that they 're now talking to a , to a human . it makes sense to handle it with the same infrastructure , since we don't want to duplicate things unnecessarily . but as far as distributing it , we shouldn't label it as part of this meeting corpus . ",
Bmr024.I,"i th yes . that 's a that 's another argument to keep it separate , because it 's gonna follow the smartkom transcription conventions and not the icsi meeting transcription conventions . exactly .    exactly do you wanna be a subject ? we  that was one of our concerns . you can i shouldn't be saying this , but , you can just since the back ups are every night , you can recycle the backed up diskspace . i didn't say that . i didn't say that . right .  there 's an argument for having you could use our old file server for disks that have data that is very rarely accessed , and then have a fast new file server for data that is , heavily accessed .   it 's the back it 's the back up capaci  we 've raised this before and someone said this is not a reliable way to do it , but the what about putting the on cd rom or dvd   but they wear out just from sitting on the shelf ? or from being read and read ?   but if that then you would think you 'd hear much more clamoring about data loss and but , we have right .  how about ? how about putting them on that plus , like on a on dat or some other medium that isn't risky ?   right . if you if they last say , they actually last five years , in the typical case , and occasionally you might need to recreate one , and then you get your tape out , but otherwise you don't . can't you just you just put them on ?  right . right .  it 's like dynamic ra dram . one thing i don't understand is , if you have the data if you if the meeting data is put on disk exactly once , then it 's backed up once and the back up system should never have to bother with it , more than once .   but this back up system is smart enough to figure out that something hasn't changed and doesn't need to be backed up again .  then , if then , let 's right .  right . what if we buy , what do they call these , high density ? no , no . because this is something that we can do without involving dave , and , putting more burden on him . how about we buy , one of these high density tape drives ? and we put the data actually on non backed up disks . and we do our own back up once and for all , and then and we don't have to bother this @ @ up ? what the these tapes  at some point these  what tape drive is it ? is it is ? right . but it might interfere with their back up schedule ,  right .  on an xh x whatever partition .  right . right .  ","what about putting the on cd rom or dvd how about putting them on that plus , like on a on dat or some other medium that isn't risky ? but this back up system is smart enough to figure out that something hasn't changed and doesn't need to be backed up again . ",
Bmr024.I,"right .  but then you 're effectively using the resources of the back up system . or is that a different tape robot ? no , no . see just give a dedi i 'm saying is @ @ i if you go to dave , and ask him "" can i use your tape robot ? "" , he will say , "" that 's gonna screw up our back up operation . ""  alright . alright . good . it if he you have to put the data on a non backed up disk to begin with . that otherwise you don't you right . right . right .   sri recognition ?   we have lots of them .  chuck , do you have any updates ?  you have to sa you have to tell people that you 're doing you 're trying the tandem features . a and i 'm still tinkering with the plp features . right . that was before i tried it on the females . see , women are nothi are , trouble . right ? as we all know .  when had i ha we had reached the point where we had reached the point where , on the male portion of the development set , the , or one of the development sets , i should say the , the male error rate with , icsi plp features was identical with , sri features . which are mfcc . then "" great . i 'll j i 'll just let 's make everything works on the females . "" and the error rate there was a three percent difference .   no , actually there 's more training data . no , no . this is hub five .  and the test data is callhome and switchboard . then and plus the vocal tract length normalization didn't actually made things worse . something 's really wrong .    that 's true .     d the one thing that i then tried was to put in the low pass filter , which we have in the most hub five systems actually band limit the at about , thirty seven hundred , hertz . although , normally , the channel goes to four thousand . right ?  and that actually helped , a little bit . and it didn't hurt on the males either .  and i 'm now , trying the and suddenly , also the v the vocal tract length normalization only in the test se on the test data . you can do vocal tract length normalization on the test data only or on both the training and the test . and you expect it to help a little bit if you do it only on the test , and s more if you do it on both training and test . and the it now helps , if you do it only on the test , ","you have to sa you have to tell people that you 're doing you 're trying the tandem features . a and i 'm still tinkering with the plp features . that was before i tried it on the females . we had reached the point where , on the male portion of the development set , the , or one of the development sets , i should say the , the male error rate with , icsi plp features was identical with , sri features . and the test data is callhome and switchboard . and plus the vocal tract length normalization didn't actually made things worse . something 's really wrong . d the one thing that i then tried was to put in the low pass filter , which we have in the most hub five systems actually band limit the at about , thirty seven hundred , hertz . although , normally , the channel goes to four thousand . and it didn't hurt on the males either . and suddenly , also the v the vocal tract length normalization only in the test se on the test data . ",
Bmr024.I,"and i 'm currently retraining another set of models where it 's both in the training and the test , and then we 'll have , hopefully , even better results .  but there 's it looks like there will still be some difference , between one and two percent , for the females . and i 'm open to suggestions . and it is true that the , that the we are using the but it can't be just the vtl , because if you don't do vtl in both systems , the females are considerably worse in the with the plp features . there must be some something else going on . that ye overall , yes , but on this particular development test set , they 're actually a little worse . but that 's beside the point . we 're looking at the discrepancy between the sri system and the sri system when trained with icsi features .  it 's baum welch training .  actually , we just do a s a fixed number of iterations . in this case four . which we used to do only three , and then we found out we can squeeze and it was we 're s we 're keeping it on the safe side . but you 're d right . it might be that one more iteration would help , but it 's  no , but with baum welch , there shouldn't be an over fitting issue , really .    we can that 's the easy one to check , because we save all the intermediate models and we can 'm actually re optimizing them . although that hasn't shown to make a big difference . pruning ? pruning in the ? i did you see this in the sri system ? the likelihoods are you can't directly compare them , because , for every set of models you compute a new normalization . and these log probabilities , they aren't directly comparable because you have a different normalization constants for each model you train .  w   we prune very conservatively . as we saw with the meeting data , we could probably tighten the pruning without really we we have a very open beam . right . course .  right . actually , there is the difference in that . for the plp features we use the triangular filter shapes . and for the in the sri front end we use the trapezoidal one . now it 's the same . it 's thirty to seven hundred and sixty hertz . no , no . but  but since currently the feacalc program doesn't allow me to change the filter shape independently of the scale . and , i did the experiment on the sri front end where i tried the y where the standard used to be to use trapezoidal filters . you can actually continuously vary it between the two . and wen i swi i tried the trap triangular ones . ","between one and two percent , for the females . we 're looking at the discrepancy between the sri system and the sri system when trained with icsi features . no , but with baum welch , there shouldn't be an over fitting issue , really . for the plp features we use the triangular filter shapes . and for the in the sri front end we use the trapezoidal one . ",
Bmr024.I,"and it did slightly worse , but it 's really a small difference .  exactly . it 's not i don't think the filter shape by itself will make a huge difference .     one thing i haven't done yet is to actually do all of this with a much larger with our full training set . right now , we 're using a i don't know , forty ? i it 's it 's a f training set that 's about , by a factor of four smaller than what we use when we train the full system . some of these smoothing issues are over fitting for that matter . and the baum welch should be much less of a factor , if you go full whole hog . and w just the strategy is to first treat things with fast turn around on a smaller training set and then , when you 've narrowed it down , you try it on a larger training set . and we haven't done that yet . th the boot models are trained from scratch . we compute ,  we start with a , alil alignment that we computed with the b the best system we have . and then we train from scratch . we com we do a , w we collect the the observations from those alignments under each of the feature sets that we train . and then , from there we do ,  there 's a lot of , actually the way it works , you first train a phonetically tied mixture model .  you do a total of first you do a context independent ptm model . then you switch to a context you do two iterations of that . then you do two iterations of context dependent phonetically tied mixtures . and then from that you do the you go to a state clustered model , and you do four iterations of that . there 's a lot of iterations overall between your original boot models and the final models . i don't think that  we have never seen big differences . once now i have these much better models . i 'll re generate my initial alignments . then i 'll get much better models at the end . "" made no difference whatsoever . it 's it 's i the boot models are recur   but there are no boot models , you 're not booting from initial models . you 're booting from initial alignments . that 's correct . but but but , what i 'm saying is we e w f w for a long time we had used boot alignments that had been trained with a with the same front end but with acoustic models that were fifteen percent worse than what we use now . and with a dict different dictionary with a considerably different dictionary , which was much less detailed and much less suited . and then we switched to new boot alignments , ",,
Bmr024.I,"which now had the benefit of all these improvements that we 've made over two years in the system . and , the result in the end was no different . what i 'm saying is , the exact nature of these boot alignments is probably not a big factor in the quality of the final models .    right . right .  anyway , i should really reserve , any conclusions until we 've done it on the large training set , and until we 've seen the results with the vtl in training .   right . and , with this , i have to leave . with this said .     a few more processors ? how many are you shooting for ?   can you mix t processors of different speed ?   we can stick them in another system .  i see .  ",,
Bmr025.A,"do that quickly . hired several more transcribers , they 're making great progress . seve several , several . and and 've been finishing up the double checking . i hoped to have had that done by today but it 's gonna take one more week . certainly . mean , it 's in the same place it 's been . no change . yes .    these are separate from the ones that these are excellent . good . excellent . hm ask a question ? as it stands within the channeltrans interface , it 's possible to do a find and a play . you can find a searched string and play . are you you 're adding like i don't know , are they fuzzy matches or are they  it 's a lot more sophisticated than the the windows based  hm good . at some point we 're gonna have to say what that private joke is , that keeps coming up .  it 's amazing . can i ask one more thing about thisl ? with the ir then you end up with a somewhat prioritized excellent . excellent .    bu isn't it always on the digits ? isn't it always on the digits forms ? it would be if these had little light indicators , little l e ds for a buzzer .  actually  i do have it 's a different topic . can i add one top topic ? we have time ? i wanted to ask , i know that that thilo you were , bringing the channeltrans interface onto the windows machine ? and i wanted to know is th it 's all done ? that 's g wonderful . great . does and that does that mean , i should know this but i don't . does this mean that the that this could be por ported to a think pad note or some other type of wonderful . wonderful . we used them once .  couple times .  and i have my feeling on it is that in principle it 's a really idea , and you have the time tags which makes it better tha than just taking ra raw notes . on the other hand , i the down side for me was that the pen is really noisy . you have ka kaplunk , kaplunk . and i don't know if it 's audible on the but that was a disadvantage . i do take notes , i could be taking notes on these things and the plus with the crosspads would be the time markings but i don't know . could did it one time but u but the other thing i 'm thinking is if we wanted that thing i wonder if we 'd lose that much by having someone be a scribe by listening to the tape , to the recording afterwards and taking notes in some other interface . it 's la it 's useful , have a summary and high points .   ","hired several more transcribers , they 're making great progress . 've been finishing up the double checking . i know that that thilo you were , bringing the channeltrans interface onto the windows machine ? and i have my feeling on it is that in principle it 's a really idea , and you have the time tags which makes it better tha than just taking ra raw notes . on the other hand , i the down side for me was that the pen is really noisy . ","Transcription is progressing well, with new people hired, and double checking almost complete. Finally, other progress made includes getting the ChannelTrans interface working, ordering more wireless microphones, and analysing recognition runs. "
Bmr025.A,"when i d  w there is an alternative . there is an alternative , it 's still , there 's your point stands about there be needing to be an infrastructure , but it doesn't have to be synchronized with the little clock 's timer on it . you c i when i did it i synchronized it by voice , by whispering "" one , two , three , four "" onto the microphone and it 's transcribed . it 's in the transcript .  it 's in the transcript . i like this pda idea .    and then  and not just for you . but it 's also , it has this problem of having to go from an analog to a d a digital record too , doesn't it ?  but say , if i if you 're writing notes in it does it can't do handwriting recognition , right ?  what i 'm thinking is that the pda solution you h you have it already without needing to go from the pixelization to a  nicely put .   ",,
Bmr025.B," if we can't , we can't . but we 're gonna try to make this an abbreviated meeting cuz the next occupants were pushing for it ,    agenda is according to this , is transcription status , darpa demos xml tools , disks , backups , et cetera and  should we just go in order ? transcription status ? who 's that 's probably you . seven ?  wh darpa demos , we had the submeeting the other day . and then does it play something back or that 's something you 're having to program ?          that was a really good look . it 's too bad that couldn't come into the  and then again , not .  that soun that sounds reasonable . it loo it my recollection of it is it 's a pretty reasonable demo format .       how about having it run under free bsd ?  but it would what would serve both purposes , is if you contact him and ask him if he 's already done it . if he has then you learn , if he hasn't then he 'll do it .  tony robinson ?  steve renal steve renals . no .    assuming we 're the thing i was asking about with , free bsd is that it might be easier to get powerpoint shows running in free bsd than to get this other package running in   right .  there was that demo , which was one of the main ones , then we talked about some other which would be showing off the transcriber interface itself and as you say , we could even merge those in some sense , but and part of that was showing off what the speech non nonspeech that thilo has done s looks like .  think at the very least we 're gonna want something illustrative with that cuz i 'm gonna want to talk about it and if there 's something that shows it graphically it 's much better than me just having a bullet point pointing at something i don't know much about ,  s when we here were having this demo meeting , what we 're coming up with is that we wanna have all these pieces together , to first order , by the end of the month and then that 'll give us a week or ju june . june . that 'll give us that 'll give us a week or to to port things over to my laptop and make that works ,    this is to an audience of researchers mean , to let s the goal is to let them it is we 're doing . that 's  good . done with that . xml tools ? seat ? not the quality or anything . no . i see .    that 's more seat information than we wanted .    some of these are missing . aren't they ? some fall out of  small shocks administered to the   ","darpa demos , at the very least we 're gonna want something illustrative with that and if there 's something that shows it graphically it 's much better than me just having a bullet point s when we here were having this demo meeting , what we 're coming up with is that we wanna have all these pieces together , to first order , by the end of the month that 'll give us that 'll give us a week or to to port things over to my laptop and make that works , ",The most pressing issue concerns the demos which the group are preparing for the DARPA meeting next month. 
Bmr025.B,"guess it is true that even with something that 's backed up it 's not gonna if it 's stationary it 's not going to go through the increment it 's not gonna burden things in the incremental backups . the monthly full will be a bear but really ? guess the idea is that we would be reserving the non backed up space for things that took less than twenty four hours to recreate like that , right ?     we can get more disk .   was allowing someone else to come up with something related that they had  good . crosspads ? crosspads ? we 've never used them . once ? i but it 's it 's a regular pad , just a regular pad of paper but there 's this pen which indicates position . and you have time and position stored that you can you have a record of whatever it is you 've written . and one of the reasons that it was brought up originally was because we were interested in higher level things , not just the , microphone but also summarization and forth and the question is if you were going to go to some gold standard of what wa what was it that happened in the meeting where would it come from ? and think that was one of the things , right ? and the it seemed like a neat idea . we 'll have a have a scribe , have somebody take good notes and then that 's part of the record of the meeting . and then we did it once or twice and we probably chose the wrong scribe but it was it 's  summary . what makes one is we should actually schedule some periods where people go over something later and put some summary some there 'd be some scribe who would actually listen , w who 'd to actually listen to the whole thing , not transcribe it , but just write down things that struck them as important . but then you don't have the time reference that you 'd have if you had it live .  one thing that we might try is on some set of meetings , some collection of meetings , edu is the right one or something else , we get somebody to buy into the idea of doing this as part of the task .  part of the reason part of the reason that adam was interested in the speechcorder idea from the beginning is he said from the beginning he hated taking notes and and forth and jane is more into it but don't know if you wanna really do this all the time think to get someone to actually buy into it and have at least some series of meetings where we do it .  and if it 's probably worth having one . the p the problem with the more extended view , all these other with quibbling about particular applications of it ","if it 's stationary it 's not going to go through the increment it 's not gonna burden things in the incremental backups . guess the idea is that we would be reserving the non backed up space for things that took less than twenty four hours to recreate like that , good . crosspads ? that you can you have a record of whatever it is you 've written . and one of the reasons that it was brought up originally was because we were interested in higher level things , not just the , microphone but also summarization and forth we get somebody to buy into the idea of doing this as part of the task . part of the reason part of the reason that adam was interested in the speechcorder idea from the beginning is he said from the beginning he hated taking notes ","Additionally, the group have progressed further with data storage issues, with backing-up their data now regarded as a priority, and more disk space required. The collection of CrossPad note-taking data will be pursued in future meetings. "
Bmr025.B,"is that it looks like it 's hard to get people to routinely use it , it just hasn't happened anyway . but if we can get a person to i do like the idea of having a couple buttons where like one button was "" and then another button was "" that 's great "" and another button "" that 's f "" right . no , but it 's just storing the pixel informa position information , it 's all digital . right . you don't have to   we have no but by i would suggest you return one . because we we haven't used it we have some aspirations of using them and  jeremy could sit in some meetings and press a button when there when somebody laughed .    dear .   what he means but isn't that funny sounding ? "" we ordered more wireless . "" it 's like wires are the things you 're wiring you 're you we 're we ordered more absence of the thing . anyway .  there 's all this going on between andreas and dave and chuck and others with various kinds of runs recognition runs , trying to figure things out about the features but it 's all in process , there 's not much to say right now . why don't we start with our esteemed guest . see all you have to do is go away to move way up in the we could .  let 's do one of those simultaneous ones . that sounds good . everybody ready ? a one .  a one and a two and a three . babble , take five . ","but by i would suggest you return one . because we we haven't used it there 's all this going on between andreas and dave and chuck and others with various kinds of runs recognition runs , trying to figure things out about the features but it 's all in process , ","Finally, other progress made includes getting the ChannelTrans interface working, ordering more wireless microphones, and analysing recognition runs. "
Bmr025.C, 'm starting to and  we can probably find some examples of different type of prosodic events going on . ooo . the end of  'll be here .  ooo . u  will that also include like batteries dying ? just a any time the mike 's putting out zeros   speaking of which .  ,we can probably find some examples of different type of prosodic events going on . ,
Bmr025.D,"i g i also got anot a short remark to the transcription . i 've just processed the first five edu meetings and they are chunked up they would they probably can be sent to ibm whenever they want them . it 's already at ibm , but the other ones        n edit key .   but y  it 's it it 's done ,   it it was just a problem with the snack version and the transcriber version but it 's solved .  did install it on my laptop and it worked . what is a crosspad ?      you don't have to . ","i 've just processed the first five edu meetings and they are chunked up they would they probably can be sent to ibm whenever they want them . it 's already at ibm , it 's it it 's done , ","Finally, other progress made includes getting the ChannelTrans interface working, ordering more wireless microphones, and analysing recognition runs. "
Bmr025.E," what you need all you need to do is say to dan "" gee it would be if this worked under autoconf "" and it 'll be done in a day . right ? right . i wouldn't be surprised . what i james christie . steve renals is not softsound , is he ? steve wro i it 's ste steve renals wrote thisl ir .  right . here 's a crazy idea actually . why don't you try and merge transcriber and thisl ir ? they 're both tcl interfaces . right . and then you get they then you get the windows media playing for free . right . but that the transcriber uses snack and then you can but you can use a lot of the same functionality and it 's  my thought was is that it would be to have the running transcripts from speaker to speaker . right ? do you have , a speaker mark here and a speaker mark here ? right . that my thought was if you had like multitrans or whatever do it . or whatever .  exactly .  you guys were gonna burn c ds ?   i see .  alright . why right . if you wanted to do that the right architecture for it is to get a pda with a wireless card . and that way you can synchronize very easily with the meeting because you 'll be synchroni you can synchronize with the linux server and if you 're not worried about you have a pda and may and you could have the same interface or whatever , you 'd have to do a little little bit of coding to do it . but you could imagine , if all you really wanted was you didn't want this secondary note taking channel but just being able to use m markers of some sort , a pda with a l a wireless card would be the probably the right way to go . even buttons you could do ,  as you said . right . the transfer function is less errorful , yes .  alright . this is yes , this is number two for me today .   alright . ",if you wanted to do that the right architecture for it is to get a pda with a wireless card . and that way you can synchronize very easily with the meeting ,The collection of CrossPad note-taking data will be pursued in future meetings. 
Bmr025.F,"the second one of those is already at ibm . that 's the one that we 're waiting to hear from them on .  as soon as they 're the ibm set .  and as soon as we hear from brian that this one is and we get the transcript back and we find out that hopefully there are no problems matching up the transcript with what we gave them , then we 'll be ready to go and we 'll just send them the next four as a big batch , and let them work on that . yes , exactly . we 're doing things in parallel , that way we can get as much done a at once .  what what does that look like ? the string that you type in . what are you are they keywords , or are they ?  i see . i see . what does the user see as the result of the query ? thisl .   if you typed in "" small heads "" you could get back a something that would let you click and listen to some audio where that phrase had occurred or some that sounds good . that sounds really neat . but you were saying that the that there 's that set of tools , cygnus tools , that   and you have to have all the o how does it play ? i hope he never listens to these meetings . tony robinson ? what about issues of playing sound files @ @ between the two platforms ? there 's another one . start and end of each ? utterance . just marks ?  right . right . minute , how w where is it in the key file ? never i never knew we were supposed to put it in the key file . really ?  you mentioned it ,  text .  i didn't do that either . takes me no time to edit these . i 'm not doing anything . but with the screensaver kicking in , it them ? there 's more than one ? we 're transcribing it anyways , why do we need notes ? summarize it from the transcription . doodle . how do you synchronize the time in the crosspad and the time of the recording ? ","the second one of those that 's the one that we 're waiting to hear from them on . and as soon as we hear from brian that this one is and we get the transcript back and we find out that hopefully there are no problems matching up the transcript with what we gave them , then we 'll be ready to go and we 'll just send them the next four as a big batch , we 're doing things in parallel , i never knew we were supposed to put it in the key file . ",Work is also going on in parallel with IBM. 
Bmr025.G," guess who i practice on ? another idea i w t had just now actually for the demo was whether it might be of interest to sh to show some of the prosody work that don 's been doing . actually show some of the features and then show task like finding sentence boundaries or finding turn boundaries .  you can show that graphically , what the features are doing . it , it doesn't work great but it 's definitely giving us something . i don't know if that would be of interest or not .  you 're looking at this now are you looking at waves or matlab ? def i the end of this month or next month ? like today ?  next month .   where if d if don can talk to whoever 's cuz we 're doing this anyway as part of our the research , visualizing what these features are doing and either it might not be integrated but it could potentially be in it . could find some . it 's different . i don't think anyone has done this on meeting data it might be neat , quick question on that . is do we have the seat information ? in the key files now ? in for the new one  great . sea alright .  alright . never mind . i 'm just trying to figure out , when morgan 's voice appears on someone 's microphone are they next to him or are they across from him ? cuz haven't been putting it in and in by right . i have not . and it they 're on th right , these , but hadn't ever been putting it in the key files . and i don't think chuck was either cuz we 're both     if right . just realized i hadn't been doing it and probably  right . i know i usually delete the i don't , forgot to d but it 's almost  and i was looking at chuck 's what did chuck do , 'll do that "" .   we will do better .     there 's also there 's this use that the what if you 're sitting there and you just wanna make an x and you don't wanna take notes and you 're you just wanna get the summary of the transcript from this time location like and then while you 're bored you don't do anything and once in a while , there 's a joke and you put a x and but in other words you can use that just to highlight times in a very simple way . also with i was thinking and i know morgan disagrees with me on this but suppose you have a group in here and you wanna let them note whenever they think there might be something later that they might not wanna distribute in terms of content , they could just make an x near that point ","another idea i w t had just now actually for the demo was whether it might be of interest to sh to show some of the prosody work that don 's been doing . and then show task like finding sentence boundaries or finding turn boundaries . you can show that graphically , what the features are doing . it , it doesn't work great but it 's definitely giving us something . i don't know if that would be of interest or not . next month . quick question on that . is do we have the seat information ? but hadn't ever been putting it in the key files . what if you 're sitting there and you just wanna make an x and you don't wanna take notes ","Here they discuss the querying and indexing tool which is progressing well albeit with a few front-end issues, and also the transcriber tool. "
Bmr025.G,"or a question mark that alerts them that when they get the transcript back they c could get some red flags in that transcript region and they can then look at it .  i know we haven't been using it but i w imagine it being useful just for marking time periods which you then get back in a transcript  right . and you don't have a lot of other cues that might be useful ,  could we keep one of these things for another year ? would h is there a big cau just in case we even some of the transcribers who might be wanting to annotate just there 's a bunch of things that might be neat to do but i it might not be the case that we can actually synchronize them and then do all the infrastructure but we could at least try it out . right . don't think it has to be part of a what everybody does in a meeting but it might be a useful , neat part of the project that we can , show off as a mechanism for synchronizing events in time that happen that you just wanna make a note of , like what jane was talking about with some later browsing , just as a convenience , even if it 's not a full blown note taking substitute . what input would you be ? you 'd just be pressing like a   that be good . m right . that would be fine too . i don't have , grandiose ideas in mind but i 'm just thinking we 've we 're getting into the next year now and we have a lot of these things worked out at in terms of the speech somebody will be interested in this and  or like this is my "" i 'm supposed to do this "" button , like "" i better remember to ""  something like that or  w  it also it 's realistic cuz people are supposed to be bringing their p d as to the meeting eventually , right ? that 's why we have this little i don't don't wanna more work for anyone but imagine some interesting things that you could do with it and if we don't have to return it and we can keep it for a year i don't know .  we c one would probably be fine . we could do like a student project , someone who wants to do this as their main like s project for something would be i 'm that 's not a bad jeremy 's gonna be an he 's a new student starting on modeling brea breath and laughter , actually , which sounds funny but it should be   "" ha ha . "" you 're gonna tease me ?  great . that 's a very philosophical statement from morgan . it 's anachronism , it 's like it 's great . we could do simultaneous . initiate him . ","one would probably be fine . we could do like a student project , someone who wants to do this as their main like s project for something would be ",The collection of CrossPad note-taking data will be pursued in future meetings. 
Bmr025.G,"i 'm just thinking , are you gonna try to save the data before this next group comes in ? we might wanna do it simultaneous . right , we might n we might need to do that actually . you have to plug your ears , eric , or or you start laughing . ",we might wanna do it simultaneous . ,
Bmr025.H,"does anyone have anything to add to the agenda ?  as a somewhat segue into the next topic , could i get a hold of the data even if it 's not really corrected yet just can get the data formats and make the information retrieval is working ? can you just it is .  just "" transcripts "" is the sub directory ?  'll probably just make some copies of those rather than use the ones that are there . and then just we 'll have to remember to delete them once the corrections are made . it 's this one . is my mike on ?  and we 're doing those as disjoint from the ones we 're transcribing here ? good . that 's the right way to do it , especially for the information retrieval anything else on transcription status ?  right , which 've been working on using the thisl tools to do information retrieval on meeting data and the thisl tools are there 're two sets , there 's a back end and a front end , the front end is the user interface and the back end is the indexing tool and the querying tool . and 've written some tools to convert everything into the right for file formats . and the command line version of the indexing and the querying is now working . at least on the one meeting that i had the transcript for conveniently you can now do information retrieval on it , do type in a string and get back a list of start end times for the meeting , of hits . keywords . right ? and and then it munges it to pass it to the thisl ir which uses an sgml like format for everything . right now , i have a tool that will do that on a command line using our standard tools , but my intention is to do a prettier user interface based either that 's the other thing i wanted to discuss , is what should we do for the user interface ? we have two tools that have already been written . the softsound guys did a web based one , which i haven't used , haven't looked at . dan says it 's pretty good but it does mean you need to be running a web server . and it 's pretty big and complex . and it would be difficult to port to windows because it means porting the web server to windows . the other option is dan did the tcl tk thisl gui front end for broadcast news which looks great . that 's a demo . and that would be much easier to port to windows . and think that 's the way we should go .  it 's a standard , text retrieval based it 's term frequency , inverse document frequency scoring . and then there are all sorts of metrics for spacing ","as a somewhat segue into the next topic , could i get a hold of the data even if it 's not really corrected yet just can get the data formats and make the information retrieval is working ? especially for the information retrieval 've been working on using the thisl tools to do information retrieval on meeting data and the thisl tools are there 're two sets , there 's a back end and a front end , the front end is the user interface and the back end is the indexing tool and the querying tool . and 've written some tools to convert everything into the right for file formats . and the command line version of the indexing and the querying is now working . at least on the one meeting that i had the transcript for conveniently you can now do information retrieval on it , do type in a string and get back a list of start end times for the meeting , but my intention is to do a prettier user interface based either but it does mean you need to be running a web server . and it 's pretty big and complex . and it would be difficult to port to windows the other option is dan did the tcl tk thisl gui front end for broadcast news ","Work is also going on in parallel with IBM. Here they discuss the querying and indexing tool which is progressing well albeit with a few front-end issues, and also the transcriber tool. "
Bmr025.H,"how far apart they have to be and things like that . it 's i it 's like doing a google query or anyth anything else like that . it uses it pr produces an index ahead of time you don't you 're not doing a linear search through all the documents . cuz you can imagine if with if we have the sixty hours ' worth you do wouldn't wanna do a search . you have to do preindexing and that these tools do all that . and the work to get the front end to work would be porting it to get it to work on the unix systems , our side is just rewriting them and modifying them to work for meetings . that it understands that they 're different speakers and that it 's one big audio file instead of a bunch of little ones and just sorta things like that . on which tool ? the thisl gui tool which is the one that dan wrote , tcl tk you type in a query and then you get back a list of hits and you can type on them and listen to them . click on them rather with a mouse . right , you 'd get something you 'd get to listen to "" beep "" . you couldn't get a video . right . and think there 'd be minimal effort to get it to work , minimally and then we 'd wanna add things like query by speaker and by meeting and all that dave gelbart expressed some interest in working on that 'll work with him on it . and it 's looking pretty good , the fact that i got the query system working . if we wanna just do a video based one that 'll be easy . if we wanna get it to windows it 's gonna be a little more work because the thisl ir , the information retrieval tool 's i had difficulty just compiling them on solaris . getting them to compile on windows might be challenging .  it certainly helps . without those i wouldn't even attempt it . but what those they what those do is provide bsd compatibility layer , that the normal unix function calls all work .  but the problem is that the thisl tools didn't use anything like autoconf and you have the normal porting problems of different header files and th some things are defined and some things aren't and different compiler work arounds and on . the fact that it took me a day to get it c to compile under solaris means it 's probably gonna take me s significantly more than that to get it to compile under windows . free bsd would probably be easier . that 's true . actually should check because he did port it to sprachcore he might have done that already . i 'll check at that right . right . that 's right . ",,
Bmr025.H,"and i 've been corresponding with dan and also with softsound guy , blanking on his name . do tony ? do . or s or steve renals . which one do my brain is not working , i don't remember who i 've been corresponding with . then it 's steve renals . just getting documentation and and f and formats , that 's all going pretty we 'll be with that .  we have that 's a good point too . i don't know . this is one of the reasons this is the one of the reasons that i 'm gonna have dave gelbart having him volunteer to work on it is a really good thing because he 's worked on the transcriber and he 's more familiar with tcl tk than i am . that 's snack , not transcriber . thisl gui probably uses snack . and my intention was just to base it on that . and if it doesn't right , we 'll have to figure out a user interface for that ,  it might be fairly difficult to get that to work in the little short segments we 'd be talking about and having the search tools and on . we can look into it , but we have to i have to sit down and try it before i make too many judgments ,   my experience with the gnu compatibility library is really it 's just as hard and just as easy to port to any system . right ? the windows system isn't any harder because it looks like a bsd system . it 's just , just like all of them , the "" include "" files are a little different and the function calls are a little different . it might be a little easier but it 's not gonna be a lot easier .   ranked . this month . next month . today isn't june first , is it .  've been doing a bunch of xml tools where you we 're moving to xml as the general format for everything and that 's definitely the right way to go because there are a lot of tools that let you do extraction and reformatting of xml tools .  yet again we should probably meet to talk about transcription formats in xml because i 'm not particularly happy with what we have now . it works with transcriber but it 's a pain to use it in other tools because it doesn't mark start and end .  utterance . it 's implicit in there but you have to do a lot of processing to get it . and and also i 'd like to do the indirect time line business . but regardless , w that 's something that you , me , and jane can talk about later . but i 've installed xml tools of various sorts in various languages and if people are interested in doing extracting any information from any of these files , ",'ve been doing a bunch of xml tools because there are a lot of tools that let you do extraction and reformatting of xml tools . yet again we should probably meet to talk about transcription formats in xml ,Tools for accessing key file information have been developed which should ensure all meeting information is present. 
Bmr025.H,"either information on users because the user database is that way i 'm converting the key files to xml that you can extract m various inf sorted information on individual meetings and then also the transcripts . and just let me know there it 's mostly java and perl but we can get other languages too if that 's desirable . the seat information is on the key files for the ones which it 's been recorded ,  where you 're sitting . right . "" it 's pretty soft and squishy . "" but that might just be me .  we should bleep that out . right . the square bracket . you haven't been putting it in .  we can go back and fill them in for the ones we have . i had told you guys about it but this is why i wanna use a g a tool to do it rather than the plain text because with the plain text it 's very easy to skip those things .  if you use the edit key , or key edit it 's edit key , command did i show you guys that ? i did show it to you , but you both said "" no , you 'll just use text file "" . it has it in there , a place to fill it in . and if you don't fill it in , you 're not gonna get it in the meetings .   and then the other thing also that thilo noticed is , on the microphone , on channel zero it says hand held mike or crown mike , you actually have to say which one .  that 's cuz you kn i know why . and then also in a couple of places instead of filling the participants under "" participants "" they were filled in under "" description "" . and that 's also a problem . anyway . that 's it . also i 'm working on another version of this tool , the one that shows up here , that will flash yellow if the mike isn't connected . and it 's not quite ready to go yet because it 's hard to tell whether the mike 's connected or not because the best quality ones , the crown ones , are about the same level if they 're off and no one 's o off or if they 're on and no one 's talking . these ones , they are much easier , there 's a bigger difference . 'm working on that and it sorta works and eventually we will change to that and then you 'll be able to see graphically if your mike is dropping in or out .    now 'll turn off the screensaver too . the other thing is as i 've said before , it is actually on the thing . there 's a little level meter but no one ever pays attention to it . ","i 'm converting the key files to xml that you can extract m various inf sorted information on individual meetings the seat information is on the key files for the ones which this is why i wanna use a g a tool to do it rather than the plain text because with the plain text it 's very easy to skip those things . and then the other thing also that thilo noticed is , on the microphone , on channel zero it says hand held mike or crown mike , you actually have to say which one . and then also in a couple of places instead of filling the participants under "" participants "" they were filled in under "" description "" . the one that shows up here , that will flash yellow if the mike isn't connected . ",Tools for accessing key file information have been developed which should ensure all meeting information is present. 
Bmr025.H,"think having it on the screen is more easy to notice . buzzer . "" bamp , bamp ! "" disk backup , et cetera ? spoke with dave johnson about putting all the meeting recorder on non backed up disk to save the overhead of backup and he said "" you could do that if you want "" but he thought it was a bad idea . what he said is doing the manual one , doing nw archive to copy it is a good idea and we should do that and have it backed up . he w he 's a firm believer in lots of different modalities of backup . his point was taken . this data cannot be recovered . and if a mistake is made and we lose the backup we should have the archive and if then a mistake is made and we lose the archive we should have the backup . just the monthly full . but he said that we sh shouldn't worry too much about that , that we 're getting a new backup system and we 're far enough away from saturation on full backups that it 's w probably and the only issue here is the timing between getting more disks and recording meetings . things that are recreatable easily and also things that are recreatable . the expanded files and things like that . they take up a lot more room anyway . but we do need more disk .  and agree with him . his point was taken that if we lose one of these we cannot get it back . i don't think there was any other et cetera there . unfortunately we could burn c ds but first of all it 's a pain . because you have to copy it down to the pc and then burn it and that 's a multi step procedure . and second of all the write once burners as opposed to a professional press don't last . think burning them for distribution is fine but burning them for backup is not a good idea . cuz th they fail after a couple years . yes , since tcl tk runs on it , things 'll just work . got an email from james landay who said "" if you 're not using them , could you return them ? "" he said he doesn't need them , he just periodically w at the end of each term sends out email to everyone who was recorded as having them and asks them if they 're still using them . we used them a couple times , but we have two .  my opinion on it is , first , i never take notes anyway 'm not gonna use it , and second , it 's another level of infrastructure that we have to deal with . and then you can download it and they have ocr and searching and all sorts of things . ","spoke with dave johnson about putting all the meeting recorder on non backed up disk to save the overhead of backup but he thought it was a bad idea . what he said is doing the manual one , doing nw archive to copy it is a good idea and we should do that and have it backed up . he w he 's a firm believer in lots of different modalities of backup . this data cannot be recovered . and if then a mistake is made and we lose the archive we should have the backup . just the monthly full . and we 're far enough away from saturation on full backups that it 's w probably and the only issue here is the timing between getting more disks and recording meetings . things that are recreatable easily and also things that are recreatable . who said "" if you 're not using them , could you return them ? "" we used them a couple times , ","Additionally, the group have progressed further with data storage issues, with backing-up their data now regarded as a priority, and more disk space required. The collection of CrossPad note-taking data will be pursued in future meetings. "
Bmr025.H,"if you take notes it 's a great little device . but i don't take notes ,   and then just died out . that 's right .  because that 's summary . right . that was one of the issues we talked about originally and that 's w part of the difficulty is that we need an infrastructure for using the time the crosspads and that means synchronizing the time you want it pretty close and there 's a fair amount of skew because it 's a hand held unit with a battery and you you have to synchronize at the beginning of each meeting all the pads that are being used , that it 's synchronized with the time on that and then you have to download to an application , and then you have to figure out what the data formats are and convert it over if you wanna do anything with this information . and there 's a lot of infrastructure which unless someone  but then there 's the infrastructure at the other end which someone has to listen to that and find that point , and then mark it .  we can keep all both of them for the whole year . it 's just  buttons . for what you 've been describing buttons would be even more convenient than anything else , right ? you have the 'm there would action item . the crosspad idea is a good one . it 's just a question of getting people to use it and getting the infrastructure set up in such a way that it 's not a lot of extra work . that 's part of the reason why it hasn't happened is that it 's been a lot of extra work for me and it 's digital but it 's in a format that is not particularly standard . we don't we certainly don't have to return it , as i said . all he said is that if you 're not using it could you return it , if you are using it feel free to keep it . that we haven't used it and are we going to ?   if we had them out and sitting on the table people might use them a little more although there is a little sounds breathy to me . breath and lau "" ha ha "" . "" ha ha . ""  that reminded me of something .  too late . it slipped out .  equipment . ordered 'm always gonna do that . w we ordered more wireless , and they should be coming in at some point . and then at the same time i 'll probably rewire the room as per jane 's suggestion that the first n channels are wireless , are the m the close talking and the next n are far field . wired less , wired more . should we do digits ? do we have anything else ? just the transcript number and then the ","if you take notes it 's a great little device . that it 's synchronized with the time on that and then you have to download to an application , and then you have to figure out what the data formats are and convert it over if you wanna do anything with this information . for what you 've been describing buttons would be even more convenient than anything else , if we had them out and sitting on the table people might use them a little more w we ordered more wireless , and then at the same time i 'll probably rewire the room as per jane 's suggestion that the first n channels are wireless , are the m the close talking and the next n are far field . ","The collection of CrossPad note-taking data will be pursued in future meetings. Finally, other progress made includes getting the ChannelTrans interface working, ordering more wireless microphones, and analysing recognition runs. "
Bmr025.H,"should we do simultaneous ?   you hav sorta have to .  have to , i don't know about other people . ",you hav sorta have to . ,
Bmr026.A,"we 're on . this is gonna be a pretty short meeting because i have four agenda items , three of them were requested by jane who is not gonna be at the meeting today . the first was transcription status . does anyone besides jane the transcription status is ? ugh ! c can i have a pen ?  no , no . we haven't done that process . they ' r they 're doing the full transcription process . right . sounds familiar . make it 's right . can you mail that out to the list ?  i haven't done that . i have lots of to add that 's just in my own directory . i 'll try to get to that .  jane also wanted to talk about participant approval , but i don't really think there 's much to talk about . i 'm just gonna do it . and if anyone objects too much then they can do it instead . i 'm gonna send out to the participants , with links to web pages which contain the transcripts and allow them to suggest edits . and then bleep them out . for the ones that we have .  nope , they 'll have access to the audio also . that 's my intention . because the transcripts might not be right . you want people to be able to listen to them . that 's a good point . that 's a good point . it 's probably going to have to be the uncompressed versions because , it takes too long to do random access decompression . that was the other point . that 's another agenda item .  but that is a good point we 'll get to that , too . darpa demo status , not much to say . the back end is working out fine . it 's more or less ready to go . i 've added some that indes indexes by the meeting type mr , edu , et cetera and also by the user id . that the front end can then do filtering based on that as the back end is going more slowly as i s said before just cuz i 'm not much of a tcl tk programmer . and dave gelbart says he 's a little too busy . think don and i are gonna work on that and you and just talk about it off line more . but the back end was pretty smooth . think , we 'll have something . it may not be as pretty as we might like , but we 'll have something .  he actually he volunteered but then he s then he retracted it .     for a demo ? sounds good . it might just be slides . transcriber is tcl tk , very generic with snack , anything you can get snack to run on , it will work . thought it was packaged with transcriber ?   patch . ugh ! ","this is gonna be a pretty short meeting because i have four agenda items , three of them were requested by jane who is not gonna be at the meeting today . they ' r they 're doing the full transcription process . jane also wanted to talk about participant approval , but i don't really think there 's much to talk about . i 'm gonna send out to the participants , with links to web pages which contain the transcripts and allow them to suggest edits . nope , they 'll have access to the audio also . because the transcripts might not be right . it 's probably going to have to be the uncompressed versions because , it takes too long to do random access decompression . darpa demo status , not much to say . the back end is working out fine . i 've added some that indes indexes by the meeting type mr , edu , et cetera and also by the user id . that the front end can then do filtering based on that as the back end is going more slowly as i s said before just cuz i 'm not much of a tcl tk programmer . transcriber is tcl tk , very generic with snack , ","This is a relatively short meeting of the Meeting Recorder group, with only a few agenda items. Transcription was discussed briefly because Jane was not present, however this appears to be progressing well in parallel with IBM. Web pages have been set up to show transcription status and to allow participants to approve transcripts. DARPA demos are progressing well with the back-end indexed to allow front-end filtering, and a potential demo ideas investigated which would use X Waves. "
Bmr026.A,"we have it 's just hasn't made it into the release yet . it 'd be easy enough to add that . again it 's it 's more tcl t someone who 's familiar with tcl tk has to do it , but it wouldn't be hard to do .  but it seems to me that i c it doesn't seem like having that real time is that necessary . yo it seems to me you could do images . jus it just seems to me jus but i don't you can do all that just statically in just record the audio clip and show an image and that 's and the last i item on the agenda is disk issues yet again . we 're doing on backed up . we 're only about thirty percent on the second disk . we have a little bit of time before that becomes critical , but we are like ninety five percent , ninety eight percent on the scratch disks for the expanded meetings . and , my original intention was like we would just delete them as we needed more space , but unfortunately we 're in the position where we have to deal with all the meeting data all at once , in a lot of different ways . there 're a lot of transcribers , all of those need to be expanded , and then people are doing chunking and i want to do the permission forms , want those to be live , there 's a lot of data that has to be around . and jane was gonna talk to , dave johnson about it . one of the things i was thinking is we just got these hundred alright , excuse me ten , sparc blade sun blades . they came in but they 're not set up yet . and it seems to me we could hang scratch disk on those because they 'll be in the machine room , they 'll be on the fast connection to the rest of the machines . and if we just need un backed up space , we could just hang disks off them . because there 's no more room in the disk racks on abbott . but the sun blades have spare drive bays . just put them in .   cuz the sun these sun blades take commodity hard drives . you can just go out and buy a pc hard drive and stick it in . there are lots of long term solutions . what i 'm looking for is where do we s expand the next meeting ? i didn't know he had left already .  you we need about a gig per meeting . alright ! what 's your computer 's name ? it and you have an x drives installed ?  and you 're o you 're offering ?  which one was that , x g ? x g ?  but that won't be getting any bigger , will it ? ","just record the audio clip and show an image and that 's and the last i item on the agenda is disk issues yet again . we 're only about thirty percent on the second disk . we have a little bit of time before that becomes critical , but we are like ninety five percent , ninety eight percent on the scratch disks for the expanded meetings . and , my original intention was like we would just delete them as we needed more space , but unfortunately we 're in the position where we have to deal with all the meeting data all at once , in a lot of different ways . you we need about a gig per meeting . ","Transcriber is now working for Windows, however live pitch contours may not work in the time available. Backed-up disk space is now fine, however temporary space is running out fast. "
Bmr026.A,"not for long . it 's probably only about four gig is on x on your x drive , but we 'll definitely take it up if you great . that will get us through the next couple days .  at least . the "" more disk space "" button ?  half a gig . for all of them . i would like to .  and put it where ?  wa a i they want . the sysadmins would prefer to have one external drive per machine . they don't want to stack up external drives . and then they want everything else in the machine room . the question is where are you gonna hang them ? right .   but i know that generally their first priority has been for backed up disk . and think what he 's been concentrating on is the back up system , rather than on new disk .  which really . popcorn . it 's just it 's not on the net , it 's a little awkward it 's not it 's behind lots of fire walls that don't allow any services through except s  and also on the list is to get it into the normal icsi net , but who knows when that will happen ? no , the problem with that is that they don't currently have a wire running to that back room that goes anywhere near one of the icsi routers . they actually have to run a wire somewhere . but dave has to do all of them . my ! and that 's all i have . this is the fifteenth ? just a week from tomorrow ?  i 'm interested . jane , no . if we talked about it in this meeting . the nod off ? i would as i would guess . or just alternate the focus . on even weeks have basic on data . i am . sor except that we keep going for our full time .  ugh . i don't . let 's read digits and go . bridge .  no , no that would be for next week .   just with rover ?  it 's pretty impressive . we clearly gotta add a few more features , though . no , front end features . we did plp and mel cepstra . let 's , try rasta and msg , and  right . i don't know . i could also put in focus condition zero from hub four from broadcast news , which is mostly prepared speech . it 's not exactly read speech but it 's pretty darn close .  that 's right .    try it . you run it ? keep both versions ? see which one 's better ? i could make arguments either way . it 's given up guessing . although , we 've done it with when we were combining with the cambridge recurrent neural net , embedded training made it worse . which i 've never figured out . ","the sysadmins would prefer to have one external drive per machine . they don't want to stack up external drives . and think what he 's been concentrating on is the back up system , rather than on new disk . just a week from tomorrow ? ","The group note that the annual report needs to be worked on for next week, and it is also suggested to hold recognition meetings separately, however these issues will be discussed in more detail at the next meeting. "
Bmr026.A,"it 's a bug .   no they were comparable . they were very close . that 's what i said .  right .  that 's another big difference . i 'm not what this 'll mean . hello ? excuse me ? alright . wrong number .  but not by a lot . vast majority is from the input unit . right , because you used the context windows and the input to hidden is much , much larger . it 'll be faster . we 're just waiting for you to leave . anything else ?  if that 's right . we started late . ",they were comparable . ,
Bmr026.B,"  that should have ma many fewer and it 's also not bunch of interruptions with people and all that , right ?   it certainly seems  if we 're held up on this other little bit in order to encompass that , that 's because i still have high hopes that the ibm pipeline 'll work out for us , it 's  you are going to   i wondered whe when we would reach dave 's saturation point . he 's been volunteering for everything and o k . finally said he was too busy . we reached it . again , the issue is for july , the issue 's gonna be what can we fit into a windows machine , and on , but can some of the that don 's talking about somehow fit into this mean you just have a set of numbers that are associated with the yes . wh   no , we 're talking about on the computer and when we were talking about this before we had littl this little demo meeting , we set up a range of different degrees of liveness that you could have and , the more live , the better , but given the crunch of time , we may have to retreat from it to some extent . think for a lot of reasons , it would be very to have this transcriber interface be able to show some other interesting signal along with it it 'd be a good thing to get in there . but , anyway , jus just looking for ways that we could actually show what you 're doing , in to people . cuz a lot of this particularly for communicator , certainly a significant chunk of the things that we waved our arms about th originally had t had to do with prosodics it 'd be to show that we can actually get them and see them . did they come in ?   weren't we gonna get it should get another rack . but if abbott is going to be our disk server it file server it seems like we would want to get it , a second disk rack for the next meeting you might be out of luck with those ten , mightn't you ? dave johnson is gone for ten days , tonight . i don't know . i don't his schedule is . i 'm just saying he 's gone . you had an eighteen gigabyte drive . we need we need another gigaquad . there should i d there should just be a b i should have a button . just press each meeting saying "" we need more disk space "" "" this week "" . skip the rest of the conversation . and how much does each meeting take ? there 's a hundred gig or cuz we have the uncompressed around also . it 's like  mean it 's the they really are cheap . ","and , the more live , the better , but given the crunch of time , we may have to retreat from it to some extent . think for a lot of reasons , it would be very to have this transcriber interface be able to show some other interesting signal along with it it should get another rack . dave johnson is gone for ten days , ","Transcriber is now working for Windows, however live pitch contours may not work in the time available. Interim measures are discussed while sysadmin are away. "
Bmr026.B,"it 's just a question of figuring out where they should be and hanging them , but we could if you want to get four disks , get four disks . it 's small these things ar are just a few hundred dollars .  right . you need a direct conversation with him . and just say an e just ask him that , wha what should you do . and in my answer back was "" are you you just want one ? "" mean that what you want to do is plan ahead a little bit and figure "" here 's what we pi figure on doing for the next few months "" .  right . right . this is a question that 's pretty hard to solve without talking to dave , cuz it  no . dave knows all these things , an and he always has a lot of plans of things that he 's gonna do to make things better in many ways an and runs out of time .   but this is a very specific question for me . we can easily get one to four disks , you just go out and get four and we 've got the money for it , it 's no big deal . but the question is where they go , and i don't think we can solve that here , you just have to ask him . attach to    e again , any one of these things is certainly not a big deal . if there was a person dedicated to doing it they would happen pretty easily but it 's jus every ever everybody has a has all of us have long lists of different things we 're doing . but at any rate that there 's a longer term thing and there 's immediate need and we need a conversation with after tea you and go down and talk to him about it just say "" wha what should we do right now ? "" eleven days  tomorrow and all of the week after .  let 's see . the only oth thing other thing i was gonna add was that talked briefly to mari and we had both been busy with other things we haven't really connected that much since the last meeting we had here but we that we would have a telephone meeting the friday after next . and i wanted to make it , after the next one of these meetings , something that we wanna do next meeting is to put together a reasonable list for ourselves of what is it , that we 've done . just bulletize e do dream up text but this is gonna lead to the annual report . if w that would   we can this that 's an  no , no but i don't need other folks for the meeting . do it . a all i 'm saying is that on  ","it 's just a question of figuring out where they should be and hanging them , this is a question that 's pretty hard to solve without talking to dave , but at any rate that there 's a longer term thing and there 's immediate need something that we wanna do next meeting is to put together a reasonable list for ourselves of what is it , that we 've done . just bulletize e do dream up text but this is gonna lead to the annual report . ","Interim measures are discussed while sysadmin are away. The group note that the annual report needs to be worked on for next week, and it is also suggested to hold recognition meetings separately, however these issues will be discussed in more detail at the next meeting. "
Bmr026.B,"what i meant was on the me this meeting if i wa something i 'm making a major thing in the agenda is i wanna help in getting together a list of what it is that we 've done can tell her . have a pretty good idea but and then the next day late in the day i 'll be having that discussion with her .   think how many people here would not be interested in in a meeting about recognition ? you 're su  we 're gonna have a guy 's meeting . real real men "" real men do decoding "" like that .   it 's cuz y you have a you need a better developed feminine side . there 's probably gonna be a lot of "" bleeps "" in this meeting .  it must be nearing the end of the week .  i i 've heard some comments about like this . that m could be . the u  right . why don't we just start with that . and then if we find , we 're just not getting enough done , there 's all these topics not coming up , then we can expand into another meeting . but that 's a great idea . let 's chat about it with liz and jane when we get a chance , see what they think and and you 're attending the the front end meeting as as the others you have probably one of the best you and i , are the main ones who see the bridge between the two . we are doing recognition in both of them .     except the only key difference between the two really is the smoothing at the end which is the auto regressive versus the cepstral truncation .  why not ?   an  right . including digits i gather , a fifth of it is how much ? right . but a fi a fifth is how much ? mean that 's actually not that different from the amount of training that there was .   w  right . that was the interesting thing . because it was apparent if you put in a bunch more data it would be better , but they been using timit . that they they experimented for a while with a bunch of different databases with french and spanish and forth cuz they 're multilingual tests and and actually the best results they got wa were using timit . but which that 's what they 're using now . but certainly if we , if we knew what the structure of what we 're doing there was . there 's still a bunch of messing around with different kinds of noise robustness algorithms . we don't know exactly which combination we 're gonna be going with . once we know , then the trainable parts of it 'd be great to run lots of through .   although we it 's not that many fewer and we take a klt anyway we could  ","how many people here would not be interested in in a meeting about recognition ? and then if we find , we 're just not getting enough done , there 's all these topics not coming up , then we can expand into another meeting . let 's chat about it with liz and jane when we get a chance , see what they think and mean that 's actually not that different from the amount of training that there was . because it was apparent if you put in a bunch more data it would be better , although we it 's not that many fewer and we take a klt anyway we could ","The group note that the annual report needs to be worked on for next week, and it is also suggested to hold recognition meetings separately, however these issues will be discussed in more detail at the next meeting. "
Bmr026.B,"and and we sh again check we should check with stephane . my impression was that when we did that before that had very little he didn't lose very much .   and the b and the base u starting off with the base of the alignments that you got from i from a pretty decent system .   that 's certainly one thing ,  the other thing is , dipping deep into history and into our resource management days , when we were collaborating with sri before , it was it is was a really key starting point for us that we actually got our alignment . when we were working together we got our initial alignments from decipher , at the time . and . later we got away from it because once we had decent systems going then it was typically better to use our own systems cuz they were self consistent but certainly to start off when we were trying to recover from our initial hundred and forty percent error rate . but that was a good way to start . and we 're not quite that bad with our switchboard systems but it was they certainly aren't as good as sri 's ,  the hybrid system we never got better than about fifty percent error . and it was there 's just a whole lot of things that no one ever had time for . we never did really fix up the dictionary . we always had a list of a half dozen things that we were gonna do and a lot of them were pretty simple and we never did . we never did an never did any adaptation we never did any   we were  we were probably at least a factor or two off .    but again it 's  it 's the conver it 's the s conversational speech bit . because our broadcast news system is actually pretty good . he knows .   it 'll still probably be worse . it 's it 'd be context independent and on . but .  agree with ad you would then you proceed with the embedded training . it 's gonna take you a while to train at this net anyway . and while it 's training you may as test the one you have and see how it did . it depended on the task . in this one i would expect it to be important because we 're coming from alignments that were achieved with an extremely different system .  right . but  was it ? i don't think it was . no .  excuse me ?  no . tha u we 've see and wi with the numbers ogi numbers task we 've seen a number of times people doing embedded trainings and things not getting better .  it just but i would i would suspect that something that had very different feature set , they were using pretty diff similar feature sets to us . ",and the b and the base u starting off with the base of the alignments that you got from i from a pretty decent system . it 's it 'd be context independent and on . ,
Bmr026.B,"i would expect that something that had a different feature set would benefit from minute , and the other thing  it was the other thing is that what was in common to the cambridge system and our system is they both were training posteriors . mean , that 's another pretty big difference and one bac at least back at that both the cambridge system and our system were training posteriors . and if we 're coming from alignments coming from the sri system , it 's a likelihood based system . that 's another difference . there 's diffe different front end different training criterion i would think that in a that an embedded training would have at least a good shot of improving it some more . but we don't know . you gonna say something ? how much training data ? and how many hours is that ?  after run right .  at least a couple thousand hidden units .  it 's th the thing i 'll think about it a little more but it 'd be toss up between two thousand and four thousand . you definitely wouldn't want the eight thousand . it 's m it 's more than let me think about it , but that th at some point there 's diminishing returns . it doesn't actually get worse , typically , but it but there is diminishing returns and you 're doubling the amount of time . not by much . fifty s fifty four to forty eight ?   it 'll have a very tiny effect .   it 's it 'd be way , way less than ten percent of the difference . there 's how bi how big let 's see . what am i trying to think of ? right . and that was trained up on like a hundred and forty hours of speech .  that would be like trained on s sixty or seventy hours .  definitely not the one thousand two thousand fr the four thousand will be better and the two thousand will be almost will be faster and almost as good .   thirty hours is like a hundred and ten thousand seconds . that 's like eleven million frames . and a two thousand hidden unit net is guess about seven , eight hundred thousand parameters . that 's probably fine . four thousand is within the range that you could benefit from but the two thousand 'd be faster  alright . uncle bernie 's rule is ten to one . bernie woodrow 's rule of  uncle bernie  yes sir . nah . since we have nothing to talk about we only talked for an hour .  de ba de . de ba de that 's all folks ! ",how much training data ? ,
Bmr026.C,"is that english ? we 're up to mr thirteen for ibm ,  there 's only two channels . it 's only  as the synthesis doesn't have to be transcribed   but it 's just transcripts , not the audio ?      i 've been putting together transcriber things for windows  and i installed it on dave gelbart 's pc and it worked just fine . hopefully that will work .      but the problem is the version transcriber works with , the snack version , is one point six whatever and that 's not anymore supported . it 's not on the web page anymore . but wrote an email to the author of to the snack author and he sent me to one point six whatever library and it works .  but then you can't add our patches and then the new version is different a and in in terms of the source code . you can't find the tcl files anymore . it 's some whatever wrapped thing and you can't access that you have to install first install tcl then install snack and then install the transcriber thing and then do the patches .   no , i haven't done that yet . i 'm nope . but i definitely will do that .     we could l look into that . and and to hear it .       an internal .    xg .  it 's  isn't that xh ? but i 'm using xh h , too .  it 's a little bit more as i usually don't do not uncompress the all of the pzm and the pda things .  it 's  one point five     it 's not bad . me too .    ","but it 's just transcripts , not the audio ? i 've been putting together transcriber things for windows but the problem is the version transcriber works with , the snack version , is one point six whatever ","Web pages have been set up to show transcription status and to allow participants to approve transcripts. Transcriber is now working for Windows, however live pitch contours may not work in the time available. "
Bmr026.D,"that 's our system .  speaking  does she have transcribers right now who are sitting idle because there 's no data back from ibm no ?   because i need to ask jane whether it 's it would be for her s some of her people to transcribe some of the initial data we got from the smartkom data collection , which is these short like five or seven minute sessions . and we want it we need the again , we have a similar logistic set up where we are supposed to send the data to munich and get it transcribed and get it back . but to get going we would like some of the data transcribed right away we can get started . and wanted to ask jane if one of their transcribers could do since these are very short , that should really be it 's  it 's only two right , s  it 's one channel to transcribe . and it 's one session is only like seven right . and some of it is read speech , we could give them the thing that they 're reading and they just may and since she 's i was gonna ask her but since she 's not around i 'll if that 's with you to , get that to ask her for that , then i 'll do that .   alrighty .  really ? is that because there 's some people it would be if we could get that to work at sri because the we have m we have more windows machines to run the right .  i wonder if we should contribute our changes back to the authors that they maintain those changes along we have ?    but it would be if the transcriber interface had like another window for the above the waveform where it would show some arbitrary valued function that is time synchron ti time synchronous with the wavform . right . right . but it would almost be like having another waveform displayed . s right .    but you still need to store the disks somehow .  you put them inside the pizza boxes for the   plus we 're talking about buying a second dis file server . i see i see . he won't set up the  xg ? that 's also where we store the hub five training set waveforms , right ? right . but i 've also been storing i 've been storing the feature files there and can s start deleting some because we now the best features are and we won't be using the old ones anymore . thats xa that 's x 'm confu no i 'm  you 're right . it 's xh and d the b i 'm also using dg i got that confused .  th the one  one on one thing to in to to do when you need to conserve space is i bet there are still some old , nine gig disks , around ","because i need to ask jane whether it 's it would be for her s some of her people to transcribe some of the initial data we got from the smartkom data collection , which is these short like five or seven minute sessions . but to get going we would like some of the data transcribed right away we can get started . and wanted to ask jane if one of their transcribers could do since these are very short , that should really be but it would be if the transcriber interface had like another window for the above the waveform where it would show some arbitrary valued function that is time synchron ti time synchronous with the wavform . ","Transcriber is now working for Windows, however live pitch contours may not work in the time available. "
Bmr026.D,"and you can probably consolidate them onto larger disks and recover the space . right .    we can put some disks in the in that back room there . to the machine that collects the data . then you could , at least temporarily , store there . the only what do it 's not on the net ? because it 's an aciri machine ?  but that can't be that hard .    is this gotta be in the morning ? or because fridays i have to leave like around two . if it could be before that would be alright . 'm i misunderstood . you are  alright .    one thing we in past meetings we had also a various variously talked about the work that w was happening on the recognition side but isn't necessarily related to meetings specifically . and i wondered whether we should have separate meeting and between whoever 's interested in that because i feel that there 's plenty of to talk about but it would be the wrong place to do it in this meeting if it 's that it 's just gonna be ver very boring for people who are not really interested in the details of the recognition system . know jane an in a separate meeting or ha talking about it in this    liz and jane probably . if you wanna put it that way . right . it 's when the talk is about data collection sometimes i 've i 'm bored . it 's i c sympathize with them not wanting to i to be if i cou this could i 'm not wanna  and  and we don't have to do it every week . we could do it every other week or whatev or whenever we feel like we we could do that , i personally i 'd i 'm not in favor of more meetings . because ,  right . we feel obligated to collect more data . ummh .     right .  we could talk a little bit about that now if there 's some time . jus the latest result was that yot i tested the the final version of the plp configuration on development test data for this year 's hub five test set . and the recognition performance was exactly , and exactly up to the the first decimal , same as with the mel cepstra front end . yes . there was a little bit of a i overall . they were the males were slightly better and the females were slightly worse but nothing really . definitely not significant . and then the really thing was that if we combine the two systems we get a one and a half percent improvement .  t with n best rover , which is like our new and improved version of rover . which u actually uses the whole n best list from both systems to combine that .  and , the ","one thing we in past meetings we had also a various variously talked about the work that w was happening on the recognition side it 's that it 's just gonna be ver very boring for people who are not really interested in the details of the recognition system . liz and jane probably . yot i tested the the final version of the plp configuration on development test data for this year 's hub five test set . and the recognition performance was exactly , and exactly up to the the first decimal , same as with the mel cepstra front end . they were the males were slightly better and the females were slightly worse but nothing really . and then the really thing was that if we combine the two systems we get a one and a half percent improvement . which u actually uses the whole n best list from both systems to combine that . ","The group note that the annual report needs to be worked on for next week, and it is also suggested to hold recognition meetings separately, however these issues will be discussed in more detail at the next meeting. Improvement has been made in the final version of the PLP, which shows better female performance, and combined with Mel Ceptra offers 1.5% improvement. "
Bmr026.D,"and after i told the my colleagues at sri about that , now they definitely want to , have a next time we have an evaluation they want to do at least the system combination . and , why not ?  what do more features in the sense of front end features or in the sense of just bells and whistles ? mean   right . we cou  that 's the there 's one thing mean you don't want to overdo it because y every front end if you multiply your effort by n , where n is a number of different systems and one compromise would be to only to have the everything up to the point where you generate lattices be one system and then after that you rescore your lattices with the multiple systems and combine the results and that 's a fairly painless thing .    little less because at that point the error rates are lower and if it 's only one percent but that would still be worthwhile doing .  jus just wanted to let that 's working out very nicely . and then we had some results on digits , with we this was really just to get dave going with his experiments . and but as a result , we were wondering why is the hub five system doing on the digits . and the reason is there 's a whole bunch of read speech data in the hub five training set . and you c and not all of no it 's actually , digits is only a fifth of it . the rest is read timit data and atis data and wall street journal and like that . a fifth would be two hours something . right . but it definitely helps to have the other read data in there because we 're doing the error rate is half of what you do if you train only on ti timit not timit ti digits , which is only what two hours something ? more read speech data definitely helps . and you can leave out all the conversational data with no performance penalty . that 's e that was e right , right . right .  we only for the hub five training , we 're only using fairly small subset of the macrophone database . you could beef that up and probably do even better .   right . that 's plenty of read speech data . wall street journal , take one example . but that might be useful for the people who train the digit recognizers to use something other than ti digits .       right . that was that . and then i th guess chuck and i had some discussions about how to proceed with the tandem system and you wanna see where that stands ? an and one side effect of that would be that it 's that the phone set would change . the mlp would be trained on only forty six or forty eight forty eight phones ? ","there 's one thing mean you don't want to overdo it because y every front end if you multiply your effort by n , where n is a number of different systems and then we had some results on digits , with and the reason is there 's a whole bunch of read speech data in the hub five training set . the rest is read timit data and atis data and wall street journal and like that . a fifth would be two hours something . but it definitely helps to have the other read data in there the error rate is half of what you do if you train only on ti timit not timit ti digits , more read speech data definitely helps . and you can leave out all the conversational data with no performance penalty . that 's plenty of read speech data . wall street journal , take one example . that might be useful for the people who train the digit recognizers to use something other than ti digits . and then i th guess chuck and i had some discussions about how to proceed with the tandem system the mlp would be trained on only forty six or forty eight ",Digit performance also improved thanks to training using scripted speech data. Progress has also been made in SRI alignment for tandem system. 
Bmr026.D,"which is smaller than the than the phone set that we 've been using far . and that will probably help , actually , because the fewer dimensions the less trouble probably with the as far as just the just we want to try things like deltas on the tandem features . and you h have to multiply everything by two or three . and fewer dimensions in the phone set would be actually helpful just from a logistics point of view . right . exactly . that was the other thing . and then we wanted to s just limit it to something on the same order of dimensions as we use in a standard front end . that would mean just doing the top i don't know ten or twelve of the klt dimensions . right . but then and then something once we have the new m l p trained up , one thing i wanted to try just for the fun of it was to actually run like a standard hybrid system that is based on those features and retrain mlp and also the the dictionary that we use for the hub five system . exactly .  that would give us a , more hopefully a better system because compared to what eric did a while ago , where he trained up , a system based on broadcast news and then tra retraining it on switchboard or s and but he he d he didn't he probably didn't use all the training data that was available . and his dictionary probably wasn't as tuned to conversational speech as the as ours is .  and the dictionary made a huge difference . we made some improvements to the dictionary 's to the dictionary about two years ago which resulted in a something like a four percent absolute error rate reduction on switchboard , which          right .   but that w even that number right . and that number was on switchboard one data , right ? where the error rate now is in the twenties .  that 's yet s right . it would be good t to re just at least to give us an idea of how the hybrid system would do .  right . and the other thing that would help us to evaluate is to see how the m l p is trained up . right ? because it 's a pretty good indicator of that . it 's sanity check of the m l p outputs before we go ahead and train up the use them as a basis for the tandem system . no .  not but that 's a good question . we weren't whether it 's worth to just use the alignments from the s r i recognizer or whether to actually go through one or more iterations of embedded training where you realign .   right .  alright . but but i but in your experience have you seen big improvements in s on some tasks with embedded training ? ","which is smaller than the than the phone set that we 've been using far . we want to try things like deltas on the tandem features . and you h have to multiply everything by two or three . and fewer dimensions in the phone set would be actually helpful just from a logistics point of view . and then we wanted to s just limit it to something on the same order of dimensions as we use in a standard front end . that would mean just doing the top i don't know ten or twelve of the klt dimensions . once we have the new m l p trained up , one thing i wanted to try just for the fun of it was to actually run like a standard hybrid system that is based on those features and retrain mlp and also the the dictionary that we use for the hub five system . it 's sanity check of the m l p outputs before we go ahead and train up the use them as a basis for the tandem system . ",
Bmr026.D,"or was it small ish improvements that you got right . that are from another right . right . you started training with outputs from a with alignments that were generated by the cambridge system ? and then  that might probably just  that was probably because your initial system your system was ba worse than cambridge 's . and you it wasn't ? really ? that 's weird . that 's weird . no it 's weird that it did i 'm it 's w it 's weird that it got worse . actually it 's not that weird because we have seen we have seen cases where acoustic retraining the acoustic models after some other change made matters worse rather than better .   with soft targets ? or ? i 'm sor i missed what 's the key issue here ?    that has about you 'd would be gender dependent training , right ? think it 's that 's about something like thirty hours . thirty hours per gender .  i 'll it 's definitely less than a hundred it 's more like thirty forty hours something like that .   remember you 'll have a smaller output layer there 's gonna be fewer parameters there . and then   see , i see ,   it 's negligible ,  was that gender dependent or independent ?    right . i actually have to go .  ",you started training with outputs from a with alignments that were generated by the cambridge system ? that was probably because your initial system your system was ba worse than cambridge 's . ,
Bmr026.E,"which meetings is she transcribing ?   we 're doing some in parallel . they 're just doing their own thing until  right . and , also i was just showing andreas , i got an x waves display , and i don't know how much more we can do with it with like the prosodic where we have like stylized pitches and signals and the transcripts on the bottom right now it 's just an x waves and then you have three windows but i don't know , it looked pretty and i 'm it think it has potential for a little something , for a demo .     we 'll see ,  it 's ascii files or binary files , whatever representation . just three different it 's a waveform and just a stylized pitch vector it 's we could do it in matl you could do it in a number of different places i 'm  that 'd be very    what do by real time ? do like  it would be to see it it would be like to see to hear it and see it , and see the pitch contours also . it would lose  right , right . thought if you meant slides you meant like just like view graphs right .   how much space do you need for these ? i have have an eighteen gig drive hanging off of my computer .  samosa . i had . it 's about there 's about twelve gig left .  i didn't realize it was critical . 'm not doing anything on it right now until i get new meetings to transcri or that are new transcriptions coming in i really can't do anything . not that i can't do anything , i jus  i have a lot of space , though . i have a lot of space and it 's not it 's n there 's very little  not for long . but it 's not going f it 's not being used often i th it 's about four or five gig cuz i have four meetings on there , three or four meetings .  watch a ball game ?  ","we 're doing some in parallel . and , also i was just showing andreas , i got an x waves display , and i don't know how much more we can do with it with like the prosodic where we have like stylized pitches and signals and the transcripts on the bottom and see the pitch contours also . i have have an eighteen gig drive hanging off of my computer . ","Transcription was discussed briefly because Jane was not present, however this appears to be progressing well in parallel with IBM. DARPA demos are progressing well with the back-end indexed to allow front-end filtering, and a potential demo ideas investigated which would use X Waves. Transcriber is now working for Windows, however live pitch contours may not work in the time available. "
Bmr026.F,"i do , peripherally . first of all with ibm i got a note from brian yesterday saying that they finally made the tape for the thing that we sent them a week or week and a half ago and that it 's gone out to the transcribers and hopefully next week we 'll have the transcription back from that . jane seems to be moving right along on the transcriptions from the icsi side . she 's assigned , probably five or six m more meetings . guess she 's hired some new transcribers and we 've run out of e d us because a certain number of them are awaiting to go to ibm . and the rest are in process being transcribed here . no . no . no . we 're not waiting on them .  we 're doing it in parallel , and also related to the transcription 've been trying to keep a web page up to date f showing what the current status is of the trans of all the things we 've collected and what stage each meeting is in , in terms of whether it 's will . i that 's the thing that i sent out just to foo people saying can you update these pages and that 's where i 'm putting it but i 'll i 'll send it out to the list telling people to look at it .   the audio that they 're gonna have access to , will that be the uncompressed version ? or will you have scripts that like uncompress the various pieces and  i was just wondering because we 're running out of the un backed up disk space on was that another one ?  i 'll did you put the the nt version out on the meeting recorder page ? or like being able to scroll through it and for the demo . is that what  there 's a lot of transcribers , too .  right . sun blades .  they came in the other day . is there why not just hang them off of abbott , is there a  i see . you can put two i thi i jus gave thilo some about ten gigs , the last ten gigs of space that there was on abbott . and but that but xg .  no . i don't think that 's on xg . on xg is only carmen and du and stephane 's disk . i do i don't think it was on xg . i th we 've collected far something like sixty five meetings . and it 's about a gig uncompressed . is a little more ? right , if you uncompressed everything it 's even more . u compressed how much are they ? like about half ? we 're definitely are storing all of those . there 's what thirty some gig of just meetings far ?  right . right . we haven't uncompressed all the meetings , but right .  ","first of all with ibm i got a note from brian yesterday saying that they finally made the tape for the thing that we sent them a week or week and a half ago and hopefully next week we 'll have the transcription back from that . guess she 's hired some new transcribers 've been trying to keep a web page up to date f showing what the current status is of the trans of all the things we 've collected that 's the thing that i sent out just to foo people saying can you update these pages i 'll send it out to the list telling people to look at it . the audio that they 're gonna have access to , will that be the uncompressed version ? or will you have scripts that like uncompress the various pieces and i was just wondering because we 're running out of the un backed up disk space on ","Transcription was discussed briefly because Jane was not present, however this appears to be progressing well in parallel with IBM. Web pages have been set up to show transcription status and to allow participants to approve transcripts. "
Bmr026.F,"sent that message out to , you and dave asking for if we could get some disk . i s i sent this out a day ago but and dave didn't respond don't know how the whole process works . does he just go out and get them and if it 's and was assuming he was gonna take over that . but he 's probably too busy given that he 's leaving .   i don't the space situation is in the machine room .  part of the reason why dave can't get the new machines up is because he doesn't have room in the machine room right now . he has to re arrange a bunch of  that might be a good short term solution , though . how long is david gonna be gone ? jane may not be . he 's wondering how much overlap there will be . good thing liz isn't here . don't listen to this , liz . could we right , i was why don't we alternate this meeting every other week ? tha that 's what  but i do i don't lot of times lately it seems like we don't really have enough for a full meeting on meeting recorder . if we did that cuz we get into these other topics .  if we could alternate the focus of the meeting that would be good . andreas and i have various talks in the halls and there 's lots of things , details and that would people 'd be interested in and i 'd where do we go from here things and it would be good .  for both females and males ?    but a percent and a half ? that 's  do you think we 'd still get the one and a half  is there even more read speech data around ?   i 'm andreas brought over the alignments that the sri system uses . and 'm in the process of converting those alignments into label files that we can use to train new net with . and then i 'll train the net . and . right . eight .  it 's a little different ? by just taking the top whatever ? right .  w what is the performance on s the best switchboard system that we 've done ? roughly ?  should we bother with using the net before doing embedded training ? should we even use that ? or should go straight to  that 's ambiguous . what about hidden unit size on this .   i was wondering what size net i should anybody have any intuitions or suggestions ? i was gonna start off with the small train set . that 's why i was i 'm not how much that is . gender dependent , thirty hours . in the small training set ? they called to tell us that ? i didn't want to do too big , just  and a thousand is too small ?  ","sent that message out to , you and dave asking for if we could get some disk . part of the reason why dave can't get the new machines up is because he doesn't have room in the machine room right now . why don't we alternate this meeting every other week ? but i do i don't lot of times lately it seems like we don't really have enough for a full meeting on meeting recorder . andreas brought over the alignments that the sri system uses . and 'm in the process of converting those alignments into label files that we can use to train new net with . and then i 'll train the net . i was wondering what size net i should anybody have any intuitions or suggestions ? ","The group note that the annual report needs to be worked on for next week, and it is also suggested to hold recognition meetings separately, however these issues will be discussed in more detail at the next meeting. "
Bmr026.F,the net that we did use already was eight thousand hidden units and that 's the one that eric trained up . gender dependent .  'll start off with two thousand just to see .  transcript ,,
Bmr027.A,"ear plug . is that does that mean you can't hear anything during the meeting ? meant that was the release date that you had on the data . i ,   that 's right . that 's why . you said you wanted it to be available then . i didn't mean it to be the hard deadline . it 's fine with me if it is , or we cou but it might be good to remind people two weeks prior to that in case , "" this is your last ""  that 's right . and he 's got it that the default thing you see when you look at the page is "" . that 's very clear all the way down the page , "" . and they have two options they can change it to . one of them is "" censor "" , and the other one is "" incorrect "" . is it is your word is "" incorrect "" ? which means also we get feedback on if there 's something that they w that needs to be adjusted , because , these are very highly technical things . it 's an added , level of checking on the accuracy of the transcription , as i see it . but in any case , people can agree to things that are wrong .  and the reason i liked it was because was because it , it gives them the option of , being able to correct it . approve it and correct it . and you have it nicely set up they email you and ,  and i wanted to say the meetings that are involved in that set are robustness and meeting recorder . the german ones will be ready for next week . those are three of those . a different set of people . and we can impose  i spoke loosely . the german , french the german , dutch , and spanish ones .  that 's that 's r it 's the other group .  exactly . i didn't mean to isolate them .  it was not the best characterization . but what i meant to say was that it 's the other group that 's not n no m no overlap with our present members . and then it 'd be good to set an explicit deadline , something like a week before that , j july fifteenth date , or two weeks before .  that 's a little bit difficult .  that 's true . i agree with that part , but that it would it , we need to have , a message to them very clearly that beyond this date , you can't make additional changes . good .       that there 's one missing line . i ha i have one question . this is in the summer period and presumably people may be out of town . ","meant that was the release date that you had on the data . but it might be good to remind people two weeks prior to that they can change it to . one of them is "" censor "" , and the other one is "" incorrect "" . the german ones will be ready for next week . and then it 'd be good to set an explicit deadline , something like a week before that , j july fifteenth date , or two weeks before . this is in the summer period and presumably people may be out of town . ","The group suggest sending reminder e-mails, although since many participants are local they can be contacted by other means if necessary. Checking of the NSA meetings has revealed that this non-native English meeting data contains transcription inaccuracies due to the use of foreign language terms and technical vocabulary. With regard to obtaining consent, the group discuss the extent to which they need to attempt to contact people, which methods are most appropriate, and how much responsibility rests on participants being available and checking their e-mail regularly. "
Bmr027.A,"but we can make the assumption , can't we ? that , they will be receiving email , most of the month . right ? because if someone  we did that , i believe . and the form says the f the form doesn't say , if "" if you don't respond by x number of days or x number of weeks "" it doesn't have a time limit . that you 'll be provided access to the transcripts and then , allowed to remove things that you 'd like to remove , before it goes to the general larger audience . there you go .  i like this .  most but the ones that we 're dealing with now are all local , except the ones who we 're in contact with all the ones in those two groups . i that 's not that many people and if i if , i there is an advantage to having them admit and if help with processing that , i will . it 's there is an advantage to having them be on record as having received the mail and indicating yes , we did . you 're right . i but sometimes that 's right . need to get it right .  it 's much easier to explain this way . t to have it on record . but w then we make the effort . we make the effort . except i really think in this case i 'm agr i agree with liz , that we need to be in the clear and not have to after the fact say "" but i assumed "" , and "" i 'm that your email address was just accumulating mail without notifying you "" ,  excellent . yes . i don't remember that this issue of the time period allowed for response was ever covered . or how they would indicate that one . it doesn't matter . and how many people ? al altogether we 've got twenty people . these people are people who read their email almost all the time . i really don't see that it 's a problem . that it 's a common courtesy to ask them to expect for them to , be able to have @ @ us try to contact them , u just in case they hadn't gotten their email . they 'd appreciate it .  i remember that .  i also think they 'd just simply appreciate it . it 's a good way of fostering goodwill among our subjects . our participants .  that 's right . i could get you on the notify list if you want me to . for that directory ? great .   i don't think , they 're recent , these visitors . i and i they 're also they 're prominent enough that they 're easy to find through i w i 'll be able to if you have any trouble finding them , i really could find them .  ","but we can make the assumption , can't we ? that , they will be receiving email , most of the month . al altogether we 've got twenty people . these people are people who read their email almost all the time . i really don't see that it 's a problem . that it 's a common courtesy to ask them to expect for them to , be able to have @ @ us try to contact them , u just in case they hadn't gotten their email . they 'd appreciate it . i don't think , they 're recent , these visitors . i w i 'll be able to if you have any trouble finding them , i really could find them . ","With regard to obtaining consent, the group discuss the extent to which they need to attempt to contact people, which methods are most appropriate, and how much responsibility rests on participants being available and checking their e-mail regularly. The group suggest sending reminder e-mails, although since many participants are local they can be contacted by other means if necessary. "
Bmr027.A,"i d don't think we will . for all the reasons that we 've discussed .  and actually , i didn't anticipate this that 's why i didn't give this comment , and it i this discussion has made me think it might be to have a follow up email within the next couple of days saying "" we wanna hear back from you by x date and , and then add what liz said "" respond to indicate you received this mail . ""  it is the first time through the cycle . some lead time . has jeremy signed the form ?   at a certain point , that copy that has the deletions will become the master copy . but and then w i was gonna say also that the they don't have to stay on the system , as cuz the ones once it 's been successfully bleeped , can't you rely on the ? can't you rely on the archiving to preserve the older version ?   this is the first cycle . there 're bound to be some glitches the first time through .   and it also doesn't give a specific i didn't think of it . s it 's a good idea an ex explicit time by which this will be considered definite . and it has to be a time earlier than that endpoint . that 's right . that 's interesting . could do that .  but why shouldn't they just email back ? i don't see there 's a problem . it 's very i like the high tech aspect of it , but i appreciate it . i like vi . six . i agree with you . it 's we could do it , could i 'd be happy with either way , batch wise what i was thinking this one that was exactly right , that we had a i had wanted to get the entire set of twelve hours ready . don't have it . but , this was the biggest clump i could do by a time where it was reasonable . people would be able to check it and still have it ready by then . my , was thinking that with the nsa meetings , i 'd like there are three of them , and they 're i will have them done by monday . unfortunately the time is later and i don't know how that 's gonna work out , but it 'd be good to have that released as a clump , too , because then , they 're they have a it 's in a category , it 's not quite distracting to them , is what i was thinking , and it 's all in one chu but after that , when we 're caught up a bit on this process , then , i could imagine sending them out periodically as they become available . i could do it either way . ","and it i this discussion has made me think it might be to have a follow up email within the next couple of days saying "" we wanna hear back from you by x date at a certain point , that copy that has the deletions will become the master copy . ","The group suggest sending reminder e-mails, although since many participants are local they can be contacted by other means if necessary. Additional topics covered more briefly in this meeting are disk space, the DARPA annual report, progress with the demo, conference submissions and attendance, and requests from the University of Washington for data. "
Bmr027.A,"it 's a question of how distracting it is to the people who have to do the checking . that 's on my list . that 's on my list .    one question about the backchannels . do you suppose that was because they weren't caught by the pre segmenter ? interesting . interesting .   when the detector for that gets better i w i there 's another issue which is this we 've been , contacted by university of washington now , to , we sent them the transcripts that correspond to those six meetings and they 're downloading the audio files . they 'll be doing that . chuck 's chuck 's , put that in . this is to show you , some of the things that turn up during the checking procedure . @ this is from one of the nsa meetings and , i if you 're familiar with the diff format , the arrow to the left is what it was , and the arrow to the right is what it was changed to .  and now the first one . "" then we started a weekly meeting . the last time , and the transcriber thought "" little too much "" but , really , it was "" we learned too much "" , which makes more sense syntactically as then this that 's the convention for indicating uncertain . the transcriber was right . she was uncertain about that . she 's right to be uncertain . and it 's also a g a good indication of the of that . the next one . this was about , claudia and she 'd been really b busy with such as waivers .  next one . this was an interesting one . the original was "" that 's not claudia 's not the bad master here "" , and then he laughs , but it really "" web master "" . and then you see another type of uncertainty which is , they just didn't to make out of that . instead of "" split upon unknown "" , it 's "" split in principle "" . no , no . these are our local transcriptions of the nsa meetings . the transcribers transcriber 's version ver versus the checked version . my checked version , after i go through it . then you get down here .  sometimes some speakers will insert foreign language terms . that 's the next example , the next one . the , version beyond this is instead of saying "" or "" , especially those words , "" also "" and "" oder "" and some other ones . those sneak in . the next one s what ? discourse markers ?  and it 's and it makes sense cuz it 's below this it 's a little subliminal there . the next one , this is a term . the problem with terminology . description with th the transcriber has "" x as an advance "" . ","do you suppose that was because they weren't caught by the pre segmenter ? we 've been , contacted by university of washington now , to , we sent them the transcripts that correspond to those six meetings and they 're downloading the audio files . @ this is from one of the nsa meetings no , no . these are our local transcriptions of the nsa meetings . sometimes some speakers will insert foreign language terms . ","Transcriptions are back from IBM, and the group discuss the checking of these, particularly since the pre-segmenter has interfered with back-channel data. Additional topics covered more briefly in this meeting are disk space, the DARPA annual report, progress with the demo, conference submissions and attendance, and requests from the University of Washington for data. Checking of the NSA meetings has revealed that this non-native English meeting data contains transcription inaccuracies due to the use of foreign language terms and technical vocabulary. "
Bmr027.A,"but really it 's "" qs in advance "" . i 've benefited from some of these , cross group meetings . then you got ,  instead of "" from something or other cards "" , it 's "" for multicast "" . and instead of "" ann system related "" , it 's "" end system related "" . this was changed to an acronym initially and it should shouldn't have been . and then , you can see here "" gps "" was misinterpreted . it 's just understanda this is a lot of jargon . and the final one , the transcriber had th "" in the core network itself or the exit unknown , not the internet unknown "" . and it comes through as "" in the core network itself of the access provider , not the internet backbone core "" . now this is a lot of terminology . and they 're generally extremely good , but , in this area it really does pay to , to double check and i 'm hoping that when the checked versions are run through the recognizer that you 'll see s substantial improvements in performance cuz the there 're a lot of these in there . no , actually no .  it 's jargon . this is cuz , you don't realize in daily life how much you have top down influences in what you 're hearing . and it 's jar it 's jargon coupled with a foreign accent . also from the standpoint of getting people 's approval , cuz if someone sees a page full of barely decipherable w sentences , and then is asked to approve of it or not , it 's ,  exactly . that 's why we discussed that . and then i also the final thing i have for transcription is that i made a purchase of some other headphones because of the problem of low gain in the originals . and they very much appro they mu much prefer the new ones , and actually that there will be fewer things to correct because of the choice . we 'd originally chosen , very expensive head headsets but , they 're just not as good as these , in this with this respect to this particular task . i don't know exactly , but we chose them because that 's what 's been used here by prominent projects in transcription . it i we had every reason to think they would work . what ? we have actua actually i have w that if we have four people come to work for a day , i was hanging on to the others for , for spares , but tell you what i recommend . it 'd just have to be a s a separate order an added order . cambridge soundworks , just down the street . they always have them in stock .  it 's made a difference in how easy .   a woman of few words . ","and i 'm hoping that when the checked versions are run through the recognizer that you 'll see s substantial improvements in performance no , actually no . this is cuz , you don't realize in daily life how much you have top down influences in what you 're hearing . and it 's jar it 's jargon coupled with a foreign accent . and then i also the final thing i have for transcription is that i made a purchase of some other headphones because of the problem of low gain in the originals . and they very much appro they mu much prefer the new ones , ",Checking of the NSA meetings has revealed that this non-native English meeting data contains transcription inaccuracies due to the use of foreign language terms and technical vocabulary. 
Bmr027.A,since last week . i 'll be interested . what 's the name of the meeting ? good . ,,
Bmr027.B," should we , close the door , it 's   that 's a  just to repeat the thing bef that we said last week , it was there 's this suggestion of alternating weeks on more , automatic speech recognition related or not ? was that the division ? which week are we in ? we had a thing about speech recognition last week too .    w what follows ? at some point y you go around and get people to sign something ? but i 've forgotten . and how long of an opportunity did you tell them ? july fifteenth . they have a plenty of time , and y given that it 's that long ,  why was that date chosen ? you just felt you wanted to ?  i don't no , the only th the only mention i recall about that was just that july fifteenth or is when this meeting starts . i see .  right . w right . we probably should have talked about it , cuz i because if we wanna be able to give it to people july fifteenth , if somebody 's gonna come back and say "" i don't want this and this used "" , clearly we need some time to respond to that . right ?    didn't remember , but  nsa . german , dutch , swiss and spanish . i it was the network services group .  otherwise known as the german , dutch , and spanish . i would suggest we discuss if we 're going to have a policy on it , that we discuss the length of time that we want to give people , that we have a uniform thing . tha that 's a month , which is fine . it seems   that somebody might request something even though we say that . but it 's good to at least start some place like that . if we how long is a reasonable amount of time for people to have if we say two weeks , or if we say a month , we should just say that say that , i a as "" per the , page you signed , you have the ability to look over this and forth "" and , because we w "" these , i would imagine some generic thing that would say "" because we , will continually be making these things available to other researchers , this can't be open ended and give us back your response within this am within this amount of time "" , whatever time we agree upon . did i ? no , i haven't yet . no , just no , no . i 'm not saying that you should change anything . i 'm what i 'm trying to spark a discussion hopefully among people who have read it that you can , decide on something . 'm not telling you what to decide . i 'm just saying you should decide something , and then ","just to repeat the thing bef that we said last week , it was there 's this suggestion of alternating weeks on more , automatic speech recognition related or not ? at some point y you go around and get people to sign something ? july fifteenth . cuz i because if we wanna be able to give it to people july fifteenth , if somebody 's gonna come back and say "" i don't want this and this used "" , clearly we need some time to respond to that . nsa . ","With regard to obtaining consent, the group discuss the extent to which they need to attempt to contact people, which methods are most appropriate, and how much responsibility rests on participants being available and checking their e-mail regularly. The group suggest sending reminder e-mails, although since many participants are local they can be contacted by other means if necessary. Checking of the NSA meetings has revealed that this non-native English meeting data contains transcription inaccuracies due to the use of foreign language terms and technical vocabulary. "
Bmr027.B,"the one thing that i did read and that you just repeated to me was that you gave the specific date of july fifteenth . and you also just said that the reason you said that was because someone said it to you . what i 'm telling you is that what you should do is come up with a length of time that you guys think is enough and you should use that rather than this date that you just got from somewhere . that 's all i 'm saying .  it you 're right . sometimes somebody will be away and , there 's , for any length of time that you choose there is some person sometime who will not end up reading it . that 's it 's , just a certain risk to take .  we haven't experienced it before . right ?  if this is a purely administrative task , we can actually have administration do it . but that , without going through a whole expensive thing with our lawyers , from my previous conversations with them , my sense very much is that we would want something on record as indicating that they actually were aware of this .  we never really talked about that .  we certainly didn't talk , about with them about , the manner of them being made the , materials available . that was something that was just within our implementation .   let me look at this again . my adam , my view before was about the nature of what was of the presentation , of how my the things that we 're questioning were along the lines of how easy  h how m how much implication would there be that it 's likely you 're going to be changing something , as opposed to that was the dispute i was making before . but , the attorneys , i guarantee you , the attorneys will always come back with and we have to decide how stringent we want to be in these things , but they will always come back with saying that , you need to you want to have someth some paper trail or which includes electronic trail that they have , k 'd it .  that if you f i if we send the email as you have and if there 's half the people , say , who don't respond by , some period of time , we can just make a list of these people and hand it to , just give it to me and i 'll hand it to administrative staff or whatever , and they 'll just call them up and say , "" have you is this and would you mail mail adam that it is , if i if it , is or not . "" we can do that .  the main thing is what lawyers do is they always look at worst cases . ","it you 're right . sometimes somebody will be away that 's it 's , just a certain risk to take . and if there 's half the people , say , who don't respond by , some period of time , we can just make a list of these people and i 'll hand it to administrative staff or whatever , and they 'll just call them up and say , "" have you is this and would you mail mail adam that it is , if i if it , is or not . "" ","With regard to obtaining consent, the group discuss the extent to which they need to attempt to contact people, which methods are most appropriate, and how much responsibility rests on participants being available and checking their e-mail regularly. The group suggest sending reminder e-mails, although since many participants are local they can be contacted by other means if necessary. "
Bmr027.B,"they s tha that 's what they 're paid to do . and it is certainly possible that , somebody 's server would be down and they wouldn't actually hear from us , and then they find this thing is in there and we 've already distributed it to someone . what it says in there , is that they will be given an opportunity to blah blah , but if if we sent them something or we thought we sent them something but they didn't actually receive it for some reason , then we haven't given them that . i email is enough .  i 've been through this i 'm not a lawyer , but i 've been through these things a f things f like this a few times with lawyers now 'm pretty comfortable with that . again , hopefully , this shouldn't be quite as odious a problem either way , in any of the extremes we 've talked about because we 're talking a pretty small number of people .      cuz it what it really does promise here is that we will ask their permission . and if you go into a room and close the door and ask their permission and they 're not there , it doesn't seem that that 's the intent of , meaning here .  right . the way icsi goes , people , who , were here ten years ago still have acc have forwards to other accounts and on . it 's unusual that they ,  if we get to a boundary case like that then will call the attorney about it . but , hopefully we won't need to . we 'll see if we do or not . very few people will and and , people see long emails about things that they don't think is gonna be high priority , they typically , don't read it , or half read it . cuz people are swamped . but or e even additionally , "" even if you 've decided you have no changes you 'd like to make , if you could tell us that "" .  right .  the other thing i 've learned from dealing with people sending in reviews and forth , is , if you say "" you 've got three months to do this review "" , people do it , two and seven eighths months from now . if you say "" you 've got three weeks to do this review "" , they do it , two and seven eighths weeks from now they do the review . and , if we make it a little less time , i don't think it 'll be that much there 's the responding part and there 's also what if , i hope this doesn't happen , what if there are a bunch of deletions that have to get put in and changes ? then we actually have to deal with that if we want it to ","i email is enough . i 'm not a lawyer , but i 've been through these things a f things f like this a few times with lawyers now 'm pretty comfortable with that . the way icsi goes , people , who , were here ten years ago still have acc have forwards to other accounts and on . if we get to a boundary case like that then will call the attorney about it . ","The group suggest sending reminder e-mails, although since many participants are local they can be contacted by other means if necessary. "
Bmr027.B,"are you del are you bleeping it by adding ? i i understand , but is it summing signals or do you delete the old one and put the new one in ?  cuz cuz if you were summing , you could no . but anyway  encrypt it . you could encrypt it , with a two hundred bit thousand bit ,  but we never also we 've also never done it . and , and i 'm responding without , having much knowledge , but i am one of these people who gets a gazillion mails and comes in as  right . the only thing we 're missing is some way to respond to easily to say , "" go ahead ""  it 's converging . and and we actually need a third thing . it 's not that you 've looked at it , it 's that you 've looked at it and agree with one of the possible actions . right ?  i see . that i my first born children are yours , and     that 's my guy . alright .   we heard anything from ibm ?  but like you said , that 's gonna be our standard proc that 's what the transcribers are gonna be spending most of their time doing , i would imagine , once we it 's gonna     that would be a shame if people said "" i don't approve it because the it 's not what i said "" .    could be . no , but you 'd if you w we should get it . if you need it .  they 're they 're pretty inexpensive .  no . just buy them . just buy them .    i realized something i should talk about . what 's the other thing on the agenda actually ? no , no . why don't you go ahead since it 's short .  it 's i it i it 's great .  double  we 've just ordered a hundred gigabytes . we 're getting three thirty sixes . right ? that are going into the main f file server .  onto abbott , the file server . there 's another hundred gig .   it 's great to be able to do it , just say "" hundred gig , no big deal "" .   i was just going to comment that i 'm going to , be on the phone with mari tomorrow , late afternoon . we 're supposed to get together and talk about , where we are on things . there 's this meeting coming up , and there 's also an annual report . now , i never actually i was asking about this . i don't really quite understand this . she was re she was referring to it as this actually didn't just come from her , but this is what , darpa had asked for . she 's referring to it as the an annual report for the fiscal year . ","are you del are you bleeping it by adding ? we heard anything from ibm ? no . just buy them . we 've just ordered a hundred gigabytes . and there 's also an annual report . now , ","Additional topics covered more briefly in this meeting are disk space, the DARPA annual report, progress with the demo, conference submissions and attendance, and requests from the University of Washington for data. Transcriptions are back from IBM, and the group discuss the checking of these, particularly since the pre-segmenter has interfered with back-channel data. "
Bmr027.B,"but the fiscal year starts in october , don't quite understand w why we do an annual report that we 're writing in july . it 's none of those . it 's that the meeting is in july they darpa just said do an annual report .   anyway , i 'll be putting together i 'll do it , as much as without bothering people , just by looking at papers and status reports . the status reports you do are very helpful . can grab there . and if , if i have some questions i 'll if people could do it as soon as you can , if you haven't done one si recently .  but , i 'm before it 's all done , i 'll end up bugging people for more clarification about but , i don't know , know what people have been doing . we have these meetings and there 's the status reports . but , . that wasn't a long one . just to tell you that . and if something hasn't , i 'll be talking to her late tomorrow afternoon , and if something hasn't been in a status report and you think it 's important thing to mention on this thing , just pop me a one liner and i 'll have it in front of me for the phone conversation .  you 're still pecking away at the demos and all that , probably . that 's right .   i might want to get updated about it in about a week cuz , i 'm actually gonna have a few days off the following week , a after the picnic .  that 's all i had .  and there 's the digits to do . may we could . fi five minute report  i would love to hear about it , especially since i 'm gonna be on the phone tomorrow , this is just a good example of the thing i 'd like to hear about . cuz he looked at you and says you 're sketching . we did . whew ! that was nicely done , liz . but lots of prosody .  y you going to , eurospeech ?  we 'll discuss it . my car my car needs a good wash ,   you get to be the one who has all the paper rustling . right ? ","they darpa just said do an annual report . anyway , i 'll be putting together i 'll do it , as much as without bothering people , just by looking at papers and status reports . the status reports you do are very helpful . can grab there . and if , if i have some questions i 'll but , i 'm before it 's all done , i 'll end up bugging people for more clarification about y you going to , eurospeech ? ","Additional topics covered more briefly in this meeting are disk space, the DARPA annual report, progress with the demo, conference submissions and attendance, and requests from the University of Washington for data. "
Bmr027.C,"adam , what is the mike that , jeremy 's wearing ? is that a wireless , or ?   was my response wrote you replied to the email saying they 're all fine . good . that makes it easy . the german ones ? those are the nsa meetings ?  i 'd i d  twelve hours . do you track , when people log in to look at the ?   except that they got the mail . all my files were still here .  and the other th i was i was thinking that it also lets them know that they don't have to go to the page to accept this . i  that way they could they can see from that email that if they just write back and say "" i got it , no changes "" , they 're off the hook . they don't have to go to the web page and just that channel . no . we have to do do you have to do the other close talking ? or we 'll tell people the frequency of the beep and then they could subtract the beep out .  here we go . that 's cuz they use forward backward . move them to the bottom . just re mail them to yourself and then they 're at the bottom . let 's see . we right . we got the transcript back from that one meeting . everything seemed fine . adam had a script that will put everything back together and there was there was one small problem but it was a simple thing to fix . and then , we , sent him a pointer to three more . and he 's off and working on those .  it 's gonna have to go through our regular process . i pointed them to the set that andreas put , on the web th if they want to compare directly with his results they can . and , then once , th we can also point them at the , the original meetings and they can grab those , too , with scp . no , no . they d they wanted the audio . jane sent them the , transcripts .  for recognition . markham 's ordering and they should be coming in soon . these are gonna go onto abbott . they should be i imagine next week it should be soon . we should she 's either really late or really early . i don't know . good update . ",we got the transcript back from that one meeting . everything seemed fine . adam had a script that will put everything back together and there was there was one small problem but it was a simple thing to fix . it 's gonna have to go through our regular process . ,"Transcriptions are back from IBM, and the group discuss the checking of these, particularly since the pre-segmenter has interfered with back-channel data. "
Bmr027.D,"it 's old school . i it 's k it 's like signing up for a mailing list . they have opt in and opt out . and there are two different ways . and either way works probably , and they 're served . can't you just do that channel ?   you can hide it . it wouldn't be that hard to hide it . you can use spread spectrum . hide it . there you go . there you go . then you have subliminal , messages , like .  it 's like certified mail .  i see .  jane , these are from ibm ? the top lines ?  i see .   i still need to get a pair , too . i 'm using one of these .   definitely .  u it 's short . if you wanna go , we can just throw it in at the end .     without thinking about it , when i offered up my hard drive last week this is always a suspect phrase . but , no . i , realized that we 're going to be doing a lot of experiments , o for this , paper we 're writing , we 're probably gonna need a lot more we 're probably gonna need that disk space that we had on that eighteen gig hard drive . but , we also have someone else coming in that 's gonna help us out with some  we just need to  w all i need is to hang it off the person who 's coming in , sonali 's , computer . whew . or we can move them . are we gonna move the off of my hard drive onto that when those come in ? that 's fine .  if i 'm can find something if i 'm desperate and , in the meantime i 'll just hold out . that was the only thing i wanted to bring up .  alright . great . that 's it .   we should probably talk off line about when we 're gonna talk off line . ","i still need to get a pair , too . all i need is to hang it off the person who 's coming in , sonali 's , computer . can find something if i 'm desperate ",
Bmr027.E,"that 's good . spanish .  the non native the all non native  and nobody really reads it anyway . when i read it , i 'm not as diligent as chuck , but i had the feeling i should probably respond and tell adam i got this and i will do it by this date , and if you don't hear from me by then "" in other words responding to your email once , right away , saying "" as soon as you get this could you respond . "" and then if you if the person thinks they 'll need more time because they 're out of town or whatever , they can tell you at that point ? because it 's  we 're assuming that or they might never have gotten the email , because although they signed this , they don't know by which date to expect your email . and someone whose machine is down or whatever we have no in internally we know that people are there , but we have no confirmation that they got the mail . then it we 're hoping that doesn't happen , but that 's why there 's such a thing as registered mail or right . you 'll either wonder at the beginning or you 'll wonder at the end . there 's no way to get around i it 's the same am amount of work except for an additional email just saying they got the email . and it 's better legally to wonder before a little bit earlier than or the date at which they would be receiving the email from you . they probably forgot all about it .  that 's why you never open these things that come in the mail . the other thing that there 's a psychological effect that at least for most people , that if they 've responded to your email saying "" yes , i will do it "" or "" yes , i got your email "" , they 're more likely to actually do it later than to just ignore it . and we don't want them to bleep things out , but it 's a little bit better if we 're getting the their , final response , once they 've answered you once than if they never answer you 'd at al that 's how these mailing houses work . it 's not completely lost work because it might benefit us in terms of getting responses . an official from somebody is better than no answer , even if they responded that they got your email . and they 're probably more likely to do that once they 've responded that they got the email . then they just come back . same as us . right . that would definitely work on me . it makes you feel m like ,  ","because although they signed this , they don't know by which date to expect your email . and someone whose machine is down or whatever the other thing that there 's a psychological effect that at least for most people , that if they 've responded to your email saying "" yes , i will do it "" or "" yes , i got your email "" , they 're more likely to actually do it later than to just ignore it . an official from somebody is better than no answer , even if they responded that they got your email . ","The group suggest sending reminder e-mails, although since many participants are local they can be contacted by other means if necessary. "
Bmr027.E,"if you were gonna p if you 're predicting that you might not answer , you have a chance now to say that . whereas , i would be much more likely myself , given all my email , t to respond at that point , saying "" what , i 'm probably not gonna get to it "" or whatever , rather than just having seen the email , thinking i might get to it , and never really , pushing myself to actually do it until it 's too late . right . r right . that 's true . that 's true . you have to do all of them , as as all of these . you have to do all you could just do it in that time period , though , but it 's a pain .  you 're right . then someday we can sell the unedited versions . right . exactly . i see . see , this is good . i wanted to create some side conversations in these meetings .   cuz we don't have enough asides . and if you do it backward then h good old no , it 's backward forward .  if it makes right . you might as just respond to the mail .  quick question . are , don't you use vi for your mai ? anyway , quick question . how m like , there were three meetings this time , or or how many ? six ? but , no of different people . guess if you 're in both these types of meetings , you 'd have a lot . but how it also depends on how many like , if we release this time it 's a fairly small number of meetings , but what if we release twenty five meetings to people ? in th i don't know .  this time was just the first chunk . that 's a good idea .  you put the reference files ? or the ? no , of the transcripts .  we can talk about it off line . they 're doing w didn't they want to do language modeling on , recognition compatible transcripts or ? right . that we should order a cou t two or three or four , actually . we have sh just get the model number and where do you buy these from ? like ? you just b go and b  that 'd be a good idea . that 's a great ambiguity . it 's one of these it 's social and , discourse level and  see , if i had that little scratch pad , i would have made an x there . it was while i was out of town . we need another eighteen gig disk to be safe .   i do when is this planned for roughly ?    good . each meeting is like a gig it 's really how long does it take you to save the data ?   ","guess if you 're in both these types of meetings , you 'd have a lot . it also depends on how many like , if we release this time it 's a fairly small number of meetings , ",
Bmr027.E,"guess we should stop twenty of at the latest . we have another meeting coming in that they wanna record .  it 's up to you . i don't why is everybody looking at me ? i 'm not what you were referring to .  i wasn't here last week .   hhh .  we 're and then , the new data that don will start to process the , when he can get these before we were working with these segments that were all synchronous and that caused a lot of problems because you have timed sp at on either side . and that 's stage two of trying the same kinds of alignments with the tighter boundaries with them is really the next step . we did get our , good news . we got our abstract accepted for this conference , workshop , isca workshop , in , new jersey . and we sent in a very poor abstract , but they very poor , very quick .  but we 're hoping to have a paper for that as which should be an interesting the t paper isn't due until august . the abstracts were already due . it 's that workshop . but , the good news is that will have the european experts in prosody different crowd , and we 're the only people working on prosody in meetings far , that should be interesting . it 's isca workshop on prosody in speech recognition and understanding , like that some generic it 's focused on using prosody in automatic systems and there 's a a web page for it . ","and then , the new data that don will start to process before we were working with these segments that were all synchronous and that 's stage two of trying the same kinds of alignments with the tighter boundaries with them is really the next step . we got our abstract accepted for this conference , isca workshop , in , new jersey . and we sent in a very poor abstract , but we 're hoping to have a paper for that as which should be an interesting but , the good news is that will have the european experts in prosody different crowd , and we 're the only people working on prosody in meetings far , it 's isca workshop on prosody in speech recognition and understanding , like that ","Additional topics covered more briefly in this meeting are disk space, the DARPA annual report, progress with the demo, conference submissions and attendance, and requests from the University of Washington for data. "
Bmr027.F," it 's the ear plug mike . no . what ? it 's a fairly good mike , actually . i shouldn't say it 's a good mike . all i really know is that the signal level is i don't know if it 's a the quality . ugh ! didn't send out agenda items because until five minutes ago we only had one agenda item and now we have two . and , right . we haven't really started , but we more or less did meeting recorder last week , thought we could do , but i figure also if they 're short agenda items , we could also do a little bit of each .  i seem to be having difficulty getting this adjusted . here we go . as most of you should know , i did send out the consent form thingies and , far no one has made any ach ! any comments on them . no on no one has bleeped out anything .  i don't expect anyone to . but . no . we had spoken w about this before and we had decided that they have they only needed to sign once . and the agreement that they already signed simply said that we would give them an opportunity . as long as we do that , we 're covered . july fifteenth .  jane told me july fifteenth . that 's what i set it . i didn't understand that there was something specific . you y you had i had heard july fifteenth , that 's what i put .  as i said , we got one date and that 's the one i used . but send a follow up . it 's almost all us . the people who are in the meeti this meeting was , these the meetings that in are in set one . right . that 's fine . i we don't my understanding of what we had upon when we had spoken about this months ago was that , we don't actually need a reply . we just need to tell them that they can do it if they want . and no reply is no changes . right .  the reason i did that it was just that people would not censor not ask to have removed because it was transcribed incorrectly , as opposed to , right . when they submit the form , it gets processed and emailed to me .      the only thing i said in the email is that the data is going to be released on the fifteenth . i didn't give any other deadline . my feeling is if someone after the fifteenth says , "" suddenly found something "" , we 'll delete it from our record . we just won't delete it from whatever 's already been released . what else can we do ? ","didn't send out agenda items because until five minutes ago we only had one agenda item and now we have two . we haven't really started , but i figure also if they 're short agenda items , we could also do a little bit of each . as most of you should know , i did send out the consent form thingies far no one has made any ach ! any comments on them . no . and we had decided that they have they only needed to sign once . ","Although the Meeting Recorder group only list two agenda items, this meeting explores transcription, and in particular, consent forms in depth, and at times results in heated debate. With regard to obtaining consent, the group discuss the extent to which they need to attempt to contact people, which methods are most appropriate, and how much responsibility rests on participants being available and checking their e-mail regularly. "
Bmr027.F,"if someone says "" hey , look , i found something in this meeting and it 's libelous and i want it removed "" . what can we do ? we have to remove it . did you read the email and look at the pages i sent ? no . why don't you do that and then make comments on what you want me to change ? i already did decide something , and that 's what 's in the email . and if you disagree with it , why don't you read it and give me comments on it ?  right .  i don't know . you should be . you should be channel b . they 've already signed a form .  and the s and the form was approved by human subjects , that 's gonna be a little hard to modify . here . you can read what you already signed . right . didn't wanna do that , because i don't wanna have a discussion with every person if avoid it . what i wanted to do was just send it out and say "" on the fifteenth , the data is released , if you wanna do something about it , do something about it , but that 's it "" . l let me reverse this . let 's say someone i send this out , and someone doesn't respond . do we delete every meeting that they were in ? i don't think that will happen . that will happen . because people don't read their email , or they 'll read and say "" i don't care about that , i 'm not gonna delete anything "" and they don just won't reply to it . no . we have what they put on the speaker form , which was just generic contact information . thought we had discussed this year ago . and it seems like this is a little odd for it to be coming up yet again .   why don't you talk t morgan , can you talk to our lawyer about it , and find out what the status is on this ? cuz i don't wanna do something that we don't need to . because what i 'm telling you , people won't respond to the email . no matter what you do , you there 're gonna be people who you 're gonna have to make a lot of effort to get in contact with . and do we want to spend that effort ? we had talked about this before and that we had even gone by the lawyers asking about that and they said you have to s they 've already signed away the f with that form that they 've already signed once .    it 's just , we 've gone from one extreme to the other , where at one point , a few months ago , morgan was you were saying let 's not do anything , and now we 're ","and if you disagree with it , why don't you read it and give me comments on it ? they 've already signed a form . and the s and the form was approved by human subjects , because people don't read their email , or they 'll read and say "" i don't care about that , i 'm not gonna delete anything "" and they don just won't reply to it . ","Although the Meeting Recorder group only list two agenda items, this meeting explores transcription, and in particular, consent forms in depth, and at times results in heated debate. "
Bmr027.F,"we 're saying we have to follow up each person and get a signature ? what are we gonna doing here ?  then we had better find out , that we can find a right . for th    right . sending lots of spam .  how far do we have to go ? do we need to get someone 's signature ? or , is email enough ? do we have to have it notarized ?    if they submit the form , i get it . if they don't submit the form , it goes in the general web log . but that 's not sufficient . right ? cuz if someone just visits the web site that doesn't imply anything in particular . right . i 'm already on it .  w for this set , i 'm not worried , because we know everyone on it . they 're all more or less here or it 's eric and dan and on . but for some of the others , you 're talking about visitors who are gone from icsi , whose email addresses may or may not work , and what are we gonna do when we run into someone that we can't get in touch with ?  other methods ?  the qu the question is just whether how active it has to be . because they filled out a contact information and that 's where i 'm sending the information . and far everyone has done email . there isn't anyone who did , any other contact method .  my original impression was that was sufficient , that if they give us contact information and that contact information isn't accurate that we fulfilled our burden .  alright . and we 'll see how many people respond to that email . far , two people have .  right . respond to the email . right . and also if we want it ready by the fifteenth , that means we better give them deadline of the first , if we have any prayer of actually getting everyone to respond in time . right . ugh ! disk space , my god ! i hadn't thought about that . that for every meeting any meeting which has any bleeps in it we need yet another copy of . no , not . you need all the channels . yes . there 's a lot of cross talk . but you have to copy the whole file . right ? because we 're gonna be releasing the whole file . it 's just i hate deleting any data . don't want i really would rather make a copy of it , rather than bleep it out and then overlapping . it 's exactly a censor bleep . what i really think is "" bleep "" and then i want to i delete the old one , put the new one in . there 's nothing left of the original signal . ","what are we gonna do when we run into someone that we can't get in touch with ? that if they give us contact information and that contact information isn't accurate that we fulfilled our burden . disk space , that for every meeting any meeting which has any bleeps in it we need yet another copy of . don't want i really would rather make a copy of it , rather than bleep it out and then overlapping . it 's exactly a censor bleep . what i really think is "" bleep "" ","The group suggest sending reminder e-mails, although since many participants are local they can be contacted by other means if necessary. Additional topics covered more briefly in this meeting are disk space, the DARPA annual report, progress with the demo, conference submissions and attendance, and requests from the University of Washington for data. "
Bmr027.F,"it would be qui quite easy to get it back again . say again ? that 's true . that 's true . backwards . but , ha you 've seen the this the speech recognition system that reversed very short segments . did you read that paper ? it wouldn't work . the speech recognizer still works . forward but backward . that 's right . good point . a point . i 'm if i sound a little peeved about this whole thing . it 's just we 've had meeting after meeting a on this and it seems like we 've never gotten it resolved .   and that 's exactly why i did it the way i did it , which is the default is if you do nothing we 're gonna release it . because , i have my stack of emails of to d to be done , that , fifty or sixty long , and the ones at the top i 'm never gonna get to . and , right . i this is gonna mean  that 's actually definitely a good point . the m email doesn't specify that you can just reply to the email , as op as opposed to going to the form and release . you can a lot of mailers support return receipt . but it doesn't confirm that they 've read it . right . just a button .  unfor we could do that . but i hate that .  i could put a url in there without any difficulty and even pretty simple mime readers can do that .  reply . i cuz i use a text mail reader . you read email in vi ? you could put wed bugs in the email . what my s expectation is , is that we 'll send out one of these emails every time a meeting has been checked and is ready . tha that was my intention . it 's just  that we just happened to have a bunch all at once .  is that the way it 's gonna be , you think , jane ? now we haven't actually had anyone go through that meeting , to see whether the transcript is correct and to see how much was missed and all that at some point we need to do that . the one thing i noticed is it did miss a lot of backchannels . there are a fair number of "" yeahs "" and "" huhs "" that it 's just that aren't in there .  yes , yes , . they 're not in the segmented . it 's not that the ibm people didn't do it . just they didn't get marked . there 's another meeting in here , what , at four ? right ? we have to finish by three forty five . u uncertains . web master .  spit upon ? no , these are ours . that 's ","what my s expectation is , is that we 'll send out one of these emails every time a meeting has been checked and is ready . now we haven't actually had anyone go through that meeting , to see whether the transcript is correct the one thing i noticed is it did miss a lot of backchannels . they 're not in the segmented . it 's not that the ibm people didn't do it . ","Transcriptions are back from IBM, and the group discuss the checking of these, particularly since the pre-segmenter has interfered with back-channel data. "
Bmr027.F,"but i bet they 're acoustically challenging parts anyway , though . really ? it 's it 's just jargon . it probably won't do any better . did i say that ? that 's exactly why i put the extra option in , is that i was afraid people would say , "" let 's censor that because it 's wrong "" , and i don't want them to do that .  ugh ! it 's probably impedance matching problems . but  they 're just earphones . they 're not headsets . they 're not microphones . but if you need it , just get it . come on . w could you email out the brand ? cuz sounds like people are interested .  the only one was don wanted to , talk about disk space yet again . you meant the disk space . we know disk space is short . it was really goo we 'll give you one then . no . soon ? no . ne new disks . on  once they come in . if you 're desperate , i have some space on my drive . but i vacillate between no space free and a few gig free .    a hundred gig here , a hundred gig there . it 's eventually real disk space .   or she 's getting a good early start . when we remember to fill them out .  and don is gonna be helping out with that .  did you wanna talk about that this afternoon ? not here , but later today ?   we were gonna do status of speech transcription automatic transcription , but we 're running late .  fifteen minutes .  if you wanna do a quick ten minute we can skip the digits . whatever you want . what do you have to say ? i 'm interested ,   no . we were just talking before about alternating the subject of the meeting . and this week we were gonna try to do t automatic transcription status . but we failed . no . did we ?  now we have the schedule . next week we 'll do automatic transcription status , plus anything that 's real timely . whew ! dodged that bullet . th excuse me ?  right , right .  right . when 's it due ?   i don't have a paper but i 'd kinda like to go , if i could . is that alright ? that 's "" no "" . that th hey , if that 's what it takes , that 's fine with me . i 'll pick up your dry cleaning , too . should we do digits ?   go for it .    ","but i bet they 're acoustically challenging parts anyway , though . it 's just jargon . the only one was don wanted to , talk about disk space yet again . if you 're desperate , i have some space on my drive . when we remember to fill them out . next week we 'll do automatic transcription status , plus anything that 's real timely . i don't have a paper but i 'd kinda like to go , ","Checking of the NSA meetings has revealed that this non-native English meeting data contains transcription inaccuracies due to the use of foreign language terms and technical vocabulary. Additional topics covered more briefly in this meeting are disk space, the DARPA annual report, progress with the demo, conference submissions and attendance, and requests from the University of Washington for data. "
Bmr027.G,it 's wired .  ,,
Bmr027.H,"damn ! those those are  s when am i on ,  hello ? hello ? alright . the ,  we should say in w when the whole thing starts , when they sign the agreement that specify exactly what , how they will be contacted and they can , they can be asked to give a phone number and an email address , or both . and , then right . a and , then , say very clearly that if they don't if we don't hear from them , as morgan suggested , by a certain time or after a certain period after we contact them that is implicitly giving their agreement . right . says that . right . if that 's i tha if that 's already if i see .   what does it say about the process of , the review process ?   right .   that 's that would be great if but you should probably have a legal person look at this and make it 's because if you , do this and you then there 's a dispute later and , some someone who understands these matters concludes that they didn't have , enough opportunity to actually exercise their right no . that will happen . do we have mailing addresses for these people ? no .  then    we do it like with these we can use it we can use a ploy like they use to , that when they serve , like  like dead beat dads , they make it look like they won something in the lottery and then they open the envelope and that right ? because and then served . you just make it , "" you won go to this web site and you 've , you 're "" right . no , it i it might i it might be the case it might right . it might be the case that this is perfectly this is enough to give us a basis t to just , assume their consent if they don't reply . but , i 'm not me not being a lawyer , i wouldn't just wanna do that without having the expert , opinion on that .    i have an idea . you reverse the signal , it lets people say what they said backwards .  no . in this i 've seen this recently . i got email , and it i if i use a mime capable mail reader , it actually says , click on this button to confirm receipt of the mail .  right . no , no . this is different . this is not i know , you can tell , the , mail delivery agent to confirm that the mail was delivered to your mailbox . but , no . this was different . ins in the mail , there was a ","w when the whole thing starts , when they sign the agreement that specify exactly what , how they will be contacted a and , then , say very clearly that if they don't if we don't hear from them , as morgan suggested , by a certain time or after a certain period after we contact them that is implicitly giving their agreement . because if you , do this and you then there 's a dispute later and , some someone who understands these matters concludes that they didn't have , enough opportunity to actually exercise their right do we have mailing addresses for these people ? ","The group suggest sending reminder e-mails, although since many participants are local they can be contacted by other means if necessary. "
Bmr027.H,"th there was a button that when you clicked on it , it would send , a actual acknowledgement to the sender that you had actually looked at the mail . but it o but it only works for , mime capable if you use netscape like that for your n right . no , no . you can do that . you can put this button anywhere you want , and you can put it the bottom of the message and say "" here , by by clicking on this , i agree i acknowledge "" right . no , no . i actually don't . i 'm just saying that if ev but i 'm    there 's these logos that you can put at the bottom of your web page , like "" powered by vi "" .  d does washi does uw wanna u do this wanna use this data for recognition or for something else ?  i see . and these the parentheses were f from s   discourse markers . discourse markers . discourse markers .     how often ? but but but we don't our language model right now doesn't know about these words anyhow .  un until you actually get a decent language model , @ @ adam 's right . you probably won't notice a difference . but it 's it 's definitely good that these are fixed .  c return the old ones . you have spare headsets ? you have spare headsets ? no , no . just earphones ?  because i , i could use one on my workstation , just to t because sometimes i have to listen to audio files and i don't have to b go borrow it from someone and  no problem .  right .  have a pair that i brought from home , but it 's f just for music listening and it 's not nnn .  anyway . the disk space was short . that 's what too . the d the internal the disks on the machines that we just got ? or extra disk ?     what ? i i 'm not actually , i 'm not what ? are we supposed to have done something ?  alternating .  we did that last week . right ? we did .  we really haven't done anything .  the next thing on our agenda is to go back and look at the , the automatic alignments because , i got some i learned from thilo what data we can use as a benchmark to see how we 're doing on automatic alignments of the background speech or , of the foreground speech with background speech .  but , we haven't actually  it 's called prosody to  can i go next ? because i have to leave , actually . ","but we don't our language model right now doesn't know about these words anyhow . you have spare headsets ? because i , i could use one on my workstation , the disk space was short . the next thing on our agenda is to go back and look at the , the automatic alignments i learned from thilo what data we can use as a benchmark to see how we 're doing on automatic alignments of the background speech or , of the foreground speech with background speech . ","Checking of the NSA meetings has revealed that this non-native English meeting data contains transcription inaccuracies due to the use of foreign language terms and technical vocabulary. Additional topics covered more briefly in this meeting are disk space, the DARPA annual report, progress with the demo, conference submissions and attendance, and requests from the University of Washington for data. "
Bmr028.A,"and we 're going . the only status ite first of all we h haven't decided whether we 're meeting recorder data issues , or recognition this week . we were recognition . you only sent me one thing , which was demo status . and asking which one we were on this week . should we simply assert that this week we are recognition , and next week data issues , and ? and , what we should probably do is any quick , small we can do every week . like morgan asked about the demo status . we can go ahead and talk about that a little bit . and then do then alternate in more depth .  actually , i may not be here either .  i gotta double check the dates . but , anyway . demo status . first of all , i did a little thing for liz with the transcriber tool , that , first of all , it uses the forced alignments , that the words appear , in their own segments , rather than in long chunks . she said that she thought that was a much better idea for the other she 's working on .  and that works fine except it 's even slower to load . it 's already pretty slow to load .  and the transcriber tool is just not very good n at that . correct . it 's just writing conversion tools from the format that the aligner actually th he did a srt file for it . and then just back into transcriber format . my decision was , for the first pass for this demo that liz was talking about i decided that i would do , only enough to get it working , as opposed to any coding . and the other thing i sh she wanted to display the stylized f zeroes , they 're called ? is that right ? and , what i did is took the file with those in it , converted it that it looks like an audio file . and , you s it shows that instead of the wavefile . and that 's working , and it actually looks pretty good . i 'd like someone who 's more familiar with it to look at it because when i was looking at it , we seemed to have lots of going on when no one 's saying anything .  no . i the audio file you can specify any sampling rate . and s i specified instead of , sixteen thousand or eight thousand , i specified a hundred .  and , the only problem with that is that there 's a bug in transcriber , that if the sample rate is too low , when it tries to compute the shape file , it fails . and crashes .  but the solution to that is just , set the option it doesn't compute the shape file , and it will work ",,
Bmr028.A,"and the only problem with that is you can't , zoom out on it . you can zoom in , but not out . the shape file is if you think about a wavefile , sixteen thousand samples per second is way too many to display on the screen . what transcriber does , is it computes a another thing to display based on the waveform . and it displays it at and it allows you to show m many different resolutions . there 's a little user interface component that lets you sh select the resolution . and if you don't compute the wavefile , you can't zoom out . you can't get a larger view of it . but you can zoom in .  and that 's alright , because at a hundred samples that 's already pretty far out . and , think it looks pretty good , but i 'll let liz look at it and see what she thinks .  we should if you were having problems with the words , we should figure out why .  you c you clip that part over your ear . anyway . we 'll all watch liz play with the mike .  no . it doesn't have to , but that 's i find that 's the only way to wear it . is that the bud 's in the ear and that the link is over it . but , anyway , that looks pretty good . the only other thing we might wanna do with that is be able to display more than one waveform . and that actually shouldn't be too slow , because it 's much lower resolution than a full waveform . the problem with it is just it does require coding . and it would be much better to get , dave gelbart to do that than me , because he 's familiar with the code , and is more likely to be able to get it to work quickly .   i understand what right . ps but for the demo it doesn't matter . i 'm not whether you wanna do the demo live anyway , or just screen shots of what we have . the problem with doing it live is it takes long to load , that , w i was talking to dave gelbart about that and it 's not actually the parsing of the xml raw that going from the xml to an internal t tree structure is pretty fast . but then it walks the tree to assemble its dat internal data structures and that 's slow . no . but what it does is it actually assembles all the user interface components then . and then displays all the user interface components . yes . a new transcript . or audio file . actually the audio files are pretty fast , too . right . the only problem with that is if anything goes wrong or if you wanna switch from one thing to another . ",,
Bmr028.A,"that 's true . we could just subset it . that 's a good idea . that 's actually probably the right thing to do . just take f ten minutes instead of an hour and a half .  that 's actually the definitely the way to do it . that 's a good idea . if there are any problems . even five minutes is probably enough . that 's what i did .  just ask just come by my office . show you as right . and for the information retrieval , don has been working on that .  it looks like it great . think for the l liz was talking about , we have something that 'll work now . and liz can look at it and see if she wants anything else . we can work on doing displaying multiple or displaying one and playing back the other . 'd h i 'd have to ask dave . i did it once before and it was just slow to scroll , that i gave up . but , the advantage is that these things are much lower sampling rate . and then it might be alright . tcl . we could check . i don't think they do . there was actually a java back end that is actually a little faster . it generates byte code . but ,  e everything is faster than tcl tk . it 's a string substitution language , i should probably beep that out in case john osterhaut ever listens . but it is wonderful . it is , for prototyping and user interface . it 's just really the language is awful . beep , y right . but let me tell you how i really feel .  that 's right . then the other issue related to that is data release . if we wanna show this in public , it should be releas i , haven't gotten any other replies from the original email asking for approval . sent out another set this morning . and , we 'll see if we get any responses . very good . did you notice i put in the filter ? go ahead . there 's a link there that now says if you want to search by filter by a regular expression , you can . i put that in just for you . it 's actually an arbitrary regular expression . but if you search your name , you 'll get all of the things you said and any time anyone said your name .  correct . it 's hard to find .   you really do have to that 's right . and it demonstrates why it doesn't work , because you really wanna go acro more than one meeting . and you need a better user interface for displaying the results .   really . that 's right . th we do have that bi marker is that , n ",,
Bmr028.A,"because we all know we 're being recorded , whenever anyone says anything like that , we then have a conversation about bleeping it out .   and also we actually have a few people who have still not filled out speaker forms . specifically in the nsa ones , and i noticed that when i tried to , generate the transcripts for nsa . that there are a few with no speaker forms . and i have a i sent out yet another this morning , which makes six total emails that i 've sent to these people , and think we need to escalate to some other method of trying to contact them . nope . if i could find phone numbers , that would certainly work . but . that 's a good idea . i 'll ask her if she can con track some of them down .  i didn't actually see who they all were . a couple of them were people at ibm who were here for one of the ibm meetings and one a guy from sri who was at one of the sri meetings . and those might be harder to track down .  they were people who didn't have accounts at icsi , they 're harder to find . am i about what ? there were other people also . there were other c other people also who didn't ha fill out the speaker forms , in addition to the n s    right . none of the e emails bounced , know they 're going somewhere . that 's all i have . you wanna talk about recognition ? j t liz , you wanna talk about recognition ? thilo , you wanna talk about recognition ? backchannel . it combines them if it 's if the pause is longer than right . the trade off is you get longer utterances , but you miss fewer utterances . take a look it 's , funny looking at some of the transcripts . i was filtering by person , and in one of the early meetings , one pers particular person , almost the only thing they said the entire meeting was "" , "" . it was just a whole list of them . it was very funny . do we know about disk ? abbott disk ?   couldn't format them . no . the only reason i 'm asking is , you 're gonna need space to split them up . and wanted to make we had some available for you . we 're we 're still for another couple days , then ? we 're for a couple weeks , then . y he just didn't say when .   i 'm he 'd appreciate that . m my feeling about that is p is p that 's the point . it 's jane that we have to coordinate that through . ",,
Bmr028.A,"what i was gonna say is , as soon as possible , and i 'm willing to not work for an hour to get it done . but because when abbott 's right . because when abbott is down you can't work . but , the per the people it disrupts the most are the transcribers .  early next week . and just as long as we have a little warning . just not during that time when it 's down . but that it should be down for an hour . right . no , we can store them here . we can store them here . you we just run the risk that if you have a crash we lose the data .    anything else ? excuse me ?  we have a kernel on popcorn , too .  input reader and an output stream .  that 's the point . if you right . quicknet is a very stream based library , without too much effort , once he has the classes written we can incorporate it into all the standard tools .  and at some point , i 'd like to get back to , porting quicknet to the multiprocessor linux box . i have forward passes working , but i haven't done training yet .  that 's right . that 's the thing about it , is that i since it 's coarse parallelism you don't have to do anything special . that would be a fine use for b for that machine . five more processors .  that 's really hard . it 's not determined . the first pass is throw out words which are overlapped . that would be a good first pass . just ignore everything that has any overlap . right .  eighty percent .  but for a but , for s for scoring , you can do it or not do it as you choose .  n but you can use the when you 're doing the scoring since you 're gonna be scoring against transcript , you can use you 're doing that anyway . ch chea try to cheat in the same way that you 're doing with the close talking . right .  just do or a free ri  they 're all gender dependent . we would have to at least do that . and pick whichever 's better . s does the clustering ? do you give it target number of clusters ? or is it ? adapted in some way ?  that 's what i 'm just thinking one of the big differences with broadcast news and these meetings is we have m many fewer participants . speaker id .  there 're different ways of thinking about it . that would be true if w you had a meeting situation with multiple mikes . but if you only had your pda sitting in front of you and you have more than one mike . ",,
Bmr028.A,"just from clustering . you might be able to cluster it better because of that . from mike .  and transfer functions . there 're lots of ways of doing it . that 's an interesting it 's a big difference .  humans are really good at that transfer function through the head , and things like that . even if you only have one ear , you can still get good transfers .    something .  it 'd be to see if it helped . that would be ft quick , since he did it in matlab .  can't you export c from matlab , or is that mathematica ? just take the inverse and you 're fine . that 's a speech detector . that 's great . just subtract that subtract that from the original signal and you 're set . noise estimate . signal to noise . that 's great . that 's why herve always talks about using the priors as one of the mixtures in his all ways combos . but still if you run er , your recognizer with all probabilities equal , what do you get out ? probably garbage . i bet the pruning the pruning probably prunes everything out . that 's right . different . but they are channelized ones , though ? right . cuz you haven't done any training . right . cuz we 're not doing it for training . right . it 's really it would be really easy to re do it . it 'd be interesting just to see i how much it changes . i bet it wouldn't change a lot . we can take we can have a pool . that 's just what i was thinking . i we know about it . tran transcriber will export stm . in case you care .  right . right . but if the segments change , that won't work . what happens if you break one segment into two ? suddenly the don they don't match and you can't line them up anymore . right . does stm do it per word , or por per utterance ? th what alright . and then it does also some within the segment .  i see . one percent . all al all we mean by that is that we 're giving the recognizer more information than it would have if you were running it raw , over a meeting that no person has ever listened to or transcribed . it is . it 's us it 's using information you wouldn't normally have .   we 're not de legitimizing the data . we 're de legitimizing the experiment . we 're not saying that the data is cheating data . we 're saying th we are cheating by using this data . because normally you wouldn't have that data available . shoot . just the clip . it 's p it really is part of the jargon .  that 's what i was saying . ",,
Bmr028.A,"and it 's used for a lot of different types of data . segment whether you have segmentation or not , is it male or female or not do the signal to noise ? like , that 's another one i see all the time , where you assume it 's known . and you say it 's cheating because you don't actually compute it . n right . same cheating .  it 's not even really negative . fine tune little bits .  did you read the paper ? what this w right . what would this be like if w it were perfect ? if this component were perfect ?  it 's too hard , usually . it 's not pejorative but , it 's not pejorative towards the data . it 's pejorative towards it 's pejorative to o ourselves . right ? to say "" i am cheating in this experiment "" is not saying that the data is bad . it 's saying that my experiment is bad .  right . i haven't gotten back to that recently . but i assume you 're saying you want me to get back to it .   you can , but you 'll lose a lot of data . but , that doesn't really help because often the recording person isn't in the room . what are you gonna do ? it will w the person if you 're looking up at the board and i disable the screensaver , you will see that the mike is off , but that doesn't necessarily help .   it 's just hard to tell between that and just someone not talking .  right .  we should be getting new equipment in , we don't have to use the earplug any more . it 's your hair . y d you can do check , but it will be very hard to tell the difference between that and , someone not talking . no . little bit of noise . i use a threshold . if it 's below a particular value , it flashes yellow . as i but it 's not perfect . probably . this is the reason why i haven't gotten back to it , is cuz my first pass at it didn't really work because all the mikes have different noise levels . and have to do something a little more clever .    there 's the s the standard deviation of the signal gives you a good clue . if that is too low , then you can be pretty that it 's , empty . right . exactly .  is there a ? far field .  we 'll just we 'll just have to note those . we can't throw away that data , cuz otherwise we 'll end up with very few meetings . but do we have a ? i 'm for interrupting . do we have an edu meeting at four ? great . good . ",,
Bmr028.A,cuz otherwise i was gonna say we have to cancel . a simultaneous digit . everyone ready ? s reading simultaneous digits ? three ! two ! one ! and ,,
Bmr028.B,"that 's correct .  do you have to pad that out ? that it looks like it 's an eight kilohertz sampled thing ? or ?  seems like you should be able to spawn that off into a background process , because not everything is displayed in that tree at once . right ? right . seems like you wanna ass did you actually look through your transcripts ? or you just approved them all . approved all mine . i didn't look at them . that 's a compliment to you . he said it 's hard to find things you say wrong . find everything that should be bleeped . i haven't done anything . i was i was away for a couple of days .  i haven't done a what does the two second threshold mean ?  i wouldn't think that the language model would continue across two seconds . wel he had a problem . right ? h he did , and then it didn't work , and i didn't hear anything after that . he didn't say he hasn't said anything to me about it .  he they 're stored on popcorn .  i 'm rebuilding the net that we 're gonna use for the tandem and what i 'm doing is , putting in the stream reader into the quicknet libraries for the sri feature files . an which is the right way to do it . when we did our first experiments and i was , creating sri feature files from the icsi front end , had perl scripts , and hacked a bunch of together just to get it going . but the r the right way to do it is to integrate it in with the icsi tools . and that 's what i 'm doing now . and once i get that done , then i 'll generate the p files i need . cuz we already have the feature files in the sri format . what i need to do is , make it that the quicknet can read those . and , it 's both . there 's a there 's an input stream and an output stream .   then it 's t tandem experiments after that ? we don't have too many . we just have that just have a few linux machin whatever the language model says . d do you think the battery ran out ? or ? ",,
Bmr028.C,"wha what was on the list ? th the i sent you a couple things , although i don't remember them . right . that was the second thing . right . right . i 'll i won't be here next thursday . i 'll be out of town . but what 's a shape file ?  i see . this bud 's for no . i don't know . u i 'm confused . is this downloading something that happens once ? and then when you d display different things , it 's fine ? in that case a new meeting , a transcript . right . but i for but for for presentation in , wouldn't be go wrong ? i see . you 're downloading a whole meeting . that @ @ .  and then still do it ahead of time , but then at least you 're covered if , if there 's a problem . i 'm gonna start working on this the week after next , that 's the point when i 'll need to look more carefully at what y what you guys have . right . the week after th the monday the week after next is july second , which is the first day i get back .  i 'm giving a talk on july sixteenth . it 's a mon monday in four weeks ? three weeks ? it 's always exciting to hear that java 's faster than something .  beep . we 're all entitled to our opinions here . it 's it must be three and a half weeks . cuz july the meeting is july sixteenth through eighteenth . and , my talk 's the first day .  i 'm flying out there the sunday before .  it 'd be desirable if , a week ahead of that , we had thought we had it , which would allow a week for re iterating .   i th i saw that . and it 's case insensitive ?  we have our first information retrieval example . it 's a regular expression searcher .   you wanna say , "" where are al where find all the contentious things i said . ""  right . has joachim sokol replied ? or ? he 's not around , is the only problem . otherwise , it 'd be a good idea . he popped in . but , he 's gone .  and tell her tell her your specific problem . she 'll fix he 's right there .  i in other meetings .  sri people , easy to f find . and , ibm people , also . just let us know .  just we certainly have their email . right . i know they 're in . and , but i don't know . he was wasn't he asking about ? there was an issue . he wanted to take it down . and then he tried wel ",,
Bmr028.C,"markham probably needs u h he probably needs us to approve another time to take things down . right ? in order to do that ? he said in that mail that he would need to take it down another time . think he no . he wanted u us to tell him when . i 'm he 'd love to fortunately , markham 's not a transcriber . but , "" i might not work . "" "" i 'm willing to not work for an hour . "" i know you 're willing to not work for an hour . but , i th i it sounds like markham should almost decide when he wants to do it , and tell us , as long as  we store our data on popcorn . that 's really great . i was just thinking we store our data on popcorn . how many institutes can you say do that ?  g megabytes and mega many megabytes , too . what , what 's on your queue for recognition experiments ? let 's talk about that for a second , what was on his queue for recognition experiments ?    i it was u some  it would be ne neat at some point in this to do , a recognition , pass on one of the pzm mikes for these s same meetings that you 've been gi n gi bi it 's gonna be terrible , but , we just don't know how terrible . and  cuz you have a set of scores about that , then , that wouldn't be bad .   but that 'd be a hell of a lot better than what we do with just these . and and , again , if you rule out the overlap , you have some numbers for that , cuz that 's yet another but , i 'm just concerned , about that cuz you have scores for that for the other case . and we just don't know how bad it will be . one of the things that dave was noticing we were talking this morning is that i it seems like and we do don't know this in detail , but it seems like you 're getting a lot from the channel adaptation , the speaker adaptation , and forth . you are , already , in that recognizer , doing something that is likely to affect , the far field microphone , formant . it may not it 's gonna be bad , but , it may not be won't decode "" bad . it might only be that it goes from forty percent to eighty , like that . i want us to assume the exac whatever it was you assumed when you did the other the close mike . i 'm but you 're saying for this for the adaptation , right . i i have i have a suggestion . do the simplest thing first . ",,
Bmr028.C,"because we 're gonna want to know that anyway . in other words , if you d no . it 's even simpler thing than that , is just that you don't know .  because you can get a number for that with the other as right ? you can turn those things off . right ?   and then put it in correctly and see how much that helps . i was just thinking , do the one that 's easiest first , because you wanna know how much that 's helping you in these cases anyhow .  if you don't have one more than one mike , you don't have a very good handle on location . that 's it 's not enough .   but , say , if you had a cardioid mike sitting someplace , then sitting there , then it would its response to him would be about the same as the response to him , and on .  i see .    but anyway , i 'd it 'd be neat to have that , because we 've been at this for a little while and we don't have any results yet with conversational speech at a distance .  we should at least get a first one . and the other thing this would be a hail mary , but , dave does have this that is helping on digits , and , and with then it 'd be , just throw that in and see .  he can do it in something else . but , it 's  actually , we 're experimenting with phase now , and , thi this , first result he got , was really great . it actually , didn't exactly eliminate the reverberation , but it completely got rid of the speech . i was thinking that . it 's that 's you didn't s tell him that ? no . i got pretty excited , because it completely got rid of the speech . i was thinking "" it could be useful for lots of things "" . we have to what ? we have to check that out . that 's   reminds me of when th when herve and i were first playing with c context dependent things for nets , and at one point we took out the speech input , we only had priors , and our performance went up . s it was a bug . but , it 's a but it was pretty f it was pretty funny anyway . that 's how it was generated . but cheating is p but chea but cheating is pretty commonly used to mean this . it really is  i i i it 's i it 's even more than that . it really gives a very strong perspective , that that what you were doing is not an un biased experiment . ",,
Bmr028.C,"if you don't say that , then people think "" they did that and they threw that , but that doesn't represent what would happen in the real world "" . but if you say "" we did a n cheating experiment "" , which is really the standard way you 'd say it , it says you deliberately put in a piece of me information that you would not have in the real world that you can learn something . just as part as your process . it 's i d i don't know , i i i 've heard this at icslp for years and years , though . it 's pretty common . people say this .  in pattern recognition , or in  right . it 's machine experiments . w when the , the neural net w wave hit in the mid eighties , and by the late eighties there were we were reviewing thousands of papers that were coming out in neural nets . it was really hot . everybody thought it would do everything . and a really common error that people were making was , they were just reporting their , classification results on the data that they were training on . and think it was it was very important for people then who were doing something diagnostic to say "" hey , i 'm doing something that isn't kosher "" . and to make it really clear that they knew it . that was , why it became a popular term . but it isn't bootstrapping . it 's really cheating . it 's just ng  but it 's cheating in a way that 's pril it 's announcing to everybody "" hey , i 'm cheating , by doing this . "" it 's saying it 's all above the table . i 'm actually using this other thing . that 's that 's the reason . bootstrapping would imply it was actually legitimate in some way . but    anyway . it has some shock value . which is part of why it 's used .  but it 's also is right . no , no . it has i don't think you 're saying the data is cheating . you 're saying "" in my experiment , i cheated in this way "" . another is what liz was talking about , how in the switchboard tests in all the switchboard tests we 've been g doing , we 've been making the same er same standard using the same standard way of getting the data to test on . which means that we weren't actually running it on , on data that had no speech . and , in a sense , that was cheating . it 's a good wake up call if people "" we have this performance but you have to keep in mind , we 're doing we 're not doing the whole real task in this way and this way . ",,
Bmr028.C,"but , i 'll convince you that it 's still important for you to listen to what i have to say next because of this and this . "" and it 's just a way of putting it all out on the table , as opposed to    in in the multi band experiments , in the first one , we really wanted to find out , "" what if you knew which band was really noisy ? "" suppose you just know that . and then , even if that , can that help you ? what can what strategy can you do , to do without that particular band in the spectrum ? and that was important to know as a baseline . and then , once you knew that , then s you go "" now how do i know that 's noisy ? "" and and , but , y i should also say that there 's a lot of it 's not just the word "" cheating "" . but there 's lots of other things that we talk about , which , as soon as you go outside of your narrow little group , it gets very , very confusing to people . and i the example i was thinking of , also , was this w thing that herve and hynek and i made about , increasing the error rate . and , we did a number of papers , and talks , and forth about , i the virtues of increasing the error rate .  and and the whole point of it was , not that it was good to increase your error rate , but it was good to be willing to risk increasing your error rate by trying risky things , and trying because there 's this notion of a local minimum , that if you just have some system that 's very complex , and you t you turn some knobs to try to make it better and better , you 'll never get out of this local minimum . you have to be willing to jump to something that 's quite different . and the first time you jump to something quite different , or the first ten times or a hundred times you do , it 's gonna be much worse , because you 've optimized the other system . the effect the immediate effect is gonna be to increase your error rate . and it was we had a couple papers like "" towards increasing the error rate in speech "" and on . and we really did get feedback from a few people , some of whom were , fairly senior , that , "" you sh you c we 're c really concerned about you misleading people into thinking they should be increasing the error rate . "" and , and we go we thought "" come on . "" but . that 's we weren't . that 's why we increased the error rate .   but  ",,
Bmr028.C,"anyway , it 's colloquial , an and , it 's interesting to hear that someone coming from a different direction it s it sounds the way it sounds to you . but , i 'd never heard that before . i that 's interesting .  just it doesn't when the microphone 's dead , it doesn't put out zeros ? or ?  johnson noise ?  but there 's there 's tea , also , though . we should do a , simultaneous digits read . in the interest of getting the snacks . you never have ? it 's a treat .  another successful babble . ",,
Bmr028.D,"it 's more segments ? or ?         th that 's what i did for my talk .     just smooth the output of the detector .   or you can you can use the one with one second or whatever . i there 's no not much difference between the one second and the two second one . and wouldn't it be better to have a little longer sequences for the recognizer ? b because of the language model ? as sometimes it happens that it cuts off within a s but , we can be that as or we can be er not but we can be somehow that there is nothing not no speech between those . it it doesn't it 's the same as in the smoother for the ibm thing .    but but the chunks are already sh i in general , are short . t it would be better to have more of them concatenated together , in order to have better language model or language modeling . i don't know .  do that .  but y there 's really not much difference between the one second and the two second . just take the one second one . i 'm not too afraid ab about that as w when there would be something some background speech there wo there would be a chunk in another channel , and when there is s something in between , i con i do not concatenate them . it 's just when there is when they are sequentially and i wou i would use th  no . we could      but d do you have gender dependent models ? a are the models gender dependent ?         some of these things are captured by by looking at the minimum and maximum and whatever you find in the channels , and but    sometimes you capture that when you mix it together , and   i don't think ",,
Bmr028.E,"it 's slow . the linear fit . that 's just background speech .   we 're talking about that demo . did it ? it migh it 'd be if we can do quick hack , just we can play the audio file , too . with th with the display . like , even if we that even if we didn't display the waveform , it might be better to , rather , play the waveform than display it . if we were to choose i don't know , if i were to choose between one or the other , i 'd rather have it played . and then displayed .    it 's coming along .  just hacking dan 's code and m stepping through it . but , it 's close . and we should be there pretty soon , with at least , like at least with , being able to search over c certain amount of meetings , just really basic just asking fo looking for a word , and looking through a bunch of different meetings . and if we have time , i 'll also add , choosing which speakers you wanna include , and but is the end of the month still the d ?   morgan , when 's the demo ?  for realizing we don't ?   i still have probably six , seven , eight gig on my disk .  whoa ! yea  and then you have the gender detection   the b for the f ? it was m march , probably . something around there . what are the nature of most of the changes ? andreas . really ? it 's just the noise from the connections and the everything .  you could put them at the back of the queue  ",,
Bmr028.F," too .  it could do you have to put it in your ear ? i does it really need to go in her ear ? that bud ? it doesn't have to go in her ear . right ?  but tcl is wonderful . there you go .  i like it . it 's great . talk to him first in person ? that 's what i would think .  is that right ? i saw him on tuesday .  did you ask lila ? cuz i bet she has this information .  and it m and , then there 's still m miguel is still an active member of the group and he 's what is , he 's an active member and he 's still here . very helpful . most of them , though , really were visitors here and lila should have contacts with them . meetings ,  not the ones that are you su ? are you nsa one and nsa three ? we 're talking about those ? i see . fine . but i knew everybody in the nsa meetings . th i 'm that we have , fresh , information on them . good . i bet i know who that was .  i all i need to do is mail , send them m a mail like two days in advance they can schedule their time . i did that with the last outage . i j i wrote to them letting them know that this w was not ,  this is on popcorn ? or ? this is on popcorn  that 's very good . what was the question ?  ooo . i don't like that term . i don't like that term . i don't like that term .  interesting .  that 's interesting . did it get rid of other too , though ? did it get rid of other besides the speech ?  interesting .  interesting .  i wanna ask , that the data i ' v i have upgraded it considerably . 've probably made i probably corrected something like , s it 's really a substantial amount of things that i 've caught , changed added to it . including a lot of , backchannels . when you 're d running things , if you run it on the old if you run it on the new version , then the numbers will be and you compare it to the to runs on the old version , then you 're gonna end up with more of an improvement than would actually be the case . as of february ? l like the hlt paper ? long as you have the same baseline , then you 'll be able to tell . long as i long as it 's the same baseline you 'll be able to tell . ",,
Bmr028.F,"but i 'm just gonn i 'm just saying that if you were to compare that with running that on the new data , that it would be an a more optimistic outcome .  i did . that sounds great . t y i was thinking , th the other day , that this is not just conversational speech . the fact that is has much technological jargon in it . i it makes it u considerably harder to , me e to transcribe and to double check and all those things . you 're gonna find a substantial gain in terms of the word ac accuracy . long as those words are in your vocabulary . all of them are . all of our meetings have a lot of jargon in them . but we those words are . i don't know how you get them into the vocabulary , but it would seem @ @ now , i have to i really need to , raise a question about the term "" cheating "" .  and the reason is , if i understand that , "" cheating "" is a term which is used to apply for what all of linguistics corpus linguistics does , and what my transcribers are doing and what i do , which is a methodology whereby you actually physically mark things in the data . like the transcription , like the words that are actually there . that part is but i do wonder sometimes if it might be possible to use a term that 's a little bit less evaluative "" hand marked "" . what i 'm thinking , is just in if when these are presented in an inte interdisciplinary context , it might be to add that explanation ? cuz otherwise it sounds like a pejorative statement on an alternative methodology ? cuz it sounds like it devalues the , all other approach , which is to put those distinctions in . they can do experiments . it just seems like , i if it were "" bootstrapping "" , or if it were there are other ways to get the point across . hu  alright .    does seem to me that it carries over some baggage with it . that , i that understand it in context as you described it . but , it seems to me that u it does import some negative evaluation , that , would not be good if it has shock value , and to the wr to the wrong audience , that might be t a negative shock . we started with hand marked data , or with , t hand transcribed data , or  did you break the microphone ? nnn . i feel better now . very much . the trouble is , that i understand it in that context , but it is almost resentful . it 's almost like , resentful of the data , resentful of the , the hard work that 's going into preparing the data ",,
Bmr028.F,"is    interesting . i didn't know that .    terminology is always context dependent . no question about it . it 's just that it seems like the point without the negative evaluation would be however , if i understand your point . that it th it has a long tradition in this field i didn't realize . and is used this is interesting what adam said about it being used also for a bunch of other , dimensions .   interesting . interesting .    interesting .  the term itself is .  but it and it 's pejorative with respect to a certain purpose . i understand . i wanted to raise the issue .  anyway . that 's interesting . i wanted to raise the issue , and i , appreciate the discussion . i wanted to ask one other question which is a different matter , which is with respect to , this thing that you 've been r working on for the recording monitoring script ? the idea you had this script that you 're working on , to be that the microphone values are in are kept in ?  cuz , y i was just wondering if i because i am finding that , in double checking , i 've run across , u one data set where the microphone was off early on , and then two other speakers their microphones went off later . and this is out of seven speakers . out of seven speakers , four microphones y three microphones bak flaked , which makes it hard for the data to be used for all possible purposes . that 's what the two that flaked late , it was the battery . but , if the script could , alert the recording person to that i don't know if there 's a way to replace a battery , if it happens in the middle of a meeting . that 's hopeless anyway . but i see . then that raises the question of , whether we should screen the data before they get transcribed . because , although that the data are still useful in terms of providing content , and that , i know that having three out of seven microphones out of commission during some part of the meeting restricts the , usefulness of the data for other purposes . and you don't wanna have it i actually think that thilo 's n in a k a when you do the pre segmenter and you run across troubles he runs across s some of these that are we have some part of that . i c there the and the other aspect of it is , that , when the microphone is not adjusted , then y i even if it 's not a lapel mike , you can get lapel mike type behavior . cuz i 'm expecting , with this , that you 're gonna end up , picking up other peoples ' signals . ",,
Bmr028.F,"it 's just the microphone is intended for certain adjustments . the only argument for doing would be with reference to the content . content maps . but mayb then it should be done in the old original way , w instead of channelizing and having the , elaborate coding of the backchannels . and actually , an alternative to even doing that level of transcription would be to have a transcriber listen and m just i don't know if a transcr someone who 's associated with the meeting could have summary of points handled in the meeting . if we could pay one person who knows that subject matter to do an outline of the meeting 's content . instead of losing the content altogether . the troub trouble in my mind is that it 's not a very neat corpus if you say "" these data are available , but these are imperfect , because of the f the batteries flaked . "" and we have many . we have such a backlog . to be able to get through the backlog of the good meetings , it would be to not have energies diverted . that 's fine . good question .     ",,
Bmr028.H,"tried that , and it died . great ! i got the wavefile but i got the wavefile , but i couldn't get the words yet . but the wavefile part looks good . i 'll have done i 'm probably doing something wrong . this microphone 's moving around . i can't put this over my ear . do that but there 's no orientation where the darn !  right .   right . right . for the demo you can always play just store the pieces that you 're gonna display and play those as separate files , if we can't , actually do it . but it 's it 's  and just make it l right . right . what happened to is it st possible to display the words in their aligned locations ?  i missed great ! but it  i couldn't get the words and the waveform at the same time for some reason , and there must be some i 'll work on it with don and see what i 'm doing wrong . great ! lot . that 's really great . do you think it 's reasonable to display more than one before the demo ? cuz  right . let me know . did it . but it is i did wanna say that , no ! no ! no ! figured you p my gosh .  terrific . since you didn't answer the emai there was a q question i had asked adam whether it 's possible to search only for your own name your own utterances , that you don't have to go through the whole meeting , and and i didn't hear back . thought "" it 's probably too hard . he 's overloaded . i won't say anything . i 'll just do it "" . great . anyway i looked at everybody else 's stu good . th that 's great . that 's great .  i spot checked . i was trying to remember i couldn't find the keywords for things that had said wrong .  that makes it g it 's hard to find anything that you say in these . great . for the filter . it 's really useful , tha cuz if you 're only at part of a meeting ,  that 's actually it 's useful . but this helps a lot . great . right . we you can search for "" beep "" or "" bleep "" . in somebody else 's turn .  we 're in a stage where we 're don 's going through getting some of the next meetings that jane s has . and , creating a second database . we haven't actually run anything yet . we need to get a critical mass for that . and check the segmentations .  great . a what do a different pause threshold ? do ?  no , it 's not bad . that 's good . i ye th u ",,
Bmr028.H,"i th that 's g that 's good . it 's no more than six words . roughly . on average . that 's pretty good , it 's better than a  y you do , becau it 's better . the longer is better . there 's th there 's a l there 's a lot of these cases just like now , where i c people say "" when they 're trying to ta and there 's about a half second pause to a second in between and then another word , and it 's much better if we can keep those together , you just fake the format that you take as input with the synch times to a new set of synch times , and  and i have like another un backed i ha have another six gig , which jeremy , if you 're not using , can on xa . to you . how about during the picnic ? beep . you 're really dedicated , if you 're no matter how you parse that one . that means we can't , save meeting data either . right ? it just can't we can't have two meetings in a row where the first meeting 's during that hour . that 's all i meant . that 's happening today . temporarily . no . i mea the fir jus n run all our jobs on your machines .  ye it 's also an interesting problem to come up with the reference . the reference file for the relative times at which  i it 's an interesting question , because i was thinking "" you can force align the transcriber transcripts , and then you try to merge them in time . but how do you score ? "" it 's just an interesting problem . right . there 's a whole dis right . we right . but there 's a whole interesting discussion , cuz the alignments are not perfect either , and we actually don't have a p it 's worth trying . i right . right . i see . when only one person is talki yes . we could try tha right . right . exactly . we should try do you assume the speaker when you do this ? th r there 's only one person who it can be , because they own that microphone . i 'm just wondering there 's no it 's not a pro right . and r right . but in terms of for norm for adaptation . right . do you do a supervised adaptation ? ye all of these adaptations ha assume that the same person  n i was just aski actually , the s those are two the simplest thing is you cheat , saying you m y unadapted . right .  i no . you can you can use a speaker what about gender detection ?   you can r no . you can run both . and you can s ",,
Bmr028.H,"the other thing is that you actually have direction here . unlike these corpora that are recorded with other microphones , like the right way to do this w in the future would be , in general , thilo 's sitting there , and this pzm is gonna he 's roughly in that location . any case where the people are not all sitting at the same place and they 're not moving around too much . w you have distance , and you have that , jane 's i n the pickup of adam on this mike is gonna be different than me , in terms of energy and forth over the whole meeting . you might get some clustering from the speaker and some of it from the characteristics of the distance , and right . exactly . they 're both picked up in the clustering , or to just do the clustering , knowing that you 're capturing both . it 's just that the clustering we 've done before hasn't had that , distance factor , or location factor in it in the same way . and we 're not really modeling it directly . if somebody does , we sh we add that because it would be a pretty big difference . when you listen , you can tell where people are , not which s side , but right . even with one microphone . right . our clustering is not gonna be intelligent that way . it 's just gonna pick up whatever energy difference , or whatever , is     f for these meetings ? right . they 're somewhere in between january and late march , like that ? n n they 're meetings that are now channelized , but they were not from we haven't a modified the recognizer actually , at some point we should update and rescore everything with , the corrected transcripts , just to h sometimes the changes are , cases where the recognizer would get it wrong anyway , cuz it was some word that we didn't have in the vocabulary , or but it does help to get the backchannels back in , and things like that . would that ? doesn't that only change the scoring if a word has moved into a different segment ? i don't think that 's har i hardly ever see that . most of them are pretty good . you would need to re run the recognition . if you re ran the recognition , then you just run it i see . if you wanna use the old you can actually never , though , really infer what you would get with a different it 's probably more fair to re run the whole th re run that . in other words , it 's not really a scoring script problem . it 's y . you it 'll work , but it 's not exactly what you would get from recognition . you never know . ",,
Bmr028.H,"you c you s you can    it definitely helps with , forced alignment , too , because , whe when we know the true words and we 're adding them to the vocabulary and training a language model and forth for future meetings , especially the like , the front end meetings or meetings with a lot of jargon in them , that is not represented in switchboard or callhome , then it really helps .   it it 's been around for a long time , and it 's because it 's strong a word , people don't take it that in it 's not negatively viewed . it just really means actually , jane is right . like , in conversation analysis , i 've never heard people use this , because they 're not using an automatic system . it really right . i 'm j you can do experiments , but the it 's cheating relative to what we call a system where we can completely control this black box . and it 's not a very smart system . it only knows what we give it . and if w if it knows more than we would really give it when it runs , we call it cheating . but it 's it 's f only used in a community that does some type of computational modeling , it 's really not used in any community doing experiments on human perception , or she certainly can define it . i thi to the wrong audience , i agree that , p to the wrong audie we should just explain what it means here , and that it 's a common term , and we 're  the first time i heard that , the same thing and you ju after a while it becomes almost a it 's a bu bit of a humbling thing when somebody says that . if they get good results but we were cheating on this feature because we took it for granted even though we can't really assume that , then it 's actually the opposite . it 's it 's it 's actually , of cheating as a way to do some work , where you can't address all of the computational tasks . like , if we wanna study , speaker habits , but we can't do speaker detection . but we wanna assume let 's say , we know this is jane and we know this is chuck , even though automatically to look at the habits , we would need to also first figure that out . but we can cheat on that factor because it 's somebody else 's research . and then we just it 's then we wanna make a proof of concept for if someone else right . or w but we really can't work on that problem . we don't have time , we 're not interested , or w whatever and you assume it 's given ",,
Bmr028.H,"because it 's , you wanna go forward with your research , and assume that you have that information .  if i don't ever think of it as negative . more like , it 's something we 're not building .  that 's a really good idea . because for all kinds of studies , we don't really enjoy meetings where some of the where the signal 's going off at times . it just makes it hard to study any parameters .  if there 's a way to check the signal quality before transcribing it and you find any problem it 'd be much better to go to another meeting , i 've already written some notes here ,  right .  but it 's my ear . i 'm it 's something wrong with my head , but actually , is there a way , though , to use whatever you 're using for background noise to check post hoc that a microphone was constantly on ?  like this o but then how are y how are you detecting during a meeting ? but is it better than nothing ? cuz it would really be right . but you could you could run that post hoc on a already recorded meeting , in the sense that , not everyone as you just said , you won't be there . and then if we find any problems , have the transcribers listen and i really think it 's better not to transcribe a meeting that 's gonna have problems once you 've spent all this effort .     i 'd mu we 're i 'd much rather have , meetings that have all the channels , even if we had to skip a meeting just for all these other purposes .   right . but may just right . there but there 's a shortage of trans transcription power .  what ? they can their four o ' clock cancelled , and they 're starting at four twenty , and i 'll set up at four fifteen .  you 'll have si you have to plug your ears or just prepare not to laugh . ",,
Bmr028.I," that 's great . is that because the transcripts get longer ? the f transcript file gets longer ? but th but that 's n you didn't have to change the software for that yet . right ? it 's just formatting the right xml ?  good . that 's very good .  right .  right .     this the this the sluggishness of the loading is all due to the parsing of the xml format . right ?   but d y no . whenever you load a new meeting or a new transcript . right . you just have to have the thing running before you open your laptop . just make shorter files .  you missed that part . if raw speed is the problem this thing is written in tcl . right ? y john osterhaut , he started his own company based on tcl and they have the native code compiler   darn . i haven't done that yet . er stalk them @ @ at their like in the morning , when i leave for work . cold calling at lunch time ? dinner time , chuck , you wanna talk about recognition ? however , got an email from thilo saying that we are ready to run we have segmentations for the old meetings that are from his segmenter , and you had three different versions , with different pause thresholds between the segments ? right . and you recommended using the one with two s maximum of two seconds ? but two s  the only advantage to using the longer threshold would be that you run less risk of missing some speech . right ? but two seconds is pretty long .      two seconds i would go with one second . i don't know , it 's a see what the length distribution is .  really ? bu i 'm i 'm just scared that with two seconds you get , you get false recognitions . you 're gonna you 're gonna hurt yourself occasionally by having missing the language model context . but you might hurt yourself more by having misrecognitions due to background speech , or , y noise , or whatever . i see . then i see . right . that 's  we can try them all and see which works better .    we need to split the waveforms , then . or do you already have them split up ? no , you don't . right ? don would need your help to create a new set of split , meetings . if right . but th there 's that pressure . i 'm   pop goes the data . right . u un can i have butter on my meeting ? i is that independent or related to also being able to write out the , feature file i in the sri format f r then you could use , like feacalc and s just specify as an output format the  ",,
Bmr028.I,"th t i 'm just ignorant about the sof software architecture of this thing .   great . b speaking of linux . th there 's some i impetus at , sri to actually u p th build support linux as a platform .  what that means is , once we have , everything running on linux we can also use a li exac if you can't use all the processors on whatever machine , we 'll help you with that . right . exactly .  it 's just ,  or if in the future , if linux machines become like way cheaper , than , solaris machines , then that wouldn't be a reason not to use linux anymore .  for the meeting ?        right . right . right . right . you just di you just right . that becomes another problem , actually . n s d s fo not for everything . for s for f even feature normalization , for , vocal tract length estimation , all of these assume who 's speaking .  you would have to do a speaker segmentation first on the far field micropho signal . you wanna cheat . no . if i we g we 're gonna bleep that out . you do you don't do all those normalizations . actually we don't have any models . you can  a actually , it 's that it 's we would have to retrain models that are not that have none of that in it . but actually we could we can just run it , assuming that it 's all one speaker , and see what happens .  actually actually , no . th   no , actually no , actually , what here 's what we would usually do u under these circumstances . we would actually we would run some segmentation . thilo 's is as good as any , probably . and then we would do an unsupervised clustering of the segments , to and put the similar ones into bins that would be pseudo speakers . and then we would do our standard processing on these pseudo speakers . and that turns out to work very on broadcast news , spine those types of tasks , where you don't have the speaker segmentation given to you . you can either do it by target number or by some measure of dissimilarity that you use as a threshold . right . you can do you can you can do certain normalizations like , gain control , before you do the clustering to rule out those types of things .  that would be fun to try .    then we should first you have to filter the whole training set and retrain .  that would solve all of our problems . wouldn't it ?  right . then you can do like an you can estimate the noise estimates . right ?    you get out switchboard . that 's just the lang the language model . ha we have this new speaker adaptation .  ",,
Bmr028.I,"a b it 's a s feature normalization t like f speaker adaptation , which , which i wr which i wrote about in the last status report , which seems to be helping about a percent and a half on hub five . we haven't tried that yet on the meetings , but hopefully it 'll help there , too .   we have a frozen we do all our experiments with a frozen version of the transcripts as of , i don't know a as of no , a little i don't know . when did we grab the transcripts ? the we 're talking about which version we 're using for evaluating the recognition . which version of the transcripts . no , no . o the the other thing is th the and the and the other thing is , it takes only a minute to rescore all the old outputs with if you had new transcripts , then we j we just re rescore the old  w we just we save the right . i when right . whenever the right now , the s the scoring is based on segments . which is not great because , the other way to do the scoring is using a nist format called stm . s segment time marked , where i have to convert the , transcripts into this format , and then the scoring program actually looks at the times . and , it you can have a different segmentation in your recognizer output than in your references , and it will still do the right thing . that 's what we need to to   but then there 's other changes . there 's other we strip away a lot of the mark up , in the transcripts , which , isn't relevant to the scoring of the speech recognition output .  no . if suppo i assume you also changed some boundaries . right ? if we want to use new transcripts with a different segmentation , then we can't use them in the current way we do scoring . we have to m switch to this o no . we have to r there 's a difference right . right . that 's true . no . but if you w just want to see what like , suppose you fixed some typ no , jane fixed some typos and you wanna see what effect does that have on the word error , then we can f we c no , but that 's what the pr that 's what i 'm saying . you can line them up based on the times . the scoring program with if you give it an stm reference file , it will actually compare the words based on their time marks . therefore , you can ,  it 's per utterance , but it allows as long as you hypothesize the word in the right segment in the reference , it gives you credit for that . ",,
Bmr028.I,"it does a word alignment , like you have to do for scoring , but it constrains the words to lie within the t the time bins of the reference . and fo for you to get a credit for it .  it 's it should be just a straightforward re formatting issue of the references .  it 's a technical term . if i you i in a to a broader audience you could call it a diagnostic experiment , rather than a cheating experiment . but they don't run experiments .  it 's like a disclaimer . now we have to l delete that expletive .      but weren't you cheating in those experiments ? s self  what does it put out ?   you could still it 's even if y if you could still transcribe the words based on the far field microphone you could , still use it for , say , language modeling ,  right . if right . there is no there 's no shortage of meetings ,  we can afford we can a   hey , i bet there 's tea .  hey , i 've never done one of those . right . sev ",,
Bmr029.A," that 's true . hub five . that 's only male . we could only jus just do the male only right ? or will we run into trouble when we g ?  that 's what i was thinking .  s we yo one thing i was wondering is , did you already do that middle one or should we re do that one , too ? you didn't do that . that 's what i was gonna say next . we hafta cut the , w s is morgan , is the plan to just pick one of the far field mikes ?  do when he 'll have the comparison ?  cuz i don't think the new data will be ready , for a couple days may probably .  the training .  it 's that one . right ? f . f . that 's it . that 's f . it 's the second nearest the machine room . want to make understand what we need to run .  let 's see . it 's if we 're talking about let 's assume that we 're gonna use the new segmentations . we need to , run recognition o just looking at the no overlap column . we have to d r do recognitions for all three of those cases . right ? because we 're gonna be using the just the male , model short training set for the male . we need to have results for all three of those , even though we have   right .  and if we 're doing the baseline anyways , it would be right ? to just limit ourselves to a smaller how long would it take to run recognition , if we did that ? is it like a day or is it a few hours or roughly ? for let 's say we just did the meeting recorder meetings for our test set . really . i didn't realize each test took that long . four hours per meeting .  s six hour test set . six meetings . alright . if we got a list of the , segmentations for these five meeting recorder meetings , we could start , the first two experiments going right away , using the short male models . you could get those going while dave is , creating waveforms for the r retraining the short male models . right . and then do we w also want to run that bottom experiment without retraining the short male models on his thing ? did you want that ? or ? we 'll save that . i it on a more basic level , also , it means that third experiment , there are actually two differences between the other experiments , not one . it 's hard to know right .  right .  on the far field ?  when you said you were gonna start that top one , were you gonna use the new segmentations ?  right . can we ? ",,
Bmr029.A,"does that mean you turn off speaker normalization when you run it ? or you just let it do what it would do , an ?  you 'll have email . right ?  segmentation ? s i don't want you to have to be burdened with doing a lot of what can i do to ? y you said it would be easy for you to do that top one there , and don can do the segmentations of the , channel f ? certainly help with , retraining the short male models , once we have the new data . the top one is done . i c re do the next one .    the bottom one would b just be a matter of pointing it at a new set of files and kicking it off , that would be re th not the bottom one , but the middle one would be really easy once you 've got the top one going . i could do that . guess need to get don to ,  to keep it the same but j just change them all to channel f ? right . right .      and that 's something that don would do right ? when he creates these .  will you talk to him about that , or do you want me to talk to him ?  and then the bottom one in terms of the test will be ?  that will just be a copy of the one above it , except for different models from training .  we need to run ?  once we have the new , once i do that , second experiment , we 'll have the , files , and give you those to process . do you create this continuous stream from the individual utterance files ?  i 'm gonna i 'll check with , markham , and see what happened with the disks . he went to put those on a couple of weeks ago and something i 'll ask david , then . you haven't seen new disks pop up , have you ?   he went to put them on  he went to put them on and then something happened . and he sent around a note saying "" it didn't work , and we 'll have to schedule another time . "" and then , didn't see nothing happened .  i 'll check with david about that .  dave , for you to get your processing going , you need the list of the , wave it 'll dep you 'll we 'll need to get the segmentations . figure out whether we 're using the new or the old from don . and then ,  from that you need the from the segmentations you 'll have the list of wavefiles that the short , set is trained on . and then you 'll need disk space . and once you 've got those things , then you can start your processing . right ?  do you have this , ",,
Bmr029.A,"there 's one other issue , and that is that dave throws out speakers that have less than twelve seconds of training data . and he said there were a few in the macrophone set like that . do we need to to find out who he 's gonna throw out , that we create a new set of short models that don't include those speakers ? in th the problem is that if we proceed like we just described , when he goes to m create the new s training data with his processing , he throws out some speakers . the t two training sets won't be identical . have just a little bit .   you think it 's then ? it 's read . we sh m right . a actually you should be able to figure out , dave , right , once the segmentations , who you 're going to which speakers will get left out , even before you run your processing . right ? the segmentations from don ? once we ? right , right , right . right . but i 'm just wondering how long it will take to get that information .  robert did what ? robert took what ?   is he gone now ?  are you interfacing to that thing with the c plus or are you is there another interface that you use ?   and it saves it in a i see . that 's neat .  ",,
Bmr029.B,"it 's e f . u for the far mike htk system i was using , it did help somewhat . i could re check that . but it was such a bad baseline that i don't that means . cuz the baseline word error rate was around forty percent on digits . right . what wo also for the log spectral mean subtraction , we wanna know which speaker 's talking when , cuz we wanna chain together the audio from one particular speaker to calculate the mean and subtract it , and we don't we also have to mean subtract the test data .  and there 's , s the way this means subtraction expects to work , is it expects to have , this continuous stream of audio data from a particular speaker to operate on . and it goes along it with this sliding window , calculating the mean using the data in the window , and then subtracting that .  that 's how i 've been doing it , just by concatenating files together . and if these files and the since they 're individual utterance files , s long silence periods are removed , which is a good thing . because this method might estimate the mean badly , if it had to face long silence periods . but that does mean that i need as much i need twice as much disk space as the original set cuz i need while i 'm running it cuz i need to create this intermediate set , of these big files , and then create the finally , the mean subtracted , little files . and then get rid of the big files . but st while i 'm doing the processing , i 'll nee i need twice as much disk space . right , an and andreas , in u doctor speech data sri hub five , there 's this , hub five training set . now , is that the long training set there ?  i th you already did , actually . and say the macrophone files that are included in this short training , are just a subset of the macrophone files . right ?  when you did some ti digits t experiments training on macrophone .  but that 's not necessarily any less data than the sri hub five set . it 's not a subset of the short sri hu hub five set . right ? whe when you trained on macrophone , to do those digits experiments , did you use the entire macrophone corpus ?    i got confused , cuz you were using the whole macrophone set .  if need to use that subset , get it processed . i actually got got f into it before , and then was doing the wrong thing and i stopped . and it shouldn't take that long to do .    right .  the segmentations ?   i have it for macrophone , already , ",,
Bmr029.B,"and , by tomorrow i 'll have it for th for the rest . ",,
Bmr029.C,"the one thing i knew i wanted to talk about was about , last minute to , try to get some recognition results .  on meeting data . and i 'm not exactly what you 're doing already , and there 's some 've talked to dave  right . we have some with no overlap , for which there would be near field results . we wanted to get the far field results for that . and then this real , long shot thing would be , that we 'd apply dave 's processing to , potentially training and test data and do the look at the same thing . and in talking this morning with , chuck and with dave one thought was to use we couldn't remember how different the numbers were , but if you just worked with males only and used the short training there 're chuck 's recollection was that when he was doing the feature it took day and a half to do the training .  how much worse is the short training set than the large one , in terms of the ultimate performance ?  it 's that should be fine for this , i would think . we an and you have the short you have short training results for the close case ? how do it 's ? it 's three percent on , on hub five . i see . but we have the models we could get that number , and the question is , what ? w it has to be enough that it 's the non overlap only . and it has to be enough to be comparable to what you folks were seeing and what you reported already .  no . he has to create that . but s but  we have a whole parallel set of things over here which are all with digits . and dave has been working with that and there 's all of those issues . but i know that if i go in with something that 's not just digits it would be good . and , we already have these results that you on a l a lot tha a particular test set , that you that we reported at hlt . it 'd be to have something more than that . and w we had talked about was having distant and then , if we could on top of that this is gonna be a lot worse . right ? whatever comparison we w one would presume . but we don't know how much worse , w which is certainly one interesting thing . and then , dave we figured that it 'd probably take a day or two to compute the ,  how many hours of training ?  but we also have to do this other processing , having a smaller training set , if it 's only a few percent difference , it might be worth doing it . ",,
Bmr029.C,"but m how big is the small training set ? do you remember ? it 's around there . and ha and male is roughly half of that , or ? or was that only male ?    that 's certainly part of the issue , is that right now he 's he hasn't written his for efficiency . it 's in matlab and on , and , it 's not an impossible amount of time . we were guestimating it was like one and a half times faster than real time , if there 's thirty hours of data , you can calculate that he can do , the enhancement in a day and something .  but if we were dealing with two hundred hours it 'd be prohibitive .   it 's a bit of a push , but it seems like , we 've got some models , we 've got some training data , we have software that works , he 's got a method that helps with , other ta another task .  it , appears to be , debugged .  yes . that 's not bad . the training .  for the test . fo right .  it 'd be really great if it was all automatic , but that , given the pressure of time , if i since you 're gonna find out in a short amount of time , that 's great . but i if it doesn't work out , we would rather charge ahead with the older segmentations and and we were gonna use one of the p z i don i don't probably whatever one you 've been using for the digits . is it this one ? i 'd which ? that 's f ? how do  bien sur alright , bet they 'll have fun with that one .    right .  but , how long does it take for the test ? right . bu but what was your result for that we had at the hlt ? was that a combination of me ? you were doing like but if you if you do half a dozen meetings , that 's about a day . we also have more machines now .    if we had about six a six hour test set 's not bad . right ?  right ? a lot of the evaluations have been four that you worked with ? that would be too . i 'm i if they have a set that they worked with , and you got did you do similarly in performance between them and the other meetings , or was it ?  and overlap or not .  just with the meeting recorder set of the de th that you did before . we want to do the same thing . once we know which segmentations we 're using .  i agree that would be an interesting thing to do , but i regard it as secondary . ",,
Bmr029.C,"if there 's machines sitting around and people sitting around and they 're waiting for other things to finish , then but chuck had been asking about that earlier as control to know , cuz , you could imagine a fantasy in which you said that dave 's processing made the , far microphone like the near microphone . in which case you shouldn't have to actually retrain . but it 's not really true . it 's fantasy . it does muck up the data in some funny ways . and i 'm questioning that . but right . it involves retraining and it involves a that 's right . the other thing which it might come in to is if there was some problem in the retraining . you 'd just have some mechanical thing we do wrong . that , since dave 's experience was that it didn't help as much if you didn't retrain , but it does help some , that we would hopefully see that . that 's true . i right .   do you ha do you have to rely on his segmentations to do the top one ?  got it . we talked about this before . what we were saying was that , the very fact that in both cases we 're ignoring the overlap section means that , we 're to some extent finessing that .  for the purposes of just determining whether a far field microphone what the effect of the far field microphone is , we should do the same to both .  we want to i incorporate certain data that would not be available during final tests , under a full fair test of it , much as we are in the all the numbers that we have far .  we simply wanna determine what 's the difference in performance due to being distant versus close . to a lesser extent you had that same magic the other way , too , because you have leakage into other microphones . right ? but , it 's just you 're using the fact that this is where this person is . right ?  it 's just easier to do .  how do you determine what you use to group together to be a ? the only other alternative would be to turn off speaker adaptation in both .   an and e that will tell us what the difference it between the mikes , and then , in order to the other difference that we 'd have to take care of is that , we don't have a mike that , is particular to a person . and we 'll have to do some clustering , and that 'll be another , issue , too . but , it i could be wrong , but it seems to me that the speaker ",,
Bmr029.C,"the level of degradation that you get from having the distant mike in a normal acoustic is much greater than what you get from , say , not applying speaker adaptation or applying speaker adaptation . that the we 'll see . but , that the gains that we 've seen from speaker adaptation on hub five things are like a few percent . right ? and  it doesn't make that much difference , i would doubt that it would be a huge amount of difference for that . that difference would definitely be marginal . the main thing is to do something to do some cepstral mean subtraction on some level . and , what 's different about this processing is just that we 're doing it at a much longer time scale . right ? but that 's right .   right .  but , i also think that a again once we got into it , that , using some clustering would probably work reasonably there , too . certainly for the two microphone case , which we 're not gonna mess with because it 's another whole deal with the low quality microphones ,  we ought to be able to at least tell that it appears that things are coming from a particular direction . we ought to be able to use that information , as but , we might be able to do not too bad a job of separating out sp segments that appear to come from a single speaker both in terms of s acoustic similarity and in terms of direction . but that 's another research thing to do and probably won't get done the next week . i 'm leaving for the , the new orleans meeting , next saturday , and , it 'd be kinda to have some results at least a day or two before that , that i could figure out what i wanted to say about it .  not to mention that , mari 's putting together this report next week , too ,  what we were hoping was that over the weekend we could do , the , calculation on the training set and , we could by the end of the weekend , we could have the top one , and then early next week , do these . if we had enough machines , do them in parallel . that by the middle of the week we had s had some result . it 's one of these hail mary kinds of things . it it , might not work out . but , f figured i may as ask for it . right . you have models of short males ? markham 's out on vacation . che check with dave .  they were like mushrooms . they 're popping up .  cuz we still all have tha the that other one going , which is the , the macrophone training . that was in the hub five small training set ? yes .  ",,
Bmr029.C,"i wonder about that , though . because all we 're doing the only reason we 're using the short training set is for speed . and there we 're not really making any claims about using a smaller training set . as long as we 're not using any testing data from  for his normalizations . i 'm right .   say this again ? missed it . he throws out some speakers that are very small . there was only a few we thought to be the case . righ ? right . no . the training set he could go through right now , and see how long the at that one ?  been looking at synthesizers ? you were looking at festival .  right . this was a business about , coming up with something that was purely prosodic . and we 're just gonna use a pitch detector , drive a synthesizer , and since it doesn't have a hook in it for , modifying energy , we 'll have a little box at the output that 'll modify the energy .  rrrrr rrrrm something like that .  digits ? that 's all folks . ",,
Bmr029.E,"we did . it 's is it the same set as the alignments ? it 's five meeting recorder meetings .   nope . i was wondering if they were in .   something w went wrong . nothing happened . no ? synthesizers ? i was doing something for the smartkom data collectioners . robert has taken his laptop t back to germany we needed a new synthesis machine . and we have now a sun workstation in the library , which does the synthesis and the festival speech s system is running on his laptop where , which we used for the smartkom data collection , for the synthesis . and he took it to germany and we couldn't do any data collection .  no . he 's just gone to a smartkom workshop . and we have now the sun in the library which can do that . and i looked into the ts f zero thing and talked to liz , and it seems that it 's quite s what she wants , but we 'll have to think about the energy thing what we wanna do . for w for festival ? you can just use it from the from the command line , and the defining the phones , whatever you want to have synthesized , and give the f zero targets , and then ts get gives out a waveform , and i want to manipulate the waveform , then . ",,
Bmr029.F,"recognition results for we started recognition on the on thilo 's segments , which was but using the far the close talking microphone . and you wanted i know you wanted the far field data .   to retrain ?    that 's about right . actually , it should probably be it depends on who else is using machines , but we have more machines now .  it 's more like a day , probably . it 's like something like three percent three or four percent absolute . not for meetings . because we didn't train we didn't re ever recognize with the small models on meeting data . but i have the models , could run reco on the the recognition also takes non negligible amount of time . we might wanna restrict it to , a few meetings , if you want to do a full comparison .   do we have the processed data ? that 's also right .  i see . right .  right . actually , i did retrain i recently retrained , for another reason , on the full training set . and that took only it took only two days . it 's actually conceivable to do use the full training set . i see .  i don't know , something like something between thirty and fifty hours , i f i forget the exac right . actually , i don't know . i 'd look it up . it 's it 's just , i don't know the remember the number . the males account for most of this meeting data anyhow .  i would say we you do only males .  u no . it 's definitely it 's less than a hundred hours , for it 's it 's probably actually , it 's it 's around thirty hours just for one gender .   no . i didn't do that , because we haven't even cut the waveforms for that .  right .  and there 's a bit of a question whether you want to use what segmentations you want to use .  david just i 'm don just , created a new version of the first meetings that we had previously recognized , but with different segmentation . and it would be if the results are comparable to what we had before to use those segmentations , because th then we could claim that everything 's automatic . right . i 'm as i said , started the recognizer , it will it will probably be a couple hours before i have some results .  but the segmentations matter for the filtering . right ? because for the test set .  need to be but , first , you would wanna process the training data , because we wanna get that started .    right .  ma you should limit ourselves to the meeting recorder meetings ?  if you were gonna cut down on the test set , i would suggest that . ",,
Bmr029.F,"actually , the longer the robustness meetings take longer , because there 's this one speaker who talks a lot . and the no . it 's because for all the for the adaptation and normalization steps , you cannot you have to d you have to , you cannot chop it up into small pieces . you 're limited by how long the longest speaker , is s speaking . how much data there is from the speaker who talks the most . you parallelize across different speakers , but if you have a bunch of speakers who speak very little and then one wh who speaks a lot , then effectively , everybody waits for the longest one to process .  that was both types of meetings , but most but there were only two robustness meetings , and four or five , meeting recorders . right .  i i don't have a good gue for everything ? for all the meetings ?   it 's probably more than a day , but probably less than two . i no . for all the meetings . because it 's again , it 's ,  each meeting each meetings takes , something like again , we i ran when we ran these , we were short on machines , and , i don't know , i would estimate four hours per meeting . something like that . right . right . that 's why i 'm saying i 'm not how they would scale with more machines . right . we have mr two , th we have two , three , four , fi there are four meeting recorder meetings that we worked with .  five ?  with the robust compared to robustness ?  the big variation is by whether it 's a native speaker or not . and whether it 's , that 's the o actually and what , whether it 's lapel or , headset microphone .  and we can exclude we don't need to recognize the non natives , because we know that we excluded them previously from right .    did ? when you used original the original models , and you just process the test set in this way , d do you get any do you get decent performance or not ?  right . right .   i 'll get started on the the first the one that already has a cross there . we need to re do that with small models . right . and then , have to ask , don to , cut the , cut the segments for the sh for the tis distant mike . that 's we would be using the same channel for each fo for everything ?   no , no . we would use the same segmentations , but he needs to extract the wavef form segments from a different channel . right .   if assuming that the performance turns out to be comparable with the old experiments and the old segmentations . ",,
Bmr029.F,"now there 's the issue of there 's the issue of speaker normalization . with the distant microphone you wouldn't know which speaker is talking . right ?  i see . you want to cheat ? we assume knowledge of the speakers as , in a way that 's compatible with the close talking test set .   no . it means no . it just means you group together the segments that by magic belong to one speaker , and treat right . right . but , in the new test , actually , that 's not true . again , if this if these new segmentations work then we then it 's a fair it 's a completely fair test . you group together all the data coming in through one channel and where thilo 's speech detector has determined that there is speech . and that speech is deemed to come from that speaker , whether that 's true or not . if you get some cross talk from another microphone , then you just process this it as if it were from that speaker . that 's more of a problem . because it 's you can just pretend it 's some gene you can pretend it 's all from one speaker and do all this processing the same , but then you 're gonna get results that are worse on account of not doing proper speaker normalization and you 're gonna have you could certainly do better than that by doing , cluster the segments , which is what we do , say , in a broadcast news system , where you don't have speaker labels . but that would be another processing step that i 'm i would have to debug first , and forth , and we wanna avoid that . agree with you . we should we should , do the this cheating experiment .  it 's not just speaker adaptation . it 's the whole norm feature normalization process . i it 's spea all that is speaker based . we in that i 'm ,  y d b the most important , is the cepstral mean subtraction . and that i don't know if we we never really i don't remember , because it 's far s long ago that we didn't do that on a per speaker basis , but a and it 's actually we 're already if we use the same segmentations that we use for the close talking microphone , then the segmentations assume that we have access to all channels and cross correlate them , there 's no point in not using that knowledge for speaker identification .  right .  right . what is the schedule here ?   we 'll call you when you get there .   i 'll ask the other thing is , and i 'll ask don which is easier to process in terms of creating these the test data for the far microphone . ",,
Bmr029.F,"if it turns out that for some reason it 's easier for him to use the old the old ,  segmentations , then we 'll just use that , i figure .    right .  right . let 's see . the you can you could run the ,  you c once the , whe the top one 's done , you could easily re run the whole set of experiments . manage the jobs and forth ,  that 's all   right . right . somehow the assuming he uses the new naming scheme , then he should call the waveforms the the waveform names have the , meeting id , and the microphone , and the , the channel and the microphone and the speaker , speaker some something that identifies the speaker .  exactly . you still need to be able to distinguish the different speakers . that 's the key point . because , if we wanna do what we just discussed the best the easiest way to do that would be to just take you make the channel be channel f , but then keep the speaker names the same as they would be in the old in the close talking , version . right . exactly . i , talk to him . they grow them on trees now . just , you shake them and they fall down .     that 's everything .  give you a list of the short version . you can  that 's right .   wel no , it is . th the  can you repeat the question ? there wa it is a subse  no . only the portion that was in the hub five training set . the hub five small training set contains as much macrophone as the large training set , for historical reasons .  do you have that processed there , then right ? because you already did y didn't you already do that experiment ?  no .  right . and you need only the males .  does this th this ? it 's not very to use the small training set for another reason , which is that the you also are losing on again , because you don't use all the data you have for one speaker . the normalizations you compute for your training speakers will be , crummier than they would in the large training set . i have to to make it really a matching experiment , i have to find i have to use short models that were trained on normalizations that were also only estimated on the short set . which is ,  i 've i have to check . in any case , i could retrain short models within a few hours actually at if i use machines at sri .  no . but if we used the whole training set for normalizations , then david would have to process much more data , which that 's a that 's one bottleneck , for us right , in terms of get  ",,
Bmr029.F,"right . you wanna do the exact same thing , or else you 'll have apples and oranges .  it doesn't make i don't think it makes that much of a difference . it 's just this little detail that if you can take care of that , then you should . have the models , i have i have ,  let 's see , and if not retrain those models very quickly .   i don't think it 'll make a matter . about throwing those out too , because when i heard how little speech there was for some of them , they can only hurt your models , because they 're again their normalizations will be all over the map , and you won't get very clean models from them , anyhow .   if you wanna do this , to speed things up , you we can leave out the macrophone data altogether . that hurt actually . no . not in the short . then you have too little data .  forget that .  when you use when you go to the large training set , then leaving out macrophone actually sometimes helps you , because it 's just not relevant to the meeting and or to conversational speech anyway .  leave it out , and in the event that i retrain the short models , why don't you give me a list of the files that you throw out , and i 'll throw them out , too . and then we have complete completely identical training conditions . but th the segmentations are only they only affect the test set . we 're talking about the training speakers . right . he already has the in you already have the information . right ?  alright .    ",,
Bmr030.A,"what does that stand for ? alright . it 's pretty vague . it 's government run ,     i sent and i sent you an email with the instructions . i don't know . morgan morgan 's leaving on saturday ? until then , we might hear something , but exactly .   it 's just alt tab . like if you hold down alt and then tap tab , you just the s just the task manager w window comes up . we  because if you just touch alt a if you just hit it once ? it 'll go back to the previous application . and the previous application was the powerpoint demo , which was the display of like , not the slide show . he didn't right .  right . and i told them , if he decides to use multiple examples for , the prosody demo , to open up separate transcribers . just you don't have to load up files e during the meeting .  he 's got the memory for it .  they 're all really short . no . i didn't have any problems i 'm i don't know , but it seemed it didn't seem to be a problem i would imagine you add sixty four to a hundred and twenty eight . either one will work , it was it was fine . we kinda walked through it a little bit on his p on his laptop . i could and it 's part of the talk itself , it 's really not a big part . it 's just gonna be a couple of i know . right . but it 's a good tool to have . the th the m the meeting i r is actually  prosody ? have you guys seen the display ? have you guys seen either of the demos ? they 're pretty like the prosody demo , we loaded up word alignments . instead of having utterances in the bottom , it 's like just word by word . you can see exactly where the overlaps are . and then , adam did something where , we converted these feature files into wave files , you can display them . instead of the wave file . and then w using multi wave you can add a file and play that sound . play the audio corresponding to that , feature file , and it 's all like , aligned and you see the pitch contours and you and when you hit play , like there 's a line that goes through it , and it 's all aligned with like the t the audio and the feature file .  there 's a  there 's a median filtering and then there 's a piece wise linear fit , based on some criteria . i 'm not  i should email morgan about it too , because he was asking about that . and right , then it 's not a linear f fit . ",,
Bmr030.A,"you 're not fitting anything then .  it it 's useless one . i actually don't know off the top of my head . this was kemal sonmez at sri , who 's a co worker with , liz . did   but , kamal has , he did a paper on this for some v speech verification , project , and we extrapolated what he did for that work and applied it to our files . and that 's how we do that 's how we get our feature files and everything for all the prosody . that no , we grabbed most of it . like , we grabbed the linear fitting we did all the alignments and all the matching and but the actual coding of the the math was done somewhere else . that 's what you were working on , right ? from end to en like , from the beginning of the process to the end of the process ? ooo . right .  right . right . s    what 's the turn around period right now from ibm ? should we be discussing this ,     and the transcribers here are still , are working , though . th they 're just doing their own thing while they 're waiting .    what i you 're just talking about playing it and recording it real time ?  and you have to record every channel separately .  we they couldn't use c ds ? i see . i see . they must be dealing with large amounts of data if they 're transcribing , anyway . people probably aren't sending them , an utterance or two . isn't that next week ? it was don't know . the demo was one of them . that 's it .   the new disks are installed now ? or ?   are we g just gonna keep recording ? like , at some point   cuz u how m you 're a data fiend . it 's like you build this room up for long , and then it 's just like , you stop .  ",,
Bmr030.B,"by next friday . it 's more money . something like that . it 's it 's some money that we can use we 're in conjunction with sri , washington , and , columbia . and to do research on the meetings .   mapping meetings , or ? it 's like creating a m a map of a meeting , in a sense . it actually doesn't have a whole lot of m speech to it . it 's higher level , i don't remember . it might have been . we had to get some did he ever figure out how to d switch between applications like he was wanting to do ? he did ? how is he gonna do it ? he he right . no . he said he tried that , but he didn't like it because it ,  it took it out of the , presentation mode .   what do you have to do ? you have olt alt tab and and then it won't and then you can come back to your full screen version of your presenta  how much memory does he have ? how much memory does he have ?    are we the only ones who are giving demo ? or is , washington gonna have a demo too ? or ?   i see . my gosh .  no .   display the features .  you see the f zero contour ?    neat . was this code that you downloaded to do this ? or was it  at sri dot com ? no , i it sounded like a url , the way you were saying it ,  what is , like the implementation that you used was something that you coded up here ? or you grabbed code from somewhere else ?  i see .  it 's done now . she said it was much faster . it really helped a lot to have that . there were a l from scratch .  no , f no . from the point where we s take it , it 's faster . u it 's sorta like doing things in parallel . if , if they can be working on that while we 're working on the other things , then when we get them in , they don't have to do that one from scratch , th right now it is taking a bit of time to turn around the meetings from ibm , part there 's several problems . one is , we were giving them these large files , which they then had to split up and put onto cassette tapes . either ninety minute or sixty minute tapes , they had to try to find an appropriate place to break this large file that we gave them . one of the things that we did is , adam made a modification to th his script that generates this you can tell it that you want , chunks that are no more than either thirty or forty five minutes . ",,
Bmr030.B,"and then we can give those to ibm and it 'll make it easier for them to put them on tape . then the other thing is that these pool of transcribers that they 're using , are not dedicated to our project , but are in use for all ibm projects , and ibm has recently giving given them a whole bunch of it 's gonna , delay us . that 's an interesting idea . the only difference would be , we would be putting the on tape versus ibm . and then we could send if we had that process down , of putting the audio onto tape , we can send ibm the tapes or we can send this transcription place the tape  u i don't know where the bottleneck was . was the bottleneck in breaking this large file up into the appropriate size chunks ? or was it actually putting it onto the tape ? exactly .   how do we do that ? how would we put  plug i the headphone output in the back of the computer ? line out into the line in on a tape player , and that sounds pretty easy .  but if it was at your desk they there was  th they , they gave they 've given us since we started doing this new , beep format with "" beep number beep "" , they 've given us , two full , transcripts . they have a third one and brian just sent me a note saying "" that third one somehow slipped through the cracks of their tr of the transcriptionists ' , s company "" . and there 's gonna be delay of a week before we get that third one back . and i 've already given him three more to work on , but he said those new three won't get done until this big chunk of data has been processed by the company . they 're working away . they 're just doing right , right . what we do is , when i go to select meetings for ibm , i go into the into the , master sheet here with the statuses and i pick ones that thilo has , pre segmented , and i change the status to "" trans ip ibm "" , that , when jane or whoever goes to select the next meeting they won't choose one of those . and , 'm not picking huge chunks , right now , of meetings for them , but that 's a good idea .   when that thing when it stutters like that , is it because there 's a delay getting the data off a disk ? or is it because there 's a delay in the d to a ?   i see . we could do it from a w a pc  david might have a bunch of o old p cs , cuz he 's replacing them with these new ones . we could get one , ",,
Bmr030.B,"and just dedicate it to doing this . not even hook it u we need to hook it to the network we can get the files to it , but  right . and then just use that machine to hook up to the tape .  we don't need a powerful machine to do these things , right ? one of these old pentiums that we have  should talk to him about that .  that 's why i wanted to avoid having to do that if we could , but it 's just another they have a device that , you put the cassette in and it has a foot pedal that lets you go back and forth and like that .  they haven't got a p really ! y can you send them huge audio files ?   that 's interesting . that 's true . are how big are these files that we send to brian ? really ? that big ? it was hundred megs .   that 's still pretty dang big .  i don't know . wha whatever you generate . the last ones you did were compressed .  wonder if the ones before that were shortened . cuz it 's all    what will that do ? is that going to ? we can get rid of the that 'll be i should be around . experiments ? that 's probably next .  something about demo .   i made a but that 's not specific to meeting recorder . i was gonna say i took some a suggestion of adam 's , and i , created a m cgi script that lets you see the current status of the speech disks . if you go to the speech local web page , and then there 's a disk status page . you can click on that and it 'll query abbott , and give you a list of all the disks that we have and then , what 's on each one , and then it shows how big the disk is and what percent full it is .  and that 's , each time you go there , it 's updated .  the new disks are installed . if you need space just let me know . i have to create the p appropriate sub directory . we 're s kinda trying to keep even the scratch ones we 're keeping a little organized , where we put a y a u doctor speech data , and then i 'll either create a sub directory for , like if it 's meeting recorder project , or hub five or whatever . we c have to create those sub directories , and no . no . nnn . it 's all scratch .  de , which is where we 're putting all the meeting no , it 's d e . d e 's not full . dd 's full . that was the first one . or , that was the last one that w filled up , ",,
Bmr030.B,"and de still had like , last time i looked it was like seven gigs  and each meeting is roughly half a gig , and we 're getting close .    morgan said something about stopping at the end of the year . like when we get around a hundred meetings . because there 's gonna be data coming from uw , hopefully by then . it feels funny ,  if we have the capability . now that we 're used to recording , it 's like , why not keep going ?  we have right now seventy five or seventy six hours of meetings . but aren't we still using the , compressed   we need to figure something out , cuz the abbott is e we can't add anymore disks to it . we can increase the size of the disks that are on it , but that will only take us far .  david had the suggestion about , new servers and things like that , and 'm gonna see if we can talk to morgan about getting some money for a new disk server . and , it would have to replace abbott ,  he david 's planning to get new servers anyways for all of the main servers . he wants to sorta go with the same type of machine for all of these . but , it 's full in there . have you seen it recently with all of the new machines that we got the sun blade one hundreds ? they 're like stacked up on benches and things all over . it 's really crowded .   they 're in the if you do a p make i 've forgotten now .  they 're in the p make pool . if you do a "" reginfo minus show attribute "" , and  a r y you can get a list of all the machines that are available to p make , by using the command "" reginfo minus show attr "" .   and then ,  and i for i 'm not what attributes we attach to the sun blade one hundreds , but it could be sb one hundred . and if you query for f all machines that have that attribute , then you should see the names of the new machines . but . non interactive there 's there 's this one called there 's the attribute called "" no "" what 's that called , "" n "" "" no "" "" no evict "" . which is roughly that . it 's although it 's like it h my machine has it on my desk . i do get jobs running on my machine all the time . but , that 's what it is .   ",,
Bmr030.C,"time ? fourteen whatever . thirty two . thirty . whatever . doesn't say much . not great . what is meet meeting maps ?       that 's   with who ?  switch between applications ? yes , that 's      nope . instead of the wave file ?   great . that 's great .   and there 's something like a median filter in it ? and and it 's a linear fit or whatever .         and and the these are our f zero candidates which i 'm supposed to use for the synthesis thing ? i suppose ?   i m didn't have time to look at that ,   much faster than doing everything alone .   fff !   plug it into the sound card .  line out ,  but the easy way is i know . no .  but you pfff .    and all  and all of the p cs are connected to the network , too , here . or , bad .  but they are also on the networks ,   the beep files .  or even a dvd burner . web based ? you can , but they never will be able to read them .  pfff ! send it via email . it 's all speech .  only .  experiments ?  these are next week . the demo ? demo and ibm ,   short meeting ? what d e ,  d is full . but they are not yet accessible ? the new machines ? they are ? oop .  a what ? god .  "" reginfo "" , you can send me that .    ",,
Bmr030.D,"   right . that 's the same software i used to get the data . i gave you a c couple examples , and right . right . if you used a line out , too , you have to worry about if you click around and you hit a beep it 'll beep onto the tape too . one three , one three o , eight six seven . one three , five four , one two , two three , seven zero . ",,
Bmr030.E,"and we 're on .  topic number one is , we got the nsf atr itr , excuse me , which was originally pretty big , but it 's divided among many sites , and they cut the budget by a th by two thirds . they approved it for all the sites , but only gave us like sixty two percent of the money . or , excuse me , cut it by sixty two percent . morgan is , and the other condition is that they have to get a budget out immediately , or the or they 'll give the money to someone else . morgan 's working on that . it 's good news . it 's not as good as it could have been but it was , the i t rs are , a long shot , and it 's really that we got that . information technology research ? something like that ? it 's , it was specifically on the meeting . d was that the one that was the meeting maps ? good . i liked that one . the general idea was , you can think about meetings at lots of different levels , all the way d from all the way down to acoustics to all the way up to dialogue , discourse , topic . and this was , how do you map all that information onto that ? a onto the meeting domain . that the analogy was you have maps of different things at different resolutions . and this had a lot of different in it . it 's mostly higher level .  but , nonetheless , if we it 's a idea . and if we can actually get it going that would be neat . and this was the one also that was ,  was it with susan ervin tripp ? she 's a linguist on campus . anyway . other topics i wanted to talk about are , the darpa demo which , since morgan isn't here we can't really talk about . wanted to make it was ready to go . but your is all ready it 's just a question of , did morgan get around to testing it . i got it . with the instructions .  guess we ge we had better be on call for a little while . i don't know . i haven't spoken with him . alt tab .  the problem was that , i was t saying "" hit alt tab "" with the assumption that he knew what i meant . but he didn't .  but it doesn't . it doesn't . and all i said was just cycle through with alt tab because that 's the standard way of doing it in windows . but he doesn't use windows .  he didn't meant . hold down at hold down alt , and then tap tab several times and you 'll cycle through all the open applications . right . ",,
Bmr030.E,"that 's a good idea . that 's not a bad idea that , and since the files are short , it 's just the tcl tk overhead is pretty high , but it shouldn't matter . he had one twenty eight ,  but it was faster than my pc .  i assume . but they 're all doing communicator  the talk 's only twenty minutes . all this time we spent on it 's gonna be thirty seconds of screen time . i actually , both of them . cuz we 're gonna wanna be playing with the  help , my brain with the prosody anyway . actually , at some point w we should talk to users of that technology who are actually gonna be using it and see what they would like to see . audio . and the stylized f naught features are pretty these this it 's does a piece wise linear and normally if you look at an f naught track , it jumps all over the place . this is a smooth one and it really does a good job . it 's a combination . t g actually could you email me a reference to that paper ? if you have it ? cuz i 'm sorta curious how what criteria it has . there 's trade off between the number of knots y you pick , and the best fit . if you 're doing a piece wise linear , you have to figure out how many pieces you want . and there 's a trade off because the best mean squared fit would be with an infinite number of knots . it is . but you there 's a trade off and i 'm wondering what criteria they use .  dot com . no , i you said "" at sri "" had to add the "" dot com "" .  other topic is , the ibm transcription status we 've sent a few to them . we 've gotten a few back .  i sorta wish jane was were here because she gave didn't she give one of them to one of the transcribers ? and , how was it ? great . hand . but that 's what we wanted . right . we knew it would be longer to have multiple groups . right . pipelined . the idea is that we 're taking less time of the linguists . of the transcribers .  we might wanna revisit hiring our own external transcription company . because that would be cheaper than having our people do it , but do it with the same process with these beep files . cuz , originally i had disc discounted that because it was just gonna be too hard . but now we have this procedure with the beep files worked out . then it would be  and we might wanna do that anyway . because it seems like that 's being a bottleneck and that 's silly . ",,
Bmr030.E,"it shouldn't be a bottleneck . it would once we got it set up it w it it may have been partially that , because they tried it , and then they would have to listen to the tape and find out where it bleeps , and go forward in the file , et cetera . but , it just seems like it 's not hard for us to do , and that would just make things go faster . get a tape deck , plug it in to the computer , hit record , on the tape deck , and just do it all analog . line out .  mean , that 's the easy way . they might have a more complex set up at ibm . i 've seen digital analog tapes where it 's controlled by the computer . but w but we don't need to do that . the disadvantage of doing it this way is it 's real time . you would have to sit there for an hour while it 's recording . but right . it 's not a big deal . master .  we should at least ask , brian if there are any particular requirements for putting things on tape . is there a particular type of tape that they want to use or anything else like that ? and , and then we should see how much of a pain it is for one of us . the o the other problem is you would wanna r do it on an unloaded machine . right ? because you wouldn't want it to start stuttering . and that means that 's more of a problem because y then you have to be there . right .   it could be either . there are lots of different places . it can be delay on the disk , or it can be just load gets high on the machine . either io load or processor load . it 's a problem with these multi user systems is that lots of processes are running and you don't really have control . wha that 's true . it 'll that 's right . you really do wanna be using a machine that 's not no , because we 're doing the beep files .  or you could just you could have it no active connection . just scp them . actually , it wouldn't be bad to have that , plus put on that machine a cd burner . no . a dvd burner , the real question is , where would we put it and who would do it ? whoever records the meeting . it 's not a big deal , but it 's yet another thing you have to do . no , because the transcription company does what they do . actually there are a few i saw a web based one at one point . where you could send them audio files over the web ",,
Bmr030.E,"and they send you back text files over the web . i should look that up again .  i assume that you can send them anything that they can access with http . half a gig . no , they 're the beep files . it 's a p hundred meg . they 're the beep files . that 's right . they 're smaller . yes . and we are sending them the compressed ones , right ?  were "" shortened "" .   the beep files , actually the "" shorten "" doesn't save a whole lot . right ? because the whole point is that it 's extracting pie pars parts that are loud anyway .  it only saves half . think we just gotta let things slide for now , and see what 's gonna happen . nothing else really to do .  we have new equipment that i 'm gonna try to set up tomorrow . new wireless . and give us a couple more wireless channels .   but it involves rewiring . and if i could borrow someone tomorrow afternoon to help my brain . just have someone to bounce the instructions off of and make don't do anything too stupid . did i have another topic on the list ? that 's wha what did i have on the agenda i mailed out ? that 's it . that was it . short meeting ? does anyone have anything else ? do we have new dd disks also ? darn . it 's all just scratch .  how are we doing on no , de is full . we must be doing it on d f . 'm just one off .  half . that means we 're p getting pretty close . shoot ! hate not to get data .  i the other thing we could do is stop doing the regular ones . and try to convince other topics to come in and do some . cuz that would be the other thing we were talking about also is once we exp once the disk has been backed up , we don't actually need it on line . another option is to copy it to tape manually we have the back up copy and the tape copy , the archive copy and the back up copy . and then just take them off line . once we have the expanded versions . if we have a ton of scratch disk the thing to do is leave those up , and then use and then not necessarily have the original data on line . full . that would be pretty tight i in the machine room . eesh !  what are they called ? what are they named ? i assume they 're in the p make pool . p make p make magic . or customs magic . if you do "" man customs "" , it has almost all of that . do we have an attribute for non interactive machines ? ",,
Bmr030.E,cuz i was thinking that would be a good one to have . ones that aren't on people 's desks . y right .  anyway . shall we do digits ? and off . ,,
Bmr031.A,"hello ?  should we close the door ? i tend to th there 're a couple meetings where there are a lot of preambles like this , in which case the transcription doesn't start until someone actually says "" "" we 're starting right now . this is the  u didn't get the door . is it turned on ?  channel b . channel b . do they know about your pie chart ?  he has a pie chart on the , s the current status page , which shows the amount of transc amount of data that had been transcribed and the amount out of the entire and at this point it 's not quite half . wouldn't is that what you 'd say , with the pie chart ? and then of that , there 's , a little sliver i could try and draw it but it 's probably better to describe . roughly . almost . not quite . and i haven't actually caught up with , since i got back recently from my vacation . i know that the transcribers finished , several meetings while i was gone . and i haven't told you cuz i haven't figured out which ones they are y are yet . but when that happens , then that pie will get even closer to the midline . it 's not quite fifty percent but really getting close . it will be . not mathematically . n but it 's a it 's i recommend his graphic , cuz it 's a really graphic . can't we downsample and , transcribe on that basis ? also seems like the corpus could all be standardized on s on this the ,    do you want to write on the l on the board ? i could write on the board . last updated in july . i 'm not the one that i saw on the web when i came back .   yes . at present there 's n none of those are on the pie chart . there 're five ? good . the c the cross hatching there is , is it 's been through the double check . right ? it 's this is the it 's it 's been tran everything on the it 's when i add a couple more from that , that were done in my absence , that th we 'll be down to about there . it 's not quite as close to half as i 'd thought , but it 's , it 's more than a and these right here have been through the double check . these haven't . how of you , holding the thing 'm not  are they from one of the foreign language ones ?  good . those will figure less prominently in things anyway . long vacations .  it 's an extra step . for speed . to get rid of what ?  no . no .  ",,
Bmr031.B,"right . it would have to be hand right . it would have to be a h a person would check it over and then give a final i 'm it 's more you didn't  you were saying that we were waiting for chuck , just   that 's good . i overlap exactly with the times you 're gone .   pie .   but that was read speech . like twenty hours . we could try , but not counting the non native speech , cuz if that just doesn't translate very right . and actually the i was thinking about this the original application doesn't really appl if you 're using this over and over again , you 're gonna be testing on the same speakers . mean that it 's not a terrible thing to assume that you don't have disjoint sets , for this particular application .   somewhat . although what 's interesting is that the majority of the words in the language model are actually they 're actually these function words and "" "" and s like that . and there 's a lot of speaker dependence there . even the transcribers will say they know who the speaker is after a while just from their backchannels and right . i don't think you 're talking the way you write , in other words . what 's the plan if were we still going to be like a center for transcribing data ? what happens if th they don't deliver things until next year when we have less resources or ?  are they 're doing twenty two or s ? could forty eight ? forty four ?  cd rom .  forty four . s but it but forty four and sixteen are not easy ?  it 's not lossy ? as long as you 're  as long as you 're not doing the processing on the downsampled just for transcribing it , for  they 're taking up more disk space .  they 'll have to start kicking people out of the meetings , like as long as they have only three people per meeting . they can just limit the number of people . they were g they said they were gonna record @ @ i don't know if there were fifty , but there were definitely above twenty . it was high . sixteen . you just get one backchannel at a time and there 's never any talk ? was there ever any talk of taking the , close talking mikes when people aren't talking and deleting those portions ? or is the breathing and things ?   and if they 're still that big i see . that 's true . it 's still really big even if you 're only one person or two people at most are actually talking all the time .  have shorter meetings ! morgan .  they 're really going to have a huge especially hawaii . really ? are they like these , right ?  they usually do thursdays . ",,
Bmr031.B,"i don't get a lot of advance notice , but it 's al always been either mondays or thursdays .  they often do it after for a while they were doing it after this meeting . wednesdays , fridays definitely wed definitely wednesday i 'm not here , don't record anything . but feel free to overlap . no , always get scared when you do these portions where you 're not gonna overlap because there 's less data points . people could backchannel and ask questions and  right .  but i don't think it 's "" aha ! "" . it 's more like "" "" rather than "" . great . great . y w we should talk to you off line about something .   but it has to be multi stream . th they in other words , the beginning of something could be one speaker and the end of that unit , like question answer pair , could be a different speaker . that 's why we can't just annotate the transcripts , one listening to one at a time . that 's why the transcriber 's for listening to it , but you can't actually encode , encode someth exactly .  it 's actually not a bad idea to say "" beep "" as a word because you can search the transcripts , y for that , to find these places . no , i 'm s i 'm serious . to have one word , like "" beep "" , especially with a really long "" eee "" like that . works great . wisconsin fishing . twentieth . beep .  actually we had this ide from the last time that they were here , that it 'd be to have uw do some work on language modeling that would be trying to get at the same detection as what we do acoustically since they can ramp up much ques quicker in the language modeling and we don we 'll do the , prosodic side . and this is supposed to be a project that we could actually integrate the posteriors that they get from their language model for every word boundary or every frame boundary , and then train up the classifiers . and it 's it 's an undergrad , too , that 's going to be doing this work .  i 'll just really briefly , i 've been working with don and also and andreas on the this paper on prosody , and what we 're trying to do is predict where people at given all information up to whatever point in time you 're considering , try to predict if that 's a good location for someone else to jump in . that 's the idea of that paper . and that 's the same task that mari , a a student named dustin , and also sarah who was at this last meeting will be looking into doing from the language modeling side . some clu clustered class n gram ",,
Bmr031.B,"and also we 're using a couple of the labellers who are doing emotion to help us , finalize some transcripts for this . these undergra undergrad students are really helping us out a lot , under don 's supervision , actually . that 's good . these offices are being , very busy don 's and the one across from him . and then also , working with jeremy on communicator emotion labelling . and most of that up to a few weeks ago was just getting the people labelling these utterances to a computer for emotion and that 's going pretty now .  we 're mostly looking for places where the person 's frustrated with the system . there are actually that 's how we started it . and we had different levels . now we have things like "" amuse "" . like , "" you finally got it "" . and and "" disappointed tired "" . like , "" no , that 's wrong again "" . which isn't really mad , but , th they gave me a lot of feedback . the labellers , after doing this , told me what they wanted as categories . and then there 's jokes . and right .  there 's not a lot of enough frustration for us to really go through quickly , cuz we have to label every meeting and also things like repeats for the same information , and forth . and i 've been coordinating a little bit with katrin at , uw who was doing user correction work that she presented at the meeting . there 's some overlap there in what you m there 's a correlation between corrections and annoyance or frustration . but jeremy 's been starting to really work on that project now from the acoustic side . we have all these waveforms , and he 's been with morgan 's help and , dan ellis 's , looking into spectral tilt a bit , he can talk about that . it 's a feature we haven't used before . and starting to , r take information from alignments and create a database that we can use as a large feature vector or table to feed to our decision trees , which will try to give us back an answer from the speech only as to whether the person 's frustrated or not .  actually , i wanted to talk with you about that cuz there 's a similar project at sri where we 're using we want to do something like that to look at whether or not some of the p stylized pitch is , perceptually similar to the kinds of things that people would mark . i actually wanted to talk to you about that .  cuz this will be after this will be after september anyway ,  right . there was just no way to use the energy in festival , that was anyway . i should move on cuz we 're running late , ",,
Bmr031.B,"but i wanted to say there 's one question in my mind , which morgan can talk to jeremy about , is how to normalize spectral tilt . it 's just i 'm in this , area i don't know much about and we should talk off line . but if you have a certain speaker and you wanna get a bunch of data from that speaker but compare it , directly on a feature to like a decision tree that won't normalize anything for you once you feed it the features , how do you normalize over a particular speaker ? what kinds of what makes sense to do with that feature ?  i but that 's something we would be glad to have help on . go ahead , jeremy . the thing i we you wanna use spectral tilt to try to get at the s n the voice quality of these utterances . you could have something like "" no "" versus "" no ! "" and these might differ in that way . but the problem is we don't know th we don't know whether the "" no "" is frustrated or not .  right . exactly . and then you also have the different speakers . and the question is , do you wanna average all the data together or do you ? you wanna capture the change in voice quality within a speaker , without having to know ahead of time w which is which , cuz that would be circular .  u this is but do you do this , say , just in the vowel regions , and do you ? a there 's a whole bunch of , unknowns . and we can try all of them and just put them into the tree as features , and  everything up to that point . that 's that 's the we keep you keep , iterat you keep updating those numbers for future utterances . th that would work .  you 're just using a mean and the varian and a variance ? just a z square , like ? right , right . it is distributed in a way that you can do this . that 's that was our this will work , i don't know .  we probably won't get that far .    m median , we could just plot these for a speaker , and get a bunch of histograms .  right .  really s really hungry fish . it 's already dead . ",,
Bmr031.C,"we 're recording just for  you can keep talking . just g guess you were gonna  the compromise is we 're starting but we 're leaving the door open . we 'll have a little more background noise and really ? the meeting 's started . this is the real thing . this is the real thing . never mind , it wasn't . there goes chuck . just kidding , it was .   last guy in gets the you just get the door now .  @ @ adam sent around this thing about what we were going to talk about and th we had this discussion of , flipping back and forth between an emphasis on the technology , particularly recognition , versus , the recordings and transcriptions and on . but , i was asking , if we could , to make it just whatever is happening rather than one or the other because , next weekend next week i 'll be at a meeting on campus and after that i 'll be europe for , several meetings ' worth . you folks 'll be gone for a couple of the meetings ' worth in europe also , right ? really ?   you didn't get an agenda , we 've got the usual  we sent them and the what pie chart ? half the data that 's been recorded has been transcribed ? that 's getting pretty good .  if we can have three point one four times as much tr transcribed as we recorded , we really would be doing you were already using adaptation w on the test set . i see .  got it . right . right . whatever this is .  right . you could have some parts of it that are disjoint and some that aren't , and see what the difference is , on the others .   you can separate it out and see how if they 're      someone else would do a lot of the work where probably your advice would be helpful . we 'd we want that for  dave gelbart . not right away . he 's got prelims and  one thing , just a e an announcement of sorts is that , chuck is gonna be going to a meeting at nist , in , about a month and a half , they 're still working out the date . cuz they want to gather together one person from each site who is involved in the meeting since they 're going to be doing a bunch of meeting recordings there . and somebody it 's like one person at the moment it 's one person from each site . there 'll be somebody from the cmu , and somebody from here , and somebody from , a number of places . probably somebody from uw .  it 's possible they 'll open it up to more people . but the main thing is just to , it 's not a conference . ",,
Bmr031.C,"it 's not a workshop , really . it 's just connecting with them .  then if they start a bunch of recordings then ultimately they 'll have training sets and test sets , and all that and but .  i again the hope is that , mean , it 's looking i have to ask these folks but , my impression is that the , ibm path is looking , more promising . and if that 's the case and if it turns out that , it 's really a relatively small amount of time for our transcribers to process things before and after , if they really have taken out enough of the , work that it 's f feasible , then we can do it with a smaller staff next year . next year , in which he 's you 're referring to is , next year we don't have a whole lot of guaranteed funding for this work . other funding may come . that 's but if we wanna just count on , what we know about , it 's more modest than this year . it 's still there 'll still be money , but it 's just more modest .  would see us as probably not doing more recordings at least for meetings or digits or anything . but , if we feel that we need to , probably still doing some recordings for smartkom but otherwise just , stop that and just take whatever comes from the other places , which ,  we have an u unknown rate . if it starts being if they 're generating this huge amount and we can't handle it then , we 'll tell them . but . although it would have been if that their had come earlier , it 's in some ways a good thing , because we 've been ironing out this path .  it 's just if that they 're sending it to us , then we have to have the disk space to do it too . that would be the hope .  d are they doing some integer multiple or ? are they doing some integer multiple of th of sixteen ? forty four point one .  that 's we record here at for at forty eight and then we downsample .  you can do it . you can do it . you can do you can go from anything to anything else . but it 's just it 's just a little more complicated . it 's just like   it 's just slightly more complicated , but it 's but i you can go from any frequency to anyth any other frequency . it 's a and , gue i would suspect it 's because it 's what the hardware does .  it 's the thing that 's deserving of discussion with them . i d i don't think it 's like , i they 'll ask us , we 'll give a simple answer and come back . ",,
Bmr031.C,"it needs some back and forth because it 's a little gnarly to have parts of the database with different things . and it 's ,  i part of the arguments for the higher sampling rate is that there 's something , say , in six to ten kilohertz that you might use for some purposes somewhere . if people are doing a wide range of things , doing location , doing a bunch of things , why throw it away if you don't need to ? on the other hand ,  it 's @ @ sixty kilohertz is plenty .  i th it 's , and they are gonna be using up a lot of disk , both for th them and for us when we 're pr processing their if they i w wa if they 're going at forty four , they won't even creep . they 'll just pounce . that might help a bit . actually at nist they were ta there were there was some discussion of fairly high sampling rates too ,  i don't think that 's true . they 're recording fifty channels of mikes . they are . they 're recording all of them .  i don't believe no . i don't think no . think they have actually a very large audio data rate . it is comparable to a video data rate .   interesting question . and that 's and that 's no video . sample rate ,  not if you have to distribute the video also . you 'll have some interesting discussions next month when you go out there . how are they gonna what 's the distribution plan ? if they have something really smart in mind , we can use it . mean , w we talked about sending around a disk or a computer . compu that 's why it 's only fifty gigs . hey , it 's the first time i 've ever heard you ask for less data . that 's probably a lot of it . and they 're gonna have mikes like that too . their array will be    now we bought a little not all that long ago we brought three thirty six gigabyte disks .  think after that we need another , rack right ? change servers ? we should probably do that while we have the space left on the th the existing thirty sixes , that we can shuffle it around .  that 's right . there are eighty gig drives now that you can get for that ? see , and that 's probably what we should send around for these to d for distribution of this corpus . this s isn't any  that 's what i meant ,  actually , what what , was it dave who was suggesting that , you just get , a computer that has one of these drives in it and just send the computer around to the different sites . and you can just get it off the computer ",,
Bmr031.C,"and press the  laptop ? send the laptop . and , you don't want y we don't want to trust the shippers necessarily , you send a person too . and they just go from site to site , and download their data johnny appleseed .  what ? does it ? there 's a they really need it in novosibirsk . r i 'm probably pr mispronouncing it . that needs a month ,  to download . things are slower there .   that 's the meeting transcrip you 're we 're you said it was almost half , that means that we have eighty or hours and out of that thirty five are transcribed ? he 's tethered ,   i see . that 's that 's not half .  a couple weeks ago . but about how much do we have that 's      alright . we still have a long ways to go but the , the ibm thing will help push through the rest of it somewhat quicker .  it might partly just be european summer vacation issues .  right .  www . what else is going on ? why don't we just go around , cuz we only have a few minutes . what new hardware ?  wha what 's your question ? what 's your question ? there 's a point when a bunch of us are off at eurospeech .    right .  i was just thinking just go around and just brief briefly look what 's other things that are going on , since we don't have much of a set agenda and we don't have much time .  why don't we d we deliberately pick two people to  i 'll i 'll keep saying "" . this is natural meetings . we have no effect from our preconceptions . with my backchannel ?  which one it is ? has anybody done anything ? come on . what are we doing ?   minute , what ? what 's , the original transcriber written in ? i see .  right . beep . not answering your calls , "" war and peace . ""    i 'll take that role anytime you want . i like saying it .   any sense about how it does on ? right , but i was just asking if you had a sense yet of , whether you already did this experiment , where there 's this question of how much it hurt you or helped you to use segmented versus   good . good .  your results are about the same as bush 's , his bush 's . you 're both , he 's coming back to the heartland and right .  he 's b he 's been he will have been off two months out of his first seven in office . that 's a pretty good deal . anyway . who are you talking about , bush or don ?   based on hub five , or like your ?         we 're doing , ",,
Bmr031.C,"should mention , dave and i have been pushing through thinking in terms of an asru paper . but i 'm still early next week we 'll decide whether we 'll do one or not . but because , the results are still confusing enough that , we gotta be convinced we understand what 's going on . but it 's starting to look like it 's almost the opposite of the usual th situation where , you get some really result with , with digits , say , and then you go to a large corpus and the result goes away . we had what looked like a good result in digits but th but then when we went to more training data that went away . the digits result right now is equivocal . but the conversational speech one , while not huge , is in hub five or meeting terms , actually it 's it 's not bad .  it 's it 's like , i w after he did some adjustments , more like a percent or that i th absolute , that it goes down and sometimes . no , i 'm talking about with the adaptation . without the adapt without the adaptation is a much bigger effect . it it 's very reasonable to think of as an alternative way of getting this kind o improvement . but what w ultimately what we have to face with it is that , he gets incredibly good results if you artificially reverberate clean close miked data . think the thing we really have to face is that our model for what 's going on is wrong or incomplete , and that in this situation in particular there 's a lot of noise . and noise plus reverberation is not the same as just reverberation . there 's that one thing that @ @ been thinking of doing , is there 's a whole lot of work that 's been going on in noise suppression in the aurora , team . and they 've got some software and i 'm think of just having us integrate that in , cuz it cuz it just it just subtracts it out . you can run it in enhancement mode where you get speech out and and , then just run it through the rest of your recognizer .  we 're working on that . people have done that for a long time . right ? i don i don't remember the paper . but that th that 's certainly one of the common techniques is to do that . and in all th the that our team is doing they certainly look at regions that you think are nonspeech in order to get noise statistics . but , there 's a host of thing different things you could do . in the aurora thing , we have a little bit of a handicap in that they don't let you , adjust the tis the statistical models . ",,
Bmr031.C,"you have to do everything at the feature level . but , but there 's , wiener filtering and spectral subtraction which are , can be looked at as m minor modifications of one another .  and they 've now built up a piece of software that does u has this general framework for a for it that you can adjust it to an any one of a dozen ways that people have done this thing and they found a particular set of parameters they liked this week . and we 're running with that for a while . but . anything else ?  what emotions do you label ? there 's just two categories , frustrated and not , or ? no .      that reminds me of something . we talked about something a ways back and i lost track of it , about having a synthesizer driven with cuz you have this as asru deadline . but that seemed like it would be fairly straight forward , that if you take the pitch from the real data , feed it into the synthesizer , and then process the output with a gain box that you also had energy from the real data .    i 'll have to hear what he 's using , f given different suggestions he 's gotten . but  wh what specifically , what you wanna do is remove the average , speaker tilt in some sense ? you don't know it .    m this is too obvious to be right , but the normal thing for c one would be to , get rid of the mean and th and the variance . right ? does that ? the mean and variance . have it be zero mean and unity variance . and then right . the answer 's you want it for every place that 's voiced . no , ev everything for that speaker .  but the main the main thing is that the you 're right . the main distinction is whether it 's voiced or not . if it 's if it 's silence or unvoiced regions , then you don't really want that in there , if you can help it . but actually , just to first order , suppose you just didn't do anything smart and just did did that , it wouldn't be that bad . because you 'd get some number that would be skewed by that x x x minus mu over sigma . it it 's the first order thing to do . there 's , much more arcane things to do and complicated things to do . but that 's th that 's the first thing to do . and then then the next thing is , "" let 's just look at the voiced regions "" , and that would be a reasonable thing to do . and then if it 's really when you look at what y i ",,
Bmr031.C,"since you 're looking at something that 's in log domain , cepstral is like log d linearly transformed of a log domain , it 's probably not that terrible an assumption to pretend it 's gaussian anyway . and the other things that get more tricky are , to handle the fact that it 's not really gaussian . and y you may not really need that for this . think that would be the obvious thing to do . no , i understand . it 's just it no , it 's more that if you felt something wasn't gaussian and you were trying to normalize for some bias of some sort , you might use a non parametric measure , like you might use a median ,  and rank statistics , and all that but you shouldn't bother with it if it 's roughly gaussian . just   and i already said what i was doing , which is mostly trying to give advice to dave when he actually does the real work on this , reverberation thing . but it 's it 's a real , it 's a real learning experience for both of us . and , it 's a problem ar problem area that people really haven't dealt with that much , as we know . w h he did he started off with what was in some sense the first obvious thing to do , although hardly anybody had done it yet . and , it does work very under some conditions and other conditions it doesn't . and now we 're understanding trying to understand what those are . it 's it 's fun . do you want to add some anything ? to say anything ? how was y did you catch fish , or ? no . no fish . when bush catches fish they actually put a bunch of fish in the lake for him . i 'm not kidding . really . they just they pre stocked it with a i 'm really not kidding . we 're ready to increase our federal funding . why don't we ? let 's do that . i still don't know if these are gonna be any good but it does get us out of here quicker . a one , and a two , and a three . and you were worried we wouldn't have any overlap today . ",,
Bmr031.D,"four .  cd .      sixteen . it 's shortened .    it 's really short , .        just not yet approved for  you didn't you wanna say something about the hardware set up ? nothing this week . end of next week . let me check with robert again , but i 'm pretty that there 's nothing this week .   i 'm  i don't like the backchannels as that 's really a problem with the speech nonspeech detection .  i 've been doing a bunch of recognition experiments on meeting data with different , segmentations with different automatic segmentations , but it 's not yet finished . it 's work in progress . for , for the paper i w i want to submit to asru to , evaluate the quality of the speech nonspeech detection by using it for speech recognition . it  it hurts compared to the ideal segmentation , when you have the manual segmentations , where you have exact boundaries for each s utterances . sometimes there are some words are cut off or there 's some segments i are s assigned to s to speech which there is nothing in . and there are more insertions but most of the time there are more the number of deletions is higher when you use the automatic segmentation compared to the ideal one . and 'm just in progress of , trying to feed the recognizer with un segmented data and to see how much worse that is . that i have three things . un un segmented , the automatic , and the ideal one .   i haven't really had time to do that .    after wednesday ?      ",,
Bmr031.E,"right . 've been looking at spectral tilt and different ways of perhaps generating it . and , i have three ways right now that we 're looking at for , we 're gonna look at for features . one is just looking at , the first cepstral coefficient and , using that . another is looking at the log ener the difference of log energies between , the high like a high frequency band and a low frequency band . and the third is just , taking a slope , of the linear fit of the spectrum and using that . those are the three ways i have right now for generating these spectral tilt numbers . and , hopefully soon we can look at some of the labelled and look at , these numbers and see which ones w seem to be working and things like that . i also recently wrote a script , that , generates the kappa statistic , which is a for labeller agreement . been looking at that as ",,
Bmr031.F,"we 're on . we 'll for chuck . close the door behind him . y you can keep talking , but you should be aware . and then , then morgan said "" why don't we start ? "" and i said "" o k "" . or we can close the door and make chuck knock when he comes . and chuck gets stuck with the ear plug mike . but he didn't shut the door . i got it since because no one ever rep responded with any items . have a couple of minor ones .  our normal transcription status , just that we can make some plans . wha what 's up with ibm , chuck ? do is yours working there , chuck ? can you ? you 're b you 're b ? there 's no on . it 's just i 'll let me raise the gain on that a little bit since it 's far from your mouth .   pie ?  also , now , that 's a strange   how much how much do we need transcribed before it 's worth doing some trainings ? it seems like probably we have enough now . right ? because , like macrophone wasn't that much data . right ? and it helped . you only used that for digits ? right . that 's right .  right .    supervised . h how would you imagine doing a test set on this corpus ? a test set , training set division ? it 's really weird . right ? because it 's it would be hard to get speaker disjoint sets . do y do we just give up on that ? but then you have the supervised versus unsupervised question . right .   right . and then s similarly with subject matter . that , if you 're training your language model on this meeting only and testing on this meeting only , you 're gonna do a lot better than if you start crossing them . are the same .  just from word choice ? most certainly . it 's just , if we 're gonna do that we should give some thought to how we wanna divide it up . and similarly with digits . we now have a lot of digits but most of them aren't transcribed . if we wanted to do a forced alignment on them , we could start collecting ourselves up a fairly large digit corpus . and same issue . we just need to get someone who 's interested in that to start looking at it . who 's working on digits currently ? 'll talk to him and see if he 's interested . certainly . he wants to pass the prelims .  is , are the cmu folks gonna be there ? right . right .  it pretty good .  i got a email from one of the uw guys . ",,
Bmr031.F,"they want to record the meetings at higher , sampling rate than sixteen kilohertz .  i didn't ask why . but it seems to me that really doesn't matter . if they have the disk space to do it , it seems that is not a big deal . i was just wondering if anyone had an opinion about mismatched rates .  excuse me ? no . no . no , it was like forty something . forty four , forty two .  something like that . and then we downsample . you get aliasing . the only thought was if we 're gonna do a combined corpus , does it really matter if some 's sampled at one rate and some 's sampled at the other ? my feeling is no , it doesn't . your audio , u these days audio tools tend to take care of all of that . but wanted to double check with other people before i told them "" no problem "" . that 's what i was saying .  i don't know . why are they asking us ? because , we 're doing the corpus , they want to be as similar as possible . but the answer is , if we tell him "" no , that 's not alright "" , what he 'll probably say is "" we 're gonna do it anyway "" . but ,   and they just don't want to downsample ?  that 's wh that 's what   but i don't remember what their hardware set up was but it was smaller than ours .  with nist they 're in a different situation cuz they 're doing video . and compared to the video , the audio is just noise in terms of disk space , literally . really ? they 're not recording all fifty of the array . they 're cooking it down , aren't they ? whew . that 's funny . that they were cooking down that data in some way before they were storing it . distributing they 're not going to . you 'll have to just work on little subsets of it . there 's just no way you could get it all .  sixteen . a lot . two or three ? it 's a lot more than that . right ? dvd is eight gig ? that 's definitely the right way to do it . someone sends us disk . we load it with data and send it back . it 's gonna be easier than any other method . if not if you want to burn the c ds , you 're welcome to it .  if they have a way of doing it . i 'm thinking prior to that . we already do that . shorten does that automatically . that 's why you why that 's why shorten reduces the size much . right .  if you talk less it does use less me d m data . the channels  ",,
Bmr031.F,"it 's actually one way to tell if a microphone is dead in a meeting is if the shortened file is too short . then you can be pretty that the mike was off . and , the t unfortunately the tabletop ones the six tabletop which we record all the time no matter how many people are there , don't compress nearly as because they 're almost always have signal on them .  most of them . they won't shorten nearly as and i assume they 're gonna do it lossless .   and then one far field .  it 's things or the mixed channel . there are a lot of ways to do it , but let 's not worry about that now . how are we on disk space , chuck ?  good . we 're using those for the expanded . the problem with that for backed up media is , the sysadmins wanna keep them at eighteen meg eighteen gig partitions because that takes about a day to get off back up tape .  for u the whole institute .  actually , going to bigger disks we can do even , and just maintain the eighteen gig partitions . you just partition them into multiple . that 's probably the next step , is to get the eighty or ninety gig drives to replace the thirty gig or an eighteen gig that we have now .  a whole handful of microdrives . is the areal density of the microdrive higher than of a w normal drive ? it must be .  they have the two gig already . and i 'm just thinking forty of them is probably still smaller in area than , one normal sized drive .  a laptop . eighty gig laptop . i 'll do that . it unfortunately it takes me a week at each site . it does take a week at each site .  a if it 's a site . right . th that only takes a day or anyway .  definitely true . any other items ? i saw the pie chart sticking out ,  d do we care ? we need different color pens , definitely . rustle , rustle . great .  should probably send those to you , shouldn't i ? there are five . there are five . we have five where , everyone has replied . it was falling off , and there 's still , two people for whom i have not been able to get in touch have never gotten a response from any of the emails about , permission forms .   that 's that 's why the nsa ones have still not been approved . though .  possibly . it 's been four months ,  that 's right .  we have new hardware . i want to set it up at some point , just wanted to meeting schedules were . we have several more wireless channels that we can set up ",,
Bmr031.F,"and get rid of these , the wired completely . and then also we got replacements for these mikes .  they 're like those . those are the only two choices right now , unfortunately . question is , when are we not recording any meetings for a couple days that do it and if it doesn't work , we won't impact people .  what 's smartkom ? end of next week . and is edu still recording ? if i did it tomorrow that would be alright it sounds like ?  it sounds like no one n no one early next week .  and then i 'll also re number that , the mikes are in order . should help with the transcripts . they wer right now the channel numbers are discontiguous . right . we 'll all say what we 're doing at the same time . which "" ? that 's a i 'll start if you want . i 've been , most recently rewriting transcriber in java for no particular reason .  trans what happened was that transcriber 's very slow to load . when you have a big meeting it c especially on a slower machine , it can take five minutes before you can start doing anything . and was thinking about why that was and the data structures i would use , and i found myself unable not to sit down and code it . did . and have a big chunk of transcriber now written in java and it comes up , in a couple of seconds .  i it 's not really probably not worth doing . but we can talk about it .  annotating .   dialogue . buttons .  i un i understand the problem .   right . right . what i don't have with it far is it doesn't play wavefiles and it display wavefiles . haven't done that since that part wasn't   and , and then also a lot of the fancy user interface that 's in transcriber i haven't done . but it works . tcl tk .  which is and flexible but very , very slow in comparison . sax . cuz it 's much faster than dom and uses less memory .  and then , preparing for quals . hopefully second week of september if ever get warren sack to answer my emails . i probably shouldn't say that on the tape .  i gotta remember to beep that out . no anyway . 've been preparing for that . and , actually , i wanted to say off line with you about any literature reviews i should do beforehand . "" war and peace . "" that 's a good choice . keep me busy . for "" beep "" . that 's a good idea . no , i agree . all of us are banging . with fishing . b you should have seen the one that got away . can i borrow a piece of paper ?  ",,
Bmr031.F,"it 's a p h right . is it wrong ? just combine it see . neat . mean and variance .  she just got back . the secret service is out there throwing fish into the ocean into the lake . "" hey , i caught one this one and it 's already cooked ! "" we 're done . should we do , simultaneous digits that we actually have time for tea ? ready ? got plenty of overlap . and and we ' ",,
Bmr031.G,"there 're some words that weren't see , there 're some stretches that weren't even in one or the other ,  what are you gonna do about those , though ? you 're never    pi will be close to one half ? that 's new . right . this raises some  how do you transcribe that ? b we can we already use it for digit training .  we did do some training on digits rather adaptation on digits . supervised adaptation .    i would love to do some , with adaptation you can use fairly small amount of data to improve your performance . and n it 's just  i don't have to time to do too much these days except what i 'm already doing .  but if there 's some someone has some free time , i 'm i 'll be happy to show them how it works and you can play with it . no , supervised adaptation . we 're doing s unsupervised speaker adaptation . but you could build a test set which you take your models and ada do supervised adaptation . and then you start with the speaker adaptation from channel adapted or room adapted or whatever . right . it 's like in , broadcast news because you have those people who re occur over and over . the anchor speakers tend typically .   as long as you 're aware that you 're doing that , that 's i don't see that as a problem .   but it would be interesting to hear what they intend to do about the speaker overlap , it could be interesting . it will be interesting to find out why they are choosing a higher sampling but then they 're just there 's just deferring the problem to later and they might save themselves a lot of disk space problems by doing it right away . that 's wha that 's like three times as much disk space . we should warn them that these disk space issues are gonna creep up on them very fast . linguistic data consortium . we should just talk less .  for dis for distribution purposes it might make sense to split it by channel , rather than by meetings . you could distribute only the near field signals , together for a bunch of meetings and then have a second row .  right . but the university of hawaii has issued a request .  those europeans . they got a lot of vaca   we had the transcribers have trouble with your backchannel , because with your backchannels . because sometimes you have this this "" that you don't n there 's "" and then there 's "" aha ! "" . and it 's not quite clear always what it is     u do you take feature requests ? that would th w s actually , it is worth doing because here 's the thing . we 're we 're starting to move from transcription to annotation . ",,
Bmr031.G,"and the transcriber interface is fine if essentially what you 're doing is stringing words together to p to make transcripts . but , in what we 're doing now w with , communicator data , but which we would like to do with meeting data , is to actually label utterances , or words , or whatever units you want with , doing a multiple choice type of labelling . and for those type of tasks , it wou it 's much more efficient to present , the th p present a bunch of , clickable buttons or whatever and , and th that 's actually a good model , which is what this current tool that we 're using has , is to atta to associate these labels with , attributes of sgml tags . you have , say , a tag for i don't know what type of utterance , whether it 's a question or a statement or whatever . and then you have an , an a tag attribute and the value of that encodes the choice . display as in showing the waveform ?    but we didn't have the exact comparison . but there were i the experiments were based on different segmentations and different transcripts . we weren't quite which whether the difference came from different transcripts , and thilo 's but the recognizer 's putting up some resistance because it doesn't like the un segmented data .   i 'll bet bush went on this european trip recently and they told him there that they get more vacations . he came back here and thought "" afford some more vacation too "" . it 's hard to keep concentration , and the focus on the  while he 's vacationing , we 've been , this is like a joint effort . d we were just  f apart from getting preparing the da the data for the , for these experiments for the , for this prosody workshop , we just , we just had a phone call with mari and her students , and they want to , e m they 're bringing up their own meeting recognizer , which is based on bill byrne 's , recognizer from johns hopkins . u based on their hub five recognizer . and , they 've been getting from us the , some support in terms of getting the latest transcripts and the also the actually the , transcripts annotated with events , like sentence boundaries and like that . because one of mari 's students was to wants to do some language modeling for , predicting overlaps and , like that .    on the recognition side , actually , the main person doing that is , harriet from harriet nock from , formerly of cambridge . and they get reasonable results except in some portions they get very high insertion rates even higher than we get with the , like even , on lapel mikes with , background speech . ",,
Bmr031.G,"and they were trying to track that down , and it could be that our recognizer 's actually doing relatively because it has a reject model for , mismatched speech , essentially , or for unspecified speech . and , they 'll i sent them our recognition output they can do a line by line comparison and see if they , their insertions correspond to our rejects and like that . we 'll see what that , leads to .  other than that , we 're that 's pretty m it as far as meetings are concerned .    right . but is it still true that the s speaker adaptation , negates much of the advantage ? with it .   right . right .    there 's some work , that do you remember this paper or poster by , some cmu folks at , hlt ? they were talking about and they s they referred to an upcoming icassp paper , at the time . some someone in karlsruhe , worked on , es estimating noise from the silent regions and then , doing some explicit i don't know if it 's something akin to parallel model combination like that to , right . anyway , couldn't judge whether this was original or not , but it seemed like they got pretty good results on their meeting data . we might want to look into that . right . right .  right .    right . hey ! we could use that in the english we have to do the english synthesis for what if we make the system really annoyed ? but you can't do it you can't just normalize it based on the utterance because then you 're gonna have zero everywhere . right ? you 'd have to normalize it based on the but that 's not really feasible because you 're having a sys you have a system , a dialogue system , where you only have access to the what the speaker said before . it 'd have to be causal , version of @ @ . or you c u  we 're not gonna build a parametric model of the o of the feature . right ? we 're just gonna we 're gonna use like thresholding right , right . right . right .    but they didn't tell her . it to keep us ,   did you jeremy , did that whoever finishes last has to buy cappuccino for everybody ? ",,
Bmr031.H," if recognition 's better on the channelized segmentations , then how many ?  f cd . forty four one . but forty eight 's a multiple of eight . you can do it , you c y there 's probably some  it 's s someone 's gonna have to downsample .  it it 's four or five times . depends what you save .    that 's eight kilohertz ? sixteen . it 's shortened .  and then shortened . what 's ldc ?   all of them are like that . god . y put the computer on tour ?  what does that mean , "" finished being transcribed "" ?       let 's get rid of them .  got back from chicago .  fishing went pretty and , i was gonna post some results , with , wisconsin fishing .  y who right . whose result ? right , exactly . i did my tour of the heartland .  i built a few houses .  but right now i 'm working on this paper this isca paper for this workshop that liz and andreas and i are putting together . we 're just getting , different results for we fixed up our different , transcripts with different types of , annotations and we re ran ali re ran alignments . and we 're gonna develop a new feature database based on those alignments and do some trees and analysis . 'm in the middle of that . and hopefully by the twentieth , the twenty third . the twentieth ! we 'll have it all straightened out . it 's gonna be a busy week . it 's amazing .   right . it 's part of the budget . how they they got scuba gear on and hooking them . ",,
Bmr031.I,"brian is on vacation now but , before he left we gave him , another set of meetings to give to the transcribers . and what is it ? four ? four . test . what am i ? test .   we gave them four meetings before he left and , that 's it . i don't think we 'll hear from him before he gets back . i don't know . i don't know .   right .  why are they asking us ? that 's why i 'm asking . how many channels ? how in the world are they gonna ever distribute this ? you 're gonna have to just get because our we 're estimating that ours if we collect say a hundred meetings and each meeting is just the audio , compressed audio 's half a gig , there 's fifty gigs just for our corpus . for a hundred meetings . and , that 's sixteen . and even a distribution of fifty gigs , it 's if you use d v ds that 's it 's still , two or three d v but if you use both sides and the two layer and all that . s seventeen .   i say we give it to ldc and let them do it . we 're we 've got for the , compressed meetings we 've still got about , it was four gigs , on the one disk that we 're using . and we 've got several we ' v we 've still got , quite a bit of space on the , un backed up .  but it 's probably we should start thinking about where to go next , especially on the backed up disk space . that 's the un backed up . those are the u the , guenter 's wall street journal data went onto one of those , some other experiment things that people are doing are on there , and if you put it there people will use it .  have to change servers , actually . we could there are a bunch of disks that we have , that are s smaller . and they 're seventeen . we could go to thirty five . we could get some extra space out of that . but the s right now the server 's full . we couldn't add any more disks . we could change a smaller disk for a larger one .   then there 's the other issue is that to g add more disk now , david says we really need to go to new servers . but he wants to go to new servers not just for us but for other groups too . there 's this coordination issue , and need to talk to him more about  when they come out with an when they come out with the eighty gig microdrive then we 'll just send one of those little things around with all the meeting data . ",,
Bmr031.I,"the pie chart shows actually m meetings that are ,  it combines the categories of , "" currently in "" i 've got it right there , there 's just a few ,  except i 'm tethered .   it combines categories . when we say "" transcribed "" , we mean either in the process of being transcribed , either here or at ibm , or completed transcription , and it also includes , checked . it includes a lot of categories together .  and that that status thing is kinda old actually right now . that one that you have ?  the the date on this one is july twenty sixth , i have to update it .  we have total number of meetings is seventy eight meetings and , the total meeting time is seventy five hours . and , the ones that are finished being transcribed , as opposed to in the process of being transcribed we 've got twenty six hours that are finished being transcribed . there 's , several processes to the transcription . there 's , i it ranges from being assigned to a transcriber , to them finishing transcription , to then being checked , with a double check . and when we say the total transcribed , that 's the one that 's gone through being checked , i believe . that 's what the i have here . but not yet approved . and then there 's , the final one is approved for release . that 's after the meeting participants have gone through it . if currently that 's zero , released approve   we have five that are potentially releasable then . that 's approval in progress .  thursdays ?  are you using ? are you using the ? you are . we already talked about that . the xml reading sax . right . right . who was that ? did you build any houses ? don't even really notice , do you ? ",,
Bns001.A,"  hm you  we should in this thing of seamless handoff or handovers should think more in different layers ? one layer is having the seamless handover . it 's clear if a technology doesn't provide that quality of service , you can't do magic and have it . there are certain constraints on that . it 's true . that 's still in mind . but for with the cases there , it is possible . that should be made possible then ?   there are still enough problems i in doing it .   but it might be the wrong thing to promise , ten megabits to everywhere . there you are . but saying "" if it 's a if the technology is you can do it . ""       hi . ist fertig . how 's it start ? who is using mobile phones ?  but usually wap shouldn't is general that it can be used with umts . if you still want to use wap with umts you might be able to do it . but that shouldn't be your only way of but usually that 's not the reason to have umts .  my impression on this proposal is that every single block has some research done already . multicast . this means that there are many things done . what was it ? was routing mobility management but no one actually put them together . but that 's the big problem . but the problem with this problem , might be that it 's too big to put all these big pieces to that you really have a complete scenario . you have , in one scenario , multicast , quality of service , routing and mobile networking . not just the islands alone . but  but but for theoretical or for historical reasons a really good question , "" if we would have the money what would we do with that ? "" if we don't we would like to do with the money , we probably wouldn't get any money to do what we don't know . that 's why , it 's a good question .  that 's just the same question just other way around . modernistic completely useless ! ",,
Bns001.B,"   hi .    joe . i , as all of came from spain , from the polytechnic university of valencia and finished my phd thesis about power saving techniques for wireless networking . i have developed an algorithm to control the ra radio frequency power of a wireless transceiver . and , 've been working also in routing issues , especially in the called ad hoc netw wireless networks . where you have a set of , mobile nodes and , no other infrastructure , no base stations . all the routing functions are done by the node by the same nodes .  nodes act as both end points and routers .  i 've in the study for some time these networks . and , there are a lot of research articles about this networks because infrastructure based network has been a long topic of research .  routing on wired networks is a topic still to be researched but it has an important background . but mobile network this mobile networks is a little bit newer , especially because until not long the things were too heavy to have a computer , a wireless transceiver , on a more or less portable thing . with the advent of this new technology , low power high , processing capability and wireless networking capability , in a really small package , new devices are being built and are appearing , in the market . and , this is more or less what i have done . and the things , i 'm interested is more or less all , around this these networks . but i could say , in general , mobile service is not only about , these specific networks . but , in general , about , services over mobile or services that can benefit from the capability of nodes to move around . and , i 've been teaching now for twelve years , comp at a computer sciences school in my university , i 've been teaching computer networks . and , i am more or less knowledgable about , tcp ip networking , iso networking , and , 'm a computer guy , 'm really say proudly more or less , computer skilled . operating systems programming languages networking @ @ . this things 'm more or less trained .  this is , my first presentation . next next meeting i will do a small sketch about my past work , and presenting some det a little bit more detailed approach with some schemes and some things from previous talks , you can have a better idea of w the work i 've been doing .   y   that 's    like have a blueprint .    and you can build a an a double technology adapter , too . you can market these double technology adapters . and , this can be a potential income , too . because you just have to license , wavelan technology . you can build , the whole thing . ",,
Bns001.B,"this u umts wavelan , mixed together .  they are using different , radio technologies . at the physical level , they 're they are not compatible .   that 's right . but i have a point regarding the this question , is the cost function .   what about the user who is switching from one let 's say zero cost area network to another network where he has to pay . it is for the service to continue when he switches from one network to another . but probably , the user wants to be aware that he 's switching from one place from one network to another . because while he 's having , let 's say , a vide video conference over the wavelan he 's not paying any extra cost . but when he continues with this service on the umts , he 's having to cover an important let 's say , an important cost or some cost , non null cost .  this can be something that probably the user wants to be aware of . this doesn't mean that the user wants the connection to be dropped when he switches . to the w from the zero cost area network to the non null cost area network . but some users want to do this . because they say "" i 'm not willing to pay any back for this service , because i 'm just watching the sports news . if i switch if , because of my motion , i 'm switching , or i 'm going out of the coverage of the wave wireless local area network , i want the service to be stopped . "" and this can be some pattern then that some users will follow .  but when quality of service comes to the scene , we have a bigger problem because this seamless migration cannot be seamless because the quality of service we are getting when we are connected to a certain network , let 's say high speed networking , cannot be sustained when we are switching to a different technology . this is another thing that is putting a little bit in more trouble our scheme or       it can be done . it is just trying to poi to pinpoint the possible problems .  if you take the slower technology of the ones you are planning to support , you can offer this warran this this throughput as the minimum warranty you can get . if everybody is asking for less than this minimum amount , no problem but in this case , not too much effort should be put on providing this quality of service because you just have a usually a huge bandwidth compared on a w with what the user is using . if you have a ten megabits bandwidth and the user is asking two kilobits per second , you can build certain reserve mechanisms to warranty the user these two kilobits per second bandwidth . ",,
Bns001.B,"but probably in it isn't it is not worth because you have many available bandwidths that it is not a problem . hi .  have you read about this barwan project held at berkeley university ?   barwan . barwan . da it was another related project called daedalus . and it seems they what they were doing was some things si somehow similar to this . u don't know . take a quick look at the thing because i was read about this long time ago . and it the latest report i found was in nineteen ninety eight . and in this report , they pres they have some slides , some papers , some a lot of things . and the main thing and the quick thing i was looking at was a video available in mp thr in mpg m peg format . and what this video was presenting was a test of one guy with a portable computer , moving across different networks . starting at the cs department at berkeley and then going out the street switching to the a campus wide network , think it 's a metricom network , an which is test ricochet ,  that 's right . and then , finally switching to it was city pd like this .  i as lo as the user is moving out of the coverage area of this second network . and , what they have built is a proxy structure . they are putting most of the work of this adaptational layer on the side of the proxies . the client or the server is not changed . it is the proxy , the one that does the work .  you can even , use it 's the same ?   i it is just that we can take a look at more in depth look at this project just to see if we are doing the same , or if we are doing something similar . it would be important for us to highlight the differences . because if not , they can say , "" you are doing the same thing . "" "" this was done now . "" we are close .  no problem .  uc ber berkeley ,  i 'll i you seen reports from nineteen ninety ninety six , ninety seven and ninety eight . the project n that the leader was professor katz .      b le let me ask you a question about umts or third or possible fourth generation communic wireless communication systems . from the point of view of the user , is there something more that nnn , that than more speed ? is there any other advantage , from the point of view of the user or of the terminals ?      but but now , at the gsm level , what you have is that every voice channel you use provides a p a pretty fine fixed data speed . ",,
Bns001.B,"we can say that every voice channel has an i an incr implied quality of service , which is nnn ninety six hundred bits per second . full duplex . doesn't it ?    no , but but not only because of data speed , but also about delay ,  because gsm networks were developed to y with a voice service in mind . delay is also considered in these networks .  for every voice channel you have pretty fine maximum delay and jitter , and a specified data speed . you can scale up this this thing by using several channels . you have , using just gsm technology , you have more or less the same building blocks as you can get with the umts . that one thing is that the technology is a little bit different , that the base station thing is different and the internal routing inside the network is different but from the point of view of the mobile things 'm not if  but the it is also being d developed , this g dprs thing , gprs thing . which is pack packet data over gsm .  i don't see that a lot of difference . we can expect a lot of differences f from the mobile terminal point of view . when umts be deployed . what i 'm trying to say is that it is not a big problem that any of us be were umts expert because don't see it that the umts thing is more a technology issue , than a research issue . 'm wrong . just es  explaining my m to be done here , not at the i 'm i agree with you that there are a lot o of things to be developed but that this is probably not here . because the orientation of our group which is networks services and applications "" , not wireless technology or the underlying wireless technology .  radio frequency technology , wide band w cdma . these things all have a lot of things to be researched . but don't think w this is not something we are doing here . voice ,     one question . i have a an important doubt about the ip availability over umts . that the carriers and some manufacturers have done an important effort in developing this web thing and 'm not what they plan to do with next generation . are they maintaining are they holding the same web technology ? or , are ju just they discarding this technology and forgetting about the thing ? i don't will happen . i don't have a clue . probably , if after searching a little bit on the net get the answer , but initially this is something to have in mind . because this umts thing will appear on the market without ip as a native protocol . and if this is the case thus seamless integration could be we strongly affected . ",,
Bns001.B,"at least , if you we want to use u m i 'm just throwing the question . mean , looking for an answer because i don't know if some of you have a clue about this . i don't carriers are planning to do about this .    no . no . not me .  in spain it 's available but my main complaint has been all the time that it is difficult to me to believe that do interesting work with a 4 lines display . check the lottery result like this , but   i don't will  u let me propose a reasoning way . let 's assume that we are successful with this proposal , we get the funding to do whatever what we want to do . my question is , what we want to do is ? let 's assume that we have the funding . what will be our first and or and second steps ? what things we we will buy , what things we will program or we will deploy ? because answering this these questions we can know much better what the application we want . let 's assume   let me put an example . some days ago , i bought , like some of you , this things . this is a pda three com palm pilot compatible , nothing that great , but it has some possibility of being expanded . but the only in here the only thing wireless thing put on this is just this omnisky modem , which is it is a subscription based thing . you have to pay every month , and i cannot imagine that tomorrow i 'll be able to buy a different thing with four different networks , four different providers on it . 'm wrong but if i have the funding i say "" buy this or even buy a mobile computer , a notebook "" .  a lot more expensive , but that 's i have the funding then add a couple of cards at most , because the majority of the notebooks only have two pc cards type two slots .  in the better case , 'm only able to add two different networks to this thing .  the difficulty i see is that if we are if you want to think in two three four different technologies we are too advanced too , let 's say , too in advance for the current technology . which is not bad , but i 'm just saying that it will be able it will  it will be difficult for us to develop a reasonable test bed with the available technology . if somebody tell us , "" now here you have the thing , and just put these four networks you want on the thing . "" how can i do it now ?  i 'm still trying to to get used to the all the ideas and to see that all the things are really connecting ",,
Bns001.B,"because this the most difficult thing i see to get this alignment to this connection point among the different things we are trying to align . that 's why i was proposing this question . let 's assume we have the funding . now let 's proceed . what things we can buy , we can put together , we can program . because at the end somebody will be asking us "" did you do your homework ? did you do what you   but for different networks ? for     w a long way , that 's right .      bless you .    but     and  n not only this . we can even use this u platform to get some european projects in the future because sometimes it 's a good thing but this will this will improve over time , i 'm  probably . this joint work of different countries de companies , universities . this is usually the best the best place to put a project on . because it is involving different partners from different points of europe . hm   unless we speak about quality of service , which is not embedded on ip services . but but nobody 's really using rsvp .   that 's right . if klaus    that 's right . can you call adam ? at this number ? ",,
Bns001.C,"no . this afternoon no , this was unrelated to the things of yesterday and last weeks wha and this probably has to be a brainstorm right now . what i told joachim yesterday was that , for my company the company i work for , they are more interested in an explicit service , than in core technology . u me , on the other hand , i 'm more interested in core service , or c core technology , myself . 'm u i was thinking about how i could combine the both of them . kpn was , they 're interested in having , like , six people working on the project for one year or three people fo working on the project for two years , and have a demonstration for a specifically in umts service . i was thinking that as a not really a umts service , but yesterday , what i discussed with joachim was a w little bit based on your ad hoc networking also . that it would be interesting to have a device where you can switch from w a wavelan technology to , umts . that 's , it 's in the future that will be a main competitor of , of umts , too , like the lucent , equipment has a l huge scope already , like five hundred feet , or even more sometimes . that 's it 's might be interesting for , a service to walk into a building or whatever is available on that network . you can switch from umts or to wavelan technologies .  it sounds strange for a company that does umts to switch to be able to switch or provide the service to switch to wavelan but at the end it makes it easier for your and cheaper for your customers . if they don't do it , somebody else will probably do it .   and something like that could be possible , even a umts to wavelan gateway , or i 'm not if that 's possible like we u if umts re contains redirects or whatever , like switches . i 'm not about it . it could be . it 's not a problem . no , but s you could have a umts gateway that translates everything to that local @ @ . if you will yes . yes .   if connection is lost , i am i 'm not if sometimes you 'd simply have to drop a connection . if you have outstanding connections . but that 's one thing of the internet , right ? it 's should be able to unplug a host , bring it somewhere else and everything continues like it should be . i 'm not if it 's if you really have to con save a connection for all applications , i don't think the one i have sitcom ?   the switching itself could be a problem . becau it 's a depends ",,
Bns001.C,"if one of the other networks is available , you are , i don't know . that could be a t topic for research , more about it .  y yes .  if you can leave it out the network that will be really that 's what you w what i would like to do ,  yes . that we are looking for a research topic on those four areas .  we we went through to through multicast . this architecture with m at least no wireless environment or a mobile ip environment , comparable to umts environments . we really did not find any difficulties there . on the blackboard , that is . in real life there will b probably be some problems . iceberg ? the iceberg project ? barwan of es i know there 's one that 's of randy katz . yes . they worked together wi little bit with nokia ? palo alto ? mountain view ?   i like them   or talk to them about s operations they thought of but didn't touch yet . i was wh when did you go through this ? cuz yesterday i was coincidentally , i b bumped into this project here . it 's funny . yesterday i was just surfing a little bit . and then from nokia i came to this that project ,  nokia research . and then that 's right . and he 's also board in nokia research ,  just to make the list a little bit longer . may you could also think about session management . i do along with the network applications and services , as you might know . it 's a if you can do it in the end systems or at sp specific servers , then , i 'm in favor of that . but se session management , the authentication , if you go from one network to the other , it 's not solved .  nobody really wants a guest on your network . unless you get some money through some way through some way . then , there is also the session management in the sense that a lot of these things at the barwan project , as you said , go through proxies . there might be handoffs at at proxies , like the zip zip proxy that we also discussed before a little bit . that 's als also in the line of session management . then there is this perfect thing the berkeley sockets . it 's almost perfect . they s skipped layer five , session management or session layer , that 's normally with if you do a socket programming , it 's directly the prot application protocol on layer four , tcp socket , or layer five for udp socket . there might also be some research  could you introduce such a session management , or norm what they do right now is they make it part of the application level protocol . ",,
Bns001.C,"that 's what they do most often . like with session management ? for mobile the applications such as ist instant messaging or talks , and on , like zip . it 's just doing a reconnect . if they think that the network is different or different capabilities come into play , they simply do a reconnect it 's part of the protocol . that 's all what about session management , like part of in proxies or is it en embedded in application level protocols ? i it 's how do you want to focus on network services . the network applications "" , if you look at the name of the group , one thing is that the they used to call a n a "" network "" that was if it was like distributed between two systems connected by a network . if you look at "" network "" from the oz layer , then it 's level two or level three , but everything below three . there are , two different interpretations of network "" . but are there "" network applications "" , then ? the name is "" network services and applications "" , s what could be an en example of a network application if you look at the oz stick ?  they will i didn't want to get a discussion now . think it works , but yes , the mapping between multicasting and the umts or whatever that 's or cdma or whatever that 's probably a thing that has to be find out . i don't statuses . they already did it par as part of umts , i 'm not i don't have a clue . i only know how it works on copper and like ethernet and on ps ppp over something and how it works like that , but on the wireless i 'm not yes , but if it 's available that means if if it 's already part of the umts standardization then it 's immediately finished , like , you can tell , kpn go to ericsson or nokia and buy it ? and if it 's not in there yet it could be a suggestion and then the hardware people will make it part u like the etsi or whatever where u wherever umts is standardized they will d go for it . this group could do that , too . could be , but i 'm not really but had the impression that we can throw away our nokia when our web gateways , when we g even go to gprs ,  let alone umts . that 's the impression i get . definitely . but still a le d it 's a fundamental it 's a part of a of design like the the terminal has a wap stick . and there 's a box that has also a wap stick . and they do sometime most cases , they do share an ip address . ",,
Bns001.C,"but doesn't have to deal with ip it 's l just a thirty bit number that a actually is an assigned number . but it 's all only used for identification . that 's the only thing . it 's stored in a wap cookie , much like htp in a cookie and from the wap gateway then it will be htp real htp it 's really a different type of connection . it looks a little bit like the wml looks a little bit like html , but that 's all what 's it 's not ip because there is a gateway , you can access with almost the same microbrowser , the same i web servers . if they provide the right content spit out the right wml language . it 's really a different network technology  but @ @ i  ri right now there is still a lot of wap , actually . that the users usage . my colleagues are .  they are using wap .  i bu you don't have a mobile phone in the usa here . that 's the reason . and i 'm not i doubt that it 's not available in germany . it 's would be unbelievable to me . it i it is . in sweden it is also there . and in the netherlands , it is also available . every provider provides  but  bu i 'm the first one to admit that 's a h that it is a hype , but and but i 'm wanted to say it is being used . but if it makes sense to me and to especially to have wap in between , no . i 'm not a supporter of it . they have this optimized protocol to transmit a few ascii bytes that can rescr refresh the screen with a different animation every , second , a few times . that 's true . i immediately agree . but the thing was , y you just asked "" will it be the same , will there be wap for umts "" and on , qprs . and don't have the answer , but it was not . i 'm just it 's weird to stop doing it with gprs . yes . if you want to do it in a mobile phone want to implement it , as a light stack yes ?  no , not if you have a big web pad then you m there 's an ip stack in it and   c can i do another one , like umts or wireless u i generally are will be m more expensive . and especially umts . if they want to get back the money . is it research topic to focus on the not really billing , i wouldn't but at least the different application of protocol based usage . you have one connection , one application uses ftp whatever , bit voice or some other ",,
Bns001.C,"that those type of application you m may might want to make more out of a megabit per second could that be something , or ? or is n no it 's e that 's true . that 's right .   n i 'm not i th agree with him . but right now we 're looking at b a th you want to do a big thing instead of a great thing . if you d assume that it should connect really good to siemens and to kpn , and to the then it starts to get big we should all go to the in the same direction . if you already assume "" they paid money "" , and now you think , what great thing you want to do , then it gives you more freedom to think about this great thing you want to m do . no . but you don't get one if you try to align kpn with siemens ,  no .  that 's right now the s the status . yes . i 'm out for th one a week and a half . on wednesday , thursday , friday , i have a workshop at stanford and next week i have a week on holiday . could be .  the only solution would for kpn would be that there is a p a project in this area . that makes sense to do in this ar this , the bay area with a group of few people , like four and that connects to this project . one somebody or two somebodies can be found founded or get money to join this project . but that the other four should build a service on top of it , that has a clear business focus . it means umts service  but you see the they ask something pretty strange . they want something pretty strange from me that of a service , a network service . there are sixty million billion people in the world that think of services all day and try to make a lot of money with it in the form of start ups or whatever . and just think of a service like that , if i could do this . w   i bu u until now i have been trying to think about it , but to me u what i have every time i encountered it , it is all this is all pretty close by , like the industry is already behind this . they want to make this available pretty soon . 'm just trying to think more ahead , like use the wireless device as a only as a signalling thing whenever you come in with your gsm phone and there is a pc available , like everything will be directed to the bigger device more services like that . the they are working pretty hard to get ip available very good and efficiently from two mobile devices or wireless devices . a th thing ",,
Bns001.C,"and there 's a we m our group might fo want to focus on the ip over ether no nets like or over ether n no nets ,  over like only over ether . carefully integrated for net but there is no net . if you want to do make like also for wireless devices end to end ip available , that could be a vision . like . he says ip to ip or end to end ip , is far it 's far away .  you what you might want to do is get u m t s out there and just do ps playing over radio . like sdh , ip over fiber or wdm . this gets rid of the sdh . or , start with get rid of the atm first and then get rid of sdh .  you guys do that discussion later on  rsvp .  don't switch it off . ",,
Bns001.D,"  adam . we could start with our meeting ?   you have to stay all the time here ? but ch you wanna do ?   we can do that . two nine seven ? right .   i will call you then .  then let 's start with our weekly meeting . the last time 's we learned too much , i believe ,  today , i have two topics . and the first topic , we have a new member in our group , miguel sanchez . i believe everybody knows him very in the meantime because he stayed here quite a little time and he is talking to everybody in the meantime . but , anyway , i would like that miguel sanchez will introduce himself a little bit , concerning his background , what he intend to do . and because i discussing with him many things concerning , his skills and what the nsa group intends to do . i hope there will be a match , then , for his future work . and the second topic is then to discuss a proposal in much more detail . i believe we still haven't left our starting position . and , yesterday i also discussed with wilbert some things and i would like to focus on the question "" what problem we are going to solve with such a proposal . "" not will they have a common activity within the group itself and with other partners outside , but , the technical problem . but that 's under the s second topic , first i would like that miguel will told us a little bit about his skills and his background .   miguel . we m discussed it yesterday that you 'll will have a talk next tuesday but , give me a sign and send me an abstract that announce it , then , for the next meeting .  one short other topic is claudia did a lot of work concerning the web pages in the meantime . and , despite busy with waivers and and visas and whatever , she found the time to write , with what we discussed before and in the form of html and we wanna put it on the web pages in the next days . i will send an email , then , to everybody that they should check their web pages whether they 're aligned with , their own views and opinions of what we should what should be presented on the web pages . and any feedback is then , appreciated . no ?  let 's switch to the project proposal . i mentioned that it is still f  claudia  then everybody sees the structure , how it is structured really structured . then you wi can easy offer some additional input which should be presented , then , on the web pages .   it is .  half collection of necessary information . su you can have you can have it . because , as le no , ",,
Bns001.D,"but this is everybody 's obliged to do it for his own , there is not claudia is not the webmaster here to , get the collection for everything .  this is responsible for everybody 's responsible for his own ,       let 's switch to the proposal . i ask everybody whether read it in the meantime , and understand everything .  everybody say yes ?  yes ,   from my point of view , as i mentioned before , we still in the starting position . the four building blocks on the network level will have really a major impact on f current available wireless networks and , also for future generations . and , what the missing thing is really what problem we are wan wanna s solve with such a project proposal . and wilbert yesterday mentioned , and he is right , that , what service we are really going to offer . the linkage between such application , also interactive multimedia application and , this networking is , not very aligned , because there will be a portion of mobile access to such application . but , that 's not the majority and that is not the major focus of this application anyway . would like to split , in principle , the discussions of what application tsk far away and i would like to more to focus if we have certain vision t concerning these building blocks and the network , what problem we are going to solve . what glue between these four building blocks exists and what synergy effects , in principle , as if they work and fit very together exists for networking and what service could we provide in that area . we will have these really closely working together of these four building blocks . wilbert , you can start to discu oder to tell the group about what you mentioned yesterday concerning certain ideas . it 's a brainstorming of these things and we can comment later on th these these ideas . and i saw you sk still discuss with mark , right ? some was it also related with these things . no ? it was @ @ .    then , then , one w sentence before . i believe everybody fits very in these things . because from the mathematical description with qs in advance , me , as an expert for quality of service and , michael as an expert for mpls and wilbert an expert for multicast , and , i discussed with miguel . it 's little bit the shift to active routing , but it is still in the area of routing . my idea is , in principle , to have , independently of any funding , independently of any outer contact , such a core activity , in principle . and we can see how much from the outer world can fit in . first of all , the first stage is the institution which is behind everybody . ",,
Bns001.D,"that means kpn in your case and siemens in our case . and then , in the broader world here other partners registered in the proposal migh tomorrow , i will go to cisco , and i will discuss all this things . they have certain additional activities and they 're interested in the results before the benefit here is , in principle , that the results are available . they are not restricted any way . if you have your own common activity . that makes a little bit more easier . and , if there is a technical linkage between such , between the outer world and us the better it is . but , anyway , if we come to a certain common work within the core of the nsa group , that 's really beneficial to everybody . and especially , wilbert , if you have in mind to go in the really from the project proposal view , we can build it on this core .  and go to the outer world with , and align it in a certain way . that it also fit , to kpn , and siemens , and in other companies .    will write a few keywords on the whiteboard  yet the basic idea is , in principle , to switch seamlessly between wireless lan technology , whatever and umts , right ? and you see the benefit that , in principle , the customer will save a lot of money . because if in house communication like wavelan or see it also in the american market , some wavelan communication in the outer world will be available , the m and that is your assumption , that the more cost extensive m t s connection could be principle used , i would like to say , over wavelan , and then i have a normal wavelan connection , right ? and the router and the wavelan connection goes into the core internet elsewhere and the connection is not dropped between this seamless hand off i would like to say . right ? or what or what but if this is the final goal , it should be as much as possible available that you do not have to break the connection if you switch between the subnets ' technology right ?  non null but if your s believe everybody is aware about the usaia architecture . and this one is , here , this is , here , also related to this kind what is mentioned there concerning the end system . and in my conf considered end system , there is a certain policy , concerning how to use subnets technologies and all these things . how to use quality of service , in advance , because you have to pay for certain technologies and for certain services . and that should not be done automatically . but it could be done automatically . ",,
Bns001.D,"but nevertheless there must be a certain user interaction always possible , that you could set up a certain mini database how to deal with all these things . that 's not a problem . but what i would like to ask wilbert here , and we discuss it yesterday , "" is it only the usage of that pcmcia card where you have instead of gsm today , umts , and instead of wireless lan today also wireless lan . remember your four and one card concerning what is the name , from dataco ? no . dacom where you can enable four technologies , and you plug in , in your laptop and then you have every four subnet layer technologies available in your laptop . is that the problem ? that 's not the problem . right . why ? but this i but this is th only the probing to figure out that you get at a certain location the information that a s certain coverage of a certain subnet techn technology is available . and if then what miguel mentions , then you add a certain policy , to switch or not to switch , to this technology , right ? but this is end system related . that 's not network related . i see no network related within these in this idea . it 's only to set up i u for me it 's like a laptop t to plug one pcmcia and currently will have two pcmcia cards , and i compare gsm with umts . and today i would like to have gsm , and then i have my gsm connectivity . and i cannot use it other technology , only gsm , because the interfaces , the driver interface , does not permit me to switch between the between different technologies . if i want to go to wireless lan i have to stop my connection and put in my wireless lan pcmcia card , and then go on and set up the same connection one more time . and what you have in mind , to do it a bit more seamlessly , and that makes an only sense for me if both technologies , in principle , were close together in that sense for application . the application would be that i have my laptop here , and i work here with wi with my device , any device , and i work here in wireless lan area . and then i go outside , and want to go still on , leaving the coverage of of the wireless lan . and at a certain state , the device receives certain signals that the coverage of umts or gsm is available . and at that state , you automatically , or based on the certain user profile , switched to the umts or gsm st network . that 's the only senseful application . ",,
Bns001.D,"from my understanding , that means only to have a certain control layer for the different drivers , which you also mentioned as a usaia architecture . and then to do the switching for an existing stream or application between these transparently to this application , between those these both technologies . there 's more potential . i don't s see it , but you have a additional idea . and i don't think that this end system device architecture , which will come automatically . and i believe there 's a lot of activity throughout the world , because this seamlessly communication is always mentioned elsewhere where you cou where you listen to .   now , i would like not to hear only three opinions . but there are also other opinions . and everybody should give a short let us understand , built for everybody and their com whether their comments . come in .   good luck .   and the building blocks ,  multicast , not a topic . routing ? what you the pointer you sent yesterday .  i c i didn't find the time , to do but ,  a ricochet here , right ?    we just discussed a lot about proxies . that 's a fun  few comments . first of all , do you mind mi miguel , to write the name of the project on the whiteboard ? that everybody will send also the pointer which miguel sent to me , to everybody that everybody can take a look to this project . and don't avail information is available because i didn't find the time currently to check it out . but first of   do     i see .    then the second thing is that daimler chrysler research here in palo alto as as in germany , ulm , is doing , in principle , the same with a car . they have a specific antenna for gsm gps and fu for future extended g gsm networks and wireless lan and other thi and other network technology . in the roof of the car . they have a s lot of servers in the trunk of the car . then they collect data how it is with handoff and all these things and they are driving around the different areas . and the same car exists here in palo alto based on wireless lan , gsm and 2 x ricochet networks . they collect the dat collect collecting a lot of data . concerning the seamless handoffs and whether it works very with speed and thomas is going to build mobile ip in their servers .  because they want to use current technology with a c a combination of mobile ip . think there is a lot of activities in the area .  and my third comment is if we are going something in that direction that is quite different from this thing here . but , anyway , as a core technology with a real product in mind . ",,
Bns001.D,"i see some difficulty because nobody currently has here certain umts know how . and you need it definitely because then it j must be your bible i would like to say that you are very familiar with umts if you wanna go in that way . and as far as i know the umts standardization is not finished yet . ninety percent , or eighty percent . i kno i 'm not but that  users of umts ? you can request certain qs . you can even request it in gps but it 's not end to end quality of service . it is only what the gateways get . and within the core network there are certain tunnels set up in the core network itself of the access provider , not the internet backbone core . and you use certain tunnel mechanism to combine , in principle , the base station cluster control . but this is is controlled by a certain node . and you have the gateway to the pdn , or the public data network . and between both there 's a certain tunnel set up . now for gsm , @ @ , or ?   what is what means quality of service . a certain degree . right ?  sometimes we have some it 's packaged data oriented . it 's not really circuit switched . in umts you have always gps as a involvement in the core network . you have , in principle , the path which still is available for the gsm network . also they use , in principle , the same the same mechanism . but you also have a dat packet oriented communication that 's on the gps and that 's also related to umts .  that is no , there 's a lot  there 's a lot of research . but the question is "" is this research wh in which direction we are going ? "" and because for inf right , but bear in mind the picture is a little bit different . the picture i have in mind concerning umts is , first of all , if you use umts only for voice , like you did it or are doing now for gsm , it 's not worth to have this network . and , currently in europe , where it will be deployed first , i believe , it will be very hard , in principle , to get some money back if you have only for using it for voice . because they paid a lot of money .  what is the point ? that you use the umts to connect to the internet and have certain services which are still not available up to now . but the problem is if you have the internet content , and you have your small device of only evolution based for these new technologies , for certain mobile phones , then you have certain problems ,  because you cannot use these things . ",,
Bns001.D,"and wap is not an answer for these things ,   the i believe there is a lot of research work and also if you see the end to end scope of the internet , from the mobile node up to the certain server , "" correspondent node "" , or whatever you call this destination , then you have certain models , for the quality of service and all these things . and then is umts only one link where you have certain subnet layer technology . and you have to match these things anyway . it 's like a normal ethernet . whatever you see , it is only an additional subnet layer technology . and you have all the things mapped to the to the internet in principle , to this technology . and furthermore , you see that the trend is to put more ip technology , really ip technology , and not certain modifications and adaptations , to their access network itself . and th there 's a lot of potential , as i believe , for certain research work . but the question is , first of all , "" do we have the competence to do something like that ? "" first of all . second , we are not hardware builders , in that sense to set up certain end systems . we can design them , from the protocol layering and have some simulations , or whatever . but isn't the final outcome really such a device ? prototype , linux based . and we go around here and we have gps base station sponsored by ericsson , since they are living not far away and wavelan connection , here now a testbed and then figure out that it works ? that 's my point .  but it 's really higher level . right ? it 's no more related to a network . we are leaving the network area . that 's dangerous . cuz if you go to the app if you for me that 's starting with middleware aspects ,  and no , i believe "" network "" is , if you see it really from the ip protocol suite , is then layer one , in principle , up t including layer four , despite the fact that layer four is only residing , normally , in the end system and in the gateways .  we have , some .  do you see this word "" application "" related to a network ? or do you see this word independently ? that was never discussed in detail . "" network services and applications "" . everything in the world . or is the application related to the network ? for my understanding and as far as we discussed , such a long time these applications should e commerce . and it 's really , really   that  no , that is a typical application , which is , in principle , also a little bit related to to the network . ",,
Bns001.D,"but not any application . and we also have the aspects for security . miguel , you mentioned here authentication and triple a , but we do not have any expert anymore . because hannes was an expert for that . the problem for me , it still exists that we have , in principle , here basic building blocks in the proposal from the networking side . we could have a certain application and there 's a lot of activities in the outside world and i believe there 's a lot of contacts . or there could be a lot of contacts with these people . especially at georgia tech . i know on next week on tuesday . tuesday , right ? we will go to ucb . there are three guys . then morgan mentioned one . i do not know exactly what he is doing , but , he 's also interesting in some collaboration . he 's also a professor in the ucb . and many universities claudia mentioned duisburg . and in principle , most of the university have some activities in that area . we will not take care about these one , but we can use them as for field ex field trial access and some support and whatever thing . and we focus really on the networking and going in more detail in this area . and the alternative is what currently we have only this proposal from wilbert to go more in the smaller scope . figure out some potential from this wavelan umts and starting from that . or , are there other suggestions ? it 's still mentioned in the proposal . and th i 'm that it is the wrong place to get the foundation why we are use this application , but and in the end of the text in the end of the pr text of the proposal . but it is mentioned that it is only an example . and that we use this application , in principle , while it is then very easy to get a certain access to these things . when you have a video game server and you want to have mobile access you must at least have one in your consortium , or as a partner whatever , who provides this service . and then we are playing videos , in principle , if you have a field trial . and that is , much more harder than to have a certain access to the university , and to this server , which is run on the campus of the university . and that is the point . you can have this f to figure out all the things and the and the now , how to say , the requirements of this application using this classroom scenario . but nevertheless , it 's not the best for and s networking you are right . but it does anybody see certain potential here to go on , ",,
Bns001.D,"and to start the work in this little bit smaller scope based on these building blocks ? because multicast you still mentio you mentioned that there is no potential . it 's described here that the potential , if you use it for the mapping to the next generation networks in the wireless access area they are still some potential to map multicast because they do not use it . and to figure out whether they 're useful inse instead of using certain tunneling mechanism and to set up these tunnels and have the mapping between a psdn telephone number or whatever number they are using to ip addresses and then there 's the tunnel i ds , and all this things , is very beneficial as for telecommunication providers . as as for isp 's . the potential is still there . you neglected that , but i don't think that you are right in that sense . in next generation ?   now what do you see about the  kpn interests ? because , i believe s if the argument changes as follows that you are here and that you are very familiar with the multicast and kpn is very interesting in umts and this is one potential target network environment we are focusing on , but only for the ip layer technology , then , why do the mapping of multica also potential mapping of multicast , must be of major interest for them . right ?  now , wap is ja not only related now to available bandwidth . that 's not the only thing . it 's only the adaptation towards the capabilities of the end device . right ?  never was a friend    right .  it 's transparent , in principle , what you can carry , but anyway , you have the gateway . it must be the ca t conversion of the media of the contents , in principle . but , i don't see that it 's too late , i believe . if wap was available in the beginning of gsm , then it was there would be a good chance that it is deployed . but now , the first generation of web browsers are in the ha and would say "" handies "" , that 's wrong in the mobile phones , but the next generation of networks are still available . and the ba the bandwidth constraints are no more applicable ? and but the hype but pffft  i never saw a user using wap . raise your hand , who is using wap .   one of six .   now , do you do you see the chance for wap ? i don't see it .  there 's a gate you can put the gateway      would like to ask claudia , you read the proposal in the meantime ?  yes , that 's right . and do you have some comments on it from the next this is version zero dot five right , that 's right .   ",,
Bns001.D,"also we want to go more in the triple a area . right ? because billing alone or ac billing is related to accounting , accounting is related to authentification and authorization .  and then you are still at the triple a service activity and nobody is has the skills to deal with that . and then we are leaving our scope anyway . that 's that is a as it what the synergy effect , right ? from   i in principle , it is related to the current state . but the networking is more explained in much more detail and the work packages are better ident oder what c could be derived for work packages is much better aligned . but that has not changed , the problem is if you one sentence . if you 're focussing on the argument chain as follows . i have an application . this application has certain requirements . these requirements are , multicast and quality of service and mobility access and then mobility management and that is it . i want to focus on it . then you have in mind that or you must have in mind that all other applications and all other networking is not affected by this . that you can use it with every application and if you introduce some new mechanism in the network , that is not related only to interactive multimedia applications like the classroom , it must be fit end to end . and if you assume something , like we discussed it , very hard with multicast , that you assume that multicast will be available at certain portions of the network or if you want to have it end to end , this mechanism must be applied really for all throughout of the internet . otherwise it makes no sense , and we come to the conclusion , "" multicast , we must deal with both approaches "" , that you have application layer multicast as as some other multicast and really multicast and then how to select these mechanism if you want to have not a certain access to the server elsewhere in the network you want to use any application .  and the application , here , that the interactive classroom . but elsewhere any application in any video audio or whatever game server what whatever interactive multimedia especially do downstreaming applications video on demand then , whatever application you can consider . not on everything . that 's not true . but we s that 's why we say here , that we have a certain possibility to change in the access networks . that means the wireless networks because that provides , in principle , the mobility . and these mechan and you see that there 's a trend to provide ip functionality more and more in these networks . but the problem is that you could not focus on this technology only for the access network . ",,
Bns001.D,"you have to have in mind always the end to end scope . and if you see , we have routing algorithm but different protocols and whatever kinds of things , u especially also for multicast , different things really for different providers , and and it 's very easy to change it , in the access network , for novel things . that 's one provider domain and you can say why not use active routing in that provider domain ? it means that packet are delivering information , and you do not have the separation of routing and forwarding process . it 's impossible to deal with that in the whole internet , because security reasons and whatever kinds of things make it impossible . how to combine these pos potential extensions in the access networks , and without losing the end to end scope in the internet . then you can have certain n novel features give the providers like kpn or whatever , the po the potential , in principle , to see the building blocks for the future networks because there 's a three g third generation like umts , a fourth generation more ip related . there will be a fifth generation , i 'm and then you derive the certain building blocks for this network , if you ever really full i full i p , end to end . but nevertheless you can only not only focus on "" i provide this mechanism "" because u you are accessing a certain server node in the internet , using any application . and then this mechanism must fit it there . but nevertheless internet backbone is in the meantime , based on its success , impossible to change . you see the difficulties with ip version six , you see the difficulties with multicast . they are discussed since , ten years or whatever . the specification are rather stable and available but we have only islands in that . we cannot assume that everything is end to end available . and you have to mi to have in mind that certain kinds of mechanisms are at a certain stage end to end available , we have a lucky that the islands are connected to each other or the same applies for mpls , they are only portions available , how to deal with that when the islands are not available and nothing is available . but you have to select it because i have a mobile phone , a mobile node or whatever device , and i want to contact a certain content in the internet . is it possible to d have certain normal features in the access network without losing the end to end scope of with these difficulties we are dealing with . i always say that the success of internet make it unflexible . it 's impossible to change something very easy . s s it 's easy more on the access network as in the internet backbone . ",,
Bns001.D,"that is overall picture that we have in mind with these things . and we can not u we are six people or seven or whatever if hannes come , we are not able to solve the problems in in the few years or whatever what the whole internet community has done in si since since a decade . but we can f pick up some f some potential and to start with something . and that 's my missing point . that we have here , in principle , really the description of this problem i mentioned and focus really on the reasonable size of the project in the first stage fo for the nsa core itself , and possible extension from , if kpn say "" yes , that 's great , "" "" that 's the right direction . we will support that . "" and if siemens say "" great , we will support it "" , and what it university of berlin and university of mannheim or duisburg or in spain oder whatever . if we have all the similar project then you have only to take care about that 's a little bit aligned , that there 's some transparency concerning the results and the activities are literally going in the same pace . that 's the basic idea . but really it 's to figure out certain smaller activities where we can start it . that 's the point . and if we get some funding back , and we have certain potent potential partners in the boat , we can go to a broader scope of this whole thing , but the problem is that f funding is the second step .  but we have no current no public funding , everybody 's paid here .    that 's right . that 's right .    now , that 's the point why i am focussing on more on the  i want to have really the activities what is really the outcome what is really the problem we are going to solve . these are my questions . and if we have identified this block then it is possible to raise some money .  it 's clear . now from my point of view in the beginning , one more time , if i see the four building blocks , and could speak only for my skills , i believe to derive a certain qs reservation in advance scheme much more general as it is done for usaia , but mapped then really to desired network subnet layer technologies . yes . for no , for y umts . but first of all , a generic system , but because you can have several mechanism really using certain quantitative description , you can have more of a qualitative description , you can have taken into account moving patterns , and whatever things , but there are a lot of ways to have certain qs reservation in advance , ",,
Bns001.D,"and i see it as definitely is necessary to have this one if i want be mobile and i want to have not a interruption of my in my application qualities of service .   but then , to go , to umts , and figure out what is available within umts . and if i really have an ip application , where i need this quality of service and having in mind that certain qs will be available in the rest of the internet . how can i map these things to the umts and what is the trend towards umts to the first generation ? and how it is possible to map this one to this technology ? and if you have the building blocks identified , what is really necessary for qs qs in advance for mobile systems , then you have , in principle , the ideas for the following generation what you could improve . because then you are no more related to this thing . i believe the same applies for multicast . and i believe the same applies for routing . in principle , in the beginning , there would be a certain paperwork anyway , some theoretical examination of these problems , and then some prototypes must be derived from that . and then we will start here with a certain testbed equipment we still have here . we have four cs available . we have to extend it then , and figure out some real scenarios , and then pfff ! because despite the fa hopefully , then we have with the money also not only for the room , that would be great , but there are also some sponsors then we add a certain field trial . but that 's pfff ! that 's years , that 's years . but in the beginning we must have a certain theoretical framework with the relevant technology . real technology . you can start with gps or umts , or whatever . because these technology will definitely available in europe . there 's some money spent on it , that it will be in a certain flavor . it will be available . and it will be also available in the usa . because there is a big harmonization effort , despite the fact they are not aligned to each other anyway , but they will have s also certain thr third generation and fourth generation networks .  and after this theoretical framework , if this one is aligned , you have some specification and you set up some linux or free bsd or whatever prototype . that is what i have in mind with that . and then and then you will see . the problem is which i see is that it could be fruitful to standardization that it could be fruitful to some extent to telecommunication providers . but there 's not a real product like you say . there 's not the selling idea behind it .  ",,
Bns001.D,"if you go with something what wilbert mentioned "" let 's have this one here "" . we have a new pcmcia card and extend something and the end system , or what you mentioned here was the seamless four technologies inter working in the end s , then you have an a device which you can sell . if you go for a networking pfff improvements , in principle , and understanding next generation building blocks , there 's no product . but it is a long term it 's long term , work you can do . and it 's more related i believe to the skills to what is available and currently as i see what will be available within the nsa group . and if we focus on this networking small more networking and some application guys came into the boat and they focus on their application whatever this means , it might be we have then the active classroom , but it could be another one that is not representative , it 's only   then is something available but i don't know i 'm not an application expert , i we have some content . we will then discuss it on next tuesday as i mentioned . anyway , but that were is my answer to the question if some money is available . the good thing is that the money is available , because everybody is paid here . that is money that the smallest portion of money which is available . but first of all wilbert need more , definitely , because then kpn is no more interesting to go on with this work , or we can convince with these things which we have in mind , companies like kpn .  and if we have other suggestions and have this as a long term nsa core group activity , and this theoretical framework , whether it is finished in half a year or one year doesn't matter , in principle , because the road map for the next generation networks is is for many years . and b before umts will be deployed very i believe it will be common t two thousand four like that .  and have an intermediate project , which is related in this direction , something like the seamless handover for two technologies or whatever . this is a smaller portion in the gen more generic framework , i would like to say , from this proposal . why not go in this way ? i don't know . but that 's the point we are sitting here together . but for dietmar he mentioned it to me , it 's very clear that he will go on with a portion of time , with this usaia in the matical sense because that means for you in a certain kind a certain extent , you are decoupled from networking because your focusing on the mathematical thing of whether it 's a network or other thing , it doesn't matter      ",,
Bns001.D,"there is it still ongoing activity with portion of time at the university of berlin . and independently whether i will leave the icsi in the mid of december or not , i will still focus on these qs in advance schemes also within siemens and also with some project there . and i believe your routing is also available ,  and when you will go back to spain , right ? and that 's why , in principle , the skills will be always available if there is a certain type of project in the home countries and then the institutions and   currently no money is available , now , i will not prevent anybody from getting some cake and we are sitting here together it 's very slow , in principle , but my last question is for wilbert . wilbert , you you got the basic idea because it was mostly discussed with you here from this current available scrap project proposal . don't you think that kpn could be convinced to go on this way what i mentioned before ? there 's no way ? they needed definitely , in principle , some service or device or product or whatever . can we both have together , it 's a little bit more easier , a discussion on thursday ?   that 's enough time for you to consider a little bit more in this direction ? and then we could have discussion and this one is an overall work , in principle , where everybody could hook in and get certain small portions to solve it and   can you consider poten also in the meantime , some potential umts services besides this one ? and no , but , fff based on this one and you see the networking that it is a little bit more evol evolved and than in the core network technology in the access network , i would like to say . and this is aligned then as much as possible to the internet . that 's the basic idea , that you can have a certain service which make use of these novel things . because normally i believe the people are either on the application layer , that means higher than layer four , or they are on layer f one to l up to layer four . and the service people are considering "" umts you have some location information , and you are have the infrastructure in the car , if i provide a certain service , independently what the network is offering , because they do not consider it very they know there is a certain location information and you have a gps , and they know , it 's based on satellite . and there 's umts , that is based on base station . there 's all that they consider . and then assume , do that . ",,
Bns001.D,"and the networking guy said it would be great to have multicast and all these things in the network , but do not consider really what a sense of benefit for applications , there were new app old application make use of it and how can new application arise which we haven't considered up to now based on this new network function , lat enrich enriched network function , lat . it 's worth to consider something in that way what is our not currently there is a techno technology split . you have ip in the mobile device but if you see the strange protocols text there 's ip over ip and tunnels and whatever , but it 's looks very strange to me because you have different numbering screens , concerning you have a phone number , you have to map it to ip addresses and on , but for me , you have not the end to end parts of for ip functionality . we are far away from that . and if you take a really look to the gprs protocols texts and i believe also they apply for umts but i 'm not very familiar with that , and the next generations access network is will come soon . you see it 's every three years or four years they will have a new generation . but anyway you   why ? what kind ip over what do you call it ? no net . that would be great ! can you repeat it ?  something like that is my final vision .   atm   there 's the problem is , you see that the providers have always there broken view for the management . if you have different protocols texts and network management system , and the billing system and all these kinds of things which is besides the networking in principle , but you still need it , is not aligned . we have it for different islands and that 's my final vision if you have really then ip networks at a certain generation where you have really the physical media and where necessary additional maclear protocols , and then you have really always end to end . it makes you things much more simple much more easier , but is far away ,    but you have the extension for the quality of service mechanism which you have to map then to the underlying technology . and but in the lan interface it makes since to use it and but  but we sh we will miss the cake and we should stop now but everybody , short  go on with considerations and potential and we didn't make s much progress today in the meeting , but anyway this activity lives from all , from the input of all . and really if somebody has an idea send an email and then i would like to enforce everybody not that i 'm doing everything i could not i f didn't have the time in the past ",,
Bns001.D,"and i will not have it in the future and will stay here only s four weeks or five weeks . it would be really not the best thing if the activity is dead when i am leaving and if i stay longer we can go on but nevertheless i rely heavily also from the contributions of everybody , and it 's in their own interest of everybody , also from the institution behind . if there is certain idea or questions or whatever , we are s only a small group of people we can easily join on a white board and start a discussion . it must not be on every tuesday , at a certain time . and i try to motivate the people . that it 's free . that 's a starting . that 's a ramp . and we can go in different directions . and if you have a real focus on the certain novel thing for the services or umts or whatever , great . if not , the long term and then these things must be , nevertheless must be defined in much more detail .    do not , what adam mentioned to switch off , will find him @ @ . cake area . and now let me see whether he will be here , and we did not forget . we are done .  hopefully everything went fine . ",,
Bns001.E,"but there 's no personal homepage for everybody ? or , is it planned or not , or ? i 'm not interested in this . that makes work .     his name and on .    yes . it 's a project of the uc .  you think more about hardware technology . there is a lot of hardware to develop , but not we have already much work put into this proposal , why to switch now ? don't see the reason for that . the application we suggested is not the best one . we have to think about an application which is for mobile users , more relevant . i don't know . video games . if you are traveling it 's boring to travel and then you decide to play a g video game with somebody else who 's traveling .  that 's right . i don't have a mobile phone . that 's right . it depends on my i 'm foc i 'm focused on performance evaluation and especially of communication networks and i never dealed with mobile communications . why not ? that 's to open my mind . not to switch off . ",,
Bns001.F," we should be on . and i 'm gonna go ahead and start by reading the digit strings , just to give you an example of how to do it . and the first thing to do is read the transcript number which is on the right hand side there . and if you could just go around the table and read them out .  if you could sign that ?   i wanted to just era it reiterate cuz we did have one person come in a little later that , there will be an opportunity to remove anything from the transcript that you don't want made public after it 's transcribed , that 'll be some months off , but you will have that opportunity    very much . i don't have to   it 's just at the end of the meeting , don't turn off the mikes just leave them on . and  actually could y actually , could you call me , at the end of the meeting ? i 'll leave my number on the board there  numbers are strange ! it is ! the meetings are strange . people interrupt each other much more than they did . two nine seven .  just leave them on for now . sometimes if you turn it off while it 's recording it crashes ",,
Bns001.G," should i next ? hey , adam , what ? it must be funny to do an a research on how people behave while reading these numbers . that must be  it must be much more interesting to see their behavior .      can i ? add something . if there 's anything else which we what we could add on the web site . p if you have a small abstract or some pictures or whatever , about the work you did before , what you are planning to do here , that would be fine , cuz now we can add some more there . or if you have something or if somebody has some slides , o or articles , whatever he wants to be published there .  and it depends what everybody wants to do .  about the projects will be something , then , about publications will be another point , and additional information about how is life in berkeley and i i don't know , some hints , some web sites or links which are useful when somebody arrives or like that . no , i 'm not doing it for everybody but what but what is planned is that i do something like a previous , layout , and give everybody the , opin the possibility to the chance to put his content inside that the layout is for everybody the same , about the projects and there will be something .    but the task changed really a lot , i 'd i rather would like to but i 'd rather like to follow the discussion before i gave any comments , cuz it 's really the first point is it 's much more than it was before i left , it 's like five weeks in between , it 's like that whew ! that big now . and it really changed a lot cuz the found the classroom inside but , the thing where i left the discussion was that we are talking about classroom where everybody could look on with any device and follow lectures or do exercise or whatever .  now we are talking about something which is much more precise and the range of is more narrow than before 'd rather like to follow it a bit , and then to get more into the ideas . what do by "" put together "" ?   why i wasn't , hold myself back a bit with comments , is cuz when i left the discussion , the discussion was what to have something like a big umbrella about everybody who was at this point , here . and the discussion was much broader than it is right now . and there i had the impression the umbrella was this classroom thing . right ? or wrong ? it is .    that 's clear . but that 's clear , but then i don't get ",,
Bns001.G,"because when we were discussion discussing this weeks ago , had the impression that , everything of these work packages fit together under this one big umbrella . and now it sounds different . that 's what i don't understand . but , it 's also because i missed the last four weeks .  it 's a bit hard for me to follow the development what happened in the last four weeks , why it changed if i understandi it right , what has changed is before we were focussing on cuz what 's difficult for me is what is meant by "" application "" ? cuz i have sometimes the impression that everybody is defining "" application "" in different way . what exactly is mean by "" application "" ?   what has changed what has changed is that we 're not only focussing on this intelligent classroom , but on everything .   but there 's something needed to sell it . and bless you . do not don't switch it off . ",,
Bns002.A,worse than no work . no . one it is actually no problem . just log out . no . log out .  that 's the proper answer .  paez . paez . ,,
Bns002.B," is that really an ad hoc network ? because the sensors are not moving . and it 's makes no sense with moving sensors because then you don't know where the sensors are .   that 's it .         i see .  a further question .  am i right that this dialogue does not prevent any disturbance of other nodes in the sending range of , n one . s    that 's it .   but then this node , this transmission is aborted . and there 's no advantage to if it 's aborted , by any data packets . this node has to stop each transmission . even the at the moment ongoing transmission . is that right ? his transmission is aborted .    that 's right .             but this scenario is also nov only working if both or all nodes have the same range of transmission . the s same radius of the sending range . otherwise this one node would hear his neighbor but not vice versa .   but i 'm thinking about this example you gave before .  but one of the but one of the senders could be much stronger than the other one .   that was my question .      but   it 's a assumption it 's clear . but on the other hand , in a real world it isn't , or ?  in real scenarios , you have to  that 's it . a car or     that you 're not assuming this .     a cellular phone and a car .        there are  there 's more than one ip address in the header , and i see . do they have to do they have to be in order ? you are looking first for node two and then for node three and on .      you mentioned six partners of this work . already what partners are included . didn't have a look at slides ,  just i 'm just curious .    and all of them had or ?  ",,
Bns002.C," we can start ?  welcome to our next meeting . today we will have a talk from miguel sanchez concerning his work related to ad hoc networks . we have here a guest , a former icsi member of the nsa group , jordi domingo pasqual . he is , assistant professor at upc . and jordi , you have a few words concerning your work one or two sentence and because we will have tomorrow a talk from him in more detail concerning what 's going on . only a short introduction , ve very short introduction , one interruption . this is not related to hearing , it 's only for fixing it . it 's not a earphone . no .   like this one .  it 's only a microphone .       and after the talk of miguel , i will give you all a few slides concerning the project proposal . i will say something about in which direction it will go and  it was my fault that i assumed that the pointer of miguel concerning umts services was deployed to everybody , but it was only sent to me , in the meantime everybody got , i believe , this pointer from me , and we it 's a homework , in principle , for the next meeting , to get a little bit familiar with these things . and believe we will not have today a very hard technical discussion , more a few topic and items we will focus in the next days , until the next meeting . and when we are ready with our meeting . everything is done . then , we have to read these number and we go around here , every member .  miguel ,  but you can also , i believe , to have an ad hoc network , where one node is then connecting to the outer world . what i have in mind , you have a car , where you plug in different devices and they talk to each other , but one device decided to go to the g s m network or gps network , or whatever things . there 's a certain task for one node within the ad hoc network to provide connectivity to the outer world , right ?   right .   let me go back to your example . have in mind some routers are burnt here , at icsi or whatever thing , what will happen then even in a fixed network ? if some sensors are getting out of service and whatever thing , the topology has changed , even if no node is moving .  and how to provide the connectivity and the intercommunication things wi within this network .  yes , this one .   miguel , can you give some examples for such protocols ? one is really    and the media is still occupied during that period , or ?   i didn't get it . what happened when i sent an rts packet ? ",,
Bns002.C,"is then the media still occupied for me ? or , is anybody allowed also to send rts packets ? because if i go to an intermediate node , you are communicating to me and i am the intermediate node to the final destination michael . and michael send also some rts packet in the time and jordi too and whatever . then you will never come to a really then you 're always exchanging rts and non acknowledgement packets for the rts . that 's my problem . then , fine .  it 's only related to the direct neighbor within the scope of the transmissions ?   i assume   fine .  but that means , in principle , that on the mac layer you have always a rts cts packet between neighboring nodes , and you send afterwards the data . but the data will be delayed in the intermediate node because you have always be assured to be rts and cts packets are changed before you can forewarning the data , right ?   now the p it 's better to draw it on the  my idea first . this is what , node one ? this is node two and this is the source , and this is node three that is the final destination .    but anyway , i would like to do that in the ad hoc network . this is the sco this is within the scope of this , special network . that means here that is within the transmission power . if i send an rts , and get back , a cts , then he is allowed to send data , right ? in the meantime , when he gets this one , he also had to send rts and then cts because this is the next scope of the transmission area , and then he can send the data , right ? that 's the case ?  and that 's what in the meantime , he c still can get some data here , where he try to get certain connectivity on the mac layer .   and then he try to forward this data . after that . he is definitely first to stop . he has to collect all the data ? could it not be a little bit strange because if that is starting a file transfer with millions of bytes , he have to collect all the bytes before he forwarding to whatever .  one data p he have to do it for all data packets ?   but , in principle , when he receives the data packet then he the same applies for the next data packet . but anyway in the meantime he has to forward the packet to the final destination . right ? it 's acting , in prin   naja to     and delayed .  but this is typical for mac layer protocols , that 's     it 's always true that only one node gets a media access , for one frame . ",,
Bns002.C,"that 's the point . we always said "" from data "" but it 's really one frame .    you are right .  but , miguel , this is a good point from dietmar , but here is a wall . and this guy is behind the wall , his transmission rate is something like that .   but miguel , if in the previous slide you mentioned that you are working also on adaptive power control . is it not possible then , if i send something and i could not find any neighbor because one of the cluster below , is it not possible to extend the power until the maximum and if do not have any connectivity with the maximum of power , then i 'm lost anyway .      and how do you miguel how do you check if the nodes are moving randomly ?  that 's applied for rts cts , but for the real frame ? the frame could also be whatever , i don't know but a few hundred bytes , that takes a little bit time .  no , s no m that 's right . but first of all it took place rts cts , and there could be , you mentioned , if it 's still occu if the medium is still occupied by another one , it will be delayed anyway to a randomly time .    y  i see .   something like that . it 's what some , cases why i go this way with my node , and suddenly , i s go out of the scope of the transmission area , because it 's really a random movement . then i still hear this is during the data transmission .  then   right . nee . that 's really right , but what i would like to say is that besides the rts cts behavior , you need certain additional mac layer functionality to deal with these packet . with transmission or whatever , for whatever control , or whatever things , right .    this is a question not directly related to these things , but that 's why only a short answer . do you assume that power control will be issue also in the next years ? in other words , is the success of having more power within the devices in three year , four years , five years , for batteries , and and @ @ and sofort on will it be succeeded that you have much power available that this difficult mechanism who is in the wireless network will be out of scope ? because if i have a device which can i use for twenty four hours , i do not have , in principle , really the constraint to deal with power savings .   that 's what i that was the reason i 'm talking about this is but anyway , that was the reason for my question . ",,
Bns002.C,"if i save with a lot of difficult mechanism , within the air interface and between the base station or access point and the mobile node , one percent of the power whereas ninety nine percent is consumed by packet processing and p u or whatever , is it worth to have it ? if i really , with a normal device with a battery lifetime of twenty four hours , thirty six hours or whatever thing and it will be increased . as the more mobile nodes are in the world the better the battery will be . that 's was the reason for my question .    i g got it .        what do by multicast protocols ? routing ?    and we will have to explain a little bit for those who are not familiar with source routing . you can have the destinations you would like to or the in the i p addresses of the intermediate nodes you still know even if it 's not the direct neighbor , but one of where you really want that the packet went through , put it in the i p header . and , this one is going then to this guy and on , until finally it 's reached destination . and , that 's what you cannot put it thousand intermediate nodes in but to put a thousand i p addresses in the header , that the packet is for forwarded accordingly to    it 's you 'll know to remove h it 's h from the header , in principle , and on , until it reaches the final destination . this one , that may that the different parts could be one to number four . two b or three b but nevertheless this guy is a is an gateway in the router for this packet , and they remove itself from the header .  it must be not the whole path , miguel , are you familiar with these proposals ? that depends on the service level you want to be . definitely not a guarantee level . but something like a control load level like that , seems to be for me possible . right ?   we can discuss later , off line .  but the but it 's really happened also in the riot case , if i get the wrong route with the rcmp redirects , it 's , in principle , then the same .  in principle , the base station .    and miguel , should i should ask you one question . and in version one and two you have different technologies . frequency hopping , two modes and also infrared . does it still apply for the eleven b ? dss .    megahertz ,   gigahertz .  in the rsm band .  and one additional question from myself , but also short , because time it running fast . i have heard that wireless lan and bluetooth will have some problems that they influence each other . ",,
Bns002.C,"do you have additional information about this topic ? that 's right .   but nevertheless , you have the range of ten meters , or of one hundred meters .   that 's a good news , but anyway , based on your initial scenario i believe because bluetooth is on one chip , like you have now your ucb buss or whatever connectivity , you will have your bluetooth connectivity . and that means your mouse , and and and whatever things connected to your laptop and also your microphone and whatever you will have , is bluetooth based . or will be bluetooth based . and this is within an wireless lan . despite the fact that they are considered for different scenarios they are still within one area .  we 'll when i will have some problems in the future with my l wireless lan and bluetooth connectivity , i will come to you , you will solve it go on .  but for cars . if your car is the infrastructure ,     many miguel . are there any questions ? we have also the time to discuss with miguel off line the things if there is some question concerning his talk or other questions . one last question from my side because i bring it up , concerning the proposal , some active routing mechanism . it 's going in a quite different direction as the traditional things discussed in the itf and i currently do not have any idea whether active routing is really a topic within the i t do you have certain experience or do certain activities in that area ?  i know ,   one more time , many miguel .  will deploy a little bit information here from the project proposal . have only four . jordi is only a short period of time here , he will get the colored one . and take a look to   kill the computer . started for advertising the project proposal here to provide a few slides first of all , wilbert , is not here , second the link here was enabling umts services and application , i assume was not read yesterday night . suggest we go roughly to the slides here and the problem is that , in principle , we have different scopes . and motivation of the project proposal from my point of view is that we will have the wireless access networks for the next generation will be more flexible . there 's a @ @ for current for fast changes within this network . and that means , if you go to slide number three , that we have the possibility to having normal features in the mobile access network , and and and also based on that it belongs normally to one single provider domain , that it is possible to use novel things and new protocols and new technologies within this network . on the other hand , in the internet backbone , we it is i impossible ",,
Bns002.C,"and we see it on several examples like this , mpls , there 's quality of service support , and multicast and all this thing , that , based on the success of the internet backbone , it 's become very unflexible , to p fo for the provision of these things . if we are going to offer building blocks , and provide novel solutions for the next generation of wireless access networks , taking into account , without modifying the end to end scope , then it 's really beneficial work , also for the use of interactive multimedia application , as it is described in the project proposal . that to start with bigger cluster of co of potential partners to do this really big work , seems not to be feasible in the next time . because if you have settled everything , and discussed everything and without any money in the background , and a lot of money in the background , that is not feasible from my point of view . nevertheless , i discussed , with a lot of partners , these things . and today , michael and me , we were on the ucb to discuss with a guy who is a professor who is probably interested in the application they are going in that direction . they have a small project funded by nsa nsf , f for this "" intelligent classroom "" , is a little bit exaggerated , i believe , but going in that direction . there are a lot of interest , but without really hard money in the background , it is very hard to come to the initial steps . and juan peire , one of the members of this nsa group has identified a certain start money , i would like to say . if you start with a small cluster of the constraints of this funding , and that means six universities and institutions three in usa and three in europe . and they are including the nsa group and that seems to be very reasonably , for me . but then we have to align the project proposal in that sense . because then we cannot do anything as it is described in the bigger scope . to reduce the overall picture , which i described in a few words , to the fact that we have really some work packages where we can focus on it , still fitting into the big picture .  and that will be the task of the next weeks . and i hope that everybody is doing his homework concerning @ @ alternative to the intelligent classroom that we h can start here only with the n s a group within this big picture with some work that we put the pieces together . because i believe many are very flexible here accounting also the future coming joining people of the nsa group , to do some work here . ",,
Bns002.C,"and if we are starting with a very small cluster with a common activity have some starting funding for bigger radius of the the project proposal , with the mind that at the final stage it will becoming a european proposal with this the whole funding . that 's my point , and my picture i have in mind . and i will go definitely back to germany the tenth of december . that is fixed now . and i hope we can use these remaining weeks to have really progress in for the proposal in that sense what i mentioned before . because then i will make the advertising that is still worth to stay here , and i hope then siemens will say for me to stay longer here . and then i will come back in the mid of end of january . that 's it 's a comment to the proposal . think everybody should consider carefully , based on this statement i made next steps and everybody has little bit other work to do but it should be always an ongoing process until i will leave until the tenth of december .    i will distribute all the things electronically to all the take a look to slide of number two ,  you see university of mannheim , university also these are the official ones , you see that in the icsi us on the u s a side , i believe that the home companies and universities are still contributing .  but these are then the official ones , and i would like to have them they say they are very interested in it .  few words , the university of mannheim is at location where joerg widmer is working on it , and i got the statement they are very interested in that . they did a lot in the area of intelligent classroom but nevertheless they did a lot in networking and university of uppsala , sweden , that 's the reason i invited christian tschudin , the professor who did ten years work in active routing . and the universidad nacional de educat  spanish . we have a better expert to pronounce it . "" uned "" . i always said "" uned "" . in spain , this is this university of juan peire . and he is also the one who had recognized one pair pair not parez , peire . peire . no , no . not paez . not . peire , p e i r e . p e i r e . you never heard from him ? you can i you can mail him later on the informa then , the whole n s a group and also of the coordinator of all the things , then georgia tech , i have good relationship to the long lasting cooperation with georgia tech and they did a lot in this area , also related to networking as as to the intelligent classroom and the ucb . ",,
Bns002.C,"we still focusing on we can have more professors involved which are working also on the networking as as on the application that the ucb is clustered as one partner but nevertheless with different departments .   but take a look to the slides , i will deploy it electronically .  i will send it electronically . after the meeting . i will . future . and , you take a look to the last two slides ,  the gprs picture is still available . you have , in principle , here now the mapping of the different areas , within gps , and , in principle , the same applies for umts . there is no much different . you always have the sgsn and umts , they are called three gsgsn . and you have the protocol stack in on the slide number five , to see what is going on . and you see the difference . the amazing thing is that you have ip over ip . as you take a look to the ggsn , you have two ip layer functionality and all those things . and you have the gps tunnel p protocol g t p between the g and the s and the gtsn . and on . believe they are very difficult protocols stuck between the between the involved nodes , and making it necessary , in principle , to deal with our four building blocks in believe , in a difficult way , if , we have in mind quality of service routing , and qualit mobility aspects and all this kinds of things for i p layer functionality . that 's , in principle , an overview , of the protocol stack and the involved nodes , and i will provide more and more information but have to also figure out everything from the scratch . i am not a total expert for the future wireless networks .  then i would like to everybody and if there 's no additional question , comment , or other remarks , i would like to start with reading these numbers . the next one .  now , let don't switch off power , i have to call adam ,  suggest , @ @ now we will have in a few minutes we will have the coffee break , tea , cake , whatever , @ @ will be offered , and then we will have a we can have a discussion . ",,
Bns002.D,"    i have prepared , a really short talk about some of the topics i have been doing some w some research work before coming here . and mainly i will present here you have more or less the sketch of the presentation . i will present some ideas and some concepts about what ad hoc networks are , about the issues in media access control in wireless networks , also about routing in such networks and , i will make some comments also about the current standards of wireless local area networks and finally , i will present the blueprint of my research project or my research proposal here . the first thing is what an ad hoc network is . an ad hoc network is made of wireless nodes . these nodes can be mobile nodes , and , in this network there is no network infrastructure . the only active thing we have is the mobile nodes . and end to end communication , is sometimes , done by direct communication from one node to the other , because they can talk to each other . but sometimes it is not possible , this direct communication , because nodes , end source or and destination nodes are are too far away . and in this case , it can be done , communication can be done , by using multi hub routing .  an intermediate , or a set of intermediate nodes will route or will forward the packet from the sender to the destination .  in a sense , what we have in this networks , is that , nodes are as both arced as both endpoints and also routers of other neighboring nodes . and this makes a difference from other network . and regarding the purposes of what can this network be used for , we can say that , cellular networks are infrastructure based networks , in this ad hoc networks , we don't have anything with the exception of the network nodes . this network can be useful for occasions where no available infrastructure is present , like in after some catastrophe catastrophic event , or , also when even when there is a network available , we don't want , for different reasons , to use the available network . this latt later case can be , the use in military systems , where we don't want to use the other the enemy network infrastructure , for evident reasons .  that 's that 's o k . that 's perfect , this in this case , we will say that this node is acting as a gat external gateway , from this network to connect to other networks , and the underlying protocols can be , ip based .  here you have several proposed , scenarios for used this networks . when no network is available ,  and another application , nasa is studying , is the use of these networks , these ad hoc networks , for sending multiple probes , missions . ",,
Bns002.D,"all of you are aware of this the last atlas , the last successful mars mission , the cellular vehicle was only one , and was walking around , roaming around the base station , which in this case was the gateway node of this network , but it was only one mobile node , nothing prevents , except the cost , to send not only one mobile rover , but ten tons of them , or at least several of them .  higher area could be covered , could be explored and all the different nodes could also use some ad hoc networking , , ad hoc routing , to extend the distance , the maximum distance , than single radio transmission will would allow .  and in the other case , or the other area of application , is the called network of sensors , where we can deploy a set of sensors in a uninhabited area , let 's say , the forest , and we can take some information for fire fighting , we can just launch from a plane , several small sensors , and these sensors can be checking that there is no fire , they can have some let 's say infrared technology sensor , we can cover a huge area with only a small set of sensors , and without any other infrastructure .    it 's an interesting question . the main thing about an ad hoc network is not that nodes move . it is the way of topology changes can happen . the idea that any change is possible at any given moment . but you can ask , "" but if the nodes are not moving , what topology changes can we expect ? "" that usually in a n in a network of sensors , what we have , or the idea is to have an important number of sensors , and with a high filer rate . the batteries are exhausted in some nodes because they are not being able to take let 's say , any sun to recharge its cells , some of them can be just out of order for other environmenta environmental conditions . the idea is that even when these nodes are not moving , they can start and stop working at let 's say , higher pace . then , what will happen in a regular network , in a network where you don't have or either mobility or this on off rate , high rate .  joe .  and finally , another non military applications , where network is available , like a room like this , where we have , in fa a wired infrastructure , but this possible application of ad hoc networks could be any place , any meeting room , where we arrive with our computers and we just can communicate seamlessly to each other without any access point , any external network , because the work we want to do is just only local based , ",,
Bns002.D,"it 's only to chat to each other or to exchange files with the person , which is in front of us .  but we n don't want to product pro provide , access to the internet  and , the same the same scenario , could also happen in a place where there is no infrastructure available . let 's say a meeting room in the middle of the desert ,  without any other network .  the point or the question could be for some of us , the idea of saying "" that sounds but why not to use a longer transmission range , we can reach any destination in just one hop ? "" this seems to make sense because , we are this way avoiding all the routing problem that , we will talk a little bit about routing later , but it seems that i probably that the problem is not an easy one , because node 's moving , the route is changing , one can think that routing in this scenario is a complex thing . but the problem is if w we just try to put more power in each tr transmitter , this transmitter can reach any destination in only one hop , what we are doing is to rising the power needs of each node , and also we are reducing the network throughput , because we are only allowing one transmissio one transmission at a time . because we cannot allow several transmissions , several high powered transmissions at the same time because one is interfering with the other .  we are 'm not telling it yet , but we are assuming that we are using a single common channel for all the nodes .  that 's why we cannot allow several transmitters in the same channel at the same time .  the idea of hav having a longer transmission range is not a good one . or at least it has the drawbacks i was telling you . let 's speak a little bit about the media access issues in wireless networks , the easiest way to show how this works is or at least one of one of the easiest is that this drawing , or this picture , what we have is a set of nodes , each one at a different location . at a at an at a given moment this node , this dash node is transmitting and the arrows are representing this transmission and the receiving nodes , these three nodes , are receiving the transmission , and i 'm trying to show the area , the covered area , for of this transmission by means of this dashed line circle .  any transmission has a maximum transmission range , and in the simpler way , we can see this like a circle with the center in the transmitter and a certain radius .  the value of this radius is in principle , is a fixed value ",,
Bns002.D,"and it depends on the power of the transmitter . this is only our simplife simplified model and this can be improved lot ,  and the real behavior is not exactly this one , but for what i want to say it 's it 's enough .   what are the differences in this wireless transmission , regarding to the wireless to the wired ones . what are the d the main differences . the main differences come from the fact that , in wireless transmission we have a special domain we don't have when we are using a wire for transmitting a signal . and the point i 'm trying to show in this picture , is that if this other node wants also to transmit while this one was transmitting , if we are using some carry detect scheme , like csma , derivated from it , the problem is that this node will hear the g the m the transmission media , it won't be able to hear anything he will conclude that no other transmission is going on , and he will start transmitting . and if he does , what will happen is that this node and this other node will also receive this transmission , and this will produce , at least at these two nodes , a collision or a m a re a bad reception .  none of these two simultaneous transmissions will be properly received at this node nor at this other node .  this problem is what is called  the this is the previous one ? this is the german    this is what is called a "" hidden terminal "" problem .  because this node is not able to hear this other node because of the distance between them . but this problem , as you can see in the picture , is really producing at least some reception problem at these two nodes .  it is a problem that we have to address and it is a new problem compared to wired media access control . and , some devel some protocols have been developed to avoid this problem and to try to address this particular behavior of wireless transmissions and the main idea is to use some reservation mechanism .  we are reserving a certain , and a specific area of space we can guarantee that nobody is trying to use the same space at the same time .  this is the basic idea .    this one . this one , n next slide is  in the main idea and the base of most of this protocols , is what this the called rts cts dialogue . the idea is that ,  this is only intended for unicast transmissions , only for when a node wants to transmit something to a neighbor node .  but not to broadcast . to all the nodes .  ",,
Bns002.D,"for this work , the transmitter has to send a reservation packet called rts , "" request to send "" , before being able to send data . and the receiver is expected to return back another packet called cts , "" clear to send "" , to allow the transmitter to send the data . if the transmitter receives successfully the cts packet from the destination , then it will be able to send the packet , the data packet . if not , it will h back off , and it will retry sometime later .  the main idea  yes . yes . the idea is if i want to send you something , i first of all , i need you to answer me to be that you are my neighbor now because you are off or you are too far away , and also because that way miguel , it may be is not being able to hearing me will hear your cts and will know that you are about to receive data from me .   forcing the receiver to transmit for a short period of time is also used to signal all the receiver neighbors that a recept a reception is taking place .  or everybody   two things . first of all , this mechanism is only a media access controlled mechanism , it is not connected with routing anyhow . and , second point ,  rts  rts packets can collide to other rts packets . this mechanism is not preventing collisions , it is preventing only data collisions .  the and you can say "" but what is the what the benefit is ? "" the benefit is that , rts packets and cts packets are short packets , really short packets . let 's say 30 bytes or less . while data packets can be much mor much bigger . let 's say one k , five k s .   a collision in this short packet is only wasting a small amount of time . and , if that way we can warranty that there is there are there is no collision between data packet , this is this means a huge increase in network throughput , because we we only waste really small time colliding .    it is a reservation mechanism ,  if reservation doesn't work if one reservation don't succeed then , this transmission should have to until the reservation   let me l let me   fo for forget about routing .   a cts . that 's   that 's it . that 's  but node is only involved in one transmission at a given time .  if now two has answer with the cts , it will be waiting until the data that has to come .   but n not before .  you cannot no , no . but we are talking only about a data packet . at the mac layer .   all the packets , all unicast packets .  that true . that 's true . but not in the meantime . ",,
Bns002.D,"after receiving probably the routing protocol will need to check the address the let 's say ip address , which is inside the data packet ,  you cannot u usually you cannot , read the data packet until you the reception is over .  because usually your network hardware only provides you a copy of a packet after ou a successful reception and usually that reception is successful if every bit has passed the crc check .  you have checked that the that this frame has received without errors .    that 's let me put some special representation of what we are doing .  this is the transmitting node , this is the receiving node , and these two areas , there 's something like this , are the places of the total space where you can hear the here , this one is the rts and this one is the cts . any node , this node is a neighbor of the receiving node , but it is not a neighbor of the transmitting node . when this node hears the cts transmission that is performed by the receiver , this will be informed , that a recev a reception is taking place in it 's area .   this node will avoid any further transmission until this reception , that will start in a moment , is over .     not no . no . let me let me show you one thing . if this node was transmitting before , it should it should ha transmit an rts packet in advance , this node should hear it before . this node is w won't be sending the cts packet to the transmitter . this transmission won't take place . m  and , there is another detail , it is not in on the slide , and it is that both the rts and the cts packet have a field , a control field where the total length of the data packet is shown .  when you hear one cts or one rts packet , that the frame that they are trying to transmit or , that this one is trying to transmit this one is about to receive the length . the bit rate , that the amount of time you have to until you can try to get the control , or t try to send your own transmission .  we are assuming that all the transmissions are bidirectional . it depends . it depends mainly on the antenna gain and the transmission power and the receiver threshold .  s what we are assuming is that all the nodes behave exactly the same regarding to transmission and receiving signals . but  but the but in this case , this idea , this geometric idea , can be can be , if you want , deformed because of some obstacles .  but this wall is working both ways . ",,
Bns002.D,"it is not only making this node not to hear this one , it 's also making this one not to hear this node .  if they because of this wall , if they are not neighbors , we can represent this putting this node like here .  no , but this is not the scenario we are assuming .  we are assuming all the nodes are exactly the same . they transmit the same power , and they have the same sensitivity . they can hear if hear you , you can hear me . and the opposite works also .  if you cannot hear me , i cannot hear you . in a ? not really , but also depends on power relationships , and antenna relationships .  because because one thing , if i use a directional antenna , this is making that in one direction , i 'm getting more let 's say more gain than another . and that 's true but th that what is also true is that one directional antenna works both ways . it provides you more gain when you are transmitting but also when you are receiving . in general even when if there if there i are different antenna gains , you 're getting mainly bidirectional channels . only when you have a an important power difference is when l the communication can only work one way . you have one big station with lot of transmission power , and then you have a really small mobile thing that can hear perfectly the signal from this bigger station , but it has not enough power to transmit something that can be heard here .  but this is not our scenario . in our scenario , all the nodes are exactly the same . they have the same signal behavior .  this is not a problem for us , at least for the moment , later we 'll see some differences .  the idea is that this mechanism is a reservation mechanism . and what we are doing here is try to reserve the area of space we are covering and here 's where our some of our work is done . the main idea for our work , is if we are using this reservation mechanism , we are reserving an area of space for a single transmission . if this area is bigger than what is really needed , we are , somehow , wasting a little bit of space .  our first work in this area was to study different mechanisms to try to adjust these transmission values , these the area , the covered area , for a single transmission , trying to get a minimum value , we can reduce the not used space for other simultaneous transmissions . and this will lead us to a better network throughput , to higher number of simultaneous transmissions . and , we have , worked about this problem in two different ways . ",,
Bns002.D,"one of these ways has been try to find a mechanism to calculate an optimal value for the transmission range and to get an equal value for all the transmitters . the idea in this first work was to obtain a fixed value for the transmission range . and the second work , it is about  it is about an algorithm to adapt the transmission power for every single transmission . in this second part of our work , we are using a different value for every single transmission .  first point , what we have proposed is a way to obtain the transmission range for an escenario where we know the number of nodes and the area of deployment , we have a fixed area , where we deploy all the nodes , we have a fixed number of nodes , and , we assume that these nodes are moving freely around this area and , what we have presented , is a mechanism to calculate to obtain the transmission radius that provides at the same time that provide us the better throughput possible the better possible throughput ,  but without our network getting partitioned , which is a problem that we are trying to avoid . if we have , because of node motion , we have something like this , this is the deployment area of or node , and if we have some nodes here and some nodes here , these nodes in this area , cannot reach the nodes on this other area .  what can we do to avoid this ? we can choose our transmission values longer enough to reach from the nodes from this area will be able to reach the nodes on this other area .  but , again , we can assume that if nodes are moving , more or less in a random fashion , this configuration is not very likely to happen .  the point we ha what we have done is to present a mechanism would pr which provides one value for a given probability .  we can say that given value are @ @ for the transmission range , will be for a given number of nodes , if we for a certain , for a certain probability .  we cannot say that this is not gonna happen , what we can say is this is not very likely to happen , if nodes move random .    this is the next . th u e e  but this is a way that it is being explored by other researchers , but not by me . but there is , one , at least one person who is doing what they call "" topology control "" , and this is , related to the control of the transmission power to get certain properties from your network , like they are what they are doing is some people working for bbn ram ramanatan is the researcher , and the article is think from this year , and ",,
Bns002.D,"these guys are doing what they call b connected networks "" , they are trying all the network nodes to have at least two neighbors .  and they are controlling the power to this g get this number of neighbors , but this is not what i am doing and the power control i am doing is more or less presented here , and what we are doing is to transmit with the minimum power needed depending on the distance to the destination .  every transmission is supposed to be done to a certain neighbor node we cull the neighbors to these nodes which are closer than a given distance ,  and because we wanted to compare our algorithm with something , we needed to compare it with the no power control , which is the usual mechanism at this media access control level . what we are doing here is to compare our mechanism against the no power control , but again we have to fix in order to be able to compare , we have to fix a given whatever , but a given maximum transmission range to compare . and , what we are doing is we are taking the advantage that we are u we have this rts cts dialogue , in advance , before sending the data , to agree with the receiver , the power level he is willing to get from us .  every single transmission in every single transmission we are checking with the receiver the power level we have to use for the data transmission . that 's the main thing . and as , we are assuming that e y for at least for veh car and walking or people riding a mo motorcycle the f frame length is small that only very small space can be travelled while the transmission is taking place .  in one millisec  you just take the let 's let 's no but but , i let 's say you have one kilobyte .  one kilobyte is eight bits .  and if you are transmitting at , let 's say , at one megabit per second , this means one microsecond per bit .  this only is taking eight milliseconds , which is not a lot of time if you are travelling , let 's say , at one hundred kilometers per second . per hour .   it will be delayed but you will start from scratch again . it will be a start with another rts cts .  but , anyway , depending on the network , you now , the this i will have to translate this ,  it shou should be something ipsh this should be something like  thirty meters per second .  in eight milliseconds , the amount of space you are travelling is not too much . for most of the wireless technologies , not for all of them ,  but i 'm i 'm also using a conservative value for the transmission speed , ",,
Bns002.D,"now you can get much more speed than speedier interfaces than this one , but that we are assuming that for a given transmission , we can consider the network as if it were built of a set of static nodes .  motion will be important for routing , but for the media access control level , we are considering that motion can be con is not important .  but again , what we are adding with this behavior is , little bit more , probably some small part to the bit error rate .  this frame will won't be received properly , and , should have to be dropped , but anyway , even if nodes are completely static , some problems will happen in the wireless transmission ,  we won't have a hundred percent perfect channel anyway . if this problem , as you show it probably it 's you can see that it is not very likely to happen , because you have to consider the probability that o of happening this     i had to prepare a more detailed view , was trying to do something soft , not to bore th the public but there are a lot of other smart things that are built in , in these protocols , like an automatic , acknowledgement . some protocols used in the same way as this rts and cts packet some of them use , an acknowledge from the receiver , which is also a short packet , you are getting some link layer acknowledgement scheme which can save a lot of data transmissions because usually when you send a frame , you will want to some acknowledgement back . if this acknowledgement has to go through the process of a new rts and a new cts , this takes longer than just a link layer extra packet . that , is also contemplated in this packet length or included in the rts and cts packets , everybody can until this acknowledgement is also transmitted by the receiver .  nnn some people proposing this mechanism is showing a b a big improvement and there are a lot of other mechanisms , also regarding and a time out mechanism , or the time out algorithm for these retries when you try to send something and you don't succeed , what you the amount of time you have to until you retry again . some people is also proposing different things , different algorithms with different results . there are a lot of good was trying to present a the main ideas . i ask you feel free to ask whatever you want , but i want to insist that it was just an simplified version , a light version .  finally this algorithm , as i was telling , what it 's doing is to check with the receiver the power level to be used . and it is very simple to see that some advantages can some advantage can be obtained , ",,
Bns002.D,"because the difference is if you don't have power control , you are using all the time the maximum power , if you have power control , sometimes you will use less than the maximum power how often do you use less power than the maximum ? this will be connected to the motion pattern .  depending how nodes are moving , all the time all your neighbors are at the maximum distance but , this probably , doesn't l look like something very very likely .  because l probably y what you will have will be some neighbors that are really close others that are a little bit far away and finally , these neighbors that are in the frontier of your coverage area .     let me answer you with a question . if , your car you have an endless source of gas , do you think it will be a problem , the amount of gas your car is using ?  it won't be a problem for your pocket , for your wallet , but it will be a problem for the environment . that the answer to your question is in this line , that if you have an endless source of power , it 's not a problem , for the battery lasting . but , it is a problem because you are using more area than you should . and therefore you are preventing other transmissions to take place at the same time . and therefore the problem is not only connected to the power it is also connected to the net to the global network throughput .   but , again , the m if you ask me "" what do you think what will happen , in the industry ? "" what that will happen is that they will try to get better hardware than we have now because now the problem with transceivers is that a lot of power is consumed at the logic of the transceiver , and not transmitted to the air . it is not power transferred to the air . the problem now is that most of the power t wireless network card is consuming , is drawn by the logic control of the card . all the calculations , all the hardware i am that that manufacturers will try to squeeze until the last ampere f of this let 's say , wasted power , because what you cannot avoid is , to p l the part of the radio frequency power you have to transmit . this is this cannot be avoided . but what you can avoid or you can reduce and probably because now it is the main factor , the main consumption factor , is the logic inside . in the same way , at as it happened with processors , now processors are much more power efficient than before .   pero e but  but even if you don't have to worry about your power source , you have to worry about your environment , ",,
Bns002.D,"about not using more resources that you don't own that are shared about w among the community .    the destination . can take place at the same time . that 's and to get the maximum network throughput . that 's the idea . however , and it is always some however , by applying this greedy mechanism , in or , more than greedy in this case , it could be , say , this stingy mechanism to trying to avoid to use any extra space is also leading to a higher level of interference at the receivers .  at the end of the road , we have to look for some trade offs to avoid too much interference at the receivers .  at the end we are using a little bit more power than these mathematically minimum values .  because if not , the the frame error rate or the bit error rate skyrockets .  because of the of high interference levels . a lot of simultaneous transmissions also means for each receiver point of view , a lot of neighbors or nodes transmitting at the same time . and , all the transmitters with the exception of the transmitter of my transmitter , are my intereferers and are and all of them are producing less quality reception , if they are a lot of them , the reception can be disturbed .  and but this is taking longer than i expected .  let 's take a k a really light view at the routing in this network , which is another important area of research . there is a group at the itf called "" manit "" . this working group is devoted to try to present or to agree a common protocol for routing ip traffic on these networks , on these ad hoc networks , and at this moment there are , i would say , a lot of proposals of different protocols for end to end traffic and also for multicast traffic , on these networks and some day in the future a protocol should be chosen but , for the moment we have several of them on the table . and any protocol has some advantages and some disadvantages . the basic problem we have to solve in these routing protocols is the fast the fast pace at what topology changes can happen .  the problem here is that now one node is my neighbor , and next second , it is not . any route that was going through this neighbor now is not possible and should change . and the problem is that an an if you let me a personal comment , that one error on the group is not to agree a set of mobility patterns to do the tests . because here , mobility is making these neighborhood relationships to appear or to disappear , it should be interesting if we agree common set of motion patterns to perform the tests ",,
Bns002.D,"because if not , it 's difficult to perform comparisons between one protocol and another , a different one . but anyway , now what we have is two basic approaches to this problem . mainly what they call the practive protocols which are extensions of back door and link end state routing protocols distance vectors , and link end state protocols , which are usually table driven , you have a process , trying to maintain up to date a set of routing table tables and the nodes and every routing de decision is just looking up the table , and sending to the proper neighbor node and , the other set of protocols are using a reactive approach and these protocols are trying to work on demand , they are trying to solve on only these routers that are needed when i want to send a packet to a given destination , first of all , i have to figure out the proper route for this packet . and then , 'm using soft routing . i 'm including on the header of this packet , the set of nodes that should be forwarding this node to the destination . these two approaches can be somehow mixed and some hybrid proposals are also on the paper , and these proposals are trying to get the advantages of both mechanisms some sometimes making a combination of them let 's say , using practive approach for the closer set of nodes , let 's say for the neighbors and the next level , and , using a reactive approach as our routing approach , for nodes that are closer than this practive area .  and u e a some multicast protocols have been proposed for this scenario too , and , they have to deal with the same problems that they 're end to end routing protocols .  routing protocols intended for multicast . for for sending one to any .  the main problems that some of the solutions are exhibiting , is the lack of scalability mainly the source routing protocols have a problem when you scale from or scale badly from tens of nodes to thousands of nodes because , you cannot have let 's say , an endless header length . you have a limited header length .   something like this you your packet should look like this way .  this header , it 's a problem . there are also some solutions like employing some hierarchical source route routing , you don't have to put all the route anoth another problem is trying to provide some quality of service in these networks , because , change is the only thing for here providing quality of service is also is quite a challenge in this network . but , again there are some proposals . not really . not really , because i don't trust  i 'm that the proposals are ",,
Bns002.D,"but don't think that you cannot warr you i don't think you can warranty too much in these networks . i see this like a a topic i 'm not convinced about . i don't trust you can really provide quality of service , but  if you are curious , can provide you the n some of the proposals which include  and finally , the other thing , which is also under research or under study is , to have some power aware routing . there are some proposals , too . that way you could routing function could be connected with global or local power consumption . you could ask to u nnn , the network to transmit your packet with the lowest global consumption or with your lowest local consumption ,  would the option for me to use less power when sending a packet is to send it to the closest neighbor . assuming that i 'm also using s or having some power control thing . that way transmitting to the closer close to my closer node , is , something that requires less effort than sending to a more distant node . the closer node is not a good it is not in the good direction to the to reach the destination . but it is for the less expensive thing for me .  but probably this this is not something really useful . and that ca what can be u really useful is to reduce the global power consumption in the routing function .  because in this way , one node is being forced to use more power but if we take a look at the whole thing , we can ask for a low consumption route , the same way as we are asking , when we want some packet to be shipped in the real life , we can go and say "" we will we are happy with this ups ground system . what we want w is two day delivery service , or w twenty four hours service , and we are willing to pay more or less for this service .   that 's o k . these are more or less some open problems , and just a quick comment about probably all of use are now aware of the availability of this standard the i triple e eight hundred and two point eleven it is powering the evolution of the of networking industry in the wireless area . and in the beginning , the first adaptors  were only one and two megabytes per second , but now we you can buy for the same price for even the same price the new eleven megabytes per second version i 've been use it for a while , and it w can tell you it works pretty and that these devices have two different modes of operation . one of them , and probably the most popular , is what we call the "" infrastructure mode "" , ",,
Bns002.D,"where you have a set of mobile nodes , and then you have one or more access points . these access points are providing the required connectivity from the mobiles to the network to the m wired network , and from there to the internet usually . we can call it a base station . and , the other mode of operation which should be appropriate , for this meeting room example , doesn't require any access point , and in this second case , communication happens f from one computer to the other at the link ly layer .  if i want to connect to let 's say , miguel 's , michael 's , will send him a packet , and he will receive it , and that 's it . we can build on top of this some routing algorithm , some ad hoc routing algorithm , but this is out of the scope of the standard . and    for the no . eleven b is only for radio and it 's only for direct sequences spread spectrum . but , there is an ongoing new version , it 's c version a , but it is not commercially available which w will use orthogonal frequency division multiplexing and will get probably twenty five megabits per second . but , again , the will move to five gigahertz , five point five gigahertz , gigahertz , area of a spec expect spectrum but now , current devices are split at that the old wavelan are nine hundred megahertz version and the new ones are the eleven megabits are two point four m ism band . however , some old wavelans are also , but not the older ones the oldest ones , are also two point four m gigahertz . s s and the good thing is that now , especially with the new version , all you you ca you are you start to see compatible products in the market . because because it 's the , let 's say , second version , but also because it 's the only way for this industry to take off . because previous versions , if you buy , let 's say , wavelan , you are tied to wavelan al the rest of your life . but now you can have interoperable products from several vendors , which is , what , in the past , will power the ethernet revolution you can buy any compatible product and it will work with the other brand . in front ?    in the beginning , what w the that to put things in perspective , what we need to know is what bluetooth is and what bluetooth is for . and bluetooth is mainly for cutting this cable . the other day i was joking about that our wireless microphones were not , wireless because it had this wire , that bluetooth is mainly a technology for cutting these cables . sh short distance cables , ",,
Bns002.D,"carrying usually really s sh nnn , nnn slow signals , or let 's say , boys and something like this .  but the initial version had only the range of ten meters , and that somebody at a certain meeting said "" why don't we have a l an extended range version , we could re use the same technology for other purposes , different than the original ones . "" i have the feeling that this is u this is what is introducing some confor confusion in the bluetooth or in the way people is looking at bluetooth because they can say "" hundred meters is an acceptable distance , let 's say , for communicating inside a building , inside a small office . some people , is being tempted to think that bluetooth could provide them some local connectivity , but for data for computing uses . however , that the when you have tried current standard working devices , you working at eleven megabits per second , you cannot switch to another thing , to another slower thing . but even when they are using the same area of a s a spectrum , because bluetooth is also intended to work in two point four gigabits , the technologies are different , bluetooth is using a frequency hopping system and  both dialing sequence and frequency hopping , spread the spectrum techniques , are also intended to provide interference l less , data transmission . the idea is that these two techniques are intended not to interfere with any other thing . even when i haven't tried , and i cannot tell you for that the only problem one network will encounter in the presence of the other is a little bit of more noise . and this will produce a little bit less throughput , but nothing more . i don't expect any more problem . even the own bluetooth specification is also assuming that another bluetooth or several bluetooth networks c will be could be in the same area of space and they are using the same hopping technology , frequency hopping technology . but again , this technology is trying to avoid the other networks by choosing different hopping patterns . if several bluetooth networks can coexist without a problem , i don't see any problem will happen if we want to make coexist one bluetooth with another wireless local area network technology .   five bucks . five bucks chip .  will be . will be . bluetooth is also designed to be compatible with existing digital european cordless telephones . hopefully , we will be able to use some of our old devices or our cordless phone base station at home , with a computer . s s think some really applications will appear . i 'll try to . let me just finish , this is something i , more or less , i told you . and the point , or or ",,
Bns002.D,"what the spark of my work here , or at least , of what i was proposing to work here , is the fact that these two model two modes of operation , i was telling you here that you have to choose at the driver level if your network adaptor is working in an access point based environment or in ad ho in an ad hoc environment . i see this as a limitation because that when you have to choose among two options , you are saying "" no "" to some of the benefits the other option , different than the one you are choosing , could provide you . and i envision an m an escenario where   let 's go . where we can have a dual mode wireless network adaptor if we are not able to reach any access point but we are able to reach another network node , this network node could do me the favor to reach or to forward my packets to the access point . the main idea , the driving force here , is to try to obtain let 's say , hybrid mode which allows an adaptor to work either in the access point or in the in the ad hoc mode in a seamless way . and to include in every single node driver , this forwarding or helper forwarding mechanism that will allow to extend the wireless coverage without a need of buying a lot of access points and putting even an access point inside the restroom . this idea can sound p can sound a little bit not very appealing for the manufacturers , at least for the manufacturers of access point because they probably are very happy of selling a lot of them .  this is the m this is near the end , this is the last  one possible extension of the same idea and something 've been thinking for awhile , is the idea that , why can't do we extend this same concept to cell array systems ? why can't we , think about some new mechanisms that users could get , connectivity by means of other users , and no directly to the base station , or , when we have several technologies in overlapped in a certain area , why can't we use the closest and the cheapest , technology , or the less power consumption technology , without the user to worry about if he is now using this or the other technology . and on the other hand , what are the billing implications of this behavior ? because it is clear that , when i 'm only talking to the base station of my provider , billing is more or less straightforward , but what happens if i 'm working let 's say , across a mall , and at a given moment i 'm using the small base station of a cordless phone that is inside the shop i 'm at the window of ? ",,
Bns002.D,"in this case , i 'm using a resource which is not owned by my provider . i 'm using , a let 's say , a private property . have to pay to this private property , or my carrier will have to pay or to refund some money to this guy . this something , 'm putting on the table i 'm not about , if this can be really of interest or not but , it 's an idea , and i 'll be happy to discuss it with you . and my presentation is over ,  you are welcome .  nnn , no to both q to both questions . i don't have previous experience i don't know if where it will it would fix . however , 'm just doing this presentation some somehow a review of my previous work . this doesn't mean that i 'm probably getting involved a little bit more in this active routing thing . will be able to hopefully i will be able to give you a better answer in the future . than michael , for your computer . should i power off it ?    w which is i which is proper michael michael , which is the proper answer ? th this one ?    universidad nacional de educacion a distancia  paez , paez paez .  wher where your slides are available ? wher where the slides are available ? when ?  you will send it ,  we have ",,
Bns002.E,"you want me to say   i 'm working in the broadband commu it 's not a hear it works like this .  that 's  that 's much more comfortable .  i 'm working in the broadband communications group and  the research topics at this moment is i p eighty traffic monitoring and characterization and tool developing tools for quality of service , performance analysis . that 's and we have several projects both spanish and european projects , ongoing in this area . excuse me @ @ . if i understood correctly , the mechanism you should look for the minimum coverage range in order to maximize the throughput of the network . there the power control algorithm should work , in order to use at each instant of time the minimum power need to reach the neighbor . that because this is the way more transmissions may take place at the same time . you need the adaptive mechanism to minimize the coverage range . that very much . who is ? perez . peire . no . i don't know . i don't know who he is .  ",,
Bns003.A,"right . the messages .  "" alumni "" .  it is . there are some gaps . there are some gaps left and , i don't know , you you can also read through the all the text which is on the web pages cuz i 'd like to change the text a bit cuz sometimes it 's too long , sometimes it 's too short , the english is not that good ,   but anyways tried to do this today and if you could do it afterwards it would be really cuz i 'm quite that i can't find every orthographic mistake in it good .  the graphics are too bad . i know . i can't change something with a logo .   good , ju an another thing is i 'd want to get a link on the logo that you can come from the logo to the icsi web p home page back .  that 's these are th some things i have to do .  and if you have something which i should put on the web page for you ,  some pictures will be a few sentences will be and it depends on how much time you have . and then the page for inf about some information for people who are new comers or , i don't know a good word for it , should we use new comers "" or with somebody who is new , arriving here , or wants to , send an application ? s  newbies ?  there i have to add some information , i don't know , i t i tried to set up everything by today for this page cuz i 've started with this , if you have any ideas what was important for you then just let m cuz i have some points like don't know f like pacific bell , like long distance carriers , then like cars and car insurances , health insurances health insurance is k something only say for german people .  i don't know if this is different in spain . that would be fine too , to have some information , or in d nnn holland . i don't know .  how how you did it or whatsoever .   then what else did i have ? then another point 's like , what about the bank , transferring your money from europe t over here , what is the cheapest way or what could you recommend  another point and then there 's another point like going out in berkeley or what to do in berkeley or in the neighborhood . no , i know . i know . but there 's nothing like this on the icsi page as far as i know . but it 's not in the this is not on the web .  i don't know , talk with jane about this . if we can use this information , i don't know , somewhere on the icsi home page too .   ",,
Bns003.A,"i talk to jane about this . no , this is why i have to talk to jane . but this is not a problem if y you are coming from germany and that there is something changed with the health insurance , then you send jane an email like "" could you change this , blah blah . ""  yes . yes , also fine .  another point is i want to would like to add a another button , something which is called like "" events "" or , i don't know , call it "" events "" like where we could s announce talks which are , future talks for the future , or and where we could also have a link on the two workshops which have going on , last summer , hannes ' workshop and then the workshop from oliver , that there might be a link behind these workshops and or former talks we have , like from people who have been here before and he wants to , publish their slides , or an article , or whatsoever , behind there . that we have like a button for events which are where workshops can be announced or old workshops could be , shown or whatever . no , it 's easy to add it ,    but this will be then down on the button of the page anyways .     see for me it 's the same also say , for me everything has completely changed , now i go back and i don't anything what to do , it 's like i have to sort everything out when i 'm back in germany but i won't go back to the university  i don't think then it 's like   no , no .  "" lost "" is bit like  that must be three weeks ago , cuz i r met him when i arrived . again ? i don't know . should i ?  wilbert i 'm i 'm that was mean ,  ",,
Bns003.B,"  p cs . p cs . the first stop , the first thing the most , complicated is to fit them with the removal removable hard disk . but it 's  the first computer i had to  the  what 's the right word ? i had to put everything out to put the removable hard disk in and it 's it 's but i but it 's not , very , difficult like that . you just have to  wilbert will set up the second computer . it 's about one hour to put this , hard disk in and a further hour to , two or three hours to install the operating systems .  at the moment . right , on friday when i installed , linux the first time i got access to the local network here , but not to any machines outside of , icsi . and , till monday there 's no access to any machines , also not to inside machines . it 's related to the work , they 've done on sunday here and i sent the pages are already on the web ?     but , your argument is , it we have to have the right to change it . if there 's anything changing in insurances like that , that we have access to this page further on to chan to make any changes . but it 's much more complicated .  the best solution is really to put a link on the icsi page to this and the itself is , located at our server .  in our directory ,  i don't know . it could be a good thing if we have such an event button that , somewhere beneath this button or wherever , that there 's a date , when the last update was . that it 's worth to click this button to see there 's a new , announcement or not . s otherwise , you are often clicking this button and you get your old information or even an empty page .   something like that . "" last updated "" ,  it 's just a su suggestion i don't know how easy it is to implement something like that . holidays and there 's no final master 's thesis like that what they have to perform ?       i will no , no , no . will stay here till the end of february and afterwards , at berlin i 'm funded by an institution of the german government ,  they are paying me , and i have to do research for them , i have to reach some goals and on . but on the other hand there will be some time left to do some work on this area i started here . and for me , myself , i 'm also very interested in continue this work and that will be manageable and , on the other hand there are also some students or  ",,
Bns003.B,"at the moment it 's quite difficult to find students , who are doing their master 's thesis and on because there are not a lot of students , which are in this state in germany now , but about two years ago the numbers of students were , studying computer science , started to increase again and in one or two years we will have , many students , which are performing their master 's thesis and think there will also be , many students which are joining in this work . hopefully , i will found will find some students which are joining in and , hopefully this work will be go on . that 's it . ",,
Bns003.C,"but wh what are the box ? but what w  build , any computer you n installing whatever . it 's needed , i will enjoy doing it .  that 's for me .          that 's     there are couple of comments i have about the web pages . one is the , it 's joe 's , graphic , it should be better . you are working at it .  and then the icsi logo could be could be ,  no , it is just ,  we can , translate the white color into transparent color it will get more natural . it 's just a suggestion . to the home page .  that 's   i i will take a look and i will tell you something .  th they have a white booklet , probably no , no , no .  the pacific bell phone was not working , when i tried the phone on this booklet it was not working . but that this could be on a starting point or if digest it 's a common      that 's too .   i 'll be here until the end of july . and ,  even later if , there is some interesting work , going on , will be able to do some work from spain too . that 's my future forecast .  the problem the that we have a problem or a difference in spain , at least , compared with the americans . and i is that our students are , are not getting involved in research until they have , finished their studies . it 's something a little bit , strange but it is this is the w   they you have to pass the different tests and you have to study the different subjects . and , until you have finished with this , you can do it by your own , but that you 're not supposed to do it . and usually students are pretty busy for not doing other things .  nnn , not really . there is . there is . but , it is not a research work . usually it 's an application work . you build a web site , your own e commerce site , whatever , or a program or but but it is not , something your teacher provides you some research papers and you , let 's say , build a simulator or try to .  we have , other students are which are , people that has a grant and they are starting as , researchers , aaa , but this is only connected to your own funding if you have projects you can have , people working with you . if you don't have , a research project you cannot pay them usually you don't have anybody . it 's dependent on the funding we have in some projects .  w it 's not not really  we we could find , some , work force .  ",,
Bns003.C,"because you can , fo redirect the work as let 's say as a subject work of something that you can try to , s in some subjects , the the , topics are more open you can introduce some research topics too .  but the main thing is that there is a , this big difference because , students are not supposed to do research , work until they have finished their gra their grade .    too , but , it also depends on the subjects because sometimes subjects are fixed you cannot , give any you want . you have to provide a certain prime for the subject too , but , sometimes , especially in the latest , courses things are probably more open and , it is something that can be changed . they are using the same idea of labelling packets with a content descriptor  there 's a connection point .  later . not really , that in the future , somebody will come to the nsa group    no , that  that it cannot , be , considered the first type task to do because nobody is knowledgeable about multicasting but that , any of us could address these things in the future , or new person could address this . in the future .  if wh what is that , it makes no sense to me to reduce , something which is more or less complete , because we don't have the person . that the way to go is probably the opposite , to try to find something which has a meaning by itself and then try to get the resources to do this     that 's  heh ? now i  ",,
Bns003.D," we can start ?  adam . i will call you then when we are ready . i believe , one hour , in that sense .  welcome to our next meeting . have couple of points we should discussed . one is related to the proposal , michael , can you close the door ?  and , furthermore , as most of will leave in tenth of december , we should discuss how we proceed in the meantime , because i get , i would like to say , different signals from siemens , i believe , in the meantime it 's a higher probability that i will return , but based on the pro procedure to get a j one visa and the ip six it will be i would like to say , earliest stage will be end of january , that means we have to get over six weeks and then furthermore i would like to know the status of everybody . i know for miguel , you will have your plans for this , ongoing process , concerning your work . from you it 's definitely clear , in principle . for michael , what are your current plans and dietmar , you then , also . what we have discussed , in principle , concerning the ongoing process with u usaia and also this , your current work , and from my point , it seems to be clear that i will go back definitely at tenth of december , and , as i mentioned before , probably will be more than fifty percent , i would like to say , that i will be come back to get the freedom to launch here the project in the sense in whatever form and get , in principle , paid by another project within siemens . how long i will stay . i believe , a couple of months definitely and based on the success , that 's always an ongoing process to go back to to germany for a couple of weeks and then come here and go on with this work and that is my current opinion , concerning how siemens deal with my , ongoing effort . and , furthermore , i would like to first of all , to dietmar because he started to use a testbed .  in principle , in his spare time .  will the first , box , this morning . i will set up , definitely , in my spare time , in the evenings and the weekends the second box , and i 'm looking for two other volunteers who are setting the third and the fourth box . a box is a s p c . equipped with we should equipped it with linux or too with free bsd , i doubt i don't know and we 'll and now we have an expert . to remov that you can pull the plug in the removable hard disk to the id bus ",,
Bns003.D,"and it 's a little bit  and why you are laughing ? i ju i don't know , i cou i s i didn't see him , don't he did . i know in the meantime it 's running , and i will definitely set up the next one .  though my idea you can equip it with a i don't your time constrain whether the time constraint allows you to set up one with free bsd ,    do you find the time ? also to support your no promises ? and even to , put your i g m p on it .  no promises . he 's very hard to sell . nee , because then the network is still running then . could we until the network is running ? because currently it 's not possible , based on certain fire wall constraints . i believe david is , currently working on that . to set up the fire wall , and he 's not an expert for that and when i get the signal i will ask one more time . nah , but nevertheless to dietmar that he @ @ . yes , we have , for secure socket , and , for web access , the fire wall is open . that 's all . and but currently it 's not working , right ? but then ,  yes .  you have internet outside access , but no telnet and not r login or whatever things , ftp yes . but no telnet . because you can that we will use it , as it is described several times , that we will use it as a local network , in principle , but it doesn't make sense to use certain kinds of media transportation f to put some you need from your pc or your ls to this , to this testbed ,   you download it , if that s must be possible from the network , but normally it should be used as for demonstrations or to figure out if you have a scenario where you have to use more than , one box which you have on your desktop , cuz that is the primary , reason for this testbed . definitely you have to have web access to download the necessary files . and then furthermore , one more to claudia . he did a lot of work and i could only pass her some advices and some discussions with her concerning the web pages . and now we are , in principle , in the state we have to do it with a project area . but they 're also some contributions from you guys requested .  and the alumni page , in principle , we have to , but it 's primarily my job , i believe , to set up that it is , adjusted really to the people who are worth to be alumnis alumnis ,  is it "" alumni "" "" alumni "" ? i 'm ",,
Bns003.D,""" alumni "" . i 'm not how to pronounce this word .  and , but , everybody should take a look to the web pages , and inform claudia if something , has to be improved or if there 's some comments or  he 's laughing all the time . why ? because it is that 's very important now not for us but for our successors and somebody will come back once a day or send some students or some colleagues or whatever . my point of view i will doc i will documented everything when i will leave here in the sense that potential successor as a group leader can hook in with these things and that these web pages will be updated every time when it is necessary . we tried to do it , that it must be at least updated only when really major changes happen . that means somebody 's leaving the group , somebody is joining the group , a new project is started , but , the effort should be minimized as possible . and , take a look to the web pages and i have announced in the project area the major headlines . and especially , wilbert , you can write something about yours ? i call it , i believe , "" multicast "" and then "" development deployment "" , for source specific multicas few lines , picture . and something like that should be added to usaia ? that 's my and  then the next point is then this active routing  i would like to discuss it before , but you were busy . and  i believe , it must be adjusted to the current activities a little bit more . and , it doesn't it is not worth to discuss it now because nobody raised it before . and , let us have a bilateral discussion afterwards . i would what i would like to have is that your contributions is related to certain things happened here . and that means really to the project proposal itself and also to the usaia architecture , in that sense , that at certain stages , cuz it 's a general architecture , certain stages to future mobile core networks , that it is related to these things . having i what i have in mind is that things should not be started from the end system . that 's my principle concern , because that will never be happen , from my point of view . it should be started as the edge device , that it cu certain mechanism , whatever , is enabled between the ingress edge device and the outgress a edge device , because it will be at the certain stage ip based in the future generation telecommunication networks before its goal . fuel it to the over the internet , and b between these both boxes , assume because the mobility happens there as a normal natural thing ",,
Bns003.D,"and the forwarding process and the routing process should be no more separated , from my point of view . and to have there a certain intelligent mechanism , that the packets can be used to set up the routes because they have all the information . they know where they have to go because ip addresses are still there and within the packet . how can this use , within this area , and how this area is then aligned to the more traditional routing within the internet backbone itself . that 's my question . and that is good a research area , then there 's a lot of i 'm not a e xpert for this . but i believe , there 's a lot of potential for that . and we should discuss it bilateral afterwards .  one more time , everybody should take a look to the web pages and from claudia , at the general remarks and should write based on the , headlines in the project proposal the things what still happened , the things what they have still in mind that we can update these last @ @ @ present the last major part of the web pages . yes , you can now access it normally with www icsi berkeley edu , and   you are definitely right . it was in a good shape , but it , then we disturbed .   i will send you some because i have something in mind . but nobody do that ,  that 's the point . we discussed it still a couple of weeks or months ago . normally it is an icsi task anyway . but right . that is from nineteen ninety one or nineteen ninety two , a a and this is not on the web , and the people normally that 's was my ,  we can do that . but that nobody feel responsible for that . and if it 's yes , yes , i see there your point . that 's right . but if it is under the networking points , the group leader is responsible to get up to date information . i believe , we are the group , where the people are , changing much more faster to join the group and to leave the group as other groups . and , the most problem as of , it 's likely that the people here in this group needs this information much more f often as other groups . yes , i see th  but we can do that . that 's  that 's a we have the directory structure , of the real unix tree . in compliance and in accordance with what you with the structure of the web pages . and , that means , the group leader normally do not have access to the general web pages . he has access to the n s a pages . and , ",,
Bns003.D,"but that 's an administration problem and that everybody agrees that the information page must be on the general , on the highest level .  i have no problem with that . but but we discuss if still  how it the process here within the nsa group .  and that was a reason i we finally decided here that we put it information on the n s a page , we have discuss dis this discussed still a couple of months ago . in our directory .  we can do that . we then create a link and then we have to ask with jane ,  that is a living thing . it 's a good idea , not only that the workshop was a talk announce because they are still announce it is a broader sense . but the idea from claudia is very good , that the slides from the talks here , if it 's worth to have it on the web , anyway should be published in that way that the people can access it . have my usaia slides . if some things and is going on you have some multicast slides concerning your work at igmp and and if we have some talks from exterm , and we had some in the past , we can also put the slides on these things because then they 're still cau still a growing context for us , opportunity for the people there ,  this guy did something there , contact him and ask him would you like to do something , contribute , whatever . ""  that 's and it 's a great idea from claudia to have this event page because it 's not a big deal ,  it 's it 's  and then it 's nah , if there are no events , then there are no events . but we still have a few which happened in the last year and then it is a growing thing but it 's done automatically that the group leader or the group , put some things also on the web . something in the center pipe .  everybody agree ? there 's we can have "" updated on "" , the button itself ? and then , "" updated "" and the current date , when something happened . i don't know how we deal with that . is it another thing we have to ?  you  let 's consider "" update event button "" .  and then the next point and , i believe , not the last one , @ @ is one that i would like to know the status as far it is possible from everybody concerning his future intention here at icsi or whether e when he will leave whether he can contri or will he consider currently , contribute here to the proposal because i 've i 'm facing the problem , if i go back to siemens and i say "" there 's a potential . "" ",,
Bns003.D,""" there are potential contacts . "" currently , no money , but if we go in one direction it is worth to know if people can still go on in that area of that work then they are back in their university or their company or whatever . and even if it 's nur unschl part time jobs and if it 's come to a real proposal , that the people can hook in , one more time because i need this information definitely t to inform the the siemens management that it 's worth to send me back here . wilbert you can start . you will leave end of january definitely . and currently you see no chance , as far as i know , to stay longer here and either you will go back to kpn or you will stay here and find then a job opportunity another company , is that right ? can you give us more details of concerning the status ? no ? pending . yes , but you have no  you are looking for a job . that 's probably then in principle , i would like to say you are lost for the nsa group , because ffft that 's it would be a wonder if , it hook in at the same area ,     ja from the work contributions ,   do whether they have from your side the statement is , that , independently of your person the kpn is not they 're not willing to send us another guy here to icsi anyway . and , if they are interested in a certain project then it must be related to a certain really service or a certain end system or real product or whatever thing with respect to umts , right ?   kpn and icsi in principle . after you will leave here that is . and then what do you intend to do in the last two months beside looking for ,  this is that from mark , right ? not ?  do you finish that and do you believe that you can finish that until end of january ? it sounded to me a little bit , hard t hard time constraint , right ?   mi miguel , you can say also .   and , do you have some students which could be join if there is i assume there is a certain activity . if you will leave in july what ? they are not  they are not involved in research ? what they are doing then ? i 'm  ach ach    why i didn't study in spain ?   are certain tasks and  no , there . we 're not talking about to send the students here to i c s i . i 'm talking if there is an activity , at least with the nsa group , that certain activities also in the university could apply for the master works , of diplomas thesis , whatever thing that      ",,
Bns003.D,"claudia , i still mentioned , have you other things ? for me , as i said before i will be funded by a d by the ministry of , the german government for research in the project called invinet that seems to be and i got freedom to do what i would like to do , and i would like to go on with the qs in advance mechanism and , in the relation of usaia i also have the activities with georgia tech . they have now a phd . it is settled , and my other next , generation of contract is also going in that sense the topic is still going go going on . and when i will come back here , i would like to use these things too to come to a closer , a bigger project outside of this goal , with contributions here from , first of all from the nsa group and then from other partners . but this i have definitely ou discussed with my management and this will happened , i believe , in december , and in the beginning of january . and i will keep informed to the management of icsi anyway , but also , i assume that my suggestions that we have a weekly phone conference and email exchange during that time that we can inform each other concerning what are the questions , what are the problems , what is the status and on .  but we will detail these things then in one of the last meetings .  how is your status and your ideas and your plans and your future and you 're addicted to the testbeds you run on the hour , that 's   sounded good to me . and michael ?  then , what is the current status anyway ? this is .   now as i see , in principle , fff that 's a really raw view . mpls offers certain success of active routing , because in principle , the forwarding pass is a little bit decoupled from this from the routing pass , and this was , in principle  it 's not really the subject but in a broader sense it could be seen in that sense . there are in a certain degree some alignment with both of you guys , right ?   it 's a separation , in principle , that i do not use the normal traditional , data forwarding pass and update , in principle , only the routing information to use it .    what is at a certain degree , that has to be figured out . there is , there are some linkage between them . @ @ in both of your work .  my last point , in principle , is the proposal itself .  i know , in the past it was always if i 'm not writing something nothing gonna happen . i believe , wilbert , you are going out of these activity . ",,
Bns003.D,"you have to use your time to finish your work as you have in mind until your end of february , or is that right ? end of january ,  you will not y you will not find any time to contribute anymore to this activity .  then from miguel 's side i expect more detailed vision . we can do it , as i mentioned before , bilateral afterwards , concerning your work and how you think it could be beneficial contribution to the activity based on the generic usaia architecture . i will write as long as i have time here , on the proposal itself and in the near term future , i will distribute a list of the small cluster of people . i tried to access juan peire several times , he didn't answer , because he still had mentioned that there 's some minor funding , that would help , to have initial meeting either here or in europe or wherever . i 've , contact one more time the professor , what is his name ? rao ? or ? l landay mentioned , rao , right ?  because he 's a professor in responsible for the infrastructure at ucb and he has some projects which are related to these , activities i would c name it cor intelligent classroom . i don't know whether succeed to get an appointment then but i will distribute a list contact list and @ @ the interests of each partner that everybody can see and everybody knows , i have in mind it 's a small nsa group activity itself , with no linkage to the outer world it 's a nsa group activity with a linkage to the outer world based on the universities at home or the companies at home there 's some linkage and the third stage is , let 's say there 's a nsa group activity in this area , with the supported , home entities and with certain linkage here to the companies or u or universities here in this area . the last one , it 's , the best one . but , you see the question is always "" where 's the money ? "" and i say "" poo , currently i don't know . "" the second question is how long i stay here and say ooo , i don't know "" ,  everybody 's waiting .  and the only rea activity could come from the nsa group itself , but it 's a work in process and that it will take some time and , everything must be just settled a little bit more . but anyway , i would like to get contributions from the people here of the nsa group concerning proposals , this is a living thing and it 's a pity that multicast is , in principle , removed and we do not have any expert from multicast anymore . and , that 's makes very hard , i believe . ",,
Bns003.D,"because that is a major @ @ , at least twenty five percent of the whole network and , but neverless we have to live with this situation . right . you are laughing , again ? we have to rewrite something , have new ideas going forward more in certain really telecommunication network and the routing and qs and remove , in principle , the multicast which , in principle , a pity because that 's a really good source of research work for the future telecommunication core networks because they are still not able to deal with multicast , they still have there that tunnel generations and all those things and i believe that would be very beneficial to use it for the really mobile scenarios in that network , but anyway we have to live with a real situation and that means we have to drop multicast from the proposal . any comments ? then we can extend the proposal one more time with multicast . you understand me in the wrong way .  i do not mean to drop it , to remove the text from the proposal . activities , planning activities . work packages .   no , no , because that 's , that 's why i mentioned that it is important thing . but , currently there 's only one new group member , sven buchholz , who will figure out the thing , how to say , the taking into account the end system , or the limited end system capabilities with respect to mobility and the network itself . where it should be ada @ @ where should be , the adaptation process performed to deal with the different devices , for ubiquitous access to the network ? should it be in the end system itself ? should be in the edge device ? it should it be in the core ? should it be on the server ? these are the questions he would like to figure out . and to p to have , in principle , the pro and cons of , different of all these different approaches . that 's the only new member . sven buchholz . he was here . i invited him and discussed with him his potential work , i @ @ . quite  but he showed up the next day but only for administration but for the technical discussion he was here one day . i 'm do not remember whether w whether you were  he will come mid of january , i believe ,  as far as i know . but this is the only guy , but that is not reflected in that sense that we remove the text . what is , the that we what 's activity we are going more in detail in describing , the network packages and detailed , descriptions more detailed descriptions .  any other question ? any other comment ?  then we pu should start with reading the numbers one more time . yes , ",,
Bns003.D,"we have to do it , that means we have to read the transcript script number and then the numbers , and if there 's a new line , a short break . and , afterwards we have to , that device is switched on , do not switch off the devices . and i will call herr janin and that adam @ @ . will start . one fine . he 's laughing all the time . michael    then i will call adam . adam ? ",,
Bns003.E," no promises . no . no promises . no . did the networks have internet connectivity ? but normally you should have access to th all the internet , r to outside . full . a restricted in . not .  not a no ftp . h  newbies . newbies . this a lot of this is not networking group nsa , restricted . m but a at least then it should be be , icsi part , and not network restricted . m move it on the normal icsi , icsi . every group has somewhere hidden , gro deep outgoing but but my point is that it should not be under the networking group thing . but  but b but that could still be applicable if you put it under the icsi site if you take the responsibility for that .  think th both arguments are not an ar are arguments against having this under the normal icsi page . or only the networking , page .    yes ,  no , no . pending .  but that 's also for me , i 'm lost for the nsa group . and also  b but even also k p n . i is lost for the , for the i c there 's a lot of , z budget cuts going on and nothing is possible anymore ,  yes .  i it will be different thing . it will be a start up . and i know they 're working on a w a few of them in this area , but it 's ou outside of icsi .  u th i am working now on something , an open source router . no , in it 's a little bit u out of mark . i 'm right now i 'm interested and i 'm looking into it and i 'm working started yesterday , actually working on it , to do the , to do an implementation of the protocol that was designed by mark , on an open source router that 's different from the one that of mark 's project . s i hope i that would be  it 's hard work .  that 's right . but i 'm working on it . lectures . you can change that . m you sh it 's pretty healthy for a student to have a project , where you have to write actually some part of research or .   o  january , yes . no . right . right . who is that ? he was here one day . i do remember him , but i didn't talk with him about , about the research topic . didn't he was going to do . we have to do that ?  did you get that ? no , it wasn't . i saw it already standing there when i was here then i started laughing ,  ",,
Bns003.F," aber das wird jetzt geaendert . das wird geaendert . but the problem is , are you allowed to change anything on the general icsi server ?  you may need just a link from the main icsi page to the nsa page .  but that 's effort . that 's the whole problem , that nobody wants to do it .  i won't change the topic then . i 'm here until end of may and after that i presumably going to a siemens project with some department of gee mens , but related to that topic what i have done here .  it 's some of pre stage to that , it might be more related or loosely related . it 's at least it 's in the same topic . and progress , it 's going on , but it 's not that fast going on as i would have like it .  i would like to have it .   but oder ? i 'm currently i 'm looking into quality of service routing , and i had discussions with a post doc from the u ucb .  we want to we started to collect information to write the paper about quality of serving routing . for mpls in an mpls domain . you have distributed routing at the edges , and one aspect is that the information is outdated , that to always have the exact information of your links , dates , and on . it what we have plans of that . and trying to look at some routing policies , or routing algorithms .  it it d  at least from the desh definition of christian tschudin , mpls is a subset of active route active routing . it 's very it 's static ? it 's no , active ? but it 's active because they have these program statements . but y    that 's right .  l lan landay ? landay .   several days .      ",,
Bro003.A," i 've got to move a bunch of furniture . let me see . that 's good . you 're alright ? will that be enough time ? once you get past the bridge that would be the worst .  once you get past the turnoff to the bay bridge .      i did you happen to find out anything about the ogi multilingual database ? they are ?  and ideally , what you 'd wanna do is you 'd wanna run it with and without the target language and the training set for a wide range of languages . and that way you can say , "" "" "" we 're gonna build it for what we think are the most common ones "" , but if that somebody uses it with a different language , "" here 's what 's you 're l here 's what 's likely to happen . "" right . i don't know anything about finnish .   resistance is futile . when you said that you were getting the labels for timit , are y what do by that ?  were the digits , hand labeled for phones ? or were they those labels automatically derived ?  i was just wondering because that test you 're t you 're doing this test because you want to determine whether or not , having s general speech performs as as having specific speech .  and i was  was just wondering if the fact that timit you 're using the hand labeled from timit might be confuse the results that you get . right , but if it 's better , it may be better because it was hand labeled .     right . what about the differences in the phone sets ? no , between timit and the digits .  i see . out of that fifty six ?     and some of them , they were making distinctions between silence at the end and silence at the beginning , when really they 're both silence . i th it was things like that got it mapped down to fifty six .  there 's not much difference , really . and the ones that are gone , are there was they also in timit had like a glottal stop , which was short period of silence , and i don't know .  what about mel cepstrum ? or is that you don't include that because it 's part of the base it 'd be an interesting test just to have just to do mfcc with the neural net and everything else the same . compare that with just m mfcc without the net .  where did th where did that come from ? digits ?  is that was that distributed with aurora , or ? where did that ? what about ti digits ?    i see . what about combinations of things ? you just select multiple things on the one dimension . when you do that , you 're increasing the size of the inputs to the net . ","did you happen to find out anything about the ogi multilingual database ? were the digits , hand labeled for phones ? you 're doing this test because you want to determine whether or not , having s general speech performs as as having specific speech . was just wondering if the fact that timit you 're using the hand labeled from timit might be confuse the results that you get . ","The main topics discussed were arrangements and objectives of an
upcoming field trip to visit research partners OGI; a number of
members reported their progress to date; if there are any tasks that
one member can help others with; an overall description of the Cube
project, a multi-lingual speech recognition system for use by the
cellular phone industry, along with consideration of some of the
issues therein, specifically disk and resource issues. "
Bro003.A,"do you have to reduce the hidden layer , no , no , i 'm just wondering about number of parameters in the net . do you have to worry about keeping that the same , or ? but wh what about a net that 's trained on multiple languages , though ? is that just separate nets for each language then combined , or is that actually one net trained on ? in one net .  i don't know . depends on the corpuses , right ? is it faster to do it on the spert , or ? is it ?   you 're just having a problem converting the labels . nuh right . i 'm not what 's available on is it you said nutmeg and what was the other one ? mustard .  right , right . i 'll check on that . what you can do , when you 're on that machine , is , just go to the slash scratch directory , and do a df minus k , and it 'll tell you if there 's space available . and if there is then , there 's different there , there 's right . there 's the slash x whatever disks , and then there 's slash scratch . and both of those two kinds are not backed up . and if it 's called "" slash scratch "" , it means it 's probably an internal disk to the machine .  and that 's the thing where , like if if you don't have an nt , but you have a unix workstation , and they attach an external disk , it 'll be called "" slash x something "" if it 's not backed up and it 'll be "" slash d something "" if it is backed up . and if it 's inside the machine on the desk , it 's called "" slash scratch "" . but the problem is , if you ever get a new machine , they take your machine away . it 's easy to unhook the external disks , put them back on the new machine , but then your slash scratch is gone . you don't wanna put anything in slash scratch that you wanna keep around for a long period of time . but if it 's a copy of , say , some data that 's on a server , you can put it on slash scratch because , first of all it 's not backed up , and second it doesn't matter if that machine disappears and you get a new machine because you just recopy it to slash scratch . tha that 's why i was saying you could check slash scratch on those on , mustard and nutmeg to see if there 's space that you could use there . you could also use slash x whatever disks on mustard and nutmeg .   and we do have   you ",i 'll check on that . ,
Bro003.A,"it 's better to have things local if you 're gonna run over them lots of times you don't have to go to the network .  one of the things that i need to i 've started looking at is this the appropriate time to talk about the disk space i 've started looking at , disk space . dan david , put a new , drive onto abbott , that 's an x disk , which means it 's not backed up .  i 've been going through and copying data that is , some corpus usually , that we 've got on a cd rom onto that new disk to free up space on other disks . and , far , i 've copied a couple of carmen 's , databases over there . we haven't deleted them off of the slash dc disk that they 're on right now in abbott ,  but we i would like to go through sit down with you about some of these other ones and see if we can move them onto , this new disk also . there 's a lot more space there , and it 'll free up more space for doing the experiments and things . anything that you don't need backed up , we can put on this new disk . but if it 's experiments and you 're creating files and things that you 're gonna need , you probably wanna have those on a disk that 's backed up , just in case something goes wrong .   far i 've copied a couple of things , but i haven't deleted anything off of the old disk to make room yet .  and i haven't looked at the any of the aurora except for the spanish . guess i 'll need to get together with you and see what data we can move onto the new disk . that would be a that 's a big deal . because the the thing that sunil was talking about , with the labels , labeling the database when it got to the noisy the that really throws things off . having the noise all of a sudden , your , speech detector , the , what was it ? what was happening with his thing ? he was running through these models very quickly . he was getting lots of , insertions , is what it was , in his recognitions . what about training up a , a multilingual net ?  another year . you 'd have to create a mapping from each language to the superset . it uses special diacritics and which you can't do with ascii characters . the sampa 's just mapping those . they just throw the speech from all different languages together , then cluster it into sixty or fifty or whatever clusters ? automatically derived  automatically derived broad classes , or ?  ","dan david , put a new , drive onto abbott , that 's an x disk , i 've been going through and copying data that is , some corpus usually , that we 've got on a cd rom onto that new disk to free up space on other disks . we haven't deleted them off of the slash dc disk that they 're on right now in abbott , but we i would like to go through sit down with you about some of these other ones and see if we can move them onto , this new disk also . they just throw the speech from all different languages together , then cluster it into sixty or fifty or whatever clusters ? ",
Bro003.A,"you 're saying that there may not be enough information coming out of the net to help you discriminate the words ?  the targets of the net are these ? articulatory features . but that implies that you can have more than one on at a time ?   i see . we could do an interesting cheating experiment with that too . we could i don't know , if you had the phone labels , you could replace them by their articulatory features and then feed in a vector with those things turned on based on what they 're supposed to be for each phone to see if it if you get a big win . do what i 'm saying ?   if your net is gonna be outputting , a vector of of it 's gonna have probabilities , but let 's say that they were ones and zeros , then y and for each ,  i don't know if this for your testing data , but if for your test data , what the string of phones is and you have them aligned , then you can just instead of going through the net , just create the vector for each phone and feed that in to see if that data helps . what made me think about this is , i was talking with hynek and he said that there was a guy at a t andt who spent eighteen months working on a single feature . and because they had done some cheating experiments  right ,  right . and they had done a cheating experiment right ? and determined that hynek said that , before they had him work on this , they had done some experiment where if they could get that one feature right , it dramatically improved the result . was thinking , it made me think about this , that if it 'd be an interesting experiment just to see , if you did get all of those right . right .   and then you also don't error they 've got on the htk side .  it gives you your the best you could hope for , ","you 're saying that there may not be enough information coming out of the net to help you discriminate the words ? we could do an interesting cheating experiment with that too . was thinking , it made me think about this , that if it 'd be an interesting experiment just to see , if you did get all of those right . ",
Bro003.B,"oakland .  other than the language , is there a reason not to use the timit phone set ? cuz it 's larger ? as opposed to the icsi phone set ?      we have that now , too , right ?  or swiss . swiss german . did the aurora people actually corrupt it themselves , or just specify the signal and the signal t  from the deep south . or you just add it to the features . it 's not a complete set of combinations , though , right ? it 's not a complete set of combinations , though , right ? there 's a computation limit , though , isn't there ? isn't there like a limit on the computation load , or d latency , like that for aurora task ?   i don't ravioli is . we can check really quickly ,   it s also depends on the net . how big is the net ? how big are the nets you 're using ?    sampa ? what does "" sampa "" mean ?  i 'm i was gonna say , does that mean ipa is not really international ? i see . got it . fact , most confusions are within the phone classes , right ? larry was saying like obstruents are only confused with other obstruents , et cetera .  the soft training of the nets still requires the vector to sum to one , though , right ? you can't really feed it two articulatory features that are on at the same time with ones cuz it 'll normalize them down to one half like that , why don't you just choose linear ? right ? linear outputs ? isn't that what you 'll want ? if you 're gonna do a kl transform on it . you   ","isn't there like a limit on the computation load , or d latency , like that for aurora task ? fact , most confusions are within the phone classes , right ? ",
Bro003.C,"this is barry chen and i am reading transcript     that 's right . i live in , the corner of campus . the , southeast corner .  six , oakland .  s just s six am , in front .  wake you up . wednesday . tell him about the cube .  telephone .  that 's test on an unseen . my turn .  let 's see , i spent the last week , looking over stephane 's shoulder . and understanding some of the data . i re installed , htk , the free version , everybody 's now using three point o , which is the same version that , ogi is using .   without any licensing big deals , or anything like that . and , we 've been talking about this , cube thing , and it 's beginning more and more looking like the , the borge cube thing . it 's really gargantuan .  but i 'm am i exactly . 've been looking at , timit the that we 've been working on with timit , trying to get a , labels file we can , train up a net on timit and test , the difference between this net trained on timit and a net trained on digits alone . and seeing if it hurts or helps . anyway .    the inputs are one dimension of the cube , which , we 've talked about it being , plp , m f c cs , j jrasta , jrasta lda  right . i haven't decided on the initial thing . probably something like plp .  right . right . right .      b may  i 'm just i 'm just , transforming them from the , the standard timit transcriptions into a long huge p file to do training . the digits  those were automatically derived by dan using , embedded training and alignment . ellis . right ?   that 's right . between languages ?  right . there 's a mapping from the sixty one phonemes in timit to fifty six , the icsi fifty six . and then the digits phonemes , there 's about twenty two or twenty four of them ? is that right ? out of that fifty six .   it 's definitely broader ,   why map the sixty one to the fifty six ? i don't know . i have  w i th that 's a good idea to talk about the whole cube and we could sections in the cube for people to work on .   do you wanna do it ?    i have the wireless .  can y can you walk around too ? no .    s the cube will have three dimensions . the first dimension is the features that we 're going to use . and the second dimension , is the training corpus . and that 's the training on the discriminant neural net .  and the last dimension happens to be right , right . this is for ann only . ","let 's see , i spent the last week , looking over stephane 's shoulder . and understanding some of the data . i re installed , htk , the free version , which is the same version that , ogi is using . 've been looking at , timit the that we 've been working on with timit , trying to get a , labels file we can , train up a net on timit and test , the difference between this net trained on timit and a net trained on digits alone . the inputs are one dimension of the cube , which , we 've talked about it being , plp , m f c cs , j jrasta , jrasta lda those were automatically derived by dan using , embedded training and alignment . the cube will have three dimensions . the first dimension is the features that we 're going to use . and the second dimension , is the training corpus . and that 's the training on the discriminant neural net . ","Most important concerns are which
combinations of features to use, and what combinations of languages
and broad/specific corpora to use for the training Essentially the cube consists of three dimension: input features;
training corpus; and test corpus. "
Bro003.C,"and , the training for the htk models is always , fixed for whatever language you 're testing on . and then , there 's the testing corpus . then it 's probably instructive to go and show you the features that we were talking about .  let 's see . help me out with with what ? plp ?  msg . jrasta . jrasta lda . multi band .  just the multi band features , right ?   we could add dan did some of that . in his previous aurora experiments . and with the net it 's wonderful . without the net it 's just baseline .    for the training corpus , we have , the d digits from the various languages . english spanish french what else do we have ? finnish . italian . one l or two l 's ?  and ,   and french . and then we have , broader corpus , like timit . timit far , right ? spanish spanish stories ? ti digits all these aurora f d data p data is from is derived from ti digits . they corrupted it with , different kinds of noises at different snr levels .   no . sp not spanish stories ? spanish something .  they corrupted it , themselves , but they also included the noise files for us , right ? or we can go ahead and corrupt other things . from spain .   from paris ,  and timit 's from lots of different places .    and , with within the training corporas we 're , thinking about , training with noise .  incorporating the same kinds of noises that , aurora is in incorporating in their , in their training corpus . i don't think we 're given the , the unseen noise conditions , though , right ? like   right . we can't train on the unseen noise conditions . right . if not if it 's unseen .  the testing corporas are , just , the same ones as aurora testing . and , that includes , the english spa italian . finnish . we ' r we 're gonna get german , right ? ge at the final test will have german . right . spanish .  we can test on s spanish .   one hundred each , about . th  when i put these testings on there , i 'm assumi there 's three tests .  type a , type b , and type c . and they 're all gonna be test tested , with one training of the htk system . there 's a script that tests all three different types of noise conditions . test a is like a matched noise . test b is a slightly mismatched . and test c is a , mismatched channel .  no , no , we 're gonna be , training on the noise files that we do have .  that 's a good question .  och ! ","and then , there 's the testing corpus . for the training corpus , we have , the d digits from the various languages . ","Essentially the cube consists of three dimension: input features;
training corpus; and test corpus. Most important concerns are which
combinations of features to use, and what combinations of languages
and broad/specific corpora to use for the training "
Bro003.C,"now , this is turning into a four dimensional cube ? just   no . that would be no .    i don't know . i don't know .  i don't know how w how we would p make this , though .    the neural net ?   on a spert board . y you did a you did it on a spert board .  it 's still a little faster on the   ad adam did some testing . or either adam or dan did some testing and they found that the spert board 's still faster . and the benefits is that , you run out of spert and then you can do other things on your computer , and you don't     for the for nets trained on digits , we have been using , four hundred order hidden units . and , for the broader class nets we 're going to increase that because the , the digits nets only correspond to about twenty phonemes .  the broader training corpus nets like timit . w we 're gonna right . right .  more classes . right , right . more classes . that 's what  and .    i was thinking two things . the first thing was , we actually had thought of this as like , not in stages , but more along the time axis . just like one stream at a time , je je check out the results and go that way .    right , right .      and the second thing was about scratch space . and you sent an email about , e scratch space for people to work on . and i know that , stephane 's working from an nt machine , his home directory exists somewhere else .       like a s like a slide ?  there 's ,  carmen was talking about this sampa thing , and it 's , it 's an effort by linguists to come up with , a machine readable ipa , thing , right ? and , they have a web site that stephane was showing us that has , has all the english phonemes and their sampa correspondent , phoneme , and then , they have spanish , they have german , they have all sorts of languages , mapping to the sampa phonemes , which no , it 's saying y can't print on ascii . we could look at articulatory type right ?  superclass . allows for ?   we have gotten soft targets to work .    i see . to sum up to one . right . nonlinearity ?  it 's sig no , it 's actually sigmoid x for the you ,  the , what 's that ? linear outputs ?  right , right . right , but during the training , we would train on sigmoid x and then at the end just chop off the final nonlinearity . ",y you did a you did it on a spert board . we could look at articulatory type ,
Bro003.D,"channel one . channel three . i was just wondering , does this mean the battery 's dying and i should change it ?  th cuz it 's full . alright . what a what about noise conditions ? w don't we need to put in the column for noise conditions ? no , don't understand . and do we do all our training on clean data ? ",,
Bro003.E,"hello .  at six . fill in the cube .  to fill in the cube .  sixty one .   i th i looks the sampa phone . sampa phone ? for english american english , and the language who have more phone are the english . of the these language . but n in spain , the spanish have several phone that d doesn't appear in the e english and we thought to complete . but for that , it needs we must r h do a lot of work because we need to generate new tran transcription for the database that we have .  databases .    without the   and italian . no , italian no . italian no . i italian yes . italian ? like mexican spain and spain . that is more important , mexican spain . because more people  and spanish too . albayzin is the name . spanish stories ? no . no . no . albayz  no no . no no . spanish from spain . finnish .  it 's preparing . they are preparing . also , we can clean that .  no . here .  necessary to put in . database three . the model the htk model . it depends on the more than six hours . for the italian , yes . one day .   m mfcc . ravioli .  who is that ? i don't know . i don't know . it depends . depends on the corpus . for albayzin i trained on neural network , was , one day also .  the neural net spert . yes .   d i begin to work with the italian database to nnn , to with the f front end and with the htk program and the @ @ . and i trained with the spanish two neural network with plp and with lograsta plp . i don't know exactly what is better if lograsta or jrasta . hm hm it 's a bit i 'll do better . and to recognize the italian digits with the neural netw spanish neural network , and also to train another neural network with the spanish digits , the database of spanish digits . and i working that . but prepa to prepare the database are difficult . was for me , n it was a difficult work last week with the labels because the program with the label obtained that i have , the albayzin , is different w to the label to train the neural network . and that is another work that we must to do , to change . albayzin database was labeled automatically with htk . it 's not hand it 's not labels by hand . labels . i 'm i 'm the labels . i 'm the labels . also that yes . the spanish labels ? that was in different format , that the format for the the program to train the neural network . i necessary to convert . and someti  it 's it 's   but n ","sampa phone ? for english american english , and the language who have more phone are the english . but n in spain , the spanish have several phone that d doesn't appear in the e english and we thought to complete . but for that , it needs we must r h do a lot of work because we need to generate new tran transcription for the database that we have . one day . depends on the corpus . yes . d i begin to work with the italian database to nnn , to with the f front end and with the htk program and the @ @ . and i trained with the spanish two neural network with plp and with lograsta plp . and to recognize the italian digits with the neural netw spanish neural network , but prepa to prepare the database are difficult . was for me , n it was a difficult work last week with the labels because the program with the label obtained that i have , the albayzin , is different w to the label to train the neural network . and that is another work that we must to do , to change . the spanish labels ? that was in different format , that the format for the the program to train the neural network . i necessary to convert . ",
Bro003.E,"yes , because they have one program , feacalc , but no , l labecut , l labecut , but don't doesn't , include the htk format to convert . and , i don't i ask e even i ask to dan ellis what do that , and h they he say me that h he does doesn't any s any form to do that . and at the end , that with labecut transfer to ascii format , and htk is an ascii format . and i m do another , one program to put ascii format of htk to ase ay ac ascii format to exceed and they used labcut to pass . actually that was complicated , but i know how we can did that do that .    yes , to , put together the label the labels between timit and spanish like that . yes .    no . the multiple language . for the other language because timit have more phone .     the tr the transcription , though , for albayzin is n the transcription are of sampa the same , how you say , symbol that sampa appear . but i don't know if timit o how is timit .  ",,
Bro003.F,"you think we 're going now , yes ? good . alright going again we 're gonna go around as before , and do our digits . transcript one three one dash one three zero . three two three four seven six five three one six two four one six seven eight nine zero nine four zero three zero one five eight one seven three five three two six eight zero three six two four three zero seven four five zero six nine four seven four eight five seven nine six one five o seven eight o two zero nine six zero four zero one two you don't actually n need to say the name . that 'll probably be bleeped out .  that 's if these are anonymized , but mean not that there 's anything defamatory about eight five seven or anything , but anyway . here 's what i have for i was just jotting down things th w that we should do today . this is what i have for an agenda far we should talk a little bit about the plans for the the field trip next week . number of us are doing a field trip to ogi and mostly first though about the logistics for it . then later on in the meeting we should talk about what we actually might accomplish .  in and go around see what people have been doing talk about that , a r progress report . essentially . and then another topic i had was that dave here had said give me something to do . "" and i have failed far in doing that . and we can discuss that a little bit . if we find some holes in some things that someone could use some help with , he 's volunteering to help . always count on a serious comment from that corner .  and then talk a little bit about disks and resource issues that 's starting to get worked out . and then , anything else anybody has that isn't in that list ?  think that means the battery 's o k . d do you     it looks full of electrons .  plenty of electrons left there .     i wanted to start this with this mundane thing .  it was my bright idea to have us take a plane that leaves at seven twenty in the morning .  this is the reason i did it was because otherwise for those of us who have to come back the same day it is really not much of a visit .  the issue is how would we ever accomplish that ?  what part of town do you live in ?  would it be easier those of you who are not , used to this area , it can be very tricky to get to the airport at six thirty . would it be easier for you if you came here and i drove you ?   if everybody can get here at six . ","we should talk a little bit about the plans for the the field trip next week . and mostly first though about the logistics for it . then later on in the meeting we should talk about what we actually might accomplish . in and go around see what people have been doing talk about that , a r progress report . essentially . and then another topic i had was that dave here had said give me something to do . "" and we can discuss that a little bit . and then talk a little bit about disks and resource issues that 's starting to get worked out . those of you who are not , used to this area , it can be very tricky to get to the airport at six thirty . if everybody can get here at six . ","The main topics discussed were arrangements and objectives of an
upcoming field trip to visit research partners OGI; a number of
members reported their progress to date; if there are any tasks that
one member can help others with; an overall description of the Cube
project, a multi-lingual speech recognition system for use by the
cellular phone industry, along with consideration of some of the
issues therein, specifically disk and resource issues. "
Bro003.F,"i 'm afraid we need to do that to get there on time .  boy . anyway ,   'll just pull up in front at six and just be out front . and , and that 'll be plenty of time . it 'll take it won't be bad traffic that time of day and going to oakland . bridge the turnoff to the bridge won't even do that . just go down martin luther king . and then martin luther king to nine eighty to eight eighty , and it 's it 'd take us , tops thirty minutes to get there . that leaves us fifty minutes before the plane it 'll just   great ,  that 'll it 's it 's still not going to be really easy but particularly for for barry and me , we 're not staying overnight we don't need to bring anything particularly except for pad of paper and and , you , two have to bring a little bit but don't bring a footlocker and we 'll be  w you 're staying overnight . i figured you wouldn't need a great big suitcase ,  that 's one night .  anyway .  six am in front . i 'll be here . 'll i 'll give you my phone number , if i 'm not here for a few m after a few minutes then nah , i 'll be fine . it for me it just means getting up a half an hour earlier than i usually do . not a lot ,   that was the real important i figured on the potential goals for the meeting until we talk about wh what 's been going on . what 's been going on ? why don't we start over here .    the htk base lines this is using mel cepstra and on , or ?  the p the plan is , to then given this what 's the plan again ? with does remind me of what you were going to do with the what 's y you just described what you 've been doing . if you could remind me of what you 're going to be doing . this is  cube .  we had talked we had talked at one point about the language id corpus ? is that a possibility for that ?  that 's really funny isn't it ? cuz th this whole thing is for developing new standards for the telephone .   i know , but the reason see , your point is that it 's it 's the features are computed locally , and they aren't necessarily telephone bandwidth , or telephone distortions . that 's wh that 's what i meant . i said @ @ , there 's there 's an ogi language id , not the not the , the callfriend is a , ldc w thing , right ? but i 'm not we ' r e the bandwidth shouldn't be such an issue right ? because e this is downsampled and filtered , ",what 's been going on ? ,
Bro003.F,"right ? it 's just the fact that it 's not telephone . and there are many other differences between these different databases . some of this 's recorded in the car , and some of it 's there 's many different acoustic differences . 'm not if . unless we 're going to include a bunch of car recordings in the training database , i 'm not if it 's completely rules it out if our if we if our major goal is to have phonetic context and you figure that there 's gonna be a mismatch in acoustic conditions does it make it much worse f to add another mismatch , if you will . the question is how important is it to for us to get multiple languages in there .   that 's what you 're thinking of using is the multi the equivalent of the multiple ? and for the difference in phonetic context that you ? provide that . we also have this broadcast news that we were talking about taking off the disk , which is microphone data for english .  right . there 's plenty of around . anyway , th the basic plan is to , test this cube . yes . to fill i fill it in ,    but that 's depen it depends how using the net "" . if you 're talking about for producing these discriminative features that we 're talking about you can't do that . because the what they 're asking for is a feature set . right ? and we 're the ones who have been weird by doing this training . but if we say , "" no , you have to have a different feature set for each language , "" this is ver gonna be very bad .   in principle , conceptually , it 's like they want a re @ @ they want a replacement for mel cepstra . we say "" this is the year two thousand , we 've got something much better than mel cepstra . it 's , gobbledy gook . "" and we give them these gobbledy gook features but these gobbledy gook features are supposed to be good for any language . cuz you don't know who 's gonna call , and it 's it 's , how do what language it is ? somebody picks up the phone . thi this is their image . someone picks up the phone , right ? and he picks up the ph y y  but , no but , y you pick up the phone , you talk on the phone , and it sends features out .  the phone doesn't what your language is . but that 's the image that they have . it could be , but that 's the image they have , right ? that 's one could argue all over the place about how things really will be in ten years . ","we also have this broadcast news that we were talking about taking off the disk , which is microphone data for english . cuz you don't know who 's gonna call , how do what language it is ? somebody picks up the phone . thi this is their image . the phone doesn't what your language is . ","The main topics discussed were arrangements and objectives of an
upcoming field trip to visit research partners OGI; a number of
members reported their progress to date; if there are any tasks that
one member can help others with; an overall description of the Cube
project, a multi-lingual speech recognition system for use by the
cellular phone industry, along with consideration of some of the
issues therein, specifically disk and resource issues. "
Bro003.F,"but the particular image that the cellular industry has right now is that it 's distributed speech recognition , where the , probabilistic part , and s semantics and forth are all on the servers , and you compute features of the on the phone . that 's what we 're involved in . we might or might not agree that 's the way it will be in ten years , but that 's that 's what they 're asking for . think that th it is an important issue whether it works cross language . now , it 's the ogi , folks ' perspective right now that probably that 's not the biggest deal . and that the biggest deal is the , envir acoustic environment mismatch . and they may very be right , but i was hoping we could just do a test and determine if that was true . if that 's true , we don't need to worry much . we have a couple languages in the training set and that gives us enough breadth that the rest doesn't matter . the other thing is , this notion of training to which they 're starting to look at up there , training to something more like articulatory features . and if you have something that 's just good for distinguishing different articulatory features that should just be good across , a wide range of languages . but don't th i know unfortunately i don't i see what you 're comi where you 're coming from , but i don't think we can ignore it .   there 's there 's , this is complex . ultimately , as i was saying , it doesn't fit within their image that you switch nets based on language . now , can you include , the target language ? from a purist 's standpoint it 'd be not to because then you can say when because surely someone is going to say at some point , "" you put in the german and the finnish . now , what do you do , when somebody has portuguese ? ""  and however , you aren't it isn't actually a constraint in this evaluation . would say if it looks like there 's a big difference to put it in , then we 'd make note of it , and then we probably put in the other , because we have many other problems in trying to get things to work here that , it 's not bad as long as we note it and say , "" look , we did do this "" .    cuz the truth is , is that it 's not like there are al although there are thousands of languages , from the point of view of cellular companies , there aren't . there 's there 's fifty   an and they aren't with the exception of finnish , which it 's pretty different from most things . ","but the particular image that the cellular industry has right now is that it 's distributed speech recognition , where the , probabilistic part , and s semantics and forth are all on the servers , and you compute features of the on the phone . we might or might not agree that 's the way it will be in ten years , but that 's that 's what they 're asking for . think that th it is an important issue whether it works cross language . ",
Bro003.F,"it 's it 's , most of them are like at least some of the others . and our guess that spanish is like italian , and on . finnish is a little bit like hungarian , supposedly , right ? or is  i kn know that h h i 'm not a linguist , but hungarian and finnish and one of the languages from the former soviet union are in this same family . but they 're just these , countries that are pretty far apart from one another , have people rode in on horses and brought their  your turn . good . are you going to be assimilated ?  when y just to clarify , when you 're talking about training up a net , you 're talking about training up a net for a tandem approach ? and the inputs are plp and delta and that thing , or ? but your initial things you 're making one choice there , right ? which is plp ,   you take plp and you , do it you , use htk with it with the transformed features using a neural net that 's trained . and the training could either be from digits itself or from timit . and that 's the and , and th and then the testing would be these other things which might be foreign language . i see . i get in the picture about the cube .    those listening to this will not have a picture either , 'm not any worse off . but but at some point somebody should just show me the cube . it sounds s i get get the general idea of it ,  but which dan ?   especially when you go over the different languages again , because you 'd the different languages have different words for the different digits , it 's it would , but on the other hand it might be better .  but still @ @ probably use it .  'm sounding cavalier , but you have , a bunch of labels and they 're han hand hand marked . actually , timit was not entirely hand marked . it was automatically first , and then hand corrected . but , it , it might be a better source . i it 's you 're right . it would be another interesting scientific question to ask , "" is it because it 's a broad source or because it was , carefully ? "" and that 's something you could ask , but given limited time , the main thing is if it 's a better thing for going across languages on this training tandem system , then it 's probably  superset ,    i forget if that happened starting with you , or was it o or if it was eric , afterwards who did that . but there were several of the phones that were just hardly ever there . especially in a system like ours , which is a discriminative system . "," your turn . it would be another interesting scientific question to ask , "" is it because it 's a broad source or because it was , carefully ? "" superset , ",
Bro003.F,"you 're really asking this net to learn . it 's hard . i it 's actually pretty common that a lot of the recognition systems people use have things like , say thirty nine , phone symbols , right ? and then they get the variety by bringing in the context , the phonetic context . we actually have an unusually large number in what we tend to use here .  a actually now you 've got me intrigued . what there 's can you describe what 's on the cube ?      even though the meeting recorder doesn't , and since you 're not running a video camera we won't get this , but if you use a board it 'll help us anyway . point out one of the limitations of this medium , but you 've got the wireless on , right ?  you can walk around . he can't , actually , but he 's tethered .  the training for htk is always that 's always set up for the individual test , right ? that there 's some training data and some test data . that 's different than this . right .  y you do have a baseline system that 's m that 's mel cepstra , right ?   probably should . at least conceptually , it doesn't meant you actually have to do it , but conceptually it makes sense as a base line . ogi folks have been doing that , too . d because that for a bunch of their experiments they used , mel cepstra , actually . that 's there and this is here and on .  italian . the newer one .   carmen brought the spanish , and stephane brought the french . is it french or belgian french ? there 's a    probably  herve always insists that belgian is i is pure french , has nothing to do with but he says those parisians talk funny . they they do , but then he likes belgian fries too ,   y and stephane was saying there 's some broader s material in the french also ? spanish i 'm just curious , carmen i couldn't tell if you were joking or i is it mexican spanish , or is it no . it 's spanish from spain , spanish .  alright . spanish from spain . we 're really covered there now . and the french from france .  from ti . from i it 's from texas . may it 's it 's not really from the us either . is that ? what they were saying was that , for this next test there 's gonna be some of the cases where they have the same type of noise as you were given before hand and some cases where you 're not . presumably , that 'll be part of the topic of analysis of the test results , is how you do when it 's matching noise and how you do where it 's not . ",a actually now you 've got me intrigued . can you describe what 's on the cube ? ,"Essentially the cube consists of three dimension: input features;
training corpus; and test corpus. "
Bro003.F,"that 's right . not if it 's not seen ,  i it does seem to me that a lot of times when you train with something that 's at least a little bit noisy it can help you out in other kinds of noise even if it 's not matching just because there 's some more variance that you 've built into things . but , exactly how it will work will depend on how near it is to what you had ahead of time . that 's your training corpus , and then your testing corpus ?   the final test , on a guess , is supposed to be german and danish , right ? there 's a there 's spanish testing in the aurora ?   something like seven things in each , each column . that 's , three hundred and forty three , different systems that are going to be developed . there 's three of you .  that 's hundred and fourteen each . what ? are you just trying to be difficult ? i 'm just kidding .     guess the question is how long does it take to do a training ? it 's not crazy t these are a lot of these are built in things and we know we have programs that compute plp , we have msg , we have jra a lot of these things will just happen , won't take huge amount of development , it 's just trying it out . we actually can do quite a few experiments . but how long does it take , do we think , for one of these trainings ?  that 's right . cuz , the major advantage of msg  good point . a major advantage of msg , i see , th that we 've seen in the past is combined with plp .    you don't wanna ,  let 's see , seven choose two would be , twenty one different combinations .  probably what ?  i hope not .  there 's   plp and msg we definitely wanna try cuz we 've had a lot of good experience with putting those together .     it doesn't increase the number of trainings . i don't think  it 's just more compu excuse me ?  we haven't talked about any of that have we ?  there 's not really a limit . what it is that there 's , it 's just penalty ,  that if you 're using , a megabyte , then they 'll say that 's very but , it will never go on a cheap cell phone .  and , u the computation isn't much of a problem . it 's more the memory . and , expensive cell phones , exa expensive hand helds , and forth , are gonna have lots of memory . it 's just that , these people see the cheap cell phones as being still the biggest market ,   but , i was just realizing that , actually , it doesn't explode out ,  ","something like seven things in each , each column . that 's , three hundred and forty three , different systems that are going to be developed . there 's not really a limit . what it is that there 's , it 's just penalty , that if you 're using , a megabyte , then they 'll say that 's very but , it will never go on a cheap cell phone . ","Most important concerns are which
combinations of features to use, and what combinations of languages
and broad/specific corpora to use for the training "
Bro003.F,"it 's not really two to the seventh . but it 's but i it doesn't really explode out the number of trainings cuz these were all trained individually . right ?  if you have all of these nets trained some place , then , you can combine their outputs and do the kl transformation and forth and , what it blows out is the number of testings . and , and the number of times you do that last part . but that last part , is has gotta be pretty quick ,   right ? it 's just running the data through you gotta do the kl transformation , but good question . one would think one net , but we 've i don't think we 've tested that . right ?  the first thing is if w if we know how much a how long a training takes , if we can train up all these combinations , then we can start working on testing of them individually , and in combination . right ? because the putting them in combination , is not as much computationally as the r training of the nets in the first place . right ? you do have to compute the kl transformation .  which is a little bit , but it 's not too much .  it 's right . right . if you do have lots of combinations , it 's how long does it take for an , htk training ? for htk ? really ? running on what ? no , i 'm ru running on what machine ?  i don't ravioli is . is it an ultra five , or is it a ? it 's a few hours . right ,   clearly , there 's no way we can even begin to do an any significant amount here unless we use multiple machines . right ? we there 's plenty of machines here and they 're n they 're often not in a great deal of use . it 's key that the that you look at , what machines are fast , what machines are used a lot are we still using p make ? is that ? you have a once you get the basic thing set up , you have just all the a all these combinations , right ?  it 's let 's say it 's six hours or eight hours , for the training of htk . how long is it for training of , the neural net ?  but on what machine ?  again , we do have a bunch of spert boards . and there 's you folks are probably go the ones using them right now . don't know . used to be .   you could be we have quite a few spert boards . you could set up , ten different jobs , to run on spert different spert boards and have ten other jobs running on different computers . it 's got to take that thing , ","how long does it take for an , htk training ? clearly , there 's no way we can even begin to do an any significant amount here unless we use multiple machines . there 's plenty of machines here and they 're n they 're often not in a great deal of use . it 's let 's say it 's six hours or eight hours , for the training of htk . how long is it for training of , the neural net ? again , we do have a bunch of spert boards . you could set up , ten different jobs , to run on spert different spert boards ",
Bro003.F,"or we 're not going to get through any significant number of these . this is  i like this because what it no no , what i like about it is we do have a problem that we have very limited time .  with very limited time , we actually have really quite a bit of computational resource available if you , get a look across the institute and how little things are being used . and on the other hand , almost anything that really i is new , where we 're saying , "" let 's look at , like we were talking before about , voiced unvoiced silence detection features and all those sort "" that 's it 's a great thing to go to . but if it 's new , then we have this development and learning process t to go through on top of just the all the work . i don't see how we 'd do it . what i like about this is you have listed all the things that we already know how to do . and all the kinds of data that we , at this point , already have . and , you 're just saying let 's look at the outer product of all of these things and see if we can calculate them . a am i interpreting this correctly ? is this what you 're thinking of doing in the short term ?  then it 's just the missing piece is that you need to , talk to talk to , chuck , talk to , adam , sort out about , what 's the best way to really , attack this as a as a mass problem in terms of using many machines .  and then , set it up in terms of scripts and forth , and in kind o some structured way .  and , when we go to , ogi next week , we can then present to them , what it is that we 're doing . and , we can pull things out of this list that we think they are doing sufficiently , that , we 're not we won't be contributing that much .  and , then , we 're there . broader class ?  it 's not actually broader class , it 's actually finer class , but more classes .    carmen , did you do you have something else to add ? we you haven't talked too much , and jrasta has the potential to do better , but it doesn't always . it 's i jrasta is more complicated . it 's it 's , instead of doing rasta with a log , you 're doing rasta with a log like function that varies depending on a j parameter , which is supposed to be sensitive to the amount of noise there is . it 's like the right transformation to do the filtering in , is dependent on how much noise there is . ","or we 're not going to get through any significant number of these . with very limited time , we actually have really quite a bit of computational resource available if you , get a look across the institute and how little things are being used . carmen , did you do you have something else to add ? ",
Bro003.F,"and in jrasta you attempt to do that . it 's a little complicated because once you do that , you end up in some funny domain and you end up having to do a transformation afterwards , which requires some tables . and , it 's it 's a little messier , there 's more ways that it can go wrong , but if you 're careful with it , it can do better . it 's   i didn't understand .  "" l labeled "" . i 'm i have a p i had a problem with the pronunciation .     let 's start over . ti timi timit 's hand labeled , and you 're saying about the spanish ? i see .     you  it 's just usual sometimes say housekeeping , right ? to get these things sorted out . it seems like there 's some peculiarities of the , of each of these dimensions that are getting sorted out . and then , if you work on getting the , assembly lines together , and then the pieces get ready to go into the assembly line and gradually can start , start turning the crank , more or less . and , we have a lot more computational capability here than they do at ogi , think that i if what 's great about this is it sets it up in a very systematic way , that , once these all of these , mundane but real problems get sorted out , we can just start turning the crank and push all of us through , and then finally figure out what 's best .    no , i 'm just saying , i 'm just thinking of it like loops , right ? and y if you had three nested loops , that you have a choice for this , and a choice for that , right ? and you 're going through them all . that 's what i meant . and , that once you get a better handle on how much you can realistically do , concurrently on different machines , different sperts , and forth , and you see how long it takes on what machine and forth , you can stand back from it and say , "" if we look these combinations we 're talking about , and combinations of combinations , and forth , "" you 'll probably find you can't do it all .  then at that point , we should sort out which ones do we throw away . which of the combinations across what are the most likely ones , and and , i still think we could do a lot of them . it wouldn't surprise me if we could do a hundred of them but , probably when you include all the combinations , you 're actually talking about a thousand of them and that 's probably more than we can do .  but a hundred is a lot . and ,  his is somewhere else ,   ","it seems like there 's some peculiarities of the , of each of these dimensions that are getting sorted out . and then , if you work on getting the , assembly lines together , and then the pieces get ready to go into the assembly line and gradually can start , start turning the crank , more or less . what 's great about this is it sets it up in a very systematic way , that , once these all of these , mundane but real problems get sorted out , we can just start turning the crank and , that once you get a better handle on how much you can realistically do , concurrently on different machines , different sperts , and forth , and you see how long it takes on what machine and forth , you can stand back from it and say , "" if we look these combinations we 're talking about , and combinations of combinations , and forth , "" you 'll probably find you can't do it all . then at that point , we should sort out which ones do we throw away . which of the combinations across what are the most likely ones , ","Most important concerns are which
combinations of features to use, and what combinations of languages
and broad/specific corpora to use for the training "
Bro003.F,"my point i want to  for bring it back to that . my th i want to clarify my point about that chuck repeated in his note .  we 're over the next year or two , we 're gonna be upgrading the networks in this place , but right now they 're still all te all ten megabit lines . and we have reached the this the machines are getting faster and faster . it actually has reached the point where it 's a significant drag on the time for something to move the data from one place to another . you don't w especially in something with repetitive computation where you 're going over it multiple times , you do don't want to have the data that you 're working on distant from where it 's being where the computation 's being done if you can help it .  now , we are getting more disk for the central file server , which , since it 's not a computational server , would seem to be a contradiction to what said . but the idea is that , suppose you 're working with , this big bunch of multi multilingual databases .  you put them all in the central ser at the cen central file server . then , when you 're working with something and accessing it many times , you copy the piece of it that you 're working with over to some place that 's close to where the computation is and then do all the work there . and then that way you won't have the network you won't be clogging the network for yourself and others . that 's the idea . it 's gonna take us it may be too late for this , p precise crunch we 're in now , but , we 're ,  it 's gonna take us a couple weeks at least to get the , the amount of disk we 're gonna be getting . we 're actually gonna get , four more , thirty six gigabyte drives and , put them on another disk rack . we ran out of space on the disk rack that we had , we 're getting another disk rack and four more drives to share between , primarily between this project and the meetings project .  but , we 've put another there 's another eighteen gigabytes that 's in there now to help us with the immediate crunch . but , are you saying don't know where you 're stephane , where you 're doing your computations . if i you 're on an nt machine , you 're using some external machine do these yet ?   are these are these , computational servers , i 'm i 've been out of it . unfortunately , these days my idea of running comput of computa doing computation is running a spread sheet .   haven't been doing much computing personally ,    those are computational servers . ","we 're over the next year or two , we 're gonna be upgrading the networks in this place , but right now they 're still all te all ten megabit lines . and we have reached the this the machines are getting faster and faster . it actually has reached the point where it 's a significant drag on the time for something to move the data from one place to another . it 's gonna take us a couple weeks at least to get the , the amount of disk we 're gonna be getting . we 're actually gonna get , four more , thirty six gigabyte drives stephane , where you 're doing your computations . ",
Bro003.F,"guess the other question is what disk there i space there is there on the computational servers .  you 're the disk czar now .   chuck will be the one who will be sorting out what disk needs to be where , and on , and i 'll be the one who says , "" spend the money . "" which , n these days , if you 're talking about scratch space , it doesn't increase the , need for backup , and , it 's not that big a d and the disks themselves are not that expensive . right now it 's but wasn't it , dave was saying that he preferred that people didn't put in slash scratch . it 's more putting in d s xa or xb or , right ? i see . right , es especially if you 're right , if you 're taking some piece of the training corpus , which usually resides in where chuck is putting it all on the , file server , then , it 's fine if it 's not backed up because if it g gets wiped out y it is backed up on the other disk .        an another question occurred to me is what were you folks planning to do about normalization ? this being ?  that 's a good idea . it 's i we seem to have enough dimensions as it is . probably if we take their probably the on line normalization because then it 's if we do anything else , we 're gonna end up having to do on line normalization too , we may as just do on line normalization .  that it 's plausible for the final thing . good .   th the other topic i we 're already there , or almost there , is goals for the for next week 's meeting . i it seems to me that we wanna do is flush out what you put on the board here .  have it be somewhat visual , a little bit .  we can say what we 're doing ,  and , also , if you have sorted out , this information about how long i roughly how long it takes to do on what and , what we can how many of these trainings , and testings and forth that we can realistically do , then one of the big goals of going there next week would be to actually settle on which of them we 're gonna do . and , when we come back we can charge in and do it .  anything else that i a actually started out this field trip started off with , stephane talking to hynek , you may have had other goals , for going up , and any anything else you can think of would be we should think about accomplishing ? i 'm just saying this because there 's things we need to do in preparation .    alright . ","you 're the disk czar now . an another question occurred to me is what were you folks planning to do about normalization ? it 's i we seem to have enough dimensions as it is . i we 're already there , or almost there , is goals for the for next week 's meeting . i it seems to me that we wanna do is flush out what you put on the board here . we can say what we 're doing , and , also , if you have sorted out , this information about how long i roughly how long it takes to do on what and , what we can how many of these trainings , and testings and forth that we can realistically do , then one of the big goals of going there next week would be to actually settle on which of them we 're gonna do . and , when we come back we can charge in and do it . ",
Bro003.F,"and and the other the last topic i had here was , dave 's fine offer to , do something on this . he 's doing he 's working on other things , but to do something on this project . the question is , "" where could we , most use dave 's help ? ""  the only problem that 's the right thing the only problem i have with it is exactly the same reason why you thought it 'd be a good thing to do . that let 's fall back to that . but the first responsibility is to figure out if there 's something that , an additional  that 's a good thing you remove the mike . go ahead , good .   what an additional clever person could help with when we 're really in a crunch for time . right ? cuz dave 's gonna be around for a long time , right ? he 's gonna be here for years . and over years , if he 's interested in , voiced unvoiced silence , he could do a lot . but if there if there 's something else that he could be doing , that would help us when we 're strapped for time we have we 've , only , another month or two to with the holidays in the middle of it , to get a lot done . if we can think of something some piece of this that 's going to be the very fact that it is just work , and i and it 's running programs and forth , is exactly why it 's possible that it some piece of could be handed to someone to do , because it 's not  that 's the question . and we don't have to solve it right this s second , but if we could think of some piece that 's defined , that he could help with , he 's expressing a will willingness to do that .    that 's something that needs to be done in any event . what we were just saying is that , was arguing for , if possible , coming up with something that really was development and wasn't research because we 're we have a time crunch . and if there 's something that would save some time that someone else could do on some other piece , then we should think of that first . see the thing with voiced unvoiced silence is i really think that it 's to do a poor job is pretty quick ,  or , a job . you can you can throw in a couple fea we kinds of features help with it . you can throw something in . you can do pretty but i remember , when you were working on that , and you worked on for few months , as i recall , and you got to , say ninety three percent , ","and and the other the last topic i had here was , dave 's fine offer to , do something on this . he 's doing he 's working on other things , but to do something on this project . the question is , "" where could we , most use dave 's help ? "" let 's fall back to that . but the first responsibility is to figure out if there 's something that , an additional what an additional clever person could help with when we 're really in a crunch for time . but if we could think of some piece that 's defined , that he could help with , he 's expressing a will willingness to do that . ",
Bro003.F,"and getting to ninety four really hard .     and th the other tricky thing is , since we are , even though we 're not we don't have a strict prohibition on memory size , and computational complexity , clearly there 's some limitation to it . if we have to if we say we have to have a pitch detector , say , if we if we 're trying to incorporate pitch information , or at least some harmonic harmonicity , this is another whole thing , take a while to develop . anyway , it 's a very interesting topic . one one of the a lot of people would say , and dan would also , that one of the things wrong with current speech recognition is that we really do throw away all the harmonicity information . we try to get spectral envelopes . reason for doing that is that most of the information about the phonetic identity is in the spectral envelopes are not in the harmonic detail . but the harmonic detail does tell you something . like the fact that there is harmonic detail is real important .    think  wh that the other suggestion that just came up was , what about having him work on the , multilingual super f superset thing . coming up with that and then , training it training a net on that , say , from , from timit is that or for multiple databases . what would you think it would wh what would this task consist of ? creating a superset from looking at the multiple languages , and then creating i m changing labels on timit ? or on multiple language multiple languages ?      what go ahead . what , has ogi done anything about this issue ? do they have any superset that they already have ? aha . that 's right . and that 's an interesting way to go too . that does make an interesting question , though . is there 's some way that we should tie into that with this .  right ? if that is a better thing to do , should we leverage that , rather than doing , our own . right ? if i if they s we have i we have the trainings with our own categories . and now we 're saying , "" how do we handle cross language ? "" and one way is to come up with a superset , but they are als they 're trying coming up with clustered , and do we think there 's something wrong with that ?  what w i see . right . although , you are not using this for the you 're using this for the feature generation , though , not the       but that 's what they were gonna did they not do that , or ?  they 're talking about it , but that 's question whether they did because that 's the other route to go . ","wh that the other suggestion that just came up was , what about having him work on the , multilingual super f superset thing . coming up with that and then , training it training a net on that , say , from , from timit wh what would this task consist of ? has ogi done anything about this issue ? do they have any superset that they already have ? because that 's the other route to go . ",
Bro003.F,"instead of this , instead of the superclass thing , which is to take suppose y you don't really mark arti to really mark articulatory features , you really wanna look at the acoustics and see where everything is , and we 're not gonna do that .  the second class way of doing it is to look at the , phones that are labeled and translate them into acoustic articulatory , features . it won't really be right . you won't really have these overlapping things and forth , but articulatory feature . right . that 's right . you either do that or you have multiple nets . and , i don't know if our software this if the qu versions of the quicknet that we 're using allows for that . do multiple targets being one ?  that 'll work ,    that 's another thing that could be done is that we could , just translate instead of translating to a superset , just translate to articulatory features , some set of articulatory features and train with that . now the fact even though it 's a smaller number , it 's still fine because you have the , combinations . it has every , it had has every distinction in it that you would have the other way . but it should go across languages better . no . this was the guy that we were just talking a that we saw on campus . this was larry saul who did this . he used sonorants . was what he was doing .  he di he didn't mention that part . but . i see .  should be . because if you get all of them in there , that defines all of the phones . that 's equivalent to saying that you 've got all the phones right . if that doesn't help , there 's although , it would be make an interesting cheating experiment because we are using it in this funny way , where we 're converting it into features .  did we just run out of disk , or ? we 're we 're off the air , or ? about to be off the air . ","to really mark articulatory features , you really wanna look at the acoustics and see where everything is , and we 're not gonna do that . the second class way of doing it is to look at the , phones that are labeled and translate them into acoustic articulatory , features . it won't really be right . is that we could , just translate instead of translating to a superset , just translate to articulatory features , some set of articulatory features and train with that . ",
Bro003.G,"test . test . perhaps ,  preparation of the french test data actually . it means that it is , a digit french database of microphone speech , downsampled to eight kilohertz and i 've added noise to one part , with the actually the aurora two noises . and , @ @ this is a training part . and then the remaining part , i use for testing and with other noises . we can this is almost ready . i 'm preparing the htk baseline for this task . and ,  the plan with these data ?   the cube ? i should tell him about the cube ?  we actually we want to , analyze three dimensions , the feature dimension , the training data dimension , and the test data dimension .  what we want to do is first we have number for each task . we have the ti digit task , the italian task , the french task and the finnish task . we have numbers with systems neural networks trained on the task data . and then to have systems with neural networks trained on , data from the same language , if possible , with , using a more generic database , which is phonetically balanced , and .  ye but , these corpus , w there is a callhome and a callfriend also , the callfriend is for language ind identification . anyway , these corpus are all telephone speech . this could be a problem for why ? because the speechdat databases are not telephone speech . they are downsampled to eight kilohertz but they are not with telephone bandwidth . but the idea is to compute the feature before the before sending them to the you don't do not send speech , you send features , computed on th the device , or you   it 's yea there are also two other databases . one they call the multi language database , and another one is a twenty two language , something like that . but it 's also telephone speech .  nnn .    but  actually , for the moment if we w do not want to use these phone databases , we already have english , spanish and french with microphone speech .    for the multilingual part we were thinking of using these three databases . this actually , these three databases are generic databases . f for italian , which is close to spanish , french and , i ti digits we have both digits training data and also more general training data .   perhaps there is also timit . we could use timit .  and perhaps , we were thinking that perhaps the cross language issue is not , big of a issue . w we perhaps we should not focus too much on that cross language training a net on a language and testing a for another language . ","preparation of the french test data actually . it is , a digit french database of microphone speech , and i 've added noise to one part , with the actually the aurora two noises . one they call the multi language database , and another one is a twenty two language , something like that . but it 's also telephone speech . actually , for the moment if we w do not want to use these phone databases , we already have english , spanish and french with microphone speech . actually , these three databases are generic databases . f for italian , which is close to spanish , french and , i ti digits we have both digits training data and also more general training data . perhaps there is also timit . ","The main topics discussed were arrangements and objectives of an
upcoming field trip to visit research partners OGI; a number of
members reported their progress to date; if there are any tasks that
one member can help others with; an overall description of the Cube
project, a multi-lingual speech recognition system for use by the
cellular phone industry, along with consideration of some of the
issues therein, specifically disk and resource issues. "
Bro003.G,"perhaps the most important is to have neural networks trained on the target languages . but , with a general database general databases . u that th the guy who has to develop an application with one language can use the net trained o on that language , or a generic net , but not trained on a   you think    i chh but the application is there is a target language for the application . if a    if  if it 's th in the phone , but it that could be th at the server 's side , and ,  we really have to do test with a real cross language . tr training on english and testing on italian , or we can train or else , can we train a net on , a range of languages and which can include the test @ @ the target language , or    perhaps .   the     but , actually , the issue of phoneti phon phone phoneme mappings will arise when we will do severa use several languages because you some phonemes are not , in every languages , and we plan to develop a subset of the phonemes , that includes , all the phonemes of our training languages , and use a network with one hundred outputs like that .  superset ,   plp . plp . msg . jrasta . and jrasta lda .  multi band . there would be multi band before , before our network , and  something like , s tct within bands and and then multi band after networks . meaning that we would have , neural networks , discriminant neural networks for each band .  and using the outputs of these networks or the linear outputs like that .   but ,  not for the ann .   we could add mfcc also .   and the finnish . english , finnish and italian are aurora . and spanish and french is something that we can use in addition to aurora .  it 's , french .  they have an accent .  we cou we could use  the french data .   the no , the french is f from , paris ,      the s  the spanish , perhaps , we will have .  but the aurora spanish , not yet , but , e pre they are preparing it , and , according to hynek it will be we will have this at the end of november , or  no . eight y probably one net .    in the broader training corpus we can use , the three , or , a combination of two languages .   it 's not too much , no . but but there is the testing also , which implies training , the htk models and , it 's  but it 's it 's not long . it @ @  it 's around six hours , for training and testing ,  more . one day ?  it 's it 's not long ","and we plan to develop a subset of the phonemes , that includes , all the phonemes of our training languages ,  it 's around six hours , ",
Bro003.G,"because , the ti digits test data is about , how many hours ? th thirty hours of speech , something like that . and it p it 's six hours . i would say two days .     it ,   to it 's nutmeg and mustard , i don't kind .      mustard .      we were thinking about using this systematically for all the experiments .   but  that this could be another dimension , but we think perhaps we can use the best , normalization scheme as ogi is using , with parameters that they use there , u   this is this is ,    i was thinking perhaps if , additionally to all these experiments , which is not really research , mean it 's , running programs and , trying to have a closer look at the perhaps the , speech , noise detection or , voiced sound unvoiced sound detection and which could be important in i for noise    defining the superset , and , joining the data and  it would consist in ,  creating the superset , and , modifying the lab labels for matching the superset .  creating the mappings , actually .   with the @ @ three languages , from each language to the superset ,  i don't think they they 're going actually the other way , defining phoneme clusters ,  they 've not done it , doing , multiple language yet , but what they did is to training , english nets with all the phonemes , and then training it in english nets with , seventeen , it was seventeen , broad classes .    and , and the result was that when testing on cross language it was better .  but hynek didn't add didn't have all the results when he showed me that ,  but that there 's something wrong or because for the moment we are testing on digits , and e i perhaps u using broad phoneme classes , it 's for classifying the digits , but as soon as you will have more words , words can differ with only a single phoneme , and which could be the same , class .   i 'm but you will ask the net to put one for th the phoneme class and      this is another p  another point . i don't think  they were talking about , perhaps , but they d i d w   but perhaps you have the choice of the final nonl  nonlinearity ,  is it always softmax or ?  if you choose sigmoid it 's o it 's ","i would say two days . it 's nutmeg and mustard ,  we were thinking about using this systematically for all the experiments . but we think perhaps we can use the best , normalization scheme as ogi is using , with parameters that they use there , and , trying to have a closer look at the perhaps the , speech , noise detection or , voiced sound unvoiced sound detection creating the superset , and , modifying the lab labels for matching the superset . creating the mappings , actually . they they 're going actually the other way , defining phoneme clusters , and e i perhaps u using broad phoneme classes , it 's for classifying the digits , but as soon as you will have more words , words can differ with only a single phoneme , and which could be the same , class .  ",
Bro004.A,"'m zero . did you fix something ? is it written on her sheet , i believe . but , channel how about over th from the front of the room ? do if it 's trained only on data from just that task , that language ?   what 's th in the three languages is not digits , it 's the broad data .  and remind me , the multilingual is just the broad data . right ? it 's not the digits . it 's the combination of two things there . it 's removing the task specific training and it 's adding other languages .  already , right right . they were building here ?  one point four ? it 's an additional thirty percent . task data . it 's multilingual .  go ahead . while you 're gone i 'll ask s some of my questions .  the what was this number forty or it was roughly the same as this one , he said ? when you had the two language versus the three language ? that 's where he removed english , right ?   i wonder were all three of these nets using the same output ? this multi language labelling ?  this would from this you would say , "" it doesn't really matter if we put finnish into the training of the neural net , if there 's gonna be , finnish in the test data . "" right ?    that would be interesting . did you do different languages from digits ? digits on another language ? the upper part is training ti digits ?  where is the baseline for the ti digits located in here ?    i see . gotcha . multi french , multi spanish can i ask something real quick ? in the upper part in the english it looks like the very best number is sixty point nine ? and that 's in the the third section in the upper part under plp jrasta , the middle column ? i is that a noisy condition ? that 's matched training ? is that what that is ? why do you get your best number in wouldn't you get your best number in the clean case ?   these are not  alright , i see .  and then in the in the non mismatched clean case , your best one was under mfcc ? that sixty one point four ? this upper third ? that 's still noisy ?   i see . where is that ? seventy nine , fifty see , they have one output . they s they say in here that the vad is not used as an additional feature . does anybody know how they 're using it ? but that   it 's i don't understand . it 's throwing out frames ? before   that 's what i was just gonna ask . how can you just throw out frames ?    ",it 's the broad data . ,"There have been four types of test, in which the training data
varies, and a variety of input features have been tried. "
Bro004.A,"in the text they say that this is a tentative block diagram of a possible configuration we could think of . that sounds like they 're not doing that yet .  i 'm just wondering what exactly did they do up in this table if it wasn't this .  plus it 's gonna introduce delays .   when they removed the silence frames , did they insert some marker that the recognizer knows it 's knows when it 's time to back trace right . they 're just inserting some nummy frames    some constant vector .  i w that 's right . but something that what is something that is very distinguishable from speech . that the silence model in htk will always pick it up .   cuz you gotta do something . otherwise , if it 's just a bunch of speech , stuck together  right .  they have a thing for doing that and th they have for awhile , in h t and you can parallelize the training . and run it on several machines and it just keeps counts . and there 's something a final thing that you run and it accumulates all the counts together . i don't what their scripts are set up to do for the aurora but ",,
Bro004.B,"  unprecedented . you think that 's you ?    guess we are gonna do the digits at the end .  that 's the mike number there , mike number five , and channel four . this is you .  and i 'm channel two or channel i 'm channel must be channel one . channel one ? yes ,  also copied the results that we all got in the mail from from ogi and we 'll go through them also . where are we on our runs ? excuse me .   our there 's a we 're pausing for a photo we 're pausing for a photo opportunity here .    he 's facing this way . what ? this would be a good section for our silence detection .  you were saying about the training data  how clearly it 's gonna be good then but the question is how much worse is it if you have broad data ? my assump from what i saw from the earlier results , guess last week , was that if you trained on one language and tested on another , say , that the results were relatively poor . but the question is if you train on one language but you have a broad coverage and then test in another , does that is that improve things i c in comparison ? no , no . different lang if you train on ti digits and test on italian digits , you do poorly , let 's say . i don't have the numbers in front of me , 'm just imagining . e you didn't train on timit and test on italian digits , say ?  w which in it has three languages . that 's including the w the the one that it 's right .  that is what i wanted to know . wasn't saying it very relative . right . ab about how much ? twenty percent further ? yes . and it 's something like one point three of the i if you compare everything to the first case at the baseline , you get something like one point one for the using the same language but a different task , and something like one point three for three languages broad i i 'm i meant something different by baseline let me  fine . let 's use the conventional meaning of baseline . i by baseline here i meant using the task specific data . but because that 's what you were just doing with this ten percent . was just trying to understand that . if we call a factor of w just one , just normalized to one , the word error rate that you have for using ti digits as training and ti digits as test , different words , i 'm but the same task and on . ",where are we on our runs ? that 's including the w the the one that it 's ,"The meeting was dominated by a discussion of the first results coming
in. There have been four types of test, in which the training data
varies, and a variety of input features have been tried. "
Bro004.B,"if we call that "" one "" , then what you 're saying is that the word error rate for the same language but using different training data than you 're testing on , say timit and forth , it 's one point one . right . and if it 's you do go to three languages including the english , it 's something like one point three . that 's what you were just saying ,  and if you exclude english , from this combination , what 's that ? aha ! that 's interesting . that 's interesting . do you see ? because no , that 's important . what it 's saying here is just that "" yes , there is a reduction in performance , when you don't have the s when you don't have minute , th the no , actually it 's interesting . it 's when you go to a different task , there 's actually not different . it 's when you went to these what 's the difference between two and three ? between the one point one case and the one point four case ? i 'm confused . cuz in both of those cases , you don't have the same task . is the training data for the for this one point four case does it include the training data for the one point one case ? how m how much bigger is it ? it 's two times , but it includes the broad english data . and the broad english data is what you got this one point one with . that 's timit right ? it 's band limited timit . this is all eight kilohertz sampling . you have band limited timit , gave you almost as good as a result as using ti digits on a ti digits test .  and but , when you add in more training data but keep the neural net the same size , it performs worse on the ti digits . now all of this is noisy ti digits , i assume ? both training and test ?    we may just need to mean it 's interesting that h going to a different task didn't seem to hurt us that much , and going to a different language it doesn't seem to matter the difference between three and four is not particularly great , that means that whether you have the language in or not is not such a big deal . it sounds like we may need to have more of things that are similar to a target language or you have the same number of parameters in the neural net , you haven't increased the size of the neural net , and there 's just not enough complexity to it to represent the variab increased variability in the training set . that could be . what about ",,
Bro004.B,"these are results with th that you 're describing now , that they are pretty similar for the different features or   i have a suggestion , actually , even though it 'll delay us slightly , would you mind running into the other room and making copies of this ? cuz we 're all if we c if we could look at it , while we 're talking , it 'd be i 'll sing a song or dance while you do it , too .   this way and just slightly to the left ,   that 's what he was saying . right .  but i it sounds like that 's interesting because it seems like what it 's saying is not much that you got hurt because you didn't have much representation of english , because in the other case you don't get hurt any more , at least when it seemed like it might simply be a case that you have something that is just much more diverse , but you have the same number of parameters representing it . it 's it sounds we have to be careful , cuz we haven't gotten a good result yet . and comparing different bad results can be tricky . but it does suggest that it 's not much cross language as cross type of speech . it 's it 's but we did  the other thing i was asking him , though , is that that in the case  you do have to be careful because of com compounded results . we got some earlier results in which you trained on one language and tested on another and you didn't have three , but you just had one language . you trained on one type of digits and tested on another . didn wasn't there something of that ? where you , say , trained on spanish and tested on ti digits , or the other way around ? something like that ? there was something like that , that he showed me last week . we 'll have to till we get this may have been what i was asking before , stephane , but , wasn't there something that you did , where you trained on one language and tested on another ? no mixture but just we 've never just trained on one lang  but we 've done a bunch of things where we just trained on one language . right ? you haven't done all your tests on multiple languages . see , you showed me something like that last week . you had a little what wha what 's the this chart this table that we 're looking at is show is all testing for ti digits , or ?   what was is that i what was it that you had done last week when you showed do you remember ? wh when you showed me the your table last week ? this is word error rate , high number is bad . if we take  ",,
Bro004.B,"let 's see plp with on line normalization and delta del that 's this thing you have circled here in the second column , and "" multi english "" refers to what ? right . i 'm i missed that . what 's mf , ms and me ?  it 's broader vocabulary . then and  think what i 'm what i saw in your smaller chart that i was thinking of was there were some numbers i saw , that included these multiple languages and it and i was seeing that it got worse . that was all it was . you had some very limited results that at that point which showed having in these other languages . it might have been just this last category , having two languages broad that were where english was removed . that was cross language and the result was quite poor . what i we hadn't seen yet was that if you added in the english , it 's still poor . now , what 's the noise condition of the training data this is what you were explaining . the noise condition is the same it 's the same aurora noises in all these cases for the training . there 's not a statistical sta a strong st statistically different noise characteristic between the training and test and yet we 're seeing some effect right . there 's some an effect from having these this broader coverage  now what we should try doing with this is try testing these on u this same thing on you probably must have this lined up to do . to try the same t with the exact same training , do testing on the other languages . on  minute . you have this here , for the italian . that 's right .    let 's see . is there any difference in it 's in the you 're saying that when you train on english and and test on no , you don't have training on english testing in what ? and the noise is different in th do we have any test sets in any other language that have the same noise as in the aurora ?   this will take some looking at , thinking about . but , what is what is currently running , that 's i that just filling in the holes here or ?   it 's just sitting right on the the column line .  yes . yes . do what was wrong with the on line normalization , or ?  yes .   right . right .     right . right . but that given the pressure of time we probably want to draw because of that especially , we wanna draw some conclusions from this , do some reductions in what we 're looking at , and make some strong decisions for what we 're gonna do testing on before next week . ","now , what 's the noise condition of the training data the noise condition is the same there 's not a statistical sta a strong st statistically different noise characteristic between the training and test but that given the pressure of time we probably want to draw because of that especially , we wanna draw some conclusions from this , and make some strong decisions for what we 're gonna do testing on before next week . ","The process
and results were explained to the group, the implications of the
results discussed, and plans for moving forward were made. "
Bro004.B,"do you are you w did you have something going on , on the side , with multi band or on this , or ?   i di it 's a trade off , right ? any anyway go ahead .  you could make the same argument , it 'd be just as legitimate , for hybrid systems as right . and th things get better with context dependent versions . right ?  but it 's still true that what you 're doing is you 're ignoring you 're coming up with something to represent , whether it 's a distribution , probability distribution or features , you 're coming up with a set of variables that are representing things that vary w over context . and you 're putting it all together , ignoring the differences in context . that 's true for the hybrid system , it 's true for a tandem system . for that reason , when you in a hybrid system , when you incorporate context one way or another , you do get better scores .  but i it 's a big deal to get that . i 'm and once you the other thing is that once you represent start representing more and more context it is much more specific to a particular task in language . the acoustics associated with particular context , you may have some kinds of contexts that will never occur in one language and will occur frequently in the other , the qu the issue of getting enough training for a particular context becomes harder . we already actually don't have a huge amount of training data  right . almost . but it does give a distribution . it 's and it is true that if there 's two phones that are very similar , that the i it may prefer one but it will give a reasonably high value to the other , too . no , but it would still be even more of a binary decision . it 'd be even more of one . because then you would say that in that this phone in this context is a one , but the same phone in a slightly different context is a zero . that would be even more distinct of a binary decision . i actually would have thought you 'd wanna go the other way and have fewer classes . the thing i was arguing for before , but again which i don't think we have time to try , is something in which you would modify the code you could train to have several outputs on and use articulatory features cuz then that would go that would be much broader and cover many different situations . but if you go to very fine categories , it 's very binary .  true .   it 's it 's an interesting thought . we could disagree about it at length but the real thing is if you 're interested in it you 'll probably try it ","and once you the other thing is that once you represent start representing more and more context it is much more specific to a particular task in language . you may have some kinds of contexts that will never occur in one language and will occur frequently in the other , the issue of getting enough training for a particular context becomes harder . we already actually don't have a huge amount of training data but it would still be even more of a binary decision . that would be even more distinct of a binary decision . we could disagree about it at length but the real thing is if you 're interested in it you 'll probably try it ",
Bro004.B,"and we 'll see . but what i 'm more concerned with now , as an operational level , is what do we do in four or five days ? and we have to be concerned with are we gonna look at any combinations of things , once the nets get retrained you have this problem out of it . are we going to look at multi band ? are we gonna look at combinations of things ? what questions are we gonna ask , now that , we should probably turn shortly to this o g i note . how are we going to combine with what they 've been focusing on ? we haven't been doing any of the l d a rasta thing . and they , although they don't talk about it in this note , there 's the issue of the mu law business versus the logarithm ,  what i what is going on right now ? what 's right you 've got nets retraining , are there is there are there any h t k trainings testings going on ? the combination , i see . msg and plp . and is this with the revised on line normalization ? old one . it 's using all the nets for that but again we have the hope that it it 's not making too much difference , but   what you do just wanna understand you have two net or three nets ? was this ? how many nets do you have ? no nets . right . but i didn't understand the software currently just has allows for the one hot output . you 're having multiple nets and combining them , or ? how are you coming up with if you say if you have a place characteristic and a manner characteristic , how do you it 's just one net . i see . i see , you 're going the other way of what you were saying a bit ago instead of   but you think if you include that plus the other features , again then we have these broad classes and somewhat broad . it 's twenty seven instead of sixty four , and you have the original features . which are plp , and then just to remind me , all of that goes into that all of that is transformed by k kl or ? right . no ,  i see . there 's a question of whether you would right . whether you would transform together or just one .  might wanna try it both ways . but that 's interesting . that 's something that you 're you haven't trained yet but are preparing to train , and   think hynek will be here monday . monday or tuesday .  think , we need to choose the experiments carefully , we can get key questions answered before then and leave other ones aside even if it leaves incomplete tables someplace , it 's really time to choose . ","and we 'll see . are there is there are there any h t k trainings testings going on ? but you think if you include that plus the other features , and then just to remind me , all of that goes into that all of that is transformed by k kl or ? there 's a question of whether you would whether you would transform together or just one . might wanna try it both ways . think hynek will be here monday . think , we need to choose the experiments carefully , we can get key questions answered before then ",
Bro004.B,"let me pass this out , these are did i interrupt you ? were there other things that you wanted to we have lots of them . something i asked they 're doing the vad they mean voice activity detection again , it 's the silence they 've just trained up a net which has two outputs , i believe . asked hynek whether i haven't talked to sunil i asked hynek whether they compared that to just taking the nets we already had and summing up the probabilities . to get the speech voice activity detection , or else just using the silence , if there 's only one silence output . and , he didn't think they had , but on the other hand , they can get by with a smaller net and sometimes you don't run the other , there 's a computational advantage to having a separate net , anyway . their the results look pretty good . not uniformly . there 's a an example or two that you can find , where it made it slightly worse , but in all but a couple examples .  i 'm i don't understand your question . it 's on training . no . yes . yes , i don't know . that 's that 's a very good question , then now that it i understand it . it 's  where does the lda come from ? "" in the in earlier experiments , they had taken lda from a completely different database , right ? that 's a good question . where does it come from ? i don't know . but to tell you the truth , i wasn't actually looking at the lda much when i was looking at it i was mostly thinking about the vad . and it ap it ap what does asp ? that 's it says "" baseline asp "" . anybody know any cuz there 's "" baseline aurora "" above it . and it 's this is mostly better than baseline , although in some cases it 's a little worse , in a couple cases . it says what it is . but i don't how that 's different from this was this is the same point we were at when we were up in oregon .  shouldn't it be what they 're doing here is , i if you look down at the block diagram , they estimate they get a they get an estimate of whether it 's speech or silence , and then they have a median filter of it . and they 're trying to find stretches . the median filter is enforcing a i it having some continuity . you find stretches where the combination of the frame wise vad and the median filter say that there 's a stretch of silence . and then it 's going through and just throwing the data away . right ?  it 's throwing out chunks of frames , ","they 're doing the vad they mean voice activity detection again , it 's the silence their the results look pretty good . ","There was also discussion of some of the work being conducted by
research partners OGI, including how the two groups should best work
together. "
Bro004.B,"there 's the median filter is enforcing that it 's not gonna be single cases of frames , or isolated frames . it 's throwing out frames and what i don't understand is how they 're doing this with h t this is  you can , right ? you it stretches again . for single frames it would be pretty hard . but if you say speech starts here , speech ends there . right ?  mean in the i in the decoding , you 're saying that we 're gonna decode from here to here . they 're they 're treating it , like it 's not isolated word , but connected , the no they have numbers though , right ? think they 're doing something like that . that they 're what by tha that is they 're trying to come up with a block diagram that 's plausible for the standard . in other words , it 's from the point of view of reducing the number of bits you have to transmit it 's not a bad idea to detect silence anyway .  but it 's it 's that 's that 's i certainly it would be tricky about it intrans in transmitting voice , for listening to , is that these kinds of things cut speech off a lot . right ? and it does introduce delays but they 're claiming that it 's within the boundaries of it . and the lda introduces delays , and b what he 's suggesting this here is a parallel path that it doesn't introduce any more delay . i it introduces two hundred milliseconds of delay but at the same time the lda down here i don't know wh what 's the difference between tlda and slda ?  you would know that . the temporal lda does include the same that he by saying this is a b a tentative block di diagram means if you construct it this way , this delay would work in that way and then it 'd be they clearly did actually remove silent sections in order because they got these word error rate results . think that it 's to do that in this because it 's gonna give a better word error result and therefore will help within an evaluation . whereas to whether this would actually be in a final standard , i don't know . as part of the problem with evaluation right now is that the word models are pretty bad and nobody wants has approached improving them . it 's possible that a lot of the problems with many insertions and forth would go away if they were better word models to begin with . this might just be a temporary thing . but , on the other hand , and it 's a decent idea . the question we 're gonna wanna go through next week when hynek shows up is given that we 've been if you look at what we 've been trying , ",think that it 's to do that in this because it 's gonna give a better word error result and therefore will help within an evaluation . as part of the problem with evaluation right now is that the word models are pretty bad and nobody wants has approached improving them . the question we 're gonna wanna go through next week when hynek shows up is given that we 've been ,"There was also discussion of some of the work being conducted by
research partners OGI, including how the two groups should best work
together. "
Bro004.B,"we 're looking at by then combinations of features and multi band and we 've been looking at cross language , cross task issues . and they 've been not much looking at the cross task multiple language issues . but they 've been looking at at these issues . at the on line normalization and the voice activity detection . and when he comes here we 're gonna have to start deciding about what do we choose from what we 've looked at to blend with some group of things in what they 've looked at and once we choose that , how do we split up the effort ? because we still have even once we choose , we 've still got another month or there 's holidays in the way , but think the evaluation data comes january thirty first there 's still a fair amount of time to do things together it 's just that they probably should be somewhat more coherent between the two sites in that amount of time . see they , they 're i don't know the specifics of how they 're doing it . they 're getting around the way the recognizer works because they 're not allowed to change the scripts for the recognizer , i believe .  that 's what i had thought . but i don't think they are . that 's what the way i had imagined would happen is that on the other side ,  you p put some low level noise probably don't want all zeros . most recognizers don't like zeros but put some epsilon in or some rand  epsilon random variable in not a constant but it doesn't , don't like to divide by the variance of that , but it 's   that 's what they would do . or else , there is some indicator to tell it to start and stop , i don't know . but whatever they did , they have to play within the rules of this specific evaluation . we c we can find out . no they 're it would do badly and it didn't badly , right ? they did something .   think this brings me up to date a bit . it hopefully brings other people up to date a bit . and wanna look at these numbers off line a little bit and think about it and talk with everybody outside of this meeting . but no it sounds like there are the usual number of little problems and bugs and forth but it sounds like they 're getting ironed out . and now we 're seem to be in a position to actually look at and compare things . think that 's pretty good . don't the one of the things i wonder about , coming back to the first results you talked about , is how much , things could be helped by more parameters . ","we 're looking at by then combinations of features and multi band and we 've been looking at cross language , cross task issues . but they 've been looking at at these issues . at the on line normalization and the voice activity detection . and when he comes here we 're gonna have to start deciding about what do we choose from what we 've looked at to blend with some group of things in what they 've looked at and once we choose that , how do we split up the effort ? ","There was also discussion of some of the work being conducted by
research partners OGI, including how the two groups should best work
together. "
Bro004.B,"and how many more parameters we can afford to have , in terms of the computational limits . because anyway when we go to twice as much data and have the same number of parameters , particularly when it 's twice as much data and it 's quite diverse , i wonder if having twice as many parameters would help . just have a bigger hidden layer . but i doubt it would help by forty per cent . but just curious . how are we doing on the resources ? disk , and  computation ? we   are were you folks using gin ? that 's a that just died ,  no ? that 's good .  we 're gonna get a replacement server that 'll be a faster server , actually . that 'll be it 's a seven hundred fifty megahertz sun but it won't be installed for a little while . u go ahead . we have the little tiny ibm machine that might someday grow up to be a big ibm machine . it 's got s slots for eight , ibm was donating five , we only got two far , processors . we had originally hoped we were getting eight hundred megahertz processors . they ended up being five fifty . instead of having eight processors that were eight hundred megahertz , we ended up with two that are five hundred and fifty megahertz . and more are supposed to come soon and there 's only a moderate amount of dat of memory . don't think anybody has been sufficiently excited by it to spend much time with it , but hopefully , they 'll get us some more parts , soon and that 'll be once we get it populated , that 'll be a machine . we will ultimately get eight processors in there . and amount of memory . it 'll be a pr pretty fast linux machine .   you can check with dave johnson . it 's the machine is just sitting there . and it does have two processors ,  and somebody could do check out the multi threading libraries . and it 's possible that the the prudent thing to do would be for somebody to do the work on getting our code running on that machine with two processors even though there aren't five or eight . there 's there 's gonna be debugging hassles and then we 'd be set for when we did have five or eight , to have it really be useful . but . notice how i said somebody and turned my head your direction . that 's one thing you don't get in these recordings . you don't get the visuals but yes . isn't that right ? you 're held up by both , right ? if the neural net trainings were a hundred times faster you still wouldn't be anything running through these a hundred times faster because you 'd be stuck by the htk trainings , right ? ","we have the little tiny ibm machine that might someday grow up to be a big ibm machine . it 's got s slots for eight , we only got two far , you can check with dave johnson . and somebody could do check out the multi threading libraries . the prudent thing to do would be for somebody to do the work on getting our code running on that machine with two processors even though there aren't five or eight . there 's there 's gonna be debugging hassles and then we 'd be set for when we did have five or eight , to have it really be useful . but . notice how i said somebody and turned my head your direction . that 's one thing you don't get in these recordings . ",The group also briefly touched upon resource issues. 
Bro004.B,"but if the htk they 're both it sounded like they were roughly equal ? is that about right ?  probably the neural net cuz it 's probably it 's i don't know . they both htk we use for this aurora it 's not clear yet what we 're gonna use for trainings  there 's the trainings is it the training that takes the time , or the decoding ? is it about equal between the two ? for aurora ? for for the aurora ?   i don't know how we can i don't know how to do we have htk source ? is that  you would think that would fairly trivially the training would , anyway , th the testing don't think would parallelize all that but that you could certainly do d distributed , no , it 's the each individual sentence is pretty tricky to parallelize . but you could split up the sentences in a test set .  aha ! i see . something that we haven't really settled on yet is other than this aurora what do we do , large vocabulary training slash testing for tandem systems . cuz we hadn't really done much with tandem systems for larger cuz we had this one collaboration with cmu and we used sphinx . we 're also gonna be collaborating with sri and we have their have theirs . don't know think the advantage of going with the neural net thing is that we 're gonna use the neural net trainings , no matter what , for a lot of the things we 're doing , whereas , w exactly which gaussian mixture based thing we use is gonna depend with that , we should go to our digit recitation task . and , it 's about eleven fifty . canned . start over here . great , could you give adam a call . tell him to he 's at two nine seven .  we can @ @ herve 's coming tomorrow , right ? herve will be giving a talk , talk at eleven . did did everybody sign these consent er everybody has everyone signed a consent form before , on previous meetings ? you don't have to do it again each time yes . microphones off ",probably the neural net ,
Bro004.C,"i don't hello , hello , hello . hello . hello , hello . aaa aaa .  that 's me . channel two . two . ooo . 'm channel two . chicken on the grill . try that corner . it 's longer . get out of the   these numbers are ratio to baseline ? ratio . it 's relative to the baseline mismatching   asp .  there it is .  it says baseline asp is twenty three mill minus thirteen . from the baseline .   temporal and spectral .  tonic . ",,
Bro004.D,"channel three ,   mike four . we as i was already said , we mainly focused on four features . the plp , the plp with jrasta , the msg , and the mfcc from the baseline aurora . and we focused for the test part on the english and the italian . we 've trained several neural networks on on the ti digits english and on the italian data and also on the broad english french and spanish databases . there 's our result tables here , for the tandem approach , and actually what we @ @ observed is that if the network is trained on the task data it works pretty  if the network is trained on the task data tandem works pretty and actually we have results are similar only on ,  just that task . but actually we didn't train network on both types of data phonetically ba phonetically balanced data and task data . we only did either task data or broad data .    if we use the same language ?  but but i did not do that . we no , we did four testing , actually . the first testing is with task data with nets trained on task data . for italian on the italian speech @ @ . the second test is trained on a single language with broad database , but the same language as the t task data . but for italian we choose spanish which we assume is close to italian . the third test is by using , the three language database and the fourth is this includes  but not digits . it 's  and the fourth test is excluding from these three languages the language that is the task language .   for ti digits for ins example when we go from ti digits training to timit training we lose around ten percent , the error rate increase u of ten percent , relative . this is not bad . and then when we jump to the multilingual data it 's it become worse and , around let 's say , twenty perc twenty percent further .   twenty to thirty percent further .    but the first step is al already removing the task s specific from  and we lose  when it 's trained on the multilingual broad data or number  the ratio of our error rates with the baseline error rate is around one point one .  no no . same language we are at for at english at o point eight . it improves , compared to the baseline . but  le let me . tas task data we are u    the f        it 's around one point one .  ye more actually . if i what would you say ? around one point four  if we exclude english , there is not much difference with the data with english .     the only difference it 's is that it 's multilingual     a part of it ,  it 's two times , actually ?  ","we as i was already said , we mainly focused on four features . the plp , the plp with jrasta , the msg , and the mfcc from the baseline aurora . and we focused for the test part on the english and the italian . we 've trained several neural networks on on the ti digits english and on the italian data and also on the broad english french and spanish databases . and actually what we @ @ observed is that if the network is trained on the task data it works pretty but actually we didn't train network on both types of data we only did either task data or broad data . the first testing is with task data the second test is trained on a single language with broad database , but the same language as the t task data . but for italian we choose spanish which we assume is close to italian . the third test is by using , the three language database  and the fourth test is excluding from these three languages the language that is the task language . example when we go from ti digits training to timit training we lose around ten percent , the error rate increase u of ten percent , relative . and then when we jump to the multilingual data it 's it become worse twenty to thirty percent further . ","The meeting was dominated by a discussion of the first results coming
in. The process
and results were explained to the group, the implications of the
results discussed, and plans for moving forward were made. There have been four types of test, in which the training data
varies, and a variety of input features have been tried. "
Bro004.D,"the english data no , the multilingual databases are two times the broad english data . we just wanted to keep this , w not too huge .   do you       let me check .  this was for the plp , the  for the plp with jrasta the we this is quite the same tendency , with a slight increase of the error rate , if we go to timit . and then it 's it gets worse with the multilingual .  there is a difference actually with b between plp and jrasta is that jrasta seems to perform better with the highly mismatched condition but slightly worse for the matched condition .    no . training on a single language , and testing on the other one ? no . the only task that 's similar to this is the training on two languages , and that no . either thi this is test with the same language but from the broad data , or it 's test with different languages also from the broad data , excluding the it 's three or three and four . no . training digits on one language and using the net to recognize on the other ? no . no , i don't think  you have two parts . the upper part is for ti digits and it 's divided in three rows of four rows each . and the first four rows is matched , then the s the second group of four rows is mismatched , and finally highly mismatched . and then the lower part is for italian and it 's the same thing . it 's the htk results , it 's htk training testings with different features and what appears in the left column is the networks that are used for doing this .  it was part of these results .   the htk aurora baseline ? it 's the one hundred number . it 's , all these numbers are the ratio with respect to the baseline . this is a word error rate ratio .  seventy point two means that we reduced the error rate by thirty percent .    to timit .  then you have mf , ms and me which are for french , spanish and english . and ,  actually i forgot to say that the multilingual net are trained on features without the s derivatives but with increased frame numbers .  and we can see on the first line of the table that it 's slightly worse when we don't use delta but it 's not that much . multi french , multi spanish , and multi english .    still poor .  no these are the s same noises ,  at least for the first for the matched ,    for the italian the results are stranger  what appears is that perhaps spanish is not very close to italian because when using the network trained only on spanish it 's the error rate is almost twice the baseline error rate .   ","this was for the plp , for the plp with jrasta the we this is quite the same tendency , with a slight increase of the error rate , if we go to timit . and then it 's it gets worse with the multilingual . there is a difference actually with b between plp and jrasta is that jrasta seems to perform better with the highly mismatched condition but slightly worse for the matched condition . no these are the s same noises , at least for the first for the matched , for the italian the results are stranger what appears is that perhaps spanish is not very close to italian because when using the network trained only on spanish it 's the error rate is almost twice the baseline error rate . ",
Bro004.D,"there is another difference , is that the noise the noises are different . for the italian part the the networks are trained with noise from aurora ti digits ,   and perhaps the noise are quite different from the noises in the speech that italian . and no .   it 's no , the third part , it 's highly mismatched . training and test noise are different .   but it 's not a clean case . it 's a noisy case but training and test noises are the same .   it 's always noisy and , the  no we don't plan to fill the holes but actually there is something important , is that we made a lot of assumption concerning the on line normalization and we just noticed recently that the approach that we were using was not leading to very good results when we used the straight features to htk .  if you look at the left of the table , the first row , with eighty six , one hundred , and forty three and seventy five , these are the results we obtained for italian with straight plp features using on line normalization . and the , what 's in the table , just at the left of the plp twelve on line normalization column , the numbers seventy nine , fifty four and forty two are the results obtained by pratibha with his on line normalization her on line normalization approach .  just  these are the results of ogi with on line normalization and straight features to htk . and the previous result , eighty six and on , are with our features straight to htk . what we see that is there is that the way we were doing this was not correct , but still the networks are very good . when we use the networks our number are better that pratibha results .  there were diff there were different things and the first thing is the alpha value . the recursion part . i used point five percent , which was the default value in the programs here . and pratibha used five percent . it adapts more quickly but ,  i assume that this was not important because previous results from dan and show that the both values g give the same results . it was true on ti digits but it 's not true on italian . second thing is the initialization of the actually , what we were doing is to start the recursion from the beginning of the utterance . and using initial values that are the global mean and variances measured across the whole database . and pratibha did something different is that he she initialed the values of the mean and variance by computing this on the twenty five first frames of each utterance . there were other minor differences , the fact that she used fifteen dissities instead s instead of thirteen , and that she used c zero instead of log energy . ","there is another difference , is that the noise the noises are different . for the italian part the the networks are trained with noise from aurora ti digits , and perhaps the noise are quite different from the noises in the speech that italian . but actually there is something important , is that we made a lot of assumption concerning the on line normalization and we just noticed recently that the approach that we were using was not leading to very good results when we used the straight features to htk . what we see that is there is that the way we were doing this was not correct , when we use the networks our number are better that pratibha results . and the first thing is the alpha value . i used point five percent , which was the default value in the programs here . and pratibha used five percent . i assume that this was not important because previous results from dan and show that the both values g give the same results . it was true on ti digits but it 's not true on italian . second thing is the initialization of the actually , what we were doing is to start the recursion from the beginning of the utterance . and using initial values that are the global mean and variances measured across the whole database . and pratibha did something different is that he she initialed the values of the mean and variance by computing this on the twenty five first frames of each utterance . there were other minor differences , ",
Bro004.D,"but the main differences concerns the recursion . i changed the code and now we have a baseline that 's similar to the ogi baseline . we it 's slightly different because i don't exactly initialize the same way she does . actually i start , i don't to a fifteen twenty five frames before computing a mean and the variance to e to start the recursion . i use the on line scheme and only start the re recursion after the twenty five twenty fifth frame . but , it 's similar . retrained the networks with these the networks are retaining with these new features . and ,  what i expect is that these numbers will a little bit go down but perhaps not much because the neural networks learn perhaps to even if the features are not normalized . it will learn how to normalize and   no , i we plan to start this act actually we have discussed @ these what we could do more as a research and we were thinking perhaps that the way we use the tandem is not there is perhaps a flaw in the because we trained the networks if we trained the networks on the on a language and a t or a specific task , what we ask is to the network is to put the bound the decision boundaries somewhere in the space . and and ask the network to put one , at one side of the for a particular phoneme at one side of the boundary decision boundary and one for another phoneme at the other side . and there is reduction of the information there that 's not correct because if we change task and if the phonemes are not in the same context in the new task , the decision boundaries are not should not be at the same place . but the way the feature gives the way the network gives the features is that it reduce completely the it removes completely the information a lot of information from the features by placing the decision boundaries at optimal places for one data but this is not the case for another data .   what we were thinking about is perhaps one way to solve this problem is increase the number of outputs of the neural networks . doing something like , phonemes within context and , context dependent phonemes . but , we know that ye but here it 's something different . we want to have features    but the the way we do it now is that we have a neural network and the net network is trained almost to give binary decisions . and binary decisions about phonemes . nnn it 's    but it 's almost binary decisions and the idea of using more classes is to get something that 's less binary decisions . but but but if    but perhaps you 're right , but you have more classes you have more information in your features . you have more information in the ","i changed the code and now we have a baseline that 's similar to the ogi baseline . the networks are retaining with these new features . act actually we have discussed @ these and we were thinking perhaps that the way we use the tandem is not if we trained the networks on the on a language and a t or a specific task , what we ask is to the network is to put the bound the decision boundaries somewhere in the space . and and ask the network to put one , at one side of the for a particular phoneme at one side of the boundary decision boundary and there is reduction of the information there that 's not correct because if we change task and if the phonemes are not in the same context in the new task , the decision boundaries are not should not be at the same place . but the way the feature gives the way the network gives the features is that it reduce completely the it removes completely the information a lot of information from the features by placing the decision boundaries at optimal places for one data what we were thinking about is perhaps one way to solve this problem is increase the number of outputs of the neural networks . context dependent phonemes . the way we do it now is that we have a neural network and the net network is trained almost to give binary decisions . ",
Bro004.D,"posteriors vector  which means that but still the information is relevant because it 's information that helps to discriminate , if it 's possible to be able to discriminate among the phonemes in context . but the       n   there is this combination ,  working on combination i will start work on multi band . and we plan to work also on the idea of using both features and net outputs . and we think that with this approach perhaps we could reduce the number of outputs of the neural network . get simpler networks , because we still have the features . we have come up with different broad phonetic categories . and we have we have three types of broad phonetic classes . something using place of articulation which leads to nine , broad classes . another which is based on manner , which is also something like nine classes . and then , something that combine both , and we have twenty f twenty five ? twenty seven broad classes . like , i don't know , like back vowels , front vowels . for the moments we do not don't have nets , it 's just were we just changing the labels to retrain nets with fewer out outputs . and then  it 's the single net ,  it 's one net with twenty seven outputs if we have twenty seven classes ,  it 's it 's standard net with fewer classes .  but  b including the features , i don't think this will work alone . it will get worse because i believe the effect that of too reducing too much the information is what happens and but  because there is perhaps one important thing that the net brings , and ogi show showed that , is the distinction between sp speech and silence because these nets are trained on controlled condition . the labels are obtained on clean speech , and we add noise after . this is one thing and but perhaps , something intermediary using also some broad classes could bring much more information .     there will probably be ,  one single kl to transform everything or per this is still something that  we don't know       no . i don't think i have one .       the features ,   i don't know . it 's the c zero using c zero instead of log energy . it 's this . it should be that ,  because  i   you can remove the frames from the feature files . i t   we 're alright , not much problems with that . it 's this table took more than five days to get back . but  no . you were using gin perhaps ,  no .     for htk ? training is longer .     ",and we plan to work also on the idea of using both features and net outputs . we have come up with different broad phonetic categories . and we have we have three types of broad phonetic classes . twenty seven broad classes . it 's it 's standard net with fewer classes . because i believe the effect that of too reducing too much the information is what happens one single kl to transform everything ,
Bro004.E," five , five . channel five ? doesn't work ? no ? era el cuatro .    i saw that . it 's channel i decided to talk about that . no . not yet . the early experiment that  aurora two . no . fifty one ? this we improve . i i 'm trying the htk with plp twelve on line delta and msg filter together . the combination , but i haven't result at this moment .  ye with the old older ,   but we can know soon .  i don't know .  begin to work in this . we are @ @ .   mu . no transform the plp and only transform the other i 'm not two e @ @ it 's one . i have one . we have one . but they have a question of the result . how are trained the lda filter ? how obtained the lda filter ? yes , the lda filter needs some training set to obtain the filter .  i don't know exactly how they are obtained . training , with the training test of each you understand me ?  lda filter need a set of training to obtain the filter . and for the italian , for the td te on for finnish , these filter are obtained with their own training set .  because it the same situation that the neural network training with their own set . i don't understand also what is what is the difference between asp and baseline over ? this is     temporal lda . no . yes . ","i i 'm trying the htk with plp twelve on line delta and msg filter together . the combination , but i haven't result at this moment . ",
Bro004.F,"wh what causes the crash ? it 's the turning off and turning on of the mike , right ? mine 's working . watch this . that 's me .  hold on . hold on . let me give you a black screen .  musical chairs everybody ! a fraction of it .    downs right . alright .  it sometimes , actually , depends on what features you 're using . but he he was using sixty four phonemes from sampa .  i 'll get it for you . bigger is worse . this is error rate , no . no .   matched condition . twenty seven .  but including the features . it just died .  ",but including the features . ,
Bro004.G," do we have that big new ibm machine the , in th and if we can do things on linux , some of the machines we have going already , like swede ? it seems pretty fast . but fudge is pretty fast too . i is it mostly the neural network trainings that are slowing us down or the htk runs that are slowing us down ? because , think that 'll be running linux , and sw swede and fudge are already running linux could try to get the train the neural network trainings or the htk running under linux , and to start with i 'm wondering which one i should pick first .  ","could try to get the train the neural network trainings or the htk running under linux , and to start with i 'm wondering which one i should pick first . ",
Bro005.A,"mike . mike one ?    i 'm for the table , but as it grows in size , it .    next time we will put colors  s there is summary of what has been done it 's this . summary of experiments since , since last week and also since the we 've started to run work on this . since last week we 've started to fill the column with features w with nets trained on plp with on line normalization but with delta also , because the column was not completely it 's still not completely filled , but we have more results to compare with network using without plp and finally , hhh , ehhh pl delta seems very important . don't know . if you take let 's say , anyway aurora two b , the next t the second , part of the table , when we use the large training set using french , spanish , and english , you have one hundred and six without delta and eighty nine with the delta .  on the baseline ,   now we see that the gap between the different training set is much much smaller  but , actually , for english training on timit is still better than the other languages . and  and f also for italian , actually . if you take the second set of experiment for italian , the mismatched condition , when we use the training on timit it 's multi english , we have a ninety one number , and training with other languages is a little bit worse .   and , and here the gap is still more important between using delta and not using delta . if y if i take the training s the large training set , it 's we have one hundred and seventy two , and one hundred and four when we use delta . even if the contexts used is quite the same , because without delta we use seventeenths seventeen frames .  the second point is that we have no single cross language experiments , that we did not have last week . this is training the net on french only , or on english only , and testing on italian . and training the net on french only and spanish only and testing on , ti digits . and , fff  what we see is that these nets are not as good , except for the multi english , which is always one of the best .  then we started to work on a large dat database containing , sentences from the french , from the spanish , from the timit , from spine , from english digits , and from italian digits . this is the another line another set of lines in the table . @ @ with spine and actually we did this before knowing the result of all the data , we have to redo the the experiment training the net with , plp , but with delta . ","i 'm for the table , but as it grows in size , it . s there is summary of what has been done summary of experiments since , since last week and also since the we 've started to run work on this . since last week we 've started to fill the column with features w with nets trained on plp with on line normalization but with delta also , but we have more results to compare with network using without plp and finally , hhh , ehhh pl delta seems very important . when we use the large training set using french , spanish , and english , you have one hundred and six without delta and eighty nine with the delta .  but , actually , for english training on timit is still better than the other languages . it 's multi english , we have a ninety one number , and training with other languages is a little bit worse . and , and here the gap is still more important between using delta and not using delta . if y if i take the training s the large training set , it 's we have one hundred and seventy two , and one hundred and four when we use delta . even if the contexts used is quite the same , except for the multi english , which is always one of the best . then we started to work on a large dat database containing , sentences from the french , from the spanish , from the timit , from spine , from english digits , and from italian digits . and actually we did this before knowing the result of all the data , we have to redo the the experiment training the net with , plp , but with delta . ","This included reporting the results, and making conclusions to shape future work. The main topic for discussion by the Berkeley Meeting Recorder group was progress on the experiments run as part of the groups main project, a speech recogniser for the cellular industry. "
Bro005.A,"but this net performed quite  it 's better than the net using french , spanish , and english only .    we have also started feature combination experiments . many experiments using features and net outputs together . and this is the results are on the other document . we can discuss this after , perhaps just , @ @ . there are four systems . the first one , is combining , two feature streams , using and each feature stream has its own mpl . it 's the similar to the tandem that was proposed for the first . the multi stream tandem for the first proposal . the second is using features and klt transformed mlp outputs . and the third one is to u use a single klt trans transform features as as mlp outputs .    you can comment these results , we ju just to be clear , the numbers here are recognition accuracy . it 's not the again we switch to another it 's experiment only on the italian mismatched for the moment for this .   actually , if w we look at the table , the huge table , we see that for ti digits msg perform as as the plp , but this is not the case for italian what where the error rate is c is almost twice the error rate of plp . i don't think this is a bug but this is something in probably in the msg process that  i don't exactly . perhaps the fact that the there 's no low pass filter ,  or no pre emp pre emphasis filter and that there is some dc offset in the italian , or , something simple like that . but that we need to sort out if want to get improvement by combining plp and msg because for the moment msg do doesn't bring much information . and as carmen said , if we combine the two , we have the result , of plp .   this is this is in the table . the number is fifty two ,  fift no , it 's the of eighteen of eighteen . it 's error rate , it 's er error rate ratio .  we have nine let 's say ninety percent .  which is what we have also if use plp and msg together , eighty nine point seven .  p plp and mel cepstra give the same results . we have these results . i don't know . it 's not do you have this result with plp alone , j fee feeding htk ? that 's what just plp at the input of htk .  plp   that 's without the neural net and that 's the result that ogi has also with the mfcc with on line normalization . this is the w but this is without on line normalization .  eighty two is the it 's the aurora baseline , mfcc . then we can use ","we have also started feature combination experiments . many experiments using features and net outputs together . and this is the results are on the other document . it 's the similar to the tandem that was proposed for the first . the multi stream tandem for the first proposal . the second is using features and klt transformed mlp outputs . and the third one is to u use a single klt trans transform features as as mlp outputs . we ju just to be clear , the numbers here are recognition accuracy . actually , if w we look at the table , the huge table , we see that for ti digits msg perform as as the plp , but this is not the case for italian what where the error rate is c is almost twice the error rate of plp . i don't exactly . perhaps the fact that the there 's no low pass filter , or no pre emp pre emphasis filter and that there is some dc offset in the italian , but that we need to sort out if want to get improvement by combining plp and msg because for the moment msg do doesn't bring much information . this is this is in the table . the number is fifty two , fift no , it 's the of eighteen of eighteen . it 's error rate , it 's er error rate ratio . we have nine let 's say ninety percent . ",
Bro005.A,"ogi , they use mfcc th the baseline mfcc plus on line normalization     what happ what happens is that when we apply on line normalization we jump to almost ninety percent . when we apply a neural network , is the same . we j jump to ninety percent . and whatever the normalization , actually . if we use n neural network , even if the features are not correctly normalized , we jump to ninety percent .  ninety no , ninety it 's around eighty nine , ninety , eighty eight . there are minor differences . no . for italian ,   but w    no .     that 's it 's a part it 's or , one million frames . it 's one million and a half .    it 's   actually , just to be some more do this number , this eighty seven point one number , has to be compared with the which number ?  but in this case for the eighty seven point one we used mlp outputs for the plp net and straight features with delta . and straight features with delta gives you what 's on the first sheet . it 's eight eighty eight point six . but th this is the second configuration . we use feature out net outputs together with features .  this is not perhaps not clear here but in this table , the first column is for mlp and the second for the features . just  actually it decreased the accuracy . because we have eighty eight point six . and even the mlp alone what gives the mlp alone ? multi english plp . no , it gives eighty three point six . we have our eighty three point six and now eighty point six , that gives eighty seven point one . eighty three point six . eighty is th is that right ?  perhaps ,     on ti digits ?  no , not yet .   it 's slightly better ,     perhaps let 's jump at the last experiment . it 's either less information from the neural network if we use only the silence output . it 's again better . it 's eighty nine point one .       scale  but is it i th the htk models are diagonal covariances , d is it         and test across everything .   the next point ,  we 've had some discussion with steve and shawn , about their articulatory  we 'll perhaps start something next week . discussion with hynek , sunil and pratibha for trying to plug in their our networks with their within their block diagram , where to plug in the network , after the feature , before as as a plugin or as a anoth another path , discussion about multi band and traps ,  actually hynek would like to see , perhaps if you remember the block diagram there is , temporal lda followed b by a spectral lda for each critical band . and he would like to replace these by a network "," no .  and test across everything . discussion with hynek , sunil and pratibha for trying to plug in their our networks with their within their block diagram , where to plug in the network , after the feature , before as as a plugin or as a anoth another path , actually hynek would like to see , perhaps if you remember the block diagram there is , temporal lda followed b by a spectral lda for each critical band . and he would like to replace these by a network ","This included reporting the results, and making conclusions to shape future work. Also discussed were the details of the continued collaboration with project partner OGI. "
Bro005.A,"which would , make the system look like a trap . it would be a trap system . this is a trap system trap system , but where the neural network are replaced by lda .  and about multi band , i started multi band mlp trainings ,  mmh actually , i w hhh prefer to do exactly what i did when i was in belgium . take exactly the same configurations , seven bands with nine frames of context , and we just train on timit , and on the large database , with spine and everything . and , i 'm starting to train also , networks with larger contexts . this would be something between traps and multi band because we still have quite large bands , and but with a lot of context also .   we still have to work on finnish , to make a decision on which mlp can be the best across the different languages . for the moment it 's the timit network , and perhaps the network trained on everything . now we can test these two networks on with delta and large networks . test them also on finnish and see which one is the best . the next part of the document is , a summary of what everything that has been done . we have seventy nine m l ps trained on one , two , three , four , three , four , five , six , seven ten on ten different databases .  the number of frames is bad also , we have one million and a half for some , three million for other , and six million for the last one .  as we mentioned , timit is the only that 's hand labeled , and perhaps this is what makes the difference .  the other are just viterbi aligned . these seventy nine mlp differ on different things . first , with respect to the on line normalization , there are that use bad on line normalization , and other good on line normalization .  with respect to the features , with respect to the use of delta or no , with respect to the hidden layer size and to the targets . but we don't have all the combination of these different parameters  s what 's this ? we only have two hundred eighty six different tests and no not two thousand .   the observation is what we discussed already . the msg problem ,  the fact that the mlp trained on target task decreased the error rate . but when the m mlp is trained on the is not trained on the target task , it increased the error rate compared to using straight features . except if the features are bad actually except if the features are not correctly on line normalized . in this case the tandem is still better even if it 's trained on not on the target digits .   ","which would , make the system look like a trap . i started multi band mlp trainings , take exactly the same configurations , seven bands with nine frames of context , and we just train on timit , and on the large database , with spine and everything . i 'm starting to train also , networks with larger contexts . this would be something between traps and multi band because we still have quite large bands , and but with a lot of context also . we still have to work on finnish , to make a decision on which mlp can be the best across the different languages . for the moment it 's the timit network , and perhaps the network trained on everything . the next part of the document is , a summary of what everything that has been done . we have seventy nine m l ps trained on ten on ten different databases . as we mentioned , timit is the only that 's hand labeled , and perhaps this is what makes the difference . the other are just viterbi aligned . the observation is what we discussed already . the msg problem , the fact that the mlp trained on target task decreased the error rate . but when the m mlp is trained on the is not trained on the target task , it increased the error rate compared to using straight features . ","Also discussed were the details of the continued collaboration with project partner OGI. This included reporting the results, and making conclusions to shape future work. "
Bro005.A,"the fourth point is , the timit plus noise seems to be the training set that gives better the best network .      i don't know but i 've perhaps i have the feeling that it 's something that 's quite simple or just like nnn , no high pass filter or my but i don't know . it 's there is , an agc agc .     but  but this was the bad on line normalization . actually . are your results are still with the bad with the o oln two ? you have oln two ,  it 's , is the good and   but   i see ,  and       the reason the reason is that the perhaps the target the task dependency the language dependency , and the noise dependency the e but this is still not clear because ,  i don't think we have enough result to talk about the language dependency . the timit network is still the best but there is also an the other difference , the fact that it 's hand labeled . we still have this one of these perhaps ?  that the fact that s for ti digits the timit net is the best , which is the english net . but the other are slightly worse . but you have two effects , the effect of changing language and the effect of training on something that 's viterbi aligned instead of hand labeled .    i don't know . did you look at the spanish alignments carmen ?  but but , perhaps it 's not really the alignment that 's bad but the just the ph phoneme string that 's used for the alignment  for we it 's single pronunciation ,  french s phoneme strings were corrected manually we asked people to listen to the the sentence and we gave the phoneme string and they correct them . but still , there might be errors just in the ph string of phonemes .   this is not really the viterbi alignment ,   the third issue is the noise dependency perhaps but , this is not clear yet because all our nets are trained on the same noises and    but  results are only coming for this net .    from these results we have some questions with answers . what should be the network input ? plp work as as mfcc ,  but it seems impor important to use the delta . with respect to the network size , there 's one experiment that 's still running and we should have the result today , comparing network with five hundred and one thousand units .  nnn , still no answer actually . the training set , some answer . we can , we can tell which training set gives the best result , but we don't know exactly why .      then some questions without answers . training set ,  training targets it 's    training s right . the training targets actually , ","the fourth point is , the timit plus noise seems to be the training set that gives better the best network . the reason the reason is that the perhaps the target the task dependency the language dependency , and the noise dependency the e but this is still not clear i don't think we have enough result to talk about the language dependency . the timit network is still the best the fact that it 's hand labeled . but you have two effects , the effect of changing language and the effect of training on something that 's viterbi aligned instead of hand labeled . but but , perhaps it 's not really the alignment that 's bad but the just the ph phoneme string that 's used for the alignment there might be errors just in the ph string of phonemes . this is not really the viterbi alignment , we can , we can tell which training set gives the best result , but we don't know exactly why .  ",
Bro005.A,"the two of the main issues perhaps are still the language dependency and the noise dependency . and perhaps to try to reduce the language dependency , we should focus on finding some other training targets . and labeling s labeling seems important because of timit results .  for moment you use we use phonetic targets but we could also use articulatory targets , soft targets , and perhaps even , use networks that doesn't do classification but just regression train to have neural networks that  does a regression and com compute features and noit not , nnn , features without noise . transform the fea noisy features in other features that are not noisy . but continuous features . not hard targets .    f but , this is w i wa this is one thing , this could be could help perhaps to reduce language dependency and for the noise part we could combine this with other approaches the kleinschmidt approach . the d the idea of putting all the noise that we can find inside a database . kleinschmidt was using more than fifty different noises to train his network , and this is one approach and the other is multi band that is more robust to the noisy changes . perhaps , something like multi band trained on a lot of noises with features based targets could help .     the future work is , try to connect to the to make to plug in the system to the ogi system . there are still open questions there , where to put the mlp     all the test sets  and   and perhaps doing this for cha changing the variance of the streams and on getting different scaling  thi this sh would be more working on the mlp as an additional path instead of an insert to the to their diagram . cuz  perhaps the insert idea is strange because nnn , they make lda and then we will again add a network does discriminate anal nnn , that discriminates , or ?   and and  and because also perhaps we know that the when we have very good features the mlp doesn't help . i don't know .  the way we want to do the d what ? the way we want to do it perhaps is to just to get the vad labels and the final features . they will send us the provide us with the feature files , and with vad binary labels that we can get our mlp features and filter them with the vad and then combine them with their f feature stream .    just re retraining r retraining the htk ?         and fff , lograsta , i don't know if we want to we can try networks with lograsta filtered features .  i 'm   but   you think it 's perhaps better to have several m l  but yea doing both is not right , or ?  but  don't know . but we have to address the problem of cpu and memory we but  but we 've ","the two of the main issues perhaps are still the language dependency and the noise dependency . and perhaps to try to reduce the language dependency , we should focus on finding some other training targets . for moment you use we use phonetic targets but we could also use articulatory targets , soft targets , and perhaps even , use networks that doesn't do classification but just regression and com compute features and noit not , nnn , features without noise . transform the fea noisy features in other features that are not noisy . perhaps , something like multi band trained on a lot of noises with features based targets could help . the future work is , try to connect to the to make to plug in the system to the ogi there are still open questions there , where to put the mlp thi this sh would be more working on the mlp as an additional path instead of an insert to the to their diagram . perhaps the insert idea is strange the way we want to do it perhaps is to just to get the vad labels and the final features . they will send us the provide us with the feature files , ",Also discussed were the details of the continued collaboration with project partner OGI. 
Bro005.A,"i don't know . we have to get some reference point to where we what 's a reasonable number ? perhaps be because if it 's too large or large or @ @   and they 're starting to wor work on some multi band .  this that was pratibha . sunil , what was he doing , do you remember ?  he was doing something new or ? i don't think trying to tune wha networks ? they were also mainly , working a little bit of new things , like networks and multi band , but mainly trying to tune their system as it is now to just trying to get the best from this architecture .    it 's   perhaps we could .  we can for we c we can forget combining multiple features and mlg perhaps , or focus more on the targets and on the training data and ?        but i don't know if we really need now a lot of machines . we could start computing another huge table but we  but   think more is always better , but i don't think we have to train a lot of networks , now that we know we just select what works fine and try to improve this and it 's sometimes we have some problems . restarting the script and my battery is low . ",,
Bro005.B,"  do you want @ @ . yes , i would like to say that , if we doesn't use the delta , we have an improve when we use s some combination . but when w this number recognition acc yes , and the baseline have i is eighty two .  by the moment . and first in the experiment one i do i use different mlp , and is that the multi english mlp is the better . for the ne rest of experiment i use multi english , only multi english . and i try to combine different type of feature , but the result is that the msg three feature doesn't work for the italian database because never help to increase the accuracy .    the train the training of the htk ? yes . yes ! this h yes . th yes .  yes ? another table . no . eighty . eighty . it 's plus six .    at the first and the   yes , better .  nnn , we don't know exactly .   we select these tasks because it 's the more difficult . you have here the information .   the spanish . for that .  with the experiment type two , i first i tried to combine , nnn , some feature from the mlp and other feature another feature . and we s we can first the feature are without delta and delta , and we can see that in the situation , the msg three , the same help nothing . and then i do the same but with the delta and delta plp delta and delta . and they all p but they all put off the mlp is it without delta and delta . and we have a l little bit less result than the baseline plp with delta and delta . if when we have the new neural network trained with plp delta and delta , the final result must be better . i don't know .     yes . no , but they feature @ @ without  but  but i don't know but if we have the neural network trained with the plp delta and delta , tha this can help . and , with this type of configuration which i do on experiment using the new neural net with name broad klatt s twenty seven , d i have found more or less the same result . little bit better ? slightly bet better . yes , is better .    i  and we have only forty feature because in this situation we have one hundred and three feature .  and then w with the first configuration , i f i am found that work , doesn't work work , but is better , the second configuration . because i for the del engli plp delta and delta , here i have eighty five point three accuracy , and with the second configuration i have eighty seven point one .   this is what we decided to do . do ?    ","yes , and the baseline have i is eighty two . and first in the experiment one i do i use different mlp , and is that the multi english mlp is the better . for the ne rest of experiment i use multi english , and i try to combine different type of feature , but the result is that the msg three feature doesn't work for the italian database because never help to increase the accuracy .  another table . eighty . it 's plus six .  first the feature are without delta and delta , and we can see that in the situation , the msg three , the same help nothing . and then i do the same but with the delta and delta plp delta and delta . ","This included reporting the results, and making conclusions to shape future work. "
Bro005.B,"yes . i say this morning that @ @ thought it was the  may no ? with the better no ?   with "" two "" , with "" on line two "" .   it 's a good . actually , it 's good with the ch with the good .    no .         sunil ? i don't re i didn't remember . he 's working with neural network .     to work some problems with the  batteries ? ",,
Bro005.C,"let 's see .  chop ! it 's out of the way . stephane was saying that they weren't hand labeled , the french and the spanish . and then you can vary it .  just listening . helping out preparing they 've been running all the experiments and and i 've been w doing some work on the preparing all the data for them to train and to test on .  right now , i 'm focusing mainly on this final project i 'm working on in jordan 's class .  i 'm trying to there was a paper in icslp about this multi band belief net structure . this guy did it was two h m ms with a dependency arrow between the two h m and wanna try coupling them instead of t having an arrow that flows from one sub band to another sub band . i wanna try having the arrows go both ways . and i 'm just gonna see if that better models asynchrony in any way or  your battery 's going down too . carmen 's battery is d going down too . just pull the batteries out . ","stephane was saying that they weren't hand labeled , the french and the spanish . they 've been running all the experiments and and i 've been w doing some work on the preparing all the data for them to train and to test on . right now , i 'm focusing mainly on this final project i 'm working on in jordan 's class . and i 'm just gonna see if that better models asynchrony in any way ",
Bro005.D," we 're on ? yes , we 're testing noise robustness but let 's not get silly .  you 've got some , xerox things to pass out ? that are  for th the last column we use our imagination .   this one 's though . this has big font .  when you get older you have these different perspectives . lowering the word hour rate is fine , but having big font ! that 's what 's it 's mostly big font .   go ahead .    a all of these numbers are with a hundred percent being , the baseline performance , but with a mel cepstra system going straight into the htk ? yes .   i see . down near the bottom of this sheet . yes .  yes .     yes .   baseline is eighty two . this is italian mismatched .       i the baseline system when you said the baseline system was eighty two percent , that was trained on what and tested on what ? that was , italian mismatched d digits , is the testing , and the training is italian digits ? the "" mismatch "" just refers to the noise and , microphone and forth , right ? did we have would that then correspond to the first line here of where the training is the italian digits ? the yes . yes . training of the net ,  what that says is that in a matched condition , we end up with a fair amount worse putting in the plp . now w would do we have a number , i suppose for the matched i don't mean matched , but use of italian training in italian digits for plp only ? fifty two percent . no , fifty two percent of eighty two ? this is accuracy ! oy ! ninety .  even just plp , it is not , in the matched condition wonder if it 's a difference between plp and mel cepstra , or whether it 's that the net half , for some reason , is not helping . same result s eighty eight point six . adding msg but that 's that 's without the neural net , right ? but she had said eighty two . right ? this the eighty two . i 'm i k i keep getting confused because this is accuracy . alright . alright . this is i was thinking all this was worse . this is all better because eighty nine is bigger than eighty two .  i 'm all better now . go ahead .    we go from eighty si eighty eight point six to ninety , eighty nine . and then adding the msg does nothing ,  for this case , right ? alright . actually , the answer for experiments with one is that adding msg , if you does not help in that case .  the other ones , we 'd have to look at it , but and the multi english , does  ","you 've got some , xerox things to pass out ? for th the last column we use our imagination . a all of these numbers are with a hundred percent being , the baseline performance , baseline is eighty two . when you said the baseline system was eighty two percent , that was trained on what and tested on what ? that was , italian mismatched d digits , is the testing , and the training is italian digits ? the "" mismatch "" just refers to the noise and , microphone and forth , what that says is that in a matched condition , we end up with a fair amount worse putting in the plp . now w would do we have a number , i suppose for the matched i don't mean matched , but use of italian training in italian digits for plp only ? fifty two percent . no , fifty two percent of eighty two ? this is accuracy ! i 'm i k i keep getting confused because this is accuracy . and then adding the msg does nothing , actually , the answer for experiments with one is that adding msg , if you does not help in that case . ","This included reporting the results, and making conclusions to shape future work. The main topic for discussion by the Berkeley Meeting Recorder group was progress on the experiments run as part of the groups main project, a speech recogniser for the cellular industry. "
Bro005.D,"if we think of this in error rates , we start off with , eighteen percent error rate , roughly . and we almost , cut that in half by putting in the on line normalization and the neural net . and the msg doesn't however particularly affect things . and we cut off , about twenty five percent of the error . no , not quite that , is it . two point six out of eighteen . about , sixteen percent of the error , if we use multi english instead of the matching condition . not matching condition , but the italian training .  yes , good .  then you 're assuming multi english is closer to the thing that you could use since you 're not gonna have matching , data for the for the new for the other languages and forth . one qu thing is that , asked you this before , but i wanna double check . when you say "" me "" in these other tests , that 's the multi english , but it is not all of the multi english , right ? it is some piece of part of it . and the multi english is how much ? you used almost all you used two thirds of it , you think . it 's still it hurts you seems to hurt you a fair amount to add in this french and spanish . i wonder why   it 's still  alright , go ahead . and then    yes , it can't be compared with the other cuz this is , with multi english , training . you have to compare it with the one over that you 've got in a box , which is that , the eighty four point six . right ?    not t not tr no . no . not trained with multi english . i see . you 're saying w asking the question , "" what has adding the mlp done to improve over the ,  yes .   eighty s it was eighty  eighty three point six and eighty eight point six .  that 's one thing , but see the other thing is that , it 's good to take the difficult case , but let 's consider what that means . what we 're saying is that one o one of the things that my interpretation of your s original suggestion is something like this , as motivation . when we train on data that is in one sense or another , similar to the testing data , then we get a win by having discriminant training . when we train on something that 's quite different , we have a potential to have some problems . and , if we get something that helps us when it 's somewhat similar , and doesn't hurt us too much when it 's quite different , that 's not bad . ","then you 're assuming multi english is closer to the thing that you could use since you 're not gonna have matching , data for the for the new for the other languages and forth . it 's still it hurts you seems to hurt you a fair amount to add in this french and spanish . i wonder why what we 're saying is that one o one of the things that my interpretation of your s original suggestion is something like this , as motivation . when we train on data that is in one sense or another , similar to the testing data , then we get a win by having discriminant training . when we train on something that 's quite different , we have a potential to have some problems . ",
Bro005.D,"the question is , if you took the same combination , and you tried it out on , on say digits ,  d was that experiment done ?  then does that , with similar noise conditions and forth , does it then look much better ? and what is the range over these different kinds of of tests ? an anyway . go ahead .  slightly better . if you use the , delta there , you would bring it up to where it was , at least about the same for a difficult case .      there is a another , suggestion that would apply , to the second configuration , which , was made , by , hari . and that was that , if you have feed two streams into htk , and you , change the , variances if you scale the variances associated with , these streams you can effectively scale the streams . right ? without changing the scripts for htk , which is the rule here , you can still change the variances which would effectively change the scale of these , two streams that come in . and , if you do that , it may be the case that , the mlp should not be considered as strongly , and , this is just setting them to be , excuse me , of equal weight . it shouldn't be equal weight . right ? i 'm to say that gives more experiments if we wanted to look at that , but , on the other hand it 's just experiments at the level of the htk recognition . it 's not even the htk ,  you have to do the htk training also . do you ? let me think . you don't .  you have to change the no , you can just do it in as once you 've done the training the training is just coming up with the variances guess you could just scale them all . variances . that 's exactly the point , that if you change change what they are it 's diagonal covariance matrices , but you say what those variances are . that it 's diagonal , but the diagonal means th that then you 're gonna it 's gonna internally multiply it and i it im implicitly exponentiated to get probabilities , and it 's gonna it 's going to affect the range of things if you change the variances of some of the features . i it 's precisely given that model you can very simply affect , the s the strength that you apply the features . that was that was , hari 's suggestion .    it could just be that h treating them equally , tea treating two streams equally is just not the right thing to do . it 's potentially opening a can of worms because , it should be a different number for each test set , but  ",,
Bro005.D,"guess the other thing is to take if one were to take , a couple of the most successful of these , and try all these different tests . alright .    ugh ! i was impressed boy , two thousand .  alright , now i 'm just slightly impressed ,  it sounds like the net corrects some of the problems with some poor normalization . but if you can do good normalization it 's let me bef before you go on to the possible issues . on the msg problem that in the in the short time solution that is , trying to figure out what we can proceed forward with to make the greatest progress , much as i said with jrasta , even though i really like jrasta and i really like msg , it 's in category that it 's , it may be complicated . and it might be if someone 's interested in it , certainly encourage anybody to look into it in the longer term , once we get out of this particular rush for results . but in the short term , unless you have some s strong idea of what 's wrong , probably . there 's supposed to msg is supposed to have a an on line normalization though , right ? but also there 's an on line norm besides the agc , there 's an on line normalization that 's supposed to be   taking out means and variances and forth .  in fac the on line normalization that we 're using came from the msg design , it 's "" on line two "" is good . "" two "" is good ? no , "" two "" is bad .   agree . it 's probably something simple i if someone , wants to play with it for a little bit . you 're gonna do what you 're gonna do but my guess would be that it 's something that is a simple thing that could take a while to find .  and the other the results observations two and three , is  that 's what we 've seen . that 's that what we were concerned about is that if it 's not on the target task if it 's on the target task then it helps to have the mlp transforming it . if it if it 's not on the target task , then , depending on how different it is , you can get a reduction in performance . and the question is now how to get one and not the other ? or how to ameliorate the problems . because it certainly does is to have in there , when it when there is something like the training data . that 's what you say th there . i see . hey ! just you can just sit here . i d i don't think we want to mess with the microphones but it 's just have a seat .  ","guess the other thing is to take if one were to take , a couple of the most successful of these , try all these different tests . on the msg problem that in the in the short time solution that is , trying to figure out what we can proceed forward with to make the greatest progress , it 's in category that it 's , it may be complicated . and it might be if someone 's interested in it , certainly encourage anybody to look into it in the longer term , once we get out of this particular rush for results . but in the short term , unless you have some s strong idea of what 's wrong , but my guess would be that it 's something that is a simple thing that could take a while to find . that 's that what we were concerned about is that if it 's not on the target task if it 's on the target task then it helps to have the mlp transforming it . if it if it 's not on the target task , then , depending on how different it is , you can get a reduction in performance . ","This included reporting the results, and making conclusions to shape future work. "
Bro005.D,"s summary of the first forty five minutes is that some work and works , and some doesn't  we can do a little better than that but if you start off with the other one , actually , that has it in words and then th that has it the associated results .  you 're saying that although from what we see , yes there 's what you would expect in terms of a language dependency and a noise dependency . that is , when the neural net is trained on one of those and tested on something different , we don't do as as in the target thing . but you 're saying that it is although that general thing is observable far , there 's something you 're not completely convinced about . and what is that ? you say "" not clear yet "" . what do  do you think the alignments are bad ? have you looked at the alignments what the viterbi alignment 's doing ? might be interesting to look at it . because , that is just looking but it 's not clear to me you necessarily would do badly from a viterbi alignment . it depends how good the recognizer is that 's that the engine is that 's doing the alignment . aha ! the pronunciation models and forth aha . i see . some of the nets were trained with spine and forth . it and that has other noise . just don't just need more results there with that @ @ . hm right , the multi english far is the best . "" multi english "" just means "" timit "" , right ? that 's  and when you add other things in to broaden it , it gets worse typically .    i like that . the training set is both questions , with answers and without answers . it 's yes it 's mul it 's multi purpose .       that seems like a good thing to do , probably , not again a short term thing . one of the things about that is that it 's e u the ri the major risk you have there of being is being dependent on very dependent on the noise and forth . but it 's another thing to try .    if you i it 's interesting thought if you just trained up one fantasy would be you have something like articulatory targets and you have some reasonable database ,  but then which is copied over many times with a range of different noises , and if cuz what you 're trying to do is come up with a core , reasonable feature set which is then gonna be used by the system .    and the real open question , e u there 's lots of open questions , but one of the core quote "" open questions "" for that is if we take the the best ones here , not just the best one , but the best few ","yes there 's what you would expect in terms of a language dependency and a noise dependency . that is , when the neural net is trained on one of those and tested on something different , we don't do as as in the target thing . do you think the alignments are bad ? have you looked at the alignments what the viterbi alignment 's doing ? might be interesting to look at it . the pronunciation models and forth right , the multi english far is the best . "" multi english "" just means "" timit "" , that seems like a good thing to do , probably , not again a short term thing . but one of the core quote "" open questions "" for that is if we take the the best ones here , not just the best one , but the best few ",
Bro005.D,"you want the most promising group from these other experiments . how do they do over a range of these different tests , not just the italian ?  and y y right ? and then then see , again , how we know that there 's a mis there 's a loss in performance when the neural net is trained on conditions that are different than , we 're gonna test on , but if you look over a range of these different tests how do these different ways of combining the straight features with the mlp features , stand up over that range ? that 's that seems like the real question . and if that if you just take plp with the double deltas . assume that 's the p the feature . look at these different ways of combining it . and take let 's say , just take multi english that works pretty for the training . and just look take that case and then look over all the different things . how does that compare between the all the different test sets , and for the couple different ways that you have of combining them . how do they stand up , over the that 's another possibility if you have time ,   it 's a little strange but on the other hand they did it before . the the other thing , though , is that  we wanna get their path running here , right ? if we can add this other as an additional path right ? cuz they 're doing lda rasta . they 're doing lda rasta ,  i see . i see . i see . we first thing we 'd wanna do there is to make that when we get those labels of final features is that we get the same results as them . without putting in a second path . just th w to make that we have we understand properly what things are , our very first thing to do is to double check that we get the exact same results as them on htk . i don't know that we need to r do we need to retrain we can just take the re their training files also . but . but , just for the testing , jus just make that we get the same results we can duplicate it before we add in another cuz otherwise , we won't things mean .  the other thing is when you say comb i 'm i 'm interrupting . that u when you 're talking about combining multiple features , suppose we said , "" we 've got these different features and forth , but plp seems pretty good . "" if we take the approach that mike did and have one of the situations we have is we have these different conditions . we have different languages , we have different noises , ","you want the most promising group from these other experiments . we know that there 's a mis there 's a loss in performance when the neural net is trained on conditions that are different than , we 're gonna test on , but if you look over a range of these different tests how do these different ways of combining the straight features with the mlp features , stand up over that range ? look at these different ways of combining it . and just look take that case and then look over all the different things . how does that compare between the all the different test sets , and for the couple different ways that you have of combining them . how do they stand up , over the we wanna get their path running here , if we can add this other as an additional path we first thing we 'd wanna do there is to make that when we get those labels of final features is that we get the same results as them . without putting in a second path . just th w to make that we have we understand properly what things are , our very first thing to do is to double check that we get the exact same results as them on htk . ",Also discussed were the details of the continued collaboration with project partner OGI. 
Bro005.D,"if we have some drastically different conditions and we just train up different m l ps with them . and put them together . what mike found , for the reverberation case at least , who knows if it 'll work for these other ones . that you did have interpolative effects . that is , that yes , if you knew what the reverberation condition was gonna be and you trained for that , then you got the best results . but if you had , say , a heavily reverberation ca heavy reverberation case and a no reverberation case , and then you fed the thing , something that was a modest amount of reverberation then you 'd get some result in between the two . it was behaved reasonably . is tha that a fair  it works better if what ? i see . see , i oc you were doing some something that was the analogy isn't quite right . you were doing something that was in way a little better behaved . you had reverb for a single variable which was re reverberation . here the problem seems to be is that we don't have a hug a really huge net with a really huge amount of training data . but we have s f for this task , i would think , modest amount . a million frames actually isn't that much . we have a modest amount of training data from a couple different conditions , and then in that and the real situation is that there 's enormous variability that we anticipate in the test set in terms of language , and noise type and channel characteristic , all over the map . a bunch of different dimensions . and i 'm just concerned that we don't really have the data to train up one of the things that we were seeing is that when we added in we still don't have a good explanation for this , but we are seeing that we 're adding in a fe few different databases and the performance is getting worse and when we just take one of those databases that 's a pretty good one , it actually is is better . and that says to me , yes , that , there might be some problems with the pronunciation models that some of the databases we 're adding in like that . but one way or another we don't have seemingly , the ability to represent , in the neural net of the size that we have , all of the variability that we 're gonna be covering . that i 'm i 'm hoping that this is another take on the efficiency argument you 're making , which is i 'm hoping that with moderate size neural nets , that if we if they look at more constrained conditions they 'll have enough parameters to really represent them .      have a feeling  ","here the problem seems to be is that we don't have a hug a really huge net with a really huge amount of training data . but we have s f for this task , i would think , modest amount . a million frames actually isn't that much . we have a modest amount of training data from a couple different conditions , and then in that and the real situation is that there 's enormous variability that we anticipate in the test set in terms of language , and noise type and channel characteristic , ",
Bro005.D,"e the think it 's true that the ogi folk found that using lda rasta , which is a lograsta , it 's just that they have the it 's done in the log domain , as i recall , and it 's it it 's just that they d it 's trained up , right ? that benefitted from on line normalization . they did at least in their case , it did seem to be somewhat complimentary . will it be in our case , where we 're using the neural net ? they were not using the neural net . don't know . the other things you have here are trying to improve results from a single  make better .   and cpu memory issues .  we 've been ignoring that , haven't we ? but but i li my impression you folks have been looking at this more than me . but my impression was that there was a strict constraint on the delay , but beyond that it was that using less memory was better , and using less cpu was better . something like that , right ? don't think we 're completely off the wall . that if we have the ultimate fall back that we could do if we find  we may find that we 're not really gonna worry about the m l if the mlp ultimately , after all is said and done , doesn't really help then we won't have it in . if the mlp does , we find , help us enough in some conditions , we might even have more than one mlp . we could simply say that is done on the server . and it 's  we do the other manipulations that we 're doing before that . think that 's think the key thing was this plug into ogi .  what are they gonna be working do we they 're gonna be working on while we take their features , and ?  guess the way it would work is that you 'd get there 'd be some point where you say , "" this is their version one "" or whatever , and we get these vad labels and features and forth for all these test sets from them , and then that 's what we work with . we have a certain level we try to improve it with this other path and then when it gets to be january some point we say , "" we have shown that we can improve this , in this way . now what 's your newest version ? "" and then they 'll have something that 's better and then we 'd combine it . this is always hard . used to work with folks who were trying to improve a good system with with a neural net system and it was a common problem that you 'd and this actually , this is true not just for neural nets ",,
Bro005.D,"but just for in general if people were working with rescoring n best lists or lattices that come came from a mainstream recognizer . you get something from the other site at one point and you work really hard on making it better with rescoring . but they 're working really hard , too . by the time you have improved their score , they have also improved their score and now there isn't any difference , because the other at some point we 'll have to  i don't know . we 're integrated a little more tightly than happens in a lot of those cases . at the moment they say that they have a better thing we can we e what takes all the time here is that th we 're trying many things , presumably in a day we could turn around taking a new set of things from them and rescoring it , right ?    no , this is this is good . that the most wide open thing is the issues about the different trainings . da training targets and noises and forth . that 's wide open . for right now i th i really liked msg . and that , one of the things i liked about it is has such different temporal properties . and that there is ultimately a really good potential for , bringing in things with different temporal properties . but we only have limited time and there 's a lot of other things we have to look at . and it seems like much more core questions are issues about the training set and the training targets , and fitting in what we 're doing with what they 're doing , and , with limited time .  we have to start cutting down .    and then , once we having gone through this process and trying many different things , i would imagine that certain things come up that you are curious about that you 'd not getting to and when the dust settles from the evaluation that would time to go back and take whatever intrigued you most , got you most interested and work with it , for the next round . as you can tell from these numbers nothing that any of us is gonna do is actually gonna completely solve the problem .  there 'll still be plenty to do . barry , you 've been pretty quiet . figured that , but that what were you involved in this primarily ?  i see . right . what 's that ?     that sounds interesting .  alright . anything to you wanted to no .  silent partner in the meeting . we got a laugh out of him , that 's good . everyone h must contribute to the our sound files here . speaking of which , if we don't have anything else that we need you happy with where we are ? know wher know where we 're going ?   you happy ? ","barry , you 've been pretty quiet . but that what were you involved in this primarily ? ",
Bro005.D,"you 're happy . everyone should be happy .  you don't have to be happy . you 're almost done .    we want a different table , at least right ? there 's some different things that we 're trying to get at now . but as far as you can tell , you 're actually on c on cpu for training and on ?    and we 're on disk ? but they 're correctable , problems . yes . i 'm familiar with that one ,  alright , since we didn't ha get a channel on for you , you don't have to read any digits but the rest of us will . is it on ? we didn't  won't touch anything cuz i 'm afraid of making the driver crash which it seems to do , pretty easily .  we 'll 'll start off the  connect the let 's hope it works . you should go first and see that you 're transcript two   why don't you go next then .  guess we 're done .  just finished digits .  it 's good . guess we can turn off our microphones now . ",,
Bro005.E,"al actually i should mention if about the linux machine "" swede . "" it looks like the neural net tools are installed there . and dan ellis i believe knows something about using that machine  if people are interested in getting jobs running on that could help with that . ",,
Bro007.A,stephane always has these great ideas and but we don't have time .   ,,
Bro007.B,"  today we 're looking at a number of things we 're trying and fortunately for listeners to this we lost some of it 's visual but got tables in front of us . what is what does combo mean ? let me try to restate this and see if i have it right . there is there is the features there 's the ogi features and then those features go through a contextual l let 's take this bottom arr one pointed to by the bottom arrow . those features go through a contextualized klt . then these features also get low pass filtered    that 's good .   three ,      aha ! aha !    no , the klt . and those two together . that 's it . that 's this bottom one . and and then the one at the top and i presume these things that are in yellow because overall they 're the best ? let 's focus on them then what 's the block diagram for the one above it ?    do you e they mentioned made some when i was on the phone with sunil they mentioned some weighting scheme that was used to evaluate all of these numbers . and we don't have the ti digits part yet ?   and have you put all these numbers together into a single number representing that ? not that should be pretty easy to do and that would be good then we could compare the two and say what was better . and how does this compare to the numbers ogi two is just the top row ?   the one place where it looks like we 're messing things up a bit is in the highly mismatched italian . an  now up one of the ideas that you had mentioned last time was having a second silence detection . filt is what that is ? we can't do it .   too bad . good idea , but can't do it .     alright for now at least that 's not there you have some results with low pass filter cepstrum doesn't have a huge effect but it looks like it could help in a couple places . little bit . and  and let 's see what else did we have in there ? guess it makes a l at this point this is should probably look at these others a little bit and you yellowed these out but see that one you can't use because of the delay . those look pretty good . let 's see that one even the just the second row doesn't look that bad right ? that 's just  and that looks like an interesting one too .    when we do this weighted measure we should compare the two cuz it might even come out better . and it 's it 's a little slightly simpler . there 's would put that one also as a and it and it 's actually does significantly better on the highly mismatched italian ,  ",today we 're looking at a number of things we 're trying do you e they mentioned made some when i was on the phone with sunil they mentioned some weighting scheme that was used to evaluate all of these numbers . and we don't have the ti digits part yet ? and have you put all these numbers together into a single number representing that ? that should be pretty easy to do and that would be good then we could compare the two and say what was better . the one place where it looks like we 're messing things up a bit is in the highly mismatched italian . one of the ideas that you had mentioned last time was having a second silence detection . we can't do it . ,"They discussed most recent results, finalized plans to continue and discussed the work required and timing needed for completion of this stage of the project. "
Bro007.B,"and little worse on the mis on the case , but it 's worse than a few things let 's see how that c see how that comes out on their measure and are we running this for ti digits or now is ti di is that part of the result that they get for the development th the results that they 're supposed to get at the end of the month , the ti digits are there also ?   and see what else there is here . see the one i was looking down here at the o the row below the lower yellowed one . that 's with the reduced klt size reduced dimensionality . what happens there is it 's around the same and you could reduce the dimension as you were saying before a bit perhaps . it 's significantly worse it 's it 's mostly worse .  but it is little . not by a huge amount , i don't know . what are the sizes of any of these sets , i 'm you told me before , but i 've forgotten . how many words are in one of these test sets ? about ? the sets the test sets are between five hundred and two thousand sentences , let 's say and each sentence on the average has four or five digits or is it most of them longer or  right , between one and sixteen . see the the reason i 'm asking is we have all these small differences and i don't know how to take them , right ? if you had just to give an example , if you had if you had a thousand words then tenth of a percent would just be one word , right ? it wouldn't mean anything .  it be 'd like to the sizes of these test sets were actually . since these also just to know the numbers , right . these are word error rates this is on how many words .   anyway if you could just mail out what those numbers are and then that be great . what else is there here ? see the second from the bottom it says sil , but this is some different silence or thing or what was that ? yes .  the silence plus the klt output ? you 're only using the silence . no . i see .  and what and what 's ogi forty five ? the bottom one there ? s right , but what 's the what does the last row mean ? that was the one that was the second row . what 's the difference between the second  this is like the second line but with the combo    alright it looks to me the same given that we have to take the filt ones out of the running because of this delay problem it looks to me like the ones you said i agree are the ones to look at ","how many words are in one of these test sets ? see the the reason i 'm asking is we have all these small differences and i don't know how to take them , right ? if you had just to give an example , if you had if you had a thousand words then tenth of a percent would just be one word , it wouldn't mean anything . it be 'd like to the sizes of these test sets were actually . also just to know the numbers , anyway if you could just mail out what those numbers are and then that be great . the silence plus the klt output ? it looks to me the same given that we have to take the filt ones out of the running because of this delay problem it looks to me like the ones you said i agree are the ones to look at ","They discussed most recent results, finalized plans to continue and discussed the work required and timing needed for completion of this stage of the project. "
Bro007.B,"but would add the second row one and then if we can also when they 're using this weighting scheme of forty , thirty five , twenty five is that on the percentages or on the raw errors ? it 's probably on the percentages right ?  alright .  they 'll argue about it .  if we can how many words are in each and then dave dave promised to get us something tomorrow which will be there as far as they 've gotten friday and then we 'll operate with that and how long did it if we 're not doing all these things if we 're only doing guess since this is development data it 's legitimate to do more than one , right ? ordinarily if in final test data you don't want to do several and take the best that 's that 's not proper but if this is development data we could still look at a couple .  i right . but the question is when do we fix the system , do we fix the system tomorrow or do we fix the system on tuesday ? i except that we do have to write it up . also ,  right what we do is we as soon as we get the data from them we start the training and forth but we start the write up right away because as you say there 's only minor differences between these .  and i would i would i 'd like to see it edit it a bit  the my what in this si i in this situation is my forte which is english .   have y have you seen alt d do they have a format for how they want the system descriptions or anything ?   see . yes , for those who are listening to this and not looking at it it 's not really that impressive , it 's just tiny . it 's all these little categories set a , set b , set c , multi condition , clean . no mitigation .  do what no mitigation means here ? that 's probably the this is probably channel error  this is i right , it says right above here channel error resilience ,  recognition performance is just the top part , actually . and they have yes , split between seen databases and non seen between development and evaluation . and right , it 's presumed there 's all sorts of tuning that 's gone on the see what they call seen databases and there won't be tuning for the unseen . multi condition multi condition . they have looks like they have  they splitting up between the ti digits and everything else , i see . the everything else is the speechdat car , that 's the multi multilingual it is . it is , but there 's also there 's these tables over here for the ti digits and these tables over here for the car data which is all the multilingual ",but would add the second row one if we can how many words are in each and then dave dave promised to get us something tomorrow which will be there as far as they 've gotten friday and then we 'll operate with that do we fix the system tomorrow or do we fix the system on tuesday ? i except that we do have to write it up . what we do is we as soon as we get the data from them we start the training and forth but we start the write up right away because as you say there 's only minor differences between these . and i would i would i 'd like to see it edit it a bit ,"They discussed most recent results, finalized plans to continue and discussed the work required and timing needed for completion of this stage of the project. "
Bro007.B,"and then there 's they also split up between multi condition and clean only . yes .  we 're doing that also ,  anyway , sounds like there 'll be a lot to do just to work with our partners to fill out the tables over the next next few days they have to send it out let 's see the thirty first is wednesday and the it has to be there by some hour european time on wednesday think e excuse me ? yes , mean we have to actually get it done tuesday right because   w i is but is it midni it was actually something like five pm on was like it was five pm i didn't think it was midnight . they said they wanted everything by five pm their time is if three pm . alright , that 's six in the morning here . yes , but i didn't think it was midnight that it was due , it was due at some hour during the day like five pm in which case we should look but my assumption is that we have to be done tuesday . then next thursday we can have a little aftermath but then we 'll actually have the new data which is the german and the danish but that really will be much less work because the system will be fixed all we 'll do is take whatever they have and and run it through the process . we won't be changing the training on anything there 'll be no new training , there 'll just be new htk runs , that 's means in some sense we can relax from this after tuesday and next meeting we can start talking a little bit about where we want to go from here in terms of the research . what things did you think of when you were doing this process that you just didn't really have time to adequately work on  what ?   but they 're ideas .  that was good . and also it 's still true that think it 's true that we at least got fairly consistent i improved results by running the neural net transformation in parallel with the features rather than in sequence which was your suggestion and that seems to have been borne out . the fact that none of these are enormous is not too surprising most improvements aren't enormous and some of them are but mean you have something really wrong and you fix it you can get big and really enormous improvements but cuz our best improvements over the years that we 've gotten from finding bugs , but anyway  see where we are and everybody knows what they 're doing and is there anything else we should talk about or are we done ?  that would be pretty low maintenance to try it . if you can fit it in . have do have one other piece of information which should tell people outside of this group too ","anyway , sounds like there 'll be a lot to do just to work with our partners to fill out the tables over the next next few days yes , mean we have to actually get it done tuesday but my assumption is that we have to be done tuesday . then next thursday we can have a little aftermath and next meeting we can start talking a little bit about where we want to go from here in terms of the research . what things did you think of when you were doing this process that you just didn't really have time to adequately work on that would be pretty low maintenance to try it . ","They discussed most recent results, finalized plans to continue and discussed the work required and timing needed for completion of this stage of the project. "
Bro007.B,"don't know if we 're gonna need it but jeff up at the university of washington has gotten a hold of a some server farm of of ten multiprocessor ibm machines rs six thousands and think each one is four processors or i don't know , eight hundred megahertz and there 's four processors in a box and there 's ten boxes and there 's some ti if he 's got a lot of processing power and we 'd have to schedule it but if we have some big jobs and we wanna run them he 's offering it .  it 's when he was here he used i not only every machine here but every machine on campus as far as i could tell ,  in some ways he just got his payback , but again i don't know if we 'll end up with if we 're gonna be cpu limited on anything that we 're doing in this group but if we are that 's an offer .  you guys doing great that 's really neat and we 'll don't think we need to the other thing that i will say is that the digits that we 're gonna record momentarily is starting to get are starting to get into a pretty good size collection and in addition to the speechdat we will have those to work with really pretty soon now that 's another source of data . which is s under somewhat better control and that we can make measurements of the room the that if we feel there 's other measurements we don't have that we 'd like to have we can make them and dave and i were just talking about that a little while ago that 's another possibility for this work . k , if nobody has anything else we should go around do our digits duty .  'll start . let me say that again . we 're done . ",the other thing that i will say is that the digits that we 're gonna record momentarily is starting to get are starting to get into a pretty good size collection and in addition to the speechdat we will have those to work with really pretty soon now that 's another source of data . ,
Bro007.C,"combo is system where we have these features that go through a network and then this same string of features but low pass filtered with the low pass filter used in the msg features . and these low pass filtered goes through m another mlp and then the linear output of these two mlp 's are combined just by adding the values and then there is this klt . the output is used as features as    could perhaps draw this on the blackboard  we have these features from ogi that goes through the three paths . the first is a klt using several frames of the features . the second path is mlp also using nine frames several frames of features the third path is this low pass filter . mlp adding the outputs just like in the second propose the proposal from for the first evaluation . and then the klt and then the two together again . this is   that 's the reason , for the f first yellow line  it 's the same except that we don't have this low pass filtering we have only two streams .  there 's no low pass processing used as additional feature stream .   actually the way things seems to it 's forty percent for ti digit , sixty for all the speechdat cars , all these languages . ehm the match is forty , medium thirty five and high mismatch twenty five .  no . but generally what you observe with ti digits is that the result are very close whatever the system .  not yet . no .    to actually ogi two is the baseline with the ogi features but this is not exactly the result that they have because they 've they 're still made some changes in the features and but actually our results are better than their results . don't know by how much because they did not send us the new results     there is something funny happening here because  but there are thirty six and then sometimes we are we are around forty two and but  there are some results here the third and the fifth line of the table filt , it seems f for the match and mismatched condition it 's it brings something . but actually there are there 's no room left for any silence detector at the server side because of the delay .  no .   except i don't know because they they are still working two days ago they were still working on this trying to reduce the delay of the silence detector but  if we had time perhaps we could try to find some compromise between the delay that 's on the handset and on the server side . perhaps try to reduce the delay on the handset and but for the moment they have this large delay on the feature computation and we don't i th   actually the the second line is like the first line in yellow ","it 's forty percent for ti digit , sixty for all the speechdat cars , generally what you observe with ti digits is that the result are very close whatever the system . not yet . actually ogi two is the baseline with the ogi features but this is not exactly the result that they have because they 've they 're still made some changes in the features and but actually our results are better than their results . don't know by how much because they did not send us the new results it seems f for the match and mismatched condition it 's it brings something . but actually there are there 's no room left for any silence detector at the server side because of the delay . no . ","They discussed most recent results, finalized plans to continue and discussed the work required and timing needed for completion of this stage of the project. "
Bro007.C,"except that we don't have this klt on the first on the left part of the diagram . we just have the features as they are .        it 's included ,    it 's significantly worse but exc except for the hm but  it 's it depends the matched is generally larger than the other sets and it 's around two thousand or three thousand words perhaps , at least .  the words , s sentences . some sets have five hundred sentences ,    it d seven digits .     we could run some significance tests or        i see .  no they 're there is this silence in addition to the klt outputs it is because we just keep we don't keep all the dimensions after the klt and we try to add the silence also in addition to the these twenty eight dimensions . it 's o it 's ogi two , it 's the th it 's the features from the first line and it 's this but without the klt on the from the left path . the second line you don't have this combo you just        guess ,   it 's not clear here .      we can   but we have to decide we have to fix the system on this d on this data , to choose the best and these but we could it d we fixed on tuesday ,       it 's this with perhaps some printing and some other @ @ . but  you we could start soon , write up something .     not really . there is the format of the table which is quite impressive . it should be the problem with the error channel error or you     it 's not divided between languages or it just   for ti digits . actually for the ti digits they want to train on clean and on noisy and  but we actually do we have the features ?  for the clean ti digits but we did not test it yet . the clean training      except if it 's the thirty one at midnight or i don't know we can still do some work on wednesday morning .    it 's d no . no , we are wondering about the hour that we have to don't know if it 's three pm it 's it 's midnight but         i 'm not these are great ideas .  but      it 's we we will we 'll try to focus on these three architectures and perhaps i was thinking also a fourth one with just a single klt because we did not really test that removing all these klt 's and putting one single klt at the end .       ","it 's it depends the matched is generally larger than the other sets no they 're there is this silence in addition to the klt outputs it is because we just keep we don't keep all the dimensions after the klt we try to add the silence also in addition to the these twenty eight dimensions . we fixed on tuesday , you we could start soon , write up something . we will we 'll try to focus on these three architectures and perhaps i was thinking also a fourth one with just a single klt ","They discussed most recent results, finalized plans to continue and discussed the work required and timing needed for completion of this stage of the project. "
Bro007.D,"the graph , another one . two htk . step .  for the italian . for this one .  for that we  for many a mismatch it 's worse . i don't remember . ye but words word i don't know . sentences .   for the italian even seven digits y more or less but sometime the sentence have only one digit and sometime like the number of credit cards , something like that .  the size that we have ?  we have the result that the output of the htk the number of sentences , no it 's the number isn't .  it the output silence of the mlp . it 's only one small experiment to happened . to apply also to in include also the silence of the mlp we have the fifty six form and the silence to pick up the silence and we include those . because when we apply the klt in addition , yes . in addition t and we not s we are not if we pick we have the silence . it 's ogi two . and with the all the output of the combo .  yes . we lost time wednesday because that the difference in the time may be is a long different of the time . the thursday the twelfth of the night of the thurs thirty one is not valid in europe . we don't know is happening . tuesday .  five pm . not five pm , three pm . three pm . no three a three pm ?  three pm here is in europe midnight .     ",it 's only one small experiment to happened . to apply also to in include also the silence of the mlp we have the fifty six form and the silence to pick up the silence and we include those . and we not s we are not if we pick we have the silence . ,"They discussed most recent results, finalized plans to continue and discussed the work required and timing needed for completion of this stage of the project. "
Bro008.A,"i 'm i didn't    m  y actually , for the danish , there 's still some mystery because , when we use the straight features , we are not able to get these number with the icsi ogi one , we don't have this ninety three seventy eight , we have eight  that 's probably something wrong with the features that we get from ogi . and sunil is working on trying to check everything .   sunday .      actually , something that 's close to cepstral mean subtraction . but , the way the mean is adapted it 's signal dependent . i 'm i 'm , the mean is adapted during speech and not during silence . but it 's very close to cepstral mean subtraction .      this tuesday ,   probably ,    it 's very short interval . there are two more columns in the sheets , two . it 's the same sheets ,   hynek will try to push for trying to combine , different things ? or    they are working on this already ? because su sunil told me that he was trying already to put some filtering in the france telecom .    first , to really have a look at the speech from these databases because , we tried several thing , but we did not really look at what 's happening , and where is the noise , and     actually , there is one thing that generally we think that most of the errors are within phoneme classes , and think it could be interesting to see if it i don't think it 's still true when we add noise , and we have the confusion ma the confusion matrices are very different when we have noise , and when it 's clean speech . and probably , there is much more between classes errors for noisy speech . and perhaps we could have a large gain , just by looking at improving the , recognition , not of phonemes , but of phoneme classes , simply . and which is a s a simpler problem , perhaps , but which is perhaps important for noisy speech .    no .   no , actually the matched condition is still quite di still quite difficult . it 's they have all these data from the close mike and from the distant mike , from different driving condition , open window , closed window , and they take all of this and they take seventy percent , for training and thirty percent for testing . training is done on different conditions and different microphones , and testing also is done on different microphone and conditions . probably if we only take the close microphones , the results should be much better than this .    there is this , the mismatched is , the same thing , but the driving conditions , the speed and the road , is different for training and testing , is that right ? ","y actually , for the danish , there 's still some mystery because , when we use the straight features , we are not able to get these number with the icsi ogi one , that 's probably something wrong with the features that we get from ogi . and sunil is working on trying to check everything . this tuesday , hynek will try to push for trying to combine , different things ? first , to really have a look at the speech from these databases because , we tried several thing , but we did not really look at what 's happening , and where is the noise , and actually , there is one thing that generally we think that most of the errors are within phoneme classes , think it could be interesting to see if it i don't think it 's still true when we add noise , and we have the confusion ma the confusion matrices are very different when we have noise , and when it 's clean speech . and probably , there is much more between classes errors for noisy speech . perhaps we could have a large gain , just by looking at improving the , recognition , not of phonemes , but of phoneme classes , simply . ",
Bro008.A,"and the last condition is close microphone for training and distant for testing .     actually , it 's very close to clean speech training because , because the close microphone and noisy speech testing ,    but the the th it doesn't work . it            actually , this is tha that 's why we it 's a different data . we 're not used to work with this data . that 's why we should have a loo more closer look at what 's going on .   this would be the first thing , and then , try to debug what was wrong , when we do aurora test on the msg particularly , and on the multi band .  but again , it 's the thing that , we were thin thinking that it would work , but it didn't work . and , there is not a bug , but something wrong in what we are doing , perhaps . something wrong , perhaps in the just in the fact that the labels are  what worked best is the hand labeled data .   i don't know if we can get some hand labeled data from other languages . it 's not easy to find . but that would be something interesting t to see .  you on friday or s on saturday or ? s sunday , i 'll be back on tuesday . amsterdam .   ","again , it 's the thing that , we were thin thinking that it would work , but it didn't work . and , there is not a bug , but something wrong in what we are doing , perhaps . something wrong , perhaps in the just in the fact that the labels are what worked best is the hand labeled data . i don't know if we can get some hand labeled data from other languages . but that would be something interesting t to see . ",
Bro008.B,digits . ,,
Bro008.C,"how much better was the best system than ours ?        do we know anything about who 's was it that had the lowest on the dev set ?  and they used the main thing that they used was spectral subtraction ? or   did anybody , do anything with the models as a an experiment ? or n nobody reported it ?    right . you could 've had a repeat count in there    when is the development set the , test set results due ? like the day before you leave   about about other experiments ? now , i 'm interested in , looking at the experiments where you use , data from multiple languages to train the neural net . and i don't know how far , or if you guys even had a chance to try that , but that would be some it 'd be interesting to me . right . right . right .    right .   where 's the meeting ?  should we do digits first ?   ","how much better was the best system than ours ? when is the development set the , test set results due ? now , i 'm interested in , looking at the experiments where you use , data from multiple languages to train the neural net . and i don't know how far , or if you guys even had a chance to try that , but that would be some it 'd be interesting to me . ",
Bro008.D,"  you can fill those out , after , actually ,  i got , these results from , stephane . also , that , we might hear later today , about other results . that , there were some other very good results that we 're gonna wanna compare to . but , r our results from other places ,  i got this from you and then i sent a note to sunil about the cuz he has been running some other systems other than the icsi ogi one . wan wanna see what that is . but , we 'll see what it is comparatively later . but it looks like , most of the time , even even though it 's true that the overall number for danish we didn't improve it if you look at it individually , what it really says is that there 's , looks like out of the six cases , between the different kinds of , matching conditions out of the six cases , there 's a couple where it stays about the same , three where it gets better , and one where it gets worse . go ahead .  and we have a little time on that and actually  we have a little bit of time on that , actually . we have a day or  when do you folks leave ? sunday ?    until saturday midnight , we have w we have time ,  that would be good . that 'd be good .  and , i u when whenever anybody figures it out they should also , for email hynek because hynek will be over there telling people what we did , he should know . good ,   we 'll hold off on that a little bit . even with these results as they are , it 's it 's really not that bad . but , and it looks like the overall result as they are now , even without , any bugs being fixed is that , on the other tasks , we had this average of , forty nine percent , or improvement . and here we have somewhat better than that than the danish , and somewhat worse than that on the german , but it sounds like , one way or another , the methods that we 're doing can reduce the error rate from mel ceptrum down by , fourth of them to , a half of them . somewhere in there , depending on the exact case .  that 's good . that , one of the things that hynek was talking about was understanding what was in the other really good proposals and and trying to see if what should ultimately be proposed is some , combination of things . if , cuz there 's things that they are doing there that we certainly are not doing . and there 's things that we 're doing that they 're not doing . and they all seem like good things .   ","i got , these results from , stephane . also , that , we might hear later today , about other results . that , there were some other very good results that we 're gonna wanna compare to . but , r our results from other places , most of the time , even even though it 's true that the overall number for danish we didn't improve it we have a little bit of time on that , actually . we have a day or when do you folks leave ? sunday ? until saturday midnight , we have even with these results as they are , it 's it 's really not that bad . and it looks like the overall result as they are now , even without , any bugs being fixed is that , on the other tasks , we had this average of , forty nine percent , or improvement . and here we have somewhat better than that than the danish , and somewhat worse than that on the german , but it sounds like , one way or another , the methods that we 're doing can reduce the error rate from mel ceptrum down by , fourth of them to , a half of them . that , one of the things that hynek was talking about was understanding what was in the other really good proposals and trying to see if what should ultimately be proposed is some , combination of things . cuz there 's things that they are doing there that we certainly are not doing . and there 's things that we 're doing that they 're not doing . ","This included some discussion of results, comparing various other groups' systems, issues involving the set up, and plans for future work. "
Bro008.D,"we don't know yet . first place , there 's still this thing to work out , and second place second thing is that the only results that we have far from before were really development set results . in this community that 's of interest . it 's not like everything is being pinned on the evaluation set . but , for the development set , our best result was a little bit short of fifty percent . and the best result of any system was about fifty four , where these numbers are the , relative , reduction in , word error rate . and , the other systems were , somewhat lower than that . there was actually there was much less of a huge range than there was in aurora one . in aurora one there were systems that ba didn't improve things . and here the worst system still reduced the error rate by thirty three percent , in development set . everybody is doing things between , roughly a third of the errors , and half the errors being eliminated , and varying on different test sets and forth . think it 's probably a good time to look at what 's really going on and seeing if there 's a way to combine the best ideas while at the same time not blowing up the amount of , resources used , cuz that 's critical for this test . the there were two systems that were put forth by a combination of , french telecom and alcatel . and , they differed in some respects , but they e one was called the french telecom alcatel system the other was called the alcatel french telecom system , which is the biggest difference , but there 're there 're some other differences , too . and , they both did very  my impression is they also did very on the , evaluation set , but , i we haven't seen you 've you haven't seen any final results for that  there is a couple pieces to it . there 's a spectral subtraction style piece it was wiener filtering . and then there was some p some modification of the cepstral parameters , where they  but some people have done exactly that thing , of and the it 's not to look in speech only , to try to m to measure these things during speech , that 's p that 's not that uncommon . but i it it looks like they did some , reasonable things , and they 're not things that we did , precisely . we did unreasonable things , which because we like to try strange things , and , and our things worked too . and it 's possible that some combination of these different things that were done would be the best thing to do . ","we don't know yet . first place , there 's still this thing to work out , and second place second thing is that the only results that we have far from before were really development set results . it 's probably a good time to look at what 's really going on and seeing if there 's a way to combine the best ideas while at the same time not blowing up the amount of , resources used , but i it it looks like they did some , reasonable things , and they 're not things that we did , precisely . we did unreasonable things , which because we like to try strange things , and , and our things worked too . it 's possible that some combination of these different things that were done would be the best thing to do . ",
Bro008.D,"but the only caveat to that is that everybody 's being real conscious of how much memory and how much cpu they 're using because these , standards are supposed to go on cell phones with m moderate resources in both respects . they didn't report it , if they did .  everybody was focused elsewhere . now , one of the things that 's about what we did is , we do have a , filtering , which leads to a , reduction in the bandwidth in the modulation spectrum , which allows us to downsample . as a result of that we have a reduced , transmission rate for the bits . that was misreported the first time out . it said the same amount because for convenience sake in the particular way that this is being tested , they were repeating the packets . it was they were s they had twenty four hundred bits per second , but they were literally creating forty eight hundred bits per second , even though y it was just repeated . in practice n this was just a ph phoney thing just to fit into the software that was testing the errors channel errors and on .  in reality , if you put this system in into , the field , it would be twenty four hundred bits per second , not forty eight hundred .  that 's a feature of what we did .  but , we still have to see how it all comes out . and then there 's the whole standards process , which is another thing altogether . probably the day after they leave , but we 'll have to stop it the day before we leave . tha the meeting is on the thirteenth and , they , right . and the , results are due like the day before the meeting  i th they are ,  since we have a bit farther to travel than some of the others , we 'll have to get done a little quicker . but , it 's just tracing down these bugs . just exactly this thing of , why these features seem to be behaving differently , in california than in oregon . might have something to do with electricity shortage . we didn't have enough electrons here and but , the main reason for having it only takes w to run the two test sets in just in computer time is just a day or right ?   the who the whole reason for having as long as we have , which was like a week and a half , is because of bugs like that .   we 're gonna end up with these same sheets that have the percentages and on just for the it 's the same sheets ,   just with the missing columns filled in .  that 'll be good . i 'll dis i 'll disregard these numbers . that 's that 's good . that 's  ","but the only caveat to that is that everybody 's being real conscious of how much memory and how much cpu they 're using because these , standards are supposed to go on cell phones with m moderate resources in both respects . now , one of the things that 's about what we did is , we do have a , filtering , which leads to a , reduction in the bandwidth in the modulation spectrum , which allows us to downsample . as a result of that we have a reduced , transmission rate for the bits . in reality , if you put this system in into , the field , it would be twenty four hundred bits per second , not forty eight hundred . that 's a feature of what we did . probably the day after they leave , but we 'll have to stop it the day before we leave . tha the meeting is on the thirteenth and the , results are due like the day before the meeting since we have a bit farther to travel than some of the others , we 'll have to get done a little quicker . but , it 's just tracing down these bugs . just exactly this thing of , why these features seem to be behaving differently , in california than in oregon . ","This included some discussion of results, comparing various other groups' systems, issues involving the set up, and plans for future work. "
Bro008.D,"the question is "" is there some advantage ? "" you could just take the best system and say that 's the standard . but that if different systems are getting at good things , a again within the constraint of the resources , if there 's something simple that you can do now it 's , very reasonable to have a standard for the terminal 's side and then for the server 's side say , "" here 's a number of things that could be done . "" everything that we did could probably just be added on to what alcatel did , and i it 'd probably work pretty with them , too .  that 's one aspect of it . and then on the terminal 's side , i don't know how much , memory and cpu it takes , but it seems like the filtering the vad they both had , right ? and , and they both had some on line normalization , right ? of sorts ,   it seems like the main different there is the , filtering . and the filtering if you can shouldn't take a lot of memory to do that and i also wouldn't think the cpu , would be much either for that part . if you can add those in then , you can cut the data rate in half . it seems like the right thing to do is to on the terminal 's side , take what they did , if it does seem to generalize to german and danish , take what they did add in a filter , and add in some on the server 's side and that 's probably a reasonable standard .  that 's that 's what that would be ideal would be is that they could , they could actually show that , a combination of some sort , would work even better than what any of the systems had . and , then it would , be something to discuss in the meeting . but , not clear what will go on . on the one hand , sometimes people are just anxious to get a standard out there . you can always have another standard after that , but this process has gone on for a while on already and people might just wanna pick something and say , "" this is it . "" and then , that 's a standard . standards are always optional . it 's just that , if you disobey them , then you risk not being able to sell your product , or and people often work on new standards while an old standard is in place and on . it 's not final even if they declared a standard . the other hand , they might just say they just don't know enough yet to declare a standard .  ","the question is "" is there some advantage ? "" you could just take the best system and say that 's the standard . but that if different systems are getting at good things , a again within the constraint of the resources , if there 's something simple that you can do everything that we did could probably just be added on to what alcatel did , and i it 'd probably work pretty with them , too . the vad they both had , and , and they both had some on line normalization , it seems like the main different there is the , filtering . shouldn't take a lot of memory to do that and i also wouldn't think the cpu , would be much either for that part . if you can add those in then , you can cut the data rate in half . ",
Bro008.D,"you will be you will become experts on this and know more far more than me about the tha this particular standards process once you go to this meeting .  be interested in hearing . i 'd be , interested in hearing , your thoughts now you 're almost done . you 're done in the sense that , you may be able to get some new features from sunil , and we 'll re run it . but other than that , you 're done , right ? i 'm interested in hearing your thoughts about where you think we should go from this . we tried a lot of things in a hurry , and , if we can back off from this now and take our time with something , and not have doing things quickly be quite much the constraint , what you think would be the best thing to do .  it 's a novel idea . look at the data .  or more generally , what is causing the degradation .   the other thing that strikes me , just looking at these numbers is , just taking the best cases , some of these , even with all of our wonderful processing , still are horrible kinds of numbers . but just take the best case , the matched german case after er matched danish after we the numbers we 're getting are about eight or nine percent error per digit . this is not usable , right ? if you have ten digits for a phone number every now and then you 'll get it right . it 's it 's , the other thing is that , and a and also , part of what 's about this is that this is , realistic almost realistic database . it 's still not people who are really trying to accomplish something , but , within the artificial setup , it isn't noise artificially added , simulated , additive noise . it 's real noise condition . and , the training the training , is always done on the close talking no ?  i see .  that explains it partially . wha what about i in the go ahead .   i see .  the high the right the highly mismatched case is in some sense a good model for what we 've been , typically talking about when we talk about additive noise in and and i k it does correspond to a realistic situation in the sense that , people might really be trying to , call out telephone numbers or some like that , in their cars and they 're trying to connect to something .     and the matched condition is what you might imagine that you might be able to approach , if that this is the application . you 're gonna record a bunch on people in cars and forth , and do these training . ","i 'm interested in hearing your thoughts about where you think we should go from this . we tried a lot of things in a hurry , and , if we can back off from this now and take our time with something , and not have doing things quickly be quite much the constraint , what you think would be the best thing to do . the other thing that strikes me , just looking at these numbers is , just taking the best cases , some of these , even with all of our wonderful processing , still are horrible kinds of numbers . but just take the best case , the matched german case after er matched danish after we the numbers we 're getting are about eight or nine percent error per digit . this is not usable , if you have ten digits for a phone number every now and then you 'll get it right . ",
Bro008.D,"and then , when y you sell it to somebody , they will be a different person with a different car , and on . it 's this is a an optim somewhat optimistic view on it , the real thing is somewhere in between the two .  but even the optimistic one is  right . right , it doesn't work . in a way , that 's , that 's the dominant thing is that even , say on the development set that we saw , the , the numbers that , that alcatel was getting when choosing out the best single numbers , it was just it wasn't good enough for a real system . you you , we still have to do . and , i don't know looking at the data , where , what 's the what 's th what 's characteristic i e that 's a good thing . does a any you have any thoughts about what else y you 're thinking that you didn't get to that you would like to do if you had more time ?    cuz a lot of time it 's true , there were a lot of times when we 've tried something and it didn't work right away , even though we had an intuition that there should be something there . and then we would just stop it .  and , one of the things i don't remember the details on , but i remember at some point , when you were working with a second stream , and you tried a low pass filtering to cepstrum , in some case you got but it was an msg like thing , but it wasn't msg , right ? you y in some case you got some little improvement , but it was , small improvement , and it was a big added complication , you dropped it . but , that was just one try , right ? you just took one filter , threw it there , right ? and it seems to me that , if that is an important idea , which , might be , that one could work at it for a while , as you 're saying . and , and you had , you had the multi band things also , and , there was issue of that . barry 's going to be , continuing working on multi band things as we were just talking about , some , some work that we 're interested in . inspired by the by larry saul with the , learning articulatory feature in in the case of his paper with sonorance based on , multi band information where you have a combination of gradient learning an and , and that , this is a , this is a neat data set . and then , as we mentioned before , we also have the new , digit set coming up from recordings in this room . ","in a way , that 's , that 's the dominant thing is that even , say on the development set that we saw , the , the numbers that , that alcatel was getting when choosing out the best single numbers , it was just it wasn't good enough for a real system . we still have to do . does a any you have any thoughts about what else y you 're thinking that you didn't get to that you would like to do if you had more time ? there were a lot of times when we 've tried something and it didn't work right away , even though we had an intuition that there should be something there . and then we would just stop it . and , one of the things i don't remember the details on , but i remember at some point , when you were working with a second stream , and you tried a low pass filtering to cepstrum , in some case you got but it was an msg like thing , but it wasn't msg , you y in some case you got some little improvement , and it seems to me that , if that is an important idea , which , might be , that one could work at it for a while , as you 're saying . and you had , you had the multi band things also , and , there was issue of that . barry 's going to be , continuing working on multi band things as we were just talking about , some , some work that we 're interested in . inspired by the by larry saul with the , learning articulatory feature in in the case of his paper with sonorance based on , multi band information where you have a combination of gradient learning an and , ",
Bro008.D,"there 's a lot of things to work with .  and , what i like about it , in a way , is that , the results are still terrible . mean , they 're much better than they were , we 're talking about thirty to sixty percent , error rate reduction . that 's really great to do that in relatively short time . but even after that it 's still , poor that , no one could really use it .  that 's great that because and y also because again , it 's not something sometimes we 've gotten terrible results by taking some data , and artificially , convolving it with some room response , we take a very at one point , brian and i went downstairs into the basement where it was in a hallway where it was very reverberant and we made some recordings there . and then we , made a simulation of the room acoustics there and applied it to other things , and but it was all pretty artificial , and , how often would you really try to have your most crucial conversations in this very reverberant hallway ?  this is what 's about the aurora data and the data here , is that it 's realistic room situation acoustics acoustic situation , both terms in noise and reflections , and on and n and , with something that 's still relatively realistic , it 's still very hard to do very         no , there 's lots of good things to do with this .   let 's you were gonna say something else ?  what do you think ? anything s b   also , there was just the whole notion of having multiple nets that were trained on different data . one form of different data was is from different languages , but the other i m in those experiments it wasn't much combining multiple nets , it was a single net that had different first thing is would it be better if they were multiple nets , for some reason ? second thing is , never mind the different languages , just having acoustic conditions rather than training them all up in one , would it be helpful to have different ones ?  that was a question that was raised by mike shire 's thesis , and on in that case in terms of reverberation . right ? that sometimes it might be better to do that . but , i don't think we know for  right . next week , we , won't meet because you 'll be in europe . whe when are you two getting back ? that 's right . you 've gotta s have a saturday overnight , right ? tuesday . amsterdam ,     we 'll skip next week , and we 'll meet two weeks from now . and , the main topic will be , you telling us what happened .   ","mean , they 're much better than they were , we 're talking about thirty to sixty percent , error rate reduction . that 's really great to do that in relatively short time . but even after that it 's still , poor that , no one could really use it . also , there was just the whole notion of having multiple nets that were trained on different data . one form of different data was is from different languages , but the other i m in those experiments it wasn't much combining multiple nets , it was a single net that had different first thing is would it be better if they were multiple nets , for some reason ? second thing is , never mind the different languages , just having acoustic conditions rather than training them all up in one , would it be helpful to have different ones ? ",
Bro008.D,"if we don't have an anything else to discuss , we should , turn off the machine and then say the real nasty things . digits !  good point .  good thinking . why don't you go ahead . ",,
Bro008.E,"eighty nine forty four .    f a lot of thing . because we trying a lot of s thing , and we doesn't work , we remove these . we trying again with the articulatory feature . i don't know exactly because we tried we some one experiment that doesn't work . forgot it , something i don't know exactly because , tsk do better some step the general , diagram . i don't know exactly s to think what we can improve . msg   i 'm sunday because it 's less expensive , the price the ticket .  ","we trying again with the articulatory feature . because we tried we some one experiment that doesn't work . because , tsk do better some step the general , diagram . ",
Bro010.A,"we 're on . this was the , talk where they were supposed to try to decide right . what 's the allowable ? what were they thinking of changing it to ?   think of it as what ?  right .  and i don't think anybody 's gonna notice the difference between a quarter of a second of latency and thirty milliseconds of latency . we had a silence detector ,  we would look for the end of an utterance based on the silence detector . and i can't remember now off the top of my head how many frames of silence we had to detect before we would declare it to be the end of an utterance .  but it was ,  i would say it was probably around the order of two hundred and fifty milliseconds .  we did the back trace at that point to get the answer . no , no it was pretty quick .  this w right . right . right . and it felt to , the users that it was instantaneous . as fast as talking to a person . it th i don't think anybody ever complained about the delay .   i don't remember the exact numbers but it was something like that . i don't think you can really tell . a person i don't think a person can tell the difference between , a quarter of a second and a hundred milliseconds , and i 'm not even if we can tell the difference between a quarter of a second and half a second . it just it feels quick .   it may feel different than talking to a person because when we talk to each other we tend to step on each other 's utterances . like if i 'm asking you a question , you may start answering before i 'm even done . it would probably feel different but i don't think it would feel slow . is the latency from the neural net caused by how far ahead you 're looking ? wasn't there was it in the , recurrent neural nets where they weren't looking ahead a little bit .  we 've always had usually we used the symmetric windows but i don't think  change the what ? i 'm missing that last word . context klt . klt .  what is the advantage of that ?  really ?       is the estimate of the noise spectrum a running estimate ? or   do you is there some long window that extends into the past over which you calculate the average ? a couple seconds ?  but wh don't they overlap sometimes ?      but what is the it seems like this thing could add to the latency . depending on where the window was that you used to calculate the signal to noise ratio .  that that was my question ,  guess . were his , windows centered around the ","what 's the allowable ? what were they thinking of changing it to ? a person i don't think a person can tell the difference between , a quarter of a second and a hundred milliseconds , i 'm not even if we can tell the difference between a quarter of a second and half a second . it just it feels quick . is the latency from the neural net caused by how far ahead you 're looking ? it seems like this thing could add to the latency . depending on where the window was that you used to calculate the signal to noise ratio . ","The group also touched upon matters that had broader implications for the work, such as the work of other groups on the same project. "
Bro010.A,"we could probably get a really good estimate of the noise if we just went to the noise files , and built the averages from them . very slow adaptation . th if they 're going to provide a , voice activity detector that will tell you the boundaries of the speech , then , couldn't you just go outside those boundaries and do your estimate there ? what are some of the low level detectors that they use ?  and are each of these , low level detectors are they ,  are these something that you decide ahead of time , like "" i 'm going to look for this particular feature or i 'm going to look at this frequency , "" or what are they looking at ? what are their inputs ?           right .      how did they measure the performance of their detector ?   didn't they didn't they also do some an oracle experiment where they said "" if we could detect the sonorants perfectly and then show how it would improve speech recognition ? remember hearing about an experiment like that .    when we talked with john ohala the other day we made a list of some of the things that w like frication , abrupt closure , r coloring , nasality , voicing   there 's also things like stress . you can look at stress .  there 's a few cases where it can like permit and permit . but that 's not very common in english . in other languages it 's more important . no , i 'm saying , i e you were saying that stress doesn't help you distinguish between words . i see what you 're saying . as long as you get the sequence , right ?   right . where it could help is at a higher level .  understanding ,  exactly .  don't know . we d we didn't get that far . we just talked about some possible features that could be marked by humans and , because of having some extra transcriber time we thought we could go through and mark some portion of the data for that . and ,  right . i 'm definitely interested in this area , too , f acoustic feature  that could help though . that 's what the head 's for ? to separate the ears ? actually the , for some reason the digit forms are blank . th that may be due to the fact that adam ran out of digits , and didn't have time to regenerate any .  if you want to put your credit card numbers and ,  i do need your names and the time , and all that , cuz we put that into the "" key "" files .  but w that 's why we have the forms , even if there are no digits . guess we 're done . ",,
Bro010.B,"i don't know . do you have news from the conference talk ?  that was programmed for yesterday  alright . to decide what to do ,    we 've a little bit worked on trying to see , what were the bugs and the problem with the latencies .  we took first we took the lda filters and , we designed new filters , using recursive filters actually . i 'm us .  we took the filters the fir filters and we designed , iir filters that have the same frequency response . similar , but that have shorter delays . they had two filters , one for the low frequency bands and another for the high frequency bands . and we redesigned two filters . and the low frequency band has sixty four milliseconds of delay , and the high frequency band filter has something like eleven milliseconds compared to the two hundred milliseconds of the iir filters . but it 's not yet test . we have the filters but we still have to implement a routine that does recursive filtering and no . no .      i  i don't know if th that 's what they were trying to they were trying to do something different like taking , using filter that takes only a past and this is just a little bit different . but i will send him an email and tell him exactly what we are doing ,    alright .   there is w one , remark about these filters , that they don't have a linear phase .  i don't know , perhaps it doesn't hurt because the phase is almost linear but .  and for the delay i gave you here , it 's it 's , computed on the five hertz modulation frequency , which is the the most important for speech   this is the first thing .  three hundred and thirty .  but there are other points actually ,  which will perhaps add some more delay . is that some other in the process were perhaps not very perf not very correct , like the downsampling which w was simply dropping frames .  we will try also to add a downsampling having a filter that a low pass filter at twenty five hertz . because wh when we look at the lda filters , they are low pass but they leave a lot of what 's above twenty five hertz .  and this will be another filter which would add ten milliseconds again .   and then there 's a third thing , is that , the way on line normalization was done is just using this recursion on the on the feature stream , and but this is a filter , it has also a delay .  and when we look at this filter actually it has a delay of eighty five milliseconds . if we  if we want to be very correct , ","do you have news from the conference talk ? we 've a little bit worked on trying to see , what were the bugs and the problem with the latencies . we took first we took the lda filters and , we designed new filters , using recursive filters actually . we took the filters the fir filters and we designed , iir filters that have the same frequency response . similar , but that have shorter delays . and the low frequency band has sixty four milliseconds of delay , and the high frequency band filter has something like eleven milliseconds compared to the two hundred milliseconds of the iir filters . no . three hundred and thirty .  ","The Berkeley Meeting Recorder Group discussed the progress of several of their members. The group also touched upon matters that had broader implications for the work, such as the work of other groups on the same project. "
Bro010.B,"if we want to the estimation of the mean t to be the right estimation of the mean , we have to t to take eighty five milliseconds in the future .    but , when we add up everything it 's it will be alright . we would be at six sixty five , plus ten , plus for the downsampling , plus eighty five for the on line normalization . it 's plus eighty for the neural net and pca . it would be around two hundred and forty  plus the frames , but it 's     and the best proposal had something like thirty or forty milliseconds of latency .        it 's that by the for the moment we have , something that 's discriminant and nonlinear . and the other is linear but it 's not discriminant it 's a linear transformation , that      actually what we want to do , perhaps it 's to replace to have something that 's discriminant but linear , also . and to see if it improves ov over the non discriminant linear transformation . and if the neural net is better than this or ,  ye      it would be on the  on the mel frequency bands ,  be before everything .     it 's power domain , i don't remember exactly . but  it 's before everything else , and    a little bit more and   and generated this ,  you have the estimation of the power spectra of the noise , and you multiply this by a factor which is depend dependent on the snr .  when the speech lev when the signal level is more important , compared to this noise level , the coefficient is small , and around one . but when the power le the s signal level is small compared to the noise level , the coefficient is more important . and this reduce actually the music musical noise ,  which is more important during silence portions , when the s the energy 's small . there are tricks like this but ,      but  but it actually , it 's a if you want to have a good estimation on non stationary noise you have to look in the future . if you take your window and build your histogram in this window , what you can expect is to have an estimation of th of the noise in the middle of the window , not at the end .  the but people the they just look in the past . it works because the noise are , pret almost stationary but ,  if y if you have a good estimation of the noise ,  because  it has to work . i  that 's hard to do .  but        that 's in this case , you cannot but hirsch does experiment with windows of like between five hundred milliseconds and one second . and five hundred wa was not bad .  and he worked on non stationary noises , like noise modulated with wi with amplitude modulations and ","but , when we add up everything it 's it will be alright . sixty five , plus ten , plus for the downsampling , plus eighty five for the on line normalization . plus eighty for the neural net and pca . it would be around two hundred and forty and the best proposal had something like thirty or forty milliseconds of latency . actually , it 's a if you want to have a good estimation on non stationary noise you have to look in the future . they just look in the past . it works because the noise are , pret almost stationary that 's hard to do . ","The group also touched upon matters that had broader implications for the work, such as the work of other groups on the same project. "
Bro010.B,"things like that , and but      in the paper he showed that actually the estimation of the noise is delayed . it 's there is you have to center the window ,       what what do but if the noise is stationary perhaps you don't even need some noise estimation algorithm . we just take th the beginning of the utterance and i know p i don't know if people tried this for aurora . everybody seems to use some adaptive , scheme but , is it very useful and is the c       they have some threshold on the previous estimate , and   ericsson used this threshold . they h they have an estimate of the noise level and they put a threshold like six or ten db above , and what 's under this threshold is used to update the estimate . is that right or ? it 's  it 's like saying what 's under the threshold is silence , and i d i y perhaps ? what could be the other low level detectors , for other features , or ? in addition to detecting sonorants or ? th that 's what you want to go for also or ? other low level detectors ?    and the de reverberation algorithm , do you have can you give some more details on this or ? does it use one microphone ? several microphones ? does it ?       i g when people are working with single microphones , they are more trying to do not very there is the avendano work , but also trying to trying to f t find the de convolution filter but in the  not in the time domain but in the the stream of features guess . @ @ there 's someone working on this on i in mons perhaps ,  we should try t to he 's working on this , on trying to on re reverberation ,    he did echo cancellation and he did some fancier things like , training different network on different reverberation conditions and then trying to find the best one , but .  if there is ?   ",,
Bro010.C," what are we talking about today ?     i 'm i know now i you 're talking about . no , nobody 's told me anything .  no , that would have been a good thing to find out before this meeting , that 's . no , i have no idea .    let 's assume for right now that we 're just plugging on ahead , because even if they tell us that , the rules are different , we 're still interested in doing what we 're doing . what are you doing ? when you say "" we "" , is that something sunil is doing or is that ? who is doing that ?      you had a discussion with sunil about this though ?  you should talk with him .  no , because the whole problem that happened before was coordination , right ? you need to discuss with him what we 're doing , cuz they could be doing the same thing and right .     we just have to be in contact more . that the fact that we did that with had that thing with the latencies was indicative of the fact that there wasn't enough communication .   right . that would be , a reduction of a hundred and thirty six milliseconds , which , what was the total we ended up with through the whole system ? that would be within ?      eighty five .  that 's a little bit of a problem .  but then there 's  just barely in there . two fifty , unless they changed the rules . which there is there 's some discussion of . but the people who had very low latency want it to be low very narrow , latency bound . and the people who have longer latency don't .  unfortunately we 're the main ones with long latency , but but , it 's   they were  they were more or less trading computation for performance and we were , trading latency for performance . and they were dealing with noise explicitly and we weren't , and think of it as complementary , that if we can put the complementary . the best systems everything that we did in a way it was just adamantly insisting on going in with a brain damaged system , which is something actually , we 've done a lot over the last thirteen years . which is we say , this is the way we should do it . and then we do it . and then someone else does something that 's straight forward . w th w this was a test that largely had additive noise and we did we adde did nothing explicitly to handle ad additive noise . we just , trained up systems to be more discriminant . and , we did this , rasta like filtering which was done in the log domain and was tending to handle convolutional noise . we did we actually did nothing about additive noise .  ","no , nobody 's told me anything . no , that would have been a good thing to find out before this meeting , let 's assume for right now that we 're just plugging on ahead , because even if they tell us that , the rules are different , we 're still interested in doing what we 're doing . what are you doing ? you had a discussion with sunil about this though ? you should talk with him . no , because the whole problem that happened before was coordination , you need to discuss with him what we 're doing , cuz they could be doing the same thing and we just have to be in contact more . that the fact that we did that with had that thing with the latencies was indicative of the fact that there wasn't enough communication . that would be , a reduction of a hundred and thirty six milliseconds , what was the total we ended up with through the whole system ? that would be within ? just barely in there . two fifty , unless they changed the rules . which there is there 's some discussion of . the people who had very low latency want it to be low very narrow , latency bound . and the people who have longer latency don't . unfortunately we 're the main ones with long latency , ","The Berkeley Meeting Recorder Group discussed the progress of several of their members. The group also touched upon matters that had broader implications for the work, such as the work of other groups on the same project. "
Bro010.C,"the , spectral sub subtraction schemes a couple places did seem to do a job . and  we 're talking about putting some of that in while still keeping some of our you should be able to end up with a system that 's better than both but clearly the way that we 're operating for this other does involved some latency to get rid of most of that latency . to get down to forty or fifty milliseconds we 'd have to throw out most of what we 're doing . and , i don't think there 's any good reason for it in the application actually . you 're you 're speaking to a recognizer on a remote server and , having a quarter second for some processing to clean it up . it doesn't seem like it 's that big a deal . these aren't large vocabulary things the decoder shouldn't take a really long time , and .  no . what does wa was your experience when you were doing this with , the surgical , microscopes and forth . how long was it from when somebody , finished an utterance to when , something started happening ?     and that 's when you 'd start doing things .  that didn't take too long at that point .   you had a you had a quarter second delay before , plus some little processing time , and then the microscope would start moving  and there 's physical inertia there , probably the motion itself was all  you would think as long as it 's under half a second i 'm not an expert on that but .    if you if you said , "" what 's the , what 's the shortest route to the opera ? "" and it took half a second to get back to you , it would be f it might even be too abrupt . you might have to put in a s a delay .   right . right . anyway ,  we could cut we else , we could cut down on the neural net time by , playing around a little bit , going more into the past , like that . we t we talked about that .  and there 's also there 's the neural net and there 's also this , multi frame , klt . they weren't looking ahead much . they p they looked ahead a little bit .   you could do this with a recurrent net . and then but you also could just , we haven't experimented with this but i imagine you could , predict a , a label , from more in the past than in the future . we 've d we 've done some with that before . it works   but we 've but we played a little bit with asymmetric , guys . you can do it .  that 's what you 're busy with , s messing around with this ,  and ,  k klt .    ","to get down to forty or fifty milliseconds we 'd have to throw out most of what we 're doing . we could cut we else , we could cut down on the neural net time by , playing around a little bit , going more into the past ,  ",
Bro010.C,"at least just to understand what the difference was between how much you were getting from just putting the frames together and how much you 're getting from the discriminative , what the nonlinearity does for you or doesn't do for you . just to understand it a little better that 's what i meant , is to see whether it having the neural net really buys you anything . it doe did look like it buys you something over just the klt . but it 's just the discrimination and the nonlinear discrimination isn't necessary . could be . good to know . but the other part you were saying was the spectral subtraction , you just at what stage do you do that ? do you 're doing that ,   just do that on the mel f that the way that they 're one thing that would be no good to find out about from this conference call is that what they were talking about , what they 're proposing doing , was having a third party , run a good vad , and determine boundaries . and then given those boundaries , then have everybody do the recognition . the reason for that was that , if some one p one group put in the vad and another didn't , or one had a better vad than the other since that they 're not viewing that as being part of the task , and that any manufacturer would put a bunch of effort into having some s good speech silence detection . it still wouldn't be perfect but e the argument was "" let 's not have that be part of this test . "" "" let 's separate that out . "" and they argued about that yesterday and , i 'm i don't know the answer but we should find out . i 'm we 'll find out soon what they , what they decided .  there 's the question of the vad but otherwise it 's on the , the mel fil filter bank , energies you do doing the ? and you 're subtracting in the in the it 's power domain , or magnitude domain . probably power domain , right ? why   if you look at the theory , it 's it should be in the power domain but , i 've seen implementations where people do it in the magnitude domain and i have asked people why and they shrug their shoulders and say , "" it works . ""   and there 's this there 's this mysterious people who do this a lot have developed little tricks of the trade . there 's this , you don't just subtract the estimate of the noise spectrum . you subtract th that times or less , or      that 's that 's what differs from different tasks and different s spectral subtraction methods . ","one thing that would be no good to find out about from this conference call is that what they were talking about , what they 're proposing doing , was having a third party , run a good vad , and determine boundaries . and then given those boundaries , then have everybody do the recognition . they argued about that yesterday i don't know the answer but we should find out . ","The group also touched upon matters that had broader implications for the work, such as the work of other groups on the same project. "
Bro010.C,"if you have , fair assurance that , the noise is quite stationary , then the smartest thing to do is use as much data as possible to estimate the noise , get a much better estimate , and subtract it off . but if it 's varying which is gonna be the case for almost any real situation , you have to do it on line , with some forgetting factor there 's a lot of different ways of computing the noise spectrum . one of the things that , hans guenter hirsch did , and pas and other people actually , he 's he wasn't the only one was to , take some period of speech and in each band , develop a histogram . to get a decent histogram of these energies takes at least a few seconds really . but , mean you can do it with a smaller amount but it 's pretty rough . and , the nist standard method of determining signal to noise ratio is based on this .  no , no , it 's based on this method , this histogram method . you have a histogram . now , if you have signal and you have noise , you have these two bumps in the histogram , which you could approximate as two gaussians .  you have a mixture of two gaussians . right ? and you can use to figure out what it is . now you have this mixture of two gaussians , you n they are , and ,  you estimate what they are , and , this gives you what the signal is and what the noise e energy is in that band in the spectrum . and then you look over the whole thing and now you have a noise spectrum . hans guenter hirsch and others have used that method . and the other thing to do is which is more trivial and obvious is to , determine through magical means that , there 's no speech in some period , and then see what the spectrum is .  but , it 's that 's tricky to do . it has mistakes . and if you 've got enough time , this other method appears to be somewhat more reliable . a variant on that for just determining signal to noise ratio is to just , you can do a w a an iterative thing , like thing , to determine means only . it is still , but just determine the means only . don't worry about the variances . and then you just use those mean values as being the , signal to noise ratio in that band . not necessarily . cuz if you don't look into the future , right ? if you just  if you just if you you , a at the beginning you have some esti some guess and , it 's an interesting question . i wonder how they did do it ?  ","there 's a lot of different ways of computing the noise spectrum . not necessarily . cuz if you don't look into the future , ",
Bro010.C,"but what does what does alcatel do ? and france telecom . pretty stationary . the thing , e e y you 're talking about non stationary noise but that spectral subtraction is rarely is not gonna work really for non stationary noise ,  but it 's hard to but that 's hard to do .  think that what is wh what 's more common is that you 're going to be helped with r slowly varying or stationary noise . that 's what spectral subtraction will help with , practically speaking . if it varies a lot , to get a if to get a good estimate you need a few seconds of speech , even if it 's centered , right ? if you need a few seconds to get a decent estimate but it 's changed a lot in a few seconds , then it , i it 's problem . imagine e five hertz is the middle of the speech modulation spectrum , right ? imagine a jack hammer going at five hertz . good luck .    no , i understand it 's better to do but think that , for real noises wh what 's most likely to happen is that there 'll be some things that are relatively stationary where you can use one or another spectral subtraction thing and other things where it 's not stationary and you can always pick something that falls between your methods ,   but i don't know if , if sinusoidally , modul amplitude modulated noise is big problem in practice . that it 's   just cheat you 're saying , cheat .     but stationary right , the word "" stationary "" is has a very precise statistical meaning . but , in signal processing really what we 're talking about is things that change slowly , compared with our processing techniques . if you 're driving along in a car i would think that most of the time the nature of the noise is going to change relatively slowly . it 's not gonna stay absolute the same . if you check it out , five minutes later you may be in a different part of the road or whatever . but it 's i using the local characteristics in time , is probably going to work pretty but you could get hurt a lot if you just took some something from the beginning of all the speech , of , an hour of speech and then later they may be may be overly , complicated for this test but but , i don't know . but what you 're saying , makes sense , though . if possible you shouldn't you should make it , the center of the window . but we 're already having problems with these delay , delay issues .  we 'll have to figure ways without it .   you bet .  imagine that 's what they 're doing , right ? is they 're they 're probably looking in nonspeech sections ","but what does what does alcatel do ? and france telecom . y you 're talking about non stationary noise but that spectral subtraction is rarely is not gonna work really for non stationary noise , but it 's hard to ",
Bro010.C,"and getting some , does france telecom do this does france telecom do th do the same thing ? more or less ?    if we 're done with that ,  let 's see . we can talk about a couple other things briefly , just , things that we 've been chatting about but haven't made it into these meetings yet . you 're coming up with your quals proposal , and , wanna just give a two three minute summary of what you 're planning on doing ?  that , is a is one of the units in our neural network . that 's all it is . it 's a sig it 's a sigmoid , with weighted sum at the input , which you train by gradient descent . actually ,  was using to get the targets . you have this and gate what we were calling an and gate , but it 's a product rule thing at the output . and then he uses , i u and then feeding into that are i 'm there 's it 's an or at the output , isn't it ?  that 's the product . and then ,  then he has each of these and things . and ,  but they 're little neural units .  and , they have to have targets . and the targets come from it has a number of properties that i really liked . one is the going towards , using narrow band information for , ph phonetic features of some sort rather than just , immediately going for the typical sound units . another thing i like about it is that you t this thing is going to be trained explicitly trained for a product of errors rule , which is what , allen keeps pointing out that fletcher observed in the twenties , for people listening to narrow band that 's friday 's talk , and then , the third thing i like about it is , and we 've played around with this in a different way a little bit but it hasn't been our dominant way of operating anything , this issue of where the targets come from . in our case when we 've been training it multi band things , the way we get the targets for the individual bands is , that we get the phonetic label for the sound there and we say , "" we train every "" what this is saying is , that 's what our ultimate goal is or not ultimate but penultimate goal is getting these small sound units . but , along the way how much should we , what should we be training these intermediate things for ? because , we don't know that this is a particularly good feature . there 's no way , someone in the audience yesterday was asking , "" couldn't you have people go through and mark the individual bands and say where the where it was sonorant or not ? "" ","we can talk about a couple other things briefly , you 're coming up with your quals proposal , ",There were also some progress reports from group members working on other projects. 
Bro010.C,"but , having a bunch of people listening to critical band wide , chunks of speech trying to determine whether it 'd be impossible . it 's all gonna sound like sine waves to you , more or less .  not it 's g all g narrow band  i m it 's very hard for someone to a person to make that determination .  we don't really know how those should be labeled . it could sh be that you should , not be paying that much attention to , certain bands for certain sounds , in order to get the best result . what we have been doing there , just mixing it all together , is certainly much cruder than that . we trained these things up on the , the final label . now we have done experiments you 've probably done where you have , done separate , viterbis on the different  you 've done that . did that help that may or may t it that aspect of what he 's doing may or may not be helpful because in a sense that 's the same thing . you 're taking global information and determining what you how you should but this is , i th little more direct . and he 's look he 's just actually looking at , the confusions between sonorant and non sonorant . he hasn't applied it to recognition or if he did he didn't talk about it . it 's just and one of the concerns in the audience , actually , was that , the , he did a comparison to , our old foil , the nasty old standard recognizer with mel filter bank at the front , and h m ms , and forth . and , it didn't do nearly as especially in noise . but the one of the good questions in the audience was , but that wasn't trained for that . this use of a very smooth , spectral envelope is something that , has evolved as being generally a good thing for speech recognition but if you knew that what you were gonna do is detect sonorants or not sonorants and non sonorants is almost like voiced unvoiced , except that the voiced stops are also called "" obstruents "" .  it 's it 's but with the exception of the stops it 's the same as voiced unvoiced , right ?    if you knew you were doing that , if you were doing something say for a , vocoder , you wouldn't use the same features . you would use something that was sensitive to the periodicity and not just the envelope . and in that sense it was an unfair test .  think that the questioner was right . it was in that sense an unfair test . nonetheless , it was one that was interesting because , this is what we are actually using for speech recognition , these smooth envelopes . ",,
Bro010.C,"and this says that perhaps even , trying to use them in the best way that we can , that we ordinarily do , with , gaussian mixtures and h m ms and forth , you don't , actually do that on determining whether something is sonorant or not . which means you 're gonna make errors between similar sounds that are son sonorant or obstruent . the these same people ? i don't remember that . that would that 's you 're right , that 's exactly the question to follow up this discussion , is suppose you did that , got that right .    there 's a half dozen like that are now this was coming at it from a different angle but it 's a good way to start . these are things which , john felt that a , human annotator would be able to reliably mark . the things he felt would be difficult for a human annotator to reliably mark would be tongue position kinds of things .   but stress doesn't , fit in this thing of coming up with features that will distinguish words from one another , right ? it 's a good thing to mark and will probably help us ultimate with recognition but  but i either case you 'd write permit , right ? you 'd get the word right .  we 're g if we 're doing if we 're talking about transcription as opposed to something else  right .  but that 's this afternoon 's meeting .  we don't understand anything in this meeting .  that 's  that 's , a neat thing and and ,   that 's not an immediate problem , that we don't immediately have a lot of extra transcriber time . but , in the long term chuck is gonna continue the dialogue with john and , and , we 'll end up doing some  it 's an interesting way to go .  i say it like "" said int "" . it has a number of good things .  y you want to talk c two or three minutes about what we 've been talking about today and other days ? avendano .  there 's also this , echo cancellation that we 've been chasing ,  we have , and when we 're saying these digits now we do have a close microphone signal and then there 's the distant microphone signal . and you could as a baseline say , "" given that we have both of these , we should be able to do , a cancellation . "" that , we , essentially identify the system in between the linear time invariant system between the microphones and re and invert it , or cancel it out to some reasonable approximation through one method or another . that 's not a practical thing , if you have a distant mike , you don't have a close mike ordinarily , but we thought that might make also might make a good baseline . ","y you want to talk c two or three minutes about what we 've been talking about today and other days ? there 's also this , echo cancellation that we 've been chasing , and when we 're saying these digits now we do have a close microphone signal and then there 's the distant microphone signal . and you could as a baseline say , "" given that we have both of these , we should be able to do , a cancellation . "" that , we , essentially identify the system in between the linear time invariant system between the microphones and re and invert it , or cancel it out to some reasonable approximation ",There were also some progress reports from group members working on other projects. 
Bro010.C,"it still won't be perfect because there 's noise . but and then there are s there are single microphone methods that people have done for , for this de reverberation . do y do any references to any ? cuz i w i was w i lead him down a bad path on that . but . right .    the first paper on this is gonna have great references , tell already . it 's always good to have references , especially when reviewers read it or one of the authors and , feel they 'll "" you 're you 've r you cited me . ""  the oth the other thing , that dave was talking about earlier was , multiple mike things , where they 're all distant . there 's all this work on arrays , but the other thing is , what can we do that 's cleverer that can take some advantage of only two mikes , particularly if there 's an obstruction between them , as we have over there . an obstruction between them . it creates a shadow which is helpful . it 's part of why you have such good directionality with , with two ears even though they 're not several feet apart . for most people 's heads . that the the head , in the way , is really that 's what it 's for . it 's  it 's to separate the ears . that 's right ,     anyway , o k . that 's all we have this week . and , it 's digit time .    it 's there 's no real reason to write our names on here then , is there ? or do did any do we need the names for the other or ?      i didn't notice this . i 'm sitting here and i was about to read them too . it 's a , blank sheet of paper .   i 'll do my credit card number later .  ",,
Bro010.D,"yesterday yesterday morning on video conference .  to improve but the low f also we were thinking to , apply the spectral subtraction from ericsson and to change the contextual klt for lda . the contextual klt . klt klt , i 'm to change and use lda discriminative . but i don't know .  s  we was think  we no nnn we was thinking to do before after vad or we don't know exactly when it 's better . before after vad or and then  begin to work .   i don't remember .   it 's the same .  a dictionary .   i have not here the proposal . no . i do i have not here the proposal . ","yesterday morning on video conference . also we were thinking to , apply the spectral subtraction from ericsson and to change the contextual klt for lda . to change and use lda discriminative . ",
Bro010.E,"conference call . klt . pretty stationary ,     two , three , it can be shorter than that .  i 've talked to some of you already . but i 'm , looking into extending the work done by larry saul and john allen and mazin rahim . they have a system that 's , a multi band , system but their multi band is a little different than the way that we 've been doing multi band in the past , where where we 've been @ @ taking sub band features and i training up these neural nets and on phonetic targets , and then combining them some somehow down the line ,  they 're taking sub band features and , training up a detector that detects for , these phonetic features he presents a detector to detect sonorance . and what it is , it 's there 's at the lowest level , there it 's an or ga it 's an and gate . on each sub band you have several independent tests , to test whether there 's the existence of sonorance in a sub band . and then , it c it 's combined by a soft and gate . and at the higher level , for every if ,  the higher level there 's a soft or gate . if this detector detects the presence of sonorance in any of the sub bands , then the detect the or gate at the top says , "" this frame has evidence of sonorance . "" and these are all  the low level detectors are logistic regressions .  and the , the one o  right .  he uses , an algorithm to train up these parameters for the logistic regression . the    right , the  at each for each sub band there are several measures of snr and correlation .  and he said there 's like twenty of these per sub band .  and for every s every sub band , e you just pick ahead of time , "" i 'm going to have like five i independent logistic tests . "" and you initialize these parameters , in some way and use to come up with your training targets for a for the low level detectors . and then , once you get that done , you train the whole thing on maximum likelihood .  and h he shows that using this method to detect sonorance is it 's very robust compared to , to typical , full band gaussian mixtures estimations of sonorance . and ,  that 's just one detector . you can imagine building many of these detectors on different features . you get enough of these detectors together , then you have enough information to do , higher level discrimination , discriminating between phones and then you keep working your way up until you build a full recognizer . that 's the direction which i 'm thinking about going in my quals . ouch .  ","but i 'm , looking into extending the work done by larry saul and john allen and mazin rahim . they have a system that 's , a multi band , system but their multi band is a little different than the way that we 've been doing multi band in the past , where where we 've been @ @ taking sub band features and i training up these neural nets and on phonetic targets , and then combining them some somehow down the line , they 're taking sub band features and , training up a detector that detects for , these phonetic features and h he shows that using this method to detect sonorance is it 's very robust compared to , to typical , full band gaussian mixtures estimations of sonorance . that 's just one detector . you can imagine building many of these detectors on different features . you get enough of these detectors together , then you have enough information to do , higher level discrimination , discriminating between phones and then you keep working your way up until you build a full recognizer . that 's the direction which i 'm thinking about going in my quals . ",There were also some progress reports from group members working on other projects. 
Bro010.E,"forced alignment on the sub band labels ?  it helps for one or t one iteration but anything after that it doesn't help .  what t build other detectors on different phonetic features ?  let 's see ,   i d i don't know . e  w easiest thing would be to go do some voicing but that 's very similar to sonorance .       nasality .  placing   like a understanding application .  s ohala 's going to help do these , transcriptions of the meeting data ?      no ? ",,
Bro010.F,"ri    we 're interested in , methods for far mike speech recognition , mainly , methods that deal with the reverberation in the far mike signal .  one approach would be , say msg and plp , like was used in aurora one and , there are other approaches which actually attempt to remove the reverberation , instead of being robust to it like msg . and we 're interested in , comparing the performance of a robust approach like msg with these , speech enhancement or de reverber de reverberation approaches . and , it looks like we 're gonna use the meeting recorder digits data for that . o o   there was something that was done by , a guy named carlos , i forget his last name , who worked with hynek , who ,  who , it was like rasta in the sense that of it was , de convolution by filtering except he used a longer time window , like a second and the reason for that is rasta 's time window is too short to , include the whole , reverberation i don't you call it the reverberation response . i if you see wh if you see what the reverberation filter from my mouth to that mike is like it 's t got it 's too long in the time domain for the for the rasta filtering to take care of it . and , then there are a couple of other speech enhancement approaches which haven't been tried for speech recognition yet but have just been tried for enhancement , which , have the assumption that you can do lpc analysis of th of the signal you get at the far microphone and the , all pole filter that you get out of that should be good . it 's just the , excitation signal that is going to be distorted by the reverberation and you can try and reconstruct a better excitation signal and , feed that through the i all pole filter and get enhanced speech with reverberation reduced . ","we 're interested in , methods for far mike speech recognition , mainly , methods that deal with the reverberation in the far mike signal . one approach would be , say msg and plp , like was used in aurora one and , there are other approaches which actually attempt to remove the reverberation , instead of being robust to it like msg . and we 're interested in , comparing the performance of a robust approach like msg with these , speech enhancement or de reverber de reverberation approaches . ",There were also some progress reports from group members working on other projects. 
Bro011.A,"am i on ?  radio two .  radio two .  people say the strangest things when their microphones are on . everybody 's on ?  you guys had a meeting with with hynek which i unfortunately had to miss .  and somebody and chuck you weren't there either , the you were there ?  everybody knows what happened except me . somebody should tell me .   what was the w what was the downsampling problem again ? i forget .  depends what it 's frequency characteristic is , you could do a stricter one .   was there any conclusion about that ? i see .  again this is th this is the downsampling of the the feature vector stream and guess the lda filters they were doing do have let 's see , the feature vectors are calculated every ten milliseconds  the question is how far down they are at fifty hertz .  at twenty five hertz since they 're downsampling by two . does anybody the frequency characteristic is ?       try what ?  right .   g the key thing for me is figuring out how to better coordinate between the two sides cuz because was talking with hynek about it later and the had the sense that neither group of people wanted to bother the other group too much . and i don't think anybody is , closed in their thinking or are unwilling to talk about things but that you were waiting for them to tell you that they had something for you and that and expected that they would do certain things and they were sor they didn't wanna bother you and they were waiting for you and we ended up with this thing where they were filling up all of the possible latency themselves , and they just had hadn't thought of that .  it 's true that no one really thought about that this latency thing would be such a strict issue in the other  then they couldn't . i see . just talk more .   there 's alright . we should just mean you 're bus other than that you folks are busy doing all the things that you 're trying that we talked about before right ? and this machines are busy and you 're busy and    let 's let 's , that as we said before that one of the things that we 're imagining is that there will be in the system we end up with there 'll be something to explicitly do something about noise in addition to the other things that we 're talking about and that 's probably the best thing to do . and there was that one email that said that it sounded like things looked very promising up there in terms of think they were using ericsson 's approach and in addition to they 're doing some noise removal thing , right ?       when you say you don't have a result yet it 's just that it 's in process ","you guys had a meeting with with hynek which i unfortunately had to miss . everybody knows what happened except me . was there any conclusion about that ? g the key thing for me is figuring out how to better coordinate between the two sides was talking with hynek about it later and the had the sense that neither group of people wanted to bother the other group too much . but that you were waiting for them to tell you that they had something for you and they were waiting for you and we ended up with this thing where they were filling up all of the possible latency themselves , just talk more . let 's let 's , that as we said before that one of the things that we 're imagining is that there will be in the system we end up with there 'll be something to explicitly do something about noise in terms of think they were using ericsson 's approach ","This included a recap of a meeting with one of the members of their research partner OGI. There were progress reports from group members working on echo cancellation, acoustic feature detection, and HTK optimization, along with discussion of many issues arising from this topics. The Berkeley Meeting Recorder Group met to discuss their recent progress. "
Bro011.A,"or that you it finished and it didn't get a good result ?      suggest actually now we sorta move on and hear what 's what 's happening in other areas like what 's happening with your investigations about echos and on .    haven't read it in a while 'm not gonna be too much help unless i read it again ,   the you , and then you 're also gonna be doing this echo cancelling between the close mounted and the the what we 're calling a cheating experiment of sorts between the distant   f delegate . that 's good . it 's good to delegate . great . great . actually he should i wonder who else is it 's dan ellis is going to be doing different cancellation . one of the things that people working in the meeting task wanna get at is they would like to have cleaner close miked recordings . this is especially true for the lapel but even for the close miked cases we 'd like to be able to have other sounds from other people and forth removed from when someone isn't speaking you 'd like the part where they 're not speaking to actually be what they 're talking about doing is using ec echo cancellation like techniques . it 's not really echo but just taking the input from other mikes and using an adaptive filtering approach to remove the effect of that other speech .  what was it , there was some point where eric or somebody was speaking and he had lots of silence in his channel and i was saying something to somebody else which was in the background and it was not it was recognizing my words , which were the background speech on the close mike . yes . you it was you i was    they would like clean channels . and for that that purpose they 'd like to pull it out . think dan ellis or somebody who was working with him was going to work on that .   right ? and don't know if we 've talked lately about the plans you 're developing that we talked about this morning don't remember if we talked about that last week or not , but just a quick reprise of what we were saying this morning .  but that 's all that 's is a certainly relevant study and , what are the features that they 're finding . we have this problem with the overloading of the term "" feature ""  what are the variables , what we 're calling this one , what are the variables that they 're found finding useful  for right . and that 's certainly one thing to do and we 're gonna try and do something more f more fine than that but    guess what , i was trying to remember some of the things we were saying , do you ha still have that ?  there 's those that  ",suggest actually now we sorta move on and hear what 's what 's happening in other areas like what 's happening with your investigations about echos and on . and don't know if we 've talked lately about the plans you 're developing that we talked about this morning but that 's all that 's is a certainly relevant study ,"There were progress reports from group members working on echo cancellation, acoustic feature detection, and HTK optimization, along with discussion of many issues arising from this topics. The Berkeley Meeting Recorder Group met to discuss their recent progress. "
Bro011.A,"some of the issues we were talking about was in j just getting a good handle on what "" good features "" are and and the other thing you were talking about is where we get the targets from . mean , there 's these issues of what are the variables that you use and do you combine them using the soft "" and or "" or you do something , more complicated and then the other thing was where do you get the targets from ? the initial thing is just the obvious that we 're discussing is starting up with phone labels from somewhere and then doing the transformation . but then the other thing is to do something better and why don't you tell us again about this database ? this is the and then tell them to talk naturally ?  you could go to these parlors and you could , have , reduced rates if you can do the measurements .  be and help science .  do but you mar when was mark randolph there , or ? he 's he 's at motorola now .    the only hesitation i had about it since , haven't see the data is it sounds like it 's continuous variables and a bunch of them . and i don't know how complicated it is to go from there what you really want are these binary labels , and just a few of them . and there 's a trivial mapping if you wanna do it and it 's e but it i worry a little bit that this is a research project in itself , whereas if you did something instead that like having some manual annotation by linguistics students , this would there 'd be a limited s set of things that you could do a as per our discussions with john before but the things that you could do , like nasality and voicing and a couple other things you probably could do reasonably and then there would it would really be this binary variable . course then , that 's the other question is do you want binary variables .  the other thing you could do is boot trying to get those binary variables and take the continuous variables from the data itself there , but i 'm not guess you could ,  anyway that 's that 's another whole direction that cou could be looked at . in general it 's gonna be for new data that you look at , it 's gonna be hidden variable because we 're not gonna get everybody sitting in these meetings to wear the pellets and   wh where this fits into the rest in my mind , is that we 're looking at different ways that we can combine different kinds of rep front end representations in order to get robustness under difficult or even , typical conditions . and part of it , this robustness , seems to come from multi stream or multi band sorts of things ","mean , there 's these issues of what are the variables that you use and do you combine them using the soft "" and or "" or you do something , more complicated and why don't you tell us again about this database ? when was mark randolph there , or ? he 's he 's at motorola now . the only hesitation i had about it since , haven't see the data is it sounds like it 's continuous variables and a bunch of them . i don't know how complicated it is to go from there what you really want are these binary labels , and just a few of them . and there 's a trivial mapping if you wanna do it and it 's e but it i worry a little bit that this is a research project in itself , whereas if you did something instead that like having some manual annotation by linguistics students , this would there 'd be a limited s set of things that you could do a as per our discussions with john before course then , that 's the other question is do you want binary variables . ","There were progress reports from group members working on echo cancellation, acoustic feature detection, and HTK optimization, along with discussion of many issues arising from this topics. "
Bro011.A,"and saul seems to have a reasonable way of looking at it , at least for one articulatory feature . the question is can we learn from that to change some of the other methods we have , since one of the things that 's about what he had was that it the decision about how strongly to train the different pieces is based on reasonable criterion with hidden variables rather than just assuming that you should train e every detector with equal strength towards it being this phone or that phone . right ? it he 's got these he "" and 's "" between these different features . it 's a soft "" and "" , but in principle you wanna get a strong concurrence of all the different things that indicate something and then he "" or 's "" across the different soft "" or 's "" across the different multi band channels . and the weight the target for the training of the "" and "" "" and ' ed "" things is something that 's kept as a hidden variable , and is learned with whereas what we were doing is taking the phone target and then just back propagating from that which means that it 's it could be that for a particular point in the data you don't want to train a particular band train the detectors for a particular band . you wanna ignore that band , cuz that 's a ban band is a noisy measure . and we don't we 're still gonna try to train it up . in our scheme we 're gonna try to train it up to do as as it can at predicting . that 's not the right thing to do . at the tail end , he has to 's where it 's sonorant . but he 's but what he 's but what he 's not training up what he doesn't depend on as truth is guess one way of describing would be if a sound is sonorant is it sonorant in this band ? is it sonorant in that band ? is it sonorant in that band ? i it 's hard to even answer that what you really mean is that the whole sound is sonorant .  then it comes down to , to what extent should you make use of information from particular band towards making your decision . and we 're making in a sense this hard decision that you should use everything with equal strength . and because in the ideal case we would be going for posterior probabilities , if we had enough data to really get posterior probabilities and if the if we also had enough data that it was representative of the test data then we would be doing the right thing to train everything as hard as we can . but this is something that 's more built up along an idea of robustness from the beginning ",,
Bro011.A,"and you don't necessarily want to train everything up towards the    we ha we have a iterative training because we do this embedded viterbi , there is some something that 's suggested , based on the data but it 's not it s doesn't seem like it 's quite the same , cuz of this cuz then whatever that alignment is , it 's that for all bands . no , that 's not quite right , we did actually do them separate tried to do them separately that would be a little more like what he did .  but it 's still not quite the same because then it 's setting targets based on where you would say the sound begins in a particular band . where he 's this is not a labeling per se . might be closer if we did a soft target embedded neural net training like we 've done a few times the forward do the forward calculations to get the gammas and train on those .  what 's next ?  you 're playing ? you 're playing ? what which test set was this ?        it 's not uncommon you do worse on long word on short words than long words anyway just because you 're accumulating more evidence for the longer word , but .      lots of silence . are the sp 's optional ? skip them ?  i see .   that as much as you can , it 's good to d not do anything really tricky . not do anything that 's really finely tuned , but just you t you i z the premise is you have a good person look at this for a few weeks and what do you come up with ? and could be . right . and that , at the moment that 's not the limitation ,  i what you were gonna say i but which i was thinking was where did six come from ? probably came from the same place eighteen came from .   that 's another parameter , right ? that you really want three or nine or right .   but right now again the idea is doing just very simple things how much better can you make it ? and since they 're only simple things there 's nothing that you 're gonna do that is going to blow up the amount of computation  if you found that nine was better than six that would be o k , actually . doesn't have to go down .  just work with the models ,     what 's your plan for you guys ' plan for the next week is just continue on these same things we 've been talking about for aurora and   we have a big list . you have a big list of things to do .  that 's good . that after all of this confusion settles down in another some point a little later next year there will be some standard and it 'll get out there ",what 's next ? your plan for you guys ' plan for the next week is just continue on these same things we 've been talking about for aurora and you have a big list of things to do . that 's good . ,"There were progress reports from group members working on echo cancellation, acoustic feature detection, and HTK optimization, along with discussion of many issues arising from this topics. The Berkeley Meeting Recorder Group met to discuss their recent progress. "
Bro011.A,and hopefully it 'll have some effect from something that has been done by our group of people but e even if it doesn't there 's go there 'll be standards after that .   guess we 're done . ,,
Bro011.B,"blow into it , it works really i was there . with hynek ?  the what we talked about yesterday ? that was actually my i was wearing the lapel and you were sitting next to me , and i only said one thing but you were talking and it was picking up all your words . what about the that mirjam has been doing ? and s shawn ,  they 're training up nets to try to recognize these acoustic features ? i see .  and their targets are based on canonical mappings of phones to acoustic f features . what does what did larry saul use for it was the sonorant detector , right ? how did he h how did he do that ? wh what was his detector ?     how did he combine all these features ? what r classifier did he  right . you were talking about that , i see .  pierced tongues and  you could just mount it to that and they wouldn't even notice . weld it . zzz .  i that 's right . you could what you could do is you could sell little rings and with embedded transmitters in them and things and   there 's a bunch of data that l around , that people have done studies like that w way back right ? can't remember where wisconsin or someplace that used to have a big database of  i remember there was this guy at a t andt , randolph ? or r what was his name ? do you remember that guy ? researcher at a t andt a while back that was studying , trying to do speech recognition from these kinds of features . i can't remember what his name was . dang . now i 'll think of it . that 's interesting . mark randolph . is he ?   i can't remember exactly what he was using , now . but i know remember it had to do with positional parameters and trying to m do speech recognition based on them .    could you cluster the just do some clustering ? bin them up into different categories and you 're talking about using that data to get  instead of using canonical mappings of phones . you 'd use that data to give you what the true mappings are for each phone ? i see .  he doesn't have  he doesn't have to have truth marks or ho   i see . where did he get his his tar his high level targets about what 's sonorant and what 's not ?  using timit ? or using   i could say a little bit about w 've been playing with . i  yes , i 'm playing . wanted to do this experiment to see what happens if we try to improve the performance of the back end recognizer for the aurora task and see how that affects things . and had this sent around last week a this plan i had for an experiment , ","they 're training up nets to try to recognize these acoustic features ? that people have done studies like that w way back can't remember where wisconsin or someplace that used to have a big database of researcher at a t andt a while back that was studying , trying to do speech recognition from these kinds of features . but i know remember it had to do with positional parameters and trying to m do speech recognition based on them . i could say a little bit about w 've been playing with . wanted to do this experiment to see what happens if we try to improve the performance of the back end recognizer for the aurora task and see how that affects things . ","There were progress reports from group members working on echo cancellation, acoustic feature detection, and HTK optimization, along with discussion of many issues arising from this topics. "
Bro011.B,"this matrix where i would take the the original system . there 's the original system trained on the mel cepstral features and then com and then optimize the b htk system and run that again . look at the difference there and then do the same thing for the icsi ogi front end . this is that i looked at ? 'm looking at the italian right now . as far as i 've gotten is i 've been able to go through from beginning to end the full htk system for the italian data and got the same results that that stephane had . started looking to and now i 'm lookin at the point where i wanna should i change in the htk back end in order to try to to improve it .  one of the first things of was the fact that they use the same number of states for all of the models and went on line and i found a pronunciation dictionary for italian digits and just looked at , the number of phones in each one of the digits . the canonical way of setting up a an system is that you use three states per phone and then the total number of states for a word would just be , the number of phones times three . and when i did that for the italian digits , i got a number of states , ranging on the low end from nine to the high end , eighteen . now you have to really add two to that because in htk there 's an initial null and a final null when they use models that have eighteen states , there 're really sixteen states . they 've got those initial and final null states . and their guess of eighteen states seems to be pretty matched to the two longest words of the italian digits , the four and five which according to my , off the cuff calculation , should have eighteen states each . and they had sixteen . that 's pretty close . but for the most of the words are sh much shorter . the majority of them wanna have nine states . and theirs are s twice as long . my guess and then if you i printed out a confusion matrix for the matched case , and it turns out that the longest words are actually the ones that do the best . my guess about what 's happening is that if you assume a fixed the same amount of training data for each of these digits and a fixed length model for all of them but the actual words for some of them are half as long you really have , half as much training data for those models . because if you have a long word and you 're training it to eighteen states , you 've got you 've got the same number of gaussians , you 've gotta train in each case , ","and then com and then optimize the b htk system and run that again . look at the difference there and then do the same thing for the icsi ogi front end . 'm looking at the italian right now . one of the first things of was the fact that they use the same number of states for all of the models and just looked at , the number of phones in each one of the digits . and when i did that for the italian digits , i got a number of states , ranging on the low end from nine to the high end , eighteen . and their guess of eighteen states seems to be pretty matched to the two longest words of the italian digits , but for the most of the words are sh much shorter . the majority of them wanna have nine states . and theirs are s twice as long . and it turns out that the longest words are actually the ones that do the best . ",
Bro011.B,"but for the shorter words , the total number of frames is actually half as many . it could be that , for the short words there 's because you have many states , you just don't have enough data to train all those gaussians . 'm going to try to create more word specific prototype h m ms to start training from .  'll , the next experiment i 'm gonna try is to just create models that seem to be more w matched to my guess about how long they should be . and as part of that wanted to see how the how these models were coming out , what w when we train up th the model for "" one "" , which wants to have nine states , what is the what do the transition probabilities look like in the self loops , look like in those models ? and talked to andreas and he explained to me how you can calculate the expected duration of an just by looking at the transition matrix and wrote a little matlab script that calculates that and 'm gonna print those out for each of the words to see what 's happening , how these models are training up , the long ones versus the short ones . i d i did quickly , i did the silence model and that 's coming out with about one point two seconds as its average duration and the silence model 's the one that 's used at the beginning and the end of each of the string of digits .  and the s p model , which is what they put in between digits , i haven't calculated that for that one yet , but they their model for a whole digit string is silence digit , sp , digit , sp blah blah and then silence at the end . and i have to look at that , but i 'm not that they are . now the one thing about the s p model is really it only has a single s emitting state to it . if it 's not optional , it 's not gonna hurt a whole lot and it 's tied to the center state of the silence model it 's not its own it doesn't require its own training data , it just shares that state . it , it 's pretty good the way that they have it set up , but i wanna play with that a little bit more . i 'm curious about looking at , how these models have trained and looking at the expected durations of the models and i wanna compare that in the matched case f to the unmatched case , and see if you can get an idea of just from looking at the durations of these models , what 's happening .     and hynek , when i wa told him about this , he had an interesting point , ","'m going to try to create more word specific prototype h m ms to start training from . 'll , the next experiment i 'm gonna try is to just create models that seem to be more w matched to my guess about how long they should be . ",
Bro011.B,"and that was th the final models that they end up training up have probably something on the order of six gaussians per state . they 're fairly , hefty models . and hynek was saying that probably in a real application , you wouldn't have enough compute to handle models that are very big or complicated . what we may want are simpler models . and compare how they perform to that . but it depends on what the actual application is and it 's really hard to your limits are in terms of how many gaussians you can have .   right .  one thing if i start reducing the number of states for some of these shorter models that 's gonna reduce the total number of gaussians . in a sense it 'll be a simpler system .   right . right .   i really wasn't even gonna play with that part of the system yet , i was just gonna change the t just look at the length of the models and just see what happens .  does anybody know how to run matlab in batch mode like you c send it s a bunch of commands to run and it gives you the output . is it possible to do that ?  octave .   great .  i was going crazy trying to do that . great ! if it 'll do like a lot of the basic matrix and vector that 's perfect . great ! ",,
Bro011.C," radio four .   alright . first we discussed about some of the points that i was addressing in the mail i sent last week .   about the the downsampling problem . and about the f the length of the filters and  we had the fact that there is no low pass filtering before the downsampling .  there is because there is lda filtering but that 's perhaps not the best w m    we discussed about this , about the try it "" .      we don't have yet  we should have a look first at , perhaps , the modulation spectrum . there is this , there is the length of the filters . the i this idea of trying to find filters with shorter delays . we started to work with this .  and the third point was the the on line normalization where , the recursion f recursion for the mean estimation is a filter with some delay and that 's not taken into account right now .  and there again , for this , the conclusion of hynek was , "" we can try it but ""  try to take into account the delay of the recursion for the mean estimation .  and this we 've not worked on this yet .  and while discussing about these lda filters , some i issues appeared , like the fact that if we look at the frequency response of these filters it 's we don't know really what 's the important part in the frequency response and there is the fact that in the very low frequency , these filters don't really remove a lot . compared to the standard rasta filter . and that 's probably a reason why , on line normalization helps because it , it removed this mean . but perhaps everything could should be could be in the filter , the mean normalization and    that was that 's all we discussed about . we discussed about good things to do also generally good to do for the research . and this was this lda tuning perhaps and hynek proposed again to his traps ,       but .     i don't happened really , but it 's also the time constraints . because , we discussed about that about this problem and they told us "" we will do all that 's possible to have enough space for a network "" but then , perhaps they were too short with the time and  but there was also problem perhaps a problem of communication .  now we will try to slikes and send mails . u s o        we 're will start to do this also . carmen is just looking at the ericsson code . and     he was the guy that was using is it the guy that was using the pattern of pressure on the tongue or ? what    we can try to have some new baseline for next week perhaps . with all these minor things modified . and then do other things , ","first we discussed about some of the points that i was addressing in the mail i sent last week . about the the downsampling problem . and about the f the length of the filters try it "" . we should have a look first at , perhaps , the modulation spectrum . the i this idea of trying to find filters with shorter delays . we started to work with this . and the third point was the the on line normalization where , the recursion f recursion for the mean estimation is a filter with some delay for this , the conclusion of hynek was , "" we can try it but "" that was that 's all we discussed about . but there was also problem perhaps a problem of communication . now we will try to carmen is just looking at the ericsson code . is it the guy that was using the pattern of pressure on the tongue we can try to have some new baseline for next week perhaps . with all these minor things modified . ",This included a recap of a meeting with one of the members of their research partner OGI. 
Bro011.C,"play with the spectral subtraction , and retry the msg and things like that . big list ? what is octave it 's a free software ?  and it does the same syntax and everything  like matlab , or ? ",,
Bro011.D,"channel four . test .  today 's system on  we modif i modified it  modifying i studied barry 's sim code , more or less . to take @ @ the first step the spectral subtraction . and we have some the feature for italian database and we will try with this feature with the filter to find the result . but we haven't result until this moment . but we are working in this also and try another type of spectral subtraction , i don't no . no , no n we have do the experiment only have the feature but the experiment have we have not make the experiment and will be good result or bad result , we don't know . it 's my i know this is mine here . ",i modified it to take @ @ the first step the spectral subtraction . but we haven't result until this moment . but we are working in this also ,
Bro011.E,"hello ?  hi ? hello ?  continuing to extend  right . right . right .   f right , and he doesn't have to have hard labels . right . for the full band . right . from canonical mappings at first and then it 's unclear using timit right , right . and then he does some fine tuning for special cases .  mike tried it and he says it 's impossible he went to octave . octave is the unix clone of matlab which you can batch .   what 's that ? octave ? it 's it 's free . we have it here r running somewhere .  it 's a little behind , it 's the same syntax but it 's a little behind in that matlab went to these like you can have cells and you can implement object oriented type things with matlab . octave doesn't do that yet , think you , octave is kinda like matlab four point something or . the basic right .   ",continuing to extend ,"There were progress reports from group members working on echo cancellation, acoustic feature detection, and HTK optimization, along with discussion of many issues arising from this topics. "
Bro011.F,"channel b .  haven't started writing the test yet , i 'm meeting with adam today and he 's going t show me the scripts he has for running recognition on mee meeting recorder digits . also haven't got the code yet , i haven't asked hynek for the for his code yet . cuz i looked at avendano 's thesis and i don't really understand what he 's doing yet but it sounded like the channel normalization part of his thesis was done in a bit of i don't the word is , a bit of a rough way it sounded like he he it wasn't really fleshed out and he did something that was interesting for the test situation but i 'm not if it 's what i 'd wanna use have to read it more , i don't really understand what he 's doing yet . 'm ho right . or i 'm hoping espen will do it .  u he 's at least planning to do it for the cl close mike cross talk and just take whatever setup he has and use it .  although ","haven't started writing the test yet , i 'm meeting with adam today and he 's going t show me the scripts he has for running recognition on mee meeting recorder digits . i haven't asked hynek for the for his code yet . cuz i looked at avendano 's thesis and i don't really understand what he 's doing yet but it sounded like the channel normalization part of his thesis was done in a bit of i don't the word is , a bit of a rough way he it wasn't really fleshed out and he did something that was interesting for the test situation but i 'm not if it 's what i 'd wanna use i don't really understand what he 's doing yet . ","There were progress reports from group members working on echo cancellation, acoustic feature detection, and HTK optimization, along with discussion of many issues arising from this topics. "
Bro012.A,"had some interesting mail from dan ellis . actually , he redirected it to everybody also the pda mikes have a big bunch of energy at five hertz  where this came up was that was showing off these wave forms that we have on the web and just hadn't noticed this , but that the major , major component in the wave in the second wave form in that pair of wave forms is actually the air conditioner .   i have to be more careful about using that as a as a good illustration , it 's not , of of the effects of room reverberation . it is isn't a bad illustration of the effects of room noise . on some mikes but  and then we had this other discussion about whether this affects the dynamic range , cuz i know , although we start off with thirty two bits , you end up with sixteen bits and are we getting hurt there ? but dan is pretty confident that we 're not , that quantization error is not is still not a significant factor there .  there was a question of whether we should change things here , whether we should change a capacitor on the input box for that or whether we should right . but then i had some other thing discussions with him and the feeling was once we start monk monkeying with that , many other problems could ha happen . and additionally we already have a lot of data that 's been collected with that ,  a simple thing to do is he has a i forget if it this was in that mail or in the following mail , but he has a simple filter , a digital filter that he suggested . we just run over the data before we deal with it . the other thing that i don't know the answer to , but when people are using feacalc here , whether they 're using it with the high pass filter option or not . and i don't know if anybody knows . but .  when we 're doing all these things using our software there is if it 's based on the rasta plp program , which does both plp and rasta plp then there is an option there which then comes up through to feacalc which allows you to do high pass filtering and in general we like to do that , because of things like this and it 's pretty it 's not a very severe filter . doesn't affect speech frequencies , even pretty low speech frequencies , but it 's  i don't know i wrote this a while ago something like that .  there 's some effect above twenty but it 's it 's mild . it probably there 's probably some effect up to a hundred hertz but it 's pretty mild . i don't know in the strut implementation of the is there a high pass filter or a pre emphasis in the ","had some interesting mail from dan ellis . where this came up was that was showing off these wave forms that we have on the web and just hadn't noticed this , but that the major , major component in the wave in the second wave form in that pair of wave forms is actually the air conditioner . i have to be more careful about using that as a as a good illustration , it 's not , of of the effects of room reverberation . it is isn't a bad illustration of the effects of room noise . on some mikes the other thing that i don't know the answer to , but when people are using feacalc here , whether they 're using it with the high pass filter option or not . when we 're doing all these things using our software there is and it 's pretty it 's not a very severe filter . doesn't affect speech frequencies , ","The Meeting Recorder group at Berkeley met to discuss recent progress. There was also concern over overlap of work with partners OGI, and a lack of a good example of room reverberation for demonstrations. "
Bro012.A,"we want to go and check that in i for anything that we 're going to use the p d a mike for . he says that there 's a pretty good roll off in the pzm mikes we don't need to worry about them one way or the other but if we do make use of the cheap mikes , we want to be to do that filtering before we process it . and then again if it 's depending on the option that the our software is being run with , it 's quite possible that 's already being taken care of . but i also have to pick a different picture to show the effects of reverberation .  no .   if they made output they were they were , they were but . it was since i was talking about reverberation and showing this thing that was noise , it wasn't a good match , but it certainly was still an indication of the fact that you get noise with distant mikes . it 's just not a great example because not only isn't it reverberation but it 's a noise that we definitely to do . it doesn't take deep a new bold new methods to get rid of five hertz noise ,  but . it was a bad example in that way , but it 's it still is it 's the real thing that we did get out of the microphone at distance , it wasn't it w wasn't wrong it was inappropriate . but someone noticed it later pointed it out to me , and i went "" man . why didn't i notice that ? ""  think we 'll change our picture on the web , when we 're @ @ . one of the things i was i was trying to think about what 's the best way to show the difference an and i had a couple of thoughts one was , that spectrogram that we show is o k , but the eyes and the brain behind them are good at picking out patterns from noise that in first glance you look at them it doesn't seem like it 's that bad because there 's many features that are still preserved . one thing to do might be to just take a piece of the spec of the spectrogram where you can see that something looks different , an and blow it up , and have that be the part that 's just to show as  i some things are going to be hurt . another , i was thinking of was taking some spectral slices , like like we look at with the recognizer , and look at the spectrum or cepstrum that you get out of there , and the the reverberation does make it does change that . and that would be more obvious .  all the recognizers look at frames . they look at look at a it 's ,  ","we want to go and check that in i for anything that we 're going to use the p d but if we do make use of the cheap mikes , we want to be to do that filtering before we process it . since i was talking about reverberation and showing this thing that was noise , it wasn't a good match , think we 'll change our picture on the web , when we 're @ @ . another , i was thinking of was taking some spectral slices , and look at the spectrum or cepstrum that you get out of there , all the recognizers look at frames . ",
Bro012.A,"at one point in time or twenty over twenty milliseconds you have a spectrum or a cepstrum . that 's what i meant by a slice .  and if you look at right . that 's why i saying either either spectrum or cepstrum but you wanna i see .  that would be lovely ,   or i could just add them up and get a different total .  what else wh what 's what else is going on ? cuz we haven't wanted to move it . we could move us , and . but it 's not wer worse and it 's better latency , right ?   the test would be if you then tried it on one of the other test sets , if it was right . this was italian , right ? then if you take your changes and then     a tenth of a per cent .    what 's what are according to the rules what are we supposed to do about the transition probabilities ? are they supposed to be point five or point six ? point it 's supposed to be point six . but not allowed ?    yes .  and that says that we could have lots more parameters actually . cuz at forty thou you could have  easily four times as many parameters .    right .   right .  how 's it going on the you did some things . they didn't improve things in a way that convinced you 'd substantially improved anything . but they 're not making things worse and we have reduced latency , right ?  they do improvement in terms of accuracy ? rather than word error rate ?   if you have ten percent error and you get five percent absolute improvement then that 's fifty percent . what you 're saying then is that if it 's something that has a small word error rate , then even a relatively small improvement on it , in absolute terms , will show up as quite large in this . is that what you 're saying ? yes .  but that 's it 's the notion of relative improvement . word error rate .   no . that 's why i 've been saying we should be looking at word error rate and not at accuracies . it 's we probably should have standardized on that all the way through . it 's just  but you 're but when you look at the numbers , your sense of the relative size of things is quite different . if you had ninety percent correct and five percent , five over ninety doesn't look like it 's a big difference , but five over ten is big . just when we were looking at a lot of numbers and getting sense of what was important .   what 's a little bit ? like  it was actually updated . jeff updated it some years ago and cleaned it up made some things better in it .  i 'm it 's not that different ","at one point in time or twenty over twenty milliseconds you have a spectrum or a cepstrum . but it 's not wer worse and it 's better latency , what 's what are according to the rules what are we supposed to do about the transition probabilities ? and that says that we could have lots more parameters actually . they do improvement in terms of accuracy ? rather than word error rate ? if you have ten percent error and you get five percent absolute improvement then that 's fifty percent . what you 're saying then is that if it 's something that has a small word error rate , then even a relatively small improvement on it , in absolute terms , will show up as quite large in this . but that 's it 's the notion of relative improvement . that 's why i 've been saying we should be looking at word error rate and not at accuracies . we probably should have standardized on that all the way through . but you 're but when you look at the numbers , your sense of the relative size of things is quite different . ",
Bro012.A,"but he he was a little more rigorous , as i recall . worse . out of what ? s  that 's six point th  we are getting hurt somewhat . and is that wh what do what piece you 've done several changes here .  do what pie  but you these degradations you were talking about were on the matched case do the does the new filter make things better or worse for the other cases ? doesn't hurt , but doesn't get a little better , no . guess the argument one might make is that , "" if you looked at one of these cases and you jiggle something and it changes then you 're not quite what to make of it . but when you look across a bunch of these and there 's some pattern ,  here 's all the if in all these different cases it never gets better , and there 's significant number of cases where it gets worse , then you 're probably hurting things , i would say . mean at the very least that would be a reasonably prediction of what would happen with a different test set , that you 're not jiggling things with . guess the question is if you can do better than this . if you can if we can approximate the old numbers while still keeping the latency down .  what i was asking , though , is are what 's the level of communication with the o g i gang now , about this and    is there any further discussion about this idea of having some source code control ? i see .  sounds like a great idea but that he 's saying people are scrambling for a eurospeech deadline . but that 'll be done in a week . after this next one .   anybo anybody in the in this group do doing anything for eurospeech ? or , is that what is that right .  for for eurospeech ?  a special dispensation . that 's great . aalborg aalborg  the deadline when 's the deadline ? when 's the deadline ? that 's great ! it 's great . we should definitely get something in for that . but on meeting digits , there 's    that you could certainly start looking at the issue but think it 's probably , on s from what stephane is saying , it 's unlikely to get active participation from the two sides until after they 've  good .  dave , the other thing , actually , is this business about this wave form . you and talk a little bit at some point about coming up with a better demonstration of the effects of reverberation for our web page , cuz the actually the  it made a good audio demonstration because when we could play that clip the really obvious difference is that you can hear two voices and in the second one and only hear  no , it sound it sounds pretty reverberant , ","we are getting hurt somewhat . do the does the new filter make things better or worse for the other cases ? doesn't hurt , but doesn't get a little better , what i was asking , though , is are what 's the level of communication with the o g i gang now , about this is there any further discussion about this idea of having some source code control ? sounds like a great idea but that he 's saying people are scrambling for a eurospeech deadline . but that 'll be done in a week . after this next one . that you could certainly start looking at the issue but think it 's probably , on s from what stephane is saying , it 's unlikely to get active participation from the two sides until after they 've dave , the other thing , actually , is this business about this wave form . you and talk a little bit at some point about coming up with a better demonstration of the effects of reverberation for our web page , it made a good audio demonstration because when we could play that clip the really obvious difference is that you can hear two voices and in the second one and only hear ",
Bro012.A,"but you can't when you play it back in a room with a big room , nobody can hear that difference really . they hear that it 's lower amplitude and they hear there 's a second voice , but that actually that makes for a perfectly good demo because that 's a real obvious thing , that you hear two voices .  that 's but for the visual , just , i 'd like to have the spectrogram again , because you 're you 're visual abilities as a human being are good you can pick out you look at the good one , you look at the cru the screwed up one , and you can see the features in it without trying to @ @  right . but you have to if you look at it closely , you see "" here 's a place where this one has a big formant formant maj major formants here are moving quite a bit . "" and then you look in the other one and they look practically flat . mean you could that 's why i was thinking , in a section like that , you could take a look at just that part of the spectrogram and you could say "" this really distorted it quite a bit . "" right . right . but it 's    there are clearly are spectral effects . since you 're getting all this indirect energy , then a lot of it does have reduced high frequencies . but the other thing is the temporal courses of things really are changed , and we want to show that , in some obvious way . the reason i put the wave forms in there was because they do look quite different . and thought "" this is good . "" but  after they were put in there i didn't really look at them anymore , cuz they were different . want something that has a is a more interesting explanation for why they 're different .  something like that .  the other thing that we had in there that i didn't like was that the most obvious characteristic of the difference when you listen to it is that there 's a second voice , and the the cuts that we have there actually don't correspond to the full wave form . it 's just the first there was something where he was having some trouble getting much in , or . i forget the reason behind it . but it 's it 's the first six seconds of it and it 's in the seventh or eighth second where @ @ the second voice comes in . we would like to actually see the voice coming in , too , since that 's the most obvious thing when you listen to it .         normalizes the variance . what 's the rationale ? because everything if you have a system based on gaussians , everything is based on means and variances . ","but you can't when you play it back in a room with a big room , nobody can hear that difference really . but for the visual , just , i 'd like to have the spectrogram again , the other thing that we had in there that i didn't like was that the most obvious characteristic of the difference when you listen to it is that there 's a second voice , and the the cuts that we have there actually don't correspond to the full wave form . but it 's it 's the first six seconds of it and it 's in the seventh or eighth second where @ @ the second voice comes in . we would like to actually see the voice coming in , too , ",
Bro012.A,"if there 's an overall reason it 's like if you were doing image processing and in some of the pictures you were looking at , there was a lot of light and in some , there was low light , you would want to adjust for that in order to compare things . and the variance is just like the next moment ,  what if one set of pictures was taken that throughout the course it was went through daylight and night ten times , another time it went thr is , how much vari or no . better example would be how much of the light was coming in from outside rather than artificial light . if it was a lot if more was coming from outside , then there 'd be the bigger effect of the of the change in the every mean every all of the parameters that you have , especially the variances , are going to be affected by the overall variance . and in principle , you if you remove that source , then , you can that 's the first order but thing , but then the second order is the variances because , again , if you if you 're trying to distinguish between e and b if it just happens that the e 's were a more were recorded when the energy was larger or the variation in it was larger , than with the b 's , then this will be give you some bias . the it 's removing these sources of variability in the data that have nothing to do with the linguistic component . but the but let me as ask you something . i is if you have a good voice activity detector , isn't it gonna pull that out ?  right . you want to reduce this effect . you can do that by doing the voi voice activity detection . you also could do it by spect spectral subtraction before the variance normalization , right ?     it does get better even though it looks ugly .  but does this have the voice activity detection in it ?    spectral subtraction , can i  can i ask a , top level question , which is if most of what the ogi folk are working with is trying to integrate this other spectral subtraction , why are we worrying about it ? ""        right . i the intellectually it 's interesting to work on things th one way or the other but i 'm just wondering if on the list of things that there are to do , if there are things that we won't do because we 've got two groups doing the same thing .  that 's  just asking . it 's i don't know . i don't know . we still evidently have a latency reduction plan which isn't quite what you 'd like it to be . that seems like one prominent thing . and then weren't issues of having a second stream ","can i ask a , top level question , which is if most of what the ogi folk are working with is trying to integrate this other spectral subtraction , why are we worrying about it ? "" intellectually it 's interesting to work on things th one way or the other but i 'm just wondering if on the list of things that there are to do , if there are things that we won't do because we 've got two groups doing the same thing . just asking . ","There was also concern over overlap of work with partners OGI, and a lack of a good example of room reverberation for demonstrations. "
Bro012.A,"that was was it there was this business that , we could use up the full forty eight hundred bits , and   do you remember when the next meeting is supposed to be ? the next in june .   the other thing is that you saw that mail about the vad v a ds performing quite differently ? that   this there was this experiment of what if we just take the baseline ? "" set of features , just mel cepstra , and you inc incorporate the different v a and it looks like the french vad is actually better significantly better .   yes . and on that one , the french one is was better . it was just better . it was enough better that it would account for a fair amount of the difference between our performance , actually .  if they have a better one , we should use it .   it 's you can't work on everything .    h hynek will be back in town the week after next , back in the country .  and start organizing more visits and connections and forth , and  working towards june . right . no use of pitch   it  right . you can make these mistakes , but he was talking about the voiced unvoiced , though , right ? not the speech nonspeech .   we should let him finish what he w he was gonna say , and u s u  many tell you something about that . we had a guy here some years ago who did some work on making use of voicing information to help in reducing the noise . what he was doing is you do estimate the pitch . and  you from that you estimate or you estimate fine harmonic structure , whichev ei either way , it 's more or less the same . but that you then can get rid of things that are not i if there is strong harmonic structure , you can throw away that 's non harmonic . and that is another way of getting rid of part of the noise that 's something that is finer , brings in a little more information than just spectral subtraction .  and he had some he did that in combination with rasta . it was like rasta was taking care of convolutional and he was and got some decent results doing that . that 's another way . but there 's there 's right . there 's all these cues . we 've actually back when chuck was here we did some voiced unvoiced classification using a bunch of these , and  works it 's not perfect but  but that you can't given the constraints of this task , we can't , in a very way , feed forward to the recognizer the information the probabilistic information that you might get about whether it 's voiced or unvoiced , where w we can't affect the distributions or anything . but we what we  we could  that but  ","do you remember when the next meeting is supposed to be ? the other thing is that you saw that mail about the vad v a ds performing quite differently ? this there was this experiment of what if we just take the baseline ? "" and you inc incorporate the different v a and it looks like the french vad is actually better significantly better . it was enough better that it would account for a fair amount of the difference between our performance , actually . if they have a better one , we should use it . h hynek will be back in town the week after next , back in the country . and start organizing more visits and connections and forth , working towards june . no use of pitch we had a guy here some years ago who did some work on making use of voicing information to help in reducing the noise . what he was doing is you do estimate the pitch . or you estimate fine harmonic structure , i if there is strong harmonic structure , you can throw away that 's non harmonic . and that is another way of getting rid of part of the noise brings in a little more information than just spectral subtraction . and he had some he did that in combination with rasta . and got some decent results doing that . that 's another way . ",
Bro012.A,"that 's voice activity detector as opposed to voicing detector . we 're talking about something a little different . right ? what you could do , this would be w useful , if you have if you view the second stream , before you do klt 's and forth , if you do view it as probabilities , and if it 's an independent if it 's not much envelope based by fine structure based , looking at harmonicity like that , if you get a probability from that information and then multiply it by multiply by all the voiced outputs and all the unvoiced outputs , then use that as the take the log of that or pre nonlinearity , and do the klt on the on that , then that would be reasonable use of independent information . that 's what you meant . and then that would be r right . you have a second neural net . it could be pretty small . if you have a tandem system and then you have some it can be pretty small net we used we d did some of this did , some years ago , and the and you use to use information primarily that 's different as you say , it 's more fine structure based than envelope based then it you can guarantee it 's that you 're not looking at very with the other one , and then you only use for this one distinction . and now you 've got a probability of the cases , and you 've got the probability of the finer categories on the other side . you multiply them where appropriate and  if they really are from independent information sources then they should have different kinds of errors and roughly independent errors , and it 's a good choice for  that 's a good idea .  right . or if you do a spectral subtraction do some spectral subtraction first and then do some on line normalization then do some more spectral subtraction you can do it layers it doesn't hurt too much but it but anyway was arguing against myself there by giving that example mean cuz i was already suggesting that we should be careful about not spending too much time on exactly what they 're doing if you get if you go into harmonics related thing it 's definitely going to be different than what they 're doing and should have some interesting properties in noise . i know that when have people have done the obvious thing of taking your feature vector and adding in some variables which are pitch related or that it hasn't my impression it hasn't particularly helped . has not .  but that 's a question for this extending the feature vector versus having different streams . and it may not have been noisy conditions .  i don't remember the example but it was on some darpa data and some years ago and it probably wasn't , actually  ",that 's a good idea . if you get if you go into harmonics related thing it 's definitely going to be different than what they 're doing should have some interesting properties in noise . ,
Bro012.A,"why don't you just do it with aurora ? just any i in each frame  why not ? i see .  but you could you can align that it 's not perfect , but if what was said and   i see .    right . in experiments that we did a long time ago and different ta it was probably resource management you were getting something like still eight or nine percent error on the voicing , as i recall . and what that said is that , left to its own devices , like without the a strong language model and forth , that you would make significant number of errors just with your probabilistic machinery in deciding one   back twenty years ago when i did this voiced unvoiced we were getting more like ninety seven or ninety eight percent correct in voicing . but that was speaker dependent actually . we were doing training on a particular announcer and getting a very good handle on the features . and we did this complex feature selection thing where we looked the different possible features one could have for voicing and and exhaustively searched all size subsets and for that particular speaker and you 'd find the five or six features which really did on them . and then doing all of that we could get down to two or three percent error . but that , again , was speaker dependent with lots of feature selection and a very complex thing . would believe that it was quite likely that  looking at envelope only , that we 'd be significantly worse than that .  the modern ones don't do a simple switch . they work on the code book excitation . they do analysis by synthesis . they try every possible excitation they have in their code book and find the one that matches best .   o k .  right . right . but what about the testing data ?  if there 's some testing data that has two or three       we 're gonna read some more digit strings  ",,
Bro012.B,"we 're on . he suggested a smaller capacitor , right ? for the p d   what 's the cut off frequency it used ? is it like twenty ?  did somebody notice it during your talk ?  didn't say anything ?      like one instant in time . you could just throw up , the some mfcc feature vectors . one from one , one from the other , and then , you can look and see how different the numbers are . i 'm just kidding . i don't mean a graph . the actual numbers .  "" see how different these sequences of numbers are ? ""  it 's not the square .  looked at looked at the results when stephane did that and it 's really wo really happens . th the only difference is you change the self loop transition probability by a tenth of a percent and it causes ten percent difference in the word error rate .  from point i 'm f for point from you change at point one and n not tenth of a percent , one tenth , alright ? from point five from point six to point five and you get ten percent better . and it 's it 's what you hypothesized in the last meeting about it just being very and you mentioned this in your email too it 's just very get stuck in some local minimum and this thing throws you out of it you 're not allowed to  that 's supposed to be point six , for the self loop .  but changing it to point five is which gives you much better results , but that 's not allowed .   right . we only tested it on the medium mismatch , right ? you said on the other cases you didn't notice i did notice something somebody , it was morgan , suggested at the last meeting that i actually count to see how many parameters and how many frames . and there are almost one point eight million frames of training data and less than forty thousand parameters in the baseline system . it 's very , very few parameters compared to how much training data .   i did one quick experiment just to make had everything worked out and for most of the for all of the digit models , they end up at three mixtures per state . and just did a quick experiment , where i changed it it went to four and it didn't have a r any significant effect at the medium mismatch and high mismatch cases and it had it was just barely significant for the matched better . 'm r gonna run that again but with many more mixtures per state .  and also just seeing what we saw in terms of the expected duration of the silence model ? when we did this tweaking of the self loop ? the silence model expected duration was really different . ","looked at looked at the results when stephane did that and it 's really wo really happens . th the only difference is you change the self loop transition probability by a tenth of a percent and it causes ten percent difference in the word error rate . and n not tenth of a percent , one tenth , it 's just very get stuck in some local minimum and this thing throws you out of it you 're not allowed to that 's supposed to be point six , for the self loop . but changing it to point five is which gives you much better results , but that 's not allowed . right . we only tested it on the medium mismatch , somebody , it was morgan , suggested at the last meeting that i actually count to see how many parameters and how many frames . and there are almost one point eight million frames of training data and less than forty thousand parameters in the baseline system . for all of the digit models , they end up at three mixtures per state . and just did a quick experiment , where i changed it it went to four and it didn't have a r any significant effect at the medium mismatch and high mismatch cases 'm r gonna run that again but with many more mixtures per state . ",
Bro012.B,"and in the case where it had a better score , the silence model expected duration was much longer . it was like it was a better match . if we make a better silence model that will help a lot too for a lot of these cases  but one thing i wanted to check out before i increased the number of mixtures per state was in their default training script they do an initial set of three re estimations and then they built the silence model and then they do seven iterations then the add mixtures and they do another seven then they add mixtures then they do a final set of seven and they quit . seven seems like a lot to me and it also makes the experiments go take a really long time to do one turn around of the matched case takes like a day . and in trying to run these experiments i notice , it 's difficult to find machines , compute the run on . and one of the things i did was i compiled htk for the linux machines cuz we have this one from ibm that 's got like five processors in it ? and now i 'm you can run on that and that really helps a lot because now we 've got extra machines that we can use for compute . and if i 'm do running an experiment right now where i 'm changing the number of iterations ? from seven to three ? just to see how it affects the baseline system . and if we can get away with just doing three , we can do many more experiments more quickly . and if it 's not a huge difference from running with seven iterations , we should be able to get a lot more experiments done . and i 'll let what happens with that . but if we can run all of these back ends f with many fewer iterations and on linux boxes we should be able to get a lot more experimenting done .  wanted to experiment with cutting down the number of iterations before i increased the number of gaussians . it weights the improvement on the matched case really heavily compared to the improvement on the other cases ?  and it 's hard to improve on the best case , cuz it 's already good , right ?  it 's not that different , right ? just subtract the accuracy .  i see .   i see . i see .  that makes sense . hey morgan ? do you remember that signif program that we used to use for testing signi ? is that still valid ? i 've been using that .  it was . i shoul  i should find that new one . use my old one from ninety two or whatever  ninety three point six four , right ? is the baseline .   i 'm   i 'm i 'm really confused about something . ","but one thing i wanted to check out before i increased the number of mixtures per state was in their default training script they do an initial set of three re estimations and then they do seven iterations then the add mixtures and they do another seven then they add mixtures then they do a final set of seven and they quit . and it also makes the experiments go take a really long time and one of the things i did was i compiled htk for the linux machines cuz we have this one from ibm that 's got like five processors in it ? and now i 'm you can run on that and that really helps a lot because now we 've got extra machines that we can use for compute . and if i 'm do running an experiment right now where i 'm changing the number of iterations ? from seven to three ? just to see how it affects the baseline system . and if it 's not a huge difference from running with seven iterations , we should be able to get a lot more experiments done . and i 'll let what happens with that . ",
Bro012.B,"if we saw that making a small change like , a tenth , to the self loop had a huge effect , can we really make any conclusions about differences in this especially when they 're this small .   already a week ! man ! you 're right . that 's amazing .  where is eurospeech this year ?  could at least i 'm going to be out next week but i could try to look into like this cvs over the web . that seems to be a very popular way of people distributing changes and over , multiple sites and things if figure out how do that easily and then pass the information on to everybody that it 's as easy to do as possible and people don't it won't interfere with their regular work , then that would be good . and we could use it for other things around here too .  great .  i used it a long time ago but it 's been a while ask you some questions .  we could just like , talk into a cup . some good reverb . but not of reverberation . i noticed that in the pictures . hey , th "" i my initial thought was "" this is not too bad ! ""   the main thing that struck me in looking at those two spectrograms was the difference in the high frequencies . it looked like for the one that was farther away , it really everything was attenuated and that was the main visual thing that i noticed . this is this is , a plot of c zero , the energy . c zero is the close talking ? the close channel ? and s channel one is the  this is still being a plot of c zero ?  can i ask what does variance normalization do ? w what is the effect of that ?  y no , i understand that , but no . no , i understand what it is , but what does it what 's what is  we  why do it ?       i see . would the major effect is that you 're gonna get is by normalizing the means , but it may help first order effects . and it may help to do the variance .      gotcha . to interrupt . but after you do this , after you do the variance normalization  i don't know , it seems like this would be a lot easier than this signal to work with .  but for the purposes of finding the speech you 're more interested in the difference between the speech and the nonspeech , right ? where 's th where at what stage is the voice activity detector applied ? is it applied here or a after the variance normalization ? or   is it applied all the way back here ? that 's why it doesn't work for channel one .  speech is more what ? ","but i could try to look into like this cvs over the web . that seems to be a very popular way of people distributing changes and over , multiple sites and things if figure out how do that easily and then pass the information on to everybody that it 's as easy to do as possible and people don't it won't interfere with their regular work , ask you some questions . ",
Bro012.B,"there also could be see a reason f for both working on it too if if you work on something else and you 're waiting for them to give you spectral subtraction it 's hard to know whether the effects that you get from the other experiments you do will carry over once you then bring in their spectral subtraction module . it 's almost like everything 's held up waiting for this one thing . i don't know if that 's true or not , but i could see how that 's what you were thinking . improves the baseline ? isn't there some other  i was just gonna say isn't there aren't there lots of ideas for doing voice activity , or speech nonspeech rather , by looking at guess harmonics or looking across time  even with e  even with the voiced non voiced unvoiced  that you or somebody was talking about  go ahead . didn't the head dude send around that message ? you sent us all a copy of the message , where he was saying that i 'm not exactly , what the gist of what he was saying , but something having to do with the voice activity detector and that it will that people shouldn't put their own in it was gonna be a i 'm i missed that . but the problem is that their models are all word level models . there 's no phone models that you get alignments for . you you could find out where the word boundaries are but that 's about it . it also the though there was one problem with that in that , we used canonical mapping our truth may not have really been true to the acoustics .   can mention one other interesting thing ? one of the ideas that we had come up with last week for things to try to improve the system  actually i s we didn't wrote this in after the meeting b but the thought i had was looking at the language model that 's used in the htk recognizer , which is just a big loop , right ? you it goes "" digit "" and then that can be either go to silence or go to another digit , which that model would allow for the production of infinitely long sequences of digits , right ? 'm gonna just look at the what actual digit strings do occur in the training data . "" and the interesting thing was it turns out that there are no sequences of two long or three long digit strings in any of the aurora training data . it 's either one , four , five , six , up to eleven , and then it skips and then there 's some at sixteen . i don't know . i didn't look at the test data yet .   but thought that was a little odd , that there were no two or three long  ",,
Bro012.B,"just for the heck of it , i made a little grammar which had it 's separate path for each length digit string you could get . there was a one long path and there was a four long and a five long and i tried that and it got way worse . there were lots of deletions . it was i didn't have any weights of these paths or i didn't have anything like that . and i played with tweaking the word transition penalties a bunch , but i couldn't go anywhere . but if i only allow "" should have looked at to see how often there was a mistake where a two long or a three long path was actually put out as a hypothesis . but . to do that right you 'd probably want to have allow for them all but then have weightings and things . thought that was a interesting thing about the data .  you want to go ahead , morgan ? ",,
Bro012.C," spectral slices ? w what d what do   i see . that 's and if you 're interested in using cvs , i 've set it up here ,    i 'll be away tomorrow and monday but i 'll be back on tuesday or wednesday .   a boom .   we can just substitute one of these wave forms and then do some zoom in on the spectrogram on an interesting area .   ","and if you 're interested in using cvs , i 've set it up here , i 'll be away tomorrow and monday but i 'll be back on tuesday or wednesday . ",
Bro012.D,"  you can @ @ .  i don't @ @ . he actually , that he say with the good vad of from ogi and with the alcatel vad . and the experiment was sometime better , sometime worse . i don't remember .    also is stephane was thinking that it was useful to f to think about voiced unvoiced to work here in voiced unvoiced detection . and we are looking in the signal . not for foreigners . right .  ","he actually , that he say with the good vad of from ogi also is stephane was thinking that it was useful to f to think about voiced unvoiced ",
Bro012.E,"hello ? i could go check . that 's right .   we 're we need labels . we don't have frame level transcriptions . s but we could use the noisy version that timit , which is similar to the noises found in the ti digits portion of aurora . another person 's voice .    ",,
Bro012.F,"we use a pre emphasis .    at first i had a remark why i am wondering why the pda is always far . we are always meeting at the beginning of the table and the pda 's there .   anyway .   since the last meeting we 've tried to put together the clean low pass downsampling , upsampling , the new filter that 's replacing the lda filters , and also the delay issue that we considered th the delay issue on the for the on line normalization .  we 've put together all this and then we have results that are not very impressive . there is no real improvement . it 's not   actually it 's better . it seems better when we look at the mismatched case but we are like cheated here by the th this problem that in some cases when you modify slight slightly modify the initial condition you end up completely somewhere air somewhere else in the space , the parameters .  the other system are for italian is at seventy eight percent recognition rate on the mismatch , and this new system has eighty nine . but i don't think it indicates something , really . i don't think it means that the new system is more robust or it 's simply the fact that  y  it 's similar for other test sets but from this se seventy eight percent recognition rate system , i could change the transition probabilities for the first and it will end up to eighty nine also . by using point five instead of point six , point four as in the htk script . that 's   this really happens .  even tenth of a percent ? we tried point one ,       but even if you use point five , i 'm not it will always give you the better results on other test set or it on the other training set ,  but .  the reason is , i not i it was in my mail also , is the fact that the mismatch is trained only on the far microphone . in for the mismatched case everything is using the far microphone training and testing , whereas for the highly mismatched , training is done on the close microphone it 's clean speech you don't have this problem of local minima probably and for the match , it 's a mix of close microphone and distant microphone and  th the mismatch is the more difficult for the training part .          but actually actually it seems to do a little bit worse for the matched case and we just noticed that actually the way the final score is computed is quite funny . it 's not a mean of word error rate . it 's not a weighted mean of word error rate , it 's a weighted mean of improvements .  which means that actually the weight on the matched is ","since the last meeting we 've tried to put together the clean low pass downsampling , upsampling , the new filter that 's replacing the lda filters , and then we have results that are not very impressive . there is no real improvement . it seems better when we look at the mismatched case but we are like cheated here by the th this problem that in some cases when you modify slight slightly modify the initial condition you end up completely somewhere air somewhere else in the space , the parameters . i don't think it means that the new system is more robust but from this se seventy eight percent recognition rate system , i could change the transition probabilities for the first and it will end up to eighty nine also . by using point five instead of point six , point four as in the htk script . but even if you use point five , i 'm not it will always give you the better results actually the way the final score is computed is quite funny . it 's not a mean of word error rate . it 's not a weighted mean of word error rate , it 's a weighted mean of improvements . which means that actually the weight on the matched is ",The Meeting Recorder group at Berkeley met to discuss recent progress. Of greatest interest was the progress on improving the latency and performance of their recogniser. 
Bro012.F,"what happened is that if you have a small improvement or a small if on the matched case it will have huge influence on the improvement compared to the reference because the reference system is quite good for the ma matched case also . no , but it 's the weighting of the improvement not of the error rate . but what is that you can have a huge improvement on the h hmk 's , like five percent absolute , and this will not affect the final score almost this will almost not affect the final score because this improvement because the improvement relative to the baseline is small  improvement ? no , it 's compared to the word er it 's improvement on the word error rate ,        but when we think about the weighting , which is point five , point three , point two , it 's on absolute on relative figures , not when we look at this error rate        anyway   it hurts a little bit on the match and  like , it 's difficult to say because again 'm not have the  right . it 's around point five . no , point six percent absolute on italian worse , we start from ninety four point sixty four , and we go to ninety four point o four .  no , i 've ninety four . the baseline , don't i 'm not talking about the baseline here . i  my baseline is the submitted system .   for finnish , we start to ninety three point eight four and we go to ninety three point seventy four . and for spanish we are we were at ninety five point o five and we go to ninety three s point sixty one .   it 's the filter . because nnn , we don't have complete result , but the filter the filter with the shorter delay hurts on italian matched , which and ,  and the other things , like downsampling , upsampling , don't seem to hurt and the new on line normalization , neither .   that 's th  we can be completely fooled by this thing , but i don't know . there is first this thing , and then the i computed the like , the confidence level on the different test sets . and for the matched they are around point six percent . for the mismatched they are around like let 's say one point five percent . and for the hm they are also around one point five .   but . about the same . it doesn't hurt .  no .   we are exchanging mail as soon as we have significant results .   for the moment , they are working on integrating the spectral subtraction from ericsson .   and  we are working on our side on other things like also trying a sup spectral subtraction but of our own , another spectral substraction .   think it 's it 's going  for the moment they 're everybody 's quite  ","what happened is that if you have a small improvement or a small if on the matched case it will have huge influence on the improvement compared to the reference because the reference system is quite good for the ma matched case also . no , it 's compared to the word er it 's improvement on the word error rate , anyway it hurts a little bit on the match no , point six percent absolute on italian we start from ninety four point sixty four , and we go to ninety four point o four . for finnish , we start to ninety three point eight four and we go to ninety three point seventy four . and for spanish we are we were at ninety five point o five and we go to ninety three s point sixty one . but the filter the filter with the shorter delay hurts on italian matched , we are exchanging mail as soon as we have significant results . for the moment , they are working on integrating the spectral subtraction from ericsson . we are working on our side on other things like also trying a sup spectral subtraction but of our own , another spectral substraction . for the moment they 're ",
Bro012.F,"there is this eurospeech deadline ,  and .  but as soon as we have something that 's significant and that 's better than what was submitted , we will fix the system and but we 've not discussed it this yet ,    s we are trying to do something with the meeting recorder digits , and but  and the good thing is that there is this first deadline , and , some people from ogi are working on a paper for this , but there is also the special session about th aurora which is which has an extended deadline .  the deadline is in may . for th  only for the experiments on aurora . it 's good ,  it 's in denmark .  it 's the thirteenth of may .   it would be for the first deadline . nnn .   i brought some i don't know if some figures here . i start we started to work on spectral subtraction . and the preliminary results were very bad . the thing that we did is just to add spectral subtraction before this , the wall process , which contains lda on line normalization . and it hurts lot . and we started to look at things like this , which is , it 's  you have the c zero parameters for one italian utterance . and i plotted this for two channels . channel zero is the close mic microphone , and channel one is the distant microphone . and it 's perfectly synchronized ,  and the sentence contain only one word , which is "" due "" and it can't clearly be seen . where is it ? where is the word ?  this is a plot of c zero , when we don't use spectral substraction , and when there is no on line normalization .  there is just some filtering with the lda and some downsampling , upsampling .    zero is very clean , actually . then when we apply mean normalization it looks like the second figure , though it is not . which is good . the noise part is around zero and then the third figure is what happens when we apply mean normalization and variance normalization .  what we can clearly see is that on the speech portion the two channel come becomes very close , but also what happens on the noisy portion is that the variance of the noise is this is still c zero . it  it normalized th the standard deviation . it you get an estimate of the standard deviation . that 's  but .    and it and this  if they are good .  what it shows is that , perhaps a good voice activity detector is good before on line normalization and that 's what we 've already observed . but  voice activity detection is not an easy thing neither .   what i notice is that , while i prefer to look at the second figure than at the third one , ","there is this eurospeech deadline , i start we started to work on spectral subtraction . and the preliminary results were very bad . the thing that we did is just to add spectral subtraction before this , the wall process , which contains lda on line normalization . and it hurts lot . ",
Bro012.F,"because you clearly see where speech is . but the problem is that on the speech portion , channel zero and channel one are more different than when you use variance normalization where channel zero and channel one become closer . and but here   think ,  for i th that it perhaps it shows that the parameters that the voice activity detector should use have to use should be different than the parameter that have to be used for speech recognition . y but it 's not clear ,  we  it 's just to the number that at that are here are recognition experiments on italian hm and with these two kinds of parameters . and , it 's better with variance normalization .    but the fact is that the voice activity detector doesn't work on channel one .    it 's applied before variance normalization . it 's a good thing , because voice activity detection on this should could be worse . it 's applied the on ,  something like this ,  perhaps , we could perhaps do just mean normalization before vad .  about ? spectral subtraction ? it 's just it 's another they are trying to u to use the the ericsson and we 're trying to use something else . and . and also to understand what happens because fff when we do spectral subtraction , actually , that this is the two last figures . it seems that after spectral subtraction , speech is more emerging now than before . the difference between the energy of the speech and the energy of the n spectral subtrac subtracted noise portion is larger . if you compare the first figure to this one actually the scale is not the same , but if you look at the numbers you clearly see that the difference between the c zero of the speech and c zero of the noise portion is larger . but what happens is that after spectral subtraction , you also increase the variance of this of c zero . and if you apply variance normalization on this , it completely sc screw everything .    and what they did at ogi is just they don't use on line normalization , for the moment , on spectral subtraction and  as soon as they will try on line normalization there will be a problem . we 're working on the same thing but  with different system and       but they ' we want to work on this . they also want to work on this ,   we will try msg , but  and they are t they want to work on the second stream also , but more with some multi band or , what they call trap or generalized trap .  it 's in june .   but i don't know which vad they use . if the use the small vad i th it 's on it 's easy to do better because it doesn't work  i don't know which one . ","it 's just it 's another they are trying to u to use the the ericsson and we 're trying to use something else . and what they did at ogi is just they don't use on line normalization , for the moment , on spectral subtraction as soon as they will try on line normalization there will be a problem . we 're working on the same thing but with different system it 's in june . but i don't know which vad they use . ",
Bro012.F,"it 's pratibha that did this experiment . we should ask which vad she used . but i it 's think you were talking about the other mail that used vad on the reference features .    we should find out if it 's really better . if it the compared to the small or the big network . and perhaps we can easily improve if we put like mean normalization before the vad . because as you 've mentioned .       my feeling is that actually when we look the proposals , ev everybody is still using some spectral envelope and it 's not pitch , but to look at the fine at the high re high resolution spectrum . we don't necessarily want to find the pitch of the sound but  cuz i have a feeling that when we look at the just at the envelope there is no way you can tell if it 's voiced and unvoiced , if there is some it 's easy in clean speech because voiced sound are more low frequency and . there would be more , there is the first formant , which is the larger and then voiced sound are more high frequencies cuz it 's frication and but ,  when you have noise there is no if you have a low frequency noise it could be taken for voiced speech and .  s think that it would be good  go on .    think if we try to develop a second stream there would be one stream that is the envelope and the second , it could be interesting to have that 's something that 's more related to the fine structure of the spectrum . and . don't know . we were thinking about like using ideas from larry saul , have a good voice detector , have a good , voiced speech detector , that 's working on the fft and larry saul could be an idea . we were are thinking about just taking the spectrum and computing the variance of the high resolution spectrum and things like this .            but   they didn't .     i if  i was not thinking this this could be an  have some probability for the v the voicing and then use a tandem system    alright . i see ,      because , spectral subtraction is good and we could u we could use the fine structure to have a better estimate of the noise but still there is this issue with spectral subtraction that it seems to increase the variance of  it 's this musical noise which is annoying if you d you do some on line normalization after .    spectral subtraction and on line normalization don't seem to go together very i    it i has not ,   was it nois noisy condition ? the example that you just     but we were thinking , we discussed with barry about this , and perhaps thinking we were thinking about some sheet cheating experiment where we would use timit ","it 's pratibha that did this experiment . we should ask which vad she used . my feeling is that actually when we look the proposals , ev everybody is still using some spectral envelope but to look at the fine at the high re high resolution spectrum . cuz i have a feeling that when we look at the just at the envelope there is no way you can tell if it 's voiced and unvoiced , think if we try to develop a second stream there would be one stream that is the envelope and the second , it could be interesting to have that 's something that 's more related to the fine structure of the spectrum . voiced speech detector , that 's working on the fft larry saul could be an idea . we were are thinking about just taking the spectrum and computing the variance of the high resolution spectrum and things like this . because , spectral subtraction is good and we could u we could use the fine structure to have a better estimate of the noise but still there is this issue with spectral subtraction that it seems to increase the variance of it 's this musical noise which is annoying if you d you do some on line normalization after . spectral subtraction and on line normalization don't seem to go together very ",
Bro012.F,"and see if giving the d this voicing bit would help in terms of frame classification .  but b but we cannot do the cheating , this cheating thing . cuz we don't have for italian perhaps we have , but we don't have this labeling for aurora . we just have a labeling with word models but not for phonemes .    noise , that 's right ,  we can say that it will help , but i don't know . if this voicing bit doesn't help , we don't have to work more about this because it 's just to know if it how much i it will help and to have an idea of how much we can gain .         and the all the speechcorders ? what 's the idea behind ? cuz they have to they don't even have to detect voiced spe speech ? they just work on the code book and find out the best excitation .   alright .  it would not help . ",,
Bro013.A,"we 're going ?  sh close your door on the way out ?   probably wanna get this other door , too .   what are we talking about today ? that was interesting . the both the the sri system and the oth and for one thing that shows the difference between having a lot of training data or not , the the best number we have on the english on near microphone only is three or four percent . and it 's significantly better than that , using fairly simple front ends on the with the sri system . th that the  but that 's using pretty huge amount of data , mostly not digits , but then again  mostly not digits for the actual training the h m ms whereas in this case we 're just using digits for training the h m did anybody mention about whether the sri system is a is doing the digits the wor as a word model or as sub s sub phone states ?  probably .   that 's true .  it 's tha it 's that much ,   still . but what 'd be interested to do given that , is that we should take that somebody 's gonna do this , right ? is to take some of these tandem things and feed it into the sri system , right ?  because  but he 's doing it with the same data , right ? to there 's there 's two things being affected . one is that , there 's something simple that 's wrong with the back end . we 've been playing a number of states don't know if he got to the point of playing with the number of gaussians yet but  but , far he hadn't gotten any big improvement , but that 's all with the same amount of data which is pretty small . and you could do that , but i 'm saying even with it not with that part not retrained , just using having the h m ms much better h m  but just train those h m ms using different features , the features coming from our aurora   i i 'm what is the problem that you 're trying to explain ? that the  much worse ?  i but i 'm almost certain that it that it has to do with the amount of training data . it 's orders of magnitude off . but having a huge if you look at what commercial places do , they use a huge amount of data . this is a modest amount of data . ordinarily you would say "" given that you have enough occurrences of the digits , you can just train with digits rather than with , but if you have a huge in other words , do word models but if you have a huge amount of data then you 're going to have many occurrences of similar allophones . ","what are we talking about today ? the both the the sri system and the oth and for one thing that shows the difference between having a lot of training data or not , the the best number we have on the english on near microphone only is three or four percent . and it 's significantly better than that , using fairly simple front ends on the with the sri system . but that 's using pretty huge amount of data , mostly not digits for the actual training the h m ms whereas in this case we 're just using digits for training the h m but what 'd be interested to do given that , is that we should take is to take some of these tandem things and feed it into the sri system , to there 's there 's two things being affected . one is that , there 's something simple that 's wrong with the back end . we 've been playing a number of states don't know if he got to the point of playing with the number of gaussians yet but , far he hadn't gotten any big improvement , but that 's all with the same amount of data which is pretty small . you could do that , but i 'm saying even with it not with that part not retrained , just using having the h m ms much better h m what is the problem that you 're trying to explain ? i but i 'm almost certain that it that it has to do with the amount of training data . it 's orders of magnitude off . ","The Main purpose of the meeting of ICSI's Meeting Recorder Group at Berkeley was to discuss the recent progress of it's members. There was also talk of comparing different recognition systems and training datasets, and a discussion of the pronunciation of the digit zero for the recording at the end of the meeting. "
Bro013.A,"and that 's just a huge amount of training for it . it 's think it has to be that , because , as you say , this is , this is near microphone , it 's really pretty clean data .  now , some of it could be the fact that  let 's see , in the in these multi train things did we include noisy data in the training ? that could be hurting us actually , for the clean case . it is if   cuz this is clean data , and that 's not too surprising . but    what numbers are we getting on ti digits ?  i see . in the actual ti digits database we 're getting point eight percent , and here we 're getting three or four three , let 's see , three for this ?  but point eight percent is something like double or triple what people have gotten who 've worked very hard at doing that . and also , as you point out , there 's adaptation in these numbers also . if you , put the ad adap take the adaptation off , then it for the english near you get something like two percent . and here you had , something like three point four . and i could easily see that difference coming from this huge amount of data that it was trained on . it 's i don't think there 's anything magical here . it 's , we used a simple htk system with a modest amount of data . and this is a , modern system has a lot of points to it .  the htk is an older htk , even .  it 's not that surprising . but to me it just meant a practical point that if we want to publish results on digits that people pay attention to we probably should cuz we 've had the problem before that you get show some improvement on something that 's it seems like too large a number , and people don't necessarily take it    the three point four percent for this is  why is it it 's an interesting question though , still . why is it three point four percent for the d the digits recorded in this environment as opposed to the point eight percent for the original ti digits database ?  given the same ignore ignoring the sri system for a moment , just looking at the ti di the tandem system , if we 're getting point eight percent , which , yes , it 's high . it 's , it 's not awfully high , but it 's , it 's high . why is it four times as high , or more ? right ? there 's even though it 's close miked there 's still there really is background noise . and suspect when the ti digits were recorded if somebody fumbled or said something wrong that they probably made them take it over . ","let 's see , in the in these multi train things did we include noisy data in the training ? that could be hurting us actually , for the clean case . i don't think there 's anything magical here . it 's , we used a simple htk system with a modest amount of data . and this is a , modern system has a lot of points to it . the htk is an older htk , even . but to me it just meant a practical point that if we want to publish results on digits that people pay attention to we probably should cuz we 've had the problem before that you get show some improvement on something that 's it seems like too large a number , and people don't necessarily take it there 's even though it 's close miked there 's still there really is background noise . and suspect when the ti digits were recorded if somebody fumbled or said something wrong that they probably made them take it over . ",
Bro013.A,"it was not there was no attempt to have it be realistic in any sense  right .  think they were bless you . i it 's yes . it 's it 's the indication it 's harder . i that 's true either way . take a look at the the sri results . they 're much better , but still you 're getting something like one point three percent for things that are same data as in t ti digits the same text . and i 'm the same system would get , point three or point four on the actual ti digits . this on both systems the these digits are showing up as harder .  which i find interesting think this is closer to mean it 's still read . but i still think it 's much closer to what people actually face , when they 're dealing with people saying digits over the telephone . i don't think i 'm they wouldn't release the numbers , but i don't think that the companies that do telephone speech get anything like point four percent on their digits . i 'm i 'm they get for one thing people do phone up who don't have middle america accents and it 's a we it 's it 's us . it has many people who sound in many different ways .     that was that topic . what else we got ? did we end up giving up on , any eurospeech submissions , or ? i know thilo and dan ellis are submitting something , but now , actually for the aur we do have for aurora , right ? because we have ano an extra month  that 's fine . th we have a couple little things on meeting recorder and we have we don't have to flood it with papers . we 're not trying to prove anything to anybody .  that 's fine .  anything else ?   wha where did this good vad come from ? this is the one they had originally ?  but they had to get rid of it because of the space , didn't they ? that 's a problem .  but the other thing is to use a different vad entirely . if there 's a if i don't the thinking was amongst the etsi folk but if everybody let 's use this vad and take that out of there  determined . i see . but i was thinking that "" there may be some interaction , but i don't think we need to be stuck on using our or ogi 's vad . we could use somebody else 's if it 's smaller or as long as it did the job . that 's good . right .  you didn't gain anything , right ?  that means logically , in principle , it should be better . probably it 'll be worse . or in the basic perverse nature of reality .              right .    i 'm s there 's ","it was not there was no attempt to have it be realistic in any sense wha where did this good vad come from ? this is the one they had originally ? but they had to get rid of it because of the space , but the other thing is to use a different vad entirely . i don't the thinking was amongst the etsi folk but if everybody let 's use this vad and take that out of there but i don't think we need to be stuck on using our or ogi 's vad . we could use somebody else 's if it 's smaller as long as it did the job . you didn't gain anything , right ? ",
Bro013.A,"none of these axes are labeled , don't this what 's this axis ? frame . and what 's th what this ? for this one . for the noi  there 's two things on the same graph . which is clean and which is noise ?  it 's harder to distinguish but it g with noise but  and presumably when there 's a       and this is the difference ? no pre emphasis ?  it 's doesn't do too there . right . now i wonder do you want to i know you want to get at something orthogonal from what you get with the smooth spectrum but if you were to really try and get a voiced unvoiced , do you want to ignore that ? do you do you clearly a very big cues for voiced unvoiced come from spectral slope and on , right ?   i see .    you probably want certainly if you want to do good voiced unvoiced detection , you need a few features . each feature is by itself not enough . but , people look at slope and first auto correlation coefficient , divided by power . or  there 's we prob probably don't have enough computation to do a simple pitch detector with a pitch detector you could have a an estimate of what the  or you could you just do it going through the p fft 's figuring out some probable harmonic structure . right . and     right .  that 's as a separate thing .  separate thing ?      what  what i was talking about was just , starting with the fft you could do a very rough thing to estimate pitch . and given given that , you could come up with some estimate of how much of the low frequency energy was explained by those harmonics .  it 's variant on what you 're s what you 're doing . the the mel does give a smooth thing . but as you say it 's not that smooth here . and if you just subtracted off your guess of the harmonics then something like this would end up with quite a bit lower energy in the first fifteen hundred hertz or and our first kilohertz , even . and if was noisy , the proportion that it would go down would be if it was unvoiced you oughta be able to pick out voiced segments . at least it should be another cue . anyway .  that 's what 's going on .  what 's up with you ?       we 're done . let 's read our digits and go home .  no . "" o "" "" o "" "" o "" "" o "" and "" zero "" are two ways that we say that digit . it 's it 's i no . people will do what they say . it 's in digit recognition we 've done before , you have two pronunciations for that value , "" o "" and "" zero "" . ","now i wonder i know you want to get at something orthogonal from what you get with the smooth spectrum but if you were to really try and get a voiced unvoiced , do you want to ignore that ? clearly a very big cues for voiced unvoiced come from spectral slope and on , certainly if you want to do good voiced unvoiced detection , you need a few features . each feature is by itself not enough . but , people look at slope and first auto correlation coefficient , divided by power . or you could you just do it going through the p fft 's figuring out some probable harmonic structure . what i was talking about was just , starting with the fft you could do a very rough thing to estimate pitch . and given given that , you could come up with some estimate of how much of the low frequency energy was explained by those harmonics . it 's variant on what you 're s what you 're doing . but as you say it 's not that smooth here . and if you just subtracted off your guess of the harmonics then something like this would end up with quite a bit lower energy in the first fifteen hundred hertz or what 's up with you ? people will do what they say . in digit recognition we 've done before , you have two pronunciations for that value , "" o "" and "" zero "" . ","This includes reports on the progress of the groups main digit recogniser project, with interest on voice-activity detectors and voiced/unvoiced detection, work on acoustic feature detection, and research into dealing with reverberation. There was also talk of comparing different recognition systems and training datasets, and a discussion of the pronunciation of the digit zero for the recording at the end of the meeting. "
Bro013.A,"no , they just write they write down or they write down zero a and they each have their own pronunciation . but people wouldn't that wa there is no convention for it . see . you 'd have to tell them "" when we write this , say it tha "" ,  and you just they just want people to read the digits as you ordinarily would and people say it different ways . yes . that 's right . it was spelled out , and they decided they wanted to get at more the way people would really say things . that 's also why they 're bunched together in these different groups . it 's  it 's everything 's fine .  actually , let me just s since you brought it up , i was just it was hard not to be self conscious about that when it after we since we just discussed it . but i realized that when i 'm talking on the phone , certainly , and saying these numbers , i almost always say zero . and cuz because it 's two syllables . it 's more likely they 'll understand what i said . that 's the habit i 'm in , but some people say "" o "" and it 's shorter .  it 's now , don't think about it .  we 're done . ","no , they just write and you just they just want people to read the digits as you ordinarily would ","There was also talk of comparing different recognition systems and training datasets, and a discussion of the pronunciation of the digit zero for the recording at the end of the meeting. "
Bro013.B,"     our t i went to talk with mike jordan this week and shared with him the ideas about extending the larry saul work and asked him some questions about factorial h m like later down the line when we 've come up with these feature detectors , how do we model the time series that happens and we talked a little bit about factorial h m ms and how when you 're doing inference or w when you 're doing recognition , there 's like simple viterbi that you can do for these h m and the the great advantages that lot of times the factorial h m ms don't don't over alert the problem there they have a limited number of parameters and they focus directly on the sub problems at hand you can imagine five or parallel features transitioning independently and then at the end you couple these factorial h m ms with undirected links based on some more data . he seemed like really interested in in this and said this is something very do able and can learn a lot and i 've just been continue reading about certain things .  thinking of using modulation spectrum to as features also in the sub bands because it seems like the modulation spectrum tells you a lot about the intelligibility of certain words and   just that 's about it . ha ! normally say "" o "" cuz it 's easier to say . "" o "" no ! ","our t i went to talk with mike jordan this week and shared with him the ideas about extending the larry saul work and asked him some questions about factorial h m like later down the line when we 've come up with these feature detectors , how do we model the time series that happens and we talked a little bit about factorial h m ms and how when you 're doing inference or w when you 're doing recognition , there 's like simple viterbi that you can do for these h m and the the great advantages that lot of times the factorial h m ms don't don't over alert the problem there they have a limited number of parameters and they focus directly on the sub problems at hand he seemed like really interested in in this and said this is something very do able and can learn a lot i 've just been continue reading about certain things . thinking of using modulation spectrum to as features also in the sub bands because it seems like the modulation spectrum tells you a lot about the intelligibility of certain words and ",
Bro013.C,"  and  've been looking at avendano 's work and 'll try to write up in my next stat status report a description of what he 's doing , but it 's an approach to deal with reverberation or that the aspect of his work that i 'm interested in the idea is that normally an analysis frames are too short to encompass reverberation effects in full . you miss most of the reverberation tail in a ten millisecond window and you 'd like it to be that the reverberation responses simply convolved in , but it 's not really with these ten millisecond frames cuz you j but if you take , say , a two millisecond window i 'm a two second window then in a room like this , most of the reverberation response is included in the window and the then it then things are l more linear . it is more like the reverberation response is simply c convolved and and you can use channel normalization techniques like in his thesis he 's assuming that the reverberation response is fixed . he just does mean subtraction , which is like removing the dc component of the modulation spectrum and that 's supposed to d deal deal pretty with the reverberation and the neat thing is you can't take these two second frames and feed them to a speech recognizer he does this method training trading the the spectral resolution for time resolution and come ca synthesizes a new representation which is with say ten second frames but a lower s frequency resolution . don't really know the theory . it 's these are called "" time frequency representations "" and h he 's making the time sh finer grained and the frequency resolution less fine grained . s 'm my first stab actually in continuing his work is to re implement this thing which changes the time and frequency resolutions cuz he doesn't have code for me . that 'll take some reading about the theory . i don't really know the theory . and another f first step is  the way i want to extend his work is make it able to deal with a time varying reverberation response and we don't really know how fast the the reverberation response is varying the meeting recorder data we have this block least squares imp echo canceller implementation and want to try finding the response , say , between a near mike and the table mike for someone using the echo canceller and looking at the echo canceller taps and then see how fast that varies from block to block . that should give an idea of how fast the reverberation response is changing .  s y you do you read some of the zeros as o 's and some as zeros . is there a particular way we 're supposed to read them ? alright .   is this a change from the last batch of forms ? ","'ve been looking at avendano 's work 'll try to write up in my next stat status report a description of what he 's doing , but it 's an approach to deal with reverberation or that the aspect of his work that i 'm interested in s 'm my first stab actually in continuing his work is to re implement this thing which changes the time and frequency resolutions cuz he doesn't have code for me . that 'll take some reading about the theory . i don't really know the theory . the way i want to extend his work is make it able to deal with a time varying reverberation response we don't really know how fast the the reverberation response is varying the meeting recorder data y you do you read some of the zeros as o 's and some as zeros . is there a particular way we 're supposed to read them ? ","This includes reports on the progress of the groups main digit recogniser project, with interest on voice-activity detectors and voiced/unvoiced detection, work on acoustic feature detection, and research into dealing with reverberation. There was also talk of comparing different recognition systems and training datasets, and a discussion of the pronunciation of the digit zero for the recording at the end of the meeting. "
Bro013.C,because in the last batch it was spelled out which one you should read .    ,,
Bro013.D,"no , i w i begin to play with matlab and to found some parameter robust for voiced unvoiced decision . but only to play . and we they we found that is a classical parameter , the sq the variance between the fft of the signal and the small spectrum of time we after the mel filter bank . and , is more or less robust . is good for clean speech . is quite good for noisy speech . but we must to have bigger statistic with timit , and is not ready yet to use on , i don't know .  i have here . i have here for one signal , for one frame . the mix of the two , noise and unnoise , and the signal is this . clean , and this noise . these are the two the mixed , the big signal is for clean . this is this axis is nnn , "" frame "" .  this is energy , log energy of the spectrum . of the this is the variance , the difference between the spectrum of the signal and fft of each frame of the signal and this mouth spectrum of time after the f may fit for the two , this big , to here , they are to signal . this is for clean and this is for noise .  i don't know . that i have d another graph , but i 'm not the lower is noise and the height is clean . it 's height . i must to have . pity , but i don't have two different it is the height is voiced portion . and this is the noise portion . and this is more or less like this . but i meant to have see @ @ two the picture . this is , for one frame . the spectrum of the signal . and this is the small version of the spectrum after ml mel filter bank . and this is i don't know . this is not the different . this is trying to obtain with lpc model the spectrum but using matlab without going factor and s not pre emphasis . nothing . and the that this is good . this is quite similar . this is another frame . ho how i obtained the envelope , this envelope , with the mel filter bank . because when did noise clear in these section is clear if s @ @ val value is indicative that is a voice frame and it 's low values you have read up and you have a paper , the paper that you s give me yesterday . they say that yesterday they are some problem and the is another problem . like this . of kind like this .  ","no , i w i begin to play with matlab and to found some parameter robust for voiced unvoiced decision . and we they we found that is a classical parameter , the sq the variance between the fft of the signal and the small spectrum of time we after the mel filter bank . and , is more or less robust . is good for clean speech . because when did noise clear in these section is clear ","This includes reports on the progress of the groups main digit recogniser project, with interest on voice-activity detectors and voiced/unvoiced detection, work on acoustic feature detection, and research into dealing with reverberation. "
Bro013.E,"first there are perhaps these meeting recorder digits that we tested .   of data ?     right . it 's allophone models ,   because it 's their very d huge , their huge system . and . but . there is one difference the sri system the result for the sri system that are represented here are with adaptation . there is it 's their complete system and including on line unsupervised adaptation . and if you don't use adaptation , the error rate is around fifty percent worse , if i remember .  nnn . it 's  it 's quite significant .    we can do something like that .  but but the main point is the data because am not our back end is fairly simple but until now , the attempts to improve it or have fail what chuck tried to do  it 's       we could retrain some of these tandem on huge  just f for the models .      but what would be interesting to see also is what perhaps it 's not related , the amount of data but the recording conditions . i don't know . because it 's probably not a problem of noise , because our features are supposed to be robust to noise . it 's not a problem of channel , because there is normalization with respect to the channel .  the fact that the result with the tandem and aurora system are much worse .  it but  but we train only on digits and it 's a digit task ,   it  alright .    right .       actually we see that the clean train for the aurora proposals are better than the multi train ,   o what i meant is that let 's say if we add enough data to train on the on the meeting recorder digits , we could have better results than this . and . what i meant is that perhaps we can learn something from this , what 's wrong what is different between ti digits and these digits and it 's point eight percent ,  four fourier .              th that 's my point i don't i        and acoustically , it 's q it 's i listened . it 's quite different . ti digit is it 's very , very clean and it 's like studio recording whereas these meeting recorder digits sometimes you have breath noise and  it 's not controlled  but       but  the only thing with these the meeting recorder and , think we gave up . but     for we will do something for the special session .     perhaps that we 've been working on is , we have put the the good vad in the system and it really makes a huge difference .    this is perhaps one of the reason why our system was not the best , because with the new vad , it 's very the results are similar to the france telecom results and perhaps even better sometimes . there is this point . ","first there are perhaps these meeting recorder digits that we tested . because it 's their very d huge , their huge system . but the main point is the data because our back end is fairly simple but until now , the attempts to improve it or have fail we could retrain some of these tandem on huge perhaps it 's not related , the amount of data but the recording conditions . the fact that the result with the tandem and aurora system are much worse . ti digit is it 's very , very clean and it 's like studio recording whereas these meeting recorder digits sometimes you have breath noise perhaps that we 've been working on is , we have put the the good vad in the system and it really makes a huge difference . this is perhaps one of the reason why our system was not the best , because with the new vad , it 's very the results are similar to the france telecom results and perhaps even better sometimes . ","There was also talk of comparing different recognition systems and training datasets, and a discussion of the pronunciation of the digit zero for the recording at the end of the meeting. The Main purpose of the meeting of ICSI's Meeting Recorder Group at Berkeley was to discuss the recent progress of it's members. This includes reports on the progress of the groups main digit recogniser project, with interest on voice-activity detectors and voiced/unvoiced detection, work on acoustic feature detection, and research into dealing with reverberation. "
Bro013.E,"the problem is that it 's very big and we still have to think how to where to put it and because it this vad either some delay and we if we put it on the server side , it doesn't work , because on the server side features you already have lda applied from the f from the terminal side and you accumulate the delay the vad should be before the lda which means perhaps on the terminal side and then smaller and  it 's from ogi . it 's the network trained it 's the network with the huge amounts on hidden of hidden units , and nine input frames compared to the vad that was in the proposal which has a very small amount of hidden units and fewer inputs .     but the abso assumption is that we will be able to make a vad that 's small and that works fine . and . we can but nnn .   they just want , they don't want to fix the vad because they think there is some interaction between feature extraction and vad or frame dropping but they still want to just to give some requirement for this vad because it 's it will not be part of they don't want it to be part of the standard . it must be at least somewhat fixed but not completely . there just will be some requirements that are still not not yet ready nnn .   there is this thing . there is   designed a new filter because when i designed other filters with shorter delay from the lda filters , there was one filter with fif sixty millisecond delay and the other with ten milliseconds and hynek suggested that both could have sixty five sixty s it 's sixty five .  both should have sixty five because  and . did that and it 's running . let 's see what will happen . but the filter is closer to the reference filter .       and then we 've started to work with this of voiced unvoiced and next week we will perhaps try to have new system with msg stream also see what happens . something that 's similar to the proposal too , but with msg stream .   we wa want to look at something like the ex excitation signal and which are the variance of it and   the lower one is noise .  this should the t voiced portions . the p the peaks should be voiced portion .   this would be perhaps an additional parameter , simply isn't       but but it 's not it 's , it 's another problem .   there is th this fact actually . if you look at this spectrum , what 's this again ? is it the mel filters ?   the envelope here is the output of the mel filters and what we clearly see is that in some cases , and it clearly appears here , and the harmonics are resolved by the f ","the problem is that it 's very big and we still have to think how to where to put it either some delay and we if we put it on the server side , it doesn't work , because on the server side features you already have lda applied from the f from the terminal side and you accumulate the delay it 's from ogi . but the abso assumption is that we will be able to make a vad that 's small and that works fine . they just want , they don't want to fix the vad because they think there is some interaction between feature extraction and vad or frame dropping but they still want to just to give some requirement for this vad because it 's it will not be part of they don't want it to be part of the standard . there just will be some requirements that are still not not yet ready designed a new filter because when i designed other filters with shorter delay from the lda filters , there was one filter with fif sixty millisecond delay and the other with ten milliseconds and hynek suggested that both could have sixty five sixty s both should have sixty five because and it 's running . but the filter is closer to the reference filter . and then we 've started to work with this of voiced unvoiced we wa want to look at something like the ex excitation signal and which are the variance of it and this would be perhaps an additional parameter , it 's another problem . if you look at this spectrum , is it the mel filters ? and what we clearly see is that in some cases , and the harmonics are resolved by the f ","This includes reports on the progress of the groups main digit recogniser project, with interest on voice-activity detectors and voiced/unvoiced detection, work on acoustic feature detection, and research into dealing with reverberation. "
Bro013.E,"there are still appear after mel filtering , and it happens for high pitched voice because the width of the lower frequency mel filters is sometimes even smaller than the pitch . it 's around one hundred , one hundred and fifty hertz nnn . and what happens is that this add additional variability to this envelope and we were thinking to modify the mel spectrum to have something that 's smoother on low frequencies . i  this is a separate thing . and .            there are only zeros here .  eee .  but perhaps in the sheets there should be another sign for the if we want to the guy to say "" o "" or it 's   but it 's perhaps more difficult for the people to prepare the database then , if because here you only have zeros and people pronounce "" o "" or zero but if the sh the sheet was prepared with a different sign for the "" o "" .       it was orthographic ,  ","there are still appear after mel filtering , and it happens for high pitched voice because the width of the lower frequency mel filters is sometimes even smaller than the pitch . we were thinking to modify the mel spectrum to have something that 's smoother on low frequencies . perhaps in the sheets there should be another sign for the and people pronounce "" o "" or zero ","There was also talk of comparing different recognition systems and training datasets, and a discussion of the pronunciation of the digit zero for the recording at the end of the meeting. "
Bro014.A,"it 's not very significant . ta great . what 's wrong with ?   you run with three , two , five ? that 's a            there was a conference call this tuesday .  i don't know yet the what happened tuesday , but the points that they were supposed to discuss is still , things like the weights ,     i have no idea .     the points were the weights how to weight the different error rates that are obtained from different language and conditions .  it 's not clear that they will keep the same weighting . right now it 's a weighting on improvement . some people are arguing that it would be better to have weights on  to combine error rates before computing improvement . and the fact is that for right now for the english , they have weights they combine error rates , but for the other languages they combine improvement . it 's not very consistent .   the ,  and this is a point . and right now actually there is a thing also , that happens with the current weight is that a very non significant improvement on the matched case result in huge differences in the final number . and perhaps they will change the weights to   in   tha that 's what they do .     and when you average the relative improvement it tends to give a lot of , importance to the matched case because the baseline is already very good and ,  i it 's       combine error rates and then   but there is this still this problem of weights . when you combine error rate it tends to give more importance to the difficult cases , and some people think that they have different , opinions about this . some people think that it 's more important to look at to have ten percent imp relative improvement on matched case than to have fifty percent on the m mismatched , and other people think that it 's more important to improve a lot on the mismatch and bu l de fff !      it 's  medium mismatch is everything with the far microphone , but trained on low noisy condition , like low speed and or stopped car and tested on high speed conditions , like on a highway and  same microphone but              but there is probably a big change that will be made is that the baseline th they want to have a new baseline , perhaps , which is , mfcc but with a voice activity detector . and some people are pushing to still keep this fifty percent number . they want to have at least fifty percent improvement on the baseline , but w which would be a much better baseline . and if we look at the result that sunil sent , just putting the vad in the baseline improved more than twenty percent , which would mean then mean that fifty percent on this new baseline is like , more than sixty percent improvement on ","there was a conference call this tuesday . i don't know yet the what happened tuesday , but the points that they were supposed to discuss is still , things like the weights , i have no idea . the points were the weights how to weight the different error rates that are obtained from different language and conditions . it 's not clear that they will keep the same weighting . some people are arguing that it would be better to have weights on to combine error rates before computing improvement . and perhaps they will change the weights to but there is this still this problem of weights . when you combine error rate it tends to give more importance to the difficult cases , some people think that it 's more important to look at to have ten percent imp relative improvement on matched case than to have fifty percent on the m mismatched , and other people think that it 's more important to improve a lot on the mismatch but there is probably a big change that will be made is that the baseline th they want to have a new baseline , perhaps , and some people are pushing to still keep this fifty percent number . they want to have at least fifty percent improvement on the baseline , ","They discussed a conference call with project partners, there have been some developments that should help speed up experiments, along with some progress made in the current area they are looking, voiced/unvoiced detection. "
Bro014.A,"on o e right now , nobody would be there , but   they didn't decide yet . this was one point of the conference call also , but  don't know .  but    m  but perhaps i don't know w  per e s someone told that perhaps it 's not fair to do that because the , to make a good vad you don't have enough to with the features that are the baseline features .   you need more features . you really need to put more in the front end .  s   if i  that 's not clear , but this e     right .          we 'll see what happen with this . and  what happened since , last week is from ogi , these experiments on putting vad on the baseline . and these experiments also are using , some noise compensation , spectral subtraction , and putting on line normalization , just after this . think spectral subtraction , lda filtering , and on line normalization , which is similar to the pro proposal one , but with spectral subtraction in addition , and it seems that on line normalization doesn't help further when you have spectral subtraction . i i have no idea , because the issue i brought up was with a very simple spectral subtraction approach , and the one that they use at ogi is one from the proposed the aurora prop proposals , which might be much better .  i asked sunil for more information about that , but , i don't know yet .  and what 's happened here is that we we have this new , reference system which use a clean downsampling upsampling , which use a new filter that 's much shorter and which also cuts the frequency below sixty four hertz , which was not done on our first proposal . i no . no . because we 're still testing . we have the result for , just the features and we are currently testing with putting the neural network in the klt . it seems to improve on the matched case , but it 's a little bit worse on the mismatch and highly mismatched when we put the neural network . and with the current weighting it 's sh it will be better because the matched case is better .  it 's like , fff ten percent relative .   w when i say it 's worse , it 's not it 's when i compare proposal two to proposal one ,  r y putting neural network compared to n not having any neural network . this new system is better , because it has this sixty four hertz cut off , clean downsampling , and , what else ? a good vad . we put the good vad .  i don't know . i j pr latency is short is  and  mainly because of the sixty four hertz and the good vad . ","they didn't decide yet . what happened since , last week is from ogi , these experiments on putting vad on the baseline . and these experiments also are using , some noise compensation , spectral subtraction , and putting on line normalization , just after this . think spectral subtraction , lda filtering , and on line normalization , which is similar to the pro proposal one , but with spectral subtraction in addition , and it seems that on line normalization doesn't help further when you have spectral subtraction . and what 's happened here is that we we have this new , reference system which use a clean downsampling upsampling , which use a new filter that 's much shorter and which also cuts the frequency below sixty four hertz , no . because we 're still testing . it seems to improve on the matched case , but it 's a little bit worse on the mismatch and highly mismatched latency is short ","They discussed a conference call with project partners, there have been some developments that should help speed up experiments, along with some progress made in the current area they are looking, voiced/unvoiced detection. The ICSI Meeting Recorder Group at Berkeley met to discuss progress on their main project, Aurora. "
Bro014.A,"and then i took this system and , w i p we put the old filters also . we have this good system , with good vad , with the short filter and with the long filter , and ,  with the short filter it 's not worse .  is it it 's in yes .    probably ,    but it 's a good thing anyway to have shorter delay . then we tried , to do something like proposal two but having , e using also msg features . there is this klt part , which use just the standard features , and then two neura two neural networks .  and it doesn't seem to help . however , we just have one result , which is the italian mismatch ,   we have to for that to fill the whole table , but   we try to , find good features that could be used for voicing detection , but it 's still , on the ,  t we w we are still playing with matlab to look at what happened , and we would be looking at , the variance of the spectrum of the excitation , something like this , which is should be high for voiced sounds .  we  the the spectrum of the excitation for a purely periodic sig signal shou sh e that 's right .    we have the mel f filter bank , we have the fft , we just no . that 's right .   e but it 's still    for unvoiced portion we have something tha that has a mean around o point three , and for voiced portion the mean is o point fifty nine . but the variance seem quite high .   we used , timit and we used canonical mappings between the phones and th  but  it 's noisy timit . that 's right .  it seems quite robust to noise , when we take we draw its parameters across time for a clean sentence and then nois the same noisy sentence , it 's very close . there are there is this . there could be also the , something like the maximum of the auto correlation function or which right now we just are trying to find some features . and ,  hopefully , what we want to have is to put these features in s some  to obtain a statistical model on these features and to or just to use a neural network and hopefully these features w would help   except the variance is quite high .       but ther more obvious is that  the more obvious is that using the th the fft , you just it gives you just information about if it 's voiced or not voiced , ma mainly , but this is why we started to look by having voiced phonemes and         we don't know exactly yet . but ,  th no . no . no , the idea was , to use them as features .  ","we try to , find good features that could be used for voicing detection , we w we are still playing with matlab to look at what happened , we would be looking at , the variance of the spectrum of the excitation , which is should be high for voiced sounds . that 's right . right now we just are trying to find some features . hopefully , what we want to have is to put these features in s some to obtain a statistical model on these features and to or just to use a neural network ","They discussed a conference call with project partners, there have been some developments that should help speed up experiments, along with some progress made in the current area they are looking, voiced/unvoiced detection. "
Bro014.A,"it could be , it could be a neural network that does voiced and unvoiced detection , but it could be in the also the big neural network that does phoneme classification .    we just how did we do it up again ?  s we have linear interpolation . we have one point for one energy for each filter bank , which is the energy that 's centered on the triangle  that 's right . then we compute the difference .    and the variance is computed only from two hundred hertz to one to fifteen hundred . because fifteen hundred . because  above , it seems that some voiced sound can have also noisy part on high frequencies , and but it 's just this is  in log domain .     what happen if what we have what we would like to have is some spectrum of the excitation signal , which is for voiced sound ideally a pulse train and for unvoiced it 's something that 's more flat . and the way to do this is that we have the fft because it 's computed in the system , and we have the mel filter banks , and if we remove the mel filter bank from the fft , we have something that 's close to the excitation signal . it 's something that 's like a train of p a pulse train for voiced sound and that 's that should be flat for it 's y  you have several some unvoiced ?  but  this is another voiced example .   this is right .   it 's around zero , but  no . it is it 's  it 's the pitch .    do you have the mean do you have the mean for the auto correlation ? for the energy . they should be more close .  they are this is there is less difference . this is less it 's less robust .   but   it seems ,   no , no . but th the robustness to noise if you take this frame , from the noisy utterance and the same frame from the clean utterance y we end up with   that 's  this is inter interesting also because if we use the standard , frame length of twenty five milliseconds , what happens is that for low pitched voiced , because of the frame length , y you don't really have you don't clearly see this periodic structure , because of the first lobe of each of the harmonics . this is like fifty milliseconds like that . but it 's the same frame and   i see that .   with a short frame you have only two periods and it 's not enough to have this neat things . but  probably we 'll have to use long f long frames .      it depends . how they 're doing it ?   ericsson is on the , filter bank , no ? it 's on the filter bank ,   probably i it     that 's all . ","it seems ,  if you take this frame , from the noisy utterance and the same frame from the clean utterance ",
Bro014.A,"we 'll perhaps try to convince ogi people to use the new filters and   not yet but i wi i will call them and now they are they have more time because they have this eurospeech deadline is over and it 's , in june .  i don't know w but  right . ",we 'll perhaps try to convince ogi people to use the new filters not yet but i wi i will call them now they are they have more time eurospeech deadline is over ,
Bro014.B,"channel one . yes .   did you solve speech recognition last week ? alright ! let 's do image processing . alright !  it 's april fifth . actually , hynek should be getting back in town shortly if he isn't already .  we 'll drag him here . i know where he is . u i meant , this end of the world , is really what i meant , cuz he 's been in europe .   great ! i 'm i didn't quite get that . there 's four and there 's seven and i 'm but in htk , what 's the difference between , a an inner loop and an outer loop in these iterations ?  right ! this was the mix up that 's right . i remember now .     as opposed to ?  and then when you have your final thing , do a full one , it 's  that 's great . you could do something like keep exactly the same procedure and then add a fifth thing onto it that had more .   might be between , shared , shared variances or  alright . what else ? this is a conference call for , aurora participant thing . i see . do who was since we weren't in on it , do who was in from ogi ? was hynek involved or was it sunil or ? you don't know .  alright .    the fact that it 's inconsistent is an obvious mistake . but the but , the other thing i don't know i haven't thought it through , but one would think that each it it 's like if you say what 's the best way to do an average , an arithmetic average or a geometric average ? it depends what you wanna show . each one is gonna have a different characteristic .  they are doing that . no , that is relative . but the question is , do you average the relative improvements or do you average the error rates and take the relative improvement of that ? and it 's not just a pure average because there are these weightings . it 's a weighted average .  that 's what he 's seeing as one of the things they could do . it 's just when you get all done , that they pro i m i wasn't there but they started off this process with the notion that you should be significantly better than the previous standard . and , they said "" how much is significantly better ? what do you ? "" and they said "" you should have half the errors , "" "" that you had before "" . it 's ,  but it does seem like i it does seem like it 's more logical to combine them first and then do the    ","and then when you have your final thing , do a full one , it 's you could do something like keep exactly the same procedure and then add a fifth thing onto it do who was since we weren't in on it , do who was in from ogi ? the fact that it 's inconsistent is an obvious mistake . but the question is , do you average the relative improvements or do you average the error rates and take the relative improvement of that ? and it 's not just a pure average because there are these weightings . it 's just when you get all done , that they pro but they started off this process with the notion that you should be significantly better than the previous standard . they said "" how much is significantly better ? and they said "" you should have half the errors , "" "" that you had before "" . but it does seem like i it does seem like it 's more logical to combine them first ",
Bro014.B,"that if you look at the numbers on the more difficult cases , if you really believe that was gonna be the predominant use , none of this would be good enough . nothing anybody 's whereas you with some reasonable error recovery could imagine in the better cases that these systems working .   the hope would be that it would it would work for the good cases and , it would have reasonable reas soft degradation as you got to worse and worse conditions .  but no . no no . it isn't the operating theater . they don they don't really know , i th one thing to do is to just not rely on a single number to have two or three numbers ,  and say here 's how much you , you improve the , the relatively clean case and here 's or matched case , and here 's how much you ,    actually it 's true . i had forgotten this , but , matched is not actually clean . what it is just that , u the training and testing are similar .  what you would do in practice is you 'd try to get as many , examples of similar as you could , and then ,  the argument for that being the more important thing , is that you 're gonna try and do that , but you wanna see how badly it deviates from that when the , it 's a little different .  but no . that 's a that 's an arg that 's an ar that 's an argument for it , but let me give you the opposite argument . the opposite argument is you 're never really gonna have a good sample of all these different things . are you gonna have w examples with the windows open , half open , full open ? going seventy , sixty , fifty , forty miles an hour ? on what roads ? with what passing you ? with  that you could make the opposite argument that the matched case is a fantasy .   that if you look at the matched case versus the po the medium and the fo and then the mismatched case , we 're seeing really , really big differences in performance . right ? and y you wouldn't like that to be the case . you wouldn't like that as soon as you step outside a lot of the cases it 's is in these cases , if you go from the , i don't remember the numbers right off , but if you go from the matched case to the medium , it 's not an enormous difference in the training testing situation , and it 's a really big performance drop .    the reference one , this is back old on , on italian was like six percent error for the matched and eighteen for the medium matched and sixty for the for highly mismatched .  ","they don they don't really know , the argument for that being the more important thing , is that you 're gonna try and do that , but you wanna see how badly it deviates from that when the , it 's a little different . the opposite argument is you 're never really gonna have a good sample of all these different things . ",
Bro014.B,"and , with these other systems we helped it out quite a bit , but still there 's something like a factor of two between matched and medium matched . and think that if what you 're if the goal of this is to come up with robust features , it does mean you could argue , that the matched is something you shouldn't be looking that the goal is to come up with features that will still give you reasonable performance , with again gentle degregra degradation , even though the testing condition is not the same as the training . i could argue strongly that something like the medium mismatch , which is not compl pathological but what was the medium mismatch condition again ? right . it 's still the same microphone in both cases , but , it 's there 's a mismatch between the car conditions . and that 's you could argue that 's a pretty realistic situation and , i 'd almost argue for weighting that highest . but the way they have it now , it 's it 's they compute the relative improvement first and then average that with a weighting ? and then the that makes the highly matched the really big thing .  u i since they have these three categories , it seems like the reasonable thing to do is to go across the languages and to come up with an improvement for each of those . just say "" in the highly matched case this is what happens , in the m the , this other m medium if this happens , in the highly mismatched that happens "" . and , you should see , a gentle degradation through that .  but i don't know . that i i gather that in these meetings it 's really tricky to make anything ac make any policy change because everybody has , their own opinion and i don't know .     nobody would be there , probably . right ? good . work to do . whose vad is this a ? th that would be good . it 's not that the design of the vad isn't important , but it 's just that it does seem to be i a lot of work to do a good job on that and as as being a lot of work to do a good job on the feature design ,  if we can cut down on that we can make some progress .    but i bu you m s but let 's say for ins see , mfcc doesn't have anything in it , related to the pitch . just suppose you 've that what you really wanna do is put a good pitch detector on there and if it gets an unambiguous if it gets an unambiguous result then you 're definitely in a in a voice in a , s region with speech .  for the baseline . if you use other features then y ","i gather that in these meetings it 's really tricky to make anything ac make any policy change because everybody has , their own opinion whose vad ",
Bro014.B,"but it 's just a question of what is your baseline . right ? what is it that you 're supposed to do better than ? and having the baseline be the mfcc 's means that people could choose to pour their ener their effort into trying to do a really good vad or tryi they 're separate . unfortunately there 's coupling between them , which is part of what stephane is getting to , is that you can choose your features in such a way as to improve the vad . and you also can choose your features in such a way as to prove improve recognition . they may not be the same thing . you should do both and that this still makes i still think this makes sense as a baseline . it 's just saying , as a baseline , we know we had the mfcc 's before , lots of people have done voice activity detectors , you might as pick some voice activity detector and make that the baseline , just like you picked some version of htk and made that the baseline . and then let 's try and make everything better .  and if one of the ways you make it better is by having your features be better features for the vad then that 's be it . but , at least you have a starting point that 's  cuz i some of the people didn't have a vad right ? and then they looked pretty bad and what they were doing wasn't bad but ,   it seems like ,  it should include the current state of the art that you want are trying to improve , and mfcc 's , or plp it seems like reasonable baseline for the features , and anybody doing this task , is gonna have some voice activity detection at some level , in some way . they might use the whole recognizer to do it but rather than a separate thing , but they 'll have it on some level .   people just had it wasn't that they purposely brain damaged it . people hadn't really thought through about the , the vad issue . and then when the proposals actually came in and half of them had v a ds and half of them didn't , and the half that did and the half that didn't did poorly . it 's  right . when you say "" we have that "" , does sunil have it now , too , or ?   but how much worse since the weighting might change how much worse is it on the other conditions , when you say it 's a little worse ?   but it has the , the latencies are much shorter . that 's  but the latencies but you 've got the latency shorter now .  it 's better than the system that we had before .   that 's all fine . but what you 're saying is that when you do these ","when you say "" we have that "" , does sunil have it now , too , but it has the , the latencies are much shorter . ",
Bro014.B,"let me try to understand . when you do these same improvements to proposal one , that , on the i things are somewhat better , in proposal two for the matched case and somewhat worse for the other two cases . does , when you say ,  the th now that these other things are in there , is it the case that the additions of proposal two over proposal one are less im important ? i get it .  right .   there was a start of some effort on something related to voicing is that ?  w what yo what you 're calling the excitation , as i recall , is you 're subtracting the , the mel filter , spectrum from the fft spectrum . right . it 's not really an excitation , but it 's something that hopefully tells you something about the excitation .    except the variance was big . right ?  but another way of looking at it might be that what w we are coming up with feature sets after all . another way of looking at it is that the mel cepstru mel spectrum , mel cepstrum , any of these variants , give you the smooth spectrum . it 's the spectral envelope . by going back to the fft , you 're getting something that is more like the raw data . the question is , what characterization and you 're playing around with this another way of looking at it is what characterization of the difference between the raw data and this smooth version is something that you 're missing that could help ? looking at different statistical measures of that difference , coming up with some things and just trying them out and seeing if you add them onto the feature vector does that make things better or worse in noise , where you 're really just i the way i 'm looking at it is not much you 're trying to f find the best the world 's best voiced unvoiced , classifier , but it 's more that , try some different statistical characterizations of that difference back to the raw data and m there 's something there that the system can use .  that 's the rea w what i 'm arguing is that 's  what i 'm arguing is that 's givi you gives you your intuition . but in reality , it 's there 's all of this overlap and forth , and but what i 'm saying is that may be because what you 're really getting is not actually voiced versus unvoiced , both for the fac the reason of the overlap and then , th structural reasons , like the one that chuck said , that the data itself is that you 're working with is not perfect . what i 'm saying is that 's not a killer because you 're just getting some characterization , one that 's driven by your intuition about voiced unvoiced certainly , ","there was a start of some effort on something related to voicing what yo what you 're calling the excitation , as i recall , is you 're subtracting the , the mel filter , spectrum from the fft spectrum . it 's not really an excitation , but it 's something that hopefully tells you something about the excitation . another way of looking at it is what characterization of the difference between the raw data and this smooth version is something that you 're missing that could help ? looking at different statistical measures of that difference , and seeing if you add them onto the feature vector does that make things better or worse in noise , the way i 'm looking at it is not much you 're trying to f find the best the world 's best voiced unvoiced , classifier , but it 's more that , try some different statistical characterizations of that difference back to the raw data that the data itself is that you 're working with is not perfect . what i 'm saying is that 's not a killer because you 're just getting some characterization , one that 's driven by your intuition about voiced unvoiced certainly , ","They discussed a conference call with project partners, there have been some developments that should help speed up experiments, along with some progress made in the current area they are looking, voiced/unvoiced detection. "
Bro014.B,"but it 's just some characterization of something back in the in the almost raw data , rather than the smooth version . and your intuition is driving you towards particular kinds of , statistical characterizations of , what 's missing from the spectral envelope . you have something about the excitation ,  and what is it about the excitation , and , and you 're not getting the excitation anyway ,  would almost take a especially if these trainings and forth are faster , i would almost just take a a scattershot at a few different ways of look of characterizing that difference and , you could have one of them but and see , which of them helps . but each one of the mixture components you have , variance only , it 's like you 're just multiplying together these , probabilities from the individual features within each mixture . it 's   it seems l    i know that , people doing some robustness things a ways back were just doing just being gross and just throwing in the fft and actually it wasn't wasn't bad . it would s and that i it 's gotta hurt you a little bit to not have a spectral , s a smooth spectral envelope , there must be something else that you get in return for that that ,   you essentially take the values that th that you get from the triangular filter and extend them to sor like a rectangle , that 's at that m value .     right .  no , it 's makes sense to look at low frequencies . right . this is i you could argue about whether it should be linear interpolation or zeroeth order , but at any rate something like this is what you 're feeding your recognizer , typically . no . the mel cepstrum is the is the cepstrum of this , spectrum or log spectrum , whatever it you 're subtracting in power domain or log domain ?  it 's like division , when you do the the spectra .   but , anyway ,  and that 's  that makes sense .     all   pitch .  that 's like fundamental frequency . i t to first order what you 'd what you 're doing ignore all the details and all the ways which is that these are complete lies . the what you 're doing in feature extraction for speech recognition is you have , in your head a simplified production model for speech , in which you have a periodic or aperiodic source that 's driving some filters . first order for speech recognition , you say "" i don't care about the source "" . right ? and you just want to find out what the filters are . the filters roughly act like a , , an overall resonant f some resonances and forth that th that 's processing excitation . ","and , and you 're not getting the excitation anyway , ",
Bro014.B,"if you look at the spectral envelope , just the very smooth properties of it , you get something closer to that . and the notion is if you have the full spectrum , with all the little nitty gritty details , that has the effect of both , and it would be a multiplication in frequency domain that would be like an addition in log power spectrum domain . and this is saying , if you really do have that vocal tract envelope , and you subtract that off , what you get is the excitation . and i call that lies because you don't really have that , you just have some signal processing trickery to get something that 's smooth . it 's not really what 's happening in the vocal tract you 're not really getting the vocal excitation . that 's why i was going to the why i was referring to it in a more , conservative way , when i was saying "" it 's  it 's the excitation "" . but it 's not really the excitation . it 's whatever it is that 's different between stand standing back from that , you say there 's this very detailed representation . you go to a smooth representation . you go to a smooth representation cuz this typically generalizes better .  but whenever you smooth you lose something , the question is have you lost something you can you use ? probably you wouldn't want to go to the extreme of just ta saying "" our feature set will be the fft "" , cuz we really think we do gain something in robustness from going to something smoother , but there 's something that we missed . what is it ? and then you go back to the intuition that , you don't really get the excitation , but you get something related to it . and it and as you can see from those pictures , you do get something that shows some periodicity , in frequency ,  and also in time .    but presumably you 'll see something that won't have this regularity in frequency , in the        it looks better , but , if , if you 're actually asking if you actually j need to do place along an fft , it may be pushing things . and ,  the spectral subtraction is being done at what level ? is it being done at the level of fft bins or at the level of , mel spectrum how are they doing it ? in that case , it might not make much difference  certainly it 'd be better .    what else ?  has anything happened yet on this business of having some standard , source , or ?  early june , late june , middle june ?    and he 's been doing all the talking but these he 's , this is this bad thing . ","and this is saying , if you really do have that vocal tract envelope , and you subtract that off , what you get is the excitation . and i call that lies because you don't really have that , you just have some signal processing trickery to get something that 's smooth . you 're not really getting the vocal excitation . that 's why i was going to the why i was referring to it in a more , conservative way , when i was saying "" it 's it 's the excitation "" . but it 's not really the excitation . you don't really get the excitation , but you get something related to it . has anything happened yet on this business of having some standard , source , and he 's been doing all the talking this is this bad thing . ",
Bro014.B,"we 're trying to get , m more female voices in this record as  make sur make carmen talks as but has he been talking about what you 're doing also , and ? yes .  we 'll get to , spanish voices sometime , and we do we want to recognize , you too . no . we like we 're w we are we 're in the , bourlard hermansky morgan , frame of mind . we like high error rates . it 's that way there 's lots of work to do . it 's  anything to talk about ?  this is in order to use the sri system right ?    it 's  certainly in a short term this just sounds easier .  longer term if it 's if it turns out to be useful , one might want to do something else , but in other words , you may be putting other kinds of errors in from the re synthesis process .  it depends what you do . it 's it 's ,  don't know . but anyway it sounds like a reasonable way to go for a for an initial thing , and we can look at exactly what you end up doing and then figure out if there 's some something that could be hurt by the end part of the process .  that 's that was it ,   anything to add ?    this goes back to earlier by drullman . and , the msg features were built up with this notion but , you had brought this up in the context of , targets somehow . but i m i it 's not they 're not in the same category as , say , a phonetic target or a syllabic target or a or a feature i see . that 's what msg does . right ? it 's but ,  anyway , we 'll talk more about it later .    le let 's do digits . let you start . ","we 're trying to get , m more female voices in this record as make sur make carmen talks as anything to add ? ",A number of other members of the group also reported the progress they were making on their work. 
Bro014.C,"yes , again . we did it again , morgan . is he gonna come here ? when you said "" in town "" , oregon .  i have something just fairly brief to report on . i did some experim just a few more experiments before i had to , go away for the w that week . was it last week or whenever ?  what i was started playing with was the th again , this is the htk back end . and , i was curious because the way that they train up the models , they go through about four rounds of training . and in the first round they do it 's three iterations , and for the last three rounds e they do seven iterations of re estimation in each of those three . and that 's part of what takes long to train the back end for this .   should write it on the board . there 's four rounds of training .  i g you could say iterations . the first one is three , then seven , and seven . and what these numbers refer to is the number of times that the , re estimation is run . it 's this program called h e  what happens is , at each one of these points , you increase the number of gaussians in the model .  the mix up . right . and in the final one here , you end up with , for all of the digit words , you end up with , three mixtures per state , in the final thing . had done some experiments where i was i want to play with the number of mixtures . but , i wanted to first test to see if we actually need to do this many iterations early on . and i ran a couple of experiments where i reduced that to l to be three , two , five , and i got almost the exact same results . and but it runs much faster .  it only took something like , three or four hours to do the full training , as opposed to wh what , sixteen hours like that ? it takes you have to do an overnight the way it is set up now .   even we don't do anything else , doing something like this could allow us to turn experiments around a lot faster . and when you have your final thing , we go back to this .  and it 's a real simple change to make . it 's like one little text file you edit and change those numbers , and you don't do anything else . and then you just run . it 's a very simple change to make and it doesn't seem to hurt all that much .  i have to look to see what the exact numbers were . was three , two , five , but i 'll double check . ","i have something just fairly brief to report on . what i was started playing with was the th again , this is the htk back end . i was curious because the way that they train up the models , they go through about four rounds of training . that 's part of what takes long to train the back end for this . the first one is three , then seven , and seven . and what these numbers refer to is the number of times that the , re estimation is run . i wanted to first test to see if we actually need to do this many iterations early on . i ran a couple of experiments where i reduced that to l to be three , two , five , and i got almost the exact same results . and but it runs much faster . it only took something like , three or four hours to do the full training , as opposed to wh what , sixteen hours like that ? even we don't do anything else , doing something like this could allow us to turn experiments around a lot faster . and when you have your final thing , we go back to this . it 's like one little text file you edit and change those numbers , ","They discussed a conference call with project partners, there have been some developments that should help speed up experiments, along with some progress made in the current area they are looking, voiced/unvoiced detection. "
Bro014.C,"it was over a week ago that i did it , can't remember exactly . but , but it 's much faster . i it makes a big difference . we could do a lot more experiments and throw a lot more in there .  the other thing that i did was , i compiled the htk for the linux boxes . we have this big thing that we got from ibm , which is a five processor machine . really fast , but it 's running linux . you can now run your experiments on that machine and you can run five at a time and it runs , as fast as , five different machines .  i 've forgotten now what the name of that machine is but send email around about it . and we 've got it now htk 's compiled for both the linux and for , the sparcs . you have to make that in your dot cshrc , it detects whether you 're running on the linux or a sparc and points to the right executables .  and you may not have had that in your dot cshrc before , if you were always just running the sparc .   tell you exactly what you need to do to get all of that to work . but it 'll it really increases what we can run on . together with the fact that we 've got these faster linux boxes and that it takes less time to do these , we should be able to crank through a lot more experiments .  after i did that , then what i wanted to do was try increasing the number of mixtures , just to see , see how that affects performance .   exactly . right . right .   let 's see ,  it goes from this try to go it backwards this at this point it 's two mixtures per state . this just adds one . except that , actually for the silence model , it 's six mixtures per state . it goes to two .  and what happens here is that 's what it is .  it 's , shoot . i can't remember now what happens at that first one . i have to look it up and see .  there because they start off with , an initial model which is just this global model , and then they split it to the individuals . and it may be that 's what 's happening here . i have to look it up and see . i don't exactly remember . that 's it .  how should that be done ? it seems like there 's a simple way this seems like an obvious mistake th they 're  it seems like they should do the percentage improvement rather than the absolute improvement .  why don't they not look at improvements but just look at your av your scores ? figure out how to combine the scores with a weight or whatever , ","we could do a lot more experiments and throw a lot more in there . the other thing that i did was , i compiled the htk for the linux boxes . we have this big thing that we got from ibm , which is a five processor machine . really fast , but it 's running linux . you can now run your experiments on that machine i 've forgotten now what the name of that machine is but send email around about it . you have to make that in your dot cshrc , it detects whether you 're running on the linux or a sparc and points to the right executables . and you may not have had that in your dot cshrc before , if you were always just running the sparc . tell you exactly what you need to do to get all of that to work . after i did that , then what i wanted to do was try increasing the number of mixtures , just to see , see how that affects performance . ","They discussed a conference call with project partners, there have been some developments that should help speed up experiments, along with some progress made in the current area they are looking, voiced/unvoiced detection. "
Bro014.C,"and then give you a score here 's your score . and then they can do the same thing for the baseline system and here 's its score . and then you can look at    it sounds like they don't really have a good idea about what the final application is gonna be .   what i 'm i was thinking about it in terms of , if i were building the final product and i was gonna test to see which front end i 'd i wanted to use , i would try to weight things depending on the exact environment that i was gonna be using the system in . if i  if they don't know , doesn't that suggest the way for them to go ?  you assume everything 's equal . y you  right .  not not try to combine them .  the training and testing .   you should weight those other conditions v very really small . that 's more of an information thing .     that 'll teach them to roll their window up .    minute . i 'm confused . wha what do  i see . there 's this assumption that the v the voice activity detector can only use the mfcc ?  i g  i don't s but they seem like two separate issues . right ?  but it seems like you should do both . right ? it seems like you should try to make your baseline as good as possible . and if it turns out that you can't improve on that , then , nobody wins and you just use mfcc . right ? it seems like whatever they choose they shouldn't , purposefully brain damage a part of the system to make a worse baseline , or    is this related to the issue that you brought up a couple of meetings ago with the musical tones and ?  what sorts of what sorts of features are you looking at ? minute . i what does that mean ? the variance of the spectrum of excitation . how do how did you get your voiced and unvoiced truth data ? is this a s a trained system ? or is it a system where you just pick some thresholds ? ho how does it work ?  because it seems like what you said about the mean of the voiced and the unvoiced that seemed pretty encouraging . right ? y y i don't know that i would trust that much because you 're doing these canonical mappings from timit labellings . right ?  really that 's cartoon picture about what 's voiced and unvoiced . that could be giving you a lot of variance .  i it may be that you 're finding something good and that the variance is artificial because of how you 're getting your truth .  right . right . is the idea that you 're going to take whatever features you develop and just add them onto the future vector ? ",it sounds like they don't really have a good idea about what the final application is gonna be . what sorts of features are you looking at ? really that 's cartoon picture about what 's voiced and unvoiced . ,
Bro014.C,"or , what 's the use of the voiced unvoiced detector ? it 's not part of a vad system that you 're doing ?   features . i see .   it 's a neat thing . it seems like a good idea . how does 'm going in too much detail , but how exactly do you make the difference between the fft and the smoothed spectral envelope ? wha wh i how is that ,   you end up with a vector that 's the same length as the fft vector ? and then you just , compute differences and , sum the differences ?  this is this is comparing an original version of the signal to a smoothed version of the same signal ?  like which of the ?  right , right . it 's the ratio . what 's th what 's the intuition behind this thing ? i don't know really know the signal processing enough to understand what is that doing .   right .      i see . do you have a picture that sh ? is this for a voiced segment , this picture ? what does it look like for unvoiced ? this is the difference .    does the periodicity of this signal say something about the the pitch ?   i see .   right . right .        right .  this moved in the    right .      that 's really neat . you don't have one for unvoiced picture ?  i would li i would like to see those pictures .  and you said this is pretty doing this thing is pretty robust to noise ?  you end up with a similar difference over here ?   that 's clean .    this one inclu is a longer it 's that time frequency trade off thing . right ? i see .  this i is this the difference here , for that ? that 's the f the original .      that 's interesting . would you wanna do this difference thing after you do spectral subtraction ? seems like you 'd wanna do it on the fft bins . if you were gonna for this purpose , that is . when is the next , aurora deadline ? june . y should we do digits ? ",and you said this is pretty doing this thing is pretty robust to noise ? you end up with a similar difference ,
Bro014.D,"channel three . channel three . channel three . alright . n not much is new . when i talked about what i 'm planning to do last time , i said i was , going to use avendano 's method of , using a transformation , to map from long analysis frames which are used for removing reverberation to short analysis frames for feature calculation . he has a trick for doing that involving viewing the dft as a matrix .  but , i decided not to do that after all because i realized to use it i 'd need to have these short analysis frames get plugged directly into the feature computation somehow and right now our feature computation is set to up to , take , audio as input , in general . decided that i 'll do the reverberation removal on the long analysis windows and then just re synthesize audio and then send that .  or or even if i 'm using our system , i was thinking it might be easier to just re synthesize the audio , because then i could just feacalc as is and i wouldn't have to change the code .  right . that 's true . but e u from the re synthesis ?  o i don't know anything about re synthesis . how likely do you think that is ?  that e that 's it , that 's it .   ","n not much is new . when i talked about what i 'm planning to do last time , i said i was , going to use avendano 's method of , using a transformation , to map from long analysis frames which are used for removing reverberation to short analysis frames for feature calculation . but , i decided not to do that after all because i realized to use it i 'd need to have these short analysis frames get plugged directly into the feature computation somehow and right now our feature computation is set to up to , take , audio as input , in general . decided that i 'll do the reverberation removal on the long analysis windows and then just re synthesize audio ",A number of other members of the group also reported the progress they were making on their work. 
Bro014.E,"almost . doo doop , doo . doo , doo . doo . one , two ,     at the middle o where the arrows are showing , that 's you 're adding one more mixture per state , or ?    for    it 's noisy timit .   looks     i 've been continuing reading . i went off on a little tangent this past week ,  looking at , modulation s spectrum  and learning a bit about what , what it is , and , the importance of it in speech recognition . and i found some , neat papers , historical papers from , kanedera , hermansky , and arai . and they did a lot of experiments where th where , they take speech and , e they modify the , they measure the relative importance of having different , portions of the modulation spectrum intact . and they find that the spectrum between one and sixteen hertz in the modulation is , is im important for speech recognition .   right . right .    i was thinking more like using them as the inputs to the detectors .    s   we can talk more about it later .  l fifty . ","i 've been continuing reading . i went off on a little tangent this past week , looking at , modulation s spectrum and learning a bit about what , what it is , and i found some , neat papers , historical papers from , kanedera , hermansky , and arai . and they did a lot of experiments where th where , they take speech and , e they modify the , they measure the relative importance of having different , portions of the modulation spectrum intact . and they find that the spectrum between one and sixteen hertz in the modulation is , is im important for speech recognition . i was thinking more like using them as the inputs to the detectors . ",A number of other members of the group also reported the progress they were making on their work. 
Bro014.F," good . it depends .  this is a    isn't it i have the picture .  we have some this , and this .  we have here some histogram , but they have a lot of overlap .  we , use timit on this , for but if we look at it in one sentence , it it 's good ,   no . we distend the we have the twenty three coefficient af after the mel f filter , and we extend these coefficient between the all the frequency range . and i the interpolation i between give for the triang triangular filter , the value of the triangular filter and of this way we obtained this mode this model speech .   it 's linear .  at the n at the center of the filter   i have here one example if you want see something like that . two thou two fifteen hundred ? no . two hundred and fifty thousand .  two thousand and fifteen hundred .  log domain .   the dif no . unvoiced , i don't have for unvoiced . i 'm  this is the between no . but it 's this , but between the frequency that we are considered for the excitation for the difference and this is the difference .  because we begin , in fifteen point the fifteen point . fifteen p  this is the auto correlation the r zero energy . for  i have the mean .  here . no . this is this ? more close . is this ? and this .  less robust .  not here . no , i have s but not here . not here .  i can't see you now . i don't have . pfft .  the mean is different with it , because the histogram for the classifica   i have here the same frame for the clean speech the same cle but they are a difference . because here the fft is only with two hundred fifty six point and this is with five hundred twelve . fifty millis  no . this is the signal . this is the signal . the frame . this is the fra the original frame .  and here no , no . we can do that . fft . filter bank ,   i am doing this .  i don't know . i 'm but that for the recognizer for the meeting recorder that it 's better that i don't speak . because after the after , the result for the ti digits on the meeting record there will be foreigns people . ",i don't know . that for the recognizer for the meeting recorder that it 's better that i don't speak . ,
Bro015.A," they would just provide that as part of the data . how about the the thing that you guys were working on before the voiced unvoiced  you stopped working on it i see no . i didn't . are you talking about no . this week i haven't . i 've been my whole time 's been taken up with meeting recorder disk crash and covering things . there is one other thing . stephane showed me a paper yesterday where th for the italian system they had done a series of experiments playing around with the the number of iterations , that i talked about last week ? and , there was a whole series of those that they had done . they didn't , i don't think , reported timing for those , but it turns out that the one that they 're actually using was not the best , in their series of experiments , which i it 's because they wanted to use the same number of iterations across all different languages and this was only done on italian i don't know who did it do stephane ? who did that ? there wasn't a huge difference in terms of the performance across all the different experiments that they did . but it varied a little bit . and guess the main thing that i take out of that is that that for our purposes here we could definitely decrease the number of iterations that we do and at least while we 're , working on all different of kinds of variations , and that would let us , pump through a lot more experiments . still have to send everybody a pointer about how to run the htk system on the linux boxes and about changing these number of iterations that you can do that . the other thing that i was thinking about trying out next is   the other th the other experiment that they had in that paper was playing with the number of gaussians per state . and  i should look at that more carefully cuz i wonder what they did about  i was thinking it was gaussians but it 's states .    the thing i was thinking about was the number of insertions really goes up when you start adding all the noise in , and the thing to do next would be to try to make the silence model more powerful , increasing the number of gaussians to the number of states , different things like that , that 's probably the next little thing i 'll play with when i get a chance ",,
Bro015.B,"one thing in the paper avendano and his collaborators wrote is that they tried doing channel normalization on the reverberant in speech by subtracting the mean of the log spectral magnitude over a two second window . but they didn't do anything with the phase , and they said perhaps that limited their approach that it did not try to normalize the phase in any way . 'm going to start thinking about ways that the ph that the phase could be used .  si if the channel and the reverberation is multiplicative in the frequency domain with the speech spectrum then the phases should be additive . perhaps just subtracting the mean of the phase would help . but i don't th i get the impression that they tried to do some things with the phase and they weren't successful . ",,
Bro015.C,"alright . it will be some sometime in summer . july or august , or .   the news more specifically t for aurora  guess there was again a conference call but they are not decide on everything yet . for the vad they probably they will do something like having some idealized vad that they could run on the channel zero of the speechdat car and then take the same end points and apply them on channel one it 's  to the clean and take the end points for the noisy .  but i am not this is decided yet .  probably the same vad for everybody .   but this is still they 're still not decided . don't  nothing much .  probably the these weight things , they will apply the same weighting scheme for ti digits than for the speechdat car . it would be weighting of  it would be an average of improvements rather than an average of word error rates which would make the more clean parts of ti digits more important than they are right now . this they t they will tend to go this way , but  if we have the result for the tandem with msg also @ it was t there is no surpri there is no surprise . there is nor significant improvement . that 's all . we 've started to work on some report for the work we 've not much more results .   it 's next week ,     right now , sunil seems i is in india actually . there is no progress from their side neither . and i 'm  sunil was working on this . he sent a bunch of results  but i don't 's the status of this . it was just the result that he sent ,  he just used the spectral subtraction and the lda filters and it was not better than what we had before . then he tried to put the on line normalization and it did not improve further , putting the on line normalization ,     no . i sent mails to start the process and we should have to we know most what we have to put in this . and .  we m  i don't know but it 's the company who prepared the italian database , it was is it alcatel , or ? i i don't know .  it 's was playing with the number of states per word . they had sixteen , seventeen , eighteen . because it was around between sixteen and twenty or  and they had better results when they increased the number of states . from eighteen to twenty , or d ' you put two ?  maria carmen ? ",,
Bro015.D,"alright . i wanted to mention a couple little bits of news . hynek is supposed to come for a couple days next week . don't know which days yet . hopefully he 'll have some intensive time to work with people . the second thing is that we 're starting to talk about having sunil come here for some chunk of the summer . that may or may not happen but if he does since actually pratibha is going to be off at ibm the effort will shift here , cuz sunil will be here and other people are working on other things  that 's my news .  there you go . it may not happen . he wants think he wants some experience someplace else and he 's thinking of going someplace , but it 's pratibha is getting her experience going to ibm and he may come here .  but y i don't know june . earlier . but anyway , hynek will be here next week and he 'll know more about it .  take a real vad but apply it to the clean data .  and i when they 're talking about it , do you have the impression that they 're talking about a particular vad which everybody would use ? or just that everybody would use the same procedure ?   sounds like they 're still arguing .      but it sounds like none of this is really decided , that this is how things are leaning and  you have a you have a lunch talk sometime in when is it ? next week ?    it sounds like things are slowing down a bit ? and trying to collate results ? and get something from it ?  right . right . but that puts it on us to do it . but . puts it on us to put more in , then , really . who 's was looking at the combination of spectral s subtraction approaches with what we had  what was that again ?  and      i i g guess nothing has ever happened about making a standardized place where the software sits that people can work with it , and upgrade it ?  let 's come back to this later .  chuck , did you get a chance to do anymore with the htk , or ?  u  this may be a very short meeting .  anything from your side ?   dave ?    wh who 's they ?    let 's see . why don't we if there aren't any other major things , why don't we do the digits , and then turn the mikes off . 'll start .   ",,
Bro015.E,"yes . but , no . this week i 'm i am begin to write the report on i stopped it . interfered .   my name is maria . this .  ",,
Bro015.F, i need a new office mate .  that 's right . continuing readings we come we 're doing some background reading on phonetics .  ,,
Bro016.A,"hello ? hello ? voicing thing .   right . continuing looking at , ph phonetic events , and , this tuesday gonna be , meeting with john ohala with chuck to talk some more about these , ph phonetic events . came up with , a plan of attack , gonna execute , and   it 's that 's it .  you you want details .   i was hoping i could wave my hands .    once wa i was thinking getting us a set of acoustic events to to be able to distinguish between , phones and words and and once we we would figure out a set of these events that can be , hand labeled or derived , from h the hand labeled phone targets . we could take these events and , do some cheating experiments , where we feed , these events into an sri system , and evaluate its performance on a switchboard task .    give you an example of twenty odd events .  he in this paper , it 's talking about phoneme recognition using acoustic events . things like frication or , nasality .  this is a paper by hubener and cardson benson bernds berndsen .      good . that 's great .        using these events , we can perform these , cheating experiments . see how good they are , in , in terms of phoneme recognition or word recognition . and ,  and then from that point on , i would , s design robust event detectors , in a similar , wa spirit that saul has done w with his graphical models , and this probabilistic and or model that he uses .  try to extend it to , to account for other phenomena like , cmr co modulation release . and ,  and also investigate ways to modify the structure of these models , in a data driven way , similar to the way that , jeff , bilmes did his work .  and while i 'm doing these , event detectors , ma mea measure my progress by comparing , the error rates in clean and noisy conditions to something like , neural nets .  and  once we have these , event detectors , we could put them together and feed the outputs of the event detectors into the sri , system , and ,  and test it on switchboard or , even aurora and , that 's the big picture of the plan .      ","continuing looking at , ph phonetic events , and , this tuesday gonna be , meeting with john ohala with chuck to talk some more about these , ph phonetic events . came up with , a plan of attack , it 's that 's it . i was thinking getting us a set of acoustic events to to be able to distinguish between , phones and words and we would figure out a set of these events that can be , hand labeled or derived , from h the hand labeled phone targets . we could take these events and , do some cheating experiments , where we feed , these events into an sri system , and evaluate its performance on a switchboard task . he in this paper , it 's talking about phoneme recognition using acoustic events . things like frication or , nasality . this is a paper by hubener and cardson benson bernds berndsen . ","Although the members of ICSI's Meeting Recorder Group at Berkeley had little progress to report, there were still a number of issues relating to their work to discuss. These included making plans for upcoming experiments, clarifying definitions, and approaches which may or may not be against the rules of the Aurora project, alongside alternatives that would not be. "
Bro016.B,"channel one .   alright .    it 's much more balanced with , when the front end is more robust .  i could look at it at this .   i don't know . i don't have this in       there 's nothing new .  i 'm  we 've been mainly working on the report and  on the report of the work that was already done .   that 's all . yea  y we 've stopped , experimenting , we 're just writing some technical report . and        we didn't we just planned to work on it one week on this report , not no more , anyway .       don't know . there are small things that we started to do . but    and actually , there were some tables that were also with partial results . we just noticed that , wh while gathering the result that for some conditions we didn't have everything . but anyway .   we have , extracted actually the noises from the speechdat car . and we can train neural network with speech and these noises .  it 's difficult to say what it will give , because when we look at the aurora the ti digits experiments , they have these three conditions that have different noises , and this system perform as on the seen noises on the unseen noises and on the seen noises . but , this is something we have to try anyway .  adding the noises from the speechdat car .    ogi does did that .  at some point they did that for the voice activity detector . right ?  they used some parts of the , italian database to train the voice activity detector , it  and spanish ,   that 's right .   different cars .        what do we like , we have male , female , at least .      do you have something simple in mind for vocal tract length normalization ?       almost ,    this noise ,  the msg   there is something perhaps , i could spend some days to look at this thing , cuz it seems that when we train networks on let 's say , on timit with msg features , they look as good as networks trained on plp . but ,  when they are used on the speechdat car data , it 's not the case  the msg features are much worse , and they 're , less more sensitive to different recording conditions , or shou  but  i don't know . i cannot tell . but it 's it the error rate is higher . i don        but  but , it 's d it 's after it 's tandem features ,    we have estimation of post posteriors with plp and with msg as input , don  i don't know .       we should look at the likelihood , or what ? or  at the log , perhaps , and    but yes . no , they are not no .    but , my point was more that it works sometimes and but sometimes it doesn't work .  ","there 's nothing new . we 've been mainly working on the report on the report of the work that was already done . y we 've stopped , experimenting , we 're just writing some technical report .   actually , there were some tables that were also with partial results . we just noticed that , wh while gathering the result that for some conditions we didn't have everything . we have , extracted actually the noises from the speechdat car . we can train neural network with speech and these noises . it 's difficult to say what it will give , this is something we have to try anyway . adding the noises from the speechdat car .  ogi does did that . at some point they did that for the voice activity detector . and spanish , different cars . ","Although the members of ICSI's Meeting Recorder Group at Berkeley had little progress to report, there were still a number of issues relating to their work to discuss. "
Bro016.B,"and it works on ti digits and on speechdat car it doesn't work , and            there is also the spectral subtraction , which ,  we should , try to integrate it in our system .   but , that would involve to use a big a al already a big bunch of the system of ericsson . because he has spectral subtraction , then it 's followed by , other processing that 's are dependent on the if it 's speech or noi or silence . and there is this spectral flattening after if it 's silence , and and s it 's important , to reduce this musical noise and this increase of variance during silence portions .   this was in this would involve to take almost everything from the this proposal and and then just add some on line normalization in the neural network .     ","there is also the spectral subtraction , we should , try to integrate it in our system . that would involve to use a big a al already a big bunch of the system of ericsson . because he has spectral subtraction , then it 's followed by , other processing that 's are dependent on the if it 's speech or noi or silence . and s it 's important , to reduce this musical noise and this increase of variance during silence portions . this was in this would involve to take almost everything from the this proposal and then just add some on line normalization in the neural network . ",
Bro016.C,"test . i don't have results yet . to try to found , nnn , robust feature for detect between voice and unvoice . and we w we try to use the variance of the es difference between the fft spectrum and mel filter bank spectrum . also the another parameter is relates with the auto correlation function . r ze energy and the variance a also of the auto correlation function .  but we don't have res we don't have result of the auro for aurora yet . we need to train the neural network and no , not yet . we work in the report , too , because we have a lot of result , they are very dispersed , and was necessary to look in all the directory to give some more structure . hm no . for icsi . just summary of the experiment and the conclusion and something like that . in july . first of july .  it 's not . for a v vad .  ","i don't have results yet . we work in the report , too , because we have a lot of result , they are very dispersed , and was necessary to look in all the directory to give some more structure . for icsi . just summary of the experiment and the conclusion first of july . ","Although the members of ICSI's Meeting Recorder Group at Berkeley had little progress to report, there were still a number of issues relating to their work to discuss. "
Bro016.D,"  i took a lot of time just getting my taxes out of the way multi national taxes . i 'm starting to write code now for my work but i don't have any results yet . i it would be good for me to talk to hynek , when he 's here . do what his schedule will be like ?  y     w for two thousand i did .  ye  i 'll still have a bit of canadian income but it 'll be less complicated because i will not be a considered a resident of canada anymore , won't have to declare my american income on my canadian return . hey , barry ? can you give an example of an event ?  ",i took a lot of time just getting my taxes out of the way i 'm starting to write code now for my work but i don't have any results yet . can you give an example of an event ? ,"Although the members of ICSI's Meeting Recorder Group at Berkeley had little progress to report, there were still a number of issues relating to their work to discuss. These included making plans for upcoming experiments, clarifying definitions, and approaches which may or may not be against the rules of the Aurora project, alongside alternatives that would not be. "
Bro016.E,"let 's see . test ? test ?   i was saying hynek 'll be here next week , wednesday through friday through saturday , and , i won't be here thursday and friday . but my suggestion is that , at least for this meeting , people should go ahead , cuz hynek will be here , and , we don't have any czech accent yet , as far as i know ,  there we go .  other than reading digits , what 's our agenda ?   do you think that would be the case for next week also ? or is , what 's your projection on ? cuz the one thing that seems to me we really should try , if you hadn't tried it before , because it hadn't occurred to me it was an obvious thing is , adjusting the , sca the scaling and , insertion penalty sorta right .  but you were looking at mel cepstrum . right . right . i it 's not the direction that you were working with that we were saying what 's the what 's the best you can do with mel cepstrum . but , they raised a very valid point , which , to first order you have other things you were gonna do , but to first order , i would say that the conclusion is that if you , do , some monkeying around with , the exact htk training and @ @ with , how many states and forth , that it doesn't particularly improve the performance . in other words , that even though it sounds pretty dumb , just applying the same number of states to everything , more or less , no matter what language , isn't bad . right ? and you hadn't gotten to all the experiments you wanted to do with number of gaussians , but , let 's just if we had to draw a conclusion on the information we have far , we 'd say something like that . right ? the next question to ask , which is the one that andreas was dre addressing himself to in the lunch meeting , is , we 're not supposed to adjust the back end , but anybody using the system would .  if you were just adjusting the back end , how much better would you do , in noise ? because the language scaling and insertion penalties and forth are probably set to be about right for mel cepstrum . but , they 're probably not set right for these things , particularly these things that look over , larger time windows , in one way or another with lda and klt and neural nets and all these things . in the fa past we 've always found that we had to increase the insertion penalty to correspond to such things .  that 's , @ @ that 's first order thing that we should try . ","i was saying hynek 'll be here next week , wednesday through friday through saturday , i won't be here thursday and friday . but my suggestion is that , at least for this meeting , people should go ahead , cuz hynek will be here , do you think that would be the case for next week also ? what 's your projection on ? cuz the one thing that seems to me we really should try , if you hadn't tried it before , because it hadn't occurred to me is , adjusting the , sca the scaling and , insertion penalty sorta but you were looking at mel cepstrum . i it 's not the direction that you were working with that we were saying what 's the what 's the best you can do with mel cepstrum . the next question to ask , which is the one that andreas was dre addressing himself to in the lunch meeting , is , we 're not supposed to adjust the back end , but anybody using the system would . if you were just adjusting the back end , how much better would you do , in noise ? because the language scaling and insertion penalties and forth are probably set to be about right for mel cepstrum . but , they 're probably not set right for these things , ","Plans were also made with regard to a visitor from research partner OGI These included making plans for upcoming experiments, clarifying definitions, and approaches which may or may not be against the rules of the Aurora project, alongside alternatives that would not be. "
Bro016.E,"by "" our front end "" take , the aurora two s take some version that stephane has that is , our current best version of something .  y don't wanna do this over a hundred different things that they 've tried but , for some version that you say is a good one .   how much , does it improve if you actually adjust that ? but it is interesting . you say you have for the noisy how about for the mismatched or the or the medium mismatched conditions ? have you ? when you adjusted those numbers for mel cepstrum , did it ?       and ,  also , sometimes if you run behind on some of these things , we can get someone else to do it and you can supervise but but it would be it 'd be good to know that .      cuz , the other that , might have been part of what , the difference was at least part of it that we were seeing . remember we were seeing the sri system was much better than the tandem system . part of it might just be that the sri system , they always adjust these things to be optimized , and yes . you can .   part of what 's going on , is the , the range of values . if you have something that has a much smaller range or a much larger range , and taking the appropriate root .  if something is like the equivalent of a bunch of probabilities multiplied together , you can take a root of some sort . if it 's like seven probabilities together , you can take the seventh root of it or if it 's in the log domain , divide it by seven . but but ,  that has a similar effect because it changes the scale of the numbers of the differences between different candidates from the acoustic model as opposed to what 's coming from the language model .  it 's more directly like the language scaling or the , the model scaling or acoustic scaling , but that those things have similar effect to the insertion penalty anyway . they 're a slightly different way of handling it .     that 's why that 's another reason other than curiosity as to why i it would be kinda neat to find out if we 're way off . the other thing is , are aren't we seeing ? y i 'm you 've already looked at this bu in these noisy cases , are ? we are seeing lots of insertions . right ? the insertion number is quite high ? i know the vad takes pre care of part of that , but  wha what 's a typical number ? do we ? you don't know .  i 'm it 's more balanced , but it wouldn't surprise me if there 's still ","by "" our front end "" take , the aurora two s take some version that stephane has that is , our current best version of something . how much , does it improve if you actually adjust that ? when you adjusted those numbers for mel cepstrum , did it ? but it would be it 'd be good to know that . part of what 's going on , is the , the range of values . if you have something that has a much smaller range or a much larger range , and taking the appropriate root . if something is like the equivalent of a bunch of probabilities multiplied together , you can take a root of some sort . because it changes the scale of the numbers of the differences between different candidates from the acoustic model as opposed to what 's coming from the language model . it 's more directly like the language scaling or the , the model scaling or acoustic scaling , ",
Bro016.E,"in the old systems we used to do , i i remember numbers like insertions being half the number of deletions , as being and both numbers being tend to be on the small side comparing to , substitutions . right . right .  and it may be less of a critical thing . the fact that some get by may be less of a critical thing if you , get things in the right range . the insertions is a symptom . it 's a symptom that there 's something , wrong with the range . but there 's your substitutions tend to go up as that , the most obvious thing is just the insertions , @ @ . but   if you 're operating in the wrong range that 's why just in general , if you change what these penalties and scaling factors are , you reach some point that 's a minimum .    we do have to do over a range of different conditions , some of which are noisier than others .  but , we may get a better handle on that if we see we ca it 's if we actually could pick a more stable value for the range of these features , it , could  even though it 's it 's true that in a real situation you can adjust the these scaling factors in the back end , and it 's ar artificial here that we 're not adjusting those , you certainly don't wanna be adjusting those all the time . and if you have a front end that 's in roughly the right range i remember after we got our more or less together in the previous systems we built , that we tended to set those scaling factors at standard level , and we would rarely adjust them again , even though you could get a for an evaluation you can get an extra point if you tweaked it a little bit . but , once we knew what rou roughly the right operating range was , it was pretty stable , and we might just not even be in the right operating range . no . you don't wanna change it for different conditions . no . no . i what i 'm saying  it depends how much we wanna do gamesmanship and how much we wanna do i if he it to me , actually , even if you wanna be play on the gamesmanship side , it can be kinda tricky . what you would do is set the scaling factors , that you got the best number for this point four five times the and on . but they might change that those weightings .    sorta think we need to explore the space . just take a look at it a little bit . and we may just find that we 're way off . we 're not .  as for these other things , it may turn out that , it 's reasonable . ","if you 're operating in the wrong range that 's why just in general , if you change what these penalties and scaling factors are , you reach some point that 's a minimum . we do have to do over a range of different conditions , some of which are noisier than others . but , we may get a better handle on that if we see it 's if we actually could pick a more stable value for the range of these features , it , could even though it 's it 's true that in a real situation you can adjust the these scaling factors in the back end , and it 's ar artificial here that we 're not adjusting those , you certainly don't wanna be adjusting those all the time . and if you have a front end that 's in roughly the right range i remember after we got our more or less together in the previous systems we built , that we tended to set those scaling factors at standard level , and we would rarely adjust them again , as for these other things , it may turn out that , it 's reasonable . ",
Bro016.E,"but then andreas gave a very reasonable response , and he 's probably not gonna be the only one who 's gonna say this in the future of , people within this tight knit community who are doing this evaluation are accepting , more or less , that these are the rules . but , people outside of it who look in at the broader picture are certainly gonna say "" minute . you 're doing all this standing on your head , on the front end , when all you could do is just adjust this in the back end with one s one knob . "" and we have to at least , determine that 's not true , which would be or determine that it is true , in which case we want to adjust that and then continue with what we 're doing . and as you say as you point out finding ways to then compensate for that in the front end also then becomes a priority for this particular test , and saying you don't have to do that .    what 's new with you ? what 's old with you that 's developed ? you  what 's old with you that has developed over the last week or two ? what was that ? what 's going on now ? what are you doing ?    that 's that 's what you were describing , a week or two ago .   you 're training neural networks now ? what wha wh wha what 's going on ?  b  i if summarize , what 's going on is that you 're going over a lot of material that you have generated in furious fashion , f generating many results and doing many experiments and trying to pull it together into some coherent form to be able to see wha see what happens . yes ?   my suggestion , though , is that you not necessarily finish that . but that you put it all together that it 's you 've got a clearer structure to it . what things are , you have things documented , you 've looked things up that you needed to look up . that , that such a thing can be written . and , when do you leave again ? first of july ?  and that you figure on actually finishing it in june . because , you 're gonna have another bunch of results to fit in there anyway . and right now it 's important that we actually go forward with experiments . it 's good to pause , and to gather everything together and make it 's in good shape , that other people can get access to it and that it can go into a report in june . but to really work on fine tuning the report n at this point is probably bad timing , but you ma you may really wanna add other things later anyway because you there 's more to go ? ","andreas gave a very reasonable response , and he 's probably not gonna be the only one who 's gonna say this in the future people within this tight knit community who are doing this evaluation are accepting , more or less , that these are the rules . but , people outside of it who look in at the broader picture are certainly gonna say "" minute . you 're doing all this standing on your head , on the front end , when all you could do is just adjust this in the back end with one s one knob . "" we have to at least , determine that 's not true , and as you say as you point out finding ways to then compensate for that in the front end also then becomes a priority for this particular test , what 's new with you ? what 's old with you that has developed over the last week or two ? what wha wh wha what 's going on ? i if summarize , what 's going on is that you 're going over a lot of material that you have generated in furious fashion , f generating many results and doing many experiments and trying to pull it together into some coherent form to be able to see wha see what happens . my suggestion , though , is that you not necessarily finish that . but that you put it all together that it 's you 've got a clearer structure to it . what things are , you have things documented , you 've looked things up that you needed to look up . that , that such a thing can be written . when do you leave again ? and that you figure on actually finishing it in june . because , you 're gonna have another bunch of results to fit in there anyway . and right now it 's important that we actually go forward with experiments . it 's good to pause , and to gather everything together and make it 's in good shape , that other people can get access to it and that it can go into a report in june . but to really work on fine tuning the report n at this point is probably bad timing , ","Although the members of ICSI's Meeting Recorder Group at Berkeley had little progress to report, there were still a number of issues relating to their work to discuss. There was also debate about the necessary continuation of a group report. "
Bro016.E,"that 's that 's , that 's permitted ?   that 's a matter of interpretation . the rules as i understand it , is that in principle the italian and the spanish and the english no , italian and the finnish and the english ? were development data on which you could adjust things . and the german and danish were the evaluation data . and then when they finally actually evaluated things they used everything .   and it is true that the performance , on the german was even though the improvement wasn't good , the pre the raw performance was really pretty good .  and , it doesn't appear that there 's strong evidence that even though things were somewhat tuned on those three or four languages , that going to a different language really hurt you . and the noises were not exactly the same . right ? because it was taken from a different ,  they were different drives . it was actual different cars and on .  it 's somewhat tuned . it 's tuned more than , a a you 'd really like to have something that needed no particular noise just some white noise like that a at most . but that 's not really what this contest is .  it 's that 's something i 'd like to understand before we actually use something from it , because it would it 's true , except that , that 's what we used in aurora one , and then they designed the things for aurora two knowing that we were doing that .  no . but , that it it probably would be the case that if , say , we trained on italian , data and then , we tested on danish data and it did terribly , that it would look bad . and someone would notice and would say "" look . this is not generalizing . "" i would hope tha i would hope they would .  but , it 's true . there 's parameters that other people have used th that they have tuned in some way for other things . it 's , we should we should that 's topic especially if you talk with him when i 'm not here , that 's a topic you should discuss with hynek to , double check it 's social security number what information do   right . again , i if you had the whole system you were optimizing , that would be easy to see . but if you 're supposedly just using a fixed back end and you 're just coming up with a feature vector , w i 'm not having the two nets suppose you detected that it was male , it was female you come up with different   it 's an interesting thought . having something along the you can't really do vocal tract normalization . but something that had some of that effect being applied to the data in some way .  ","that 's permitted ? the rules as i understand it , is that in principle the italian and the spanish and the english italian and the finnish and the english ? were development data on which you could adjust things . and the german and danish were the evaluation data . and then when they finally actually evaluated things they used everything . it doesn't appear that there 's strong evidence that even though things were somewhat tuned on those three or four languages , that going to a different language really hurt you . and the noises were not exactly the same . they were different drives . it 's tuned more than , a a you 'd really like to have something that needed no particular noise but that 's not really what this contest is . that 's something i 'd like to understand before we actually use something from it , except that , that 's what we used in aurora one , and then they designed the things for aurora two knowing that we were doing that . no . but , that it it probably would be the case that if , say , we trained on italian , data and then , we tested on danish data and it did terribly , that it would look bad . and someone would notice that 's topic especially if you talk with him when i 'm not here , that 's a topic you should discuss with hynek to , double check it 's ","These included making plans for upcoming experiments, clarifying definitions, and approaches which may or may not be against the rules of the Aurora project, alongside alternatives that would not be. Plans were also made with regard to a visitor from research partner OGI "
Bro016.E,"but just listen to yourself . that really doesn't sound like a real time thing with less than two hundred milliseconds , latency that and where you 're not adjusting the statistical engine that just   no . not just expensive . i don't see how you could possibly do it . you can't look at the whole utterance and do anything . you can only right ? each frame comes in and it 's gotta go out the other end .    you can do ,  fairly quickly you can do male female f male female but as far as , like bbn did a thing with , vocal tract normalization a ways back . other people did too . with , l trying to identify third formant average third formant using that as an indicator of  third formant i if you imagine that to first order what happens with , changing vocal tract is that , the formants get moved out by some proportion if you had a first formant that was one hundred hertz before , if the fifty if the vocal tract is fifty percent shorter , then it would be out at seven fifty hertz , and on . that 's a move of two hundred fifty hertz . whereas the third formant which might have started off at twenty five hundred hertz , might be out to thirty seven fifty , it 's at  although , you frequently get less distinct higher formants , it 's still third formant 's reasonable compromise , and if i recall correctly , they did something like that . and but that doesn't work for just having one frame that 's more like looking at third formant over a turn like that , and   but on the other hand , male female is a is a much simpler categorization than figuring out a factor to , squish or expand the spectrum .  y you could imagine that just like we 're saying voiced unvoiced is good to know male female is good to know also .  but , you 'd have to figure out a way to , incorporate it on the fly . as you say , one thing you could do is simply , have the male and female output vectors tr nets trained only on males and n trained only on females or or ,  but  i don't know if that would really help , because you already have males and females and it 's putting into one net .  is it ? do   y you 're you were saying before ? shouldn't be . they should be less r right ? wh ? but let me ask you this . what 's the , do you kno recall if the insertions were higher with msg ? but you should always look at insertions , deletions , and substitutions .   msg is very , very dif plp is very much like mel cepstrum . msg is very different from both of them . ",,
Bro016.E,"if it 's very different , then this is the thing 'm really glad andreas brought this point up . i had forgotten to discuss it .  you always have to look at how this these adjustments , affect things . and even though we 're not allowed to do that , again we could reflect that back to our use of the features . if it if the problem might be that the range of the msg features is quite different than the range of the plp or mel cepstrum . and you might wanna change that .   that means they 're between zero and one . but i it doesn't necessarily they could be ,  do doesn't tell you what the variance of the things is . right ? cuz if you 're taking the log of these things , it could be ,  knowing what the sum of the probabilities are , doesn't tell you what the sum of the logs are .    or what what you 're the thing you 're actually looking at . your the values that are actually being fed into htk . what do they look like ? right . they 're kinda like log probabilities is what i was saying . almost . but then you actually do a klt on them .  they aren't normalized after that , are they ? no .   right . the question is whatever they are at that point , are they something for which taking a square root or cube root or fourth root like that is gonna be a good or a bad thing ?  and that 's something that nothing else after that is gonna things are gonna scale it subtract things from it , scale it from it , but nothing will have that same effect .    anyway , the right .  no . again you don't really look at that . it 's something that , and then it 's going through this transformation that 's probably pretty close to it 's , whatever the klt is doing . but it 's probably pretty close to what a discrete cosine transformation is doing . but still it 's not gonna probably radically change the scale of things . i would think . and ,  it may be entirely off and it may be at the very least it may be quite different for msg than it is for mel cepstrum or plp . that would be the first thing i 'd look at without adjusting anything would just be to go back to the experiment and look at the , substitutions , insertions , and deletions . and if the if the , i if there 's a fairly large effect of the difference , say , the r ratio between insertions and deletions for the two cases then that would be , an indicator that it might be in that direction . anything else ?    but , some problems are harder than others , and ",,
Bro016.E,"and , sometimes , there 's enough evidence for something to work and then it 's harder , it breaks .  it 's but it but , i it could be that when you say it works we could be doing much better , even in ti digits . right ?     right . o   this 'll be , something for discussion with hynek next week .   right .  how are , how are things going with what you 're doing ?  he 'll be around for three days . we 'll have a lot of time .   i 'll , he 's he 'll he 'll be talking with everybody in this room  not thursday and friday .  cuz i will be at faculty retreat .  i 'll try to connect with him and people as on wednesday . but  how 'd taxes go ? taxes go good .  that 's just that 's one of the big advantages of not making much money is the taxes are easier .  you are . aren't you ?    canada w canada wants a cut ? have to do you have to do two returns ?   for tw that 's right , ju two thousand .  probably not this next year ,    alright .  barry , do you wanna say something about your here ?  no why don't you say something about what it is ? we 're all gathered here together . we 'd , whose paper is it ?   from , university of hamburg and bielefeld .  that 's not based on data .      when we did the spam work there we had this notion of an , auditory @ @ auditory event . and ,  called them "" avents "" , with an a at the front .  and the idea was something that occurred that is important to a bunch of neurons somewhere .  a sudden change or a relatively rapid change in some spectral characteristic will do this . there 's certainly a bunch of places where that neurons are gonna fire because something novel has happened . that was the main thing that we were focusing on there . but there 's certainly other things beyond what we talked about there that aren't just rapid changes , but      there 's , a couple people who are gonna be here i forget if i already told you this , but , a couple people who are gonna be here for six months .  there 's a professor kollmeier , from germany who 's , quite big in the , hearing aid signal processing area and , michael kleinschmidt , who 's worked with him , who also looks at auditory properties inspired by various , brain function things .   they 'll be interesting to talk to , in this issue as these detectors are , developing . he looks at interesting things in the different ways of looking at spectra in order to get various speech properties out .    short meeting , but that 's and , ","this 'll be , something for discussion with hynek next week . how are , how are things going with what you 're doing ? do you wanna say something about your here ? ","Plans were also made with regard to a visitor from research partner OGI Although the members of ICSI's Meeting Recorder Group at Berkeley had little progress to report, there were still a number of issues relating to their work to discuss. "
Bro016.E,"we might as do our digits . and like i say , i encourage you to go ahead and meet , next week with , hynek . alright , i 'll start . it 's , one thirty five . seventeen  ",,
Bro016.F," i don't really have , anything new . been working on meeting recorder   i did play with that , actually , a little bit . what happens is , when you get to the noisy you start getting lots of insertions . and , 've tried playing around a little bit with , the insertion penalties and things like that .  it didn't make a whole lot of difference . like for the matched case , it seemed like it was pretty good . i could do more playing with that , though . and , and see . yes . you 're talking about for th for our features .  right .    for th the experiment is to , run our front end like normal , with the default , insertion penalties and forth , and then tweak that a little bit and see how much of a difference it makes if we were   i don't remember off the top of my head .  i didn't even write them down . i don't remember . i would need to i did write down ,  when i was doing wrote down some numbers for the matched case .  looking at the i wrote down what the deletions , substitutions , and insertions were ,  for different numbers of states per phone . but , that 's all i wrote down .  i would  i would need to do that . do that for next week .  need to get , front end , from you or you point me to some files that you 've already calculated . i probably will have time to do that and time to play a little bit with the silence model . have that for next week when hynek 's here .  is there ? i wonder if there 's anything that we could do to the front end that would affect the insertion what could you do ?     right . that w right . in effect , that 's changing the value of your insertion penalty . that 's interesting .  right . if we the insertion penalty is , then we can get an idea about what range our number should be in , that they match with that .   i 've seen that with the mel cepstrum . i don't know about the aurora front end , but this the whole problem with insertions was what we talked about when the guy from ogi came down that one time and and that was when people were saying , we should have a , voice activity detector that , because all that that we 're getting thr the silence that 's getting through is causing insertions .  i 'll bet you there 's still a lot of insertions .  right .    would the ? would a good idea be to try to map it into the same range that you get in the matched case ? ","i don't really have , anything new . been working on meeting recorder i did play with that , actually , a little bit . what happens is , when you get to the noisy you start getting lots of insertions . 've tried playing around a little bit with , the insertion penalties and things like that . it didn't make a whole lot of difference . like for the matched case , it seemed like it was pretty good . i could do more playing with that , though . you 're talking about for th for our features . the experiment is to , run our front end like normal , with the default , insertion penalties and forth , and then tweak that a little bit and see how much of a difference it makes i don't remember off the top of my head . i didn't even write them down . looking at the i wrote down what the deletions , substitutions , and insertions were , for different numbers of states per phone . but , that 's all i wrote down . i would need to do that . do that for next week . have that for next week when hynek 's here . i wonder if there 's anything that we could do to the front end that would affect the insertion in effect , that 's changing the value of your insertion penalty . if we the insertion penalty is , then we can get an idea about what range our number should be in , ","Although the members of ICSI's Meeting Recorder Group at Berkeley had little progress to report, there were still a number of issues relating to their work to discuss. These included making plans for upcoming experiments, clarifying definitions, and approaches which may or may not be against the rules of the Aurora project, alongside alternatives that would not be. Plans were also made with regard to a visitor from research partner OGI "
Bro016.F,"if we computed what the range was in matched , and then when we get our noisy conditions out we try to make it have the same range as ? i wasn't suggesting change it for different conditions . i was just saying that when we pick a range , we wanna pick a range that we map our numbers into we should probably pick it based on the range that we get in the matched case . otherwise , what range are we gonna choose to map everything into ?        right .  mainly working on what ?  how about that ? any anything new on the thing that , you were working on with the , no results ?  the ,  voicing detector . is this a report that 's for aurora ? or is it just like a tech report for icsi , or ?  i see . are you discovering anything , that makes you scratch your head as you write this report , like why did we do that , or why didn't we do this , or ?  could you say it again ? what exactly did they do ? it 's it 's probably something that , the the , experiment designers didn't really think about , because most people aren't doing trained systems , or , systems that are like ours , where you actually use the data to build models . they just doing signal processing .   that 's true . and they didn't forbid us right ? to build models on the data ?  do we know anything about the speakers for each of the , training utterances ? do you have speaker information ? that would be good . bank pin . just male f female ? i was thinking about things like , gender , gender specific nets and , vocal tract length normalization . things like that . i d i don't i didn't information we have about the speakers that we could try to take advantage of . you could put them both in as separate streams  i don't know . i was just wondering if there was other information we could exploit .   no . i hadn't thought it was thought too much about it , really . it just something that popped into my head just now . and you could use the ideas a similar idea to what they do in vocal tract length normalization . you have some , general speech model , just a mixture of gaussians that you evaluate every utterance against , and then you see where each , utterance like , the likelihood of each utterance . you divide the range of the likelihoods up into discrete bins and then each bin 's got some knob setting .    that 's true . right . could be expensive .  right . right . whatever it was , it would have to be on a per frame basis .   i don't know .     right .   is it balanced , in terms of gender ","any anything new on the thing that , you were working on with the , are you discovering anything , that makes you scratch your head as you write this report , like why did we do that , or why didn't we do this , it 's probably something that , the the , experiment designers didn't really think about , because most people aren't doing trained systems , or , systems that are like ours , where you actually use the data to build models . they just doing signal processing . and they didn't forbid us to build models on the data ? ","Although the members of ICSI's Meeting Recorder Group at Berkeley had little progress to report, there were still a number of issues relating to their work to discuss. "
Bro016.F,"the data ?  no and th the , for the tandem system , the values that come out of the net don't go through the sigmoid . right ? they 're the pre nonlinearity values ? and those  and tho that 's what goes into htk ?   cuz if the log probs that are coming out of the msg are really big , the standard insertion penalty is gonna have very little effect compared to , a smaller set of log probs .  but you said you won't be here next thursday ?  unless you 're getting money in two countries . they both want their cut . right ? but not for this next year ? the just to expand a little bit on the idea of acoustic event . there 's , in my mind , anyways , there 's a difference between , acoustic features and acoustic events . and of acoustic features as being , things that linguists talk about , like , that 's not based on data , necessarily . right . that 's not based on , acoustic data . they talk about features for phones , like , its height , its tenseness , laxness , things like that , which may or may not be all that easy to measure in the acoustic signal . versus an acoustic event , which is just some something in the acoustic signal that is fairly easy to measure . it 's , it 's a little different , in at least in my mind .  it 's kinda like the difference between top down and bottom up . of the acoustic phonetic features as being top down . you look at the phone and you say this phone is supposed to be have this feature , and this feature . whether tha those features show up in the acoustic signal is irrelevant . whereas , an acoustic event goes the other way . here 's the signal . here 's some event . what ? and then that that may map to this phone sometimes , and sometimes it may not . it just depen depends on the context , things like that . and it 's different way of looking . ","just to expand a little bit on the idea of acoustic event . there 's , in my mind , anyways , there 's a difference between , acoustic features and acoustic events . and of acoustic features as being , things that linguists talk about , that 's not based on data , necessarily . that 's not based on , acoustic data . they talk about features for phones , which may or may not be all that easy to measure in the acoustic signal . versus an acoustic event , which is just some something in the acoustic signal that is fairly easy to measure . it 's kinda like the difference between top down and bottom up . of the acoustic phonetic features as being top down . you look at the phone and you say this phone is supposed to be have this feature , and this feature . whether tha those features show up in the acoustic signal is irrelevant . whereas , an acoustic event goes the other way . here 's the signal . here 's some event . and then that that may map to this phone sometimes , and it 's different way of looking . ","These included making plans for upcoming experiments, clarifying definitions, and approaches which may or may not be against the rules of the Aurora project, alongside alternatives that would not be. "
Bro017.A,"hello ? it 's your right to remain silent .  are they adjacent , or are they s   hey !      you 're multiplying the standard deviation ? it 's cuz   the spread , right . it 's the same mean , right ?  saying .   right . doesn't matter right . the sharper the variance , the more important to get that one right . didn't you say you got these htk 's set up on the new linux boxes ?  right .  that 's right . pretend ,     ye i remember when we were trying to put together all the icsi software for the submission .   ",,
Bro017.B,"is it starting now ? what from what whatever we say from now on , it can be held against us , right ? and  the problem is that i actually don't know how th these held meetings are held , if they are very informal and just people are say what 's going on and    guess that what may be a reasonable is if i first make a report on what 's happening in aurora in general , at least what from my perspective . and that carmen and stephane reported on amsterdam meeting , which was interesting because it was for the first time we realized we are not friends really , but we are competitors . cuz until then it was like everything was like wonderful and  there is a plenty of there 're plenty of issues . and what happened was that they realized that if two leading proposals , which was french telecom alcatel , and us both had voice activity detector . and i said "" big surprise , we could have told you that n four months ago , except we didn't because nobody else was bringing it up "" . french telecom didn't volunteer this information either , cuz we were working on mainly on voice activity detector for past several months because that 's buying us the most thing . and everybody said "" but this is not fair . we didn't know that . "" and the it 's not working on features really . and be i i said "" you are right , if i wish that you provided better end point at speech because or at least that if we could modify the recognizer , to account for these long silences , because otherwise that th that wasn't a correct thing . "" and then ev everybody else says "" we should we need to do a new eval evaluation without voice activity detector , or we have to do something about it "" . and in principle i we we said . because but in that case , we would like to change the the algorithm because if we are working on different data , we probably will use a different set of tricks . but unfortunately nobody ever officially can somehow acknowledge that this can be done , because french telecom was saying "" no , no , now everybody has access to our code , everybody is going to copy what we did . ""  our argument was everybody ha has access to our code , and everybody always had access to our code . we never denied that . we thought that people are honest , that if you copy something and if it is protected by patent then you negotiate , right ? if you find our technique useful , we are very happy . but and french telecom was saying "" no , no , ","and that carmen and stephane reported on amsterdam meeting , which was interesting because it was for the first time we realized we are not friends really , but we are competitors . there is a plenty of there 're plenty of issues . and what happened was that they realized that if two leading proposals , which was french telecom alcatel , and us both had voice activity detector . and i said "" big surprise , we could have told you that n four months ago , except we didn't because nobody else was bringing it up "" . french telecom didn't volunteer this information either , cuz we were working on mainly on voice activity detector for past several months and everybody said "" but this is not fair . we didn't know that . "" and the it 's not working on features really . and then ev everybody else says "" we should we need to do a new eval evaluation without voice activity detector , or we have to do something about it "" . and in principle i we but in that case , we would like to change the the algorithm because if we are working on different data , we probably will use a different set of tricks . but unfortunately nobody ever officially can somehow acknowledge that this can be done , because french telecom was saying "" no , no , now everybody has access to our code , everybody is going to copy what we did . "" our argument was everybody ha has access to our code , and everybody always had access to our code . we never denied that . we thought that people are honest , that if you copy something and if it is protected by patent then you negotiate , but and french telecom was saying "" no , no , ","He reported on a recent project meeting from his group's perspective. There was much politics involved, and disagreement between groups. "
Bro017.B,"there is a lot of little tricks which cannot be protected and you guys will take them , "" which probably is also true . it might be that people will take th the algorithms apart and use the blocks from that . but i somehow think that it wouldn't be bad , as long as people are happy abou honest about it . and they have to be honest in the long run , because winning proposal again what will be available th is will be a code . the the people can go to code and say "" listen this is what you stole from me ""  "" let 's deal with that "" . don't see the problem . the biggest problem is that f that alcatel french telecom cl claims "" we fulfilled the conditions . we are the best . we are the standard . "" and e and other people don't feel that , because they they now decided that is the whole thing will be done on endpointed data , essentially that somebody will endpoint the data based on clean speech , because most of this the speechdat car has the also close speaking mike and endpoints will be provided . and we will run again still not clear if we are going to run the if we are allowed to run new algorithms , but i assume because we would fight for that , really . but since n u at least our experience is that only endpointing a mel cepstrum gets gets you twenty one percent improvement overall and twenty seven improvement on speechdat car then obvious the database mean the the baseline will go up . and nobody can then achieve fifty percent improvement . they that there will be a twenty five percent improvement required on u m bad mis badly mismatched it y but you have the same prob mfcc has an enormous number of insertions . and now they want to say "" we will require fifty percent improvement only for matched condition , and only twenty five percent for the serial cases . "" and and they almost on that except that it wasn't a hundred percent and last time during the meeting , brought up the issue , i said "" quite frankly i 'm surprised how lightly you are making these decisions because this is a major decision . for two years we are fighting for fifty percent improvement and suddenly you are saying "" no we will do something less "" , but we should discuss that . and everybody said "" we discussed that and you were not a mee there "" and i said "" lot of other people were not there because not everybody participates at these teleconferencing c things . "" then they said "" no because everybody is invited . "" however , there is only ten or fifteen lines , people can't even con participate . they and they said "" we will discuss that . "" ","there is a lot of little tricks which cannot be protected and you guys will take them , "" which probably is also true . and they have to be honest in the long run , because winning proposal again what will be available th is will be a code . the the people can go to code and say "" listen this is what you stole from me "" the biggest problem is that f that alcatel french telecom cl claims "" we fulfilled the conditions . we are the best . and e and other people don't feel that , because they they now decided that is the whole thing will be done on endpointed data , still not clear if we are going to run the if we are allowed to run new algorithms , because we would fight for that , really . at least our experience is that only endpointing a mel cepstrum gets gets you twenty one percent improvement overall and twenty seven improvement on speechdat car then obvious the database mean the the baseline will go up . and nobody can then achieve fifty percent improvement . they that there will be a twenty five percent improvement required on u m bad mis badly mismatched and now they want to say "" we will require fifty percent improvement only for matched condition , and only twenty five percent for the serial cases . "" and and they almost on that except that it wasn't a hundred percent and last time during the meeting , brought up the issue , for two years we are fighting for fifty percent improvement and suddenly you are saying "" no we will do something less "" , and everybody said "" we discussed that and you were not a mee there "" and i said "" lot of other people were not there because not everybody participates at these teleconferencing c things . "" then they said "" no because everybody is invited . "" however , there is only ten or fifteen lines , people can't even con participate . they and they said "" we will discuss that . "" ",
Bro017.B,"immediately nokia raised the question and they said "" we agree this is not good to dissolve the the criterion . "" now officially , nokia is complaining and said they are looking for support , think qualcomm is saying , too "" we shouldn't abandon the fifty percent yet . we should at least try once again , one more round . "" this is where we are . i hope that this is going to be a adopted . next wednesday we are going to have another teleconferencing call , we 'll see what where it goes .  that 's what that 's a g very good point , because david says "" we ca we can manipulate this number by choosing the right weights anyways . "" while you are right but but  if if you put a zero weight zero on a mismatched condition , or highly mismatched then you are done . but weights were also deter already decided half a year ago .  people will not like it . now what is happening now is that i th that people try to match the criterion to solution . they have solution . now they want to make their criterion is and that this is not the right way . it may be that eventually it may ha it may have to happen . but it 's should happen at a point where everybody feels comfortable that we did all what we could . and i don't think we did . that this test was a little bit bogus because of the data and essentially there were these arbitrary decisions made , and everything . this is where it is . what we are doing at ogi now is working on our parts which we little bit neglected , like noise separation . we are looking in ways is in which with which we can provide better initial estimate of the mel spectrum which would be a l f more robust to noise , and far not much success . we tried things which long time ago bill byrne suggested , instead of using fourier spectrum , from fourier transform , use the spectrum from lpc model . their argument there was the lpc model fits the peaks of the spectrum , it may be m naturally more robust in noise . and that makes sense , "" but far we can't get much out of it . we may try some standard techniques like spectral subtraction and not much . or even i was thinking about looking back into these ad hoc techniques like dennis klatt was suggesting the one way to deal with noisy speech is to add noise to everything . add moderate amount of noise to all data . that makes th any additive noise less addi less a effective , right ? because you already had the noise in a and it was working at the time . it was like one of these things , but ","now officially , nokia is complaining and said they are looking for support , think qualcomm is saying , too "" we shouldn't abandon the fifty percent yet . we should at least try once again , one more round . "" what we are doing at ogi now is working on our parts which we little bit neglected , like noise separation . we are looking in ways is in which with which we can provide better initial estimate of the mel spectrum which would be a l f more robust to noise , and far not much success . ",He also brought the ICSI members up to date with his group's latest work. 
Bro017.B,"if you think about it , it 's actually pretty ingenious . just take a spectrum and add of the constant , c , to every value . exactly . and if then if this data becomes noisy , it b it becomes eff effectively becomes less noisy but you cannot add too much noise because then you 'll s then you 're clean recognition goes down , but it 's yet to be seen how much , it 's a very simple technique . yes it 's a very simple technique , you just take your spectrum and use whatever is coming from fft , add constant ,  on onto power spectrum . that or the other thing is if you have a spectrum , what you can s start doing , you can leave start leaving out the p the parts which are low in energy and then perhaps one could try to find a all pole model to such a spectrum . because a all pole model will still try to put the continuation of the model into these parts where the issue set to zero . that 's what we want to try . i have a visitor from brno . he 's a like young faculty . pretty hard working he 's he 's looking into that . and then most of the effort is now also aimed at this e trap recognition . this this is this recognition from temporal patterns . you don't know about traps !  tha this is familiar like because we gave you the name , but , what it is , is that normally what you do is that you recognize speech based on a shortened spectrum . essentially l p lpc , mel cepstrum , everything starts with a spectral slice . if you s given the spectrogram you essentially are sliding the spectrogram along the frequency axis and you keep shifting this thing , and you have a spectrogram . you can say "" you can also take the time trajectory of the energy at a given frequency "" , and what you get is then , that you get a p vector . and this vector can be a s assigned to s some phoneme . namely you can say i it i will say that this vector will will describe the phoneme which is in the center of the vector . and you can try to classify based on that . and you you classi it 's a very different vector , very different properties , we don't know much about it , but the truth is you get many decisions . and then you can start dec thinking about how to combine these decisions . exactly , that 's what that 's what it is . because if you run this recognition , you get you still get about twenty percent error twenty percent correct .  on like for the frame by frame basis , it 's much better than chance . ","and then most of the effort is now also aimed at this e trap recognition . this this is this recognition from temporal patterns . but , what it is , is that normally what you do is that you recognize speech based on a shortened spectrum . essentially l p lpc , mel cepstrum , everything starts with a spectral slice . if you s given the spectrogram you essentially are sliding the spectrogram along the frequency axis and you keep shifting this thing , and you have a spectrogram . you can say "" you can also take the time trajectory of the energy at a given frequency "" , and what you get is then , that you get a p vector . namely you can say i it i will say that this vector will will describe the phoneme which is in the center of the vector . it 's a very different vector , very different properties , ",He also brought the ICSI members up to date with his group's latest work. 
Bro017.B,"that 's another thing . currently we start we start always with critical band spectrum . for various reasons . but the latest observation is that you are you can get quite a big advantage of using two critical bands at the same time . adjacent , adjacent . and the reasons there are some reasons for that . because there are some reasons could talk about , will have to tell you about things like masking experiments which yield critical bands , and also experiments with release of masking , which actually tell you that something is happening across critical bands , across bands . and it 's mean time t zero is one number , time t it 's a spectral energy , logarithmic spectral energy ,  yes , yes . yes , yes . and that 's what i 'm saying then , this is a starting vector . it 's just like shortened f spectrum , but now we are trying to understand what this vector actually represents , question is like "" how correlated are the elements of this vector ? "" turns out they are quite correlated , because especially the neighboring ones , right ? they represent the same almost the same configuration of the vocal tract . there 's a very high correlation . the classifiers which use the diagonal covariance matrix don't like it . we 're thinking about de correlating them . then the question is can you describe elements of this vector by gaussian distributions "" , or to what extent ? because and on and on . we are learning quite a lot about that . and then another issue is how many vectors we should be using , the the minimum is one . but is the critical band the right dimension ? we somehow made arbitrary decision , "" yes "" . then but then now we are thinking a lot how to how to use at least the neighboring band because that seems to be happening this i somehow start to believe that 's what 's happening in recognition . cuz a lot of experiments point to the fact that people can split the signal into critical bands , but then you can you are quite capable of processing a signal in independently in individual critical bands . that 's what masking experiments tell you . but at the same time you most likely pay attention to at least neighboring bands when you are making any decisions , you compare what 's happening in this band to what 's happening to the band to the to the neighboring bands . and that 's how you make decisions . that 's why the articulatory events , which fletcher talks about , they are about two critical bands . you need at least two , you need some relative , relative relation . absolute number doesn't tell you the right thing . you need to compare it to something else , what 's happening ",,
Bro017.B,"but it 's what 's happening in the close neighborhood . if you are making decision what 's happening at one kilohertz , you want to 's happening at nine hundred hertz and it and at eleven hundred hertz , but you don't much care what 's happening at three kilohertz . to some extent , it that is also true .  but it 's but th what humans are very much capable of doing is that if th if they are exactly the same thing happening in two neighboring critical bands , recognition can discard it . is what 's happening hey ! we need us another voice here .    and if you d if you a if you add the noise that normally masks the the signal right ? and you can show that in that if the if you add the noise outside the critical band , that doesn't affect the decisions you 're making about a signal within a critical band . unless this noise is modulated . if the noise is modulated , with the same modulation frequency as the noise in a critical band , the amount of masking is less . the moment you provide the noise in n neighboring critical bands . the s m masking curve , normally it looks like i start from here , you have no noise then you are expanding the critical band , the amount of maching is increasing . and when you e hit a certain point , which is a critical band , then the amount of masking is the same . that 's the famous experiment of fletcher , a long time ago . like that 's where people started thinking "" this is interesting ! ""  but , if you if you modulate the noise , the masking goes up and the moment you start hitting the another critical band , the masking goes down . essentially that 's a very clear indication that cognition can take into consideration what 's happening in the neighboring bands . but if you go too far in a if you if the noise is very broad , you are not increasing much more , if you are far away from the signal from the signal f the frequency at which the signal is , then the m even the when the noise is co modulated it 's not helping you much .  things like this we are playing with the hope that perhaps we could eventually u use this in a real recognizer . like partially we promised to do this under the aurora program . probably not . most likely we will not have anything which c would comply with the rules . like because latency currently chops the require significant latency amount of processing , because we don't know any better , yet , than to use the neural net classifiers , and traps . ",,
Bro017.B,"though the work which everybody is looking at now aims at s trying to find out what to do with these vectors , that a g simple gaussian classifier would be happier with it . or to what extent a gaussian classifier should be unhappy that , and how to gaussian ize the vectors , and this is what 's happening . then sunil is asked me f for one month 's vacation and since he did not take any vacation for two years , i had no i didn't have heart to tell him no . he 's in india . and he may be looking for a girl , for i don't i don't ask . i know that naran when last time narayanan did that he came back engaged .  i know . i know , i know , and then then what happened with narayanan was that he start pushing me that he needs to get a phd because they wouldn't give him his wife . and she 's very pretty and he loves her and we had to really  we had had a incentive because he always had this plan except he never told me . figured that was a that he he told me the day when we did very at our nist evaluations of speaker recognition , the technology , and he was involved there . we were after presentation we were driving home and he told me .  said "" he took another three quarter of the year but he was out . wouldn't surprise me if he has a plan like that , though pratibha still needs to get out first . cuz pratibha is there a year earlier . and s and satya needs to get out very first because he 's he already has four years served , though one year he was getting masters .   which ? speaker recognition ? there , we don't know about evaluation , next meeting is in june . and but like getting get together . nobody said that yet . i assume yes , but nobody even set up yet the date for delivering endpointed data . and this that but i  what would be extremely useful , if we can come to our next meeting and say "" we did get fifty percent improvement . if you are interested we eventually can tell you how "" , but we can get fifty percent improvement . because people will s will be saying it 's impossible . twenty two t twenty two percent better than the old baseline . u yes . yes . but i assume that it will be similar , i don't see the reason why it shouldn't be . i d i don't see reason why it should be worse . cuz if it is worse , then we will raise the objection , we say "" how come ? "" ",,
Bro017.B,"because if we just use our voice activity detector , which we don't claim even that it 's wonderful , it 's just like one of them . we get this improvement , how come that we don't see it on your endpointed data ?   c and on clean speech data .  david told me david told me yesterday or harry actually he told harry from qualcomm and harry brought up the suggestion we should still go for fifty percent he says are you aware that your system does only thirty percent comparing to endpointed baselines ? they must have run already something .  and harry said "" but we think that we didn't say the last word yet , that we have other things which we can try . "" there 's a lot of discussion now about this new criterion . because nokia was objecting , with qualcomm 's we supported that , we said "" yes "" . now everybody else is saying "" you guys might must be out of your mind . "" the guenter hirsch who d doesn't speak for ericsson anymore because he is not with ericsson and ericsson may not may withdraw from the whole aurora activity because they have many troubles now . ericsson 's laying off twenty percent of people . guenter is already he got the job already was working on it for past two years or three years he got a job at some fachschule , the technical college not too far from aachen . it 's like professor u university professor not quite a university , not quite a it 's not aachen university , but it 's a good school and he 's happy . and he he was hoping to work with ericsson like on t like consulting basis , but right now he says it doesn't look like that anybody is even thinking about speech recognition . they think about survival .   but this is being now discussed right now , and it 's possible that that it may get through , that we will still stick to fifty percent . but that means that nobody will probably get this im this improvement . yet , wi with the current system . which event es essentially that we should be happy with because that would mean that at least people may be forced to look into alternative solutions and but not  yes . yes . we getting there , right .   is it like is how did you come up with this number ? if you improve twenty by twenty percent the c the f the all baselines , it 's just a quick c comp co computation ?  it 's about right .  we were just discussing , since you mentioned that , in it w driving in the car with morgan this morning , we were discussing a good experiment for b for beginning graduate student who wants to run a lot of who wants to get a lot of numbers on something ","we were just discussing , since you mentioned that , in it w driving in the car with morgan this morning , we were discussing a good experiment for b for beginning graduate student who wants to run a lot of who wants to get a lot of numbers on something ","Having discussed this with the ICSI project leader, the OGI member told of some future investigation they had devised, which would look at the adjusting the importance of some features. "
Bro017.B,"which is imagine that you will start putting every co any coefficient , which you are using in your vector , in some general power . general pow power . like you take a s power of two , or take a square root , suppose that you are working with a s c zer c one . if you put it in a s square root , that effectively makes your model half as efficient . because your gaussian mixture model , right ? computes the mean . and but it 's the mean is an exponent of the whatever , the this gaussian function . you 're compressing the range of this coefficient , it 's becoming less efficient . right ?   morgan was @ @ and he was saying this might be the alternative way how to play with a fudge factor ,  in the just compress the whole vector . and i said "" in that case why don't we just start compressing individual elements , like when because in old days we were doing when people still were doing template matching and euclidean distances , we were doing this liftering of parameters , right ? because we observed that higher parameters were more important than lower for recognition . and the c ze c one contributes mainly slope , and it 's highly affected by frequency response of the recording equipment and that thing ,  we were coming with all these f various lifters . bell labs had he this raised cosine lifter which still is built into h htk for reasons n unknown to anybody , but we had exponential lifter , or triangle lifter , basic number of lifters . and . but they may be a way to fiddle with the f insertions , deletions , or the giving a relative modifying relative importance of the various parameters . the only problem is that there 's an infinite number of combinations and if the if you s if y you need a lot of graduate students , and a lot of computing power . i know . exactly .  if you were at bell labs or i d i shouldn't be saying this in on a mike , right ? or i ibm , that 's what that 's what somebody would be doing . the places which have a lot of computing power , because it is really it 's a p it 's a it 's it will be reasonable search  but i wonder if there isn't some way of doing this search like when we are searching say for best discriminants .    and hev everything is fixed . everything is fixed . each for both , you would have to do .  you have to do bo both . because essentially you are saying "" this feature is not important "" . or less important , that 's th that 's a painful one ,   but minute . you may not need to re retrain the m model . ","which is imagine that you will start putting every co any coefficient , which you are using in your vector , in some general power . like you take a s power of two , or take a square root , because your gaussian mixture model , you 're compressing the range of this coefficient , it 's becoming less efficient . morgan was @ @ and he was saying this might be the alternative way how to play with a fudge factor ,  and i said "" in that case why don't we just start compressing individual elements , like when because we observed that higher parameters were more important than lower for recognition . and the c ze c one contributes mainly slope , ","Having discussed this with the ICSI project leader, the OGI member told of some future investigation they had devised, which would look at the adjusting the importance of some features. "
Bro017.B,"you just may n may need to c give less weight to mod component of the model which represents this particular feature . you don't have to retrain it . you just multiply .   you modify the gaussian in the model , but in the test data you would have to put it in the power , but in a training what you c in a training in trained model , all you would have to do is to multiply a model by appropriate constant . because in test data you ca don't have a model . you have only data . but in a tr that is true , but w what you want to do you want to say if obs you if you observe something like stephane observes , that c one is not important , you can do two things . if you have a trained recognizer , in the model , the component which di dimension wh to the s it . but what i 'm proposing now , if it is important but not as important , you multiply it by point one in a model . but but that you multiply the i would have to look in the math , how does the model   effectively , that 's i exactly . that 's what you do . that 's what you do , you modify the standard deviation as it was trained . effectively you , in f in front of the model , you put a constant . s effectively what you 're doing is you are modifying the deviation . right ?  the spread . and and  your als no . by making it narrower , your yes , you making this particular dimension less important . because see what you are fitting is the multidimensional gaussian , right ? it 's a it has thirty nine dimensions , or thirteen dimensions if you g ignore deltas and double deltas . in order if you in order to make dimension which stephane sees less important , mean not useful , less important , what you do is that this particular component in the model you can multiply by w you can de weight it in the model . but you can't do it in a test data because you don't have a model for th when the test comes , but what you can do is that you put this particular component in and you compress it . that becomes th gets less variance , subsequently becomes less important . that would be very bad , because your t your model was trained expecting that wouldn't work . because your model was trained expecting a certain var variance on c one . and because the model thinks c one is important . after you train the model , you you could do still what i was proposing initially , that during the training you compress c one that becomes then it becomes less important in a training . ",,
Bro017.B,"but if you have if you want to run e ex extensive experiment without retraining the model , you don't have to retrain the model . you train it on the original vector . but after , you wh when you are doing this parametric study of importance of c one you will de weight the c one component in the model , and you will put in the you will compress the this component in a in the test data . s by the same amount . no , that would be a severe mismatch , right ? what you are proposing ? n no you don't want that . because that would then your model would be unlikely . your likelihood would be low , right ? because you would be providing severe mismatch . no that would be very good match , right ? that you would i see what you are sa saying , but no i don't think that it would be the same . no , the if you set it to a mean , that would no , you can't do that . y you ca ch chuck , you can't do that . because that would be a really f fiddling with the data , you can't do that . but what you can do , i 'm confident you ca i 'm reasonably confident and i putting it on the record , right ? people will listen to it for centuries now , is what you can do , is you train the model with the original data . then you decide that you want to see how important c one is . what you will do is that a component in the model for c one , you will divide it by two . and you will compress your test data by square root . then you will still have a perfect m match . except that this component of c one will be half as important in a overall score . then you divide it by four and you take a square , f fourth root . then if you think that some component is more important then th it then it is , based on training , then you multiply this particular component in the model by  multiply this component it by number b larger than one , and you put your data in power higher than one . then it becomes more important . in the overall score , i believe . no . no . yes . right . yes . exactly .  you may want to do it other way around ,   let 's see .    you would have to modify the mean in the model . i you i agree with you .   but but it 's i it 's do able , right ? it 's predictable .   it 's predictable .  it might be .     p pretty new outliers , interesting outliers , right ? variance .   no . no .        ",,
Bro017.B,"chuck is getting himself in trouble . hey ! and chuck is really fishing for how to keep his computer busy , right ? that 's that 's that 's a good thing because then y you just write the "" do "" loops and then you pretend that you are working while you are you c you can go fishing .  then you are in this mode like all of those arpa people are , right ? since it is on the record , i can't say which company it was , but it was reported to me that somebody visited a company and during a d during a discussion , there was this guy who was always hitting the carriage returns on a computer . after two hours the visitor said "" wh why are you hitting this carriage return ? "" and he said "" we are being paid by a computer ty we are we have a government contract . and they pay us by amount of computer time we use . "" it was in old days when there were of pdp eights and that thing . because they had a they literally had to c monitor at the time on a computer how much time is being spent i or on this particular project . nobody was looking even at what was coming out . i know , right .     it would be similar to i knew some people who were that was in old communist czechoslovakia , right ? we were watching for american airplanes , coming to spy on on us at the time , there were three guys stationed in the middle of the woods on one l lonely watching tower , spending a year and a half there because there was this service right ? and they very quickly they made friends with local girls and local people in the village and and but they there was one plane flying over s always above , and that was the only work which they had . they like four in the afternoon they had to report there was a plane from prague to brno flying there , they f very q f first thing was that they would always run back and at four o ' clock and quickly make a call , "" this plane is passing "" then a second thing was that they took the line from this u post to local pub . and they were calling from the pub . and they but third thing which they made , and when they screwed up , they finally they had to p the pub owner to make these phone calls because they didn't even bother to be there anymore . and one day there was no plane . at least they were smart enough that they looked if the plane is flying there , right ? ",,
Bro017.B,"and the pub owner says "" my four o ' clock , quickly p pick up the phone , call that there 's a plane flying . "" there was no plane for some reason , it was downed , or and they got in trouble . but . but    at least go test the s test the assumption about c one to begin with . but then one can then think about some predictable result to change all of them . it 's just like we used to do these the distance measures . it might be that      because you see , what is happening here in a in a in such a model is that it 's tells you what has a low variance is is more reliable , right ? how do we      how do we know , especially when it comes to noise ?  th that 's that 's why people used these lifters were inverse variance weighting lifters that makes euclidean distance more like mahalanobis distance with a diagonal covariance when you knew what all the variances were over the old data . what they would do is that they would weight each coefficient by inverse of the variance . turns out that the variance decreases at least at fast , i believe , as the index of the cepstral coefficients . you can show that analytically . typically what happens is that you need to weight the weight the higher coefficients more than the lower coefficients .  when when we talked about aurora still i wanted to m make a plea encourage for more communication between different parts of the distributed center . even when there is nothing to s to say but the weather is good in ore in berkeley . i 'm that it 's being appreciated in oregon and it will generate similar responses down here , like ,  what nowadays ,  it 's actually do able , almost . i don't think no . we should do that . we should definitely set up     that would make it easier .   and then we also can send the dis to the same address right , and it goes to everybody because what 's happening naturally in research , i know , is that people essentially start working on something and they don't want to be much bothered , right ? but what the then the danger is in a group like this , is that two people are working on the same thing and i c both of them come with the s very good solution , but it could have been done somehow in half of the effort there 's another thing which i wanted to report . lucash , wrote the software for this aurora two system . reasonably good one , because he 's doing it for intel , but i trust that we have rights to use it or distribute it and everything . cuz intel 's intentions originally was to distribute it free of charge anyways . ","when we talked about aurora still i wanted to m make a plea encourage for more communication between different parts of the distributed center . even when there is nothing to s to say but the weather is good in ore in berkeley . i 'm that it 's being appreciated in oregon and it will generate similar responses down here , no . and then we also can send the dis to the same address and it goes to everybody ",There were also further calls for greater communication between the groups. 
Bro017.B,"u s and we will make that at least you can see the software and if it is of any use . just it might be a reasonable point for p perhaps start converging . because morgan 's point is that he is an experienced guy . he says "" it 's very difficult to collaborate if you are working with supposedly the same thing , in quotes , except which is not s is not the same . which one is using that set of hurdles , another one set is using another set of hurdles . and then it 's difficult to c compare . he got the software . they sent the release .     because intel paid us should i say on a microphone ? some amount of money , not much . not much say on a microphone . much less then we should have gotten for this amount of work . and they wanted to have software that they can also play with it , which means that it has to be in a certain environment they use actu actually some intel libraries , but in the process , lucash just rewrote the whole thing because he figured rather than trying to f make sense of including icsi software not for training on the nets but he rewrote the or somehow reused over the parts of the thing that the whole thing , including mlp , trained mlp is one piece of software . is it useful ?  or that 's what he was saying , right . he said that it was like just many libraries and nobody knew what was used when , and that 's where he started and that 's where he realized that it needs to be at least cleaned up , and think it this is available .  ev n not not in a first ap approximation because he started first just with a plain c or c plus before check on that .  and in otherwise the intel libraries , they are available free of f freely . but they may be running only on windows . or on the on intel architecture , may not run in sun .  that is p that is possible . that 's why intel is distributing it , right ? or that 's  i know there was some issues that initially we d do all the development on linux but we use we don't have we have only three suns and we have them only because they have a spert board in . otherwise we t almost exclusively are working with pc 's now , with intel . in that way intel succeeded with us , because they gave us too many good machines for very little money or nothing . we run everything on intel . and yes . i have to take my glasses no .    can can i t start then ? ",,
Bro017.C,"    it could be even better , because the voice activity detector that i choosed is something that cheating , it 's using the alignment of the speech recognition system , and only the alignment on the clean channel , and then mapped this alignment to the noisy channel .       but we are not too far from fifty percent , from the new baseline . which would mean like sixty percent over the current baseline , which is  we are around fifty , fifty five .    i don't know exactly if it 's because it de it depends on the weightings and  but .   finally we 've not finished with this . we stopped .    we have a document that explain a big part of the experiments , but it 's not , finished yet .   right . we 've fff done some strange things like removing c zero or c one from the vector of parameters , and we noticed that c one is almost not useful you can remove it from the vector , it doesn't hurt .  in the no , in the proposal .        which but we have several means .  right ?  which  but , at the no . but it 's the variance is on the denominator in the gaussian equation . it 's it 's the contrary . if you want to decrease the importance of a c parameter , you have to increase it 's variance .  that 's right .    what i see what could be done is you don't change your features , which are computed once for all , but you just tune the model . you have your features . you train your model on these features . and then if you want to decrease the importance of c one you just take the variance of the c one component in the model and increase it if you want to decrease the importance of c one or decrease it   just adjust the model ,    it becomes more flat and    no , that 's right . it 's just tuning the models and testing , actually . it would be quick .       they t  they have smaller means , also .    we can set up a webcam no . no . we don't have .    what about harry ? we received a mail last week and you are starting to do some experiments . and use this intel version .    the only thing i would check is if he does he use intel math libraries , because if it 's the case , it 's not easy to use it on another architecture .     on intel architecture i 'm     there are at least there are optimized version for their architecture . i don't know . i never checked carefully these sorts of  ","finally we 've not finished with this . we have a document that explain a big part of the experiments , we 've fff done some strange things like removing c zero or c one from the vector of parameters , and we noticed that c one is almost not useful you can remove it from the vector , it doesn't hurt . no . we don't have . ",
Bro017.D," more or less it 's finished . ma nec to need a little more time to improve the english , and to fill in something some small detail , something like that , but it 's more or less ready . necessary to include the bi the bibliography .  multiply . go fishing . ","more or less it 's finished . ma nec to need a little more time to improve the english , and to fill in something some small detail , something like that , ",
Bro017.E," that 's right .  that 's usually what we do . we just sorta go around and people say what 's going on , what 's the latest  that would be great .  it seemed like there were still some issues , right ? that they were trying to decide ? like the voice activity detector , right . right . right . right .  right .  right . right .    right . right .    right . but minute , the endpointing really only helped in the noisy cases . but you still have that with the mfcc .   right .         what about the issue of the weights on the for the different systems , the matched , and medium mismatched and   and they 're the staying the same ?  right .      you haven't tried that yet ?    i see . right . you 're  you 're making all your training data more uniform .      what is that ? the traps sound familiar , i but i don't        but you have many of those vectors per phoneme , right ?     how wide are the frequency bands ? how do you convert this energy over time in a particular frequency band into a vector of numbers ? but what 's the number ? is it just the it 's just the amount of energy in that band from f in that time interval .          it 's really w it 's like saying that what 's happening at one kilohertz depends on what 's happening around it . it 's relative to it .   hey stephane .   go ahead .         but you probably won't have anything before the next time we have to evaluate , right ?   latency and things .      is he getting married right . i 've known other friends who they go to ind they go back home to india for a month , they come back married ,  he finally had some incentive to finish ,   when he knew you were happy ,    have the when is the next evaluation ? june no , for aurora ?   are people supposed to rerun their systems , or ?     do what the new baseline is ? if you don't have using your voice activity detector ? similar ,        where 's guenter going ?          how 's your documentation or whatever it w what was it you guys were working on last week ?  have you been running some new experiments ? saw some jobs of yours running on some of the machine really ? ! that has no effect ? is this in the baseline ? or in in  in some what ?    you 're compressing the range , right ? of that     right .    insertions .   you need like a some you need to have a genetic algorithm , that tries random permutations of these things .    actually , i don't know that this wouldn't be all that bad . you compute the features once , right ? and then these exponents are just applied to that  ","it seemed like there were still some issues , that they were trying to decide ? like the voice activity detector , how 's your documentation or whatever it w what was it you guys were working on last week ? have you been running some new experiments ? ","There was much politics involved, and disagreement between groups. The ICSI group reported their most recent progress and detailed their recent findings. "
Bro017.E,"and is this something that you would adjust for training ? or only recognition ? you would do it on both . you 'd actually  for each set of exponents that you would try , it would require a training and a recognition ?  if you instead of altering the feature vectors themselves , you modify the gaussians in the models .  but why if you 're multi if you 're altering the model , why w in the test data , why would you have to muck with the cepstral coefficients ? no . but you 're running your data through that same model .    all of the mean and variances that correspond to c one , you put them to zero .  but what are you multiplying ? cuz those are means , right ? you 're you you 'd have to modify the standard deviation that you make it wider or narrower . oop .   by making th the standard deviation narrower , your scores get worse for unless it 's exactly right on the mean . right ? there 's you 're allowing for less variance .    couldn't you just do that to the test data and not do anything with your training data ?   could you also if you wanted to if you wanted to try an experiment by leaving out say , c one , couldn't you , in your test data , modify the all of the c one values to be way outside of the normal range of the gaussian for c one that was trained in the model ? that effectively , the c one never really contributes to the score ? do what i 'm say  someth  but what if you set if to the mean of the model , then ? and it was a cons you set all c ones coming in through your test data , you change whatever value that was there to the mean that your model had .  that 's true , right , because you have      you 're talking about the standard deviation ?   but don't you have to do something to the mean , also ? but if your if your original data for c one had a mean of two . and now you 're you 're changing that by squaring it . now your mean of your c one original data has is four . but your model still has a mean of two . even though you 've expended the range , your mean doesn't match anymore . do you see what   right .  it 's predictable ,  but as a simple thing , you could just muck with the variance . to get this the effect that you 're talking about , right ? could increase the variance to decrease the importance . because if you had a huge variance , you 're dividing by a large number , you get a very small contribution .   ",,
Bro017.E,"actually , this reminds me of something that happened when i was at bbn . we were playing with putting pitch into the mandarin recognizer . and this particular pitch algorithm when it didn't think there was any voicing , was spitting out zeros . we were getting when we did clustering , we were getting groups of features with a mean of zero and zero variance . when ener when anytime any one of those vectors came in that had a zero in it , we got a great score . it was just , incredibly high score , and that was throwing everything off . if you have very small variance you get really good scores when you get something that matches . that 's a way , that 's a way to increase the n that 's interesting . that would be that doesn't require any retraining . that means it 's just recognitions .  you have a step where you modify the models , make a d copy of your models with whatever variance modifications you make , and rerun recognition . and then do a whole bunch of those . that could be set up fairly easily and you have a whole bunch of  that 's an interesting idea , actually . for testing the   that 's right . and they 're just t right now they 're installing increasing the memory on that the linux box .  absinthe . absinthe . we 've got five processors on that . and two gigs of memory .  exactly .  see how many cycles we used ?   my gosh ! he had to make it look like  how idle time .  have you ever seen those little  it 's this thing that 's the shape of a bird and it has a red ball and its beak dips into the water ? if you could hook that up it hit the keyboard that 's an interesting experiment .   ugh !    and there wasn't ?  that 's a really i that wouldn't be too difficult to try . could set that up . and we 'll just the first set of variance weighting vectors would be just one modifying one and leaving the others the same . and do that for each one . that would be one set of experiment wh when the data matches that , then you get really  right . but there could just naturally be low variance . because i like , i 've noticed in the higher cepstral coefficients , the numbers seem to get smaller , right ?  just naturally .  exactly . and it seems like they 're already compressed . the range of values .        is the if we mail to "" aurora inhouse "" , does that go up to you guys also ?  what is it we sh do we have a mailing list that includes the ogi people ?  we should set that up . that would make it much easier . ","if we mail to "" aurora inhouse "" , does that go up to you guys also ? do we have a mailing list that includes the ogi people ? we should set that up . that would make it much easier . ",
Bro017.E,"just call it "" aurora "" that would    we can set that up .            does anybody have anything else ? to shall we read some digits ?  hynek , i don't know if you 've ever done this . the way that it works is each person goes around in turn , and you say the transcript number and then you read the digits , the strings of numbers as individual digits . you don't say "" eight hundred and fifty "" , you say "" eight five , and forth .   ",,
Bro019.A,"chuck , is the mike type wireless wireless headset ?      the mike number is  one .     hello ?    i need a little orientation about this environment and scr s how to run some jobs here because i never d did anything far with this x emissions  'll ask you after the meeting .         shall i start from don't know how may i how  'll start from the post aurora submission  after the submission the what i 've been working on mainly was to take other s submissions and then over their system , what they submitted , because we didn't have any speech enhancement system in ours .  tried  and u first i tried just lda . and then i found that  if i combine it with lda , it gives @ @ improvement over theirs .     just the lda filters . plug in take the cepstral coefficients coming from their system and then plug in lda on top of that . but the lda filter that i used was different from what we submitted in the proposal . what i did was i took the lda filter 's design using clean speech , mainly because the speech is already cleaned up after the enhancement instead of using this , narrow band lda filter that we submitted i got new filters .  that seems to be giving improving over their system . slightly . but , not very significantly . and that was showing any improvement over final by plugging in an lda . and then after that i added on line normalization also on top of that . and that there also i n i found that i have to make some changes to their time constant that i used because th it has a mean and variance update time constant and which is not suitable for the enhanced speech , and whatever we try it on with proposal one . but i didn't play with that time constant a lot , g found that i have to reduce the value i have to increase the time constant , or reduce the value of the update value . that 's all i found have to .   and the other thing what i tried was , took the baseline and then ran it with the endpoint inf th information , just the aurora baseline , to see that how much the baseline itself improves by just supplying the information of the the w speech and nonspeech . and i found that the baseline itself improves by twenty two percent by just giving the wuh .  no . no . no , things didn't get better with the same time constant that we used . with the different time constant i found that i didn't get an improvement over not using on line normalization , because i found that i would have change the value of the update factor . but i didn't play it with play quite a bit to make it better than . it 's still not ","the other thing what i tried was , took the baseline and then ran it with the endpoint inf th information , just the aurora baseline , to see that how much the baseline itself improves by just supplying the information of the the w speech and nonspeech . i found that the baseline itself improves by twenty two percent by just giving the wuh . ","He began the meeting by reporting his recent activities, which included looking at the new baseline system. "
Bro019.A,"the on line normalization didn't give me any improvement . and   just stopped there with the speech enhancement . the other thing what i tried was the adding the endpoint information to the baseline and that itself gives like twenty two percent because the second the new phase is going to be with the endpointed speech . and just to get a feel of how much the baseline itself is going to change by adding this endpoint information , use  that 's , that 's what the feeling is like . they 're going to give the endpoint information .    no . no . that i   exactly . that is where the consensus is . like y you will you 'll be given the information about the beginning and the end of speech but the whole speech is available to you .     that the baseline itself it improves by twenty two percent . i found that in s one of the speechdat car cases , that like , the spanish one improves by just fifty percent by just putting the endpoint . w you don't need any further speech enhancement with fifty .  by fifty percent .   that is when the qualification criteria was reduced from fifty percent to something like twenty five percent for matched . and they have actually changed their qualification c criteria now . and  after that , went home f had a vacation fo for four weeks .  ye  and i came back and i started working on some other speech enhancement algorithm . from the submission what i found that people have tried spectral subtraction and wiener filtering . these are the main approaches where people have tried , just to fill the space with some f few more speech enhancement algorithms to see whether it improves a lot , i 've been working on this signal subspace approach for speech enhancement where you take the noisy signal and then decomposing the signal s and the noise subspace and then try to estimate the clean speech from the signal plus noise subspace . and i 've been actually running some s far i 've been trying it only on matlab . i have to test whether it works first or not and then i 'll p port it to c and i 'll update it with the repository once i find it giving any some positive result .     no there is a slight different .  which are extracted at the handset because they had another back end blind equalization      the speech .  the cepstral f the difference is like there may be a slight difference in the way because they use exactly the baseline system for converting the cepstrum once you have the speech . if we are using our own code for th that could be the only difference . there is no other difference .     only lda .  af i after that i added on line normalization ,     i assume .  without any change .  with  the new lda filters .        ","because the second the new phase is going to be with the endpointed speech . and just to get a feel of how much the baseline itself is going to change by adding this endpoint information , use  ","He began the meeting by reporting his recent activities, which included looking at the new baseline system. "
Bro019.A,"because the your improvement on hm and will also go down significantly in the spreadsheet  but the matched may still the matched may be the one which is least affected by adding the endpoint information .  the the and hm are going to be v hugely affected by it .   but they d the everything is like , but there that 's how they reduce why they reduce the qualification to twenty five percent or some something on . no , they are going ahead with the same weighting .  there 's nothing on  usual .     right . but actually the matched   the matched condition is not like , the one in ti digits where you have all the training , conditions exactly like replicated in the testing condition also . it 's like , this is not calibrated by snr the matched has also some mismatch in that which is other than the has also some slight mismatches , unlike the ti digits where it 's like prefectly matched because it 's artificially added noise . but this is natural recording . the matched is like the matched is defined like it 's seventy percent of the whole database is used for training and thirty percent for testing . it 's it 's  it 's   because the m the main major reason for the m the main mismatch is coming from the amount of noise and the silence frames and all those present in the database actually . no     if you want to reconstruct the speech , it may be a good idea to do it on fft bins . but for speech recognition , it may not . it may not be very different if you do it on mel warped or whether you do it on fft . you 're going to do a linear weighting anyway after that .   it may not be really a big different . it i  the other thing is like when you 're putting in a speech enhancement technique ,  is it like one stage speech enhancement ? because everybody seems to have a mod two stages of speech enhancement in all the proposals , which is really giving them some improvement . they just do the same thing again once more . and there 's something that is good about doing it to cleaning it up once more .  we can  that 's what that 's wh    've been thinking about combining the wiener filtering with signal subspace , just to see all some such permutation combination to see whether it really helps or not . the signal subspace ? the the signal subspace approach has actually an in built wiener filtering in it .  it is like a kl transform followed by a wiener filter . is the signal is a signal substrate . the different the c the advantage of combining two things is mainly coming from the signal subspace approach doesn't work very if the snr is very bad . it 's ",,
Bro019.A,"it works very poorly with the poor snr conditions , and in colored noise . wiener filtering . it 's a cascade of two s     that 's one reason we could combine s some something to improve snr a little bit , first stage , and then do a something in the second stage which could take it further . the colored noise  the colored noise the v the signal subspace approach has it actually depends on inverting the matrices . it ac the covariance matrix of the noise . if it is not positive definite , it has a it 's it doesn't behave very if it is not positive definite ak it works very with white noise because we know for that it has a positive definite . the way they get around is like they do an inverse filtering , first of the colo colored noise and then make the noise white , and then finally when you reconstruct the speech back , you do this filtering again .       this vts has been proposed by cmu ? is it the cmu ?  from c . the other thing is to , most of the speech enhancement techniques have reported results on small vocabulary tasks . but we going to address this wall street journal in our next stage , which is also going to be a noisy task very few people have reported something on using some continuous speech there are some i was looking at some literature on speech enhancement applied to large vocabulary tasks and spectral subtraction doesn't seems to be the thing to do for large vocabulary tasks . and it 's always people have shown improvement with wiener filtering and subspace approach over spectral subtraction everywhere . but if we have to use simple spectral subtraction , we may have to do some optimization to make it work @ @ .    i m guenter hirsch is in charge of that . guenter hirsch and ti . roger r roger , in charge of .  i don't know . there are they have there is no i don't know if they are converging on htk or are using some mississippi state ,  i 'm not about that .   it had additive n        you just take the switchboard trained ?     that 's    with what other new p new parameter ?     i 'm i didn't get it .           make it longer .  unvoiced .  as using just the cepstrum , or ?  is it with ti digits , or with ?    voiced , unvoiced is like  or anything .   d  what one one thing is like what before we started using this vad in this aurora , the th what we did was like , most of about this , adding this additional speech silence bit to the cepstrum and training the on that . that is just a binary feature and that seems to be improving a lot on the speechdat car where there is a lot of noise but not much on the ti digits . ","with what other new p new parameter ? as using just the cepstrum , ",They also explained some of their projects to their guest. 
Bro019.A,"a adding an additional feature to distin to discriminate between speech and nonspeech was helping . that 's it . we actually added an additional binary feature to the cepstrum , just the baseline .   in the case of ti digits it didn't actually give us anything , because there wasn't any f anything to discriminate between speech , and it was very short . but italian was like very it was a huge improvement on italian .       there was a paper in icassp this icassp over the extracting some higher order information from the cepstral coefficients and i forgot the name . some is some harmonics i don't know , pull that paper out from icassp . it  i don't know . i don't remember . it wa it was taking the , it was about finding the higher order moments of  and i 'm not about whether it is the higher order moments , or higher order cumulants and  it was it was  he was showing up some something on noisy speech , some improvement on the noisy speech . some small vocabulary tasks . it was on plp derived cepstral coefficients .  trying to f to moments ,     no not yet . yesterday i called up a lady who ha who will have a vacant room from may thirtieth and she said she 's interviewing two more people .  and she would get back to me on monday . that 's only thing i have and diane has a few more houses . she 's going to take some pictures and send me after i go back . it 's that 's no . i 'm going back to ogi today . i p i plan to be here on thirty first .  if there 's a house available or place to i hope .  in that case , i 'm going to be here on thirty first definitely .   that is of you . it may be he needs more than me .    there is aligned spectral pairs , is like the is that the aligned s no . you just instead of the log you took the root square , cubic root what di w i didn't get that . polynomial .  is that the line spectral it 's like line sp      ",,
Bro019.B," and the filter but it 's it 's the new . the new . the new .  but  in grenada one of my friend . jose carlos segura .  originally the idea was from cmu . i don't have good result , with the inc including the new parameters , i don't have good result . are similar or a little bit worse .   i tried to include another new parameter to the traditional parameter , the coe the cepstrum coefficient , that the auto correlation , the r zero and r one over r zero and another estimation of the var the variance of the difference for of the spec si spectrum of the signal and the spectrum of time after filt mel filter bank . nuh . anyway . the first you have the sp the spectrum of the signal , and you have the on the other side you have the output of the mel filter bank . you can extend the coefficient of the mel filter bank and obtain an approximation of the spectrum of the signal . i do the difference i found a difference at the variance of this different because , suppose we think that if the variance is high , you have n noise . and if the variance is small , you have speech . to to the idea is to found another feature for discriminate between voice sound and unvoice sound . and we try to use this new feature . and i did experiment i need to change to obtain this new feature i need to change the size the window size . of the a of the analysis window size , to have more information . sixty two point five milliseconds and i do i did two type of experiment to include this feature directly with the other feature and to train a neural network to select it voice unvoice silence and to concat this new feature . but the result are n with the neural network i have more or less the same result . result .   it 's neve e sometime it 's worse , sometime it 's a little bit better , but not significantly . and no , i work with italian and spanish and if i don't y use the neural network , and use directly the feature the results are worse . but doesn't help . to know   will try to do that . you did some experiment .  digits . ","i don't have good result , with the inc including the new parameters , i don't have good result . i tried to include another new parameter to the traditional parameter , that the auto correlation , the r zero and r one over r zero and another estimation of the var the variance of the difference for of the spec si spectrum of the signal and the spectrum of time after filt mel filter bank . the idea is to found another feature for discriminate between voice sound and unvoice sound . and we try to use this new feature . i do i did two type of experiment to include this feature directly with the other feature n with the neural network i have more or less the same result . sometime it 's worse , sometime it 's a little bit better ,  will try to do that . ",The other members of the group also reported their recent progress in areas such as spectral subtraction and voicing detection. They also explained some of their projects to their guest. 
Bro019.C,"is it the twenty fourth ?    we we abandoned the lapel because they were not too hot , not too cold , they were they were far enough away that you got more background noise , and and forth but they weren't close that they got quite the the really good no , th they they didn't minute . i 'm saying that wrong . they were not far away that they were really good representative distant mikes , but on the other hand they were not close that they got rid of all the interference . it was no didn't seem to be a good point to them . on the other hand if you only had to have one mike in some ways you could argue the lapel was a good choice , precisely because it 's in the middle . there 's some kinds of junk that you get with these things that you don't get with the lapel little mouth clicks and breaths and forth are worse with these than with the lapel , but given the choice we there seemed to be very strong opinions for getting rid of lapels .  and you should do a lot of talking we get a lot more of your pronunciations . no , they don't have a have any indian pronunciations .  session r r nineteen . if you say o k . do we have anything like an agenda ? what 's going on ?     one thing sunil 's here for the summer , right .  one thing is to talk about a kick off meeting   and then just progress reports individually , and then plans for where we go between now and then ,    why don't you start with that ? that 's  how about an email that points to the faq , what i 'm saying ? that you can  as i understand , he 's using all the machines and you 're using all the machines , is the rough division of i remember i forget whether it was when the rutgers or hopkins workshop , i remember one of the workshops i was at there were everybody was real excited cuz they got twenty five machines and there was some make like thing that sit sent things out . all twenty five people were sending things to all twenty five machines and things were a lot less efficient than if you 'd just use your own machine . as i recall , but .  run command "" doesn't use p make , or ? why would one use that rather than p make ? now , does it have the same behavior as p make , which is that , if you run something on somebody 's machine and they come in and hit a key then it   what about ","sunil 's here for the summer , and then just progress reports individually , and then plans for where we go between now and then , how about an email that points to the faq , ","The ICSI Meeting Recorder Group at Berkley have a temporary new member on loan from research partner OGI. The other members of the group also reported their recent progress in areas such as spectral subtraction and voicing detection. The group shall soon be taking delivery of more machines for a computation farm, and they discussed some software tools for running large processes. "
Bro019.C,"i remember always used to be an issue , it 's not anymore , that if you if something required if your machine required somebody hitting a key in order to evict things that are on it you could work , but if you were logged into it from home ? and you weren't hitting any keys ? cuz you were , home ?    we can ask him sometime . you probably wouldn't ordinarily , though . right ? you probably wouldn't ordinarily . you you 're at home and you 're trying to log in , and it takes forever to even log you in , and you probably go , "" screw this "" , and     why don't we  sunil since you 're haven't been at one of these yet , why don't yo you tell us what 's up with you ? wh what you 've been up to , hopefully .  can you back up a second , i missed something ,  my mind wandered . ad when you added the on line normalization and forth , things got better again ? or is it ? did it not ? no , no . with a different time constant .  no you didn't ,       g the issue is that people do that anyway , everybody does that , and they wanted to see , given that you 're doing that , what are the best features that you should use . clearly they 're interact . don't know that i entirely agree with it . but it might be in some ways it might be better t to rather than giving the endpoints , to have a standard that everybody uses and then interacts with . but , it 's still someth reasonable . it should make the spectral subtraction style things work even better , because you don't have the mistakes in it .    it 's g it 's gonna be harder to beat that actually . but  no , that 's that 's a good update .    s you s you you said one thing i want to jump on for a second . now you 're getting tuned into the repository thing that he has here and we 'll have a single place where the is .   just briefly , you could remind us about the related experiments . cuz you did some that you talked about last week ,  where you were also combining something both of you were both combining something from the french telecom system with the u i don't know whether it was system one or system two , or ?  let me just stop you there . then , one distinction is that you were taking the actual france telecom features and then applying something to   but that 's what but u  i 'm not being clear . what i meant was you had something like cepstra right ? and one difference is that , you were taking spectra . but you got some different result . ","sunil since you 're haven't been at one of these yet , why don't yo you tell us what 's up with you ? just briefly , you could remind us about the related experiments . cuz you did some that you talked about last week , both of you were both combining something from the french telecom system with the u ","He began the meeting by reporting his recent activities, which included looking at the new baseline system. The ICSI Meeting Recorder Group at Berkley have a temporary new member on loan from research partner OGI. The other members of the group also reported their recent progress in areas such as spectral subtraction and voicing detection. "
Bro019.C,"'m trying to understand it . but i th it sounds like you should look at some tables of results and see where i where the where they were different and what we can learn from it .  right . but are they changing the weighting ? i don't understand that . haven't been part of the discussion ,  it seems to me that the matched condition is gonna be unusual , in this case . unusual . because , you don't actually have good matches ordinarily for what any @ @ particular person 's car is like , or  it seems like something like the middle one is more natural . don't know why the matched is  the wa matched has mismatch ?   remind me of what matched meant ? you 've told me many times .  right .  unless they deliberately chose it to be different , which they didn't because they want it to be matched , it is it 's saying if you it 's not guaranteed . right . right . again , if you have enough if you have enough it 's it 's saying you much as you train your dictation machine for talking into your computer , you have a car , and you drive it around a bunch and record noise conditions , and then i don't think that 's very realistic , th i  i they 're saying that if you were a company that was selling the commercially , that you would have a bunch of people driving around in a bunch of cars , and you would have something that was roughly similar and that 's the argument , but i 'm not buy it ,    what else is going on ?    the other thing would be to combine what you 're doing . one or the other of the things that you 're doing would benefit from the other happening first . right , he 's doing a signal subspace thing , it would work better if you 'd already done some simple spectral subtraction , or vi the other way around ,  how is it 'm ignorant about this , how does since wiener filter also assumes that you 're adding together the two signals , how is that differ from signal subspace ?    the difference is the kl . i see . essentially you could do simple spectral subtraction , followed by a kl transform , followed by a wiener filter . in general , you don't that 's right you don't wanna othorg orthogonalize if the things are noisy . actually . that was something that herve and i were talking about with the multi band that if you 're converting things to from bands , groups of bands into cepstral coef local local cepstral coefficients that it 's not that great to do it if it 's noisy .    you should do spectral subtraction and then add noise .   i was only half kidding . ",,
Bro019.C,"if you you do the s spectral subtraction , that also gets rid and then you then add a little bit l noise addition that what j jrasta does , in a way . if you look at what jrasta doing essentially i it 's equivalent to adding a little noise , in order to get rid of the effects of noise .   yes . who is doing this ? who 's the guy in grenada ? i don't know him .   at any rate , you 're looking general , standing back from it , looking at ways to combine one form or another of noise removal , with these other things we have , looks like a worthy thing to do here .  one of the seems like one of the things to go through next week when hari 's here , cuz hari 'll have his own ideas too or not next week , week and a half , will be go through these alternatives , what we 've seen far , and come up with some game plans .   one way would he here are some alternate visions . one would be , you look at a few things very quickly , you pick on something that looks like it 's promising and then everybody works really hard on the same different aspects of the same thing . another thing would be to have t to pick two pol two plausible things , and have t two working things for a while until we figure out what 's better , and then ,   but , w he 'll have some ideas on that too . they 're making there somebody 's generating wall street journal with additive artificially added noise like what they did with ti digits , and ?   and then they 're generating htk scripts to mis mississippi state  that 'll be a little task in itself .  we 've it 's true for the additive noise , y artificially added noise we 've always used small vocabulary too . but for n there 's been noisy speech this larv large vocabulary that we 've worked with in broadcast news . we did the broadcast news evaluation and some of the focus conditions were noisy and but we didn't do spectral subtraction . we were doing our funny right ? we were doing multi multi stream and forth . but it , we di we did helped . it , did something .   now we have this meeting data . like the we 're recording right now , and and that we have for the the quote unquote noisy data there is just noisy and reverberant actually . it 's the far field mike . and we have the digits that we do at the end of these things . and that 's what most o again , most of our work has been done with that , with connected digits .  but we have recognition now with some of the continuous speech , ",,
Bro019.C,"large vocabulary continuous speech , using switchboard switchboard recognizer ,  no training , from this , just plain using the switchboard . that 's what we 're doing ,  now there are some adaptation though , that andreas has been playing with , but we 're hop actually dave and i were just talking earlier today about at some point not that distant future , trying some of the techniques that we 've talked about on , some of the large vocabulary data .  no one had done yet done test one on the distant mike using the sri recognizer and ,  cuz everybody 's scared . you 'll see a little smoke coming up from the cpu trying to do it , but  but , you 're right that that 's a real good point , that we don't if any of these ta that 's why they 're pushing that in the in the evaluation .  but good .  anything else going on ? at you guys ' end , or ?  you probably need to back up a bit seeing as how sunil ,  i really wonder though . we 've had these discussions before , and one of the things that struck me was that about this line of thought that was particularly interesting to me was that we whenever you condense things , in an irreversible way , you throw away some information . and , that 's mostly viewed on as a good thing , in the way we use it , because we wanna suppress things that will variability for particular , phonetic units .  but , you 'll do throw something away . and the question is , can we figure out if there 's something we 've thrown away that we shouldn't have . and  when they were looking at the difference between the filter bank and the fft that was going into the filter bank , i was thinking "" they 're picking on something they 're looking on it to figure out noise , or voice voiced property whatever . "" that 's interesting . that helps to drive the thought process of coming up with the features . but for me the interesting thing was , "" but is there just something in that difference which is useful ? "" another way of doing it , would be just to take the fft power spectrum , and feed it into a neural network , and then use it , in combination , or alone , or whatever no . no the just the same way we 're using the same way that we 're using the filter bank . exact way the same way we 're using the filter bank . the filter bank is good for all the reasons that we say it 's good . but it 's different . and , if it 's used in combination , it will get at something that we 're missing . ","anything else going on ? you probably need to back up a bit we 've had these discussions before , and one of the things that struck me was that about this line of thought that was particularly interesting to me was that we whenever you condense things , in an irreversible way , you throw away some information . and the question is , can we figure out if there 's something we 've thrown away that we shouldn't have . when they were looking at the difference between the filter bank and the fft that was going into the filter bank , i was thinking "" they 're picking on something they 're looking on it to figure out noise , or voice voiced property whatever . "" but for me the interesting thing was , "" but is there just something in that difference which is useful ? "" another way of doing it , would be just to take the fft power spectrum , and feed it into a neural network , and , if it 's used in combination , it will get at something that we 're missing . ",The other members of the group also reported their recent progress in areas such as spectral subtraction and voicing detection. They also explained some of their projects to their guest. 
Bro019.C,"and using , orth klt , or adding probabilities , all th all the different ways that we 've been playing with , that we would let the essentially let the neural network determine what is it that 's useful , that we 're missing here . that 's probably why y i it would be unlikely to work as by itself , but it might help in combination . but i have to tell you , i can't remember the conference , but , it 's about ten years ago , i remember going to one of the speech conferences and i saw within very short distance of one another a couple different posters that showed about the wonders of some auditory inspired front end and a couple posters away it was somebody who compared one to just putting in the fft and the fft did slightly better . mean the i it 's true there 's lots of variability , but again we have these wonderful statistical mechanisms for quantifying that a that variability , and doing something reasonable with it .    it 's same , argument that 's gone both ways about we have these data driven filters , in lda , and on the other hand , if it 's data driven it means it 's driven by things that have lots of variability , and that are necessarily not necessarily gonna be the same in training and test , in some ways it 's good to have data driven things , and in some ways it 's bad to have data driven things .  part of what we 're discovering , is ways to combine things that are data driven than are not . anyway , it 's just a thought , that if we had that it 's just a baseline which would show us "" what are we really getting out of the filters "" , or probably not by itself , but in combination ,  there 's something to be gained from it , and let the but , y you 've only worked with us for a short time , in a year or two you w you will actually come up with the right set of things to extract from this information . but , the neural net and the h m ms could figure it out quicker than you .  it 's just a thought .   and it 's particularly more relevant now since we 're gonna be given the endpoints .     talking cumulants cumulants but no .  cumulants ,   or m e   but again you could argue that th that 's exactly what the neural network does . neural network is in some sense equivalent to computing , higher order moments of what you   it doesn't do it very specifically , and pretty but .  anything on your end you want to talk about ?   the voiced unvoiced version of that could tie right in to what carmen was looking at .  ",it 's just a thought . anything on your end you want to talk about ? ,They also explained some of their projects to their guest. 
Bro019.C,"if you if a multi band approach was helpful as it is , it seems to be helpful for determining voiced unvoiced , that one might be another thing . no . you live in a cardboard box in the street now or , no ?  suni i d ' you v did did you find a place ? is that out of the way ?   and then , you 're coming back thirty first ,  if they 're available , and they 'll be able to get you something , worst comes to worst we 'll put you up in a hotel for a while until you  two bedroom cardboard box . th that 's great . dave .  do y wanna say anything about you actually been last week you were doing this with pierre , you were mentioning . is that something worth talking about , or ? it 's a r root lpc , of some sort .  no , no . it 's it 's taking the finding the roots of the lpc polynomial . it 's like line spectral pairs . except what they call line spectral pairs they push it towards the unit circle , don't they , to but it but but what we 'd used to do w when i did synthesis at national semiconductor twenty years ago , the technique we were playing with initially was taking the lpc polynomial and finding the roots . it wasn't plp cuz hynek hadn't invented it yet , but it was just lpc , and we found the roots of the polynomial , and th when you do that , sometimes they 're f they 're what most people call formants , sometimes they 're not . it 's it 's a little , formant tracking with it can be a little tricky cuz you get these funny values in real speech , but . you get these complex pairs . and it depends on the order that you 're doing , but .  this is from synthetic speech , or ?  if it 's from synthetic speech then it 'll be cleaner . for real speech in real then what you end up having is , like i say , funny little things that are don't exactly fit your notion of formants all that but mostly they are . mostly they do . and what in what we were doing , which was not much looking at things , it was because it was just a question of quantization . we were just storing it was we were doing , stored speech , quantization . but in your case  i bet it might have may have been but he didn't have control over it   the actual you 're not getting the actual formants per se . you 're getting the again , you 're getting the ,  you 're getting something that is af strongly affected by the plp model . and it 's more psycho acoustic . ","is that something worth talking about , ",
Bro019.C,"it 's a little it 's it 's different thing . but i ordinarily , in a formant synthesizer , the bandwidths as as the ban formant centers are that 's somewhere in the synthesizer that was put in , as what you but you view each complex pair as essentially a second order section , which has , band center and band width , and  but .  o k .  you 're going back today and then back in a week and .  great ! welcome . digits . i almost forgot that . i almost forgot our daily digits .  ",,
Bro019.D,"r nineteen ?  it 's not systematically queued . all the jobs are running . if you launch twenty jobs , they are all running . alright .  right .    right .  it was system one .  we the main thing that we did is just to take the spectral subtraction from the france telecom , which provide us some speech samples that are with noise removed .  but it 's the s exactly the same thing because on the heads handset they just applied this wiener filter and then compute cepstral features , right ? or ? right .  think we should have a table with all the result because i don't don't exactly are your results ? but ,  but we did this , and another difference is that we just applied proposal one system after this without with our modification to reduce the delay of the lda filters , and there are slight modifications , but it was the full proposal one . in your case , if you tried just putting lda , then on line normalization ?  we just tried directly to just , keep the system as it was and ,  when we plug the spectral subtraction it improves signif significantly .  but , what seems clear also is that we have to retune the time constants of the on line normalization . because if we keep the value that was submitted it doesn't help you can remove on line normalization , or put it , it doesn't change anything . as long as you have the spectral subtraction . but , you can still find some optimum somewhere , and we don't know where exactly but ,  right .      with changes , because we change it the system to have  lda filters . there are other things that we finally were shown to improve also like , the sixty four hertz cut off . w it doesn't seem to hurt on ti digits , finally . because of other changes .  there are some minor changes ,  and , right now if we look at the results , it 's , always better than it seems always better than france telecom for mismatch and high mismatch . and it 's still slightly worse for matched .  but this is not significant . but , the problem is that it 's not significant , but if you put this in the , spreadsheet , it 's still worse . even with very minor  even if it 's only slightly worse for matched . and significantly better for hm .  but , i don't think it 's importa important because when they will change their metric ,  mainly because of when you p you plug the frame dropping in the baseline system , it will improve a lot hm , and  what will happen i don't will happen . but , the different contribution , for the different test set will be more even .          ","the main thing that we did is just to take the spectral subtraction from the france telecom , we just tried directly to just , keep the system as it was when we plug the spectral subtraction it improves signif significantly . you can remove on line normalization , or put it , it doesn't change anything . as long as you have the spectral subtraction . and , right now if we look at the results , it 's , always better than it seems always better than france telecom for mismatch and high mismatch . and it 's still slightly worse for matched . but this is not significant . ",The other members of the group also reported their recent progress in areas such as spectral subtraction and voicing detection. 
Bro019.D,"it means that if the database is large enough , it 's matched . because it in each set you have a range of conditions    you  we are playing we are also playing , trying to put other spectral subtraction in the code .  it would be a very simple spectral subtraction , on the mel energies which i already tested but without the frame dropping actually , and it 's important to have frame dropping if you use spectral subtraction .  i d i don't know . it 's both cases can i  some of the proposal , we 're doing this on the bin on the fft bins , others on the mel energies . you can do both , but i cannot tell you what 's which one might be better or i i don't know .  but it gives something different , but i don't are the , pros and cons of both .   it might be .  in my implementation i should also try to inspire me from this thing and         what was your point about colored noise there ?   right .     there is this . and we we find some people that agree to work with us , and they have implementation of vts techniques it 's vector taylor series that are used to to model the transformation between clean cepstra and noisy cepstra .  if you take the standard model of channel plus noise , it 's a nonlinear transformation in the cepstral domain . and there is a way to approximate this using first order or second order taylor series and it can be used for getting rid of the noise and the channel effect . working in the cepstral domain ? there is one guy in grenada , and another in lucent that i met at icassp .     it 's again a different thing that could be tried .     but , but for there 's required to that requires to re check everything else , and re optimize the other things and , for the on line normalization may be the lda filter .  i       but there is much variability in the power spectrum .      'm      but anyway the question is even more , is within speech , can we get some features ? are we drop dropping information that can might be useful within speech , to to distinguish between voice sound and unvoiced sounds ?           but  i  actually you have peaks that are not at the formant 's positions , but they are lower in energy and they are much lower .   ","we are playing we are also playing , trying to put other spectral subtraction in the code . it would be a very simple spectral subtraction , on the mel energies we we find some people that agree to work with us , and they have implementation of vts techniques it 's vector taylor series that are used to to model the transformation between clean cepstra and noisy cepstra . it can be used for getting rid of the noise and the channel effect . ",The other members of the group also reported their recent progress in areas such as spectral subtraction and voicing detection. 
Bro019.E,"if you 're in a desperate situation and you need a place to stay , you could stay with me for a while . i 've got a spare bedroom right now .  it 's it i don't think it directly relates . i was helping a speech researcher named pierre divenyi and he 's int he wanted to look at how people respond to formant changes ,  he created a lot of synthetic audio files of vowel to vowel transitions , and then he wanted a psycho acoustic spectrum . and he wanted to look at how the energy is moving over time in that spectrum and compare that to the listener tests . and , i gave him a plp spectrum . and to he t wanted to track the peaks he could look at how they 're moving . took the plp lpc coefficients and i found the roots . this was something that stephane suggested . i found the roots of the lpc polynomial to , track the peaks in the , plp lpc spectra . right .  if @ @ every root that 's since it 's a real signal , the lpc polynomial 's gonna have real coefficients . think that means that every root that is not a real root is gonna be a c complex pair , of a complex value and its conjugate .  for each and if you look at that on the unit circle , one of these one of the members of the pair will be a positive frequency , one will be a negative frequency , just  f for the i 'm using an eighth order polynomial and i 'll get three or four of these pairs which give me s which gives me three or four peak positions . it 's right .   but there 's some of that , yes . it was created from a synthesizer , and i d this we could get , formant frequencies out of the synthesizer , as and , w one thing that the , lpc approach will hopefully give me in addition , is that i might be able to find the b the bandwidths of these humps as stephane suggested looking at each complex pair as a like a se second order iir filter .  but i don't think there 's a g a really good reason not to get the formant frequencies from the synthesizer instead . except that you don't have the psycho acoustic modeling in that .  ","it i don't think it directly relates . i was helping a speech researcher named pierre divenyi and he 's int he wanted to look at how people respond to formant changes , he created a lot of synthetic audio files of vowel to vowel transitions , and then he wanted a psycho acoustic spectrum . and he wanted to look at how the energy is moving over time in that spectrum and compare that to the listener tests . ",
Bro019.F,"now we 're on . yes . yes . for you it is . your mike number 's written on the back of that unit there . and then the channel number 's usually one less than that . it 's one less than what 's written on the back of your  you should be zero , actually . for your channel number . what we usually do is we typically will have our meetings and then at the end of the meetings we 'll read the digits . everybody goes around and reads the digits on the bottom of their forms .  we 're this is session r nineteen . sunil 's here for the summer ? i could say a few words about some of the compute that 's happening around here , that people in the group know .  we we just put in an order for about twelve new machines , to use as compute farm . and we ordered sun blade one hundreds , and i 'm not exactly how long it 'll take for those to come in , but , in addition , we 're running the plan for using these is , we 're running p make and customs here and andreas has gotten that all fixed up and up to speed . and he 's got a number of little utilities that make it very easy to run things using p make and customs . you don't actually have to write p make scripts and things like that . the simplest thing and send an email around or , should do an faq on the web site about it  there 's a c  there 's a command , that you can use called "" run command "" . "" run dash command "" , "" run hyphen command "" . and , if you say that and then some job that you want to execute , it will find the fastest currently available machine , and export your job to that machine , and and run it there and it 'll duplicate your environment .  you can try this as a simple test with the l s command . you can say "" run dash command l s "" , and , it 'll actually export that ls command to some machine in the institute , and do an ls on your current directory . substitute ls for whatever command you want to run , and and that 's a simple way to get started using this . and , soon , when we get all the new machines up , e then we 'll have lots more compute to use . now th one of the things is that each machine that 's part of the p make and customs network has attributes associated with it . attributes like how much memory the machine has , what its speed is , what its operating system , ","i could say a few words about some of the compute that 's happening around here , that people in the group know . we just put in an order for about twelve new machines , to use as compute farm . and andreas has gotten that all fixed up and up to speed . and he 's got a number of little utilities that make it very easy to run things using p make and customs . and send an email around or , should do an faq on the web site about it and , if you say that and then some job that you want to execute , it will find the fastest currently available machine , and export your job to that machine , and , soon , when we get all the new machines up , e then we 'll have lots more compute to use . ","The group shall soon be taking delivery of more machines for a computation farm, and they discussed some software tools for running large processes. "
Bro019.F,"and when you use something like "" run command "" , you can specify those attributes for your program . if you only want your thing to run under linux , you can give it the linux attribute , and then it will find the fastest available linux machine and run it on that .  you can control where your jobs go , to a certain extent , all the way down to an individual machine . each machine has an attribute which is the name of itself . you can give that as an attribute and it 'll only run on that . if there 's already a job running , on some machine that you 're trying to select , your job will get queued up , and then when that resource , that machine becomes available , your job will get exported there .  there 's a lot of features to it and it kinda helps to balance the load of the machines and right now andreas and i have been the main ones using it and we 're the sri recognizer has all this p make customs built into it .   exactly . i got started using the recognizer just recently and fired off a training job , and then i fired off a recognition job and i get this email about midnight from andreas saying , "" are you running two trainings simultaneously s my m my jobs are not getting run . "" had to back off a little bit . but , soon as we get some more machines then then we 'll have more compute available .   that 's just a quick update about what we 've got .    you could write a script which called run command on each sub job right ? but you probably wanna be careful with that because you don't wanna saturate the network .   you should probably not run more than , say ten jobs yourself at any one time , just because then it would keep other people it 's not that much as that , e with if everybody ran fifty jobs at once then it would just bring everything to a halt and , people 's jobs would get delayed , it 's sharing thing .  you should try to limit it to somet sometim some number around ten jobs at a time .  if you had a script that had a thousand things it needed to run , you 'd somehow need to put some logic in there if you were gonna use "" run command "" , to only have ten of those going at a time . and then , when one of those finished you 'd fire off another one .        exactly . you have to be a little bit careful .  but you can also if you have that level of parallelization and you don't wanna have to worry about writing the logic in a perl script to take care of that , you can use p make ",there 's a lot of features to it and it kinda helps to balance the load of the machines ,"The group shall soon be taking delivery of more machines for a computation farm, and they discussed some software tools for running large processes. "
Bro019.F,"and you write a make file that your final job depends on these one thousand things , and when you run p make , on your make file , you can give it the dash capital j and then a number , and that number represents how many machines to use at once . and then it 'll make that it never goes above that .  get some documentation . it depends . if you "" run command "" , that i mentioned before , is doesn't know about other things that you might be running . it would be possible to run a hundred run jobs at once , and they wouldn't know about each other . but if you use p make , then , it knows about all the jobs that it has to run and it can control , how many it runs simultaneously . it uses "" export "" underlyingly . but , if you i it 's meant to be run one job at a time ? you could fire off a thousand of those , and it doesn't know any one of those doesn't know about the other ones that are running . if you have ,  like , if you didn't wanna write a p make script and you just had a , an htk training job that is gonna take six hours to run , and somebody 's using , the machine you typically use , you can say "" run command "" and your htk thing and it 'll find another machine , the fastest currently available machine and run your job there . yes .  there are right . some of the machines at the institute , have this attribute called "" no evict "" . and if you specify that , in one of your attribute lines , then it 'll go to a machine which your job won't be evicted from . but , the machines that don't have that attribute , if a job gets fired up on that , which could be somebody 's desktop machine , and they were at lunch , they come back from lunch and they start typing on the console , then your machine will get evicted your job will get evicted from their machine and be restarted on another machine . automatically . which can you to lose time , right ? if you had a two hour job , and it got halfway through and then somebody came back to their machine and it got evicted . if you don't want your job to run on a machine where it could be evicted , then you give it the minus the attribute , "" no evict "" , and it 'll pick a machine that it can't be evicted from .    i 'm not how that works . it seems like andreas did something for that .  but  i don't know whether it monitors the keyboard or actually looks at the console tty , ",,
Bro019.F,"if you echoed something to the dev console       'm not about that one . but    and also stephane 's a really good resource for that if you can't find me . especially with regard to the aurora he knows that better than i do . are y are you saying lda ? lda .   people won't even have to worry about , doing speech nonspeech then .  i see .  i see .   are people supposed to assume that there is are people not supposed to use any speech outside of those endpoints ? or can you then use speech outside of it for estimating background noise and things ?   the baseline itself improves by fifty percent .   perfect to match . it 's not guaranteed though . is it is spectral subtraction typically done on the after the mel , scaling or is it done on the fft bins ? does it matter , or ?     i see .  i don't not that i know of . that 's right wi with what targets ? phones .   you 're not down here permanently yet ?   you just you typically just get a few roots ?  two or three , something like that ?  how did if this is synthetic speech can't you just get the formants directly ? how is the speech created ? wasn't a formant synthesizer was it ?  i see . that 's the point .  we should do digits quickly . you wanna go ahead ?  ","people won't even have to worry about , doing speech nonspeech then . ","He began the meeting by reporting his recent activities, which included looking at the new baseline system. "
Bro019.G,"i have a question about the parallelization ? let 's say i have like , a thousand little jobs to do ? how do i do it with "" run command "" ? do  a thousand times ?   too much file transfer and  just do p make . s   right . right .  you 're talking about your voicing ? nothing i wanna really talk about . just share a little bit sunil hasn't heard about what i 've been doing .   i told you i was i was getting prepared to take this qualifier exam . that 's just , trying to propose your next your following years of your phd work , trying to find a project to define and to work on . i 've been , looking into , doing something about r speech recognition using acoustic events .  the idea is you have all these different events , voicing , nasality , r coloring , burst or noise , frication , that kinda building robust primary detectors for these acoustic events , and using the outputs of these robust detectors to do speech recognition .  and , these primary detectors , will be , inspired by , multi band techniques , doing things , similar to larry saul 's work on , graphical models to detect these , acoustic events . and , been thinking about that and some of the issues that i 've been running into are , exactly what acoustic events i need , what what acoustic events will provide a good enough coverage to in order to do the later recognition steps . and , also , once i decide a set of acoustic events , h how do i get labels ? training data for these acoustic events . and , then later on down the line , start playing with the models themselves , the primary detectors .   i kinda see like , after building the primary detectors i see myself taking the outputs and feeding them in , sorta tandem style into a gaussian mixtures back end , and doing recognition .  that 's just generally what i 've been looking at .       were you gonna say something ?  it looked  never mind .  and this past week i 've been looking a little bit into traps and doing traps on these e events too , just , seeing if that 's possible .  and other than that , i was kicked out of i house for living there for four years .  s som something like that . in albany ,   and  that 's it .  thirty first .   no , no . my cardboard box is actually a spacious two bedroom apartment .  ","sunil hasn't heard about what i 've been doing . that 's just , trying to propose your next your following years of your phd work , trying to find a project to define and to work on . i 've been , looking into , doing something about r speech recognition using acoustic events . building robust primary detectors for these acoustic events , and using the outputs of these robust detectors to do speech recognition . ",They also explained some of their projects to their guest. 
Bro021.A," still working on my quals preparation 'm thinking about , starting some , cheating experiments to , determine the , the relative effectiveness of , some intermediate categories that i want to classify . if i know where voicing occurs and everything , i would do a phone phone recognition experiment , somehow putting in the , the perfect knowledge that i have about voicing . in particular i was thinking , in the hybrid framework , just taking those lna files , and , setting to zero those probabilities that , that these phones are not voicing . say know this particular segment is voicing , i would say , go into the corresponding lna file and zonk out the posteriors for , those phonemes that , are not voiced , and then see what kinds of improvements i get . and this would be a useful thing , to know in terms of which , which of these categories are good for , speech recognition . that 's i hope to get those , those experiments done by the time quals come around in july .  i was thinking just set to some really low number , the non voiced , phones . right ? and then renormalize . right .    m i 'm gonna f work with timit timit phone recognition with timit . and ,  the outputs of the net go into the standard , h icsi hybrid , recognizer . chronos or phone recognition . right , right .  and , another thing would be to extend this to , digits where look at whole words . and i would be able to see , not just phoneme events , but , inter phoneme events . this is from a stop to a vo a vocalic segment .  something that is transitional in nature .  that 's it .  ","still working on my quals preparation 'm thinking about , starting some , cheating experiments to , determine the , the relative effectiveness of , some intermediate categories that i want to classify . if i know where voicing occurs and everything , i would do a phone phone recognition experiment , and this would be a useful thing , to know in terms of which , which of these categories are good for , speech recognition . i hope to get those , those experiments done by the time quals come around in july . ",Other progress was also reported. 
Bro021.B," somebody else should run this . i 'm sick of being the one to go through and say , "" what do you think about this ? "" you wanna ? why don't you run it today ?  do you make errors in different places ? different kinds of errors ?      i really would like to suggest looking , a little bit at the kinds of errors . i know you can get lost in that and go forever and not see too much , but sometimes , but , just seeing that each of these things didn't make things better may not be enough . it may be that they 're making them better in some ways and worse in others , or increasing insertions and decreasing deletions , or or ,  helping with noisy case but hurting in quiet case . and if you saw that then you it would something would occur to you of how to deal with that .    there 's less difference . right ? cuz it 's  again , if you trained in one noise and tested in the same noise , you 'd given enough training data you don't do b do badly . the reason that we d that we have the problems we have is because it 's different in training and test . even if the general kind is the same , the exact instances are different . and when you whiten it , then it 's like you the only noise to first order , the only th noise that you have is white noise and you 've added the same thing to training and test . it 's ,  it 's a smoothing , but  but you 're still getting more recognition errors , which means that the differences , even though they look like they 're not big , are hurting your recognition . right ?  the other thing is that you just picked one particular way of doing it . first place it 's fifteen db , down across the utterance . and you 'd want to have something that was a little more adaptive . secondly , you happened to pick fifteen db and twenty 'd be better , or twelve .  he he had to figure out how much to add . he was looking at the peak value . right ? and then   then afterwards a log is taken , and that 's why the little variation tends to go away . or not constant but , varying over time is another way to go .  were you using the normalization in addition to this ? what was the rest of the system ?    but on the other hand if everybody is trying different kinds of noise suppression things and forth , it might be good to standardize on the piece that we 're not changing . right ? if there 's any particular reason to ha pick one or the other ,  ","do you make errors in different places ? different kinds of errors ? i really would like to suggest looking , a little bit at the kinds of errors . i know you can get lost in that and go forever and not see too much , but sometimes , just seeing that each of these things didn't make things better may not be enough . it may be that they 're making them better in some ways and worse in others , or increasing insertions and decreasing deletions , helping with noisy case but hurting in quiet case . and if you saw that then you it would something would occur to you of how to deal with that . ",
Bro021.B,"which one is closer to what the proposal was that was submitted to aurora ? are they they both ?  no , i 'm i you 're trying to add in france telecom . tell them about the rest of it . like you said the number of filters might be different right ? or cep  we 'd wanna standardize there , wouldn't we ? sh you guys should pick something and all th all three of you . as long as you guys agree on it , it doesn't matter . we have a maximum of sixty , features that we 're allowed .   no . i 'm just , being a manager this week .  the big one takes a while . that takes two , three weeks . but , you can get i don't know if you even want to run the big one , in the final system , cuz , it takes a little while to run it . you can scale it down by i 'm it was two , three weeks for training up for the large broadcast news test set training set . i don't know how much you 'd be training on . the full ? i if you trained on half as much and made the net , half as big , then it would be one fourth the amount of time and it 'd be nearly as good .   also , we had we 've had these , little di discussions you ha haven't had a chance to work with it too much about , other ways of taking care of the phase . that was something i could say would be that we 've talked a little bit about you just doing it all with complex arithmetic and , and not , doing the polar representation with magnitude and phase . but it looks like there 's ways that one could potentially just work with the complex numbers and in principle get rid of the effects of the average complex spectrum . but  p  'm still hopeful that we don't even know if the phase is something the average phase is something that we do want to remove . there 's some deeper reason why it isn't the right thing to do . but , at least in principle it looks like there 's , a couple potential ways to do it . one being to just work with the complex numbers ,  and , in rectangular coordinates . and the other is to , do a taylor series  you work with the complex numbers and then when you get the spectrum the average complex spectrum actually divide it out , as opposed to taking the log and subtracting . then ,   there might be some numerical issues . we don't really know that . the other thing we talked a little bit about was taylor series expansion . and , actually i was talking to dick karp about it a little bit , ","also , we had we 've had these , little di discussions that was something i could say would be that we 've talked a little bit about you just doing it all with complex arithmetic and not , doing the polar representation with magnitude and phase . ",
Bro021.B,"and and , since i got thinking about it , and , one thing is that y you 'd have to do ,  we may have to do this on a whiteboard , but you have to be a little careful about scaling the numbers that you 're taking the complex numbers that you 're taking the log of because the taylor expansion for it has , a square and a cube , and forth . and if you have a number that is modulus , very different from one it should be right around one , if it 's cuz it 's a expansion of log one one minus epsilon or o is one plus epsilon , or is it one plus ? there 's an epsilon squared over two and an epsilon cubed over three , and forth . if epsilon is bigger than one , then it diverges . you have to do some scaling . but that 's not a big deal cuz it 's the log of k times a complex number , then you can just that 's the same as log of k plus log of the complex number .  there 's converges . but . i missed the v i 'm i was distracted . i missed the very first sentence . then , i 'm a little lost on the rest . what what ? i see .     right .  as he is wont to do .    that 'd be good from for analysis . it 's good to have some , cases of the same utterance at different times .  i see . that @ @ given that you 're using the vad also , the effect of the vts is not far do you how much of that do you think is due to just the particular implementation and how much you 're adjusting it ? or how much do you think is intrinsic to ? i have an idea . if , y you 're right . each of these require this . given that we 're going to have for this test at least of boundaries , what if initially we start off by using known sections of nonspeech for the estimation ? right ? s e first place , even if ultimately we wouldn't be given the boundaries , this would be a good initial experiment to separate out the effects of things . how much is the poor relatively , unhelpful result that you 're getting in this or this is due to some inherent limitation to the method for these tasks and how much of it is just due to the fact that you 're not accurately finding enough regions that are really n noise ?  if you tested it using that , you 'd have more reliable stretches of nonspeech to do the estimation from and see if that helps .   i 'm actually just confused about the equations you have up there .  the top equation is which is the log domain ? and ","that @ @ given that you 're using the vad also , the effect of the vts is not far ",
Bro021.B,"but y is what ? y of the spectrum or ? no , no . the top y is what ? is that power spectrum ? no , is that power spectrum ? is it ?  that 's    this it 's the magnitude squared you have power spectrum added there and down here you have you put the depends on t , but b all of this is just you just mean you just mean the log of the one up above . and , that is x times ,  o x times one plus , n n minus x ? and then , that 's log of x plus log of one plus ,  is that right ? log of i actually don't see how you get that .    no . that doesn't follow .   just never mind what they are . it 's just if x and n are variables right ? the log of x plus n is not the same as the log of e to the x plus e to the n . we can take it off line , but i don't know .  i  cuz it doesn't just follow what 's there . it has to be some , taylor series no . that doesn't follow . that that the f top one does not imply the second one . because cuz the log of a sum is not the same as th as  right . right . you could s  n no , but i don't see how you get the second expression from the top one . the just more generally here , if you say "" log of , a plus b "" , the log of a plus b is not or a plus b is not the , log of e to the a plus e to the b . right ? and that 's what you seem to be saying . right ? cuz you up here you have the a plus b plus n . right . right . and then how do you go from there to the ? look .  let 's c equals a plus b , and then right .  that one 's right .  i see . i see . i understand now . alright ,   it 's just by definition that the individual that the , capital x is by definition the same as e to the little x because she 's saying that the little x is the , is the log . alright .  alright . these things are a lot clearer when you can use fonts different fonts there which is which . but i under i understand what now .    yes . i understand now . and that 's where it comes from .  right . right .   now once you get that one , then you do a first or second order , taylor series expansion of this . right .       how h ",,
Bro021.B,"how much in the work they reported , how much noisy speech did you need to get , good enough statistics for the to get this mapping ?   cuz what 's certainly characteristic of a lot of the data in this test is that , you don't have the the training set may not be a great estimator for the noise in the test set . sometimes it is and sometimes it 's not .  and what are you using for the noisy ? y doing that strictly  and you train it up entirely from , nonspeech sections in the test ?           what is the first variable in that probability ? no , no . i 'm in the one you pointed at . what 's that variable ?  yes .   yes .    i 'm not following this perfectly but , i are you saying that all of these estimates are done using , estimates of the probability density for the noise that are calculated only from the first ten frames ? and never change throughout anything else ? per utterance , or per ? per utterance .  it 's done new for each new utterance . this changes the whole mapping for every utterance .     you estimated , f completely forgetting what you had before ? or is there some adaptation ?  now do we know , either from their experience or from yours , that , just having , two parameters , the mean and variance , is enough ?  i know you don't have a lot of data to estimate with , but ,  no , i 'm talking about the noise . there 's only one gaussian . right . and you and it 's ,  right , it 's only it 's only one minute . this is what 's the dimensionality of the gaussian ? this is this is twenty twenty ? it 's it 's actually forty numbers that you 're getting . you don't have a  but , no paper is a bible ,  this is this is , the question is , whether it would be helpful , i particularly if you used if you had more suppose you did this is almost cheating . it certainly isn't real time . but if y suppose you use the real boundaries that you were were given by the vad and forth or we 're gonna be given even better boundaries than that . and you look you take all o all of the nonspeech components in an utterance , you have a fair amount . do you benefit from having a better model for the noise ? that would be another question . first question would be to what extent i are the errors that you 're still seeing based on the fact that you have poor boundaries for the , nonspeech ? and the second question might be , given that you have good boundaries , could you do better if you used more parameters to characterize the noise ?  ",,
Bro021.B,"also another question might be they are doing they 're using first term only of the vector taylor series ? if you do a second term does it get too complicated cuz of the nonlinearity ?  no , i won't ask the next question then .  no , it 's interesting . w we haven't had anybody work with it before , it 's interesting to get your feedback about it . right . i have some .  they prefer to have them on just that they 're continuing to get the distant , information . s ",,
Bro021.C,"alright .  the first thing is that the p eurospeech paper is , accepted .   it 's the paper that describe the , system that were proposed for the aurora . right ,  and the , fff comments seems from the reviewer are good .    it 's , aalborg in denmark . and it 's ,  september .   then , whhh i 've been working on t mainly on line normalization this week . i 've been trying different slightly different approaches . the first thing is trying to play a little bit again with the , time constant . second thing is , the training of , on line normalization with two different means , one mean for the silence and one for the speech .  and have two recursions which are controlled by the , probability of the voice activity detector .  this actually don't s doesn't seem to help , although it doesn't hurt .  but both on line normalization approach seems equivalent . they  they can be very different .  i didn't look , more closely . it might be ,   there is one thing that we can observe , is that the mean are more different for c zero and c one than for the other coefficients . and  and it the c one is there are strange thing happening with c one , is that when you have different noises , the mean for the silence portion is can be different . and when you look at the trajectory of c one , it 's has a strange shape and i was expecting th the s that these two mean helps , especially because of the strange c ze c one shape , which can like , yo you can have , a trajectory for the speech and then when you are in the silence it goes somewhere , but if the noise is different it goes somewhere else . which would mean that if we estimate the mean based on all the signal , even though we have frame dropping , but we don't frame ev drop everything , but this can hurts the estimation of the mean for speech , and but i still have to investigate further , a third thing is , that instead of t having a fixed time constant , i try to have a time constant that 's smaller at the beginning of the utterances to adapt more quickly to the r something that 's closer to the right mean . t  and then this time constant increases and i have a threshold that if it 's higher than a certain threshold , i keep it to this threshold to still , adapt , the mean when if the utterance is , long enough to continue to adapt after one second or  this doesn't help neither , but this doesn't hurt .  it seems pretty it was i don't know . no . ","the first thing is that the p eurospeech paper is , accepted . it 's the paper that describe the , system that were proposed for the aurora . and the , fff comments seems from the reviewer are good . i 've been working on t mainly on line normalization this week . i 've been trying different slightly different approaches . this actually don't s doesn't seem to help , although it doesn't hurt . but both on line normalization approach seems equivalent . i didn't look , more closely . ","The majority of the group are working on tasks related to the Aurora Project, including on-line normalization and Wiener filtering. "
Bro021.C,"u it 's this idea of having different on line normalization , tunings for the different mfcc 's . but   there actually , s it 's very important to normalize c zero and much less to normalize the other coefficients . and , actu at least with the current on line normalization scheme . and we we know that normalizing c one doesn't help with the current scheme . and and in my idea , i was thinking that the reason is because of these funny things that happen between speech and silence which have different means .   but it 's not easy to      alright .   w that 's it , for the on line normalization .  i 've been playing a little bit with some thresholding , and ,  as a first experiment ,  what i did is t is to take , to measure the average no , the maximum energy of s each utterance and then put a threshold this for each mel band . then put a threshold that 's fifteen db below a couple of db below this maximum , and actually it was not a threshold , it was just adding noise . was adding a white noise energy , that 's fifteen db below the maximum energy of the utterance . and  when we look at the , mfcc that result from this , they are a lot more smoother .  when we compare channel zero and channel one utterance clean and , the same noisy utterance there is almost no difference between the cepstral coefficients of the two .  and and the result that we have in term of speech recognition , actually it 's not worse , it 's not better neither , but it 's , surprising that it 's not worse because you add noise that 's fifteen db just fifteen db below the maximum energy . and at least it 's it 's whitening this the portion that are more silent , as you add a white noise that are has a very high energy , it whitens everything and and the high energy portion of the speech don't get much affected anyway by the other noise . and as the noise you add is the same is the shape , it 's also the same . they have the trajectory are very , very similar . and  it 's different . it 's something that that affects more or less the silence portions because anyway , the sp the portion of speech that ha have high energy are not ch a lot affected by the noises in the aurora database . if you compare th the two shut channels of speechdat car during speech portion , it 's n the mfcc are not very different . they are very different when energy 's lower , like during fricatives or during speech pauses . and ,  ye it distort the speech . right .  no . it didn't . but  ","i 've been playing a little bit with some thresholding , as a first experiment , no , the maximum energy of s each utterance then put a threshold that 's fifteen db below actually it was not a threshold , it was just adding noise . when we look at the , mfcc that result from this , they are a lot more smoother . and the result that we have in term of speech recognition , actually it 's not worse , it 's not better neither , ","The majority of the group are working on tasks related to the Aurora Project, including on-line normalization and Wiener filtering. "
Bro021.C,"but in this case i really expect that the two these two stream of features , they are very different . and we could gain something by combining them or   right .  i systematically add the noise , but the , noise level is just some threshold below the peak .    which is not really noise , actually . it 's just adding a constant to each of the mel , energy . to each of the mel filter bank .  it 's really , white noise . i th   may the this threshold is still a factor that we have to look at . and i don't know , constant noise addition would be fine also , or       it was it was , the same system .  it was the same system .   a third thing is that , i play a little bit with the , finding what was different between , and there were a couple of differences , like the lda filters were not the same .  he had the france telecom blind equalization in the system .  the number o of mfcc that was were used was different . you used thirteen and we used fifteen . a bunch of differences . and , actually the result that he got were much better on ti digits especially . 'm investigated to see what was the main factor for this difference . and it seems that the lda filter is was hurting . when we put s some noise compensation the , lda filter that 's derived from noisy speech is not more anymore optimal . and it makes a big difference , on ti digits trained on clean . if we use the old lda filter , the lda filter that was in the proposal , we have eighty two point seven percent recognition rate ,  on noisy speech when the system is trained on clean speech . but and when we use the filter that 's derived from clean speech we jumped from eighty two point seven to eighty five point one , which is a huge leap .   now the results are more similar , and i don't i will not , investigate on the other differences , which is like the number of mfcc that we keep and other small things that we can optimize later on anyway .  th the new system that i tested is , closer because it doesn't have it have less of france telecom i   but , we   we were gonna work with this or this new system , or with  right .  but we will use the lda filters f derived from clean speech . actually it 's not the lda filter . it 's something that 's also short enough in latency .         and there is also this log energy versus c zero .  w if       that 's it ,   are you still using only the ten first frame for noise estimation or ? or i ?   you have to standardize this thing also , ","a third thing is that , i play a little bit with the , finding what was different between , he had the france telecom blind equalization in the system . the number o of mfcc that was were used was different . you used thirteen and we used fifteen . ",
Bro021.C,"noise estimation , because all the thing that you are testing use a different they all need some noise spectra but they use every all use a different one .     p s this it 's the power spectrum of noisy speech . and   is it the first order expansion ?     but the second expression that you put is the first order expansion of the nonlinear relation between what is that ? it 's log o of capital y . right . capital y .  right .  and the model of clean speech is a codebook . right ?   it 's one mixture of the model . right ? ",,
Bro021.D,"    the the whatever you , tested with recently . right ?  the number of cepstral coefficients is what ?   the right now , the system that is there in the what we have in the repositories , with uses fifteen .         we haven't w we have been always using , fifteen coefficients , not thirteen ?  that 's something 's   then  ma we can at least , i 'll t s run some experiments to see whether once i have this noise compensation to see whether thirteen and fifteen really matters or not . never tested it with the compensation , but without , compensation it was like fifteen was s slightly better than thirteen , that 's why we stuck to thirteen .  fifteen . the log energy versus c zero . that 's the other thing . without noise compensation certainly c zero is better than log energy . be because the there are more , mismatched conditions than the matching conditions for testing .  always for the matched condition , you always get a slightly better performance for log energy than c zero . but not for for matched and the clean condition both , you get log energy you get a better performance with log energy . once we have this noise compensation , i don't know , we have to try that also , whether we want to go for c zero or log energy . we can see that .    i 've been , implementing this , wiener filtering for this aurora task . and , i actually thought it was doing fine when i tested it once . i it 's using a small section of the code . and then i ran the whole recognition experiment with italian and i got worse results than not using it . then i i 've been trying to find where the problem came from . and then it looks like i have some problem in the way there is some very silly bug somewhere . and , ugh ! i it actually i it actually made the whole thing worse . i was looking at the spectrograms that i got and it 's , like w it 's very horrible . like , when i   i actually implemented the wiener f fil filtering as a module and then tested it out separately . and it gave , like got the signal out and it was i plugged it in somewhere and then it 's like i had to remove some part and then plugging it in somewhere . and then i in that process i messed it up somewhere .  it was real it was all fine and then i ran it , and i got something worse than not using it .  i was like i 'm trying to find where the m problem came , and it seems to be somewhere some silly and , the other thing , was , hynek showed up one suddenly on one day ","the right now , the system that is there in the what we have in the repositories , with uses fifteen . we haven't w we have been always using , fifteen coefficients , not thirteen ? i 'll t s run some experiments to see whether once i have this noise compensation to see whether thirteen and fifteen really matters or not . never tested it with the compensation , but without , compensation it was like fifteen was s slightly better than thirteen , i 've been , implementing this , wiener filtering for this aurora task . i actually thought it was doing fine when i tested it once . i it 's using a small section of the code . and i got worse results than not using it . i 've been trying to find where the problem came from . and then it looks like i have some problem in the way there is some very silly bug somewhere . i it actually i it actually made the whole thing worse . and it 's , like w it 's very horrible . i was like i 'm trying to find where the m problem came , hynek showed up one suddenly on one day ","The majority of the group are working on tasks related to the Aurora Project, including on-line normalization and Wiener filtering. "
Bro021.D,"and then i was t talking wi  was actually that day i was thinking about d doing something about the wiener filtering , and then carlos matter of and then he showed up and then i told him . and then he gave me a whole bunch of filters what carlos used for his , thesis and then that was something which came up . and then , i 'm actually , thinking of using that also in this , w wiener filtering because that is a m modified wiener filtering approach , where instead of using the current frame , it uses adjacent frames also in designing the wiener filter . instead of designing our own new wiener filters , i may just use one of those carlos filters in this implementation and see whether it actually gives me something better than using just the current f current frame , which is in a way , something like the smoothing the wiener filter but @ @ s i don't know , i was h i 'm i 'm , like that that is the next thing . once this i once i sort this pro problem out 'll just go into that also . and the other thing was about the subspace approach .  i plugged some groupings for computing this eigen s values and eigenvectors . just @ some small block of things which i needed to put together for the subspace approach . and i 'm in the process of building up that and ,  guess that 's it . and , th that 's where i am right now .  new   one plus n by x . one plus n by x . and and , log of  no . if e restricts it is y what is , the log the taylor series expansion for log one plus n by x is the first one .   y if you take log x into log one plus n by x , and then expand the log one plus n by x into taylor series  no .  x . x . this is x , inside . one and x k c noise . weak . probably it would do that . it 's overlapping . s s we switch off with this or n ? no .   ","was actually that day i was thinking about d doing something about the wiener filtering , and then carlos matter of and then he gave me a whole bunch of filters what carlos used for his , thesis instead of designing our own new wiener filters , i may just use one of those carlos filters in this implementation that that is the next thing . once this i once i sort this pro problem out 'll just go into that also . the other thing was about the subspace approach . ",
Bro021.E," i 'm working with vts . i do several experiment with the spanish database first , only with vts and nothing more . not vad , no lda , nothing more . vectorial taylor series . to remove the noise too . what ?  if vts . i 'm sor the question is that  remove some noise but not too much . and when we put the m the , vad , the result is better . and we put everything , the result is better , but it 's not better than the result that we have without vts . no , no . is not . pfft . i don't know because hhh , i do the experiment using only the f onl to use on only one fair estimation of the noise . and also i did some experiment , doing , a lying estimation of the noise . and , it 's a little bit better but not n  no , i do that two t did two time .    another thing is the , the codebook , the initial codebook . that it 's too clean and cuz it 's a i don't know . the methods if you want , you c say something about the method . in the because it 's a little bit different of the other method . we have if this is the noise signal , in the log domain , we have something like this . now , we have something like this . and the idea of these methods is to n given a , how do you say ? i will read because it 's better for my english . i given is the estimate of the pdf of the noise signal when we have a , a statistic of the clean speech and an statistic of the noisy speech . and the clean speech the statistic of the clean speech is from a codebook . this is the idea . this relation is not linear . the methods propose to develop this in a vectorial taylor series approximation . no , this in the it 's this is the log domain . i must to say that . is the t is egual is equal to , log of this is this and this is this .  this is the noisy speech . it 's the power spectrum . this is the noisy it 's of the value  w o it 's the same .   but , n y we can expre we can put this expression the  and the noise signal .  if we apply the log , we have e is n log e is equal , to log of x plus n . and , we can say that e is equal to log of , exponential of x plus exponential of n . this is in the ti the time domain . we have that ,  we have first that , x is equal ,   this is the frequency domain ","i 'm working with vts . only with vts and nothing more . not vad , no lda , nothing more . to remove the noise too . and when we put the m the , vad , the result is better . and we put everything , the result is better , but it 's not better than the result that we have without vts . ","The majority of the group are working on tasks related to the Aurora Project, including on-line normalization and Wiener filtering. "
Bro021.E,"and we can put u that n the log domain log of x omega , but , in the time domain we have an exponential . no ? no ? it 's i am i 'm problem .  but this i i don't   do this incorrectly . the expression that appear in the paper , is , is x now , this is the and then not exactly . no , no . it 's not the first space . we have pfft , we can put that x is equal i is equal to log of ,  we can put , this ? the top ?  but we can we know that , the log of e plus b is equal to log of e plus log to b . and we can say here , it i and we can , put this inside . and then we can ,    no , no , no , no . this not . no . no . it 's not . but this is the same  no . i say if i apply log , i have , log of e is equal to log of , in this side , is equal to log of x plus n . no ? right . this is right . and then if i apply exponential , to have here e  we have this , no ?  s i th we can put here the set transformation . no ?  in this case , we can put here a y . now we can put this . no ? and here we can multiply by x . yes .  that 's true . that 's true . but this is correct ? and now do it ,  pfff ! put log of ex plus log and this is now it 's correct . the idea  we have fixed this equa  this is another linear relation that this to develop this in vector s taylor series .  and for that , the goal is to obtain , est estimate a pdf for the noisy speech when we have a statistic for clean speech and for the noisy speech .  and when w the way to obtain the pdf for the noisy speech is we know this statistic and we know the noisy st we can apply first order of the vector st taylor series of the of the order that we want , increase the complexity of the problem . and then when we have a expression , for the mean and variance of the noisy speech , we apply a technique of minimum mean square estimation to obtain the expected value of the clean speech given the this statistic for the noisy speech the statistic for clean speech and the statistic of the noisy speech . this only that . but the idea is that u  we have our codebook with different density gaussian . ",,
Bro021.E,"we can expre we can put that the pdf for the clean test , probability of the clean speech is equal to i don't know exactly . i need to s i don't know exactly .  i the clean speech the codebook for clean speech , i am using timit . and i have now , sixty four gaus gaussian . of the noise i estimate the noises wi for the noises i only use one gaussian . yes . the first experiment that i do it is solely to calculate the , this value the compensation of the dictionary o one time using the noise at the f beginning of the sentence . this is the first experiment . and i fix this for all the sentences . because the vts methods the first thing that i do is to obtain , an expression for e probability e expression of e . that mean that the vts with the vts we obtain ,  we obtain the means for each gaussian and the variance . this is one . this is the composition of the dictionary . this one thing . and the other thing that this with these methods is to , obtain to calculate this value . because we can write we can write that the estimation of the clean speech is equal at an expected value of the clean speech conditional to , the noise signal the probability f of the statistic of the clean speech and the statistic of the noise . this is the methods that say that we 're going obtain this . and we can put that this is equal to the estimated value of e minus a function that conditional to e to the t to the noise signal . this is this function is the term after develop this , the term that we take . give px and , p the noise . and put that this is equal to the noise signal minus i put before this name ,  and calculate this . this is the gaussian . v this is the like this , but conditional . no , it 's condition it 's not exactly this . it 's modify . if we have clean speech we have the dictionary for the clean speech , we have a probability f of our weight for each gaussian . no . and now , this weight is different now because it 's conditional . and this i need to calcu i know this and i know this because this is from the dictionary that you have . i need to calculate this . and for calculate this , i have an develop an expression that is that . calculate calculated this value , with the statistic of the noisy speech that i calculated before with the vts approximation . and normalizing . and i know everything . with the , nnn ",,
Bro021.E,"when i develop this in s taylor series , i can't , calculate the mean and the variance of the for each of the gaussian of the dictionary for the noisy speech . now . and this is fixed . if i never do an estimat a newer estimation of the noise , this mean as mean and the variance are fixed . and for each s frame of the speech the only thing that i need to do is to calculate this in order to calculate the estimation of the clean speech given our noisy speech .  never cha this is one of the approximations that i am doing . per utterance . yes . per utterance . yes . and th  it 's not   it 's fixed , the dictionary . and the other estimation is when i do the on line estimation , i change the means and variance of th for the noisy speech each time that i detect noise . i do it again this develop . estimate the new mean and the variance of the noisy speech . and with th with this new s new mean and variance i estimate again this .  no , no . it 's not completely no , it 's i am doing something like an adaptation of the noise . i estimate mean and variance for each one of the gaussian of the codebook .  only one i am only using only one . i don't it 's in after the mel filter bank . twenty three . the original paper say that only one gaussian for the noise . isn't the right thing .    it 's quite complicated . it 's the for me it 's the first time that i am working with vts .  it 's another type of approximation because i because it 's a statistic approximation to remove the noise . i don't know .  ",,
Bro021.F," should we take turns ? you want me to run it today ?    let 's see , we should just get a list of items things that we should talk about .  there 's the usual updates , everybody going around and saying , what they 're working on , the things that happened the last week . but aside from that is there anything in particular that anybody wants to bring up for today ? no ?  why don't we just around and people can give updates . do you want to start , stephane ? this is what do you , what 's in the paper there ? the one that we s we submitted the last round ?   where 's it gonna be this year ?   are the means pretty different for the two ?    wasn't there some experiment you were gonna try where you did something differently for each , don't know whether it was each mel band or each , fft bin or someth there was something you were gonna some parameter you were gonna vary depending on the frequency . i don't know if that was for each ,  morgan , you brought it up a couple meetings ago . and then it was something about , some and then somebody said "" it does seem like , c zero is the one that 's , the major one "" or , s i can't remember exactly what it was now .   why does that m smooth things out ? i don't understand that .      would that be similar to doing the smoothing , then , over time or ?  performance went down ?  what was the threshold part of it ? was the threshold , how far down ?  and what 's ho i don't understand . how does it go ? if it if the peak value 's above some threshold , then you add the noise ? or if it 's below s i see . i see .  i see .  do you have more , stephane , or ? do you have anything , morgan , or ? how about you , barry ?     do you just take the probabilities of the other ones and spread them out evenly among the remaining ones ?    that will be really interesting to see ,  then you 're gonna feed the those into some standard recognizer . wh are you gonna do digits or ? with timit .  then you 'll feed those  where do the outputs of the net go into if you 're doing phone recognition ? an and you 're gonna the you 're gonna do phone recognition with that ?  i see .   right .  great .    let 's see , i haven't done a whole lot on anything related to this week . i 've been focusing mainly on meeting recorder 'll just pass it on to dave .      how about you , sunil ? how about you , carmen ? what is vts again ? yes . ","let 's see , we should just get a list of items there 's the usual updates , everybody going around and saying , what they 're working on , the things that happened the last week . do you want to start , stephane ? how about you , barry ? 'll just pass it on to dave . how about you , sunil ? how about you , carmen ? ","The ICSI Meeting Recorder Group at Berkeley met once more to discuss group members' progress. Other progress was also reported. The majority of the group are working on tasks related to the Aurora Project, including on-line normalization and Wiener filtering. "
Bro021.F,"right , right . ask you that every single meeting , don't i ? i ask you that question every meeting .  "" what is vts ? "" great .  we 're about done .  some of the digit forms don't have digits . we ran out there were some blanks in there , not everybody will be reading digits . but , you 've got some . right , morgan ?  why don't you go ahead and start . and it 's just us down here at this end that have them .  whenever you 're ready . leave it on ,  and the   ",,
Bro021.G," in my lunch talk last week i said i 'd tried phase normalization and gotten garbage results using that l long term mean subtraction approach . it turned out there was a bug in my matlab code . tried it again ,  and , the results were better . i got intelligible speech back . but they still weren't as good as just subtracting the magnitude the log magnitude means . and also i 've been talking to , andreas and thilo about the , smartkom language model and about coming up with a good model for , far mike use of the smartkom system .  i 'm gonna be working on , implementing this mean subtraction approach in the far mike system for the smartkom system , and , one of the experiments we 're gonna do is , we 're gonna , train the a broadcast news net , which is because that 's what we 've been using far , and , adapt it on some other data . an andreas wants to use ,  data that resembles read speech , like these digit readings , because he feels that the smartkom system interaction is not gonna be exactly conversational . s actually i was wondering , how long does it take to train that broadcast news net ? two , three weeks .      and , actually , regarding the phase normalization did two experiments , and one is phases get added , modulo two pi , and because you only know the phase of the complex number t to a value modulo two pi . and thought at first , that , what i should do is unwrap the phase because that will undo that . but i actually got worse results doing that unwrapping using the simple phase unwrapper that 's in matlab than i did not unwrapping and that 's all i have to say .     ","in my lunch talk last week i said i 'd tried phase normalization and gotten garbage results using that l long term mean subtraction approach . it turned out there was a bug in my matlab code . and , the results were better . but they still weren't as good as just subtracting the magnitude the log magnitude means . and also i 've been talking to , andreas and thilo about the , smartkom language model and about coming up with a good model for , far mike use of the smartkom system . i 'm gonna be working on , implementing this mean subtraction approach in the far mike system for the smartkom system , and thought at first , that , what i should do is unwrap the phase but i actually got worse results doing that unwrapping using the simple phase unwrapper that 's in matlab than i did not unwrapping ",Other progress was also reported. 
Bro022.A,"and what was that , morgan ? what project ?  it was true for two years . should we just do the same deal where we go around and do , status report things ?  and when sunil gets here he can do his last   that 's a good idea . any objection ? do y  m do you want to start , morgan ? do you have anything , or ?  why don't you go ahead , barry ?  when is your , meeting ?  the quals .   soon .   is the idea you 're going to do this paper and then you pass it out to everybody ahead of time and ?  i remember now . have you d ? i was just gonna ask , do you want to say any a little bit about it , or ?  wh what you 're gonna you said you were talking about the , particular features that you were looking at , or you 're gonna use timit ?     that 's why you were interested in getting your own features into the sri files .   sounds good . you just have a few more weeks ,  it 's about a month from now ?  you want to go next , dave ? and we 'll do did you add this data to the training set , for the aurora ? or you just tested on this ? morgan was just saying that , as long as you do it in both training and testing , it shouldn't have any effect . but i was under the impression that you just tested with this data . you didn't train it also . i wonder if there could be something like , for s for the pzm data , if occasionally , somebody hits the table you could get a spike .  i 'm just wondering if there 's something about the , doing the mean normalization where , it could you to have better signal to noise ratio .    was that everything , dave ? what does it leave ? could you take what was left over and then subtract that ? all set ? do you want to go , stephane ? it didn't seem to help in the htk system . there 's also the normalization . like they do ,  i 'm not how they would do it when they 're working with the digits , but in the switchboard data , there 's , conversation side normalization for the non c zero components ,  right .    the n on the numbers you got , the two point seven , is that using the same training data that the sri system used and got one point two ? exact same training data ?  it would also be interesting to see , to do the regular aurora test ,  but use the sri system instead of htk . why not the full aurora , test ?  right .  that 's what comple     ","should we just do the same deal where we go around and do , status report things ? why don't you go ahead , barry ? you want to go next , dave ? do you want to go , stephane ? it didn't seem to help in the htk system . there 's also the normalization . i 'm not how they would do it when they 're working with the digits , but in the switchboard data , there 's , conversation side normalization for the non c zero ","Each of the group reported their most recent progress, and any results they have achieved. A typical progress report meeting for the ICSI Meeting Recorder Group at Berkeley. This then prompted discussion about the reasons behind such findings, which were for the most part not as expected. "
Bro022.A,"the work would be into getting the files in the right formats , right ?  because when you train up the aurora system , you 're , you 're also training on all the data . it 's      no something that i 've used in the past is , when just looking at the energy , is to look at the derivative . and you make your decision when the derivative is increasing for many frames . then you say that 's beginning of speech . but , i 'm trying to remember if that requires that you keep some amount of speech in a buffer . it depends on how you do it . but that 's been a useful thing .  right . right .   how about you , carmen ? is that it ?   want to go ahead , morgan ? transcript l dash two one five . ","how about you , carmen ? ","Each of the group reported their most recent progress, and any results they have achieved. "
Bro022.B,"for two years we were two months , away from being done . the , torrent chip .  we were two we were we went through it jim and i went through old emails at one point and for two years there was this thing saying , we 're two months away from being done . it was very believable schedules , too . we went through and with the schedules and we   it was very true .  we probably should for him to come before we do his .   all in favor i don't do anything . i no , i 'm involved in discussions with people about what they 're doing , but they 're since they 're here , they can talk about it themselves . i had another thought just now , which is , remember we were talking before about we were talking in our meeting about , this that some of the other that avendano did , where they were , getting rid of low energy sections ?   if you if you did a high pass filtering , as hirsch did in late eighties to reduce some of the effects of reverberation , avendano and hermansky were arguing that , perhaps one of the reasons for that working was ma may not have even been the filtering much but the fact that when you filter a an all positive power spectrum you get some negative values , and you gotta figure out what to do with them if you 're gonna continue treating this as a power spectrum . what hirsch did was , set them to zero set the negative values to zero . if you imagine a waveform that 's all positive , which is the time trajectory of energy , and , shifting it downwards , and then getting rid of the negative parts , that 's essentially throwing away the low energy things . and it 's the low energy parts of the speech where the reverberation is most audible . you have the reverberation from higher energy things showing up in in this case you have some artificially imposed reverberation like thing . you 're getting rid of some of the other effects of reverberation , but because you have these non causal windows , you 're getting these funny things coming in , at n and ,  what if you did ? there 's nothing to say that the processing for this re synthesis has to be restricted to trying to get it back to the original , according to some equation . you also could , just try to make it nicer . and one of the things you could do is , you could do some vad like thing and you actually could take very low energy sections and set them to some , very low or near zero value .  i 'm just saying if it turns out that these echoes that you 're hearing are , or pre echoes , whichever they are ",,
Bro022.B,"are , part of what 's causing the problem , you actually could get rid of them . be pretty simple . you do it in a pretty conservative way that if you made a mistake you were more likely to keep in an echo than to throw out speech . it 's this room . it 's this room .  it 's these are just microphone this micro close microphone and a distant microphone , he 's doing these different tests on . we should do a measurement in here . i g think we never have . it 's i would guess , point seven , point eight seconds f r t something like that ? but it 's it 's this room .   but the other thing is , he 's putting in w i was using the word "" reverberation "" in two ways . he 's also putting in , a he 's taking out some reverberation , but he 's putting in something , because he has averages over multiple windows stretching out to twelve seconds , which are then being subtracted from the speech . and since , what you subtract , sometimes you 'll be subtracting from some larger number and sometimes you won't . and you can end up with some components in it that are affected by things that are seconds away . and if it 's a low energy compo portion , you might actually hear some funny things . i don't think just multiplying the signal by two would have any effect .  if you really have louder signals , what is that you have better signal to noise ratio . if what you 're doing is improving the signal to noise ratio , then it would be better . but just it being bigger if with the same signal to noise ratio no .  but it 's trained and tested on the same thing . if the if you change in both training and test , the absolute level by a factor of two , it will n have no effect . i see .  i don't understand then .  no . there 's nothing inherent about removing if you 're really removing , r then i don't see how that would make it louder . it might be just some  it might just be some artifact of the processing that , if you 're  i don't know . there is this . minute . it i i if , subtracting the mean log spectrum is like dividing by the spectrum . depending what you divide by , if your if s your estimate is off and sometimes you 're you 're getting a small number , you could make it bigger . it 's just a question of there 's it could be that there 's some normalization that 's missing ,  to make it y you 'd think it shouldn't be larger , but in practice it is . that 's something to think about . ","i don't think just multiplying the signal by two would have any effect . if you really have louder signals , what is that you have better signal to noise ratio . ",
Bro022.B,"i don't know . i 'm was his point eight percent , er , a result on testing on macrophone or training ?  that was done already . we were and it 's point eight ?   that 's a lot better . what w ?   but this no . because , there 's a sample and hold in the a tod and these period these typically do have a dc offset . and they can be surprisingly large . it depends on the electronics . the microphone isn't gonna pass any dc . but , typi unless actually , there are instrumentation mikes that do pass go down to dc . but ,  no , it 's the electronics . and they and then there 's amplification afterwards . and you can get , it was it was in the wall street journal data that i can't remember , one of the darpa things . there was this big dc offset we didn't know about for a while , while we were messing with it . and we were getting these terrible results . and then we were talking to somebody and they said , "" didn't everybody knows that . there 's all this dc offset in th "" yes . you can have dc offset in the data .  see , we have a different interpretation of this . he says it doesn't work . i said , it works magnificently , but just not for the task we intended . it gets rid of the speech . it leaves it leaves the junk . it 's tremendous . you see , all he has to do is go back and reverse what he did before , and he 's really got something . ex exactly . you got it . it 's a general rule . just listen very carefully to what i say and do the opposite . including what said . it sounds like they also have he 's saying they have all these , different kinds of adaptation . they have channel adaptation . they have speaker adaptation .  it 's probably more than that . they have i thin think they use these , genone things . there 's these pooled models and they can go out to all sorts of dependencies .  they have tied states and i don't real i 'm talk i 'm just guessing here . but they don't just have triphones . they have a range of , dependencies . is that ? are these results comparable ? you were getting with the , aurora baseline something like two point four percent on clean ti digits , when , training the sri system with clean tr digits ti digits . right ? and  and , is your two point seven comparable , where you 're , using , the submitted system ?  it 's about the same , little worse . i 'm you were htk . right ?  that 's right .   ","the microphone isn't gonna pass any dc . actually , there are instrumentation mikes that do pass go down to dc . no , it 's the electronics . then there 's amplification afterwards . you can have dc offset in the data . they have channel adaptation . they have speaker adaptation . they have i thin think they use these , genone things . there 's these pooled models and they can go out to all sorts of dependencies . they have tied states ","This then prompted discussion about the reasons behind such findings, which were for the most part not as expected. "
Bro022.B,"the comparable number then , for what you were talking about then , since it was htk , would be the two point f right , right . right . right , right .  alright .  he 's doing some different things . yes .  good . they are helping . that 's good to hear .    you 'd have to train the sri system with all the different languages . it 'd be a lot of work . that 's the only thing . that 's true , but that also when we 've had these meetings week after week , oftentimes people have not done the full arrange of things because on whatever it is they 're trying , because it 's a lot of work , even just with the htk . it 's a good idea , but it seems like it makes sense to do some pruning first with a test or two that makes sense for you , and then take the likely candidates and go further . to clarify something for me . i they were supp supposedly , in the next evaluation , they 're going to be supplying us with boundaries . does any of this matter ? other than our interest in it .  do we ? is there some reason that we think that 's the case ?   but we 'll get some insight on that when , the gang gets back from crete . because there 's lots of interesting problems , and then if they really are going to have some means of giving us fairly tight , boundaries , then that won't be much the issue .  but i don't know .  right . right .  if you could get at some of that , although that 'd be hard . but  right .    cuz i would have thought that having some spectral information ,   in the old days people would use energy and zero crossings , would give you some better performance . right ? cuz you might have low energy fricatives or , stop consonants , like that .  that if you d if you use purely energy and don't look at anything spectral , then you don't have a good way of distinguishing between low energy speech components and nonspeech . and , just as a gross generalization , most nonsp many nonspeech noises have a low pass characteristic , some slope . and most , low energy speech components that are unvoiced have a high pass characteristic an upward slope . having some at the beginning of a of an s sound just starting in , it might be pretty low energy , but it will tend to have this high frequency component . whereas , a lot of rumble , and background noises , and forth will be predominantly low frequency . by itself it 's not enough to tell you , but it plus energy is it plus energy plus timing information is ","to clarify something for me . they were supp supposedly , in the next evaluation , they 're going to be supplying us with boundaries . does any of this matter ? do we ? is there some reason that we think that 's the case ? but we 'll get some insight on that when , the gang gets back from crete . ",
Bro022.B,"if you look up in rabiner and schafer from like twenty five years ago that 's what they were using then . it 's not a    one could imagine combining them in different ways . but , what you 're saying is that the mlp based one has the spectral information .  you can imagine is ? right . right . and that might not be optimal , but but in principle what you 'd want to do is have a a probability estimated by each one and put them together .     this is cubic root of power spectra ? if you have this band pass filter , you probably get n you get negative values . right ?      last week you were also talking about building up the subspace   the other thing is in i and not and c zero would be a different you could do a different normalization for c zero than for other things anyway . the other thing i was gonna suggest is that you could have two kinds of normalization with , different time constants .   you could do some normalization s before the vts , and then do some other normalization after . i don't know . but c zero certainly acts differently than the others do , that 's    you 're you 're the first one here to work with vts ,  we could call someone else up who has , ask them their opinion .  i don't have a good feeling for it .  you wouldn't even need to switch to cepstra . right ? you can just normalize the   and then you have one number which is very dependent on the level cuz it is the level , and the other which isn't .    one of the things we 've talked about it might be star time to start thinking about pretty soon , is as we look at the pros and cons of these different methods , how do they fit in with one another ? because we 've talked about potentially doing some combination of a couple of them . pretty soon we 'll have some sense of what their characteristics are , we can see what should be combined .  why don't we read some digits ?  o k . ","you 're you 're the first one here to work with vts , we could call someone else up who has , i don't have a good feeling for it . ",
Bro022.C,"   i don't see why your signal is louder after processing , because yo      the system is use the absolute energy , it 's a little bit dependent on the signal level . but , not much ,     i had a question about the system the sri system . you trained it on ti digits ? but except this , it 's exactly the same system as the one that was tested before and that was trained on macrophone . right ? on ti digits it gives you one point two percent error rate and on macrophone it 's still o point eight . but is it exactly the same system ?   you use vtl vocal tract length normalization and , like mllr transformations also , and all that it was training on macrophone and testing on meeting digits .   i 've just been text testing the new aurora front end with aurora system actually front end and htk , acoustic models on the meeting digits and it 's a little bit better than the previous system . we have i have two point seven percent error rate . and before with the system that was proposed , it 's what ? it was three point nine .  we are getting better . and  two point seven . on the meeting we have two point seven .   we have the new lda filters , and didn't look , but one thing that makes a difference is this dc offset compensation . do y did you have a look at the meet meeting digits , if they have a dc component , or ?   concerning these d still , these meeting digits . i 'm more interested in trying to figure out what 's still the difference between the sri system and the aurora system . and  will train gender dependent models , because this is also one big difference between the two systems .  the other differences were the fact that the acoustic models of the sri are more sri system are more complex . but , chuck , you did some experiments with this and it was hard t to have some exper some improvement with this .    right .  the vocal tr  this is another difference . their normalization works like on the utterance levels . but we have to do it we have a system that does it on line . it might be it might be better with it might be worse if the channel is constant , or nnn . sri it 's tr  it 's triphones .    and    the first thing i that i want to do is just these gender things .  and see with andreas if i don't know how much it helps , what 's the model . that 's right . it 's the clean ti digits training set . right .  you used the clean training set .          ye  the complete sri system is one point two .   it was four point something . right ? the htk system with , b ","i don't see why your signal is louder after processing , didn't look , but one thing that makes a difference is this dc offset compensation . do y did you have a look at the meet meeting digits , if they have a dc component , i 'm more interested in trying to figure out what 's still the difference between the sri system and the aurora system . will train gender dependent models , because this is also one big difference between the two systems . the other differences were the fact that the acoustic models of the sri are more sri system are more complex . but , chuck , you did some experiments with this this is another difference . their normalization works like on the utterance levels . ","Each of the group reported their most recent progress, and any results they have achieved. Topics the group touched upon included spectral subtraction, phase normalization, Voice activity detection, along with comparisons between systems. This then prompted discussion about the reasons behind such findings, which were for the most part not as expected. "
Bro022.C,"mfcc features    the only difference is the features , right now , between this and  they are helping .    and another thing i would like to do is to just test the sri system that 's trained on macrophone test it on , the noisy ti digits , cuz i 'm still wondering where this improvement comes from . when you train on macrophone , it seems better on meeting digits . but i wonder if it 's just because macrophone is acoustically closer to the meeting digits than ti digit is , which is ti digits are very clean recorded digits and  f s that 's that 's what i wanted , just ,  just using the sri system , test it on and test it on aurora ti digits . right .  there is this problem of multilinguality yet . we don't i we would have to train on   it 's   that 's right .   i see .  right . i see what   but , just testing on ti digits would already give us some information about what 's going on . and    the next thing is this vad problem that ,   i 'm just talking about the curves that i sent you whi that shows that when the snr decrease , the current vad approach doesn't drop much frames for some particular noises , which might be then noises that are closer to speech , acoustically .    first of all , the boundaries might be , like we would have t two hundred milliseconds or before and after speech .  removing more than that might still make a difference in the results . and no . because we don't didn't looked that much at that . but , still , it 's an interesting problem . and          and actually there 's  there 's an it 's still for even for the evaluation , it might still be interesting to work on this because the boundaries that they would provide is just , starting of speech and end of speech at the utterance level . and    but when you have like , five or six frames , both it with    it might be useful for noise estimation , and a lot of other things that we want to work on . but   did started to test putting together two vad which was not much work actually .  i im re implemented a vad that 's very close to the , energy based vad that , the other aurora guys use .  which is just putting a threshold on the noise energy , and , detect detecting the first group of four frames that have a energy that 's above this threshold , and ,  from this point , tagging the frames there as speech . it removes the first silent portion of each utterance . and it really removes it ,  still o on the noises where our mlp vad doesn't work a lot .  and   your point is will be to u use whatever          ","the next thing is this vad problem that , i 'm just talking about the curves that i sent you whi that shows that when the snr decrease , the current vad approach doesn't drop much frames for some particular noises , which might be then noises that are closer to speech , acoustically . first of all , the boundaries might be , like we would have t two hundred milliseconds or before and after speech . removing more than that might still make a difference in the results . no . ","Topics the group touched upon included spectral subtraction, phase normalization, Voice activity detection, along with comparisons between systems. "
Bro022.C,"it might be that what i did is removes like low , low energy , speech frames . because the way i do it is combine the two decisions the one from the mlp and the one from the energy based with the and operator .  i only keep the frames where the two agree that it 's speech . if the energy based dropped low energy speech , they are lost .  but s still , the way it 's done right now it helps on the noises where it seems to help on the noises where our vad was not very good .  but  but the way it 's combined wi is done  the way i use a an a "" and "" operator is it i , the frames that are dropped by the energy based system are , dropped , even if the , mlp decides to keep them . but ,   m   actually if i don't don't want to work too much of on it right now . wanted to see if it 's what i observed was the re was caused by this vad problem . and it seems to be the case .  the second thing is the this spectral subtraction .   which i 've just started yesterday to launch a bunch of , twenty five experiments , with different , values for the parameters that are used .  it 's the makhoul type spectral subtraction which use an over estimation factor . we substr i subtract more , noise than the noise spectra that is estimated on the noise portion of the s the utterances . tried several , over estimation factors . and after subtraction , i also add a constant noise , and i also try different , noise , values and we 'll see what happen .   but st still when we look at the ,  it depends on the parameters that you use , but for moderate over estimation factors and moderate noise level that you add , you st have a lot of musical noise .  on the other hand , when you subtract more and when you add more noise , you get rid of this musical noise but you distort a lot of speech .    it until now , it doesn't seem to help . but we 'll see . the next thing , what i will try to do is just to try to smooth the , to smooth the d the result of the subtraction , to get rid of the musical noise , using some filter , or  right .   to get something that 's would be closer to what you tried to do with wiener filtering . and   it you can it 's that 's it for me .  this is on speechdat car italian ? in some cases s there are also o     actually , the vts that you tested before was in the log domain and the codebook is e dependent on the level of the speech signal . and ","actually if i don't don't want to work too much of on it right now . wanted to see if it 's what i observed was the re was caused by this vad problem . the second thing is the this spectral subtraction . which i 've just started yesterday to launch a bunch of , twenty five experiments , with different , values for the parameters that are used . the next thing , what i will try to do is just to try to smooth the , to smooth the d the result of the subtraction , right . ","Topics the group touched upon included spectral subtraction, phase normalization, Voice activity detection, along with comparisons between systems. "
Bro022.C,"expect it if you have something that 's independent of this , i expect it to , be a better model of speech . and .  no . we could normali norm remove the median .   but here also we would have to be careful about removing the mean of speech and not of noise . because it 's like first doing general normalization and then noise removal , which is    ",,
Bro022.D,"i am still working with , vts . and , one of the things that last week , say here is that the problem was with the diff because the signal have different level of energy . and , talking with stephane and with sunil , we decide that it was interesting to apply on line normalization before applying vts . but then we decided that 's it doesn't work because we modified also the noise . and thinking about that , we then we decide that is a good idea . we don't know . i don't hav i don't this is i didn't do the experiment yet to apply vts in cepstral domain .  we s decide to m to obtain the new expression if we work in the cepstral domain . and i am working in that now , but i 'm not if that will be usefu useful . i don't know . it 's k it 's k it 's quite a lot it 's a lot of work . it 's not too much , but this it 's work . and i want to know if we have some feeling that the result i would like to know if i don't have any feeling if this will work better than apply vts aft in cepstral domain will work better than apply in m mel in filter bank domain . i r i 'm not i don't know nothing .  to have better  ye yea  we i was thinking to estimate the noise with the first frames and then apply the vad , before the on line normalization . we see  i am thinking about that and working about that , but i don't have result this week .  ","i am still working with , vts . and , one of the things that last week , say here is that the problem was with the diff because the signal have different level of energy . and , talking with stephane and with sunil , we decide that it was interesting to apply on line normalization before applying vts . but then we decided that 's it doesn't work because we modified also the noise . thinking about that , we then we decide that is a good idea . we don't know . i didn't do the experiment yet to apply vts in cepstral domain . we s decide to m to obtain the new expression if we work in the cepstral domain . but i 'm not if that will be usefu useful . it 's quite a lot it 's a lot of work . and i want to know if we have some feeling that the result i don't have any feeling if this will work better than apply vts aft in cepstral domain will work better than apply in m mel in filter bank domain . i don't know nothing . ","Each of the group reported their most recent progress, and any results they have achieved. "
Bro022.E,"    last week i finally got results from the sri system about this mean subtraction approach . and , we got an improvement , in word error rate , training on the ti digits data set and testing on meeting recorder digits of , six percent to four point five percent , on the n on the far mike data using pzm f , but , the near mike performance worsened , from one point two percent to two point four percent . and , wh why would that be , considering that we actually got an improvement in near mike performance using htk ? and with some input from , andreas , i have a theory in two parts .  first of all htk sr the sri system is doing channel adaptation , and htk wasn't .  this ,  this mean subtraction approach will do a channel normalization and that might have given the htk use of it a boost that wouldn't have been applied in the sri case . and also , the andreas pointed out the sri system is using more parameters . it 's got finer grained acoustic models . those finer grained acoustic models could be more sensitive to the artifacts in the re synthesized audio .  and me and barry were listening to the re synthesized audio and sometimes it seems like you get of a bit of an echo of speech in the background . and that seems like it could be difficult for training , cuz you could have different phones lined up with a different foreground phone , depending on the timing of the echo .  i 'm gonna try training on a larger data set , and then , the system will have seen more examples o of these artifacts and hopefully will be more robust to them . 'm planning to use the macrophone set of , read speech , and ,        in thi in this room ?  y i don't know . o one thing , i noticed is that , the mean subtraction seems to make the pzm signals louder after they 've been re synthesized . was wondering , is it possible that one reason it helped with the aurora baseline system is just as a gain control ? cuz some of the pzm signals sound pretty quiet if you don't amplify them . i don't know why y , either .   it w i it wouldn't affect things .    did i w what ?   i i b i right . i trained on clean ti digits . i did the mean subtraction on clean ti digits . but i didn't i 'm not if it made the clean ti digits any louder . i only remember noticing it made the , pzm signal louder .  i don't know . if it 's like , if it 's trying to find a reverberation filter , it could be that this reverberation filter is making things quieter . ","last week i finally got results from the sri system about this mean subtraction approach . and , we got an improvement , in word error rate , training on the ti digits data set and testing on meeting recorder digits of , six percent to four point five percent , on the n on the far mike data using pzm f , but , the near mike performance worsened , from one point two percent to two point four percent . wh why would that be , considering that we actually got an improvement in near mike performance using htk ? with some input from , andreas , i have a theory in two parts . first of all htk sr the sri system is doing channel adaptation , and htk wasn't . and also , the andreas pointed out the sri system is using more parameters . those finer grained acoustic models could be more sensitive to the artifacts in the re synthesized audio . o one thing , i noticed is that , the mean subtraction seems to make the pzm signals louder after they 've been re synthesized . was wondering , is it possible that one reason it helped with the aurora baseline system is just as a gain control ? cuz some of the pzm signals sound pretty quiet if you don't amplify them . ","Each of the group reported their most recent progress, and any results they have achieved. This then prompted discussion about the reasons behind such findings, which were for the most part not as expected. "
Bro022.E,"and then if you take it out that taking it out makes things louder .  nuh the mean .   i see .   should listen to that again .       if you 're talking about the macrophone results that andreas had about , a week and a half ago , it 's the same system .  that 's i i didn't . no .  and i also , did some experiments about normalizing the phase .  c i came up with a web page that people can take a look at . and , the interesting thing that i tried was , adam and morgan had this idea , since my original attempts to , take the mean of the phase spectra over time and normalize using that , by subtracting that off , didn't work . that we thought that might be due to , problems with , the arithmetic of phases . they add in this modulo two pi way and ,  there 's reason to believe that approach of taking the mean of the phase spectrum wasn't really mathematically correct . what i did instead is i took the mean of the fft spectrum without taking the log or anything , and then i took the phase of that , and i subtracted that phase off to normalize . but that , didn't work either . and , that 's everything . right . for with the sri system the aurora baseline is set up with these , this version of the clean training set that 's been filtered with this g seven one two filter , and , to train the sri system on digits s andreas used the original ti digits , under u doctor speech data ti digits , which don't have this filter . but i don't think there 's any other difference .  w it was one point two with the sri system , i d do the b ? the baseline aurora two system , trained on ti digits , tested on meeting recorder near , we saw in it today , and it was about six point six percent . ","and i also , did some experiments about normalizing the phase . the interesting thing that i tried was , adam and morgan had this idea , since my original attempts to , take the mean of the phase spectra over time and normalize using that , by subtracting that off , didn't work . that we thought that might be due to , problems with , the arithmetic of phases . what i did instead is i took the mean of the fft spectrum without taking the log or anything , and then i took the phase of that , and i subtracted that phase off but that , didn't work either . ","Each of the group reported their most recent progress, and any results they have achieved. "
Bro022.F,"  should i go that , you 're gonna talk about aurora per se ?   this past week i 've just been , getting down and dirty into writing my proposal .    finished a section on , on talking about these intermediate categories that i want to classify , as a middle step . and , i hope to get this , full rough draft done by , monday can give it to morgan . my meeting with , the quals . the quals are happening in july twenty fifth .  d day .  right , right . y you write up a proposal , and give it to people ahead of time , and you have a short presentation . and , and then , then everybody asks you questions .    y s  a little bit about ?  the right . i was ,  one of the perplexing problems is ,  for a while i was thinking that i had to come up with a complete set of intermediate features in intermediate categories to classify right away . but what i 'm thinking now is , i would start with a reasonable set . something like , like , re regular phonetic features , just to start off that way . and do some phone recognition . build a system that , classifies these , these feat these intermediate categories using , multi band techniques . combine them and do phon phoneme recognition . look at then i would look at the errors produced in the phoneme recognition and say , i could probably reduce the errors if i included this extra feature or this extra intermediate category . that would reduce certain confusions over other confusions . and then reiterate . build the intermediate classifiers . do phoneme recognition . look at the errors . and then postulate new or remove , intermediate categories . and then do it again . for that part of the process , i would use timit . and ,  then after , doing timit . right ? that 's that 's , that 's just the ph the phone recognition task . i wanted to take a look at , things that i could model within word . i would mov i would then shift the focus to , something like schw switchboard , where i 'd i would be able to , to model , intermediate categories that span across phonemes , not just within the phonemes , themselves ,  and then do the same process there , on a large vocabulary task like switchboard .  and for that for that part i would i 'd use the sri recognizer since it 's already set up for switchboard . and i 'd run some tandem style processing with , my intermediate classifiers . that 's why i was asking about that .   and that 's it . any questions ?  a few more . it 's a month and a week .    that 's with the new iir filters ?  ","this past week i 've just been , getting down and dirty into writing my proposal . finished a section on , on talking about these intermediate categories that i want to classify , as a middle step . i hope to get this , full rough draft done by , monday can give it to morgan . ","Each of the group reported their most recent progress, and any results they have achieved. "
Bro022.F,gets rid of the speech .    sri .    ,,
Bro022.G,"what is the reverberation time like there ? on , the one what the s in the speech that you are using like ? it 's , this room ?       with the htk back end ? what we have for aurora ? i know in the meeting , like right .  no . the dc component could be negligible . if you are recording it through a mike . any all of the mikes have the dc removal some capacitor sitting right in that bias it .   it is the digital  it 's the a tod that introduces the dc in .        it 's and the acoustic models are like k triphone models or is it the whole word ?  it 's triphone . it 's like the tied state .   because w we were wondering whether that vad is going to be realistic one or is it going to be some manual segmentation . and then if that vad is going to be a realistic one , then we can actually use their markers to shift the point around , the way we want to find a rather than keeping the twenty frames , we can actually move the marker to a point which we find more suitable for us . but if that is going to be something like a manual , segmenter , then we can't use that information anymore , because that 's not going to be the one that is used in the final evaluation . we don't is the type of vad which they 're going to provide . with some gap . with some pauses in the center , provided they meet that whatever the hang over time which they are talking .  then the they will just fill it up . th   every everywhere has a delay associated with it . you still have to k always keep a buffer , then only make a decision because you still need to smooth the decision further . that 's always there . can smooth the snr estimate , also . your filter is a function of snr .  actually , it 's ,   i don't know , it 's go ahead . and it 's go ahead .   u th i 've been playing with this wiener filter , like . and there are there were some bugs in the program , was p initially trying to clear them up . because one of the bug was i was assuming that always the vad the initial frames were silence . it always started in the silence state , but it wasn't for some utterances . the it wasn't estimating the noise initially , and then it never estimated , because i assumed that it was always silence .  speechdat car italian .  there 're a few cases , actually , which i found later , that there are . that was one of the bugs that was there in estimating the noise . ","no . the dc component could be negligible . any all of the mikes have the dc removal some capacitor sitting right in that bias it . and the acoustic models are like k triphone models or is it the whole word ? can smooth the snr estimate , also . your filter is a function of snr . th i 've been playing with this wiener filter , like . and there are there were some bugs in the program , was p initially trying to clear them up . ","Each of the group reported their most recent progress, and any results they have achieved. "
Bro022.G,"and , once it was cleared , i ran a few experiments with different ways of smoothing the estimated clean speech and how t estimated the noise and , smoothing the snr also . and the trend seems to be like , smoothing the current estimate of the clean speech for deriving the snr , which is like deriving the wiener filter , seems to be helping . then updating it quite fast using a very small time constant . we 'll have few results where the estimating the the more smoothing is helping . but still it 's like it 's still comparable to the baseline . i haven't got anything beyond the baseline . but that 's not using any wiener filter . and , 'm trying a few more experiments with different time constants for smoothing the noise spectrum , and smoothing the clean speech , and smoothing snr . there are three time constants that i have . i 'm just playing around . one is fixed in the line , like smoothing the clean speech is helping , 'm not going to change it that much . but , the way i 'm estimating the noise and the way i 'm estimating the snr , i 'm just trying a little bit . that h and the other thing is putting a floor on the , snr , because that if some in some cases the clean speech is , like when it 's estimated , it goes to very low values , the snr is very low . and that actually creates a lot of variance in the low energy region of the speech . i 'm thinking of putting a floor also for the snr that it doesn't vary a lot in the low energy regions . and , the results are , like far i 've been testing only with the baseline , which is which doesn't have any lda filtering and on line normalization . want to separate the contributions out . it 's just vad , plus the wiener filter , plus the baseline system , which is , just the spectral the mel sp mel , frequency coefficients .  and the other thing that i tried was but took of those , carlos filters , which hynek had , to see whether it really h helps or not . it was just a run to see whether it really degrades or it helps . and it 's it seems to be like it 's not hurting a lot by just blindly picking up one filter which is nothing but a four hertz a band pass m filter on the cubic root of the power spectrum . that was the filter that hy carlos had . and  just to see whether it really it 's is it worth trying or not . it doesn't seems to be degrading a lot on that . there must be something that that can be done with that type of noise compensation also , ","and , once it was cleared , i ran a few experiments with different ways of smoothing the estimated clean speech and how t estimated the noise and , smoothing the snr also . and the trend seems to be like , smoothing the current estimate of the clean speech for deriving the snr , which is like deriving the wiener filter , seems to be helping . then updating it quite fast but still it 's like it 's still comparable to the baseline . but that 's not using any wiener filter . and the other thing is putting a floor on the , snr , some in some cases the clean speech is , like when it 's estimated , it goes to very low values , the snr is very low . that actually creates a lot of variance in the low energy region of the speech . far i 've been testing only with the baseline , which is which doesn't have any lda filtering and on line normalization . want to separate the contributions out . it 's just vad , plus the wiener filter , plus the baseline system , which is , just the spectral the mel sp mel , frequency coefficients . ",
Bro022.G,"which would ask carlos about that . how he derived those filters and and where d if he has any filters which are derived on ogi stories , added with some type of noise which what we are using currently , like that . 'll  cubic root of power spectrum .  and i 'm floating it to z zeros right now . it has , like the spectrogram has , like  it actually , enhances the onset and offset of the begin and the end of the speech . it 's there seems to be deep valleys in the begin and the end of high energy regions , because the filter has mexican hat type structure . those are the regions where there are , like when i look at the spectrogram , there are those deep valleys on the begin and the end of the speech . but the rest of it seems to be pretty  that 's something i observe using that filter . and  there are a few very not a lot of because the filter doesn't have a really a deep negative portion , that it 's not really creating a lot of negative values in the cubic root .  i 'll s may continue with that for some w i 'll 'll ask carlos a little more about how to play with those filters , and but while making this wiener filter better .   that 's it , morgan .  i would actually m didn't get enough time to work on the subspace last week . it was mostly about finding those bugs and th things , and i didn't work much on that . pratibha . ",,
Bro028.A,"we should be going . couldn't you t couldn't you , test the human performance on just the original audio ?  i see . y your performance was one percent , and then when you re synthesize with lpc twelve it went to five .  but but from this it 's pretty safe to say that the system is with either two to seven percent away from the performance of a human . right ? it 's somewhere in that range . two to six percent . in the lpc synthesis ?  've , downloaded , a couple of things from mississippi state . one is their software their , lvcsr system . downloaded the latest version of that . got it compiled and everything . downloaded the scripts . they wrote some scripts that make it easy to run the system on the wall street journal , data . haven't run the scripts yet . i 'm waiting there was one problem with part of it and i wrote a note to joe asking him about it . 'm waiting to hear from him . but , i did print something out just to give you an idea about where the system is . they on their web site they , did this little table of where their system performs relative to other systems that have done this task . and , the mississippi state system using a bigram grammar , is at about eight point two percent . other comparable systems from , were getting from , like six point nine , six point eight percent . they 're this is on clean they 've started a table where they 're showing their results on various different noise conditions but they don't have a whole lot of it filled in and i didn't notice until after i 'd printed it out that , they don't say here what these different testing conditions are . you actually have to click on it on the web site to see them . don't those numbers really mean . see , i was a little confused because on this table , i 'm the they 're showing word error rate . but on this one , i don't know if these are word error rates because they 're really big . under condition one here it 's ten percent . then under three it goes to sixty four point six percent .  they 're error rates but they 're , they 're really high .  correct ? accuracy ? on digits .     is it ?  that 's probably what it is then . they have a lot of different conditions that they 're gonna be filling out .  it 's gonna be hard .  they 're i 'm still waiting for them to release the , multi cpu version of their scripts , cuz right now their script only handles processing on a single cpu , which will take a really long time to run .  but their s beli ","'ve , downloaded , a couple of things from mississippi state . they wrote some scripts that make it easy to run the system on the wall street journal , data . haven't run the scripts yet . i 'm waiting there was one problem with part of it and i wrote a note to joe asking him about it . 'm waiting to hear from him . they 're i 'm still waiting for them to release the , multi cpu version of their scripts , cuz right now their script only handles processing on a single cpu , which will take a really long time to run . ","On the larger vocabulary task, there are still a few issues to resolve before work can really get started. "
Bro028.A,"yes , for the training also . and , they 're supposed to be coming out with it any time , the multi cpu one . as soon as they get that , then i 'll grab those too and  i 'll go ahead and try to run it though with just the single cpu one , and i they , released like a smaller data set that you can use that only takes like sixteen hours to train and can run it on that just to make that the thing works and everything . it wasn't on the conference call this morning ?  did they say anything on the conference call about , how the wall street journal part of the test was going to be run ? because remembered hearing that some sites were saying that they didn't have the compute to be able to run the wall street journal at their place , there was some talk about having mississippi state run the systems for them . and i did that come up   the only , mail i get is from mississippi state  about their system . i don't get any mail about  it does . i 'm wondering about that because there 's this whole issue about , simple tuning parameters , like word insertion penalties . and whether or not those are going to be tuned or not , and it makes a big difference . if you change your front end , the scale is completely can be completely different ,  it seems reasonable that at least should be tweaked to match the front end . but i did , but joe said , "" what you 're saying makes sense and i don't know "" . he doesn't the answer is . that 's th we had this back and forth a little bit about , are sites gonna are you gonna run this data for different sites ? and , if mississippi state runs it , then they 'll do a little optimization on that parameter , and , but then he wasn't asked to run it for anybody . it 's just not clear yet what 's gonna happen . he 's been putting this out on their web site and for people to grab but i haven't heard too much about what 's happening . i wonder if it might be possible to , simulate the back end with some other system . we get our f front end features , and then ,  as part of the process of figuring out the scaling of these features , if we 're gonna take it to a root or to a power we have some back end that we attach onto our features that simulates what would be happening .  and just adjust it until that our l version of the back end , decides that  that 's true . and then we just use that to determine some scaling factor that we use .    ","as soon as they get that , then i 'll grab those too i 'll go ahead and try to run it though with just the single cpu one , and i they , released like a smaller data set that you can use that only takes like sixteen hours to train and can run it on that just to make that the thing works and everything . ","On the larger vocabulary task, there are still a few issues to resolve before work can really get started. "
Bro028.A,"w what do when you say "" what kind "" ?  gaussian mixture model . it 's the same system that they use when they participate in the hub five evals . it 's a , came out of , looking a lot like htk . they started off with when they were building their system they were always comparing to htk to make they were getting similar results . and it 's a gaussian mixture system ,  i don't know . and then divide the mixtures in half . i don't know if they do that . i 'm not really th i have i don't have it up here but i have a the whole system description , that describes exactly what their system is and i 'm not but , it 's some mixture of gaussians and , clustering and , they 're trying to put in all of the standard features that people use nowadays .   is this a histogram across different frequency bins ? or ? one histogram per frequency bin . and that 's th   and that , histogram represents the different energy levels that have been seen at that frequency ?  they , is the idea that you run a test utterance through some histogram generation thing and then you compare the histograms and that tells you what to do to the utterance to make it more like ? i see .      h what does he do to choose those ?  it 's a it 's a little bit like a genetic algorithm in a way . greedy .  that 's ri  ",,
Bro028.B,"ne next week we 'll have , both birger and , mike michael michael kleinschmidt and birger kollmeier will join us .  and you 're probably gonna go up in a couple three weeks or when d when are you thinking of going up to , ogi ?  good . at least we 'll have one meeting with yo with you still around , and that 's good . all today ,  no , this i 'm this is a conference call between different aurora people or just ? it 's the main conference call .  and what are we sitting at currently ?  two thirty . it 's we have to reduce it by ten milliseconds somehow .  w it 's p d primary primarily determined by the vad at this point , right ? s we can make the vad a little shorter . that 's we probably should do that pretty soon that we don't get used to it being a certain way .  was hari on the phone ?     but th the two th two thirty includes the tandem network ?  and i is the tandem network , small enough that it will fit on the terminal size in terms of ? no .    right . ho how much memory d ? h how many ? i 'd like to see that , cuz could think a little bit about it , cuz we we could make it a little smaller or it 'd be neat if we could fit it all . i 'd like to see how far off we are . but it 's still within their rules to have it on the , t server side . right ?  and this is still ? y you 're saying here . i c i should just let you go on .  could ? i 'm really can you repeat what you were saying about the silence probability ? i only my mind was some   right .  the vad network is ?  but  we don't ?     in a way what it might i it 's a little bit like combining knowledge sources . right ? because the fact that you have these two nets that are different sizes means they behave a little differently , they find different things . and , if you have , the distribution that you have from , f speech sounds is w one source of knowledge . and this is and rather than just taking one minus that to get the other , which is essentially what 's happening , you have this other source of knowledge that you 're putting in there . you make use of both of them in what you 're ending up with . it 's better . anyway , you can probably justify anything if what 's use    that might be the key , actually . cuz you were really thinking about speech versus nonspeech for that . that 's a good point .  back on the second stream , ","we have to reduce it by ten milliseconds somehow . w it 's p d primary primarily determined by the vad at this point , s we can make the vad a little shorter . we probably should do that pretty soon that we don't get used to it being a certain way . but th the two th two thirty includes the tandem network ? and i is the tandem network , small enough that it will fit on the terminal size ho how much memory d ? h how many ? i 'd like to see that , cuz could think a little bit about it , cuz we we could make it a little smaller i 'd like to see how far off we are . but it 's still within their rules to have it on the , t server side . ","The latency limit has been set, and the group's system is performing very well, but is a little over. "
Bro028.B,"that 's something we 've talked about for a while . that 's certainly a high hope .  we have this default idea about just using some purely spectral thing ? for a second stream ? but , how was the stream combined ? right . if you just had a second stream that was just spectral and had another neural net and combined there , that , might be good . right . you just put in some other noise , something that 's different . it 's probably helpful to have a little noise there . but it may be something else th at least you could say it was . and then if it doesn't hurt too much , though . that 's a good idea . this is a particular human . this is this i this is stephane .      it 's there 's two problems there . mean , the first is that by doing lpc twelve with synthesized speech w like you 're saying , it 's i you 're adding other degradation . right ? it 's not just the noise but you 're adding some degradation because it 's only an approximation .  and the second thing is which is m more interesting is that , if you do it with whispered speech , you get this number . what if you had done analysis re synthesis and taken the pitch as alright ? now you put the pitch in . what would the percentage be then ? see , that 's the question . you see , if it 's if it 's , let 's say it 's back down to one percent again . that would say at least for people , having the pitch is really , really important , which would be interesting in itself .  if i on the other hand , if it stayed up near five percent , then i 'd say "" boy , lpc n twelve is pretty crummy "" .  'm not 'm not how we can conclude from this anything about that our system is close to the human performance . you 're not doing the lpc what if you did a what if you did lpc twenty ? twenty . right ? th lpc is not a really great representation of speech . all i 'm saying is that you have in addition to the w the , removal of pitch , you also are doing , a particular parameterization , which ,  let 's see , how would you do ? fo no . actually , we d we don't , because we do , mel filter bank , right ? i don't mel , based synthesis would sound like , but certainly the spectra are quite different . it 's one percent . he 's trying to remove the pitch information and make it closer to what we 're seeing as the feature vectors . we were j it 's a little bit still apples and oranges ","this is a particular human . this is this i this is stephane . there 's two problems there . mean , the first is that by doing lpc twelve with synthesized speech w like you 're saying , it 's i you 're adding other degradation . it 's not just the noise but you 're adding some degradation because it 's only an approximation . and the second thing is which is m more interesting is that , if you do it with whispered speech , you get this number . what if you had done analysis re synthesis and taken the pitch as now you put the pitch in . what would the percentage be then ? see , that 's the question . that would say at least for people , having the pitch is really , really important , th lpc is not a really great representation of speech . ",
Bro028.B,"because we are choosing these features in order to be the best for recognition . and , i if you listen to them they still might not be very even if you made something closer to what we 're gonna i it might not sound very good . and i the degradation from that might actually make it even harder , to understand than the lpc twelve . all i 'm saying is that the lpc twelve puts in synthesis puts in some degradation that 's not what we 're used to hearing , and is , it 's not just a question of how much information is there , as if you will always take maximum advantage of any information that 's presented to you . you hear some things better than others . and it isn't but , i agree that it says that , the information that we 're feeding it is probably , a little bit , minimal . there 's definitely some things that we 've thrown away . and that 's why i was saying it might be interesting if you an interesting test of this would be if you actually put the pitch back in . you just extract it from the actual speech and put it back in , and see does that is that does that make the difference ? if that takes it down to one percent again , then you 'd say "" it 's having , not just the spectral envelope but also the pitch that , @ @ has the information that people can use , anyway . "" or it 's  it 's one point four times , to , seven times the error , for stephane .  but i don't know . i do don't wanna take you away from other things . but that 's what that 's the first thing that i would be curious about , is , i when you we  you did lpc re synthesis l pc re synthesis . and you did it with a noise source , rather than with a s periodic source . right ? if you actually did real re synthesis like you do in an lpc synthesizer , where it 's unvoiced you use noise , where it 's voiced you use , periodic pulses . right ? it might be hard to do it but it but that if you if you detect that there 's periodic s strong periodic components , then you can use a voiced voice thing . it 's probably not worth your time . it 's a side thing and there 's a lot to do . but i 'm just saying , at least as a thought experiment , that 's what i would wanna test . i wan would wanna drive it with a two source system rather than a one source system . and then that would tell you whether it 's ",but i don't know . i do don't wanna take you away from other things . it 's probably not worth your time . it 's a side thing and there 's a lot to do . ,
Bro028.B,"cuz we 've talked about this harmonic tunneling or other things that people have done based on pitch , that 's really a key element . without that , it 's not possible to do a whole lot better than we 're doing . that could be .  but , other than that , i don't think it 's other than the pitch de information , it 's hard to imagine that there 's a whole lot more in the signal that , that we 're throwing away that 's important . right ? we 're using a fair number of filters in the filter bank and   that look  that 's one percent is what i would figure . if somebody was paying really close attention , you might get i would actually think that if , you looked at people on various times of the day and different amounts of attention , you might actually get up to three or four percent error on digits .  it 's we 're not incredibly far off . on the other hand , with any of these numbers except the one percent , it 's st it 's not actually usable in a commercial system with a full telephone number  right . good . while we 're still on aurora you can talk a little about the status with the , wall street journal things for it . this is on clean test set ? what numbers are they getting on these on the test conditions ? that 's probably aurora .  i don't find that surpri we w what 's some of the lower error rates on some of the higher error rates on , some of these w highly mismatched difficult conditions ? what 's a ?  twenty percent error rate on digits . if you 're doing if you 're doing ,  sixty thousand  and if you 're saying sixty thousand word recognition , getting sixty percent error on some of these noise condition not surprising .  it 's a bad sign when you looking at the numbers , you can't tell whether it 's accuracy or error rate . this is for the training ?   cuz we have to get started , cuz it 's cuz , if the good .  cuz we 'll the actual evaluation will be in six weeks  is that about right you think ? really , we don't know ?  some i have to say , there 's something funny sounding about saying that one of these big companies doesn't have enough cup compute power do that , they 're having to have it done by mississippi state . it just sounds funny . but , anyway . it could be chuck and i had actually talked about this a couple times , and over some lunches , that , one thing that we might wanna do the there 's this question about , what do you wanna scale ? suppose y you can't adjust these word insertion penalties and forth , ","while we 're still on aurora you can talk a little about the status with the , wall street journal things for it . cuz we have to get started , it could be chuck and i had actually talked about this a couple times , and over some lunches , that , one thing that we might wanna do the there 's this question about , what do you wanna scale ? suppose y you can't adjust these word insertion penalties and forth , ","On the larger vocabulary task, there are still a few issues to resolve before work can really get started. "
Bro028.B,"you have to do everything at the level of the features . what could you do ? and , one thing i had suggested at an earlier time was some scaling , some root of the , features . but the problem with that is that isn't quite the same , it occurred to me later , because what you really want to do is scale the , @ @ the range of the likelihoods rather than but , what might get at something similar , it just occurred to me , is an intermediate thing is because we do this strange thing that we do with the tandem system , at least in that system what you could do is take the , values that come out of the net , which are something like log probabilities , and scale those . and then , then at least those things would have the right values or the right range . and then that goes into the rest of it and then that 's used as observations . it 's , another way to do it . i know they 're not . i know they 're not . but ,  because what we 're doing is pretty strange and complicated , we don't really the effect is at the other end . my thought was they 're not used as probabilities , but the log probabilities we 're taking advantage of the fact that something like log probabilities has more of a gaussian shape than gaus than probabilities , and we can model them better . in a way we 're taking advantage of the fact that they 're probabilities , because they 're this quantity that looks gaussian when you take it 's log . it would have a reasonable effect to do that . i d i don't know . but , we still haven't had a ruling back on this . and we may end up being in a situation where we just really can't change the word insertion penalty . but the other thing we could do is also we could this may not help us , in the evaluation but it might help us in our understanding at least . we might , just run it with different insper insertion penalties , and show that , "" not changing it , playing the rules the way you wanted , we did this . but if we did that , it made a big difference . ""  and just adjust it until it 's the best number ? we can probably use the real thing , can't we ? and then jus just , use it on a reduced test set  mean , that 's a reasonable thing to do and the only question is what 's the actual knob that we use ? and the knob that we use should unfortunately , like i say , i don't know the analytic solution to this ","you have to do everything at the level of the features . and , one thing i had suggested at an earlier time was some scaling , some root of the , features . it occurred to me later , because what you really want to do is scale the , @ @ the range of the likelihoods rather than but , we still haven't had a ruling back on this . and we may end up being in a situation where we just really can't change the word insertion penalty . but the other thing we could do is also we could this may not help us , in the evaluation but it might help us in our understanding at least . we might , just run it with different insper insertion penalties , and show that , "" not changing it , playing the rules the way you wanted , we did this . but if we did that , it made a big difference . "" ","On the larger vocabulary task, there are still a few issues to resolve before work can really get started. "
Bro028.B,"cuz what we really want to do is change the scale of the likelihoods , not the cha not the scale of the observations . but , do they have the same mix down procedure , where they start off with a small number of some things and ?   d do what tying they use ? are they some bunch of gaussians that they share across everything ? or if it 's ?   the other , aurora thing is if any of this is gonna come in time to be relevant , but , we had talked about , guenter playing around , over in germany and , @ @ possibly coming up with something that would , fit in later . i saw that other mail where he said that he it wasn't going to work for him to do cvs . he just has it all sitting there .  if he 'll he might work on improving the noise estimate or on some histogram things , or saw the eurospeech we didn't talk about it at our meeting but saw the just read the paper . someone , i forget the name , and ney , about histogram equalization ? did you see that one ? read the paper . i didn't see the poster . but it 's a little more it 's a little finer , right ? they had like ten quantiles and they adjust the distribution . you have the distributions from the training set , and then , this is just a histogram of the amplitudes , right ? and then people do this in image processing some . you have this histogram of levels of brightness or whatever . and then , when you get a new thing that you want to adjust to be better in some way , you adjust it that the histogram of the new data looks like the old data . you do this piece wise linear or , some piece wise approximation . they did a one version that was piece wise linear and another that had a power law thing between them between the points . and , they said they s they see it in a way as s for the speech case as being generalization of spectral subtraction in a way , because , in spectral subtraction you 're trying to get rid of this excess energy . it 's not supposed to be there . and , this is adjusting it for a lot of different levels . and then they have s they have some a floor if it gets too low you don't do it . and they claimed very results , and this i i don't remember that . do you remember ? one one per critical  and i don't remember whether it was filter bank things or whether it was fft bins or i don't remember that . and how often they you 've seen them . and they do they said that they could do it for the test ",,
Bro028.B,"you don't have to change the training . you just do a measurement over the training . and then , for testing , you can do it for one per utterance . even relatively short utterances . and they claim it works pretty in pri  in principle . i didn't read carefully how they actually implemented it , whether it was some , on line thing , or whether it was a second pass , or what . but they that was the idea . that seemed , different . we 're curious about , what are some things that are , u @ @ conceptually quite different from what we 've done . cuz we one thing that w that , stephane and sunil seemed to find , was , they could actually make a unified piece of software that handled a range of different things that people were talking about , and it was really just setting of different constants . and it would turn , one thing into another . it 'd turn wiener filtering into spectral subtraction , or whatever . but there 's other things that we 're not doing . we 're not making any use of pitch , which again , might be important , because the between the harmonics is probably a schmutz . and the , transcribers will have fun with that . and , the , at the harmonics isn't much . and , and we there 's this overall idea of really matching the hi distributions somehow . not just ,  not just subtracting off your estimate of the noise .  guess , guenter 's gonna play around with some of these things now over this next period , or ?  he 's got it anyway , he can . potentially if he came up with something that was useful , like a diff a better noise estimation module he could ship it to you guys u up there and we could put it in .    that 's good . why don't we just , starting a w couple weeks from now , especially if you 're not gonna be around for a while , we 'll be shifting more over to some other territory . but , n not much in this meeting about aurora , but , just , quickly today about you could just say a little bit about what you 've been talking about with michael . and and then barry can say something about what we 're talking about . y gets thrown out .   it 's actuall it 's much simpler . but it 's it 's there 's a lot number of things i like about it , let me just say . first thing , you 're right . i in truth , both pieces of this are have their analogies in we already do . but it 's a different take at how to approach it and potentially one that 's m bit more systematic than what we 've done , ",,
Bro028.B,"and a b a bit more inspiration from auditory things . it 's think it 's a neat thing to try . the primary features , are essentially , it 's it 's , plp or mel cepstrum , like that . you 've got some , compression . we always have some compression . we always have some the filter bank with a quasi log scaling . if you put in if you also include the rasta in it i rasta the filtering being done in the log domain has an agc like , characteristic , which , people typi typically put in these auditory front ends . it 's very , very similar , but it 's not exactly the same .  i would agree that the second one is somewhat more different but , it 's mainly different in that the things that we have been doing like that have been had a different motivation and have ended up with different kinds of constraints . if you look at the lda rasta what they do is they look at the different eigenvectors out of the lda and they form filters out of it . right ? and those filters have different , kinds of temporal extents and temporal characteristics . and they 're multi scale . but , they 're not systematically multi scale , like "" let 's start here and go to there , and go to there "" , and forth . it 's more like , you run it on this , you do discriminant analysis , and you find out what 's helpful . they use several of them .  you don't have to but but , hynek has .  but it 's also , hyn when hynek 's had people do this lda analysis , they 've done it on frequency direction and they 've done it on the time direction . he may have had people sometimes doing it on both simultaneously some two d and that would be the closest to these gabor function things . but i don't think they 've done that much of that . and , the other thing that 's interesting the , the feature selection thing , it 's a simple method , but i kinda like it . there 's a old , old method for feature selection . i remember people referring to it as old when i was playing with it twenty years ago , know it 's pretty old , called stepwise linear discriminant analysis in which you which it 's used in social sciences a lot . you pick the best feature . and then you take y you find the next feature that 's the best in combination with it . and then on and on . and what michael 's describing seems to me much , much better , because the problem with the stepwise discriminant analysis is that you don't know that if you 've picked the right set of features . ",,
Bro028.B,"just because something 's a good feature doesn't mean that you should be adding it .  here at least you 're starting off with all of them , and you 're throwing out useless features . that 's that seems , that seems like a lot better idea . you 're always looking at things in combination with other features .  the only thing is , there 's this artificial question of , exactly how you a how you assess it and if your order had been different in throwing them out . it still isn't necessarily really optimal , but it seems like a pretty good heuristic . th it 's it 's kinda neat and and , the thing that i wanted to add to it also was to have us use this in a multi stream way .  that , when you come up with these different things , and these different functions , you don't necessarily just put them all into one huge vector , but perhaps you have some of them in one stream and some of them in another stream , and forth . and , and we 've also talked a little bit about , shihab shamma 's in which you the way you look at it is that there 's these different mappings and some of them emphasize , upward moving , energy and fre and frequency . and some are emphasizing downward and fast things and slow things and forth .  there 's a bunch of to look at . but , we 're sorta gonna start off with what he , came here with and branch out from there . and his advisor is here , too , at the same time .  he 'll be another interesting source of wisdom .     or the or features . right ? y actually , you make me think a very important point here is that , if we a again try to look at how is this different from what we 're already doing , there 's a , nasty argument that could be made th that it 's not different because , if you ignore the selection part because we are going into a very powerful , nonlinearity that , is combining over time and frequency , and is coming up with its own better than gabor functions its , neural net functions , its whatever it finds to be best . you could argue that it but i don't actually believe that argument because i know that , you can , computing features is useful , even though in principle you haven't added anything you subtracted something , from the original waveform if you 've processed it in some way you 've typically lost something some information . and you 've lost information and yet it does better with features than it does with the waveform .  i know that i sometimes it 's useful to constrain things . ","th it 's it 's kinda neat the thing that i wanted to add to it also was to have us use this in a multi stream way . that , when you come up with these different things , and these different functions , you don't necessarily just put them all into one huge vector , but perhaps you have some of them in one stream and some of them in another stream , and forth . ","The group heard of the plan of one of it's member's work into intermediate classifiers, and also of how a visiting research student's work into auditory models can be applied to their work. "
Bro028.B,"that 's why it really seems like the constraint in all this it 's the constraints that are actually what matters . because if it wasn't the constraints that mattered , then we would 've completely solved this problem long ago , because long ago we already knew how to put waveforms into powerful statistical mechanisms .    then it would work . i agree . there 's the problem . then it would work . but , i it 's with finite of those things we have done experiments where we literally have put waveforms in and and , we kept the number of parameters the same and forth , and it used a lot of training data . and it and it , not infinite but a lot , and then compared to the number parameters and it , it just doesn't do nearly as anyway that you want to suppress it 's not just having the maximum information , you want to suppress , the aspects of the input signal that are not helpful for the discrimination you 're trying to make .  just briefly ,  be before you get on the next part l let me just point out that s there 's a pretty relationship between what you 're talking about doing and what you 're talking about doing there . right ? it seems to me that , if you take away the difference of this primary features , and , say , you use as we had talked about doing you use p rasta plp for the primary features , then this feature discovery , thing is just what he 's talking about doing , too , except that he 's talking about doing them in order to discover intermediate categories that correspond to these what these sub features are showing you . and , the other difference is that , he 's doing this in a multi band setting , which means that he 's constraining himself to look across time in some f relatively limited , spectral extent . right ? and whereas in this case you 're saying "" let 's just do it unconstrained "" . they 're really pretty related and they 'll be at some point where we 'll see the connections a little better and connect them .  should we do our digits and get ou get our treats ? it 's like , the little rats with the little thing dropping down to them . we do the digits and then we get our treats .  ",,
Bro028.C," michael kleinschmidt , who 's a phd student from germany , showed up this week . he 'll be here for about six months . and he 's done some work using an auditory model of , human hearing , and using that f to generate speech recognition features . and he did work back in germany with , a toy recognition system using , isolated digit recognition as the task . it was actually just a single layer neural network that classified words classified digits , and he tried that on on some aurora data and got results that he thought seemed respectable . and he w he 's coming here to u use it on a a real speech recognition system . 'll be working with him on that . and , should say a little more about these features , although i don't understand them that the it 's a two stage idea . and , the first stage of these features correspond to what 's called the peripheral auditory system . and that is like a filter bank with a compressive nonlinearity . and i 'm i 'm not what we have @ @ in there that isn't already modeled in something like , plp . i should learn more about that . and then the second stage is , the most different thing , from what we usually do . it 's , it computes features which are , based on like based on diffe different w wavelet basis functions used to analyze the input . th he uses analysis functions called gabor functions , which have a certain extent , in time and in frequency . and the idea is these are used to sample , the signal in a represented as a time frequency representation . you 're sampling some piece of this time frequency plane . and , that , is interesting , cuz , @ @ for one thing , you could use it , in a multi scale way . you could have these instead of having everything like we use a twenty five millisecond or analysis window , typically , and that 's our time scale for features , but you could using this , basis function idea , you could have some basis functions which have a lot longer time scale and , some which have a lot shorter , and it would be like a set of multi scale features . he 's interested in , th this is because it 's , there are these different parameters for the shape of these basis functions , there are a lot of different possible basis functions . and he actually does an optimization procedure to choose an optimal set of basis functions out of all the possible ones . the method he uses is funny is , he starts with he has a set of m of them .  he and then he uses that to classify he t he tries , using just m minus one of them . ","michael kleinschmidt , who 's a phd student from germany , showed up this week . he 'll be here for about six months . and he 's done some work using an auditory model of , human hearing , and using that f to generate speech recognition features . and he did work back in germany with , a toy recognition system using , isolated digit recognition as the task . he w he 's coming here to u use it on a a real speech recognition system . th this is because it 's , there are these different parameters for the shape of these basis functions , there are a lot of different possible basis functions . and he actually does an optimization procedure to choose an optimal set of basis functions out of all the possible ones . is , he starts with he has a set of m of them . he t he tries , using just m minus one of them . ","The group heard of the plan of one of it's member's work into intermediate classifiers, and also of how a visiting research student's work into auditory models can be applied to their work. "
Bro028.C,"there are m possible subsets of this length m vector . he tries classifying , using each of the m possible sub vectors . whichever sub vector , works the best , he says the fe feature that didn't use was the most useless feature , we 'll throw it out and we 're gonna randomly select another feature from the set of possible basis functions . i it 's multi scale because you use several of these in parallel , is that right ? of    ","there are m possible subsets of this length m vector . he tries classifying , using each of the m possible sub vectors . whichever sub vector , works the best , he says the fe feature that didn't use was the most useless feature , we 'll throw it out and we 're gonna randomly select another feature from the set of possible basis functions . ","The group heard of the plan of one of it's member's work into intermediate classifiers, and also of how a visiting research student's work into auditory models can be applied to their work. "
Bro028.D," not next week but the week after .   we can start with this .    there was this conference call this morning ,  and the only topic on the agenda was just to discuss a and to come at to get a decision about this latency problem . it 's the conference call between the aurora , group . there were like two hours of discussions , and then suddenly , people were tired , and they decided on a number , two hundred and twenty ,  included e including everything . it means that it 's like eighty milliseconds less than before .  currently d we have system that has two hundred and thirty . that 's fine .  that 's the system that 's described on the second point of this document . but that 's  that 's not a problem ,   at this point ,      it was mainly a discussion between hari and david , who was like   the second thing is the system that we have currently . yes . we have system that gives sixty two percent improvement , but if you want to stick to the this latency it has a latency of two thirty , but if you want also to stick to the number of features that limit it to sixty , then we go a little bit down but it 's still sixty one percent . and if we drop the tandem network , then we have fifty seven percent .  no , i don't think no . it 's still in terms of computation , if we use their way of computing the maps the mips , it fits , but it 's , m mainly a problem of memory .  and i don't know how much this can be discussed or not , because it 's it could be in rom , it 's not that expensive . but i d i don't kn remember exactly , but i c i have to check that .     there were small tricks to make this tandem network work .  and one of the trick was to , use some hierarchical structure where the silence probability is not computed by the final tandem network but by the vad network .  it looks better when , we use the silence probability from the vad network and we re scale the other probabilities by one minus the silence probability .  it 's some hierarchical thing , that sunil also tried , on spine and it helps a little bit also .  and . the reason w why we did that with the silence probability was that ,   there is the tandem network that e estimates the phone probabilities and the silence probabilities also . and things get better when , instead of using the silence probability computed by the tandem network , we use the silence probability , given by the vad network ,  which is smaller , but  we have a network for the vad which has one hundred hidden units , ","there was this conference call this morning , and the only topic on the agenda was just to discuss a and to come at to get a decision about this latency problem . there were like two hours of discussions , and then suddenly , people were tired , and they decided on a number , two hundred and twenty , included e including everything . currently d we have system that has two hundred and thirty . that 's not a problem , the second thing is the system that we have currently . yes . we have system that gives sixty two percent improvement , but if you want to stick to the this latency it has a latency of two thirty , but if you want also to stick to the number of features that limit it to sixty , then we go a little bit down but it 's still sixty one percent . and if we drop the tandem network , then we have fifty seven percent . no , i don't think it 's still in terms of computation , if we use their way of computing the maps the mips , it fits , but it 's , m mainly a problem of memory . and i don't know how much this can be discussed or not , because it 's it could be in rom , it 's not that expensive . i d i don't kn remember exactly , there were small tricks to make this tandem network work . and one of the trick was to , use some hierarchical structure where the silence probability is not computed by the final tandem network but by the vad network . it looks better when , we use the silence probability from the vad network ","On the Aurora Project, there were reports on a project conference call, the status of the tandem neural networks, and progress with the Mississippi State recognizer. The latency limit has been set, and the group's system is performing very well, but is a little over. "
Bro028.D,"and the tandem network has five hundred .  it 's smaller but th the silence probability from this network seems , better .   it looks strange , but but it it 's has something to do to the fact that we don't have infinite training data and  and things are not optimal and  there was a p problem that we observed , that there was there were many insertions in the system .  actually plugging in the tandem network was increasing , the number of insertions . and , it looked strange and then just using the other silence probability helps .   the next thing we will do is train this tandem on more data .      and the features are different also . the vad doesn't use the same features there are .     there are other things that we should do but , it requires time and we have ideas , like these things are like hav having a better vad . we have some ideas about that . it would probably implies working a little bit on features that are more suited to a voice activity detection . working on the second stream . we have ideas on this also , but w we need to try different things and but their noise estimation ,    but , we did a first try with this , and it clearly hurts . it was c it was just combined , by the acoustic model . there was , no neural network for the moment .       and the other thing , that noise estimation and th try to train the training data for the t tandem network , right now , is like i is using the noises from the aurora task and that people might , try to argue about that because then in some cases we have the same noises in for training the network than the noises that are used for testing , and we have t n to try to get rid of these this problem .      the last thing is that we are getting close to human performance . that 's something i would like to investigate further , but ,  i did did , listen to the m most noisy utterances of the speechdat car italian and tried to transcribe them . and , that 's that 's the flaw of the experiment . this is just i j it 's just one subject , but but still , what happens is that , the digit error rate on this is around one percent , while our system is currently at seven percent . but what happens also is that if i listen to the , re synthesized version of the speech and i re synthesized this using a white noise that 's filtered by a lpc , filter  you can argue , that , that this is not speech , the ear is not trained to recognize this . but s actually it sound like whispering , we are      but  ye ","there was a p problem that we observed , that there was there were many insertions in the system . actually plugging in the tandem network was increasing , the number of insertions . and then just using the other silence probability helps . the last thing is that we are getting close to human performance . that 's something i would like to investigate further , i did did , listen to the m most noisy utterances of the speechdat car italian and tried to transcribe them . that 's the flaw of the experiment . but still , what happens is that , the digit error rate on this is around one percent , while our system is currently at seven percent . but what happens also is that if i listen to the , re synthesized version of the speech and i re synthesized this using a white noise that 's filtered by a lpc , filter you can argue , that , that this is not speech , the ear is not trained to recognize this . but s actually it sound like whispering , ",
Bro028.D,"that ey that , what i listened to when i re synthesized the lp the lpc twelve spectrum is in a way what the system , is hearing , cuz @ @ all the all the , excitation all the the excitation is not taken into account . that 's what we do with our system . and in this case it 's not lpc , but lpc ?     but that 's what we do with our systems . and but is it that different , i   this is the one percent number .           to f seven times ,  but but the signal itself is like a mix of of a periodic sound and , @ @ unvoiced sound , and the noise which is mostly , noise . not periodic . what do exactly by putting back the pitch in ? because i    but it 's neither purely voiced or purely unvoiced . esp especially because there is noise .          that 's what i was thinking by doing this es experiment , like evi but right .    that 's it .    at these noise levels .  these numbers ,  it 's around fifteen to twenty percent . and the baseline , error rate . twenty percent error rate , and and on digits . and this is still the baseline . right ? the baseline is sixty percent also on digits , on the m more mismatched conditions .  we don't know yet ,   no . no .  no . this first , this was not the point of this the meeting today and , frankly , i don't know because i d didn't read also the most recent mails about the large vocabulary task . but , did you do you still , get the mails ? you 're not on the mailing list or what ?  we should have a look at this .   you didn't get any answer from joe ?    nnn , the dist    but , these values are not directly used as probabilities anyway . there are there is       now he has a version of the software .      it was a poster . or   it was something similar to n on line normalization finally in the idea of normalizing  right . n   they have , different histograms . i something like one per frequency band , or but i did  but i should read the paper . went through the poster quickly , and i didn't  i don't have feedback from him , but he 's gonna ,      if we had infinite processing power and data , using the waveform could that 's   ",,
Bro028.E,"are you were going to say why what made you wh what led you to do that .  st stephane . getting close .  out of curiosity , what recognizer is the one from mississippi state ? is it ? is it like a gaussian mixture model ?      it 's like a greedy    as we were talking about this i was thinking , whether there 's a relationship between between michael 's approach to , some optimal brain damage or optimal brain surgeon on the neural nets . if we have ,  we have our rasta features and and presumably the neural nets are learning some nonlinear mapping , from the features to this probability posterior space . right ? and , and each of the hidden units is learning some some pattern . right ? and it could be , like these , these auditory patterns that michael is looking at . and then when you 're looking at the , the best features , you can take out you can do the do this , brain surgery by taking out , hidden units that don't really help and this is k sorta like   right . that segues into what i 'm doing . the big picture is k come up with a set of , intermediate categories , then build intermediate category classifiers , then do recognition , and , improve speech recognition in that way . right now i 'm in the phase where i 'm looking at , deciding on a initial set of intermediate categories . and i 'm looking for data driven methods that can help me find , a set of intermediate categories of speech that , will help me to discriminate later down the line . and one of the ideas , that was to take a neural net train an ordinary neural net to to learn the posterior probabilities of phones . and at the end of the day you have this neural net and it has hidden units . and each of these hidden units is is learning some pattern . and what are these patterns ? i don't know . and i 'm gonna to try to look at those patterns to see , from those patterns presumably those are important patterns for discriminating between phone classes . and some , intermediate categories can come from just looking at the patterns of that the neural net learns .    that 's the first part one of the ideas to get at some patterns of intermediate categories . the other one was , to , come up with a model a graphical model , that treats the intermediate categories as hidden variables , latent variables , that we don't know anything about , but that through , s statistical training and the algorithm , at the end of the day , we have , we have learned something about these latent , latent variables which happen to correspond to intermediate categories . ","that segues into what i 'm doing . the big picture is k come up with a set of , intermediate categories , then build intermediate category classifiers , then do recognition , right now i 'm in the phase where i 'm looking at , deciding on a initial set of intermediate categories . and i 'm looking for data driven methods that can help me find , a set of intermediate categories of speech that , will help me to discriminate later down the line . and one of the ideas , that was to take a neural net train an ordinary neural net to to learn the posterior probabilities of phones . the other one was , to , come up with a model a graphical model , that treats the intermediate categories as hidden variables , latent variables , that we don't know anything about , but that through , s statistical training and the algorithm , at the end of the day , we have , we have learned something about these latent , latent variables which happen to correspond to intermediate categories . ","The group heard of the plan of one of it's member's work into intermediate classifiers, and also of how a visiting research student's work into auditory models can be applied to their work. "
Bro028.E,"and those are the two directions that i 'm looking into right now . and , that 's it . tea time ?  ",,
Bsr001.A,"this is on . hi , hi , hi . hello ? hello ? i 'm on zero ! yes ! 'm being recorded by the wire . and mike are coming on my channel . guess now we have a lot of censors self censorship going on . no , we got to relax and let go .   he 's a the sound effect man .  alright . they want to do something serious with this research . solo means you just can    you 're going to be saying , funnier things , leave it on .   clearly my impression is i if i have to wear this thing , more than five minutes , i will be completely affected by it somehow .  i wouldn't be   that one . the one i tried . i 'd they really press my temples , otherwise my ear channels , otherwise my joints here . depending where i put it , it press different things , but that 's a @ @ fine .    this thing is probably , acoustically more challenging but i like this . th is it ? but there is a t no . a anything which is distracting or painful , is going to impact negatively with this .  but but at that point it wouldn't be much different to wear this or that . hhh . but probably this is designed in such a way that it should be closer . and this , but this is designed to be worn like this . i really like this . mean , if i have to design the thing , would rather , use this type of thing than the other ones . and also i is    i noticed that . i noticed that . but , that might be the challenging part . because otherwise you are if it was comfortable  i , no .  i i i 'm more deaf on this ear , whatever this is on . i could wear it this way . still , i 'm i it 's my impression . there is a lot more work to do with this one but if you want something really nonintrusive , really something that     you think if you do you think this is going to be too f too    and with this you 're saying , you are also in that situation ?        those are really bad . you have , he would . and and what about this one ? this thing wearing sideway that can ?  d does it have a speaker ? does it have a speaker or ?    you do . y    you 're a  the market is a captive market . good . the original project looks a lot like , the p your project . we set up with this , idea of the meeting the mediated spaces idea in general ",,
Bsr001.A,"and then incr incarnated in this room that will be mediated somehow by , a computer to access information , to help along the meeting , and will be like two main functions . one is the interaction with the computer which , as you said , is your interaction with the pda in your case , where you query it to ask for information , et cetera . at the same time , our process is somehow , getting all this multi channel information , doing some cross , channel , cancellation and transcribing the individual streams , not necessarily in real time . and the idea is y you can eventually after the meeting query , previous meetings and and there is all this work on transcription , similar probably to what we do in switchboard but with better bandwidth ,  but worse , environmental conditions . an and then , there is , all these issues about processing all this information , transcription , but then using , prosody information to better , segment , endpoint . also using topic segmentation to help better classification of information or extraction of information .  we didn't dare to say it will be just in a pda you throw in the middle of a meeting . that was daring .       but , let 's assume somehow the compu processor power is going to be there . whatever . initially you may do a super computer for the transcription , real time and then     ou we set up this concept like a year and a half ago . and at that time i said , we said , "" don't worry about the compute power "" . it will be somewhere ,         our approach , somehow , i believe it 's probably , complimentary in many ways , is to focus on the actual deep technology that we have somehow in speech . and make progress on , the algorithms . and then , it will run somewhere .  as you said , to we would like the idea to have it there but our focus is to develop the algorithms , to push the state of the art on this transcription task . and , the other task probably is also , challenging the comp the querying , the command , control , or , doing that in natural language .    i see . you really are challenged to do that , to put as much power as you can in the pda .  our approach is , we do whatever is necessary to do it and , some of it may go into something , depending on , your scalable power .    is , eventually y you will get all this sc higher and higher , powers in these portable things . as long as you have enough algorithms and technology to do something better if you have more processing power . ",,
Bsr001.A,"the situation now in the speech community is that , there is some boundary , some limit in the performance . and no matter how much processing you throw in , you don't get any better . and we are trying to push that . and then you have room to port whatever you can to , smaller devices .  interrupt you .    always @ @ .       exactly . it 's one of the areas where kemal is going to work speaker tracking , and speaker id .  you want to know . if you have the people wired individually it probably is easier . but in the other situation ,         there are some programs in tv . i 've been trying to get this from something like this from , public cast   and they but they do it somehow . they clean it up . i notice that they s they sa have some help with control of what person to pick up . there is some program at midnight somewhere . it 's a bunch of four people discussing and they , it 's a lot clean .  i probably .    i 've heard that sometimes . but it 's though . you don't think they fill it with any , they i am pretty they do . it 's it 's still , understandable .    at the same time .     in many cultures it 's not bad manners to speak on top of another one . i it somehow   could be reassuring ,  keep going , keep going .  i belie i believe there is a lot of overlap and would be great to com to take advantage of that to make a synergy more than an overlap , and , help each other . i believe each group has , depths in different , areas ,  we clearly c should collaborate for the best of everybody .  i , there are no final the official decisions have to be made in terms of resources to that . my personal opinion , if you ask , is that we should because the only way if i learn anything on speech in for the last , @ no , no . you need a task to really , improve your system for that particular environment . right now we are focusing our research on doing evaluation type of , in incremental improvements .  switchboard , they have five is you have two people talking , it 's the closest thing . but we really should move into the data that reflects as much as possible , the real scenario . and that 's a way to improve . and then you do improvement on that particular database . even if we don't collect the data to train models , we should collect data at least to evaluate progress .        on one question . this thing is also for you , made on internal funding ? or i know you 're applying for some darpa funding . ",,
Bsr001.A,"you already got some .       you are on the line . this would never go away !  thousands of people are listening to us now because it 's in the future , but , sequentially thousands .  erase that part . we could have like , some periodic meetings , and like , phone meetings  at the same time we contribute to the database collection , and , but it will be all documented . how is that ? three peop total ? s some peo people speak with their mouth full , that 's a @ @ . delete that part . i one question . i haven't been in these , preliminary de decision meetings , but i don't 's the idea for the computer interaction . it 's going to be a real computer , as in wizard of oz ? what 's and it will be a real computer recognition .        somebody will be playing the recognizer and then other agents will be doing their task independently .   good . you p you plan to train actually models based on this data .       if you plan on really training collecting a database for database for training , you are talking about , twenty thousand or forty thousand sentences . things like that .  tens of hours .    but i   clear clearly i if everybody 's collecting data to train on , m we should do something   if you doubt , don't do it .    it seems to be like , if everybody w e u was in the universities collecting data , we are , you are , sharing the data and making a bigger corpus is going to be , a benefit for everybody .  morgan said yes .     except   most people , after this evaluation and conference @ @ should be working on these type of things . at least ,   but eventually will be people working on recognition aspects and , and in core technology . mean , recognition technology and also core , algorithms , et cetera . and for those people to have these data will be , the best way to , develop the systems to an @ @ .   probably , on the   you were also thinking about the same tool ?  already ! it 's  no ,    this is something that re requires a bootstrap . there is no ldc database . there is , at least we have to share the data , that 's the bottom line ,      you say , "" hey , eight ! ""  i see . ",,
Bsr001.B,"ch ch , ch ch , ch ch right . that 's right . you need me , i really count . and is that the channel number or the microphone number ? right .  these are disturbing . being just in front of your ears , it you can hear the shadow it creates . there was this like little acoustic shadow from having this in front , feel it . there 's too much  you can feed it to the feed it through the headphones ,    yes , that 's right . the medical .     what exactly is the purpose of the corpus ? what 's the purpose of the right . but it will train them to the microphone characteristics of this c right .    i agree .          i 'm actually finding this quite comfortable now that i 've got it just right . it 's just u i it must have numbed the areas .   code ! right . that 's an interesting language model i 'm   i 'm beginning to feel my heart beat now .      you get the wrong answer quicker don't you ?        right . this i   yes . right .  it 's still in the forma it 's still in the format which is slightly more formal than , completely informal conversational speech . they will do , a bit .  the host probably gets , gets a little bit more . gets a little boost .   there i      that 's the op   is that in exchange for access to the c right . and you 're saying some of the infrastructure is , the a t andt video conferencing .  right . pi a free gift .   right . should we stop recording ? that 's to the listeners . that 's right . it could be . this could be the most popular corpus .  ha ! but that 's only on one sp    right .   that was , w  that 's gonna be @ @ .  there might be a different style of , different , actually , style of interaction .   yes , certainly .      just the fact that people are making different assumptions is quite an interesting problem . it 's quite an interesting issue . that brings up    contribute the data . yes .  is that the channel limitation cutting in ?  two of @ @ .  m  and do you have the same agenda , although there 's a goal ? is there one goal or several goals ? because that 'll would be more interesting data if there is like a budget meeting is a classic example , of where every comes in pursuit of a different goal . right . right . right .    in th  right . and this is just train training them using the the head mounted data initially . or , is the intention to do some som right .  understood . right . you 're not intending to do any ",,
Bsr001.B,"you said you weren't gonna planning to do any beam forming as such , but you 're not intending to do any signal processing or , the acoustic modeling of the environment or microphones , or anything else ? cuz that 's actually my interest at the moment ,  right , right .    right . you 're having  when you say multi stream , right .  that 's interesting . right ,      it 's transcription and processing ,  it 's not a speaker phone is it ?  i guessed it from the clue ,             sampling rate in the end .  bits , sixteen k ,  yes , that 's right , not , but it 's similar but not quite the same .  the bit we 're a bit deficient in as we    right .  to study using the same thing . can you do that ?             right .   declination ,   right ,     that 's the reason ,     up a bit .  in one ear . just the order ,   right . you also gain noise from the projector as isn't it ?  no ? it  it actually gives you a way of calibrating microphone position in a way . doesn't it ?  for volume , it 's a point source    t digit strings ,  ",,
Bsr001.C,"it 's being recorded anyway , right ? why listen to the guy ? if you need it you may record it . then we can get liz 's x marks later to see if there are any important things . mine is on . where am i ? which one ? which one ? channel i 'm on two . good . you are on zero . they 're already labeled ?  that 's what i figured out . no ? i 'm , you 're counting from one instead of zero ,  right . right .  no ! this is harry , we should record some of your clicks and , actually this thing is really cutting the blood flow . i 'm gonna pass out . this is a very sensual thing . this is a little better . boy ! this is just m bad design . this , this is ouch .  go to that . what are you doing ? actually , i use something like this on the telephone and it 's very comfortable . not for this , for no . it 's just but talking in general , that 's , that 's really like having one of these almost ,  he 's about to pass out . that 's why  really ? you could actually produce like code or ?        when you go to your pda system it 's , really an awful open problem to determine how many speakers there are and where they change turns ,  that 's actually being ad that 's one of the problems that 's being addressed at this year 's evaluation ,  which is taking place right now , actually . right . you do need to figure out the number of speakers in the waveform . this is a nist evaluation .  right , speaker verification . switchboard . switchboard and , i we  we will also run some part of that , evaluation too but probably not that segmentation part . but i don't know if they are using a different data for that . but it 's while i say "" switchboard "" , s there 's only two speakers . but , i don't know how they , actually went about .  cuz they were saying some up to eight speakers . they some other data for that part , you 're right . no , no .  right . no . we 've also , s done some of that as , i have a small , hacked up system which for the broadcast news determines the approximate number of speakers and actually assigns some names to them . this is something we did for the maestro project , for rick . but , for broadcast news it works much better actually . it 's , you do get like in an interview , long segments and there can be like a problem solution thing where they would actually , they have to come to one solution . ",,
Bsr001.C,"not with these around . you 're encouraged to , just utter digits once in a while .  one two three four . ",,
Bsr001.D,"hello ? i 'm on channel four ? channel four , channel four , channel four ? why ? that was good . hey . hey . hey . i have a feeling we 're on reversed . does yours say "" three "" ? no ?  sss this is the problem . good .  good , good .  whoa !  hello ? i 'm number three . that 's right .   that 's great !  they 'll be deaf deafening the transcriber . that 's really something .  it looks pretty slick though . that 's great . ca can we fast forward through this conversation ? no . that 's really  on the temple 's the pressure ?  we have to add that to the form they sign .   it 's very comfortable .   hey , whi what where are @ @ ? do you s do have you studied a click language ? i don't @ @   i 'll just take i didn't know that you could whistle that you 're a very soft whistler , you 're mostly able to do that without much air aren't you ?   that 's amazing ! how fun ! can you project it pretty    but they 're just very , very sensitive . fascinating !   we could can't we buy an expander that you just    there are some with a lot of overlap .   but the worst the worst case is politically incorrect where they don't really make any adjustments and it 's hard to even follow what they 're saying . it 's just it 's truly overlapped .  you guys are more in business that i am . my feeling is that when i when i 've seen that show it 's like there are sometimes people who take over the floor and other people are trying to get in , and they can never get access . it depends very much on the mix . it 's just , i know that there are periods where two people are talking in t at the same time and you 're only able to hear parts of the weaker voice . and , that 's it 's a style . it 's a style . but i but i 've seen debates where and it 's engaging people . it 's been going on for a while now .     or in new york or in new york , high involve high in high involvement style .   that 's what it 's called .  what do is say , la la la . i know , but we can blend it for the public .  like saying , like "" hal ? ""   is it the three , i see ,  i wanna ask one question though . is it the same three people each time or a different three people ?  that 's good .  the other thing too is , i if you have the equipment then , i it could be different . then the recording is easy ",,
Bsr001.D,"and they  i 'd give you my mike . i 'm not allowed to .  alrighty . should we interpret what he says ? morgan says there we go . is it gonna be like an hpsg grammar ? i see . is morgan nodding his head ?  he could be reached by the far field , couldn't he ?  i wanted to ask one question about the nature of the design . th given that the overlaps are up where the difficulty comes , in a bunch of a areas , whether it would be useful to have some of the sessions have like an additional rule where if a person , the that there 's someone who recognizes people to speak like that to cut down on the you then you have the meeting context , you have multiple channels , you have the microphones n varying the way you want them to vary , but you 'd cut down substantially on the overlaps . it wouldn't be f for all meetings but whether just sprinkled through there once in a while , something like that might be useful or not . just wanted to raise that . i don't know .   what say is that wha sometimes , if we were to have this coordination thing , some of the overlap is due to someone wanting to claim the floor at a certain point without knowing that other people have the same desire at the same point in time . and if you were to have someone who was like a moderator , then you raise your hand , the moderator would say , you first ,  or press the button . and there are always gonna be backchannels , that 's natural and lovely . but these overlaps that are due to people n not knowing other people wanna leap in at the same time and wanting to coordinate that , it could be lessened . not eliminated entirely .   and they 've been collecting digits too .  that 's a good idea . that 's a good idea .  that 's right , this we could each make up a string . i know the numbers that were used but i don't remember the combinations . we could do some digits .  that 's what i was wondering . ha wha we could just make numbers up , can't we ?   can you bring them up from the no ,  alright . i wanted to ask about also the air conditioning . are is there a plan to turn the air conditioning off in some of these meetings or is it always gonna be on ?  but i was just thinking , he was showing it on what he showed us on the web site , you could see the contribution of the air conditioning . and wondered if that was gonna be sometimes clear .   there you go . perfect . recognize those . ",,
Bsr001.E,"hello ? right . no , no . you subtract he was just saying trap subtract one .  ch .  really ?  i 've been clicking plenty . but they don't show up . they don't show up on that thing . i 'm they 're recorded . they tend to clip . ahh . you 've implemented radio buttons . what happened ? they have much pressure at th it 's  just trying to give you a hard transcription task . no . i 'm no , i wish . no . no . just studied phonetics in general . it 's weird . it 's apical alveolar thing . i don't know . it 's get a very high pitch that way too . and you get dogs to d cock their heads and it 's really good . cuz you can get really high . no . not too  but it 's that you get enough of the high frequencies .  that you really get animals like  i 'm surviving . i you guys gave up too soon . you just get used to it after five minutes .  we you 'd mentioned there was some possibility that somewhere else is going to you might contract out to do the transcription ? can y that 's what i was wondering .   one thing that horacio h hadn't mentioned is ,  y you were talking about the same idea of just collecting a meeting and looking at it afterwards . but the thing that i 'm interested in , and i 'm probably the one who 's gonna start doing the collection , is e is having this situation where people are talking to each other and talking to a computer in the machine in the room .  and that 's probably what u that 's certainly what 's gonna come out of , of our group first .  and it  what we 're doing is waiting to look at the pilot and see what people wanna do but it 's going all be wizard of oz at first . we 're gonna let them do what they wanna do first and then see if we should subsequent things . try to constrain them or not constrain them . or try to figure that out . that 's one of them pardon ?  e and it 's all of these things i is a g it is exactly these things that i mentioned . this is these are the main things that i 'm interested in . exactly these . when do when you 're starting and when you 're ending .   right . we wanna look at exactly those sorts of things . of us , at least in the beginning , is gonna have a number of different characteristics . it 's not going to be natural . it 's not gonna be a regular meeting . it 's gonna be an artificial situation cuz we 're gonna have to , mock up some back end .  ",,
Bsr001.E,"the kinds of , the kinds of speech is the speech is gonna be slightly different . people are gonna be in an unnatural task . we 're t gonna be trying to figure out how they 're gonna but but we will have the , we 'll have all this all the m microphones set up all the same .  right . right . and and if your task is to just generally do , summary and , and large vocabulary speech recognition over the thing , then it doesn't matter that much which , that there 's much a difference .  actually we could do that at our site too even though that 's not what i 'm normally gonna be collecting , but there 's no reason we can't collect that , and , then you 'd have a more m your normal meeting . they 're going to be goal directed . you 're supposed to you 're supposed to you 're a budget meeting and you have a spreadsheet up there , and everybody has to work out the some particular goal of where to p allocate money . and they can t ask the computer to switch things around in different columns like that . but everybody s and acs actually a o another characteristic is that we 're only dealing with three people .    we 're gonna start with just three people ,  it 's mainly it 's partly channel limitation because we wanna double mike everybody . it 's also to a large extent ,  and we have eight channels .  it 's also e what came up when even liz was , involved a little while ago with and christine just in terms of the thinking of the subjects and trying to have enough people . we wanted to , encourage like everybody to talk , try to figure out some way that everybody would be able to participate and a g yes , that was the idea . but i don't know , that was , w we 're not planning to do anything with all that like right away . if there were is there we h we 're happy to take input on that . and also , i very much wanna find out about the , the specs on the board that you have in the ma in the i in the pci card cuz we might wanna go with that .  no , no , we 're ho we 're hoping to just bring in different groups of three people apiece .  in a given meeting ? what we 're try what we 're trying to do is not make it too not make it too , ar artificial .  not like say , "" let 's role play . your , y "" "" you do this , you wanna "" but rather give them an actual task . actually have  and they all just have their own they just happen to have their own opinions . ",,
Bsr001.E,"and another possible thing that we 're thinking of is something like , we have these regular wednesday lunches and you gotta plan a menu , right ? everybody has things that they like an and , but a lot of the no . none of that . n no eating during meetings . salivating if you 're thinking about the food , but it   the idea is we wanna start off with a somewhat simple back end and we 're thinking of , agentifying an excel spreadsheet and having s like some spreadsheet what wh people will see a spreadsheet and they can ask it to move numbers around .  we thought that would be a useful task for budget meetings or that thing . starting off we would start off definitely with a wizard of oz task but it would be something yes , but it would be something but everything would be an agent . and it just be we wouldn't have the recognition grammar to begin with . we wouldn't have the nl grammar to begin with . but these are all components that are obvious to us how to build . nothing that 's far in the future . it 's just a matter of work .    right . something that can be built up , relatively quickly and makes sense how to do . fairly simple back end .   that 's good .  great . that 's really interesting . we 're starting off with digit too for our different for this , endpointing   we were thinking something like , ten hours to begin with . it 's about the right . that 's actually , that 's the other thing . we weren't  one thing i should point out , we were n we were not planning on tra doing transcription of the full thing right away , u cuz that 's not i was initially interested in just the speech that was directed at the computer . and we were not planning on doing the transcribing the entire thing . but that 's something to talk about . if you wanted to transcribe , you have the yes , @ @ you 'll be fine . what is the company ? i heard a "" sh "" .   that 's me personally . our group in general as horacio was saying is also interested in some of the same general issues .  and i 'm also interested in prosody , use u used over person to person like segment and helping for segmentation and  n the language models c really ?   on the language model we 're we 're gonna be using the same thing that we 've done in the past which is , we need a natural language grammar written anyway . it 's written in unification grammar framework . but with context free grammar , power , and it 's just changed directly into something the recognizer recognizes off of directly with no ,  it 's it 's hand coded . ",,
Bsr001.E,"because we need to write the natural language grammar anyway to understand . it 's a small , atis sized type task .  that 's the way we 've been approaching it . if we 're ge we if we 're gonna be able to interpret it then if we 're not gonna be able to interpret that then it 's not gonna do us much good anyway to recognize it . we might as go directly from the natural language grammar . it is a unification base , it 's not as theoretically bound as hpsg in particular , although the couple of people that we have working on it have hpsg backgrounds . it 's all up to when i have free time . anybody else want to work on this horacio ?  know they 're all working on mediated spaces but there 's a lotta aspects o e to that project . right . yes . yes . we haven't even we haven't collected a byte yet  right .  and we have the same sampling rate . one thing we do know is that we 're all producing nist sphere files in , in the standard format . sixteen bit , sixteen kilohertz . at the end we 're all and the amazing thing is that even , the entire way through we 're actually using some very , very similar and tha   it 's coincidence that it 's very fortunate cuz  we actually have , quite similar hardware as it turns out . which is ver it 's very good ,  we 're actually    all those issues 'm we @ @ like i say . i 'm personally not interested in those for my particular aspect of the project but sri in general is the  and s i don't know , we will end up transcribing stu if hor if horacio wants , wants that done , that 'll be we 'll end up doing that . it 's amazing too that , the transcription tool we just converged on the same all these things were very , very similar . it 's we were gonna use the same tool . we set up that tool already ,    that 's right .  i don't think we have any problem . we had certainly in our the proposal that we tried to make to nsf , we were assuming we would distribute this through the ldc .  we have no problem with that . it 's terrific .  s it tho those kinds of things are sorta the things that we were thinking of trying , cuz we are having we do have a more artificial set environment again . we 're trying something new having people speak to the computer . i don't think we talked about that in particular cuz we didn't we haven't done any pilots , we haven't seen this , incredibly difficult data of overlapping . but this is ",,
Bsr001.E,"christine helverson , who 's working on this with me from the s aspect of user , usability and would , y sh she 's interested in these sorts of things . what can you ask people to do that , that they can reliably do and without too much , cognitive load , that can help things out , or , those sorts of issues .  i don't know . it 's something that could fit easier in our context than in a general meeting context . i don't know . just have a button . and ring the buzzer .  i don't know . we for a t for a completely different reason i assume but and not within a big room . just ,   but you need the room and the set up . we 're doing digits we 're not doing digits in the room set up we 're doing it for a complete  one of the specific things i 'm interested in is knowing is the open mike issue . when you 're talking to the computer , knowing when you 're done speaking . and 'm loo interested in in interested in looking at prosody .  and we 're just having we 're just doing lists of digits to see when people pause to know , "" there was a big gap in time here but , they "" we can tell prosodically they weren't done ,    right . right . right , just look at the very last look at the very end . funny . and what are these what are the digit strings are from ti digits and ,  i don't  how long are how long chunks are they , a  i 've never looked over the ti digits corpus , i don't know .   but the projector 's not part of your meeting or is it ? do is this normally gonna be on during collection ? for ours it will but we have a rear projector , it 's in a separate room . ",,
Bsr001.F,"that 's right !   there 's a switch on top .  "" on off "" . the wireless ones are actually labeled . they have a little piece of tape . that 's r exactly the problem . subtract one from the mike number to get the channel number . or add one .  guess i am channel eight . you look ni you look nine . funny , you don't look a day over seven .  it 's r it 's remarkable how quickly people forget . far , e you h you must have much better ear . and far every meeting i 've recorded someone has at one point or another said , "" i probably shouldn't have said that . "" think they 're i bet they 're recorded quite loudly . it that 's a user interface , dan . very what does "" solo "" mean ?   but it doesn't actually do anything else ? that 's right .  lot o a lot of us ended up wearing it around your neck and then facing up . i kn and , just because there doesn't seem to be a good way to mount it . this thing ? or just that one ?   the    but this is very comfortable . i could wear this without any difficulty . i we c we 'd have to buy new ones . the other wa the other way i had it , which might work , is you put one over an ear and then you can adjust the other one . and that didn't that seemed to be pretty that doesn't work for you ? you see how jane 's wearing it ? that seems to work too . and you just have to bring it up . except you can bring it quite a bit closer to your mouth .   right .  we we should look into if we can buy a replacement . if they 're eighty bucks , that might be worth doing cuz they 're very uncomfortable . what you 'd rather do is nothing  but to get a good quality if you were listening to it downstairs , that one 's quite a bit lower quality .    try this one on . i my feeling is that this is for collecting a corpus not for an actual end user application . and think a little bit of intrusion is not ridiculous .  i agree . training s training speech recognition systems . we wanna do both . that if you if we try , from the get go , to do it off the pzm , we won't get anything . you won't be able to align . you won't be able to segment . you won't be able to do anything . right ! we haven't done the detail experiment but just from listening to it , it 's pretty bad , whereas these are m are very good . ",,
Bsr001.F,"that 's why if you use dragondictate or viavoice , or any of those others to do dictation you need to use these . there 's just no other way around it . and as i said , i find this one i find this one is no problem the only thing is a little bit of audio degradation in one ear , and i get a little bit of peripheral vision , but other than that , it 's not bad those , on the other hand , are very uncomfortable .  that 's right . guess the problem is we got the kid 's version . it 's wired . whereas i used speech recognition for about four years using one of these , 'm used to this . i don't use it anymore . my hands got better stopped using it . but , for about four years i used dragondictate and naturallyspeaking to do all my work .  it was really a pain .  but i didn't have a choice . i couldn't type .    when i first came back to grad school that was a project i wanted to work on , "" voice environments for programmers "" , but we couldn't get any funding for it and my hands got better .  that 's how i ended up working on this project instead . anyway . what are you guys doing ? what 's your project ?     right .  worse acoustics .       this is this is the pda one is very , very ambitious . and it 's also it 's depending on not only that not only does it depend on iram taping out and working as specified , it also depends on writing vectorized speech recognition algorithms which is non trivial .  right , one of our our back off policy on that if there 's problems with iram is it 'll be a wireless link , right ? you 'll dump the audio wirelessly to a network somewhere and you 'll do the recognition .   we we 've had a lot of discussions about it and to some extent it comes down to a religious issue . my religion is personal computers are good and terminal mainframes are bad . and if you can get away with it , i don't want to have a terminal in my hand and a mainframe somewhere else . the too many things to cont can go wrong and you lack control . the pc revolution has shown how good it is if you can have the power yourself . and the iram project provided us a method of having a very powerful thing in your hand . and we wanna see what we can do with it but we 'd also don't want the project to actually completely depend on it .  the project will go forward regardless of whether iram works or not . right .    right .  right , the for us the meeting recorder project has a very similar approach . ",,
Bsr001.F,"me personally , for my p h d thesis , i 'm sorta doing the other way and seeing how much speech recognition can i do on this little unit .   that 's right . the as i said , the meeting recorder project , we have people at uw , people here working on robust algorithms that will be running on work stations . they won't be running on iram . and then what i 'm trying to do is see how much of it put on iram .  right . that 's right , we don't even to do with it . we don't need to n right .   we don't even to do with their cycles . we w like as an example , we had a visitor who was working on speaker id , acoustic change detection . and he has a very good system for that and he wants to use this corpus .    it th what 's about what 's about getting this corpus is , i with the people wired you have a excellent baseline . right ? you have a very easy problem and you can get the right answer , to ground truth very easily and then you can degrade it by using the p z you can degrade it further by using those things . and really see what you can do with a real system .  that 's right . that 's right . really ? they 're doing an unknown number ? that 's good . just mixing it wouldn't work because the channel characteristics are too different . what we were working on here was parts of broadcast news . and that 's a slightly strange task because they tend to be long segments . but they were parts that were interviews that he worked on . and , right .    he had he got very good results . right . right . tried his on his system on the meeting recorder  but we don't have any trained neural nets or , his system was based on our hybrid neural net system that we use for speech recognition . and i was using the broadcast news nets on this data . it didn't do t tremendously and then the other problem also was that it doesn't handle overlap very his algorithm .  right . that 's right , with all the i interrupts . yes . mixing ,  like but they have in i 'm they do . they i 'm they have an audio engineer in the back . but that 's different than an audio engineer fiddling with the mixing parameters . right ?  high involvement . that 's a good way of saying it . what do we do ? it seems like there 's a lot of overlap between our projects , it would be to work together .  is your intention to start collecting some meeting data ?  more data is better .   right . ",,
Bsr001.F,"what would be is if we could , converge on formats and conventions , and on , and software . just right . i , it shouldn't be done . yes . we 're talking about that right now . i 'm not how much i should say about it . that the ,  there 's some possibility that we 're gonna get a third c party company to do the transcription for us in exchange for the corpus . right , and we have a little bit of darpa . under the communicator project . that 's part of it . and then , part of it 's on the iram group . iram group is paying for part of it . and then part of it 's just icsi general funds , is paying for it as the infrastructure , they th they were paid but they don't expect anything in return . they 're just being very and good neighbors and and they wanted anyway . and then they just allowed us to direct the audio portion of it to what we needed .  and to our listening audience . feedback . right . we talked about that and it was w when i spoke with him he really just said it was a money issue . that it 's certainly not any intellectual property issue where we 're perfectly willing to give people those boxes . the boxes are cheap . but , can they afford to get a six channel sony wireless and can they afford the p z and that   this is this is the same company that may be doing the transcripts for us , may be giving us may be giving us ,   and it would also it would be really to be able to do it in other rooms , cuz otherwise we 're gonna learn a lot about this air conditioning . yes . that 'd be great .  i agree . are you gonna m i is there gonna be some mark for that ? are they gonna say , "" computer , bring up a web page on "" or ?  i see . i 'm just thinking , from a discourse point of view it 'd be very interesting to somehow mark "" i 'm talking to the computer "" . right . "" computer , show me a web page on x , "" return . are you talking to me ? are you talking to me ? xml , that solves everything .  that 's right . we 're gonna make right . someone will make some assumption that 's different than someone else . and then we suddenly won't be able to interoperate .  that 's something we should try to i 'm not what wh what 's a good solution than that other than trying to keep in touch with each other . right .    meetings like this are good because we can actually record them .   right .  ",,
Bsr001.F,"when you 're talking about your artificial meetings , i they are gonna be goal directed , though . they 're gonna s say , you 're having a meeting to do this .   that will be different .  if you 're double miking everyone , that 's a close talking and a lapel , and then two environmental mikes , is that right ? right . if you ha m u  that that is , yes , or drinking . y getting coffee on these is definitely a bad thing . wizard of oz . real computer but a w someone driving it .  that 's close enough to what we 're interested in that it would t it 'd be useful for training the acoustic models , without any question .  cuz if you don't the accuracy 's gonna be horrendously bad .  we 'll definitely need to do both . right . it really i it will really depend on if we have someone who really wants to do that .  i it 's just as an example , i 've done some very simple digits recognitions where , i said if i had known we were having this meeting i would have done this before ,  having people read digit strings cuz digits are much easier .  and just combining just doing multis    but , just mixing the just doing multi stream on the different mikes helped enormously . and i was a little surprised . you you wh why ? i have no idea . because they 're a little different .   right . and that actually helped . that gave several percent improvement . absolute . that , just having stereo will help cuz they 're a little different . you get a little slightly different estimators and , you combine them together , and you do a little better . right , that the m our initial plan for icsi was to do forty hours . and then u w is talking about doing an additional sixty to a hundred hours if they have the money . if they can actually do it . that 's what they had said before but that was more ambitious .   recording it 's easy . it 's transcription that 's a pain . but you have to put on a mike .  we 're out of mikes . don't switch mikes . don't switch mikes . that 's way too confusing .  but if you had the data and we had a company . i didn't know whether i should name the company that may be providing us transcription or not . ibm . we 've been trying we 've been trying to work with them for a while on these projects and they don't it 's hard for them to give us money but they seem to be willing to give us time . and one of the po potentials is for them to do transcription in exchange for access to the corpus . ",,
Bsr001.F,"it would be great .  yes ,  that would be excellent .  that 's right . morgan says thumbs up . and that al right .  how are you gonna get dra ground truth on that ? we should   but anyway , what i was gonna say is that although we 're not gonna have speech directed to a computer , my expectation is that the acoustic models will be very similar . the language models probably won't be . i if it 's wizard of oz it will be . if they know that  the language model will be certainly be different but  and you 're gonna hand c hand code that ? i  i see . right , if you wanna interpret it you need to do that anyway . what 's your time frame look like for doing meetings , actually starting to record some ?   the reason i 'm asking is that it 's certainly better to get in early with standards , and data formats , and conventions .   it 's a it 's ex excellent , excellent .  that 's right . just agreeing on a sampling rate and a number of bits , and , header formats and all that . sixteen bit , sixteen kilohertz ? good . big endian , little endian ? but that 's that was coincidence , right ? think probably the biggest thing would no that wouldn't be true . if you 're not gonna transcribe it yourself , then you 're not gonna care too much about our transcription conventions . right of it .   right .  it 's a it seems like , if you and jane  if you and jane keep in touch about transcription conventions , that would be very helpful .    that 's right . right . it 's much more worth while to do if someone else is gonna use it . although again if this now named company is the one who 's gonna do the transcription , i sus i suspect they have in house tools that they 'll end up using . that 's alright . he can talk anyway . i was . ldc is what we were thinking too .  robert 's rules . think that   there are certainly f formal meeting settings where that 's what 's happens , y that robert 's rules of order and all that . that 's not something we had thought about before but it certainly is another type of meeting that could be done . no , i didn't . i didn't know we were gonna be recording this meeting , didn't . yes , in the other meetings we have . that 's another thing we should talk about , is making that we 're doing it in the same way .  if i had known and here we have all these new speakers , i could have gotten lots of digits in but no , i have people read them . seven .  falling ,    ",,
Bsr001.F,"i hadn't thought about that . i hadn't even thought about throwing out the last couple . definitely should . don't throw it away but don't use it in your training .  and  right . the only thing i don't like about it is that it 's not phonetically very rich , but .  that 's right , timit . we actually talked about that .  it 's plenty bad . it 's plenty bad just with digits , although i haven't trained any nets on it . i 've just been using existing digits or broadcast news nets since we don't have enough data yet . one , seven , eight , two , three , one , three , seven , eight , four . m that sorta thing .  but what were they ? they vary from extracted exactly the same ones ,  that 's like the timit sentences . greasy wash water ,  but , have a bunch of tools for generating these and for helping transcribe them . since what the transcript is you don't have to type it in , you just have to segment it . have tools for doing that . using x waves , tcl tk , perl , and some c programs too . don't have any of the print outs . i print them out a as i need them . what i should do is just print out a whole stack and leave them up here but i haven't done that . but i it 's a different task . it 's a different task than read . you do it differently if it 's sitting in front of you and you 're reading it than if it 's not .  we could write them down and then read them , but . i we can get digits . a as you said , we don't have to be in a meeting . and if we 're short on digits just , capture people in the hallway , drag them in here , and have them read digits for me . that 's right .  the we hear right now is actually the projector , not the air conditioner . the projector is much louder than the air conditioning .  no , not normally , not for our meetings . i at least very few of the ones we 've done have we had to do anything on the computer . right . that 's right , from volume . that 's interesting . although unfortunately , they 're all pretty close , right ? look ! digit strings . that 's right . no ! ",,
Bsr001.G,"i was just thinking that in the meeting you could like have this secret thing that would play music if you 're if you got bored . give you stock quotes @ @ . nobody would know , right ? no , just like no one would know if something 's actually coming through if you got bored cuz right . right . you sit at the meeting but you just  you just say , ""  right . right . hello ? and what about these ? where 's the am i nine ?   this is kinda fun . no , but it won't last long . it probably right . you can hear it . the rest of us that 's amazing .  that would give you a headache . can you convert these ear ones to something comfortable ? just by putting little or j  you can just use the microphone and take the headband off . but the  if it didn't hurt , if it was comfortable but you knew it was there , would it bother you ? because i actually think it makes everybody act a little more professional .  your telephone , and people use it for cell phones and .  you can't do any research otherwise . it 's just it 's too hard . it 's too hard without you should collect both simultaneously . and it 's gonna be too hard to do it without a  forget it . you won't be able to get grants . you won't be able to get funding . no , i 'm serious . you won't be able to show any results .  it was pretty bad . it takes off quite a lot . somebody will design a comfortable close talking mike . it 's there are too many applications to for them not to not do that . it may not look like this but .  this one 's fine . right . i  those are pretty bad .   this would drive me crazy . i people are very picky about this . but that 's painful . i can't   broadcast news is for this third party listener , right ? they , if you were listening to an interview that sounded like this , you 'd turn off your radio . it 's just got a d it 's a lot easier .   i was thinking , if transcriber were invented in italy it would have been handling multiple in new york . right .  and software too . things like rewriting this transcriber tool and thi that shouldn't be re redone . and the transcription conventions and then , uw i don't know if you mentioned this at the beginning but , the mari 's group , mari and morgan i th what happened historically , i don't know how much i 'm supposed to say if this is being recorded . anyway ,   there 's funding , it 's no , it 's i 'll tell you later . listeners . ",,
Bsr001.G,"too bad you weren't here . it does make you it 's it 's like you 're behind closed doors but you have to normally a note taker would know not to do that .  anyway , uw is getting some funding from darpa on communicator , with and that 's sorta how i got involved . morgan wanted me to do something . i my interest was in the language and dialogue m modeling , and the turn overlaps , and how to apply a language model , a dialogue act model to actually feed down to do better recognition . not just because it will be really difficult to do just speech recognition and then try to get some meaning out of it . you have to have some structure from the   and knowing that an utterance is really short and low volume , you should be able to figure out it 's a backchannel and things like that . anyway , and you guys know more than i do , there was some talk that you were gonna build a portable version of this that mari 's group there 's not a huge amount of funding in the way , mari probably won't be able to do a ton of collection . but i was thinking if there were prototype collection devices or standards , then we could share data . and we would have like a monopoly on that . mar once you get three sites collecting data and each site can demo it , and say it 's at the other two sites . which was would be really good for funding purposes . but that i don't really know . that 's what i heard from morgan ,  is that and according to morgan it 's like happening and  right . and he said something about a portable that they wouldn't have a dedicated room like you guys have here .  right . right , and it doesn't have different sides can do different pieces of it and exactly . right . and you 'll get different kinds of conversations and different interactions , and just having three different sites would be great just for diversity , and   but what ? they don't say when they stop . they don't say , "" i 'm done , computer "" . they only mark the beginnings .  it there are very very interesting . and actually mari 's but there might be , neat ways you can do this that are not natural but they become very easy , and that    but you can still collect the multiple microphones in a similar way and transcribe , and th that 'd be actually . the formats would be similar . but having the idea of the computer in there forces you to create a log file format that can handle these other devices . you were talking about the penn and  it 's the formatting is really one of the biggest issues .  ",,
Bsr001.G,"not the f transcript formatting but the audio formatting and the figuring out how to synchronize all of these , pieces . and what software you can use for post processing all of them . which i   or phone meetings , or even or meetings like this with about the meetings . with a telephone . no , i 'm serious . even if we don't make any decisions we 'll have a lot of data .  right . right .   right .  definitely . that was morgan . why is that ? why ? the microphones are different ?  that  that 's pretty  that 's they were gonna there was a difference in the amount of money awarded from the beginning to e  recording is right . right . you can have my mike .  but perhaps the company a company that might ,  there no .  but it , and there will be a lot of people to people talk in those meetings i bet with even three people ,    and , it will really help the design too . it 'll m keep it from being too specific to somebody 's set up or task . do we right , right .  we have some ideas there but not enough data to train . harry , and kemal and i probably actually having different kinds of conversations is really helpful too because to g to make these models robust . you don't wanna train on just a few people 's voices cuz then you 'll just learn the their prosodic patterns . that 's not what we want . that is from the transcription and from the speaker s segmentation . that 's not hard . the hard part is getting enough training data and nor you also need normalization data . you 're iteratively normalizing as you go through the  actually the acoustic may not be either . it 's if it 's very good , that 's true . if it makes mistakes it 'll be different though it   definitely . right . that 's actually why i called this meeting , cuz you 're both working on it and with , different sampling rates , and these silly things like that .   what ?   nist headers . s  just made that up but ,  but that  but you have different na you we 're gonna have different , hardware and    actually that 's the transcription conventions i was talking about this with jane it 's really important to people at least like me who wanna know , certain @ @ who are looking at aspects that are they 're not words but they 're structural things you 're trying to recognize . and also for the speaker . people interested in the speaker separation because what you call a turn and the end of a turn , and that it 's horribly confused if you don't it 's inherently hard . and you have to make some simplifications and different people make different simplifications , ",,
Bsr001.G,"and then you can't compare them which is what the literature is like now . and then there 's the issue of recognizer dictionaries , and non standard forms , and things like that have to be mapped . gonna "" versus "" going to "" and that thing . they 're not hard but but we definitely will be interested in some language and dialogue .  and uw is also probably gonna be interested in that too , the dialogue kinds of things . i   that 's originally we should thank jane because that 's how i originally she showed me some transcripts and "" this is great "" .   but what if you had like written the s the tcl kluge and then both done the same  but you still need something that can display these channels . e better than what it can do , and then who is the contact at uw ? like morgan ? morgan doesn't have a microphone but is it mari and mari or katrin , or jeff , or  both both jeff and katrin have some time on this . no , on the p on the darpa project , who would be contacts for mari . and if mari 's too busy then     eventually ldc could be very interested in it , especially if you have a tool that can do this . there isn't one . and the data . it 'll we can actually you can sell corpora eventually to the ldc and you can get time , student time , to clean up the corpus and things .    right . but you connect you collect digits in conversation or individ  i was thinking never mind , i 'm getting attacked . you don't need the meeting for that . you can just sit me in this room and set up all the microphones . right ,  right , right .  that 's a really good idea . to always    d if you definitely shouldn't use your last sample . people that do prosody work , they add a few at the end because otherwise people will   no , but that is beautiful because then you can get this f zero floor for each of the speakers . just from that . your junk is our , training data . no , that 's a really good idea to have some standard especially if a the different sites can do something like that . you 'll at least be able to see whether difficulty across site is due to , the lexicon version ,    you should definitely it 's some calibration , for many of these tests . you could have ti "" she put her dirty laundry in the clean bathwater "" , whatever .  have we all memorized these ? we know them . right . you could write them write something on the board and , i don't know .   right . it 's way too cold in here . a all right .  modern technology . ",,
Bsr001.G,"see , you may wanna call up your computer . "" computer , give us digit strings . "" ",,
Bsr001.H,"  you have to turn those things on if they 're not on already . are they there 's a switch on top .  looks good .   no , no , no , no . but you have to the channel the number on the mike is the number on the screen plus one , cuz , otherwise we would 've that 's right . god .  it means i was trying to think of things they put on real mixers that i should have on mine . but it 's really good . the solo actually cuz it 's actually it 's how to it 's what can i what application can i have for a , a class method rather or a class a class procedure . the solo by sa satellite . then if you click on one of the other ones , it clears that one . doesn't do anything , no , no . but it 's   the those  right , right . but , but it 's not such a directional microphone probably .      right , cuz you 've got it is ,   no , the hang on , hang on ! right , right . th it 's y  it depends , 've no , we got a japanese version , that 's it ,  the it 's funny , i li i like this . it actually gets most of its strength from the fact this thing 's stuck in your ear . and , and originally it does . when i bought those things i originally got this version , cuz plantronics makes an in the ear one . and i really liked it but , other people didn't . it just depends . i 've been using in the ear walkman headphones , for a long time , 'm used to that weird sensation having something stuck in my ear . but if , if you 're not used  right .   i don't know .  right .   it 's not   right . i was gonna say that , in terms adam has a a particular agenda , but there are lots of other things . and it 's the way that a project like this works that a group like this where we have students coming in , it 's meant to be long term thing that will get us data and people will be able to come along and look at different aspects of it . it 's not clear , whether s someone at uw 's gonna look at , beam forming or whatever . but ,  it 's goo it 's a good property for us that there are a lot of different things you could do with it , and it 's we haven't thought it through . but that 's it 's it 's fair enough .    you can get the ground truth .   which , wha evaluation of of the speaker id and what 's the what wha what has the data been ? ",,
Bsr001.H,"what data are they using ? what is the    right . right .  but it @ @ bu   right . pause if you wanna say something that 's sensitive .     that 's right . it 's funny , like we close the door and it 's         i know . that 's that portable thing 's been mentioned . but that was  somebody 's got a unit which is something like the adat which , it 's a device which will record onto tape , multiple channels . and think that was gonna be and we were g like someone actually has this knocking around . some company that we were gonna was gonna lend it to us , something like this . the same it might be the same company or it might be a different company . there 's another company which also has a has purchased a very a big multi channel thing .  and if we if they could lend us that , we could imagine doing these kinds of recordings . that that like you said , the fundamental thing is it doesn't have to be this hardware . it 's just the idea that you have multiple channels to synchronize data and then the post processing can be uniform and like that ,  right . right . right . no , it has to be error complete . the computer has to   no , but no but , y but it 's like , if it really was an intelligent assistant sitting there you could say , "" perhaps the computer could show us this . "" and you 'd be talking to someone else but the computer 's meant to be listening , and saying , "" it means me . "" "" i shou i should do something now . "" the  that 's the question . if we are collecting these at different sites , different kinds of tasks , different people , what is there that 's gonna be uniform about this collection ? and part of it will be , this combination of close talking and environmental mikes . and then part of it will just be the data presentation , if we have common transcription standards and , that it 's all transcribed or there 's some integration of the standards thing . but u as long as that makes sense , then it 's to have a variety of tasks , right ? to have different right .  right . right .  but  i w if we 're gonna have if we 're gonna there 's an opportunity to share tools , right ? the if we that 's right . right . wha  right . we we 've thought about doing right , right . that 's     no , the idea is to train on the , on these mikes but use these to get the alignments that we 're gonna train to , right ? i don't know .  ",,
Bsr001.H,"also , i suspect that it may we may not be able to get anywhere without doing something , right ?  we may end up having to do that .  hang on . you ne bu to combining the posteriors on full band recognition like from three different or four different mikes .  it 's something like tens of hours tens of hours of data ,  really ? we 've run it  not quite but  it 's not we it 's a we we need to , right .  cuz we 're very naturalistic here .   bu but how much how valuable given that you 're interested in this computer directed data and we 're not gonna have any of that ?  i see .  right .  right . right .   but it but it    that 's interesting . the and in some ways that does change the , the economics of doing that . but ,    but we still  that 's interesting . right , we need some browsing .  it 's he 's allowed to speak , he ca     right . it 's difficult because you want it to be real speech , right ? and also it 's not clear how people can even adjust to that rule . but if there    we no in general     we give people a list of digits and they have to like put them into their discussion , like say , "" five , one , seven , three . ""  but there is but there is also this fascinating prosodic thing that goes on because you what we have is like these lists of ten digit strings or twenty digit strings and they 're like one to five or one to seven digits . and people read through them . and we 're saying , we won't to be able to separate them pause between but it 's very people don't like doing that . and there is this prosodic thing which is indicating when whe the pauses between these digit strings . and then when they finish , the actual the whole sheet , there 's this wonderful phrase @ @ . and it right . right .   treat especially  right , right . there 'll be a common that 'd be great . that 's a good idea .  right .  it 's ti digit strings . it 's actually it 's like but from one to nine digits . it is actually the actual digit strings from ti digits .    the order ,  put them on the internet , put them on a web page . i we should do that cuz y you can turn it off on that thing right there and it makes a huge difference . but the projector ,  this is the first time we 've done it with a projector .  but the c but the recorder just crashed . ",,
Btr001.A,"what 's what do we do with this ? anything ?   is anybody wearing one of those awful quote crown microphones that people used to be    just curious .    they 're tough sometimes . sometimes the german accents can get a little bit daunting .   i forget who it was that i was transcribing but , it was tough to figure out what e he was saying , at any given point in time and i would just listen to it over and over again , going "" my god ! my head 's gonna explode ! "" like , not really understanding a  and i was getting a little frustrated because i would put a lot of things into parentheses and then go back over it and go back over it again and still  i like to try to clear as much up as i possibly can and felt like with the german accents , just for me personally , those were probably the toughest to get around . they weren't impossible but just like they too the m they took the most time too . would take twice as long on a g given channel w with a speaker who has a german accent than somebody who 's a native english speaker , or even asian like , speaks an en asian language . i found that easier .   somebody who speaks like chinese @ @ .  i studied i studied old english for a while .  and then i 've worked with larry hyman on like some of the bantu languages .  and i 'm also working with ian maddieson and he 's been doing work on the , like also some african languages . 've like learned a little bit . no , sing in german . but pronounce it but i don't know any . do pronounce a lot of languages and not actually speak them because of singing .       haven't transcribed this spanish woman , i don't know if i have .  that 's kinda  like the region ?  right . menton . right . there 's another language that 's spoken in spain too , that 's what am i thinking of ? castillian .  and  catalan . depending on where she is , like ch   german .  he if when people talk over one another like constantly , like there 's this whole barrage of voices coming from everywhere , it 's like "" my god ! what 's going on right now ? "" it 's   you couldn't visually isolate it ?  that 's possible . it 's  that 's possible . i was just gonna say something . i was gonna say that , it 's easier for people to mimic like the timbre of somebody 's voice if it 's the same if , that person 's voice is the same if that person is the same sex as you . implicitly people pay attention more closely to speakers of the same sex . i don't know . ",,
Btr001.A,"i don't know if that 's actually true but i 'm just throwing that out there . an interesting research project .  me too .  right . at the beginning it seems to happen when , voicing occurs later l like with fricatives and with like , like i it doesn't happen with , like "" buh "" much because you 've got the pre voicing before the consonant actually begins .   that 's interesting .  it 's like "" fff "" , "" sss "" . "" shh "" . it 's like the noisy , like airflow ones where you 've got like a stoppage in your mouth like , like your tongue right .    and it sometimes changes the entire utterance , too . we stop voicing sometimes . sh   prn . right .    with like some of them like with the difference between "" the "" and "" the "" , you can distinguished very , u dif definitively like what context they 're gonna be used in . like like you would say "" the apple "" because it 's "" the "" plus then the next word starts with a vowel . or "" the cat "" because it 's next word starts with a i 'm it 's  but something like    i 've run into that .  sometimes i 'll put in like a bracket like the orthographic a slash like if i 'm really confused .  kinda go "" there 's two , here . "" a few times . right . this is fine . in m i was just gonna say fifteen minutes later would help me a little bit just cuz i have a class up at dwinelle b just before this . that 's why i was a little late today because  i took the bus for part of the way . but that might help me just a little bit because then it i i 'm gonna be hobbling a little slowly . no . tea ! no . tha that 's funny . that 's true . this is very important . this is fine with me .  i have . you talking about the ibm ones ? right ,   i could tell you something that  i really th  right . if if if i could be completely frank , i really didn't like the ibm ones .  i found them to be just ended up redoing them . like from start to finish , when i was checking them like it would take me as long as it would have taken me to just to transcribe it by myself . i 'm really picky . tigerfish are better . if it says "" tf "" .  the ones that say "" ibm "" are like they actually say "" ibm "" . yes ! and you have to parse them all down .    right . als  that 's interesting . eee !      right .  that 's true . ",,
Btr001.A,"'m such a perfectionist that i combine the two when i 'm checking , like i act as though i 'm transcribing it . and i really do . like i 'm i tend to take a little longer than other people doing checking but like i 'm like ultra careful . i that 's just how i am . but , like i really think of it in terms of re transcribing it almost and i only b  like , i change time bins a lot , and i like will change what people write like for whatever words they write a lot , like don't see too much of a difference but that 's just because it 's me . like like checking more for that reason because then it 's it 's like it 's a little helpful . it 's like somebody 's helping me a little bit , but i 'm actually doing the work anyway , is how i see it . right .   right .  like little sighs , or like inbreaths , like as though you 're gonna start speaking , which i feel is important because it means that somebody 's about to interject something but then they decide for whatever reason that they 're not going to . and oftentimes i find that the segmenter will miss those things , those vo vocal cues . breath laughs especially .  it 's actually a breath laugh . right . right . it 's no it 's like .    yo yo . there 's one guy in particular who does that . it 's really cute actually . reacting .  right .    y who i kept wanting to meet ? was bhaskara . is he really ? he has such a voice . i really like his voice , kept wanting to meet him . and then john told me that he 's not around anymore .   neat . just curious . i haven't either .  yes . i th know who you 're talking about .    i know . i started like making mental friends . i 'm just like , "" i really like that person . what , i 'm gonna be his or her friend . "" and then  some of that computer my god . i 'll just sit there like going , "" fff ! "" it 's going right over my head .  start zoning out sometimes . like , i don't mean to , but i 'm just going , "" i don't any of these acronyms are and no idea what you 're talking about . ""  and they 're writing on boards and that we can't see , and we don't they 're referring to , and right . they 're referring to this or that and the other thing and you 're just going , "" no , i don't understand . "" really ? see . you have to do it vocally as opposed to visually ? ",,
Btr001.A,"like you can't use gesture ?  right . cute .  are you raising your hand ?  right . right , right . gets bored .   yes . a couple people in particular do that ,  i don't no , i don't agree necessarily . i do it .  i trail off with "" .  i don't necessarily do it as often as the one speaker i 'm thinking of ,  but , i do that because partly because i want to make that people know that my thought my utterance is finished , but that it 's not necessarily final . like , you can right . or you can build on it or j d expound on it .  it 's kinda like a shrug . it 's like a m it 's like a  what do   or y i 've heard you say "" , in that sense like "" in other words blah blah . "" like a an inad  right , but that 's true . or i 'm misunderstanding what you were sa when just ending with "" .  to me it 's like a vocal shrug . s that 's   i could see that . same with "" i don't know "" . you can also end an utterance with , "" blah blah but i don't know "" . like that . like , i feel like that 's similar to "" but "" . to "" ,  too .  it 's like saying like , "" this is funny but it shouldn't be funny "" or "" this is funny but it 's funny for some perverse reason "" .  how the one i 'm thinking of is like if like "" ha "" you say you would say like , like  he 's laughing "" ha "" and then he 'd go "" i . and  kinda ,  kinda like "" ""  and to me that 's more of like the "" this shouldn't be funny but it is . this is funny because it 's disgusting or perverse in some way . "" wi  you meant just like a just a normal "" ? meaning , "" let 's keep going "" ? that 's   let 's come back to the original subject and i will take it from there "" .  cuz i 've heard , morgan do that .  he does that a lot . for obvious reasons , probably , if that 's the way he uses it .   be polite , or whatever . right . go johno keeps making comments about the transcribers . it 's the funniest thing . he 'll like say he 'll say like mean things about the transcribers . he 'll be like like sometimes he 'll do that ,  but sometimes he doesn't . and sometimes he 'll just be like "" here , transcribers , try transcribing this ! "" like , "" "" right . li  the digits task . we ",,
Btr001.A,"can somebody explain to me why you do digits ? i still don't really know . i 've been writing the numbers just cuz i wasn't what to do . you don't have to ?    where 's the little things that 's supposed to say "" transcript l dash blah blah "" ?           joel . i almost started laughing cuz you were cracking up . he you almost made me mess up . ye he almost made me mess up .   bye . i love you , man . ",,
Btr001.B,"just put your name on it ,            euh . euh .      really ?   seems like i always have to cut off pads at the end . i don't have much problem at the beginning , but . no , of n just nothing .   unlike like a "" tuh "" or a "" kuh "" that just stops .      i don't ever have .   they used to .   i didn't get one either .       i kinda did too .      or if they 're breathing loudly .    it 's really a laugh .               like "" you can see you might be wrong , but i don't want to actually say that . ""   hm          we are meant to be transcribing if they 're just left in the curly brackets ? and sometimes they don't .    i see .     can i ask also ? it says it looks like the groupings are important , but some of the transcripts i 've seen they don't have any commas or breaks , it 's just a string of numbers . we should be adding the breaks if   but if you can clearly hear pauses and there 've not been transcribed , we should be adding the commas or not ? though the one i 'm working on now is like that .  it was hard ! it is .  ",,
Btr001.C,"     some of them just occurred over and over the again , like pda . like that got easy . there was a bunch of them that , they just kept getting repeated often and often over and over ,  just got better , but .  no . right . right .    can we give names ? we w we probably shouldn't , right ?      he got easier though , because he started like he would say certain words over and over , and  when he said "" sign yah "" , and it sounds like "" sign "" , he was saying "" signal "" . and would transcribe it as "" signal "" . "" meexe "" , "" meese "" , "" mees , right .    he was never like it was never up to like a native speaker , but like that it got a little easier .  i remember in the beginning you had and you were just sorta like you were beating your head against the wall , but i it go but it got better , it got better . i know . i remember .  or in quebec , right ? in canada it 'd be it 's different . a lot of the pronunciations are different ,  castillian ?    right . right . a big im i tha the transcriptions improved immensely , like exponentially , after it was able to isolate a single person onto a single channel .  there 's no question .   no . no . no . and you had to mark interruptions by a slash , right ?   what ? there might be a gender thing there , though , too , cuz as women it might be easier to differentiate there were fewer women , too , but i wonder if a man transcribing all the guys would have had like if you had transcribed it you would have had an easier time differentiating them ? i don't know why that would be true , but you wonder if there 'd be like a gender difference there ? i don't know , i 'm thinking about it as like a psychologist i suppose . anyway .    it was ea it became much easier .   right . right . which wasn't as hard . it took time . it took time . i find that i have to adjust the time bins a lot anyway .  not for the end of the utterance but for the beginning . sometimes the beginning the person started to say something , it 's a very slight difference , and then the time bin starts . you have to just move it back a little bit . and besi and you mentioned at some point that you wanted a little pad of time anyway .  don't have it just start ,    there 's nothing going on . for the non linguists , what 's a fricative ?  i see . i see .  right . got it . ",,
Btr001.C,"'m the only non linguist . right , you      right .  right .  i it never occurred to me , but now that you 're mentioning it , n possibly . right . nelson 's the only one who , morgan . you guys call him morgan . he 's the only one who ever did that ,  he does it a    that 's true . that 's true .    right . that came up a couple of times ,   it 's rare .  hnh . it should be . i have something in the morning , which i don't normally have . i don't remember off the top of my head when it ends . i 'll let if it 's it 'll be a problem but it should be two thirty should be late enough .  no . except we 'll miss treat time . we could have like a half hour , then take a little break , then come back and finish the meet little bit of treats . it 's not gonna be birthday cake ,    right . yes . right . right , "" laugh , period "" . something like that , right ?  they 're not linguists ,  i don't know if i did one .  those show up in tigerfish too , cuz 've had a couple of tigerfish where i 've had to break them up . a couple were .  and i had to sorta break them down . right . right .   makes it really hard . right .  they don't do they know the names of the speakers ?  cuz y cuz sometimes there 'd just be interesting things where there 'd be a misunderstanding about like like morgan would be speaking but it 'd be on your channel , and it 'd be like , "" this is clearly not a woman speaking . "" it 's like , "" how could they do that ? "" it 's like now it 's it m seems more reasonable that they 'd make a mistake like that if they had no idea .  i liked transcribing .     if it sounds like a yawn . i 've transcribed yawns ,  you can hear , there 's like .  it , like something like that .   or when it 's a laugh . often in the tigerfish there 'd it would si say "" breath "" , but it w it actually seemed more like a laugh .  cuz everyone 's laughing . someone has just said something funny and everyone 's like , "" ha "" .  right , it 's not a very committed laugh , but it 's still a laugh . it 's like "" 'll laugh cuz everyone else is laughing , "" i who knows , but but it should be "" clear throat "" , fix that .  know who you 're talking about , but     wanted to liz looked like . i 've never gotten to see her . ",,
Btr001.C,"she 's got a voice . i know she 's here , i know she 's a big part of the institute , right ?   i must have , don't know who what she looks like .  she 's got a voice . but anyway . it 's if we say things about these people , right ?  right . all you hear is the squeaky pen , and you 're like , "" no , something 's going on that i don't know . "" you guys talked about doing a videotape . the   cuz i know it was mentioned . also having a meeting where you all wore blindfolds . li it was liz 's idea , wasn't it ?  there you go . i would just be worried that someone would cheat .  it 's like a prisoners ' di prisoners ' dilemnas game , where everyone 's wearing their blindfold but someone could just cheat and look , see what 's going on .  someone just leaves ,  gets coffee , comes back , and no one knows .        or giving permission ?       right .  what does he say ? why ? no . woo hoo ! let 's do simultaneous digits . no , let 's not . no , let 's not .  i remember i did that a little bit , and , you must have too . kinda early on . they do write the numbers in .   no , i agree . it 's at the top . i have a question . cuz now i 'm looking at this and i realize i don't know the answer , is ,  sometimes when people are reading "" zero "" , they say "" o "" , and sometimes they say "" zero "" , but and that there must be an indication here .  that "" read o or read zero "" . my !   you 're not used to seeing the numbers like that . i see , that 's why . it 's optional . you can say one or the other ?   i don't care . whatever .    right . aw ! i 'm just happy i didn't make any mistakes . that 's why i sat back here , i was like , "" i didn't want i don't wanna look at you people . "" to read it . no . that 's the killer . alright then . sounds good .  signing off . ",,
Btr001.D," one thing that i remember being really difficult at the beginning and it got easier as we went along was , acronyms and technical terms . because there are many and it 's a field that i 'm not really l very i don't know , i don't know very much about this computers and speech recognition . i 've never taken classes on it or anything , i found that really hard . and i remember transcribing and having a bunch of every five words there 'd be something i 'd put in parentheses cuz i didn't it was .    but it 's definitely gotten easier because the same things keep getting repeated , once you learn what it is , and you can say , "" they meant by that "" or "" i know how to spell that now "" like that . and the cast of characters that you put up on the web was helpful also .  especially when describing like the set up in this room , also , and the different types of mikes . i don't know . and it 's hard to tell when people are talking relatively quickly . they just glide over some of the letters . they don't fully pronounce them . you can't really tell even if you listen to it ten times @ @ what it is .    even though i still don't they are . i assume they 're microphones of some sort , but that 's all .  about the microphone ? i can't remember . he 's e he said that they were designed for a specific sized head ? right ? and if your head happened to be that size , then you were fine and if it w was bigger , then it was like torture , o or i don't know . i don't know .  it doesn't look bad , but , it depends really . hm that 's interesting .   for me i found the spanish speakers to be the hardest . and the german speakers i found a little bit easier , and that was because i had i took german for a semester and i 've had exposure to german , because i had a lot of friends who were really into germany and german language and but and i found that i could if they were pronouncing something in a certain way i could say , "" that 's just the german way of pronouncing this "" and then i figured out what they were saying . but with the spanish speakers it was i 've never taken spanish , and even though i 've taken french , and i speak french fairly i found the spanish to be much harder and also because the level of fluency for the spanish speakers was a little bit less than the level of fluency of the german speakers that are here ?  there was a couple of different spanish speakers . that 's really interesting .       ",,
Btr001.D,"he was hard .  and you got to know his pronunciation of them . i remember , i remember that . and m the way he said "" mixed "" was really strange , too . "" miss ed "" or somethi   he  especially because also in the beginning meetings , he 'd say something and no one in the meeting would understand , and then everyone would say , "" what was that again ? "" and then they 'd pronounce it in english and could figure out what it was that way .  like his english fluency got better ? i went crazy . i would skip doing that portion for as long as i could because couldn't deal with it , and  and they won't know .     i have no idea about spain , but i know that in france parisian french is much easier for me to understand cuz i learned it versus france in like marseilles or in the south or in like the provin like the villages in the south , it 's really hard to understand .  much different .     and isn't it catalan ?     that 's really good .  cuz that 's definitely something that i wouldn't have be able to do .  there were problems even with , am english speakers though . not in their level of fluency , but in some people tend to mumble , and and it 's hard to catch what it is is , cuz it goes by really quickly and you can't really tell and that too . that too .  or just i don't know . and some people tend to get interrupted more , i know that 's not something that the person themselves can control but   especially when they 're when you were using the l the mikes that weren't m headmounted mikes . and there was input from other people on the same channel as the person who was talking . and that was really hard to deal with .         no , it was one like one ribbon for everybody and you had to you could switch signals , like you could listen to a different one , but you couldn't really could you ? did we didn't do that very much . you couldn't visually do it , no . and f  and it was very hard to be precise about it , and it was very hard to tell i had much trouble at the very beginning trying to figure out who was who . cuz there 's m many men and few women . the women were easy to f figure out who was who , and then the men all their voices sounded the same except there was one british english speaker and that was easy but   an easier time ? that 's possible . i don't know .   it 's interesting . i don't know .  but it definitely got much better when that change happened .   that took a l ",,
Btr001.D,"e no . it just took time . me too ,   that happens a lot . then to have it be cut off .  shrink in them or whatever ,  of breath or of nothing ?    with fricatives a lot . although i found one in actually i was just working right before this meeting , one where someone said , "" great "" and the g it was pronounced as a k it was unvoiced and then part of the r was cut off in the beginning . and then you it sounded like "" great "" if you just listened to that time bin it still sounded like "" great "" . but if you listened to right before it you could hear a little the k or whatever and a little bit of the r .  i don't know . usually it 's not usually that doesn't happen but this time it did . or "" sss "" . or but it 's not completely blocking the airflow .    it does . completely .  i don't remember the words exactly . it 's a shame . there was one that was a whole sentence was broken up in the middle , and there was a little like millisecond of break in the middle . and if you connected it all together , it completely changed what was right before it and what was right after it . it was written as something else , and then it became a word together from what was before and after and then with this little tiny millisecond pause . guess i don't know . when we talk in between different segments of the word there 's pauses somehow ,  or the you can  like that . it 's probably like inaudible for us but and the pause was just short that it made up a pause . i don't is it that doesn't make any sense , but .  on purpose , though . or not .   that is true .   how it was really pronounced ?  i always get confused with the pronunciation convention . i get confused with pronunciation , like when there 's a strange pronunciation that i wanna mark . because m may di in the beginning did we do the strange pronunciation and then write prn and what it really was meant to be ? and now we 're doing the normal word and then inside the brackets what it sounded like ? we did a switch , right ? or not . i don't know if it 's just me that 's confused or if it was swi   the convention as it stands now is write the word as it is normally conventionally spelled in english with the little apostrophe , or whatever you call it , and then "" prn "" , how it 's pronounced .    he does it a lot .    or "" a "" versus "" a "" .     ",,
Btr001.D,"there 's a study done on when people say "" and when people say "" . also , there 's contec in concet contextual variation , and it 's predictable i haven't read the it 's really interesting .   what 's on that similar topic , thought of something that 's been hard for me sometimes , is you can have a pronunciation of the word "" a "" as "" a "" . and then you can have "" like a pause or whatever as "" , and sometimes it 's hard to tell what the person meant . are did they mean "" like they 're pausing or did they mean "" a "" like "" a person "" ?  and you can tell from the context but sometimes it 's hard ,      like you can't tell ,   a few . it 's really  relatively rare .   can only think of like two or three occasions where i sat and thought about it for a while . other times just you figure you look at it and what 's the context .  it 's i don't know .  this time is fine for me .  then you don't have to rush . hnh nn . mistreat ? what we could do ? we could just ask the someone like the front desk person or lila to like set aside a little bit for us . we 'll survive . that 's fine too .     and they put paren not parentheses . what 's it called ? punctuation after brackets .    no it doesn't to me either but . no . no . i didn't either . it was a little bit faster than just transcribing it , but i definitely saw a lot of there was a lot of errors that are not in the tigerfish ones .  and they just have better intuitions , or i don't but , about what 's said . if it says "" tf "" . and we had to split them up . where they have li but they 're not like they 're not huge , though . really ?   i don't know .  but they don't have that option .  and they don't one person doesn't listen to all the channels of one meeting , right ? they can't get clues from the other channels ? or can they ? i don't know .       as there are slots in the pre segmentation .         god , it must take them a really long time to do these . that 's amazing . it sounds hard .   leak their secrets ? i i definitely prefer not doing the transcript i liked transcribing because i felt like i was much closer to the data and i had a lot more ideas , like you were saying , hypotheses of what 's going on and but it took a really long time and i 'd get frustrated with it . and that i would lose my i don't know , ",,
Btr001.D,"i would not be as thorough , not be as careful .  it was more personal .    you don't tend to notice as much i don't think at checking as you do transcribing , because it 's already there you don't have to pay as much attention . and time bin corrections and things ,         one thing that 's annoying with checking is that a lot of times in the meetings you tend to have one or two people who talk a lot and the rest of the people just sit there until it 's their turn to give their little report or whatever . and yet you have to check the channels for if they did backchannels or if they did other things that you need to encode that weren't on the pre segmenter . but sometimes it 's not visually easy . and i 'm sometime i debate with myself whether it 's really worth it to sit there and listen to the whole thing or risk missing a little bit and doing it visually . it 's hard to decide sometimes .    and s  that 's the thing . i that 's the thing that makes it harder sometimes .   the transcribers ?  and even bigger things . you 've said things that weren't caught on the pre segmenter , like whispers , just like , "" that 's interesting "" , like that .  you 're about to s speak . but then they don't .  and sometimes even laughs .   i don't either . m but , don't take them out if they 're already there . i don't     but it 's a laugh .  and you can and everyone else is laughing , and then the other person is like "" ha "" but it 's not a actual laugh , but like i don't know how you do it ,      in between the segments that they did transcribe ?  that 's where you f tend to find   it 's it depends on the person , some people don't tend to do aren't that involved in the meeting , and they don't tend to say as much , m backchannels or whatever . and some people  i remember transcribing one person , all they did was clear their throat and breathe . and then read digits and then it was like the end of the meeting .  but then some people tend to   but then there are some people who are even if they 're not actually speaking , you can tell they 're more involved or interested cuz they 're always , "" really , reacting .   right ,  i remember from the very beginning , i would go to tea and start recognizing voices . and like turn around and be like , "" that person doesn't look anything like i imagined them . "" a nnn .  nn  she always tends to get interrupted . it 's really makes it a lot nicer to transcribe ",,
Btr001.D,"because there can be a lot of heated discussions about these very technical issues and people will have their opinions and , and then you can it 's really to have a little bit of humor , a little bit of break away from that because it 's hard to sit there and li see like , "" but , don't you see h you 're being rude to this person , you 're cutting off this person and it 's not ""    you definitely get an image of especially if you can relate it to what the person or y what you assume the person is interested in academically . it 's really   and there was a whole set of meetings that are like that . it wasn't there ?  those were really hard . really hard .  and it 's hard   u no .   what would be the point of that ?  that would be really interesting . right . that 'd be kinda creepy .   that 's good . that 's  it 's i had something that i could bring up .  as far as ideas about looking at the data and getting ideas about whatever you said hypotheses about how to figure it out . one thing that i 'm you probably don't remember this that i was really interested in is the use of "" and the use of "" or "" . because the way people use it in these meetings , i found , was i don't know if it was it if it 's different than other people . i don't know if it 's a computer speech thing . computer people speech thing , but people tend to end utterances quite often with "" or "" and trailing off .   and i found that really interesting , and i was curious to figure out when that happened , if it happened in certain occasions and whatever , and i never really got around to it , but . it didn't sound stran it doesn't sound like bizarre enough that i don't understand . but i don't think it 's something that happens in just everyday speech really . really ? really ?   like that you 're flexible ?  but it tends to happen "" tends to happen when the person brings up a new idea that goes against what the other people is saying . or at least that 's what i found . like if someone in a meeting is talking about a certain thing and someone interrupts or doesn't necessarily interrupt and says something either a new topic or a different take on the same topic will tend to use will trail off with "" .     and "" or "" tends to be used with questions more than but . that was really interesting . when you end the utterance .  right .   i 'd definitely like to look more at that if but .   "" but i 'm not really you can you could finish my thought . "" ",,
Btr001.D,"it 's a different shrug though . it shows less of confident like less confidence in what they just said in a way .     more similar than to ""  or it 's just a link to get back to the conversation like to connect it with what is going on elsewhere ? like laughing with it in a way ?      it means that .  if it 's when people don't laugh enough i don't know . right . giving them permission to i don't know about permission . to keep going with the meeting .  cuz sometimes you can get on digressions that just last for like minutes at a time . and people are just hysterical and they 're like , "" what were we talking about ? i don't know "" . it 's hard when people get really in like into their laughing and start talking at the same time . it 's hard to figure out what they 're doi what they 're talking about , and also they don't tend to talk very f there 's a lot of disfluencies when they 're laughing and talking . it 's hard to   "" but i don't mean the transcribers we have here ""  like when they do random sounds that you have no idea   my god .   i did that once too .  the  i 've been just leaving it .  that 's what too .   but in the transcriptions we don't have to deal with that because when the other interface deals with it then they break it up or whatever .   are we gonna do them together then ? or no ? whatever .  pause briefly between lines .  no . it is , it 's hard . good .  you did ? good . unless we hear from you .  ",,
Btr001.E,"  i usually put most of the acronyms in parentheses cuz it 's safe , cuz people can say their acronyms really fast and i figure that even if know exactly what letters they said , it 's probably best to put them in parentheses cuz i probably don't .  right .          if you 're talking about who you 're talking about are you talking about  o can  is that  there 's one in particular who i find the hardest to transcribe of all , and it 's d she 's spanish .  and , and i 've taken lots i 'm fluent in spanish , and when i correct it , tay tell that the person who , transcribed it before me probably didn't speak spanish , cuz catch a lot of things like "" no , that 's not what she said "" , tell she 's pronouncing it the way that if you read it from a a spanish speaker 's mind that you would , pronounce it the way that you would pronounce it in spanish . but the same time , can't get most of it , cuz i i find it one of the hardest ones to transcribe .  right .    "" miss ""      i don't know .     the last one i did she actually said a lot , and it was kinda it was very hard to transcribe . you kno it was i j think that , her fluency in english wasn't wa wasn't very high up there , it was really difficult . but , i did find that knowing spanish helped me a lot . i could tell that a lot of things that the other transcriber had put in parentheses , i was like , "" see how you couldn't understand that "" , but i c i kn she 's doing . know the mistake she 's making . and  in german ,       you guys didn't have o one channel per person before ? what ?  that 's difficult .     i always adjust the time bins . right .   i always wonder about the , time bins . i usually ended adjusting them a little bit  definitely when something 's cut off at the beginning or the end but also sometimes there 's just like huge pads of , air before and or after , that i don't really feel is necessary for that segment , and i usually , shrink it a bit and make it a little bit just nothing ,    or "" thh "" . it 's a sound that  and you can keep it going a little bit .    i like that . that 's fun .   would you want , a transcription of something like that , of a big pause in between in the middle of a word ? or just leave it as , "" fascinating "" ?     right .  i  and some people just say , "" "" s   really ? i was trying to figure that out myself a couple times , ",,
Btr001.E,"and i couldn't get anything . i kept looking the "" 's "" and "" 's "" and i was like , "" this would be hard to do . ""  really ? i don't usually get con right .     right . this is a good time for me . no .    that 's some good motivation to not start a half hour later .   that 's fine . i don't have ever done one from an external i th i feel like they 've all been done probably by another transcriber here . t m then have . the o one i 'm working on now . they have different definitely a different style , right ? do they end all them all in dots , like dot ? and they capitalize like every single first  then i 'm doing that right now .  which makes no sense to me . like "" that 's not a syntactic part of that sentence "" .     which are what are the two differences ? i 'm not do i have a tigerfish one right now ?   don't 've ever the ibm ones were the ones that came in huge , huge paragraphs , see , i never got one of those . right ,   i didn't g ever get one of those . no . i 'm glad i didn't . ye they 're not remember , u i used to see do they get them , id is they don't have like an interface , right ? they just   they just have it segmented . you can tell because sometimes they have it wrong and it 's like , "" if you had just listened to what was before "" . but they don't have that . i figured that they didn't .   right .   they hear all the channels at once like you guys were saying you first did ?         i kinda miss it . i liked  i liked transcribing . i i feel like it was , more personal . i was the n this is just , correcting other i feel like i 'm just like correcting a test now ,  that somebody 's already done , and but , it 's still but , i did like actually doing the transcribing a little bit more .   and when you 're , just checking you 're usually just looking for certain things that are gonna come up , and i usually assume that , the words are mostly right , although i g i go through and i look and make all the words are right , but usually it 's like , punctuation and capitalization and other things that i 'm end up changing . and time bins ,  really ?  right .   right .    sometimes when you crank up the visual all it gives you is the background speakers .    the but also if they have it all pre segmented and they can only hear the segments , they often miss what 's in between ",,
Btr001.E,"because they didn't even have the option of listening to what 's in between .  and the segmenter usually misses little things like "" and "" and  sometimes the segmenter will    i usually take out i usually don't put in any of the breaths unless they 're laughs . i usually don't transcribe the inbreaths or things like that .     it 's a laugh ,  right .  i 'd fix that too .    you find little lost words in the middle .       i haven't seen most of them .       that would be interesting .      m   i don't right . right . it 's like you guys can take from here ,  somebody build on my thought . it 's are you people also do it with "" but "" .  that 's true . u nnn . ending with "" . when you end with "" . when you say something right , and you say "" . it  it 's people end in "" but "" a lot too . and i feel that means that they want somebody else to take it up ? or somebody just like take it from here ? "" blah blah , but . ""   i feel like it asks for somebody else to , put input in now .    right . it may almost have to do with like , "" i told a joke , now everyone 's laughing , and now it 's common courtesy i 'll tell everyone to stop laughing ,  you don't offend me about how good my joke was . ""  it 's almost like , ""   my joke 's over , you can stop laughing now "" .   because it 's like how do how much do you laugh after someone 's joke to tell them how much you enjoyed it or  or how long do you after the joke to right .  definitely . sometimes they make me laugh hard , because they 'll just be talking about something technical and i 'll be bored and then suddenly they 'll say something that they only just chuckle at and then i laugh at for the next like twenty minutes because it 's funny . like one time everybody was doing the , digits , and they were all doing it at the same time , and they started off shaky , they were like , "" do we wanna do this at the same time , that 's @ @ wh let 's not all start laughing "" and then they all did it at the same time and one person ended up at the very end doing the digits and everybody had finished and he had like two more lines to go , and when he ended somebody turned to him and went , "" you lose ! "" and kept laughing and laughing .    really ?  it 's right here , i looked for that too .    right .   pause after each line ?   alright . ",,
Btr001.E,"eight three one , seven six , three nine , and i only started laughing when i had one batch of numbers left , and i couldn't get it .  i it just c it is . i finished my last one , it was really hard though . i got all the way down and then the very last one came and i was like , "" i haven't laughed . "" and then i was @ @ . and then couldn't help it .   sounds good , alright . ",,
Btr001.F," w would you mind telling me again , he 's gonna write it .  now , if the batteries were to go out during the meeting , there 's really what do we do ? do we have batteries back there ?   and you 'll be in your office during this ? very much . lot . appreciate it . could you close the door for me   very much for coming .   let 's see , as the meeting today is to , @ @ benefit from your involvement in the data , all the things that you 've been exposed to in these many months . and put down some ideas you 've seen some of this in the email that i sent out earlier . and , none of these are not obligatory toca topics but they 're just things that might be useful to discuss , just as a way of organizing the discussion . but if there are other topics you 'd like to discuss that 'd be great too . alright ,  it struck me that , we could start out with some general thing about , things that you found easier or more difficult with respect to transcribing or checking or using the interface or , dealing with the time bins or any aspect of that type . and then , talk about specifics of the data and then talk about , aspects of the conventions and then the technical set up regarding the , auditory image and the interface .   we could just , start with issues of the @ @ the tar ti up there at the top of what did you find easiest or more s most difficult about transcribing the data ?  parentheses , meaning uncertainty .  is  good . it 's sorta like a foreign language , isn't it ? it 's you have these specialized terms for things that i didn't know n needed specialized terms .     that 's not a bad strategy . i it 's true that i always check the parentheses at the last stage and those are pretty easy to clear , in terms of when they 're in context . not a bad strategy .  yes .  i suspect in context . and also when you have the juxtaposition of pda and pzm then , you @ @ in context you can tell which one it 's is probably likely to be the one that you had . these here are the p z that right there . you 've heard , the "" crown of pain "" . no . he was telling us , before the meeting that , that they 're not in circulation right now , that they 're they were unpopular . i liked them , and adam liked them . the quality was good . what what did he say ? he said some more things about that , but i was n i was working on something else .   that 's right . that 's right .  ",,
Btr001.F,"it 's i liked them . and there 's the actually , there 's the picture of the crown adjustment on the wall right there . it hooks over your ears from the back . good c   now what about accents ? do you have , did you find any p   what 's you 've studied some languages , which ones do you are you studying ? it 's more of a romance direction , or ?    it 's not really you 're not really exposed to german very much . interesting . interesting .   i it 's a good question .  and i can't really answer that .  that 's fascinating . what you can see is that it 's her lack of english fluency that 's being that 's really interesting . i do find that the german tends to be easier for me than s than the others because of my c exposure and interest in german . but , i suspect you haven't because this was , earlier on that we had a lot of actually she was in the middle phase i would say . we had another spanish speaker who was earlier who was also difficult . but that 's really interesting . yes . yes yes .  ex exactly . "" miss ed "" .  which was you could predict it , if you knew look looked back at it , they  interesting .  i had the same experience . sometimes and actually sometimes when people lack a certain level of fluency you can ask them themselves , "" what did you say there ? "" and they can't tell you . s it 's general variability when it 's not when you 're learning a language and you haven't gotten to a certain level . i also wonder if it 's partly that span spanish has different pronunciations in different regions ? do you think that , that , being not that i would know that . but wondered if ,  she was from probably continental spain versus @ @ y other spanish i wonder if that would have a contributing factor .   that 's right . and in my case with , german w i a certain region that i do in and then get farther away from that region and i notice it 's more and more difficult .  but she was also very low volume . and , and didn't say a lot . i c i agree . this was a difficult person to understand . but . imagine that ,    i couldn't do it in spanish . i 've i found myself doing that somewhat in german .   that 's right . or they 're laughing when they 're talking or they 're    we had lapels for d l brief and then sometimes people would wear these around their necks , which would mean really a problem that you 're saying of getting input from others , ",,
Btr001.F,"and also , it varying when they change their hea w head position .  but excellent . good to know . s that was you 're talking about early on , the change fro into channeltrans ?    that 's right . overlaps . that 's interesting . it 's possible .      it seems like it 's related to this production idea . how you internalize what you 're externalizing in a way , but .  in the prev you 've also gone through they 've been here since the beginning . you 've also gone through the use the int in introduction of the pre segmentation , and that thing . initially they had to actually mark all the time bins themselves as    i see .  it doesn't hurt to have a pad . it 's nicer to have a pad than not , d but s don't have to be really don't doesn't have to be     i  have you i 'm hybrid , i appreciate having them do this ,  in did you have you run into places i 've run into a couple where actually the word was different when you adjusted the time bin . have you had that happen ? that 's fascinating . it 's really a kick .  there are some times when there have been words that they just pause right in the middle of . you 're i it 's h  it ge u i 'm sometimes on purpose , but sometimes it 'd just be s saying something and especially people who have really lo elongation in their style , and they say , "" that 's really fascinating "" it 's not a great example , but and  there 's it 's funny how , i it 's funny to me that th something like that , you just change one little boundary and suddenly the whole meaning changes and i 've run across that also . what i 've done i 've it 's very rare . when i 've run across it . and , there are times that i haven't detected it and i 'm not @ @ fin i haven't looked at everything . i 've looked at i 've probably looked at per at least eighty percent of the data , all the way through e every meeting for about eighty percent of the that i 've cleared far . and , i it s you guys are getting good that it 's like i 'm get through them faster , and i 'm getting to the point where i don't have to go through them all the way ,  it 's like it 's just we 've gotten to a level , it 's just really great , of , of pre precision that it takes a lot of a load off of me . and , and 'm not gonna be checking them all i don't think in the @ @ for throughout the whole rest of the project . but , ",,
Btr001.F,"certainly have spot checking . but , hhh , those that i have found that way , to me , the most sensible way to handle it from my perspective was to treat it as a pronunciation situation . just do a a mark , then "" fascinating "" , and then put "" prn "" and interrupted by a pause "" or , some other gloss like that , "" p r dot fascinating "" , whatever it is . what was this ?  i 've there was an adjustment , and i and i 've switched them all the way at this point that   that 's right . and then in the brackets , what it  "" is a very e easy example . a person says , "" then , it 's "" with a ha a little hatch and then , "" prn "" and then "" m , or whatever it is in quotes .  that 's right . and mean , there 's also this other reduction that w that we 've done in terms of like not capturing every time a person says "" and "" versus "" nnn "" versus , "" nd "" , whatever all the different ways of reducing "" and "" . because you can assume that the speech recognition , pronunciation models will handle a certain amount of reductions of these types , and the same thing for , the "" . "" the "" versus "" the "" that there are those known variants , and exactly . and that they should be able to handle themselves , and that we assume also that for discourse purposes , those distinctions are not really the focus right now , and those distinctions could be added later if needed but it 's unlikely that they would be . and it 's time consuming . we 've made these simplifying assumptions with that , and then you begin to think , "" what about "" ? is an appropriate variant for "" and it wouldn't be necessary to mark those either , it 's definitely there 's a , choice of how far you go with that , and whether "" is enough of a variant it 's th this is a case where , i appreciate it when people mark those kinds of things but i figure that i @ @ that 's not as far aw away from "" as "" is , it 's not quite but i don't change it back if it 's there ,  yes .    interesting . that 's interesting .     once in a while . yes . i i agree . and when i 'm in doubt , if there 's a case where it really could be either , and i could flip a coin , i 'll choose the one that would make syntactically the most sense , give them the benefit of the doubt that they 're being fluent about it .  it must be really rare though , ",,
Btr001.F,"i haven't run across that often . ha h is it rare ?  le let 's see now , there 's another methodo what i go i wanna ask you at some point , it just occurred to me , i 'd like to ask you the following question , you can have this in the back of your minds , something like , what sorts of hypothesis your hypothesis about the ti trying to find the distributional explanations for some of these things . what hypotheses have has this caused you don't wanna have you give away a paper topic that you wanna explore , but , if there 's interesting th hypotheses that the that y have been suggested to you by looking at the data . that kinda thing , at some point .  and al and i also wanna say , that , i 'd like to meet again also next week , and i don't know if this is a good time frame , it 'd be good to have it an hour later or i don't know could do anything about good time for you ?    excellent , cuz we could probably move it one hour later , unless i see .  you did really  did you ?  would anybody be constrained by having it be a full half hour later ?  and th the final question i that 's right ! she said "" mistreat time "" . that 's that 's an interesting hey , they would . they would . that 's not a bad solution . that 's right , it 's already done . it 's good to have these things all scheduled .    then i was gonna ask you , what about an hour later ? if we h had those things an hour later like , would people  good . alright , i 'll settle on that . now , i wanted to say , you 've been through a couple of different , @ @ improvements in the methods , the pre segmentation . there was another impro another improvement in that s let 's ask if it was an improvement from your standpoint . the tigerfish , approach .  s moving from having the first transcription done by an external service , and then you correcting that versus doing the initial transcription yourselves . ho how have you and think you you did you has there already been t ibm or if it was dash tf , that 's the tigerfish .  there 's a lot of that .   that 's right too .   exactly . exactly , i 'm glad you exactly .  good to know . that 's helpful .       i 'm not if you had an ibm one . this was earlier on . you probably do . you didn't get one ? interesting . no . in neither case . ",,
Btr001.F,"and i 'm thinking i 'm thinking you 're causing me to think back over what the differences were in the what they got and ibm didn't  there 's also some i iffiness about how d if we 're not really how tigerfish does it , the methodology . how do they do this . because sometimes you 'll have the s the same word , and i 've seen this within within a single turn , l it 'll be spelled in three different ways . and it 's like , is this the same person who 's forgetful , or is it that they have several people doing it together ? it 's parallel . they 're all doing it in parallel and one falls behind and the other one but , who knows ? the way they 're listening to it is they get a they get it 's linearized . if you picture what we have on the screen , there 's this block and it goes over i 'm doing it from my perspective . you have this block and it goes over to here and stops and this person starts to talk and he goes over to here and then you have an overlap over here . and what they would get is this block from the first guy , this block from the second guy , and then the top of the overlap and then the second guy in the overlap . and then it would move on . it 's like this you go this way as much as you can , then you cycle through there and then you go up to this next level and  let 's see , they hear them  they hear them separately in two chunks , but then sometimes they get confused about who the foreground speaker is , because they 're not being told who the foreground speaker is .  and especially you can see if you have like four speakers , it be reason you can find a way of doing that . but with nine speakers what they get is they get a beep that tells them when there 's something that they think that the f pre segmenter thought there should be s transcribed in there . and they 'll get and it 's numbered that we end up with the same number of transcribed slots . exactly . cuz the first time when we didn't have them numbered , we ended up with a couple extra segments that were transcribed , and it was hard to patch the whole thing back together because when it comes back to our end , it 's just this long string of things that they 've partitioned according to the tape that they were given . cuz they don't they actually don't have digital interface either it 's audiotape . and they type it on and then it comes back to us ",,
Btr001.F,"and adam and thilo have a program wa they put it back together into our interface format and then we can use it . but ,  there are f cases where you 'll get a segment and it 's someone else 's utterance and that 's because that was overlapping with someone else and this is the weaker speaker of the two , and you 'll have like two parallel r renditions of the same thing . because i it 's just i n what they get is like i t is they get something like "" beep one "" . and then they get "" beep two "" , "" beep three "" . chuck wooters does the numbers . and , it cycles through . no . and they don't know which channel is s l supposed to be together . yes , exactly . that 's quite right . and that 's why . exactly right .  they 're very fast . is l   it turns out that they 're really much faster than the other approaches we 've used , and we don't know exactly how they do it and that 's by intention , that @ @ not just me who thinks that it 's that proprietarily , it 's a very competitive business and they probably don't wanna , say too much about it .   but they 're very fast . it 's   excellent .  you miss i see . interesting . how interesting .      and this is when you crank up the visual . you 've still got the maximum  it 's true . it 's true , it 's just a big mess .  that 's right . i it 's a judgment call . and you can also say if the backchannels were limit low on volume that they weren't o visually obvious , then you can say , "" it 's reasonable not to worry about them . "" that 's tr right , that 's quite right . that 's right .  yes , i agree .  c it 's good to  it it 's communicative .   have you noticed that tiger i 've noticed that tigerfish uses "" cough "" a lot where it isn't really a cough . you notice that ?    do you find you 've i this has caused me to wonder . in tigerfish ones , do you find that where they 've where they have like "" dot 's "" cuz it 's segments they didn't hear , that you add u you probably do add things in those places where it 's where nothing is transcribed really , because they didn't even hear it .  interesting . interesting .   it just occurred to me , this is a different question , but i w from having listened to all these people , and it is ab abnormal to be listening to them as if you 're they 're talking into your ear , really . it 's this really unusual acoustic circumstances .  ",,
Btr001.F,"i end up feeling like i know these people better than i really do . and it 's like you go out to tea and there they are and , "" you were funny in that meeting "" and it has this unusual dynamic because , i 'm privy to information which really by all rights i shouldn't be , except they they signed , they were there , they but it but it 's an unusual relationship to say , i if you 're in the meeting yourself , then you you 'd have access to all this information and all your inferences about , whether they 're funny or not funny or whatever , but it that 'd be interesting . yes . he 's on campus , i found this out .   guy . guy . but he is . i went on i actually went on a hike with him two weeks three weeks ago .   guy . she 's here . i 'm you 've seen her , but   that 's no problem . i also find that some of the if someone sits there and it th there 's this o one who doesn't say much , but she just is always pleasant .  and it 's smiling voice and she laughs and what a difference .  it 's like actually it 's she 's just pleasant . and , adds a lot just by virtue of that . can people will talk on all these technical things but she 'll say something technical and then laugh , and it 's very interesting , the ambience that you can get through these little things .  i agree with you . i agree , it 's really interesting , also , i it 's a persona , you get this there 's definitely a sense of persona .   that 's right . it 's difficult . yes . it 's mainly a matter of two things . first is the storage . it 'd be huge that , you 'd wanna be that it was of interest to someone , that it would be worthwhile doing . and that 's the other thing , that we don't have someone currently doing the video thing . it would really be interesting .  that was liz 's idea . it 's a question of feedback , and being able to give feedback .  exactly .  and , mean , th that was the meeting where , @ @ the m the th y partitions wouldn't work . another possibility is pa partitions wouldn't work because then it would cut off the p z ms from having the indirect it 's like you have these unusual configuration problems that you wouldn't normally have . blindfolds . and someone else said , "" you could just turn the light out . "" but then , someone else said no , cuz there are these m special lights that have to stay on all the time ",,
Btr001.F,"for the fire code or whatever it is . but then that 's right .  there are other things we could expand on and with i in terms of the methodology . it 's to have a core set of data though and they 've d actually done some they 've had some good results in terms of the digits which they do in terms of having a r a broad set of speakers doing the same thing , meeting after meeting .  i 'm wondering ,  we still technically mean , what should we do in terms of tea ? technically if we could hang on for fifteen more minutes and have tea ? and then continue with this next week ? that 'd be great .   let 's see . yes . yes .   that 's right . do you people does everyone agree with that intu i f i s share her intuition that 's it is unusual to have "" used as a final , part of a person 's turn . it 's  i was wondering . yes , that 's possible ,   interesting .   b but that 's not really an example of this , because they don't just say "" . is that right ? s wanna be   "" i c i could get all those extra signatures , but i don't know ,  that 's a very characterization . interesting . once again a sh is it a shrug ? would you say it 's another shrug ? or    that 's interesting .   interesting . what about , the way people treat w when they give a joke , and they 're like they laugh and then after the laugh they say , "" .  if you it 's like , "" ha ha   do you have you run across this ? and it 's like , to me 've heard comedians do that . there 's some there 's something there about you make a joke and then you have an "" in there somehow , which i don't really understand the function of . do you it 's possible , now what i 'm thinking i didn't have the extra e what do you say , nuances in the "" , which you just did . however , the context fits . that 's an interesting take on it . it 's possible . it 's possible . it 's just a normal "" .  but it 's stuck in it 's a little louder than usual . it 's not any of the extra , glottal thing .  but it just seems like it 's more prominent than it really is like a placeholder of some sort , like which is self reflexive in the brings focus back onto the jokemaker , but that 's possible .  it could be . yes , po that 's possible . it 's possible . exactly who i was thinking of actually .  exactly .  that 's true , that would the ",,
Btr001.F,"and he does continue after that . but it 's just to say "" you kn to say "" while you 're laughing i it 's just to me it 's an interesting category . that 's possible . very interesting . interesting . yes .  that 's that 's   yes . yes . he 's very funny . he 's very funny . i started laughing with something he said the other day , it was the beginning of a meeting and it hadn't gotten far into it and and he 's doing this one of these mock fights with nancy , which he does . have you run across these mock fights ? and he s he says , something like ,  i and he 's m e they have this @ mutual condescending joking thing going on , and he says , "" i could explain this to you . i have a better laugh than you do . the transcribers told me "" and it went on a little longer but it 's li it 's like this really  and then at one point she at another meeting , she was not which channel she was on , and he said , "" you 're on channel and and then she said , "" no , sh shouldn't it be channel and "" and he says "" no , it should be channel and . and then it turned out it was channel and which he said , and she said he s he said , "" i bested you again nancy "" . and she said , "" yes , that 's my recollection of all of our meetings together "" . they have this really it 's really those sorts of things , i it 's true , it 's like , it really does liven things up to have the , the interrelationships .  i found that 's a aspect of a lot of these meetings , the the , little periods of humor like that . alright , do we would we could do digits if we desired . if w if we wanted to do that . let 's do simultaneous digits . no , you don't ? the idea is that you have then , you have ground truth , exactly what they 're supposed to have said , and then sometimes we go through and actually , people do double check that they read them correctly and all , that we 're as you 've done .  and you did also ? no , because it 's it should be able to be taken care of efficiently with this interface . if the t tigerfish people do it , then , leave it , that 's fine .  sometimes they don't . if you do that 's alright as you don't have to . because , we 're we have the assumption that we 'll take care of it this in this other way , ",,
Btr001.F,"but in any case , the idea is that you have ground truth , exactly what the person should have said and you check to be and usually there aren't many errors when they were checked . and then , you have this multiplicity of voices , reading these things , and you can do really good speech recognition that way . they have some papers out that they 've done this . it 's really it 's been very fruitful in terms of the analyses . it 's to have , a standard it 's like , psychological approach also that you like to have some standard stimulus here and then you can  i agree , it 's a design feature . yes , you run across that . let 's see , it would be it 's up there .  up there at the top .   yes . used to be . used to be . this they changed them . initially it was words all spelled out , one "" yes . and that was like a stroop test in some ways . it took a lot of conc when i was doing those i had to really concentrate . it was like s "" one , s seven "" it was like you really had to "" let 's see , the words and the numbers "" and and then you 'd have an "" periodically and , they were initially spelled out that way , one or the other . but we converted them to this format , and then the idea you could conceivably put an "" or a "" zero "" for the "" o 's "" and still have this benefit , but that the idea is that people can choose what they think is most natural for them to say in those locations , and there 'd be yes ,    yes . see er also , this has been a change in the procedure that used to be that they were like one long string different sized strings . but to have them broken up like this , it 's m been about half a year that this or seven months , i don't know , longer , that they 've gotten actually broken up within the line . the idea is @ @ to pause when you see that . no . that 's right , break it up more finely .  i would say don't worry about that , because , this is w again it 'd be to get the words right , but , the the interface that these guys used , allows you to set the time boundaries really accurately , it 's not important . it 's more important to focus on the words , because there we don't know the ground truth .   i don't know , how do you feel ?  what we could do is we could do it together one week and then separate the next like that to give the variety . ",,
Btr001.F,"we why don't we do them together this time just because in the interest of time , to get you out in time .   we just start out , we and you s you say , "" transcript l "" whatever it is , and then launch into the numbers and then pause between the gr the gaps and then you 're supposed to treat  you s you 're supposed to treat each line as like a little sentence . what do they say , "" each line into smaller groups . read each string as if you were giving it to someone over the telephone using the groupings indicated . yes , there you go .  here we go . ready , set , go . that 's right . it 's funny how distracting it is , it 's like there 's no content . did y did you finish your last batch ? you 're right in the middle of it , i 'm on the edge . i wanna very much , and look f and we 'll meet next week at the same time , u unless i g i need to check on the schedule but the same time or within an hour ra of it . good . great . very much . signing off . ",,
Btr002.A,"   i see . hello . mine 's good .      annette 's ? right .   right .     would you put a period after "" ? you would or you wouldn't ? yes .  right .   right . right . the second one where the "" is all by itself , it 's like , "" that would be a problem . "" the "" is like disconnected from the the first one is like , the "" is connected to the sentence , and "" that 'd be a problem , "" it 's but the next one is like not connected to "" that would be a problem "" . it 's like , "" "" less  right . i do that too . i right . sometimes , though , it does sound like they ended a sentence and then i do like sometimes it 's just like , "" that 'd be hard , . and but and then ofte often it sounds like they were trying to think of something else to say , but they couldn't really , and then they get interrupted and then i put a dash . but i never usually put period and then new word "" unless it 's like , end of the sentence and then , "" ""    right . that 's always one of the hardest parts about the native speakers , is you don't know exactly like how to do the punctuation because their intonation is different . non native speakers is what i meant . that 's true . right .   not "" twosome gruesome "" .  sometimes they p they usually put them in prethen parentheses , and you think to yourself , "" you were way off , but at least you knew you were way off . ""  "" groups of "" , "" gruesome "" . you 've got the , "" s "" in the middle . "" gruesome "" . it 's both labial at the end . gruesome groups of gruesome groups of the "" p "" wasn't pronounced very like "" groups of ""    that 's really hard , th to not be able to go and listen to the other channels and figure out the context of what it 's occurring in .          right .   right .  right .   painful .  they were painful .  and then you see it , and off with the headphones !         right .  what i would think would be a really n neat feature for the interface ? some backwards tab where it could go backwards without you having to go up and do it manually , and , press the button and "" juh juh juh "" . cuz if you miss something and you wanna go back to it , it 's such a hassle . it 'd be if there was just some like , opposite of tab that you could hit , that it would just move backwards . there wouldn't even have to be any , ",,
Btr002.A,"i know . it w you wouldn't even have to have the audio . that 's not i wouldn't  right  some some timebins are humongous , and if you miss it , you 've gotta go back and find it , and dragging it and looking for it and you may not be able to see it , even .        really ? i do that with the keyboard .  "" return "" and then and then "" shift "" "" backspace "" . that 's what i do ,  i do it all on the keyboard . really ? i don't do that either . right .   right .  and then collapse it . i did that much . that would be i 'm rather used to it now , though .  you 're scared , to hold shift down while you 're backspacing ? like  you 're typing capitals , and you 're backspacing , and you 're like "" take the shift off ! i 'll collapse everything ! "" i do that now .  or vice versa , th that backspace and the little and the th that little evil apostrophe that keeps showing up . "" i don't want you ! ""  it 's one of the backspaces on the keyboards that most of us are probably used to . you wanna backspace and you get apostrophe , apostrophe , apostrophe . t you 're like , "" no ! ""   right . i 'm used to it now too .  the pc one ? i 'm not which one is which .  like , when i first had started working i would have definitely wanted the pc keyboard , but now i 'm just used to it .  it 's the one in that corner , right ? that has the pc r that 's that one 's got the pc keyboard , and then the two on those sides have the , sun keyboard . right . yes .   exactly , exactly .  that 's true . i forgot about that one ,  right . i 'm     nn nnn . no . this was a different interface entirely ?     right .      right .         i didn't know about that . really ?   that !  does that doesn't that skips is that what you 're talking about ? if you use that i 've never used been able to use that cuz it i s feel like it skips such huge portions . we do . i d i i wouldn't i wouldn't use that unless i was trying to get to a whole different part of the  right . right .    no ?     i like those .  m the ones that where they 're talking about linguistic things , though , are great . i love those . i like those   my .    now you did it again ! stop torturing them !    had that one .   that was fun .  i don't even wanna try to repeat what he said ",,
Btr002.A,"because i don't wanna put the transcriber through it again . but they actually had a big list of things that people had transcribed and then they were reading one them one by one and being what 's this ? this ? "" and then doing the sounds , and then , "" this sound must be this sound ! this sound must be this ! "" u i had i had one like that too . i had  i had one where they were just talking about each word , and they were saying they were just describing the word over and over again , and just the q the quotes around the word were driving me crazy . when they kn knowing when to put the quotes and when and then they were talking about like the difference between "" when it 's "" a "" or when it 's "" , and at some point they were saying it much , i didn't know how to transcribe it anymore . i was like , "" i don't know if you 're saying "" a "" or "" anymore "" .  it was fun . i 'm fine .       definitely .  that 's fun ! really ? i still do that .       right .          right .              i don't 've ever heard it .     right .  that 's true .  i don't am never whether or not to transcribe , a difference with , and "" "" . like , how do you transcribe "" "" ?   w what about pre transcribing it , "" hmph "" ? what about transcribing it that way , like "" hmph "" ? right . right .  right . i it could have two meanings ,   that 's funny . "" ho ho "" ? that is too much fun . right .         right .  a lot of times , though , the breaths are , results of bad segmentation , and there 's a segmentation of nothing , and they just write it as a breath when it 's clearly not a breath . and i usually always take those out . usually , it seems like the segmenter , often just segments when there 's really long spaces , it segments random spaces in between . and th they get that and there 's nothing there , they m s mark it as a breath when it 's really actually nothing . usually i take those out . right . exactly , exactly . exactly .  really ? i always get i always get "" breath "" .      right . right .    silences are generally like not good in conversation too . cuz once you get a sil it it 's to your benefit to try to get in right when you think they 're done because if there 's a silence , not only is it awkward , but then that cues everybody to start thinking of a new topic to stop the silence , ",,
Btr002.A,"and then you don't get to talk about what you wanted to talk about because the whole subject has changed .  s      right . that 's what i usually do too .     i put in the "" x ""s . i put in if it 's , unintelligible i put i count how many syllables and then i put in "" six x ""  right . that will have to be transcribed with little , symbols . right . you 've ruined the whole meeting ! we can't transcribe any of it now ! right .   you have ? i 've never heard the swearword versions .  right . right . then again , i always think that it 's closer to stick with the "" x because it 's how effective is , the roman alphabet at deciphering all the sounds that a human can make . it 's not the ipa and it 's just , think , it 's best to leave it with "" x because i y english orthography conventions are just uncertain anyway in the first place , and , i usually only use them when i know that , the person was trying to make a word . i know that the word they were trying to say and that they were stuttering that , then i feel fine just writing out the letters . but otherwise , i don't feel right trying to write them out because i feel like it 's , you can't really you can't really spell those things with the r with the roman alphabet ,  it 's it was only set up for it was set up for a different purpose , not necessarily phonological . right .  right .   i always i often transcribe that as "" or "" . i always thought that was "" or "" with a strange pronunciation . right .  i don't get that one . right . r right .  m right .      right . right .    right . they used "" mumble "" for  right . the number "" x "" . right .    that 's fine . right . yes .  alright . right .  ",,
Btr002.B,"hello ?  hello ?  hello ? there 's hold on .        and now they have those strange computerized voices that n           i didn't n even know you could do that .  ni that 'd be good . that would be good . the little accent thingy . right .       by the light switch , ready . it doesn't really matter .        or in the beginning , the very beginning .   i wonder if like microsoft has a word for it . bling . let 's not make things hard on ourselves later .   what ?  stay .      god !  no , i don't  right . it 's something you 're not interacting with , you 're just listening .       unless you 're on , talking on the phone , and the phone is the levels are funny . then you hear it . th it 's like that .             like  i hadn't thought of that . ""  hhh .              ",,
Btr002.C,"hello .  hello . hello . that 's good . @ @ not  whoa . right .  "" ish decay . ""   right .   right .    it right , as though it 's leading into something else . bu and  i a new subject . the first one , too , is more like to me , i don't necessarily put , like a d a p a period after that "" . i might actually either put a dash after it depending on whether or not they got unt interrupted or i would even act as though they were , just trailing off . put that those two dots after it . which depending on what 's going on 'll do that . cuz to me it sounds more like they 're trailing off .  right .  period . right . that 's another thing , is i if you 're not a native speaker of english you might not pick up , because , every language has different , intonation mappings . and right . and also if you 're a non native speaker transcribing it , you wouldn't necessarily kn kn understand the conventions of english t intonation as , intimately as a native speaker might . n right . not much . no .  g group . "" groups of "" , "" gruesome "" . if you if for some reason they didn't hear the "" f "" , if they didn't hear the "" fuh "" , it might just sound like "" grou "" "" gruesuh "" . and then you would have to come up with some consonant and it 's an "" m "" to you . "" fff "" . because also , "" f "" is "" fff "" . is , "" fff "" . right . "" fff "" . because it 's because it 's , bilabial too . "" fff "" . you 'll di or interl interdental , "" fff "" . it 's close enough , to "" , you 're getting the closure of the lips . that 's what they were do getting . i don't know .   it 's because they don't realize that you 're supposed to sp do they ? they don't really realize that you 're supposed to split it up . like , they think , "" i hear it just as clearly i hear this other person 's voice just as clearly and i realize it 's not jane , and i realize it 's not a female even , but , because it 's clear on this channel , i 'm supposed to transcribe it . "" i 'd imagine that 's p that might be what that is . that 's true . they do say that m men 's voices c carry better . that 's why they use think who was telling me ? ian maddieson was talking about this , that they use male voices in , airports . ",,
Btr002.C,"because the acoustics of it just fits into the hea a hearer 's range that 's th it fits into a hearer 's range of perception , better than a lot of female voices . and that 's why they use male voices . we were just talking about that . d depending on their auditory , capabilities . if their auditory capabilities , have been , squished down like in a certain place where it would be n easier for a person with normal , hearing to hear a male 's voice , like if i 'm saying if they d if they had a some damage to part of their brain that processes auditory information , then and , i e i u if that part of the brain normally codes for , male voices , in a normal hearer , then they might not be able to . does that make sense ? like if that part is damaged . but , but if for most h hearers it 's just easier . and it 's like a certain , rough male voice too , graspy raspy ,  is better .  it 's really interesting .  right . i was just saying that it sometimes , if remember i was saying if there 's a discrepancy between fricatives , shuh "" or "" suh "" will show up in a certain part of the spectrum , and , oftentimes the "" fuh "" is like knocked out of the spectrum by by filtering in some of the older phones . and that 's why , like he that they don't y right .  i didn't get that from him , actually . i felt like , he 's saying that for our for all intents and purposes with this , it 's covering whatever sounds are necessary to be covered , like everything . that 's what i th i do too .  right . you were saying , like in the case of something with clipping , does it were you saying that , it increases to or , expands to accommodate that ? or , no ?  right . i see what you 're saying . right .    i do remember those , actually . i remember i had one . one with that and it was just , al all the time .  especially if they also got louder too , and they hit it , it was just like "" whoahh ! "" yes . take one off , right . right .  t that 's true . right . and otherwise you have to drag it . right .  i s something don't know how to do this , but when i wanna expand a timebin back or even forward , i 'll use the mouse , the middle in terms of , if , if it 's if it 's cut off , like the beginning of an utterance , i 'll move it move the line back . ",,
Btr002.C,"and i usually just use the mouse . how do you do that with the keyboard ? y you just do it that way .  to me that 's takes longer than to do it with the mouse . because you can just click y drag the line . that 's true . right , then i 'll drag it . right .         that would be great . i 've erased entire utterances before , accidentally . but then when you go to type on your keyboard at home , do you do this too ? i 'm scared . like i won't hold shift down i won't do it .  i 'm just like , "" what am i doing ? ""       but then think there 's a different keyboard on i always forget th linguine , than on , no , the other one . amaretto . i right . and it 's and i always use i tend to use linguine . but the last couple times you 've stolen linguine before get to it .  go onto amaretto , which is fine . but then like , it takes me a good ten minutes to get re used to that keyboard . and keep no , it 's really but , i have noticed that i 'll screw some up when i 'm trying to get re adj the pc ? i would vote for the pc .  or no ! i like the linguine keyboard . that 's all i know . to the left  linguine is the one in the corner . right as you walk in the door , the one straight ahead of you is amaretto . and the one to the left of that against the far corner is linguine . right .  i could get used to it too . i right .      right .     that makes sense because i cuz , if the s the resolution if it 's moving too slowly then if you were to click on some place then it makes sense that it would get confused . but if it 's moving quickly , seems that it 's covering more ground faster , don't know . i usually just don't use that ,  i tend to make it move fast . right . right . right .  that 's the reason i separate it out .  yes . because the , the waveform becomes too stretched out . right . because  it 's to have right . a happy medium , you can make that the waveform has its th g shape .  now i you 're talking about .  really ?    the little intricacies and idiosyncracies of people 's voices and right .  eah . depends on the person . that 's true .  i don't like the technical ones cuz i don't understand what they 're talking about . and 'm just and i 'm sitting there bored cuz i r i really have no concept of what they 're talking about . ",,
Btr002.C,"'m going "" "" "" i 'm just gonna listen to you . ""  the ones with liz , and you .    i li that 's why i like johno . really ? it 's funny .  that 's why i like listening to him . he 's always making fun of transcribers .   my god ! no .   right . i like transcribing you cuz you 're very polite . no , really . you 're always like "" i was just thinking about this , and this might be if "" i it 's just cute because everybody 's like , "" "" and they 'll just listen to you , they don't interrupt you , they 're just like , "" "" it 's neat . right . right . now i 'm just wondering how they 're gonna transcribe you saying that . the "" doink "" . i know . no ! joel 's like , "" i am not amused . "" aw !  right .  no .   it 's interesting cuz like , when i 'm working late at night , i actually don't feel lonely because there 's many voices in my head . no , no . while i while i 'm working here , it 's like nine o ' and nobody 's here except for me , and i 'm like , "" i don't feel lonely because there are like eight people talking to me all at once "" . i 'm like , "" . takes a long time . takes a long time . sometimes .  right . one thing i noticed is that uhhh ! there was this one meeting i was transcribing , there were nine speakers , and by the end of it , i was entirely sick of listening to the same conversation all over again nine times in slow mo ! i was going nuts . i was like , "" i cannot take this anymore . i can't listen to this anymore . my god ! "" i swear it 's like a bad dream . it 's like , "" this is keep happ this keeps happening to me "" .   yes ! .  i still do that . i still do that .  or 'll think no , n i would also be really aw aware of w how i was speaking . cuz i also tend like , we were talking about "" . i do that . i 'll end utterances with "" or "" and "" . and it 'll just be a trailing off , and i 'll think , "" man . i would be such a pain in the butt to transcribe . "" like i g  i 'll do the same thing as you do , and i 'll listen to somebody and his or her speech will be particularly idios idiosyncratic , and i 'll go , "" 'm glad i 'm not transcribing him or her "" . right . ",,
Btr002.C,"i 'm amazed sometimes that we manage to communicate . cuz people will say just monosyllabic little grunts and squeaks and things , and it means something . right . right . yes . mhh .  cuz then exactly what 's going on , what the context cues are  this is what it 's like to be blind . no visual input right . and you get much more aware of all of it too .  that 's neat .  right .   right .  that 's true . right . indecipherable . machines . the one i kn get all the time is "" tsk "" it 's it 's , like i don't know how transcribe it as i say click "" and then i say , "" it 's like a vocal gesture . "" like a shrug or a vocal some like , "" there it is "" . or , "" that 's it . "" like that , that people do that one a lot . and there was one speaker who used to do it constantly . and after a while , i started getting confused as to whether or not he was just going "" tsk tsk "" to himself , or whether he was meaning it in conversat sometimes it was really obvious that he meant it as some vocal cue . but then sometimes it was more ambiguous . like it was tough to tell , because he would just always be clicking .   this guy does a lot of single ones . just and , that 's another thing like i realize i do that too . i can't remember the name actually .  that 's a different person . i know who you 're talking about . but this is somebody differ  the one you 're talking ab  right . th i was thinking the one that you just did , like "" tsk "" . makes me think of the what people would write as "" tsk "" . as though they 're like , trying to communicate displeasure . and that  u i cu there 's at least two or three that think of that to me are very different . there 's like , that , and there 's like , the one i did before that 's like i don't know hhh .    i 'll put like a i 'll usually put a an exclamation point somehow . like i 'll go "" hmph . "" really ? laugh . right .  that 's interesting .  s i was gonna say , i put i put "" breath laugh "" in the brackets when i don't know whether it 's a breath or a laugh , which is what i remember you telling me to do that . right . right . right .  a lot of people go , right . right . try to be more careful in my speech , more often . unless i 'm really not paying any attention ",,
Btr002.C,"like , if i 'm at a party and i 'm just having a good time , then it doesn't really matter , but in n normal one on one speech tend to try to enunciate more . cuz i 've been told i mumble . and used to be worse about it . i was told by my parents that i used to mumble a lot . and also i have this east coast accent that comes in sometimes that makes it hard for people on the west coast to understand what i 'm saying . a lot of times like , if i 'm not paying attention i 'll say something that , will not really be heard . i tend to leave off final consonants , and people , n i have to be conscious of that sometimes .     right . i tend to think of a conversation that has no interruptions as being something that 's n unnatural and forced . like a meeting where , everybody says their little schpiel and people are meant to be , pretty quiet and attentive for the most part . and then they let them finish , and then somebody else comes in and says something about it .  and in a n like a friendly conversation i notice that 's not really true . like what you were saying .  that 's interesting . no , not makes sense because if you 're if you wanna speak next , it 's almost like you got y you gotta get your foot in the door . you gotta be the one who make people recognize that you 're the one who 's gonna speak next . i see .     right .   i 'm glad you ment brought that up because i actually i 'm one of the culprits that puts in all the little itsy bitsy tiny sounds in the middle of everything , because i was because cuz i was thinking you 're just supposed to write down everything you hear as closely as possible . and i 'm glad you said that because , that actually takes a good amount of time , and like pretty strict concentration to d to do that .  and i do that if it 's unintelligible , but if tell something if somebody goes "" r "" i 'll put an "" r "" . if they go "" r e m "" , i 'll go "" r "" "" "" m "" "" m "" . like i 've been doing that because like that 's what hear . and i 'm pretty damn that  hhh !  i 'm i feel really bad now . no ! i 'm  no , i 'm was and then tha that 's wha i 'm i 've heard the i 've heard the swearword version . remember that ? remember that ? it was a while back . i it was a long time ago . ",,
Btr002.C,"and i was like , "" oah ! "" i emailed you , i was like , "" m you might wanna check this out . "" i do remember that . but it was very quiet . can see how that would have been gone over by accident . it was just very quiet , like under the breath thing , that 's why it was missed . understand .  i was just saying that , 'm pretty that tell what exactly what sounds are being produced . if it 's "" er "" , i write an "" r "" . if it 's "" , tell it 's just not useful ?    right . even if it 's "" er "" , or you would keep "" er "" . right , right . right .  right . right . we add the that 's probably why you added in that , thing that automatically puts in the people 's initials .   initials . right . to fill in . i see .  right .  we did it the time we start digits ?  go .  ",,
Btr002.D,"i 'm yes . change it . i was just trying a new head position .  that 's what i was just thinking , or it was really quiet i don't know .   ugh !  i wonder if that was someone who was who had an accent ,   that 's very subtle . right .      like it 's a whole new utterance . like it 's not connected . it 's like like introducing it 's like introducing a new thing that they don't talk about .     "" what are we gonna do now , "" but they don't say that .     i would hope they would have native speaker transcribers transcribing .  no , that 's not what i meant , but that would be no , what i meant was that i would hope that , for meetings in english you would have native speakers transcribing it because it you would have more intuitions about what should be there . even if you can't fully understand the word , you can make a guess , you can that isn't completely off like some of these are , but they 're pretty rare those things , the f the really bad mistakes that they make are pretty rare  not this t  no , not "" twosome gruesome "" . sometimes , but they tend to be pretty good about parentheses .    exactly .  i don't know . you get the "" gr "" from "" groups "" , but i don't know where the rest of it came from .  "" groups of "" also "" group of , groups of , group s "" i wonder where the "" p "" went , though ?  nnn , it 's possible .  is that what it 's about ? i wasn't i couldn't u i don't know , for some reason that didn't make sense to me . but th it 's about when things are transcribed on other channels than what they 're set on ?   i 'm supposed to do it . h they probably don't even know how many people are at the meeting , or w anything .    we 're really spoiled , then , with our interface here , right ? it 's very useful .  or they just tend to sp peak louder , for announcements and things ?  they should do that at bart , too , because sometimes it 's hard to hear . those are i a w actually probably just the computer problem not the gender problem .    by filtering what was the answer here ? it that 's not the case ?  good .   that 's what it seems like . i have a question . in the some of the earlier meetings there was a lot of spikes , or what i called spikes . i was wondering what that is . i don't even know if it 's relevant or useful to know , but i 'm just curious .  loose .   ",,
Btr002.D,"cuz those ones sometimes were extraordinarily bad and pai   and like not listen to them . or just or skip it entirely .   y yes .  and you turn it down ? no , a that 's really important . that 's really important because i generally have the volume turned up to above normal volume just can hear more clearly , and if it 's like that for someone screeching into the microphone than it would be really painful . you could , that 's especially we have really good headphones , like it 's very useful in like all senses cuz it 's very good . no . or , turn up or , like  but it would play it backwards too . but just to move back , but not necessarily a whole timebin ?  or otherwise , drag it , or like click on it .  that would be useful . because i noticed i started feeling like i was getting some carpal tunnel issues . much better now that i have the keyboard st tray , but it was cuz i had my hand in one position using it all the time . and that i would it would crack a lot . it was very weird . but .  i see what you 're saying . i would press "" tab "" and listen to where i wanted it to stop , and then press "" return "" , create a new timebin , and then "" shift "" "" shift "" , what is it ? "" shift "" , "" backspace "" to c collapse it , do you drag the line ? see , i never do that for some reason .      one thing that 's gotten me into problems a little bit is having the "" shift backspace "" as the collapser . because i 'll tend to delete things , or go too far , or i 'll be holding down "" shift "" because i wanna type something as a capital , and then end up collapsing the timebins . it might be better to use a different keys  or just , but , or just to change the keys used , for that option . i 'm used to it too , but , i don't 'm that bad , but i do that too .  it 's just th right above the backspace .   did it right . i 'm actually used to i 'm used to the sun one , now . amaretto has a different one . linguine is basmati have the same . right ?   but just the beginning . which is the the pc one is the amaretto one , right ? i prefer th i prefer the one on linguine or basmati . i don't it 's called .   in the c the one in the  i could get used to i could get used to it too . am very used to i don't know . cuz i always use it .     ",,
Btr002.D,"i remember recognizing certain numbers . i don i don't remember which ones , but it was i could recognize when there was a fricative at the beginning of a number for some reason . it was like , a little bit of energy , or some whatever you call it , and then it grew really big . like "" four "" and "" five "" and "" three "" all had this same characteristic , and "" six "" and "" seven "" o both had the same characteristics to their in the beginnings . but "" six "" and "" eight "" ? "" eight "" , i remember tended that people tended to not pronounce the last "" t "" . and when they did , it was slightly farther away from the rest of the word than you would have es expected . same with "" six "" . the "" x "" , the "" ks "" or whatever , at the end . but  that was a that was really interesting to notice that .  it 's a very different interface , though . it seems very strange .  i only did it a little bit , too .     if i remember correctly , it seemed to be very efficient in the key strokes that you used to do certain things . i can't remember what they were , now , but remember that it was once you learned them , it was very neat and concise and , th like couple keys that you used .       i feel like i did a little checking on that . i don't don't remember actually transcribing it , but i remember listening to  right .  one thing that i still can't figure out with the interface , it does this sometimes but other times it doesn't , is when you click on there 's a bar above where this sound wave is , that has , n the it has a little bar of where the meeting is , like in and it goes along as you 're listening to the meeting and then it ends up the end . and if you click on that bar to the right of that little marker then it moves forward , if you click on the left it moves back . but sometimes it moves two frames or two screens , and sometimes it doesn't . really ?  cuz i noticed that a few times it would do it would move twice and then in n sometimes i it wouldn't , and had resolution set differently or i s   right . that 's what i tend to do , is i use a soundwave , but if i 'm trying to scan through a long period of what appears to be silence sometimes i 'll s ry and be sc try to scan it , but i can't because it skips . ",,
Btr002.D,"then i end up clicking on the arrow , they have the arrow at the far right , and use that sometimes .   at the far right and far left there 's a little arrow that allows you to go like second by second i don't know . not second by second , but little bit by bit , it 's not on the resolution part . it 's where you have the marker of where you are in the meeting . you have this bar , and then you have a time marker that moves along . say , you 're halfway through the meeting , it 's gonna be halfway along the line .    it 's  exactly . right at the right and left of that    exactly . we have resolution set different . cuz i noticed when jen and i have different resolutions , cuz hers moves much quicker than mine , which means it 's more stretched out , right ? i usually have it set to where it has , point five second intervals on the numbers .  i i do too , but sometimes if it gets too for me too stretched out , i 'll tend to think that there 's a break in between a pause inside of a word i don't know .  prefer it to be a little bit tighter , but i 'll stretch it in a particular place if i need to ,    that 's interesting , though . if there 's any left we can grab it . those were good .    and also that we can i don't know , that we have this shared realm of knowledge , and can laugh about things that other people would not understand whatsoever , or  i it 's really or even just about what we were talking about with the technical part , the interface . i don't know . in the very beginning .   i prefer ones that are somewhat linguistically related , cuz it 's more interesting for me .  exactly . and it 's f really hard t   i  you guys do some in the mee in the meeting recorder ones , there 's some talk of , d i don't know , discourse it 's really fun too to listen to when you give reports on transcription . cuz there are always people like , talking bad about the transcribers , and just making fun of u and it 's really funny , i don't know . it 's really funny to listen to . you haven't ? it 's really funny .  no !   it 's funny when there 's little side conversations like that , that happen at the same time too . those are interesting . and it 's really when people start getting really excited about something or angry about something because then they tend to interrupt each other a lot , and i don't know . ",,
Btr002.D,"i remember one where one person , was really trying to get something out , really desperately , and he kept getting interrupted by like three p three other people , and he was like , "" i i i "" and it was it was sad but it was also really interesting to watch , or to listen to . both .  they 're like just trying really hard to get it out before they get interrupted falls apart . i don't know .       yes . i know .   i to remembered one thing that really was you needed it was you that pointed out the problem . like you needed to be at the meeting to be able to transcribe correctly , the noise . it was adam was making this really strange noise , and he was pretending he was like pretending to r screw something into his head ? was that what it was ? y     y i had one like that where they were describing the different f qualities of "" and "" and "" uah "" and like what "" is versus "" versus "" . that was really hard .  that 's really interesting .      i don't have to be anywhere until five ,  good . man .  that 's really funny . right .    it takes a long time ,  i tends i what i noticed , is it tends to have a still , a dominant group of speakers and then there are two or three people generally who don't talk except to say their digits or who or to breathe and cough and sniff and whatever .  but that still overall you 're gonna have probably three or four or five dominant speakers .  exactly .  you 've this is like the tenth time for you , then .    man .  occasionally . like on the bus when i 'm bored . really ?  that 's funny .  that 's interesting .   i noticed a lot of my speech i don't know , i wouldn't call them errors , disfluencies , a lot more once when i started transcribing . noticed and in ge people in general , that people break up their speech interestingly .  actually . that shows a lot of how , it 's not all acoustic . there 's other things involved , eye contact , body language , gesture , whatever .  i definitely think and there would be a lot more interesting data to analyze later on , personally .   and you can really get a feel for the re interpersonal relationships , which comes into play , not for speech recognition , but for other things ,  you just have to rely on your intonation , and other things like that .    that 's pretty amazing . enhanced other senses , that 's really    that 's something you don't hear in normal speech too . in normal conversations , unless it 's very dramatic or very loud , ",,
Btr002.D,"that people click their lips are always making funny noises and      we we filter all that out .   which is a very it 's that 's how i tended before studying linguistics anyways and , definitely before doing transcription , how i tended to look all conversations , and then coming here and doing this , you have to look at speech in a more intense way .  including , every little aspect . i and when i tell people what i do here , and tell them , "" i 'm transcribing "" . and they 're they 'm like a stenographer i 'm like , "" no , i don't correct the grammar . i don't erase the "" 's and "" 's , i record all the sighs , and the laughs , and the breaths , and "" and they 're i don't know . this is a very different thing than most people can relate to , or know about .    and when you think about it , they pick up exactly where they left off , even though it 's several seconds later , there 's no glitch in the syntax or anything . it 's we 're pretty amazing machines . or creatures , whatever . that 's really   it 's like "" tisk "" .   it could be . but i noticed it more as it was not because it was always in a g the one i 'm thinking of always came in groups of four and it wasn't ever like a , single l   right . . that 's the impression i got too . no .   that 's more like the "" @ @ "" .   it could be .  me too .  it 's like "" humph "" .   i usually tend to think that it 's a more of a hhh . not indignation . something more positive . i don't know exactly wha how to characterize it , but something more    or i don't know .       that 's interesting . i noticed , i m as far as problems with laughs , is that a lot of them were marked as breaths . because a lot of people , we already talked about this last time , but but not much as , i never saw that written out phonetically , or whatever . that 's what i used to do too . you would have like "" lef laugh , breath , laugh "" transcribed ? i 've   i see what you 're saying .     sometimes it 's hard to tell .  exactly .     i 've taken out some of those .  i 'm they are . although , they did put a "" missing segment "" sometimes in brackets . i 've gotten both .   i 've seen a few of them , but i 've seen a several "" breath "" 's too .   it 's just in the wrong place .    really ?  one thing that i noticed ",,
Btr002.D,"i don't know if it 's a really a question of me being more c changing my speech necessarily , but i 'm much more aware of interruptions in conversation in normal conversation . am more careful in the sense that i don't interrupt as much , or j i 'm more aware of it when i am doing it , like that , but , pay attention more to the fact that every all the time in normal conversation there are interruptions . there 's no unless you have really aw if there were no interruptions it would sound really awkward . there would be a lot of pauses , and that would imply uncomfortability , but ,     it 's different .   but even in cases like that , even when it is see now i 'm contradicting myself , but even when it is very turn taking is very w like people follow the turn taking rules , or whatever , and don't really blatantly interrupt people ,  and i remember this actually from a meeting because liz was complaining there wasn't enough o interruptions , or e not enough overlaps , it wasn't interruptions it was overlaps , that i was thinking about . not enough overlaps . and she wanted to there to be an argument that there 'd be more . and ch what she didn't realize was that throughout the meeting up until then there had been , they were just very small , but they were there . they 're there all the time .           and then everybody talks at once . thinking about it , 've only noticed a couple times where there 's been actual silence on all channels for a period of time . it 's only been like twice .       then right .    do you remember what you were gonna say ?                   initials ? i also found that it was easier to deal with the meetings when there are speaker initials .      can i ask one more thing about these comments . we are for "" qual "" is used for things like "" whispered "" , or "" said while laughing "" , or things of that nature . i remember at some point we were doing a difference between vocal and non vocal sounds ?    very efficient . but for noise that we know is something like mike noise , like a door , whatever , then we can mark it as that and no right . or o or if it 's right .  we do need to add that one ?  that 's fine . that 's what we did last time .   ",,
Btr002.E,"everything 's the microphone adjustments , we should check would you check the microphone adjustments , is m is marisa 's close enough ? we could we look but , also , to get the do you what you said about is i is it close ? alright . but this w he 's the expert , and i don't know exactly ,  it 's interesting . hello ?  your voice is it 's like , s you can see across all the channels when you talk . it 's great . very much . very much . alright . welcome back . for coming . what we 'd do today is pick up where we were last time and go over some ideas about , i the return to the conventions , but i also wanted to , share with you a couple of the things that i 've picked up in terms of checking . and these are th these are things that came up with the tra with the tigerfish transcripts . i 'm just doing this cuz it 's interesting . i have an example which there 're a couple of examples . i have one in front of you which is the one where , u leah noticed this one where i said something and , the transcriber interpreted it as "" twosome gruesome , different sizes different this "" , and , actually what i meant to say was "" you 're saying groups of different sizes , different size groups ? ""  i it 's really enormously far away . now this could be one of those cases where the auditory was just really bad . very soft . with the microphone noise , from someone else , or an overlap , or but they 're not usually that bad , i don't think . then , i have a couple of others . there 's one , the person said , "" interesting idea "" , but tigerfish thought it was , "" just an idea "" . now that changes the meaning . it 's interesting . and then there are various ones like , "" ish decay "" instead of "" htk "" . and now this one "" ish decay "" . now "" ish "" was in parentheses they were suspicious that wasn't right , but that was the closest they could come . and , with when you 're dealing with acronyms , that 's that shows one of the problems with acronyms . is that it 's clear if it , but always conceivable . i don't remember off hand . i did check the example . and , and this would be consistent . it was transcribed as "" with h "" , but it was really "" with age "" .  and , then there are some where actually punctuation changes the meaning . this is the these are things that barbara show found . ",,
Btr002.E,""" spurts wouldn't be right "" was what it looked like . but , actually when you listen to it , it would be "" spurts wouldn't be . right ? "" a it is subtle . and yet , it 's like and instead of "" and it 's "" they put "" annette 's "" . now this is interesting because it 's like , we know that there 's no annette on any of the meetings we 've ever dealt with , but , it 's , conceivable . and then ,  let 's see . there 's one other here was interesting . this was it should have been "" the quals w the quals slides will be fine "" . this is jerry feldman . and , instead it was transcribed with "" the "" and then an uncertain syllable "" the "" and then "" all the slides will be fine "" . which is interesting . and , this was a case where the timebin was off . i wanted to bring an example where th all the slides "" it 's w started too late . it 's another case of devoicing at the initial  that was very interesting . and that it shows , these sorts of things , i was thinking it would be interesting to do an analysis of these things because that ,  if first of all , there 's this overall point that it shows a degree to which , when you listen to speech , and when you 're just , in general , listening , probably , but it shows espec specifically this to this task , that it 's very constructive . you 're not going on simply the auditory there 's a huge contribution from the top down processing , and the e different types . you 've got the contextual information , you have syntax , you have your mastery of english , and these various things . but these kinds of errors , it just shows the degree which it 's not strictly an acoustic task . and the other thing that 's interesting is , the types of confusions that happen , do preserve certain aspects of the stimulus . the stress tends to be preserved , the content word will be substituted for another content word , and , it 's not surprising that they would hear this . i 'm o i 'm often surprised by how plausible something can be with without it being correct . because it really seems like it 's and then often , i it 's , i there 's ex the parentheses are used , the person knew it wasn't really a perfect match . but , now having said that i 'm impressed by h how by how , how infrequent these kinds of extreme cases are . most of the types of things that i find in checking are much more mild .  do you wanna    in a way ",,
Btr002.E,"let me be understand . you 're saying s boy , it 's hard to ig ignoi that ignore that word .  the example is , "" that would be hard "" "" that 'd be a problem , ""  and how does it change the meaning ? what 's what are the two different meanings there ?  i see what you 're saying !   it 's interesting that there are many cases . and i agree . i th those are very good conventions . i also like w this whole point about how that y th the fact that you 're raising this , i li i like this example that , we have several things that are being cued by intonation , because if that 's a f full falling intonational contour on "" that 's a problem "" , "" that 'll be a problem "" . then i would think that there should be a period there . and then especially if you 've got a pause following it , but you don't always y these things are correlated but they 're not perfect .  non native na non native speakers ?   ideally , wouldn't that be something . i ideally it would be to have like a spaniard t tran transcribing the is that what or that 'd be i agree .  i in terms of like when you 're going through the tigerfish transcripts , you don't find a lot of these kinds of extreme cases ?   good . good to hear .  good . it 's could be . there 's also this problem that they didn't have context to constrain the interpretation , cuz   when i 'm clearing the par parentheses , i find that very useful . i sometimes i try to just go through and pick up the parentheses , see if do it just by itself , but it 's remarkable how sometimes something can be opaque , and then you go back to , the person 's previous utterance or you go to the mixed channel , or you , check on the other things and suddenly it becomes perfectly clear . it 's very surprising . very surprising . good . yes . it 's really a an odd task in a way because they 're they have no clues about how dominant the speaker is on the channel they 're transcribing . and the pre segmenter doesn't give them any or the information eith either . i 'm that it 's because of the  yes . that would make some sense .   i see .   this means that people with hearing problems would hear , one of these announcements better if it were a male voice then .   selective . is better ? it 's a wider band then . because of do you think it might be from the ",,
Btr002.E,"she asked this question last time which was , whether our system here , the recording system , may have some of the same channel restr some channel restrictions , such as they ran across when they were looking at telephone , transmissions at a certain point . cuz , telephone transmissions , there 's some filtering going on . you don't hear the full band of frequencies . and , w i asked c a couple of people and they c answer came back that it was intere an interesting it 's reminded me because of the comment about noise , noise being sp really spreading frequencies across , using frequencies across a broader spectrum . in a way , bandwidth can increase with some of these cases of distortion that we have . but it 's n it 's not a useful increase in frequency range . answer ? that they don't . we don't have a reduction in that direction . that , one could have if one had cheaper microphones than we have , but we 've got good microphones and another there is an upper limit set on our bandwidth by the sampling rate but then that becomes adam 's ans that then it becomes a matter of , is that something that would be relevant to perceptual range . and , i didn't really have the sense that it would .   good . i that was my impression also . it wa we don't have that reduction like you have on telephones . and actually in the work that they were doing with the telephone corpora , they did run into limitations and certain types that they when what their speech recognition approach is because of the filtering . it does seem like when i hear these things , except for the distortion parts , where the volume 's too high , or th when the volume 's too low , but that 's a different problem , except for those cases , it seems to me that it really is as if the person were speaking in my ear . i don't feel that it 's being reduced in any way .  and he was saying in the , areas where you have clipping , where it 's recorded too high , and it starts to saturate and you have trouble , thought that was very interesting . bandwidth then gets actually wider instead of narrower because you have ,   you have these y you still have the frequencies are represented but the energy distributions are thrown off , and , you have also some additional frequencies . you end up with a wider bandwidth functionally ,  but not helpful for speech . no , technically , the bandwidth is wider than it 's actually paradoxical in a way cuz you usually think bandwidth better bandwidth is better . but in the cases of distortion than you can end up with ,  a wider bandwidth which isn't useful in terms of understanding speech .  ",,
Btr002.E,"yes . yes . one source was , there was a problem with a connection where the microphone went int went into a box i was trying to think of this as prior to yes , it was prior to the wireless . there was a particular connection which wasn't wireless , which was , mechanically bad in some sense , and if it got touched , it would s it would send an impulse , i in al an an irrelevant non wanted artifact . i agree . painful . exa i agree . and that 's th i would watch the visual sis signal to avoid that . it 's like   that 's really awful . you 've noticed that those have gotten better over the intervening ? good .   too . i when i realized when i realized , i meant to tell everyone to watch that visual signal cuz that 's saved me a bunch of times .  it might be useful to talk about the interface for a bit , in terms of what it is that you like particularly , and what you don't , and , that thing . interesting .  interesting .   interesting idea . i 'll s i 'll suggest that to the charer . that 's it 's good to be careful about the mousing . you were gonna say ?  how do expand "" ? what do by "" expand "" ?      i vary . i should it depends on how much i wanna go back and how certain the boundary is . if see it if it 's if see this thing 's coming up and it 's just clear , it 's that mountain right there , tell , then dragging is really f efficient . but if it 's like a mess in there , then it helps me to be able to locate it with the actual clicking . and then do this what th you were just describing . but , that 's annoying ! this if i were to if i were to add an option , it might be to have an undo for that . because i have had that happen . s good .   how do you get per i don't know the evil apostrophe .  i see . this is the difference between the pc keyboard and the sun keyboard ? like i only have one i have one versus two of the others . is that right ? it 's   there 's basmati ? amaretto ?  s which t i 've forgotten which one is which . which one do you prefer ? is it the if we had a show of hands , how many people would vote for the sun keyboard versus the let 's put it the other way . how many people would not vote for the sun keyboard ? would vote for the other one ? the pc keyboard ? i don't know . i don i 'm not it 's the  the linguine is ",,
Btr002.E,"you 're multi keyb let 's do it that way . if we have a map of the room , the one when you first walk in the one on the left is that basmati ?  and and then the f the far right corner as you walk in ?  u good .  and the one close to you is basmati . now , ha who would 've if you have a strong now you 're bi keyboardal  s but but , who would prefer the keyboard on linguine ? we got two votes for linguine . and who would prefer amaretto ? amaretto ? we got more multi keyboardal people ? that 's lovely . same here ? excellent .   i pr i see . i have experienced this keyboard conflict , and f with me the things that are confusing are th where the control key is , end up pressing shifts and control keys whenever i want the other one , whiche whichever it is . i could easily put a pc keyboard in there if anyone had i we already have one , i could add ane another one we w let me know if you want it to have it shifted . but ,  that 's good . let me see . i wanted to , m comment a little more on the interface in terms of what aspects of it are helpful in this , unique the shapes of some of these things are . i know we had this interface for a time when people were doing marking of the numbers , and , i 've forgotten someone said that they could recognize a seven when they saw it . they could see the waveform and "" it 's gonna be a seven . "" becau  it is different . it w it would it had the benefit of it this was to handle the digits , only , which is what you figure . and , did you you might have done that , joel . did you also ? two people did that , i did you do it ?  good , good .  that we 'll bring it back . the th adam wrote this as using the same , computer language as channeltrans is written in , and what it would do is present you with the digit string that the person was supposed to have said , and then you would listen to it , and everyth the j there were two parts to the task , one of them was to see if that 's what they actually said , and to indicate , in the i transcribe errors of it . and then the other aspect was to tighten the timebins . and those data were actually used in some analyses which showed very good results . and it shows , it 's useful . this is why we do these digits . it 's a standard task , and you have lots of different voices , ",,
Btr002.E,"and it 's very clear . what the canani canonical answer is when a person says a number , at least most of the time , what number it was they said . its "" ground truth "" , as they call it , is very clear .  but i it was , really rather minimal . i like that interface . very efficient , and really is , th think that we 'll probably use it for getting the digits refined in terms of their timebins . excellent . that 's right ! that 's right . i also think that wasn't this a stage where some of these meetings hadn't been transcribed , don't think you could use a string search , right ? i was trying to remember how that worked . but it was difficult finding them for some reason . y it was also , like you that 's a down side .  actually , you also did a different type of transcription i with res respect to , our sister project , the smartkom project , which involved listening to people who were supposed to be wandering through germany , and this is s supposed to be something that would be useful in developing an interface to help them find their way . someone else did that too , i 've forgotten who else did that ? did anybody else here do that ?  actually , you might have done this also , as about it .  actually we started with the words and it was a matter then of trying to find the most efficient way to match the words up with the s with the actual sounds . cuz they were reading from a script . and then there was some conversation in addition , that , needed to be transcribed . but ,  one thing that you learn with this interface right away is that if you have really , really long utterances , it 's extremely inefficient to do anything . because you end up p if you try to n go up in the transcript , you end up with this huge space of time and things covering several screens and it 's just horribly i inefficient ,  yes .   yes .  i 've noticed that . that 's dependent w on how you have the resolution set . that little tiny thing . and if i increase the resolution it 's spread out a bit more , then i seem to have more control over it . but , i don't have yes . i 'm gonna report that to him , cuz i 've i know that 's one of the reasons why , when i suggested to visual scan the record , that i suggested doing it by clicking on the right of the of that navigation bar you 're mentioning . or , actually , clicking on the right of the sound wave and then letting it run past the boundary , ",,
Btr002.E,"because i had the same problem . it 's cuz you always know yes . much more  cuz you end up missing entire frames . ye i was surprised by that .  yes , . on the on that bar you were describing . clicking  is this the arrow on the right , it would be underneath that little resolution bar ? it 's like in that u cluster up there ?  i have to do something visually . my i would say you have the transcript screen , and then you have a bar . you 're referring to this bar , aren't you ? and then there 's like this little resolution changer . and then down here you have the soundwave , and then something down here , and then you got the cha the different channels come out . right in here you have this bar that you move and as y as you go along it is are you saying you saying that there 's an arrow right here ? and then there 's an arrow right here ?  you can @ @ that 's interesting . i haven't paid attention to the numbers . i like visually , i it helps me to have it be separated enough that i could find a new breaking point if i needed it . expanded ?  we 're coming close to the end of our time here . i did ask about dessert and they told me it was ice cream and it doesn't save  that 's right . there 's some those are but i did i was thinking i it is interesting to me to think about how each of us have sampled different meetings , and yet , i it 's intriguing to me to think that if i were to describe someone 's characteristics in terms of their speech patterns , i bet you , we would all agree on who it was .  that 's interesting . it 's a statement of speaker style , but . do you have any favorite parts of these meetings ? things that you we di we talked briefly about this last time . is this do you think this is usually toward the end of the meeting , or does it vary ? cuz it could the person  do you have a favorite group that you like ? i don't wanna any partisanship here , but a fav a favorite t type of meeting that you like , or , or it whichever . i that way or a nature of a meeting , or   those are th e would these be the edu meetings ? that 's what is that true ? really ?  i 'm really ? i 'm glad . johno does a lot of that . it would be a kick in a in a good natured way @ @ . it would be really fun to have a collage of all these things the transcribers "" "" rer rer "" ",,
Btr002.E,"and then s be some horrible thing , "" the transcriber 's gonna have trouble with this . @ @ "" did you hear the meeting where the guy was doing , clicks like from african languages ? wasn't that a kick ? that was really a kick .   i was . exactly . exactly exactly . exactly ! have you noticed that sometimes you have these a g greater frequency of speech errors , during times of inter of overlap which is you can just tell a person 's m monitoring at two levels and it 's difficult .    let 's see . have you noti th one of the things that i found is , surprisingly difficult these days is to co is to get certain electronic sounds , to try and describe them . have i was thinking about that the other day , it was like it 's like , y someone in one of these edu meetings , they have a laptop and they hit the thing and the and there 's an error screen that comes up and it has this "" doink "" sound . and it what is that ? it 's not a beep . it 's not a bell . it 's not s it 's not a "" dong "" . it 's not a you there 're all these words that i could imagine and it 's like , it 's a "" tinny electronic sound that comes up when you make an error with your laptop "" . and that 's not really very helpful . the voice quality ? the shift in that thing . th and then , there are these other things that are really interesting , like the vocal changes in character . people shifting into a comic voice , or mock this or mock that , the sighing and the , "" no ! "" it 's it 's , i there are lot 's of nuances which we which we use very often . comic words and things like that . and   "" eech "" , "" whee "" . s yes . it was one of these it was this deal . yes . yes . and he got to transcribe this meeting . and there was all this meta about cuz i was giving a report on what the comments were , and it was one of these was this , s "" whee "" . is what he said . and he was going like this at the time . yes , that 's right . let 's just man . you did an excellen excellent job . that was really it was like m transcription , a meta transcription and meta . it 's really @ @ . i 'm really interested in this topic . would it be a problem if we continued a little bit longer on this ? or do you need to g do people need to leave . ",,
Btr002.E,"i don't wanna keep you longer than are we we won't be that long , i don't think . but i really appreciate it . this is just really i it 's interesting to me , the specific experiences of having encountered these data in this way . does , did anybody else wanna say anything about yes . my gosh . it is there 's another case where i ran across like o of that type , i when i was sitting here and we were doing this was like o one of the first meetings i ever participated in and dan was adjusting something here and adam was in the next room , and , adam says , "" 'll come in here and check the levels , "" and he says something and dan says , "" no "" . and it sounds like he 's saying "" no "" to adam , and it was w if this would have been extremely rude . but the thing and the reason that it would be rude is because you don't have this information from hearing all these equalized volume channels , you don't know that they 're not participating in the same conversation it really is strange . i it lead us it ta if we w it is true that this is an artificial and i discourse c aspect , the mixed channel is artificial because we 're boosting it in order to make everything audible . but when you leave here ? when you 're somewhere else ? no , no . how about these meetings when where there are like eight speakers i in one meeting . are those what are those like ? are  i had that same reaction . and sometimes these are meetings i participated in . it 's it 's like that 's righ that 's right . never changes . i 'm gonna check out outside to make that we 're with the , is it if we stay for another half hour in this room ? good , that raises a question . do you think that , you would have been considerably helped if we had video tapes of these things ?  that 's right , cuz you 're involved in gesture research .   interesting .   that 's i know someone who actually recognizes perfumes in the elevator . there 's a blind man in this building , and , lila was in the elevator one day . and they hadn't spoken yet cuz he just came on the elevator and he says and then she said something and he says , "" y you sp you 've changed your perfume . "" it 's pretty interesting . pretty interesting . yes , she had .    it 's very interesting . have you i 've learned several things about having been wi i with the close talking mikes . this is a new experience . cuz i have been involved in this thing for quite a while , ",,
Btr002.E,"but th there are several things i didn't realize you could hear reliably , and some of these are the things like when the mouth opens and the inbreath and and it and how extremely audible and visual , you can see these the inbreaths and things . it 's that was really surprising to me , that you it 's that tangible . it 's also one of these things that u usually is not meaningful , we screen it out . u all these different in cuz , we do that all the time with all other lots of other aspects of the acoustic signal . it sounds like it 's a smooth melody , but these things are voicing and unvoicing , are tripping in and out , and they don't the contour is really not nearly that neat .    that 's right . that 's right . the i agree . another thing that is interesting in these meetings is , certain speakers have a tendency to embed utterances in other embed in other utterances . and , it 's very clear when you see it when you hear it with the intonational markers , but just the contours , but the words on the page , it 's not clear . and there are a couple people who do this in particular . i would say that it 's both i would say that both jerry and morgan do this . and it 's amazing how fluent it is when you hear it , but how very complicated it is when you see the words .     and then there are these things which are also nicely represented in the data which are these funny sounds people make , which to some degree is borrowing from comic talk . i notice people going , "" pfft "" if they 're trying to say something is done . the germans do this in particular . and there are others that we use like that th which are semi conventionalized , but you wouldn't think that you would write them down . yes ! good example . yes . this cou is this the one that it could be the one that we were thinking about . yes . it would be it would how interesting . i 'll ask you who this is later . i don't wanna cuz  the one that i 'm thinking of , i it 's a matter of you can tell it 's in context where he 's looking in his agenda to see , "" do i have time to do this ? "" and he 's calculating it in his mind . it 's li almost like a stand in for calculator , thing . and i but it 's signaling . i 'm that everybody i 'm that other people can hear it . it 's like , "" minute , i 'm thinking . "" but it 's not lexicalized . this is not a ",,
Btr002.E,"i not in a standard way , it 's  he must do this in a lot of meetings because i 've run across it several times .  heard that one . i see . yes . now what i would say it 's good to know this . c what i would say is , if it 's communicative s beyond just the p mouth opening and the w the mechanical aspects that happen when you happen to be about to speak , then i would like to have it if it 's communicative , i 'd like to have it preserved . a but if it 's just this mechanical "" mouth "" is fine . the it seems like the computer science people use "" lipsmack "" for that . i personally , my choice w we 've we 're still deciding on how we 're gonna encode it in the final version . but i tend to not like "" lipsmack "" because that 's could be meaningful and it 's a little confusing . people talk about , "" gee , that was really good , "" and then they do a i 'm not gonna do it cuz i don't really know how to do lipsmack . but it seems like it would be a vocal gesture , a definite type of thing . yes . same here . i would too . i would say "" tongue click "" for that . but i would also probably put in parentheses it that it was a vocal gesture . because it 's communicative of a certain thing . good point . yes . really good point .  i would too . it 's more emphatic .  but it th it 's true that th segments are different too . now , y this is a good question . would say th sometimes we 've seen "" hmph "" in literature meaning in but it 's a sigh a si a sound of indignation . if it 's meant as a sound of indignation then that would be how i would capture it , with the hmph thing . a like a sup an elevated "" ? it 's like a m more surprise , or engagement ?  and then there 's the other kind which sounds similar , but it 's really part of a laugh .  which is i would just say "" laugh "" for that . good . done . done . i 've run across that also . and right . change it to "" laugh "" . done . i ran across a couple "" ho "" 's occ i 've seen "" ho "" 's and and "" heh "" .  that 's right . w we yes .   yes . yes .   i agree with you . that 's what i prefer . good . done . done .  that 's good . that 's good . that 's right . that 's good . that 's right . and ",,
Btr002.E,"i agree with you . and that 's important because we 're capturing then the communicative level . and it 's likely that it has a different contour than most breaths as because it 's expulsive and , that thing . ex exactly . exactly . done . yes they do . the shyer ones sometimes will laugh i with the breath laugh . and you can see it . you can see the little peaks , which is interesting . but yes . exactly . i wouldn't , that 's a case whe i know generally with the tigerfish things that they put "" breath "" and we leave it in . but there , "" laugh "" , change it . and , there are other places where it 's in the way , i mainly said not to change their "" breath "" 's simply because it would take time to move them if and if they 're not in the way then don't mess with it , but yes ! great . that 's right . one wonders what it might be  there are some where  see , i do a previous filtering before i give the tigerfish ones out , and i u i have tried to get the that particular the "" missing segment "" removed . but i don't always do it . you 've s they slip through .  interesting . let 's see , do you think that this has changed your speech n in other ways , in terms of myself , i do feel that i 'm when i spend a lot of hours doing this i become less fluent . i have more false starts and things .  i don't know if it 's it could just be because there 're many more hours i haven't been talking . good .     mainly for clarity , it sounds like , like in phrasing or strategies .   it depends partly on the type of interruption . if it 's a clarifying type like "" do "" when they 're partway through it in a utterance . this is really  i agree . i did do one analysis wh where i looked at one meeting , and , th cuz the claim had been , actually o one of the people in the meeting had made the claim in the previous meeting that , "" there probably the overlaps only occur during setup and , at the end when we 're leaving . "" exactly . exactly . and , that 's the feeling you would get if unless you looked at the data at this level . and did an analysis and it was really a pretty constant rate all the way through the entire meeting and everyone was involved . wasn't just one , or two speakers . everyone was it 's quite true . that 's true . i should say , i didn't distinguish between overlaps and interruptions . some of these were backchannels and things like that . ",,
Btr002.E,"but it 's still the case . you have y you that 's true . that 's very true . it 's true . that 's very rare . i agree . interesting observation . if they 're i c if this has raised a couple of things for me that i wanted to mention because , at this point , we 're at the really fine grain level of standardization which i hadn't really thought of specifying in advance before , and , wanted to just mention a couple of things . these are ,  i don't think that these are very common . but with the idea that what we 're trying to do is encode the communicative when we have these grey areas , w i wanted to draw attention to the fact that there are sometimes these stretches where a person is trying to say something and formulating their thought , and they 're coming out with a bunch of segments , which really aren't part of a word . have you run across that where they 're saying and then they say a word . and , my feeling on that is , that this isn't really a phonological transcript , and potentially those things could probably be rendered , although some of them are not even full segments , they 're even sub s subsegmental , i would say . you got a single flap of a vocal cord sometimes , and , they 're th it 's like the apparatus is almost kicking in , they 're almost gonna say but it hasn't somehow this vibration hit before the rest of it and that 's not communicative . my the way i do those things when i hear those , if is to i use in parentheses one "" x "" it 's marked . or if it 's @ @ then i put six or seven or however many it is great . and then what i do is i put in , brackets , uncodeable "" uncodeable vocal sounds "" . and potentially they 're codable , but wanted to mark roughly how man how long it is , then indicate what the nature of it is , no one 's gonna try and go back and decode it as something that 's pechen a word that was not it has a different status than parenthesized , parts when there are words involved , just to set it aside , have some length indication , and sometimes i 'll even put them in a separate bin , although that 's not necessary . it 's just sometimes it works out that way that they @ @ , they do this thing . i shouldn't do that often . i 'm about that . they do this sound , and then there 's a pause , and then they start speaking , then it 's really obvious , split it apart and it won't be any problem . ",,
Btr002.E,"i wanted to mention that one ,    excellent . i see . i see .  that 's it 's alright . no problem . no , no . this is not i wouldn't give it a second thought . you sh  y you 've heard have you heard "" shoot "" ? i 've heard "" shoot "" a couple of times . no , no , no , no , the "" shoot "" type ,   i do remember that . that 's right . that 's right .   it was .   b but y t finish your point . y yes .    i agree . and there 's another problem too , and that is that we do have some short words which are communicative . and sometimes if you have an "" er "" as part of one of these fragments , we do have a lexicalized "" er "" which is a filler item . does have a meaning . think for both of the reasons it 's good to just leave it in this category of not really communicating in a word like way . i would keep "" er "" . "" e "" "" er "" if it 's a filler . "" er , "" th that stays . but if it 's p part on these little fragments , no .  i 'm making a distinction . you have the , comic "" er "" where the person says something and then they pretend that they didn't wanna say that , and then they throw in an "" er "" . m and that would be an "" er "" . er . but if they 're saying "" or "" in a reduced way it comes out as "" er "" , do it as "" or "" . cuz that 's that falls within the realm of pronunciation variants . it 's just like different ways of saying "" and "" .  and i have like , two more things i wanted to say . one of them is ,  this is an interesting category to me , and i don't , y don't have to mark this systematically . but when you 're going through the meeting , and what i 'd like people to do if you 're not is to go through the meeting ,  if you 're doing separate channels first and then as a final pass through the mixed channel , i don't 've made that explicit but it w it 's really helpful to go through it a final time though the mixed channel that you hear things in context . and at that point what i sometimes pick up is this meta level , where someone is finishes someone 's someone else 's utterance . you 'll suddenly have this stranded word out in the middle of nowhere , and it 's because this other speaker on this other channel was trying to formulate this thought , and they paused , ",,
Btr002.E,"and they paused just enough that this person leaped in and gave them a word . and those are interesting , when i find that i note it as , finishing put capital letters . capital letter , colon , apostrophe "" s "" , utterance .  if in the examp i in the instance in which let 's say that , morgan 's talking , he 's talking . and then somewhere there 's a bit of a pause , and let 's say adam fills in a word for him . then what i do is , on adam 's channel , i say i say , "" completing "" and this isn't that common of an occurrence . "" completing speaker initial with a colon apostrophe "" s "" 's utterance "" . and what that means is at the time when we see we 're gonna go to a stage of anonymization . it 's important to have the colon here because that 'll make it possible to easily know , who it was without having to do the math involved in figuring out which channel it was . the problem with i originally wanted to use channel numbers as the referent index , but that 's not functional because we have these two different numbering schemes . you have the numbering in the channeltrans interface and you have the numbering in the "" key "" file and those can be very different . to be able to , th this is redundant in a useful way in that that you 're not gonna make a mistake . i tried to do it with the numbers and i was making all sorts of inconsistent problems , stopped it . that 's i did that partly to keep track of things .   somet the initials ? i 'm glad to hear that . i st i didn't do that systematically until , really rather recently , i 'm glad to know that 's useful . it s takes an extra step . glad it 's useful . now have one more thing to say and that is that ,  like once this is just such a rea i 'm getting down to like the really eensy weensy but , once i found a comment that , in curly brackets about mumbling . and , i g that 's this is just to mention an instance that happened once , it 's really grasping for details . but , i f and it may be that it was not from anybody here ,  but that , "" mumble "" is only useful in the s to me , in the sense of "" whispered "" , if it 's like a manner of speaking , in which case it 's a "" qual "" . but not in terms of replacing this string of undecipherable fragments .  this was u when it was used exactly . it was used in place of , something that was in unintelligible . ",,
Btr002.E,"in which case , it would be better to use parentheses and either exclamation , or the number of syllables , if exactly . if it 's a manner of speaking , then it 's useful . and otherwise the parentheses with an estimate of syllables is better .  i don't wanna keep you . i kept you long . i really appreciate this . yes ? yes .  yes . but good question . and you don't have to add any of those tags . the only tags that you need to add , is th there 's like one exception that 's just microscopic , and that is , sometimes this is again really rare , sometimes i 've run across the word "" noise "" . and offhand , i don't know if that 's a vocal noise or non vocal noise . and then i listen to it and i figure it out . but that 's the only place you would use a "" vocal "" "" non vocal "" tag , where it 's potentially ambiguous between those two categories . cuz otherwise , what i do when i get these , is and do my checks , and then i have a , script that i wrote which will separate everything in out that has curly brackets , do a listing of them , and then anything some of them already have tags from some previous , modification , but anything that doesn't , go through this list , and i k tag it right then . and in one in one change , modify , five hundred instances of this . there 's no need to add the "" vocal "" or the "" non vocal "" . yes . you can either if you mark it "" mike noise "" then i 'll noise it is when i go through the thing and put voc or nvc on the in the substitution file . but it 's very efficient for me to add those tags later . it 's really not the same thing with the "" qual "" . just long as tell which of those three categories it is . or "" pron "" , but , those that 's really very obvious , the pronunciation . long as tell what they are . it 's good for you to add the "" pron "" . i would appreciate the "" pron "" , come to think of it . but the other three long as it 's clear to me , w from the comment which of those three it is , then i 'm fine . that 's great . alright ,  do we have time ? would you mind ? can we do digits ? why don't do you wanna do it , in unison this time ? we did !  do it separately , then . good deal . that is really what that time field is . ",,
Btr002.E,"i used to think it was the beginning of the meeting , but yes . quite right . quite right . that 'd be good .  who wants to start ? 'll start .  transc and the time is o eight . i wanted to make one comment and that is , some of these are like two digits and just be you say both digits separately . one eight instead of eighteen .   wonderful . very , very much . i really appreciate this . and , now we get to turn the microphones off , and , ",,
Btr002.F,"we have littler heads    right . i "" ish decay "" ? what 's an "" ish "" ?    actually , that comes back to a point . we had talked about this last week , where you were interested in "" . saying "" at the end of something . and sometimes that would get transcribed as let me just think of an example .  let 's say i say , "" that would be hard to do , "" right ? and the way i would transcribe it , i would put that "" that would be hard "" , comma , "" at the end . cuz it 's just the end of that the right .   i would just end it . but then sometimes they transcribe it like "" that would be a problem "" , period , new word , like capitalized "" . right . and it just seems to sotal that 's not the meaning . and it changes the meaning ,  or whatever , "" that would be a problem "" , whatever .   it seems like because if i was just reading that thing , i would say , "" that would be a problem . "" what th if it was like , "" period , capital , as opposed to , "" that would be a problem , "" "" that would be a problem . "" some right ,  right .  right .  wonder what influences them to think of "" twosome gruesome "" , like this person just saw a horror movie and , this is the interpretation that came to mind what like , where would you get the word "" gruesome "" ? you just pull it out of the air ? anyway .    right . "" pss "" . but this other business , that you have at the bottom with people getting transcribed on another channel is , is much more common . right . and what 's always funny to me is when it 's th they m mi miss the gender completely , like , morgan 'll be on jane 's channel , or just something bizarre like that .    fancy schmancy . if i was gonna make just a guess , though , from my experience it would seem like the men get mis the men get moved onto other channels , more frequently . and it 's just probably cuz they have deeper voices and they 're getting picked up on more channels , than their own channel . for w it 's an acoustic thing .        you could see it coming and you 'd turn the volume down but sometimes you 'll see like something coming up like , "" someone 's gonna cough really loudly "" , and i could tell because of the way it looks ! or "" someone 's about to laugh really loudly "" ,  and then you 're just sort you 've got like you 're like  ",,
Btr002.F,"unless there 's gonna be some speech in there , i don't need to listen that carefully .    you could h really hurt your ears .   gives some good clues ,   sometimes it doesn't pick up backchannelling , though , and sometimes you have to , try to listen there 's no visual but you have to the resolution , right ?   just to jump it back . right , cuz sometimes you 'll hear it 'll be in right in the middle of the timebin , and you don't have to listen to the whole thing again cuz you 've already gotten the first part . you just want it to go back , i don't know that 's true .  the less you have to click on the mouse , the faster you could go . you were having some wrist problems and right ?   i do that with the mouse ,     do find that the keyboard is different here than it is even at my s for my school computer and 'll al i 'll just be if i was just at school , and i come here , it 's just or vice versa it 's just , it 's like i 'll reach for one key and it 'll do something completely different , and i have to just get used to it again the backspace is in the wrong place . and then i 'll keep i keep caps locking too cuz the caps lock 's in a different spot .  th  i do that all the time . i don't know . you seem very upset about it , we we should trade .   get used to it .   is basmati . i believe that 's correct , linguine must be the one in the left hand corner .   have no preference .  it just goofs me up for like minute and then i sorta get used to it .     i did it a little . just a little bit .  what happened to that , you just stopped doing it ? or ?  right . good .  the hardest thing 'd be finding them . cuz i would get the whole tr i 'd get the whole transcript of the meeting and you had to find them . you 'd have to find where the digits were . and they 'd usually be at the end somewhere , but you had to fig figure out where the heck in the meeting to look for them ,   the interface was different . i it was more complicated . but anyway , than what it would be now ,   right . that 's when i use it too . if there was pie again , if there was those tarts again , i 'd be like , "" set us some aside some there . "" but i 'm not a big ice cream fan . nah . when people get really loopy , and start telling lots of jokes , ",,
Btr002.F,"i enjoy always transcribing those sections . it 's it seems to be more at the end . like  they 'll be joking around . a favorite what ? like , meeti like , meeting recorder as opposed to edu as oppo like , those groups ?  i 've never heard anyone make fun of transcribers . no ! when you guys were saying that last week , i was like "" never heard that . "" yes . i did that . and whistles . he was it i you must have been sittin there was a meeting where there was this guy , he was making these funky sounds and making funny whistles , and you must have been sitting next to him cuz you engaged him in a conversation about it . and he was like , "" make dogs , raise their ears cuz whistle high . "" and you were like , w "" that 's fascinating . "" i remember that meeting . it was pretty funny .         no .  just weird things like before like , i had weird thing happen , and we 'd talked about it . it was when i 'd first started working on the project i got this discussion where this was before we had the different channels , and , dan ellis it was when dan ellis was still here it was like early on , right ? and , he everyone 's talking , and then all of the sudden , you hear dan talking to someone else and it 's different people that you 'd never heard before . and what he had done , is he had left the room to g he 'd li and he had brought the microphone with him . and this is without the channelized interface . you have no idea . you think everyone 's just become schizophrenic and they 're all like in they 're own r world because then all of the sudden he 's talking about a co he needs a copy machine . and i don and i 'm just assuming , he 's still in the room and what the heck 's he talking about ? but just just weird things like that , and , he had just left the room and gone and made a copy and he still had his microphone on , and then you could hear the r the women behind the desk talking to him , and just like that . it was just really bizarre .  anyway . just weird things like that .    they take longer to do . in a way they 're more fun , though . there 's just more variety . who won't talk . and to breathe . there 'll be lots of breathing . did you guys ever , when this happened to me when i first started transcribing , cuz i had never really transcribed like this before , but , i would leave here , ",,
Btr002.F,"and i would go out and do my daily business , and i would hear people speaking to me , and i would transcribe them in my head ! i 'd imagine what i would type . it went away , like after a couple of weeks , but it was just bizarre . really ? no , for me it was unconscious . it was i didn't mean for to be doing it . it would just intru it was an intrusion . not a te not a bad intrusion , but not something i was volitionally yes !         had she changed her perfume ?  oof !    right . most of the time when we 're listening to other people 's speech , we 're just trying to get the gist . not literally what people are saying and all the "" "" 's "" and "" 's "" , and all those different things , we just tune it out ,  and , it 's that top down thing again . just right ? in a way . just trying to get the , what is the p "" what is the point of what this person is trying to communicate ? "" thing .   no . i 've heard which transcribe as "" mouth "" . make a mouth cuz had talked to you about this about what did we do cuz wha what was it that i i was "" lipsmack "" ! i was marking "" lipsmack "" , and you said that 's it 's a different noise , but , it 's what made me think of it , but , and you said , "" don't do "" lipsmack "" , just do we don't need it 's too specific . just do "" mouth "" for all tha all those noises "" .     right .  right .  right .  if it 's surprise then the exclamation point makes sense , too .  once , adam was laughing , and it was actually written out phonetically , and i changed it . i 'm like "" it 's just laughing "" . like somebody had written , like "" hyuh "" and i it was tigerfish had done something like they had written out a phonetic laugh , and they didn't do it at any other place in the transcript . it was just that one spot . it was just a regular old vanilla laugh , it wasn't anything special .  here 's a question , and there 's been some variance in transcripts that i 've looked at . when  when you laugh , you 're exhaling all this air , and you need to i inhale , and how do you transcribe the inhale ? some people are transcribing it as a breath . i used to , back in the day back when i was do transcribing , i would do the whole thing as a laugh because to me the breath is part of the laugh . ",,
Btr002.F,"cuz i cuz in the ones i 've been che the one i 've been checking actually right now , that breath gets marked as a breath , and i 've been taking them out . that 's actually , it 'd be a "" laugh "" and then two dots , like the next bin will be empty , and then it 'll be "" breath "" . and it 'll be that it 'll be three d separate units as opposed to it 's one coherent thing .  that 's a different thing . s cuz sometimes it 's not clear . like sometimes "" hhh ! "" is a laugh . and if other people are laughing , then i 'll usually give them and say that they 're laughing . exactly .   right . good .  they give the segmenter , though cuz they don't have the rich interface that we do , the they must be giving the pre segmenter the benefit of the doubt , "" there must be something there , whether hear it or not . "" they just say , "" it 's a breath then "" . yes ! that 's true .  frequently that 'll also be a misattribution too , of voice . cuz then you 'll hear part of what another person is saying and th tha and that 's all transcribed on that one level , but then you 'll hear a little bit of it and then "" missing segment "" . it 's like , "" they just it 's in the wrong that person 's not talking . you just get rid of it .   that 's true . that 's not true .  it 's rare .  i was wondering who had been putting those in . yes .   man ! i do that too ! i used to do that ! a lot of time . like a skull and crossbones . it 's not i it 's  it 's not like you said the f word . it 's not an it 's still a pg she 's pretty darn that , she could make it out probably . no one 's ever sworn in any of the meetings ! that actually not the swearword version . just "" shoot "" . that 's   right .  how do you mark it ? i see .  and then do "" qual mumbled "" or "" qual whispered "" i see .    good . good . do you wanna read digits ? do you wanna do that ? no ? we did it in unison last time . did . and do you want us to mark the t roughly the time we start ?  we have to  no problem . ",,
Buw001.A,"we 're not recording yet , are we ? meeting recorder meeting . do we do th do you go around the room and do names or anything ? what ? whoops . would it m  this thing .  it 's   this w alright . how 's that working ?   the goal was what can we do how can you do the data collection differently to get what can you add to it to get , some information that would be helpful for the user interface design ? like especially for querying . getting people to do queries afterwards , getting people to do summaries afterwards .   if you actually take notes as a summary as opposed to n take notes in the sense of taking advantage of the time stamps . action item or reminder to send this to and blah blah . that wouldn't be a summary . that would just be that would b relate to the query side . right .   we also could come up with some code for things that people want to do that for frequent things . and the other things , people can write whatever they want . it 's to some extent , for his benefit .  if that if we just keep it simple then it 's still useful . right . you did that on purpose . but anyway , shall we do the roll call ? mari on channel zero .  right . right . the there will be jargon that we he there 'll be transcription errors .  u actually there 's three issues . there 's the crosspad issue . should we do it and , if what 'll we have them do ? do we have s people write summaries ? everybody or one person ? and then , do we ask people for how they would query things ? is that right . right . right . right . they  right .   w how about this idea ? that normally at most meetings somebody is delegated to be a note taker . and why don't we just use the notes that somebody takes ? right . right .      what it does what it does is provide a different it 's an interesting thing . i don't think it gets at the queries per se , but it does give us an information fusion thing that , you wanna i say "" what were the hot points of the meeting ? ""  you could say they 're gonna ask about , when did and talk about blah . and at least that gives you the word that they might run a query on . right . it 'll tell you the hit but not the query . right . w th you could do the summaries actually may help get us there , for a couple reasons . ","what can you add to it to get , some information that would be helpful for the user interface design ? the there will be jargon that we he there 'll be transcription errors . actually there 's three issues . there 's the crosspad issue . should we do it and , if what 'll we have them do ? do we have s people write summaries ? everybody or one person ? and then , do we ask people for how they would query things ? that normally at most meetings somebody is delegated to be a note taker . and why don't we just use the notes that somebody takes ? ","Meeting notes taken by participants as standard minutes or summaries, or on devices like CrossPads can provide useful information. "
Buw001.A,"one , if you have a summary if you have a bunch of summaries , you can do a word frequency count and see what words come up in different types of meetings . action item "" is gonna come up whether it 's a vlsi meeting , or speech meeting , or whatever . words that come up in different types of meetings may be something that you would want to query about . the second thing you could possibly do with it is just run a little pilot experiment with somebody saying "" here 's a summary of a meeting , what questions might you want to ask about it to go back ? ""  that 's one possi one possible scenario , though , is you have the summary , and you want to ask questions to get more detail .    right . right . i th no . you got to have somebody who knows the pro knows the topic or whose job it is delegated to be the note taker . somebody who 's part of the meeting .  it serves two purpo purposes . one , as refresh to help bootstrap queries , but also , we do want to generate summaries . and then it 's it 's key .  i ? or , d o what in most meetings , this one being different , but in most meetings that i attend , there 's somebody t explicitly taking notes , frequently on a laptop you can just make it be on a laptop , then yo you 're dealing with ascii and not somebody you don't have to go through handwriting recognition . and then they post edit it into , a summary and they email it out for minutes . that happens in most meetings . right .     right . it depends on whether it 's a business meeting or a technical discussion . and i agree , technical discussions you don't usually have somebody taking notes . right .     no , no , no .  e  what do we 're not saving it anyway ? i 've written all of this down and it 's getting emailed to you .  that 's why i 'm saying that the note taking would be in many for many meetings there will be some note taking , in which case , that 's a useful thing to have we we don't need to require it . just like the it would be great if we try to get a picture with every meeting .  we won't worry about requiring these things , but the more things that we can get it for , the more useful it will be for various applications .  before we leave the crosspads and call it done . if i 'm collecting data then there is this question of do i use crosspads ? ","the second thing you could possibly do with it is just run a little pilot experiment with somebody saying "" here 's a summary of a meeting , what questions might you want to ask about it to go back ? "" but in most meetings that i attend , there 's somebody t explicitly taking notes , frequently on a laptop and then they post edit it into , a summary and they email it out for minutes . ",
Buw001.A,"that if we really have me collect data and i can't use crosspads , it 's probably less useful for you guys to go to the trouble of using it , unless you think that the crosspads are gonna n i 'm not what they 're gonna do . but having a small percentage of the data with it , i 'm not whether that 's useful or not . it 's no big deal . we just do it and see what happens .  right . nothing .  right .  that 's true . if it seems to be really useful to you guys , we could probably get a donation to me . right .  right . right .  crosspads , we 're just gonna try it and see what happens .  the note taking that this is gonna be useful . if we record data i will definitely ask for it . i j we should just say this is not we don't want to put any extra burden on people , but if they happen to generate minutes , could they send it to us ? and then  but again , like the crosspads , i don't would base a lot of on it , because know when i see the clock coming near the end of the meeting , i 'm like inching towards the door .  you 're probably not gonna get a lot of people wanting to do this . right . that doing it orally at the end of the meeting is the best time . don't because they 're captive audience . once they leave , forget it . but i right . but , i don't think that they 'll necessarily you 'll get many people willing to stay . but , if you get even one   for a little while it was just that i was really tired . that and y too much caffeine and really tired , but then no , that 's real "" .  what 's our schedule ? let 's see , you and i need dis no , we did the liz talk .  that was the prosody thing . we need to finish the it 's already four fifteen . after . we need to finish this discussion , and you and i need a little time for wrap up and quad chart .   what 's the plan for this discussion ? we should less .   action   e why don't you say five thirty ? i don't is that we 'll probably hit horrible traffic . that 's not a lot of time , but  but actually i would say that 's a better thing to ask than have them summarize the meeting . you get two that 's true .  that 's actually a really good idea . but actually it would be an easy thing to just go around the room and say what was the most interesting thing you learned , for those pe people willing to stay . ","crosspads , we 're just gonna try it and see what happens . i j we should just say this is not we don't want to put any extra burden on people , but if they happen to generate minutes , could they send it to us ? because know when i see the clock coming near the end of the meeting , i 'm like inching towards the door . you 're probably not gonna get a lot of people wanting to do this . that doing it orally at the end of the meeting is the best time . ","Meeting notes taken by participants as standard minutes or summaries, or on devices like CrossPads can provide useful information. Another option would be the recording by participants of short oral summaries of the meeting. "
Buw001.A,"and that might be something people are willing to stay for . that 's fine .  right .   i that 's hard to generate and that 's half of what i would use it for . but i also a lot of times make think to myself "" this is interesting , i 've gotta come back and follow up on it "" . things that are interesting , i would be , wanting to do a query about . and also , i like the idea of going around the room , because if somebody else thought something was interesting , i 'd want to know about it and then i 'd want to follow up on it .  right . right .   in the interest of , generati generating an interesting summary , no , i in the interest of generating some minutes here , and also moving on to action items and other things , let me just go through the things that i wrote down as being important , that we at least decided on . crosspads we were going to try , if landay can get the , get them to you guys , and see if they 're interesting . and if they are , then we 'll try to get m do it more .  getting electronic summary from a note taking person if they happen to do it anyway .  getting just , digital pictures a couple digital pictures of the table and boards to set the context of the meeting . and then going around the room at the end to just say qu ask people to mention something interesting that they learned . rather than say the most interesting thing , something interesting , and that way you 'll get more variety .  "" thing that was discussed . "" and then the last thing c would be for those people who are willing to stay afterwards and give an oral summary .  does that cover everything we talked about ? that that we want to do ?    play with and generate real queries from . right .   right .    we 're piloting . we 'll just do it and see what happens . speaking of action items , can we move on to action items ?  or we should until the summary of this until this meeting is transcribed and then we will hav i got why don't you hand me those transparencies that i remember to take them . eee ,   what i have down for action items is we 're supposed to find out about our human subject , requirements .  people are supposed to send me u r for their for web pages , to c and i 'll put together an overall cover . and you 're s  and you also need to look at your web page and clean it up by mid july .  let 's see . choo choo . we mailing list ? you need to put together a mailing list .    ","crosspads we were going to try , if landay can get the , get them to you guys , and see if they 're interesting . getting electronic summary from a note taking person if they happen to do it anyway . getting just , digital pictures a couple digital pictures of the table and boards to set the context of the meeting . and then going around the room at the end to just say qu ask people to mention something interesting that they learned . and then the last thing c would be for those people who are willing to stay afterwards and give an oral summary . play with and generate real queries from . what i have down for action items is we 're supposed to find out about our human subject , requirements . people are supposed to send me u r for their for web pages , to c and i 'll put together an overall cover . and you also need to look at your web page and clean it up by mid july . you need to put together a mailing list . ","Meeting notes taken by participants as standard minutes or summaries, or on devices like CrossPads can provide useful information. Taking some photos of the whiteboard and the positioning of participants is easy enough to do. Another option would be the recording by participants of short oral summaries of the meeting. Finally, project web pages and mailing list are being set up and UW are going to investigate the suitability of their recording equipment. "
Buw001.A,"i need to email adam or jane , about getting the data . who should i email ?  how about if right now all i want i personally only want text data . the only thing jeff would do anything with right now but i 'm just speaking fr based on a conversation with him two weeks ago i had in turkey . but all he would want is the digits . but i 'll just speak for myself . i 'm interested in getting the language model data . 'm just interested in getting transcriptions . then just email you ?   and your email is ?  and then  right . related to the conversation with picheny , i need to email him , my shipping address and you need to email them something which you already did .   we never had our data format discussion .  that 's w my u feeling right now on format is you guys have been doing all the work and whatever you want , we 're happy to live with .  other people may not agree with that , but cuz i 'm not actually touching the data , shouldn't be the one to talk . but    or , like if you have a or , like if you have somebody who makes your plane reservations for you , which is the n   e it could result in some good bloopers , which is always good for presentations .  anyway   other let 's see , other action items . have the i 'm shooting to try to get it done get it put together by the beginning of august .  if we don't know . i it 's probably unlikely that we 'll pull this off , but a at least it 's worth trying .  and i will email these notes i 'm not what to do about action items for the data although , then somebody somebody needs to tell landay that you want the pads .   right . but that 's actually what i wanna do . that 's what i wanna work with , is things that s the wrong material but the right da the right source .  he seemed when i asked him if he could actually supply data , he seemed a little bit more reluctant . i 'll send him email . i 'll put it in an action item that i send him email about it . and if i get something , great . if i don't get something landay . and , otherwise , if you guys have any papers or i could use , could use your web pages . that 's what we could do . you 've got all the web pages on the meeting recor  forget this ! i one less action item . use what web pages there are out there on meeting recorders .  there 's icsi , xerox , cmu ,    great . that solves that problem . one less action item .  ","i need to email adam or jane , about getting the data . 'm just interested in getting transcriptions . w my u feeling right now on format is you guys have been doing all the work and whatever you want , we 're happy to live with . i 'm shooting to try to get it done get it put together by the beginning of august . that 's what i wanna work with , is things that s the wrong material but the right da the right source . i could use , could use your web pages . you 've got all the web pages on the meeting recor use what web pages there are out there on meeting recorders . there 's icsi , xerox , ",There is also work being done on the annotation of prosody. 
Buw001.A,"that 's good enou that 's all think of .  i don't think we should have rules of participation , but we should try to get a variety of meetings . that 's something that if we get the meeting going at uw , that i probably can do more than you guys , cuz you guys are probably mostly going to get icsi people here . but we can get anybody in ee , over and possibly also some cs people , over at uw . that there 's a good chance we could get more variety .   right .  'm just writing here , we 're not gonna try to specify rules of interaction but we 're gonna try to get more variety by i using different groups of people and different sizes . e  and then the other thing might be , technical versus administrative . cuz if i recorded some administrative meetings then that may have less overlap , because you might have more overlap when you 're doing something technical and disagreeing or whatever . the reason why i didn't want to is be why i personally didn't want to is because i wanted it to be as , unintrusive as possi as you could be with these things hanging on you . is that an action item ?    yes , we should do that . they 're related to this morning 's meeting . think "" pass "" is socially acceptable . but i will say i will actually a spin on different slightly different spin on what you said , this issue of , realizing that we could take minutes , and that actually may be a goal . that may be the test in a sense , test data , the template of what we want to test against , generating a summary . that 's an interesting new twist on what we can do with this data .   great . ","i don't think we should have rules of participation , but we should try to get a variety of meetings . that 's something that if we get the meeting going at uw , that i probably can do more than you guys , 'm just writing here , we 're not gonna try to specify rules of interaction but we 're gonna try to get more variety by i using different groups of people and different sizes . the reason why i didn't want to is be why i personally didn't want to is because i wanted it to be as , unintrusive as possi ",
Buw001.B,"this should be off the record , but i know . it just it really hurts . it gives you a headache , like if you on your temple   with the we kno i know . we know exactly how much you have left in your cup . were we gonna do digits ? you can write them on the board , if you want . liz , on channel one . actually and i actually want to say something about the note pad . if you could sense just when people are writing , and you tell them not to doodle , or try not to be using that for other purposes , and each person has a note pad . they just get it when they come in the room . then you c you can just have a fff plot of wh who 's writing when . that 's all you and , you can also have notes of the meeting . but i bet that 's that will allow you to go into the the hot places where people are writing things down . you can tell when you 're in a meeting when everybody stops to write something down that something was just said . it may not be kept in the later summary , but at that point in time is was something that was important . and that wouldn't take any extra or someone could just pu you could just put your hand on the pad and go like that if you want to . it 's then you can go to the points where the you could actually go to those points in time and find out what they were talking about . and you r and  but i bet it 's a good superset of it . at least you can find the locations where there are keywords and right , right . but thinking about queries is a little bit dangerous right now . we don't even if you want to find out what any user will use , that might be true for one domain and one user , but different domain and a different user  the summary is actually gonna drive the queries then . your research is going to be very circular . right . but you could always post hoc label them .   landay can put a student in to be a note taker . no ? no , but someone who can come sit in on the meetings and then takes the notes with them that the real note taker and that way that one student has , a rough idea of what was going on , and they can use it for their research . this isn't really necessarily what you would do in a real system , because that 's a lot of trouble and it 's not the best way to do it . ","if you could sense just when people are writing , and you tell them not to doodle , or try not to be using that for other purposes , and each person has a note pad . they just get it when they come in the room . then you c you can just have a fff plot of wh who 's writing when . and , you can also have notes of the meeting . but i bet that 's that will allow you to go into the the hot places where people are writing things down . but i bet it 's a good superset of it . ",
Buw001.B,"but if he has some students that want to study that then they should get to know the people and attend those meetings , and get the notes from the note taker  how does the summary get generated ? i 'm not against the idea of a summary , but i wanted to think carefully about who 's generating it and how because the summary will drive the queries .     dan ? y you should also have a record of what 's on the board . i find it very hard to reconstruct what 's going on . i don't know how i don't know how , but the outline is up here and that 's what people are seeing . and if you have a or you shou could tell people not to use the boards . but there 's this missing information otherwise . y right .  people who were never at the meeting will have a very hard time understanding it otherwise . even people who were at the meeting . i don't mean that you model it . we should just like archiving it or storing it . because someone someone later might be able to take these and say "" they , at least these are the people who were there and here 's what they started talking about , and "" and just big , big interest . huge . it personally , i don't i would never want to deal with it . but i 'm just saying first of all there 's a whole bunch of fusion issues that darpa 's interested in . fusing gesture and face recognition , even lip movement and things like that , for this task . and there 's also personal interest on the part of mark liberman in this in storing these images in any data we collect that later we can do other things with it . and even doing something very crude like i know with atis , we just had a tape recorder running all the time . and later on it turned out it was really good that you had a tape recorder of what was happening , even though you w you just got the speech from the machine . if you can find some really , low , perplexity , way of doing that , it would be worthwhile . otherwise you 'd you lose it . also cmu has been doing this and they were the most vocal at this meeting , alex waibel 's group . and they have said , i talked to the student who had done this , that with two fairly inexpensive cameras they just recorded all the time and were able to get all the information from or it was three from all the parts of the room . think we would be we might lose the chance to use this data for somebody later who wants to do some processing on it if we don't collect it ","y you should also have a record of what 's on the board . but the outline is up here but i 'm just saying first of all there 's a whole bunch of fusion issues that darpa 's interested in . fusing gesture and face recognition , even lip movement and things like that , also cmu has been doing this and they have said , i talked to the student who had done this , that with two fairly inexpensive cameras they just recorded all the time think we would be we might lose the chance to use this data for somebody later who wants to do some processing on it if we don't collect it ",There is also interest in the speech community for fusion of speech with visual data. 
Buw001.B,"or you could put a paper bag over everybody 's head and not look at each other and not look at boards , and just all be sitting talking . that would be an interes bu i definitely won't participate if there 's a camera . no , it wa n not , not for cmu . they have a pretty crude set up . and they had they just turn on these cameras . they were not moving or anything . and stored it on analog media . and they didn't actually align it or anything . they just they have it , though .  they just they just had the videotapes with a c a counter  i 'm not  i 'm just the community if ldc collects this data u and l if mark liberman is a strong proponent of how they collect it and what they collect , there will probably be some video data in there . and that could argue for us not doing it or it could argue for us doing it . the only place where it overlaps is when some of the summarization issues are actually could be , easier made easier if you had the video .  of the board . or at least make that the note taker takes a sh a snapshot of the board . that 'll make it a lot easier for meetings that are structured . otherwise later on if nobody wrote this on the board down we 'd have a harder time summarizing it or agreeing on a summary . right . that would be the other alternative , to make that anything that was on the board , is in the record . ow . it 'd be useful to have a small amount of it just as a proof of concept . it will what you can do with things . but not to rely on them for basic modeling . wouldn't base any of the modeling on having those .  it 's just i 'd be it would  that w shouldn't be hard for without hearing each other though , probably . then you should try them a few weeks later and they have all these memory experiments about how little you actually retain and wasn't right , right . it is like shouldn't landay and his group be in charge of figuring out how to do this ? this is an issue that goes a little bit beyond where we are right now . they 're the expert we i don't remember it . i have like no recall memory . it 's interesting that he 's got this discussion free yet it 's separate . but the people will just look at the summaries or the minutes and re and back generate the queries . that 's what i 'm worried about . you might as just give him the summaries . and  how to do this from the summary . ",it 'd be useful to have a small amount of it just as a proof of concept . ,
Buw001.B,"what you want to h to do is , people who were there , who later see , minutes and s put in summary form , which is not gonna be at the same time as the meeting . there 's no way that can happen . are we gonna later go over it and make up some to which these notes would be an answer , or a deeper   but that 's done off they have to do that off line . you that 's a good one . dan doesn't sex he is .  going to see the kids . just wanted to say one thing about queries . the level of the query could be , very low level or very high level . and it gets fuzzier and fuzzier as you go up , right ? you need to have some if you start working with queries , some way of identifying what the if this is something that requires a one word answer or it 's one place in the recording versus was there general agreement on this issue of all the people who ha you can gen you can ask queries that are meaningful for people . they 're very meaningful cuz they 're very high level . but they won't exist anywhere in the a it but it may probably if you have to sit there at the end of a meeting and say one thing you remember , it 's probably whatever action item was assigned to you . in gen that 's all i remember from most meetings . in general , that could be something you could say , right ? i 'm supposed to do this . it doesn't that 's realistically what people might be remembering .    but you also should probably give them the mixed equal sound level they 're not gonna easily be able to do that , probably .   i i you should  you should that may be all that they want to send off to their transcribers . and xerox . and there 's you should l look under intelligent environments , smart rooms ,  right . and then right . j there 's th that 's where you would want to eventually be able to have a board or a camera , because of all these classroom  they 're still gonna overlap , but mark and others have said that there 's quite a lot of found data from the discourse community that has this characteristic and also the political y anything that was televised for a third party has the characteristic of not very much overlap .  like the , dominance relations of the people in the meeting .  and there was a big division , liberman and others were interested in a lot of found data . there 's lots of recordings that they 're not close talk mike , but and there 's lots of television , on , political debates and things like that , congre congressional hearings . ","the level of the query could be , very low level or very high level . if this is something that requires a one word answer or it 's one place in the recording versus was there general agreement on this issue of all the people who ha you can gen you can ask queries that are meaningful for people . but they won't exist anywhere in the a but mark and others have said that there 's quite a lot of found data from the discourse community that has this characteristic there 's lots of recordings that they 're not close talk mike , and there 's lots of television , on , political debates and things like that , congre congressional hearings . ","Candidate types are keyword searches, action items, elaboration on points of interest, and agreement between participants. "
Buw001.B,"boring like that .  and then the cmu folks and i were on the other side in cuz they had collected a lot of meetings that were like this and said that those are nothing like these meetings . there 're really two different kinds of data . and , we just left it as @ @ that if there 's found data that can be transformed for use in speech recognition easily , then we would do it , but newly collected data would be natural meetings .  as far as i know , they h have not . but e i 'm not  if people were interested they could talk to them , but i got the feeling there was some politics involved . no . i don't know . the you need to talk to waibel and but they had multiple mikes and they did do recognition , and they did do real conversations . but as far as i know they didn't offer that data to the community at this meeting . but that could change cuz mark mark 's really into this . we should keep in touch with him . what they mean is they don't have to fund to collect , and especially good "" found "" has , also the meaning that 's it very natural . it 's things occur without any the pe these people weren't wearing close talking mikes , but they were recorded anyway , like the congressional hearings and , for legal purposes or whatever . mark 's aware of those , too . that would be found data because they found it and it exists . they didn't have to collect it . it 's not "" found "" in the sense that at the time it was collected for the purpose . but what he means is that mark was really a fan of getting as much data as possible from reams and reams of of broadcast web tv radio but he understands that 's very different than these this type of meeting . but , what ? it 's still it 's interesting for other reasons . you can tell by the prosody . rrrh ! this is painful task . i pass . ","and then the cmu folks and i were on the other side in cuz they had collected a lot of meetings that were like this and , we just left it as @ @ that if there 's found data that can be transformed for use in speech recognition easily , then we would do it , but newly collected data would be natural meetings . but as far as i know they didn't offer that data to the community at this meeting . it 's things occur without any the pe these people weren't wearing close talking mikes , but they were recorded anyway , like the congressional hearings and , for legal purposes or whatever . ","The corpus could be enriched with found data (public or collected by other projects), if those prove appropriate for use in the project. "
Buw001.C,"katrin on channel two .     that 's true . and you 're gonna send it out by email , too .    that 's better . are you thinking about just asking one participant or all of them ? make it a voluntary thing , and then that 's why i was wondering . but when you go around the room you might just get the effect that somebody says something and then you go around the room and they say "" me too , i agree . ""     no , that 's fine . now , something that i mentioned earlier to mari and liz is that it 's probably important to get as many non technical and non speech people as possible in order to get some realistic users . if you could ask other people to call and use our system , that 'd be good . cuz we don't want people who already know how to deal with dialogue systems , who know that you shouldn't hyper articulate , and things like that .   your grandmother .    i agree with jane and eric . the question of how to generate queries automatically was the most interesting question that came up , and it 's something that , as you said , is a whole research topic in itself , don't think we 'll be able to do anything on it because we don't have funding on it , in this project . but , it 's definitely something i would want to do something on . ","now , something that i mentioned earlier to mari and liz is that it 's probably important to get as many non technical and non speech people as possible if you could ask other people to call and use our system , that 'd be good . ",
Buw001.D,"   are we recording now ? is this we 're we 're live .  what were we gonna talk about again ? we said data collection , which we 're doing . no . i it 'd be even better with this big it 's not that long . w u the element , n should be as close to you your mouth as possible .  alright . what we had was that we were gonna talk about data collection , and , you put up there data format , and other tasks during data collection , and realized we skipped the part that we were saying we were gonna do at the front where we each said who we were . roll call . no , not a no , my mind went elsewhere .  i 'm morgan , and where am i ? i 'm on channel three . i 'm rocky raccoon on channel suppose we broaden out and go to a range of meetings besides just these internal ones . there 's gonna be lots of things that any group of people who know each other have in column common that we will not know .  we were originally gonna do this with vlsi design , and the reason we didn't go straight to that was because immediately ninety percent of what we heard would be jargon to us .   that 's right . there were others  right . we can go back . there 's another problem which is , we certainly do want to branch out beyond , recording meetings about meeting recorder . and , once we get out beyond our little group , the people 's motivation factor , reduces enormously . and if we start giving them a bunch of other things to do , how we did n another meeting here for another group and , they were fine with it . but if we 'd said , "" now all eight of you have to come up with , the summar "" t see ? there we go . i i 'm worried that if you did even if you did push them into it , it might be semi random , as opposed to what you 'd really want to know if you were gonna use this thing . that we the f the core thing is that once we get some of these issues nailed down , we need to do a bunch of recordings and send them off to ibm and get a bunch of transcriptions even if they 're slightly flawed or need some other and then we 'll have some data there . and then , i we can start l looking and thinking , what do we want to know about these things and at the very least .   it that 's a good idea but that doesn't 'm missing something , but that doesn't get to the question of how we come up with queries , right ?  ","what we had was that we were gonna talk about data collection , and other tasks during data collection , and , once we get out beyond our little group , the people 's motivation factor , reduces enormously . ",The discussion concerned mainly ideas about data collection and the nature and generation of queries on meetings. 
Buw001.D,"that 's what is that it gets at something interesting but if we were asking the question , which we were , of of , "" how do we figure out what 's the nature of the queries that people are gonna want to ask of such a system ? "" , knowing what 's important doesn't tell you what people are going to be asking . does it ?   but we 're just looking for a place to start with that because , th what james is gonna be doing is looking at the user interface and he 's looking at the query in i we have five hours of pilot data of the other but we have zero hours of queries . he 's just going "" where do i start ? ""         i 've b been thinking i 've been thinking about it a little bit here about the th this , e that the now i 'm thinking that the summary a summary , is actually a reasonable , bootstrap into this into what we 'd like to get at . it 's not ideal , but we we have to get started someplace . was just thinking about , suppose we wanted to get w we have this collection of meeting . we have five hours of we get that transcribed . now we have five hours of meetings and , you ask me , "" morgan , what d what questions do you want to ask ? "" i wouldn't have any idea what questions i want to ask . i 'd have to get started someplace . if i looked at summary of it , i 'd go "" i was in that meeting , i remember that , what was the part that "" and th that might then help me to think of things even things that aren't listed in the summary , but just as a as a refresh of what the general thing was going on in the meeting .   that 's true too .  a adam , you can you can correct me on this , but , my impression was that , true that the meetings here , nobody sits with a w with a laptop and i but those are bigger deal things . right ? where you 've got fifteen peo most th this is one of the larger meetings . most of the meetings we have are four or five people and you 're not you don't have somebody sitting and taking minutes for it . you just get together and talk about where you are .     do they ?  li l l liz , you u liz , you sa you sat in on the , subcommittee meeting or whatever on you on the subcommittee meeting for at the , that workshop we were at that , mark liberman was having . wasn't there . they h must have had some discussion about video and the visual aspect , and all that .       ","but if we were asking the question , which we were , of of , "" how do we figure out what 's the nature of the queries that people are gonna want to ask of such a system ? "" , knowing what 's important doesn't tell you what people are going to be asking . i we have five hours of pilot data of the other but we have zero hours of queries . now i 'm thinking that the summary a summary , is actually a reasonable , bootstrap into this into what we 'd like to get at . now we have five hours of meetings and , you ask me , "" morgan , what d what questions do you want to ask ? "" i wouldn't have any idea what questions i want to ask . if i looked at summary of it , i 'd go "" i was in that meeting , and th that might then help me to think of things even things that aren't listed in the summary , but just as a as a refresh of what the general thing was going on in the meeting . ","Summaries could be used to bootstrap for queries, the exact nature of which remained nebulous. Candidate types are keyword searches, action items, elaboration on points of interest, and agreement between participants. "
Buw001.D,"to address what adam 's saying , you that the key thing there is that this is a description of database collection effort that they 're talking about doing . and if the database exists and includes some visual information that doesn't mean that an individual researcher is going to make any use of it . right ?  right . we 're gonna we 're gonna do what we 're gonna do , whatever 's reasonable for us . but having minimally , what dan is referring to at least having some representation of the p the spatial position of the people , cuz we are interested in some spatial processing . and       great idea .  for for our purposes we probably will d we might try that some and we certainly already have some recordings that don't have that , which , we 'll get other value out of , there you go . at the moment we should be determining this on the basis of our own , interests and needs rather than hypothetical ones from a community thing . as you say , if they decide it 's really critical then they will collect a lot more data than we can afford to , and will include all that .  i i 'm not worried about the cost of setting it up . i 'm worried about the cost of people looking at it . in other words , it 's it 'd be silly to collect it all and not look at it and think that we do have to do some picking and choosing of the that we 're doing . but i am int i do think that we m minimally want something we might want to look at some , subsets of that . like for a meeting like this , at least , take a polaroid of the of the boards , and a and know the position of the people   departing for the moment from the data collection question but actually talking about , this group and what we actually want to do , guess that 's th the way what you were figuring on doing was , putting together some notes and sending them to everybody from today ?    the question that we started with was whether there was anything else we should do during th during the collection . and the crosspads was certainly one idea , and we 'll get them from him and we 'll just do that . right ? and then the next thing we talked about was the summaries and are we gonna do anything about that .   what the point was to try again , to try to collect more information that could be useful later for the ui it 's landay supplying it that landay 's can be easier to do . it right now he 's g operating from zero , and even if we didn't get it done from uw , it seems like that would could still you shou ","minimally , what dan is referring to at least having some representation of the p the spatial position of the people , at the moment we should be determining this on the basis of our own , interests and needs rather than hypothetical ones from a community thing . like for a meeting like this , at least , take a polaroid of the of the boards , the question that we started with was whether there was anything else we should do during th during the collection . and the crosspads was certainly one idea , the point was to try again , to try to collect more information that could be useful later for the ui ","Taking some photos of the whiteboard and the positioning of participants is easy enough to do. The discussion concerned mainly ideas about data collection and the nature and generation of queries on meetings. Meeting notes taken by participants as standard minutes or summaries, or on devices like CrossPads can provide useful information. "
Buw001.D,"at least try it .   lot of the we 're doing now really is pilot in one sense or another . and we try it out and see how it works .     who does this summarization ?     ru  it 's like the note taking thing , that y that you can't certainly can't require it or people aren't gonna want to do this . but if there 's some cases where they will , then it would be helpful .  the fl the fluorescent light is flickering .       you still wanted to talk with liz . and you and i need to you already did the liz talk .    i 'm at your disposal . up to you . we should be able to wind up in another half hour you think ? less ? we still haven't talked about the action items from here and on . and  there 's gonna be these student projects that can do some things but it can't be , very deep . u i actually think that , again , just as a bootstrap , if we do have something like summaries , then having the people who are involved in the meetings themselves , who are cooperative and willing to do yet more , come up with queries , could at least give landay an idea of the things that people might want to know . ye right ? if he doesn't know anything about the area , and the people are talking about and ,    right . i would think that would be the most likely thing . hey .  boy , i don't know how we get at this   it 's gonna take some thought .  it seemed the interest that i had in this thing initially was , that i the form that you 're doing something else later , and you want to pick up something from this meeting related to the something else . it 's really the imp the list of what 's important 's in the something else rather than the and it might be something minor of minor importance to the meeting . if it was really major , if it 's the thing that really stuck in your head , then you might not need to go back and check on it even . it 's that you 're trying to find you 're you 've now you weren't interested say i said "" i wasn't that much interested in dialogue , i 'm more of an acoustics person "" . but thr three months from now if for some reason i get really interested in dialogue , and i 'm "" what is what was that part that , mari was saying ? ""   and then i 'm trying to fi that 's when i look in general when i look things up most , is when it 's something that didn't really stick in my head the first time around ","lot of the we 're doing now really is pilot it 's like the note taking thing , that y that you can't certainly can't require it or people aren't gonna want to do this . but if there 's some cases where they will , then it would be helpful . u i actually think that , again , just as a bootstrap , if we do have something like summaries , then having the people who are involved in the meetings themselves , who are cooperative and willing to do yet more , come up with queries , could at least give landay an idea of the things that people might want to know . and it might be something minor of minor importance to the meeting . and then i 'm trying to fi that 's when i look in general when i look things up most , is when it 's something that didn't really stick in my head the first time around ","The discussion concerned mainly ideas about data collection and the nature and generation of queries on meetings. Meeting notes taken by participants as standard minutes or summaries, or on devices like CrossPads can provide useful information. Summaries could be used to bootstrap for queries, the exact nature of which remained nebulous. "
Buw001.D,"and but for some new reason i 'm i 'm interested in the old i don't know .    that might get at some of what i was i was concerned about , being interested in something later that w i didn't consider to be important the first time , which for me is actually the dominant thing , because if it was really important it tends to stick more than if i didn't , but some new task comes along that makes me want to look up . having multiple people might get at some of that .   and this is a starting point .  w irreversible . what i keep coming back to in my own mind is that , the soonest we can do it , we need to get up some system that people who 've been involved in the meeting can go back later , even if it 's a poor system in some ways , and , and ask the questions that they actually want to know . if if as soon as we can get that going at any level , then we 'll have a much better handle on what questions people want to ask than in any anything we do before that . but we have to bootstrap somehow , and   right .  if we can figure out a way to jimmy a very rough system , say in a year , then that in the second and third years we actually have something to ask queries .  i 'm i 'm not agree with that . because b because it depends on , what our goal is . if our goal is wizard of oz ish , we might want to is it that people would really like to know about this data . and if it 's something that we don't know how to do yet , th great , that 's , research project for year four   not not true wizard of oz because people are too aware of what 's going on . but just  w just "" what would you like to know ? ""   i usually don't remember my action items . but i 'd i   we had somewhere up there we had milestones , but did y did you get enough milestone , from the description things ?  and , there 's detail behind each of those , as much as is needed . you just have to let us know . right . three of them . mean ,  mostly together . wh  i i w in our phone call , before , we , it turns out the way we 're gonna send the data is by , and , and then what they 're gonna do is take the cd rom and transfer it to analog tape and give it to a transcription service , that will  foot pedals and see , that 's a good question . no , it 'll be probably about like you did , ","and but for some new reason i 'm i 'm interested in the old what i keep coming back to in my own mind is that , the soonest we can do it , we need to get up some system that people who 've been involved in the meeting can go back later , even if it 's a poor system in some ways , and , and ask the questions that they actually want to know . if if as soon as we can get that going at any level , then we 'll have a much better handle on what questions people want to ask than in any anything we do before that . if we can figure out a way to jimmy a very rough system , say in a year , then that in the second and third years we actually have something to in our phone call , before , we , it turns out the way we 're gonna send the data is by , and then what they 're gonna do is take the cd rom and transfer it to analog tape and give it to a transcription service , that will  ","Candidate types are keyword searches, action items, elaboration on points of interest, and agreement between participants. An initial prototype system to test any hypotheses can be pipelined. The recorded data will be stored on CD-ROM's and sent to IBM for transcription. "
Buw001.D,"and then there will be some things many things that don't work out and that 'll go back to ibm and they 'll , they run their aligner on it and it kicks out things that don't work which the overlaps will certainly be examples of that . and , what w we will give them all of it . right ? we 'll give them all the multi channel and  good idea .  it 's also won't be adding much to the data to give them the mixed . right . and i was gonna m email them the which i haven't yet , a pointer to the web pages that we currently have , cuz in particular they want to see the one with the way the recording room is set up and on , your page on that .  we were gonna we w right .  what n important thing key thing will be that you we tell you what it is . we also had we also had the , that we were s that you were gonna get us the eight hundred number and we 're all gonna we 're gonna call up your communicator thing and we 're gonna be good slash bad , depending on how you define it , users .  we can do that .    my mother would have a very interesting conversation with it but it wouldn't have anything to do with the travel .  we talked about that we 're getting the recording equipment running at uw . and it depends , w e they 're they 're p m if that comes together within the next month , there at least will be , major communications between dan and uw folks as to but we have it 's pretty we don't know . he s he said that it was sitting in some room collecting dust and we don't know , i e we don't know . "" recording equipment . "" w we know it 's eight channels . we know it 's digital . we don't even know if there 're microphones .  we 'll find out .  i 'll do that . and he also said something about outside there that came up about the outside text sources , that he may have some text sources that are close enough to the thing that we can play with them for a language model .   but it 's p it might be  why search for them ? they 're we know where they are . that 's true .  we can we can do better than that .  there 's some , carnegie mellon right ? on meeting recording , and and xerox .     wasn but w we were saying before also that the natural language group here had less overlap . it also depends on the style of the group of people .    did they discuss any of that in the meeting they had with l liberman ? what what do they    ","and then there will be some things many things that don't work out right . and i was gonna m email them the which i haven't yet , a pointer to the web pages that we currently have , cuz in particular they want to see the one with the way the recording room is set up we also had the , that we were s that you were gonna get us the eight hundred number we 're gonna call up your communicator thing and we 're gonna be good slash bad , depending on how you define it , users . we talked about that we 're getting the recording equipment running at uw . and he also said something about outside there that came up about the outside text sources , that he may have there 's some , carnegie mellon right ? it also depends on the style of the group of people . ","Finally, project web pages and mailing list are being set up and UW are going to investigate the suitability of their recording equipment. "
Buw001.D,"actually , th @ @ the cmu folk have collected a lot of data . is that going to be publicly available , or ?  just to check . w we should 's out there certainly .  they only did the far field ? i see .  once we send out we still haven't sent out the first note saying "" hey , this list exists "" . but , once we do that it 's on i already added that one on my board to do that .   hopefully everybody here is on that list . we should at least check that everybody here ?  we haven't sent anything to the list yet . we 're just compiling the list .    seems like we 're winding down . right ? many ways . good man .  being more management lately than research , the thing that impressed me most was the people dynamics and not any of the facts . that is , i really enjoyed hanging out with this group of people today . that 's what really impressed me .  i 'd probably search for something like that .   find me a funny thing that jeff said .  think we 're done . great . now these we turn off . right ? ","actually , th @ @ the cmu folk have collected a lot of data . we still haven't sent out the first note saying "" hey , this list exists "" . we 're just compiling the list . ",
Buw001.E,"  it 's a good idea . which way is mari ? y your thing may be pointing in a funny direction . it 's it helps if it points upwards . it   that thing the little th that part should be pointing upwards . that 's it .  that 's good . that thing is good .   it 's a it 's working . right . we because you 'd have several people with these pads , you could collect different things . cuz i tend to take notes which are summaries . and i 'm dan ellis . let me , turn that off . pzm nearest , next nearest . next one . furthest . pdm right , pza right pda right , pda left .   right . although but , summary is one of the things we 'd want from the output of the system . right ? they 're something . it 's a output you 'd like .  activity .  see , there are th  but th there is this , there is this class of queries , which are the things that you didn't realize were important at the time but some in retrospect you think "" hang on , didn't we talk about that ? "" and it 's something that didn't appear in the summary but you and that 's what this complete data capture is nicest for . cuz it 's the things that you wouldn't have bothered to make an effort to record but they get recorded . and th there 's no way of generating those , u until we just until they actually occur . it 's like right , right . exactly . but it 's difficult to say "" and if i was gonna ask four questions about this , what would they be ? "" those aren't the things that come up .       i 've d when we have other meetings . when i have meetings on the european projects , we have someone taking notes . i often do it .  how many people are those meetings ?  we sh we should i don't know . f u for this data capture , it would be to have a digital camera just to take pictures of who 's there , where the microphones are , and then we could also put in what 's on the board . like three or four snaps for every for every meeting . no . think that right now we don't make a record of where people are sitting on the tables . and that the at some point that might be awfully useful .  we n not as part of the not as a part of the data that you have to recover . just in terms of   actually  people with radio mikes can go into separate rooms and continue recording without hearing each other . that 's the thing . that 's right . that 's the interesting thing , though . ","right . we because you 'd have several people with these pads , you could collect different things . but th there is this , there is this class of queries , which are the things that you didn't realize were important at the time but some in retrospect you think "" hang on , didn't we talk about that ? "" and it 's something that didn't appear in the summary but you for this data capture , it would be to have a digital camera just to take pictures of who 's there , where the microphones are , and then we could also put in what 's on the board . like three or four snaps for every ","Meeting notes taken by participants as standard minutes or summaries, or on devices like CrossPads can provide useful information. Taking some photos of the whiteboard and the positioning of participants is easy enough to do. "
Buw001.E,"if we do if we collect four different summaries , we 're gonna get all this weird data about how people perceive things differently . it 's like this is not what we meant to research .   it 's  right . hello . dan here .  mari ? someone wants to know when you 're getting picked up . is someone picking you up ? five thirty . sounds  h bye . that 's that . really .  you can keep it on .  cuz you 'll get very different answers from everybody , right ?   on the other hand people might try and come up with different ones , right ? they might say "" i was gonna say that one but now i have to think of something else "" .  right .   and "" interesting "" is more interesting than "" important "" .  there is still this hope that people might actually think of real queries they really want to ask at some point . and that if that ever should happen , then we should try and write them down . really . if they 're real queries .     research , we 'd have to listen to all the data . just imagine if get people to ask questions that they def the machine definitely can't answer at the moment , but  yes .  then we 'll know . right . we we need to look at our web page and make one that 's that 's p pda free .    right .    we should talk about it , but  that was that was what he was saying was this he this thing that , jason had been working on finds web pages that are thematically related to what you 're talking about . that 's the idea . that would be a source of text which is supposedly got the right vocabulary . but it 's very different material . it 's not spoken material ,      right .   we can do that . turn off really ? it 's those guys . who specifically ask not to be . "" hey , look what we found ! "" "" i found this great corpora . ""  we should go around and s we should go around and say something interesting that happened at the meeting ? i had a real revelation about taking pictures . i don't know why i didn't do this before and i regret it . that was very interesting for me . not that i the boards aren't really related to this meeting . i will take pictures of them , but but  that 's why i 'll take pictures of them , then . for the moment . how are we gonna find that in the data ?  right . how happy were they ? that 's great .  perfect .  great . ","that was that was what he was saying was this he this thing that , jason had been working on finds web pages that are thematically related to what you 're talking about . that would be a source of text which is supposedly got the right vocabulary . we should go around and say something interesting that happened at the meeting ? ",
Buw001.F,"no , that wasn't recorded . temple squeezers . have to d stop doing this sigh of contentment , after sipping cappuccino i was just noticing a big s the down side to that is that he indicated that the , quality of the handwriting recognition was quite poor .  right . eric on channel nine . there 's there 're sub problems in that , in that where or when do you actually ask them about that ? that was one thing i was thinking about was is that dan said earlier that , two weeks later , which is when you would want to query these things , you might ask them then . but there 's a problem with that in that if you 're not if you don't have an interactive system , it 's gonna be hard to go beyond the first level of question . right . and furth id explore the data further .  did they store it digitally , or ? or just put it on videotape ? or even just have one or two people stay behind .   have a question about queries , which is ,  i don't know . there you go .  good .  the question i had about queries was , what we 're planning to do is have people look at the summaries and then generate queries ? are we gonna try and o   the question i had is have we given any thought to how we would generate queries automatically given a summary ? that 's a whole research topic un unto itself , that it may not be a feasible thing . but n i 'm not that 's a solved problem . right ? of how to generate queries from a that was what my question was aimed towards . do we the question then is h how much bias do we introduce by introduce by saying , this was important now and , tha something else is important later ? does it does the bias matter ? i don't know . that 's , a question for you guys . but   but that 's the question , really , is that does building queries based on what 's important now introduce an irreversible bias on being able to do what morgan wants to do later ? that 's that 's right .  i agree . important "" can often be uninteresting . but w it 's not right . it doesn't it isn't difficult for us to do , we might as just do it . "" here 's a mysterious file and "" adam ! i 'm not .   i see . i 'm gonna pass because i can't of the jane took my answer .   'm gonna pass for the moment but y come back to me . one thing you could search for is were people laughing a lot . right ?  no .  ","the down side to that is that he indicated that the , quality of the handwriting recognition was quite poor . in that where or when do you actually ask them about that ? the question i had about queries was , what we 're planning to do is have people look at the summaries and then generate queries ? the question i had is have we given any thought to how we would generate queries automatically given a summary ? that 's a whole research topic un unto itself , ","Summaries could be used to bootstrap for queries, the exact nature of which remained nebulous. "
Buw001.G,"headphones that aren't uncomfortable . i don't think no . i don't think they 're designed to be over your ears .  but i definitely haven't figured it out . "" sip , sigh . "" that u usually we 've done that and also we 've s done digits as but i forgot to print any out .  besides with this big a group , it would take too much time . but it takes too much time . especially for querying . landay . james . but if we had the crosspads , we could ask people , if something comes up write it down and mark it somehow ,  but that 's alright . i don't think there 'd be many that you couldn't have someone clean it up pretty easily .  and i 'm adam janin on channel a . and , do you want to do the p d as and the p z far . and eventually once this room gets a little more organized , the jimlets will be mounted under the table , and these guys will be permanently mounted somehow . probably with double sided tape , but you we won't have to go through that . that was just one of the reasons . but , definitely . and i asked them to and none of them did . i asked them to send me ideas for queries after the meeting and no one ever did . i didn't follow up either . didn't track them down and say "" do th do it now "" . but , no one spontaneously provided anything . don't know how else to generate the queries other than getting an expert to actually listen to the meeting and say "" that 's important , that might be a query "" . that gives you a summary but it doesn't really how do you generate queries from that ? james and i were talking about this during one of the breaks . and the problem with that is , i 'm definitely going to do something with information retrieval even if it 's not full bore what i 'm gonna do for my thesis . i 'm gonna do something . i 'm not gonna do anything with summarization . and if someone wants to do that , that 's fine , but it 's not gonna be me .  i see . y i this would tell you what the hit is , not what the query is . what and you could you can generate a query from the hits , but  that 's difficult because then they 're not gonna ask the questions that are in the summary . but , it would give  th it has to be a participant . it doesn't have to be . that is another use of meeting recorder that we haven't really talked about , which is for someone else , as opposed to as a remembrance agent , ","but if we had the crosspads , we could ask people , if something comes up write it down and mark it somehow , don't know how else to generate the queries other than getting an expert to actually listen to the meeting and say "" that 's important , ","Summaries could be used to bootstrap for queries, the exact nature of which remained nebulous. "
Buw001.G,"which is what had been my primary thought in the information retrieval part of it would be . but , if you had a meeting participant , they could use the summary to refresh themselves about the meeting and then make up queries . but it 's not i don't know how to do it if until you have a system . that 's what i was saying . but at least it would get us started .  although it seems like that 's , a high burden on the note taker . that 's a pretty fine grain that the note taker will have to take . but they  right . that 's a little bit of a problem . their note taking application they 've been doing for the last couple of years , and i don't think anyone is still working on it . they 're done . 'm not that they have anyone currently working on notes . what we 'd have to interest someone in is the combination of note and speech . and the question is "" is there such a person ? "" and right now , the answer is "" no "" . we 'll just have to see .  then you want to have it . by hand . minutes . never . never . i 've never seen it at icsi . does anyone ? dan is the one who most frequently would take notes , and really ? that 's true are four or five people . culture . the iram meeting , they take notes every there 's person with a laptop at each meeting . there are more . there are ten ish . they 're very sparse . this is something early in the project we talked a lot about . i agree , but you just you g end up with video , and instrumented rooms . and that 's a different project , different but don't you think that 's don't you think that but  right . but adding photographs adds a whole nother level of problems .  but that it 's gonna be a lot of effort on our part to create it , and store it , and get all the standards , and to do anything with it .   low fidelity .  right . once the room is a little more fixed that 's a little easier cuz you 'll the wireless . but  i don't disagree . that if you have that , then people who are interested in vision can use this database . the problem with it is you 'll have more people who don't want to be filmed than who don't want to be recorded . that there 's going to be another group of people who are gonna say "" i won't participate "" .  but , that 's a lot of infrastructure and work . to set it up and then anonymize it ?   couldn't find it ?  except in ","if you had a meeting participant , they could use the summary to refresh themselves about the meeting and then make up queries . but adding photographs adds a whole nother level of problems . but that it 's gonna be a lot of effort on our part to create it , and store it , and get all the standards , and to do anything with it . that if you have that , then people who are interested in vision can use this database . the problem with it is you 'll have more people who don't want to be filmed than who don't want to be recorded . but , that 's a lot of infrastructure and work . ",
Buw001.G,"er , if we weren't recording this , this would get lost . right ? that we 're not saving it anyway . right ? in our real life setting . in that case we don't need to take pictures of it .  and they seem to not be able to give enough of them away , we could probably get more as i 'm not it will again depend on landay , and if he has a student who 's interested , and how much infrastructure we 'll need . if it 's easy , we can just do it . but if it requires a lot of our time , we probably won't do it . we have to figure out what we 're gonna do . right . right . i ag agree with that . though , the importance marking is a good idea , though . that if people have something in front of them  do it on pilots or laptops if something 's important everyone clap . that 's right .  that 's fine .  what i was gonna say is that i don't want to ask people to do something they wouldn't normally do in a meeting . it 's ver want to keep away from the artificiality . but it definitely if they exist . and then jane 's idea of summarization afterward is not a bad one .  picking out to let you pick out keywords , and , construct queries . people in the meeting . just at the end of the meeting , before you go , go around the table .  ugh .  and see score them ?   i d i don't know how you would do it , though .  running to  fff ! is email easier ? i when you first said do it , spoken , what i was thinking is , then people have to come up and you have to hook them up to the recorder . if they 're already here that 's good , but if they 're not already here for i 'd rather do email . i 'm much faster typing than anything else .  i don't know . at  read the digits , do the summary . god , that 's bugging me . can we turn that light off ? if can we turn that just that let there 's a very annoying . much better . too much caffeine . it was the projector for a moment . it was like , "" what 's going on ? "" we 've just been talking , how do we generate queries ? and that was one suggestion . and what ? at least . m i even if that much ? less . in answer to "" is it landay 's problem ? "" , he doesn't have a student who 's interested right now in doing anything . he has very little manpower . there 's very little allocated for him ","though , the importance marking is a good idea , though . what i was gonna say is that i don't want to ask people to do something they wouldn't normally do in a meeting . and then jane 's idea of summarization afterward is not a bad one . ",
Buw001.G,"and also he 's pretty focused on user interface . don't think he wants to do information retrieval , query generation , that y but i , right . or just a memory refresher . i agree . we 're still here . as many are willing to do it . one thing we could do is for the meetings we 've already done i we didn't take minutes and we don't have summaries . but , people could listen to them a little bit and generate some queries . jane doesn't need to . i 'm you have that meeting memorized by now .  or want to get up and leave . me too , me too .  you have the other thing , that they know why we 're doing it . we 'll we 'll be telling them that the reason we 're trying to do this is to d generate queries in the future , try to pick things that other people didn't say . right . like jim bass says "" add a few lines on dialogue in your next perf "" but that 's gonna be very hard to generate . but but what 's interesting to me may not b have been interesting to you . by by going around  you can't get of it , right ? w we just need to start somewhere .  importance ? i wouldn't even say that "" that they learned "" . you might want to mention something that you brought up . that 's like n that 's gonna predominantly end up being whoever takes down the equipment then . that would be , let 's see , me . give them a reward , a dollar a query ?   we 're gonna  think we 're gonna have to start with keywords and if someone becomes more interested we could work our way up . but really ? that 's true . i was thinking about wizard of oz , but it requires the wizard to know all about the meetings .  i understand .  but that neither could anyone else , though , is what , my point is . right . since we have the transcript . dates i don't know . that 's something i always forget . that 's all i wrote down . can you hand me my note pad ?   right . mailing lists . how quickly do you want it ? my july is really very crowded . and  that 's right . dot berkeley dot edu , is this ibm ? do they how are they gonna do the multi channel ?  mix ? that 's , my question . we 'll give them all sixteen channels and they 'll do whatever they want with it . it 's not hard .     and then p possibly not an immediate action item but something we do have to worry about is data formats for higher level information . or d or not even higher level , ","we 'll we 'll be telling them that the reason we 're trying to do this is to d generate queries in the future , think we 're gonna have to start with keywords is this ibm ? do they how are they gonna do the multi channel ? not an immediate action item but something we do have to worry about is data formats for higher level information . ","Candidate types are keyword searches, action items, elaboration on points of interest, and agreement between participants. The recorded data will be stored on CD-ROM's and sent to IBM for transcription. "
Buw001.G,"different level , prosody and all that we 're gonna have to figure out how we 're gonna annotate that . but that 's not that 's display . that 's different than format . get my parents to do it . my father would last through the second prompt before he hang hung up . he would never use it .  what is it ?  it 's a tape recorder . it 's eight tape recorders .   un unfortunately landay told me that jason is not gonna be working on that anymore . he 's switching to other again . who ? landay or jason ?  true .  but that 's not very much .  that 's what his software does is h it picks out keywords and does a google like search . you could   the "" georgia tech classroom two thousand "" is a good one . georgia tech did a very elaborate instrumented room . and i want to try to stay away from that .   it 's also it 's not near far , right ? @ gonna add that to one of my action items .  cuz i had thought they 'd only done far field , intelligent room sorts of things . i hadn't known that then they 'd done any more than that .   everyone here is on the list . you are . i added a few people who didn't who i knew had to be on it even though they didn't tell me . like jane , you are on it , aren't you ?  "" psst . want to buy a corpora ? "" it 's not the same . now , i was already thinking about it ,   i really liked the idea of what was interesting was the combination of the crosspad and the speech . especially , the interaction of them rather than just note taking . can you determine the interesting points by who 's writing ? can you do special gestures and on that have , special meaning to the corpora ? i really liked that . did you take pictures of the boards ? to the pre previous meeting . that 's right .  i wonder if work 's already been done on it . if we had people wearing the wireless mikes all the time  that actually has come up a couple times in queries . i was talking to landay and that was one of his examples . when did people laugh ? we need a laugh detector . cuz that seems to be pretty common . not in the congressional hearings . quiet sobbing . we 're done . ","different level , prosody and all that we 're gonna have to figure out how we 're gonna annotate that . but that 's not that 's display . the "" georgia tech classroom two thousand "" is a good one . ",There is also work being done on the annotation of prosody. 
Buw001.H,"what otherwise you just get a heartbeats . it 's a one thing that came up in the morning was the , i if he i , if he has s i don't remember , mister lan doctor landry ? la landay ? he has , these , tsk note taking things , then that would be a summary which you wouldn't have to solicit . y if we were able to do that .   the roll call . i 'm jane edwards , on channel b . should we have used pseudo names ? should we do it a second time with pseudo no . no . next nearest .  i have a question on protocol in these meetings , which is when you say "" jimlet "" and the person listening won't that is , sh shou how do we get is that important information ? the jimlet the box that contains the   good .  good . we were on the data collection and the summary issue .  tsk . there is this other thing which y which you were alluding to earlier , which is , there are certain key words like , "" action item "" and things like that , which could be used in , t to some degree finding the structure . and i also , was thinking , with reference to the n note taking , the advantage there is that you get structure without the person having to do something artificial later . and the fir third thing i wanted to say is the summaries afterwards , they should be recorded instead of written because that , it would take long for people to write that you wouldn't get as good a summary . good . good point .    that 's a idea .  i also think that w if you can use the summaries as an indication of the important points of the meeting , then you might get something like y if th if the obscure item you want to know more about was some form of data collection , the summary would say , "" we discussed types of na data collection "" . and , and you could get to it by that . if you had the larger structure of the discourse , then if you can categorize what it is that you 're looking for with reference to those l those larger headings , then you can find it even if you don't have a direct route to that . that that , there 's we 're using "" summary "" in two different ways . what you just described i would describe as "" minutes "" . and what i originally thought was , if you asked someone "" what was the meeting about ? "" and then they would say "" we talked about this and then we talked about that , and and talked about "" and then you 'd have , like ","which is when you say "" jimlet "" and the person listening won't that is , sh shou how do we get is that important information ? and i also , was thinking , with reference to the n note taking , the advantage there is that you get structure without the person having to do something artificial later . and the fir third thing i wanted to say is the summaries afterwards , they should be recorded instead of written ",Another option would be the recording by participants of short oral summaries of the meeting. 
Buw001.H,"i e my thought was to have multiple people summarize it , on recording rather than writing because writing takes time and you get irrelevant other things that u take time , that whereas if you just say it immediately after the meeting , a two minute summary of what the meeting was about , you would get , with mult see , i also worry about having a single note taker because that 's just one person 's perception . and , it 's releva it 's relative to what you 're focus was on that meeting , and people have different major topics that they 're interested in . my proposal would be that it may be worth considering both of those types , the note taking and a spontaneous oral summary afterwards , no longer than two minutes , from multiple people .  i agree . i agree . that 's wonderful . i agree .  it 's just a digital record . yes , i agree . i agree . it 's i because discourse is about things , and then you have the things that are about , and it 's recoverable . yes . and it 's simple . like you said , three snapshots and just to archive .    i agree . and if it 's simple as as simple as just the digital   she 's not making  there 's that 'd be the parallel , but she 's we 're just proposing a minimal preservation of things on boards , sp spatial organization and you could anonymize the faces for that matter . this is we can talk about the it 's just one snapshot . we 're not talking about a movie . we 're talking about a snapshot .    it 's worth considering . we don't want to spend that much more time discussing it , but  th if it 's easy to collect it th then it 's a wise thing to do because once it 's gone . and   exactly . exactly . we and it especially since this is common knowledge . this is shared knowledge among all the participants , and it 's a shame to keep it off the recording . s i don't understand that point . think that the   i agree . that 's great . i 'm thinking that   how fascinating . that could be very interesting .  if  i 'd just try however the least intrusive and quickest way is , and th and closest to the meeting time too , cuz people will start to forget it as soon as they l leave .  w i would s  and i 'm also wondering , couldn't that be included in the data sample that you could increase the num the words that are , recognized by a particular individual ? if you could include the person 's meeting and also the person 's summary that would be an ad addition to their database . under the same acoustic circumstance , ","i e my thought was to have multiple people summarize it , on recording rather than writing whereas if you just say it immediately after the meeting , a two minute summary of what the meeting was about , you would get , my proposal would be that it may be worth considering both of those types , the note taking and a spontaneous oral summary afterwards , but she 's we 're just proposing a minimal preservation of things on boards , ",Another option would be the recording by participants of short oral summaries of the meeting. 
Buw001.H,"cuz if they just walk next door with their set up , nothing 's changed , just you turn let the record show the light is flickering . i 'm also wondering if we could ask the people a question which would be "" what was the most interesting thing you got out of this meeting ? "" becau in terms of like informativeness , it might be , that the summary would not in even include what the person thought was the most interesting fact . you get two different types of information . because you get the general structure of important points and what the meeting was about . you get the general structure , the important points of what the meeting was about with the summary . but with the "" what 's the most interesting thing you learned ? "" the fact that , i know that transcriber uses snack is something that was interesting and that dan worked on that . thought that was really  you could ge pick up some of the micro items that wouldn't even occur as major headings but could be very informative . it wouldn't be too , cost intensive either . it 's like something someone can do pretty easily on the spur of the moment .    and that it would pick up the micro structure , the some of the little things that would be hidden . that would be interesting .  and one thing , we 're saying "" important "" and we 're saying "" interesting "" . and those can be two different things .  good .   i will say that i chose "" interesting "" because it includes also "" important "" in some cases . but , i feel like the summary gets at a different type of information . and also i it puts a lot of burden on the person to evaluate . inter "" interesting "" is non threatening in     k  that 's good . i like that . i like that .   a and one qualification on the oral summaries . they 'd be s they 'd be separate . they wouldn't be hearing each other 's summaries . and that would also be that the data would be included in the database .      i was wondering if there might be one s more source of queries which is indicator phrases like "" action item "" , which could be obtained from the text from the transcript .  that 's something to be determined , something to be specified , but text oriented . you 'd remember that , that 's true . but then you could prompt them to say , "" other than your action item "" , whatever . but the action item would be a way to get , an additional query .   but but you could get again @ @   good .    you could email to both of us , just if you wanted to . i don't think either of us would mind recei ","i 'm also wondering if we could ask the people a question which would be "" what was the most interesting thing you got out of this meeting ? "" it might be , that the summary would not in even include what the person thought was the most interesting fact . you could ge pick up some of the micro items that wouldn't even occur as major headings it wouldn't be too , cost intensive either . they 'd be s they 'd be separate . they wouldn't be hearing each other 's summaries . and that would also be that the data would be included in the database . i was wondering if there might be one s more source of queries which is indicator phrases like "" action item "" , which could be obtained from the text from the transcript . ","Candidate types are keyword searches, action items, elaboration on points of interest, and agreement between participants. "
Buw001.H,"but in any case i 'd be happy to send you the edwards at icsi . using foot pedals and they don't have a way . but they have a verification . i did . i m emailed them the transcriber url , the on line , data that adam set up , the url they can click on an utterance and hear it . and i emailed them the str streamlined conventions which you got a copy of today . good . excellent . good . i c i cc ' ed morgan . i should have sent i should have cc ' ed you as we did . we discussed , musi musical score notation and and its xml   excellent . it c great .  can i ask , one thing ? it relates to data collection and i and i 'd and we mentioned earlier today , this question of  i s i know that from with the near field mikes some of the problems that come with overlapping speech , are lessened . but i wonder if is that sufficient or should we consider getting some data gathered in such a way that , u w we would c p have a meeting with less overlap than would otherwise be the case ? either by rules of participation , or whatever . now , it 's true , we were discussing this earlier , that depending on the task if you 've got someone giving a report you 're not gonna have as much overlap . but , i we 're gonna have s non overlapping samples anyway . but , in a meeting which would otherwise be highly overlapping , is the near field mike enough or should we have some rules of participation for some of our samples to lessen the overlap ?   just want to be there 's enough data to good .   on the task , and the task . it 's just wanted to because it is true people can modify the amount of overlap that they do if they 're asked to . not entirely modify it , but lessen it if it 's desired . but if that 's sufficient data wanted to be that we will not be having a lot of data which can't be processed . time . fine . and i i know that the near f near field mikes will take care of also the problems to s to a certain degree . wanted to be   as a contributary know that in l in legal depositions people are pr are prevented from overlapping . they 'll just say , "" till each person is finished before you say something "" . it is possible to lessen if we wanted to . but these other factors are fine . wanted to raise the issue .    that 's always desired . want to be we don't that we 're able to process , i u as much data as we can .   u e  i am . ","i m emailed them the transcriber url , the on line , data that adam set up , they can click on an utterance and hear it . and i emailed them the str streamlined conventions we discussed , musi musical score notation i s i know that from with the near field mikes some of the problems that come with overlapping speech , are lessened . if you 've got someone giving a report you 're not gonna have as much overlap . but , in a meeting which would otherwise be highly overlapping , is the near field mike enough or should we have some rules of participation for some of our samples to lessen the overlap ? wanted to be that we will not be having a lot of data which can't be processed . ",
Buw001.H,"i w just for clarification . found data "" , they mean like established corpora of linguistics and other fields , right ? it sounds like such a t   but it includes like standard corpora that have been used for years in linguistics and other fields .  exactly .  that 's interesting .    just wanted to know . realized there 's another category of interesting things which is that , i found this discussion very , i this question of how you get at queries really interesting . and the and i and the fact that it 's nebulous , what that what query it would be because it depends on what your purpose is . actually found that whole process of trying to think of what that would involve to be interesting . but that 's not really a specific fact . thought we went around a discussion of the factors involved there , which was worthwhile .   that 's a good point .   like e expert systems and or ?   h do we need do i need to turn something off here , or i do unplug this , or ? ","found data "" , they mean like established corpora of linguistics and other fields , right ? but it includes like standard corpora that have been used for years in linguistics and other fields . ","The corpus could be enriched with found data (public or collected by other projects), if those prove appropriate for use in the project. "
