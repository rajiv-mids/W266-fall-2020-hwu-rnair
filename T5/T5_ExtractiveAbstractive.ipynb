{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"T5_ExtractiveAbstractive.ipynb","provenance":[{"file_id":"1QmLVy9BRlWkwzqGb3xeCLAcSerUVBLTi","timestamp":1606592557699},{"file_id":"1AZtUbaz75zZAztw1LI9uWV2PoH3BAKOu","timestamp":1605978559499},{"file_id":"1UF8WpYXCqNkWZi7JfeLBISki5zkxoR1T","timestamp":1605490905789}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"26795496a54a4322b3de446a439e5db8":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8b5fa38084284294af3c9eaddecffaa4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1c5f46b827ae42b9b61dbb80a35c3ad8","IPY_MODEL_bcd508bf905a48daaaf6c2e715e825d8"]}},"8b5fa38084284294af3c9eaddecffaa4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1c5f46b827ae42b9b61dbb80a35c3ad8":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","state":{"_view_name":"LabelView","style":"IPY_MODEL_e9648c49d6474a5d951a257a274899e0","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 13.63MB of 13.63MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3c7d5b349eb042ceb05f5daa592ac688"}},"bcd508bf905a48daaaf6c2e715e825d8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4bf5bf69096f44ee9df44ba7c79a3799","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a4856c9358184d6bbd815f6b22a8685b"}},"e9648c49d6474a5d951a257a274899e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3c7d5b349eb042ceb05f5daa592ac688":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4bf5bf69096f44ee9df44ba7c79a3799":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a4856c9358184d6bbd815f6b22a8685b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"6JMpA3Pi4rr9"},"source":["# T5 Baseline\n","\n","The initial exploration will use T5-small as the pre-training model along with ICSI dataset. When the model is ready, we will expand the dataset and also validation set for other hyperparameter tuning.\n","\n","1. Library Loading  \n","2. Dataset Loading\n","3.   Dataset Transformation\n","4.   Training and Test Splitting\n","5.   Fine Tuning\n","6.   Checkpoint saving\n","7.   Evaluation\n","\n"]},{"cell_type":"markdown","metadata":{"id":"lyAat9uX5rJn"},"source":["## Library Loading"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BODRVvgf5RGZ","executionInfo":{"status":"ok","timestamp":1606750890442,"user_tz":300,"elapsed":12191,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"ffb570a7-1b1c-4c47-e9fb-f22d4f89ed41"},"source":["!pip install transformers -q\n","!pip install wandb -q\n","#!pip install datasets\n","!pip install nlp\n","#!pip install rouge_score\n","!pip install rouge\n","#!curl -q https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n","#!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: nlp in /usr/local/lib/python3.6/dist-packages (0.4.0)\n","Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from nlp) (2.0.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from nlp) (4.41.1)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from nlp) (0.8)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.6/dist-packages (from nlp) (2.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from nlp) (3.0.12)\n","Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from nlp) (0.3.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from nlp) (1.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from nlp) (1.18.5)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from nlp) (2.23.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->nlp) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->nlp) (2018.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2020.11.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (3.0.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->nlp) (1.15.0)\n","Requirement already satisfied: rouge in /usr/local/lib/python3.6/dist-packages (1.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rouge) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eqwv6NyQ_Wjl","executionInfo":{"status":"ok","timestamp":1606750898916,"user_tz":300,"elapsed":20657,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","import time\n","\n","# Importing the T5 modules from huggingface/transformers\n","# T5ForConditionalGeneration is specific for sequence-to-sequence\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","\n","#from nlp import load_metric\n","import nlp\n","from rouge import Rouge\n","\n","import wandb"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U8XNh-h8_g0_","executionInfo":{"status":"ok","timestamp":1606750898917,"user_tz":300,"elapsed":20652,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"976b6204-9fdc-46ed-ed20-29b84d647dbd"},"source":["# Checking out the GPU we have access to. This is output is from the google colab version. \n","!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mon Nov 30 15:41:38 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P0    24W / 300W |     10MiB / 16130MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gtYB7VvI_jm4","executionInfo":{"status":"ok","timestamp":1606750898918,"user_tz":300,"elapsed":20647,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["# # Setting up the device for GPU usage\n","from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PcXUpiwbe8Cs","executionInfo":{"status":"ok","timestamp":1606750900843,"user_tz":300,"elapsed":22566,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"5a222104-2757-48cb-f764-ee4dace42bc7"},"source":["!wandb login\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwuqq09\u001b[0m (use `wandb login --relogin` to force relogin)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Xqq1uu8hA49j"},"source":["## Data Loading\n","\n","Loaded from GDrive the transformed dataset.\n","\n","This portion is using the dataset from extractive summary to abstractive summary"]},{"cell_type":"code","metadata":{"id":"XGXLrMD7GC4O","executionInfo":{"status":"ok","timestamp":1606750900844,"user_tz":300,"elapsed":22561,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","train_size = 0.8"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cvq382j4A3MC","executionInfo":{"status":"ok","timestamp":1606750902058,"user_tz":300,"elapsed":23770,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"bd1af1bc-d9ed-4fb9-ae87-d5c080cb3684"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","#/content/drive/My Drive/W266/data/ICSI_extrac_abstrac_512token.csv"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DysKSkQoBpfE","executionInfo":{"status":"ok","timestamp":1606764734818,"user_tz":300,"elapsed":3171,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"2205159e-0690-4006-e04b-49499c86cd73"},"source":["#df = pd.read_csv('/content/drive/My Drive/W266/512_tokens/ICSI_extrac_abstrac_512token.csv',encoding='latin-1')\n","#df = df[df['extractive'].notna()][['abstractive','extractive']]\n","train_dataset_1 = pd.read_csv('/content/drive/My Drive/W266/data/1024_tokens/ICSI_1024_train_cleaned_eax.csv',encoding='latin-1')\n","dev_dataset_1 = pd.read_csv('/content/drive/My Drive/W266/data/1024_tokens/ICSI_1024_dev_cleaned_eax.csv',encoding='latin-1')\n","test_dataset_1 = pd.read_csv('/content/drive/My Drive/W266/data/1024_tokens/ICSI_1024_test_cleaned_eax.csv',encoding='latin-1')\n","train_dataset_2 = pd.read_csv('/content/drive/My Drive/W266/data/1024_tokens/AMI_1024_train_cleaned_eax.csv',encoding='latin-1')\n","dev_dataset_2 = pd.read_csv('/content/drive/My Drive/W266/data/1024_tokens/AMI_1024_dev_cleaned_eax.csv',encoding='latin-1')\n","test_dataset_2 = pd.read_csv('/content/drive/My Drive/W266/data/1024_tokens/AMI_1024_test_cleaned_eax.csv',encoding='latin-1')\n","\n","train_dataset = pd.concat([train_dataset_1,train_dataset_2])\n","#dev_dataset = pd.concat([dev_dataset_1,dev_dataset_2])\n","dev_dataset = dev_dataset_2\n","test_dataset = pd.concat([test_dataset_1,test_dataset_2])\n","\n","#train_dataset = train_dataset[train_dataset.abstractive.notna()]\n","#dev_dataset = dev_dataset[dev_dataset.abstractive.notna()]\n","#test_dataset = test_dataset[test_dataset.abstractive.notna()]\n","\n","train_dataset = train_dataset.dropna(subset=['abstractive'])\n","train_dataset = train_dataset.reset_index(drop=True)\n","\n","dev_dataset = dev_dataset.dropna(subset=['abstractive'])\n","dev_dataset = dev_dataset.reset_index(drop=True)\n","\n","test_dataset = test_dataset.dropna(subset=['abstractive'])\n","test_dataset = test_dataset.reset_index(drop=True)\n","\n","# use the pre-defined \"summarize\" for abstractive summary\n","train_dataset.extractive = 'summarize: ' + train_dataset.extractive\n","dev_dataset.extractive = 'summarize: ' + dev_dataset.extractive\n","test_dataset.extractive = 'summarize: ' + test_dataset.extractive\n","print(train_dataset.head(1))\n","print(len(train_dataset))\n","print(len(dev_dataset))\n","print(len(test_dataset))\n"],"execution_count":25,"outputs":[{"output_type":"stream","text":["    meeting  ...                                        abstractive\n","0  Bdb001.C  ...  On the one hand, a bespoke XML structure that ...\n","\n","[1 rows x 3 columns]\n","420\n","189\n","102\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":203},"id":"2Jv3VHyUcENB","executionInfo":{"status":"ok","timestamp":1606764744448,"user_tz":300,"elapsed":836,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"4a30ad55-13e1-4ea7-fc30-07be571779c4"},"source":["dev_dataset.tail(5)"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>meeting</th>\n","      <th>extractive</th>\n","      <th>abstractive</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>184</th>\n","      <td>TS3011c.D</td>\n","      <td>summarize: ease of use is important , but inno...</td>\n","      <td>For the conceptual design, the marketing exper...</td>\n","    </tr>\n","    <tr>\n","      <th>185</th>\n","      <td>TS3011d.A</td>\n","      <td>summarize: could i see the scroll bar as as a ...</td>\n","      <td>It can be used as a normal remote, but the spe...</td>\n","    </tr>\n","    <tr>\n","      <th>186</th>\n","      <td>TS3011d.B</td>\n","      <td>summarize: plastic or rubber . twenty two . th...</td>\n","      <td>The rubber case is yellow with grey or black, ...</td>\n","    </tr>\n","    <tr>\n","      <th>187</th>\n","      <td>TS3011d.C</td>\n","      <td>summarize: novice users u use this device as n...</td>\n","      <td>It can be used as a normal remote, but the spe...</td>\n","    </tr>\n","    <tr>\n","      <th>188</th>\n","      <td>TS3011d.D</td>\n","      <td>summarize: is it ? is it fancy ? was it innova...</td>\n","      <td>The criteria used were fancifulness (2), techn...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       meeting  ...                                        abstractive\n","184  TS3011c.D  ...  For the conceptual design, the marketing exper...\n","185  TS3011d.A  ...  It can be used as a normal remote, but the spe...\n","186  TS3011d.B  ...  The rubber case is yellow with grey or black, ...\n","187  TS3011d.C  ...  It can be used as a normal remote, but the spe...\n","188  TS3011d.D  ...  The criteria used were fancifulness (2), techn...\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IENujMiWE70j","executionInfo":{"status":"ok","timestamp":1606764746550,"user_tz":300,"elapsed":427,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"2d1d6e93-20ee-4cb3-e72d-c83b3581f631"},"source":["#train_dataset=df.sample(frac=train_size,random_state = SEED)\n","#test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n","#train_dataset = train_dataset.reset_index(drop=True)\n","#print(\"FULL Dataset: {}\".format(df.shape))\n","\n","print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n","print(\"DEV Dataset: {}\".format(dev_dataset.shape))\n","print(\"TEST Dataset: {}\".format(test_dataset.shape))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["TRAIN Dataset: (420, 3)\n","DEV Dataset: (189, 3)\n","TEST Dataset: (102, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TZ4EXP96GZ8n"},"source":["## Dataset Transformation\n","\n","Tokenize the input and also perform the attention masking to make sure everything can be done in tensors. \n","\n","Tunable Hyprparam:\n","\n","*   MAX_LEN\n","*   SUMMARY_LEN\n","* TRAIN_BATCH_SIZE\n","* DEV_BATCH_SIZE\n","* TEST_BATCH_SIZE\n"]},{"cell_type":"code","metadata":{"id":"07SniX-oGTcj","executionInfo":{"status":"ok","timestamp":1606764749601,"user_tz":300,"elapsed":439,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["# most code from https://colab.research.google.com/drive/1ypT7oCjtBOTSMJv7J5_1vO7hDYSD_-oU?authuser=2#scrollTo=932p8NhxeNw4\n","\n","class CustomDataset(Dataset):\n","\n","    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.source_len = source_len\n","        self.summ_len = summ_len\n","        self.abstractive = self.data.abstractive\n","        self.extractive = self.data.extractive\n","\n","    def __len__(self):\n","        return len(self.abstractive)\n","\n","    def __getitem__(self, index):\n","        extractive = str(self.extractive[index])\n","        extractive = ' '.join(extractive.split())\n","\n","        abstractive = str(self.abstractive[index])\n","        abstractive = ' '.join(abstractive.split())\n","\n","        source = self.tokenizer.batch_encode_plus([extractive], max_length= self.source_len, pad_to_max_length=True,return_tensors='pt')\n","        target = self.tokenizer.batch_encode_plus([abstractive], max_length= self.summ_len, pad_to_max_length=True,return_tensors='pt')\n","        source_ids = source['input_ids'].squeeze()\n","        source_mask = source['attention_mask'].squeeze()\n","        target_ids = target['input_ids'].squeeze()\n","        target_mask = target['attention_mask'].squeeze()\n","\n","        return {\n","            'source_ids': source_ids.to(dtype=torch.long), \n","            'source_mask': source_mask.to(dtype=torch.long), \n","            'target_ids': target_ids.to(dtype=torch.long),\n","            'target_ids_y': target_ids.to(dtype=torch.long)\n","        }"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"PgOB45_8K6kK","executionInfo":{"status":"ok","timestamp":1606764752000,"user_tz":300,"elapsed":1063,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["### Training Dataset and Test Dataset \n","\n","# TRAIN Dataset: (1231, 4)\n","# DEV Dataset: (744, 4)\n","# TEST Dataset: (165, 4)\n","\n","MAX_LEN = 1024\n","SUMMARY_LEN= 150\n","\n","# note here only uses the t5-small model.\n","tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n","train_set = CustomDataset(train_dataset, tokenizer, MAX_LEN, SUMMARY_LEN)\n","dev_set = CustomDataset(dev_dataset, tokenizer, MAX_LEN, SUMMARY_LEN)\n","test_set = CustomDataset(test_dataset, tokenizer, MAX_LEN, SUMMARY_LEN)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ws6q9x_TMgtP","executionInfo":{"status":"ok","timestamp":1606764752255,"user_tz":300,"elapsed":260,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"ae4b92fe-3ce1-4115-e75a-04aba9e2e239"},"source":["# double checking the result size, only for one point\n","# https://stackoverflow.com/questions/43627405/understanding-getitem-method\n","print(train_set[0]['source_ids'].shape)\n","print(train_set[0]['source_mask'].shape)\n","print(train_set[0]['target_ids'].shape)\n","print(train_set[0]['target_ids_y'].shape)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([1024])\n","torch.Size([1024])\n","torch.Size([150])\n","torch.Size([150])\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"WFx2e48uKnY3"},"source":["## Fine Tuning\n","\n","Here we directly use the pre-trained model t5-small and will save checkpoint every 500 steps. \n","\n","Tunable Parameter:\n","* T5ForConditionalGeneration or T5\n","* epoch - train, dev, test\n","* optimizer - LEARNING_RATE, Adam\n","* output: num_beams, length_penalty,early_stopping\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"P9MmjbqbYjHB"},"source":["### Training & Validation Functions\n","\n","The training part uses the t5-small pretrained model, didn't make any change to the model layer structures, and fine tune the parameters based on the dataset we have."]},{"cell_type":"code","metadata":{"id":"05VKilCKKptn","executionInfo":{"status":"ok","timestamp":1606764756537,"user_tz":300,"elapsed":986,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["losslist = []\n","def train(epoch, tokenizer, model, device, loader, optimizer):\n","  # put into train mode \n","  model.train()\n","  # enumerate the dataloader for training set into the defined network\n","  for _,data in enumerate(loader, 0):\n","      y = data['target_ids'].to(device, dtype = torch.long)\n","      # https://discuss.pytorch.org/t/contigious-vs-non-contigious-tensor/30107/2\n","      y_ids = y[:, :-1].contiguous()\n","      lm_labels = y[:, 1:].clone().detach()\n","      lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n","      ids = data['source_ids'].to(device, dtype = torch.long)\n","      mask = data['source_mask'].to(device, dtype = torch.long)\n","\n","      outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, lm_labels=lm_labels)\n","      loss = outputs[0]\n","      losslist.append(loss)\n","      if _%10==0:\n","        wandb.log({\"Training Loss\": loss.item()})\n","      if _%500==0:\n","        print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n","      \n","      # https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch\n","      # https://discuss.pytorch.org/t/how-are-optimizer-step-and-loss-backward-related/7350\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"-VNL1ru0Wvsc","executionInfo":{"status":"ok","timestamp":1606764760565,"user_tz":300,"elapsed":787,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["# https://towardsdatascience.com/fine-tuning-a-t5-transformer-for-any-summarization-task-82334c64c81\n","\n","def dev(epoch, tokenizer, model, device, loader):\n","  #https://stackoverflow.com/questions/60018578/what-does-model-eval-do-in-pytorch\n","  model.eval()\n","  predictions = []\n","  actuals = []\n","  #rouge_metric = load_metric('rouge') \n","  # https://datascience.stackexchange.com/questions/32651/what-is-the-use-of-torch-no-grad-in-pytorch\n","  with torch.no_grad():\n","\n","    for _, data in enumerate(loader, 0):\n","\n","      y = data['target_ids'].to(device, dtype = torch.long)\n","      ids = data['source_ids'].to(device, dtype = torch.long)\n","      mask = data['source_mask'].to(device, dtype = torch.long)\n","\n","      generated_ids = model.generate(\n","          input_ids = ids,\n","          attention_mask = mask, \n","          max_length=150, \n","          num_beams=12,\n","          repetition_penalty=2.5, \n","          length_penalty=1.0, \n","          early_stopping=True\n","          )\n","      preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n","      target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n","      if _%100==0:\n","          print(f'Completed {_}')\n","      predictions.extend(preds)\n","      actuals.extend(target)\n","      #print(preds)\n","      #print(target)\n","      #rouge_metric.add(preds, target)\n","      \n","    #rouge_results = rouge_metric.compute(rouge_types=[\"rouge2\"]) \n","  return predictions, actuals"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"UJddO-eY3whv","executionInfo":{"status":"ok","timestamp":1606764761269,"user_tz":300,"elapsed":408,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["def compute_rouge_scores(cand_list, ref_list):\n","    \"\"\"\n","    :param cand_list: list of candidate summaries\n","    :param ref_list: list of reference summaries\n","    :return: rouge scores\n","    \"\"\"\n","    rouge = Rouge()\n","    rouge_1_f_score = 0.\n","    rouge_2_f_score = 0.\n","    rouge_L_f_score = 0.\n","\n","    rouge_1_r_score = 0.\n","    rouge_2_r_score = 0.\n","    rouge_L_r_score = 0.\n","\n","    rouge_1_p_score = 0.\n","    rouge_2_p_score = 0.\n","    rouge_L_p_score = 0.\n","\n","    doc_count = len(cand_list)\n","\n","    for cand, ref in zip(cand_list, ref_list):\n","      try:\n","        rouge_scores = rouge.get_scores(cand, ref)[0]\n","        rouge_1_f_score += rouge_scores['rouge-1']['f']\n","        rouge_2_f_score += rouge_scores['rouge-2']['f']\n","        rouge_L_f_score += rouge_scores['rouge-l']['f']\n","\n","        rouge_1_r_score += rouge_scores['rouge-1']['r']\n","        rouge_2_r_score += rouge_scores['rouge-2']['r']\n","        rouge_L_r_score += rouge_scores['rouge-l']['r']\n","\n","        rouge_1_p_score += rouge_scores['rouge-1']['p']\n","        rouge_2_p_score += rouge_scores['rouge-2']['p']\n","        rouge_L_p_score += rouge_scores['rouge-l']['p']\n","      except:\n","        pass\n","    rouge_1_f_score = rouge_1_f_score / doc_count\n","    rouge_2_f_score = rouge_2_f_score / doc_count\n","    rouge_L_f_score = rouge_L_f_score / doc_count\n","\n","    results_dict = {}\n","    results_dict['rouge_1_f_score'] = rouge_1_f_score\n","    results_dict['rouge_2_f_score'] = rouge_2_f_score\n","    results_dict['rouge_l_f_score'] = rouge_L_f_score\n","\n","    return results_dict"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"4beVpzOMCoFu","executionInfo":{"status":"ok","timestamp":1606764763330,"user_tz":300,"elapsed":2112,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["AMI_PATH = \"/content/drive/My Drive/W266/data/gold_abstractive_summary/goldsummary_AMI_as_dev.csv\"\n","ICSI_PATH = \"/content/drive/My Drive/W266/data/gold_abstractive_summary/goldsummary_ICSI_as_dev.csv\"\n","\n","amigold = pd.read_csv(AMI_PATH)\n","icsigold = pd.read_csv(ICSI_PATH)\n","\n","def rouge_per_document(final_df,gold):\n","  merged_df = pd.concat([dev_dataset.meeting, final_df.Generated_Abstractive_Summary], axis=1)\n","  merged_df[\"meetinglevel\"] = merged_df.meeting.apply(lambda x: x.split(\".\")[0]) \n","\n","  gas_list =[]\n","  meeting_list = []\n","  generated_abstractive = \"\"\n","  for me in set(merged_df.meetinglevel):\n","    for gas in merged_df[merged_df.meetinglevel == me]['Generated_Abstractive_Summary']:\n","      generated_abstractive+= gas + \" \"\n","    gas_list.append(generated_abstractive)\n","    meeting_list.append(me)\n","    generated_abstractive = \" \"\n","  per_doc_summary = pd.DataFrame(\n","    {'Meeting': meeting_list,\n","     'Generated_Abstractive_Summary': gas_list\n","    })\n","  \n","  new_df = pd.merge(per_doc_summary, gold,  how='left', left_on='Meeting', right_on ='meeting')\n","  rouge_results_perdoc = compute_rouge_scores(new_df.Generated_Abstractive_Summary,\n","                                      new_df.abstractive)\n","  return rouge_results_perdoc\n","  "],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rxyXnBnZYex-"},"source":["### Run Epoch\n","Train and Evaluation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Y5TwfR5FBIki","executionInfo":{"status":"ok","timestamp":1606745710194,"user_tz":300,"elapsed":734,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"452aa20d-9839-4e63-fd14-569cf1d1fa4a"},"source":["id = wandb.util.generate_id()\n","id\n","#dwlkfpg3 AMI 1024\n","#1aei9r6r ICSI 1024\n","#3ugok7an ICSI 512\n","#30e6cuxp AMI 512\n","#3fsv41il ICSI 1024 Cleaned \n","#2knqed4a AMI 1024 Cleaned \n","#3le4t5oh AMI 1024 Cleaned t5-base\n","#3oar0l9l ICSI 1024 t5-base\n","#1foudah4 AMI 1024 eax small\n","#3thp15xs ICSI 1024 eax small\n","#3rc2qh90 ICSI 1024 eax small 0.0001\n","#2ypembrw ICSI 1024 eax small 0.001\n","#3k5y8yms AMI 1024 eax small 0.0001\n","#2volhe8e AMI 1024 eax small 0.001\n","#2cy97ztl Together training 1024 eax small 0.0001"],"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2cy97ztl'"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":120},"id":"i8gLtGWbh7AZ","executionInfo":{"status":"ok","timestamp":1606764774108,"user_tz":300,"elapsed":5576,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"edffe39f-7d18-4be5-f3f1-9858f86415c1"},"source":["#run = wandb.init(project=\"T5_1024_MSFT_AMI_01\",resume=True)\n","run = wandb.init(project=\"T5_1024_together\", id=\"2cy97ztl\", resume=\"allow\")\n","\n","config = wandb.config          # Initialize config\n","config.TRAIN_BATCH_SIZE = 1    # input batch size for training (default: 64)\n","config.VALID_BATCH_SIZE = 1    # input batch size for testing (default: 1000)\n","config.EPOCHS = 50        # number of epochs to train (default: 10)\n","config.LEARNING_RATE = 0.0001   # learning rate (default: 0.01)\n","config.SEED = 42               # random seed (default: 42)\n","config.MAX_LEN = MAX_LEN\n","config.SUMMARY_LEN = SUMMARY_LEN \n"],"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","                Tracking run with wandb version 0.10.11<br/>\n","                Resuming run <strong style=\"color:#cdcd00\">confused-forest-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://wandb.ai/wuqq09/T5_1024_together\" target=\"_blank\">https://wandb.ai/wuqq09/T5_1024_together</a><br/>\n","                Run page: <a href=\"https://wandb.ai/wuqq09/T5_1024_together/runs/2cy97ztl\" target=\"_blank\">https://wandb.ai/wuqq09/T5_1024_together/runs/2cy97ztl</a><br/>\n","                Run data is saved locally in <code>/content/wandb/run-20201130_193248-2cy97ztl</code><br/><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"q5vvXTv0OQLK","executionInfo":{"status":"ok","timestamp":1606764774109,"user_tz":300,"elapsed":2831,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["# https://deeplizard.com/learn/video/kWVgvsejXsE#:~:text=The%20num_workers%20attribute%20tells%20the,sequentially%20inside%20the%20main%20process\n","# num_workers to default 0\n","# This means that the training process will work sequentially inside the main process. \n","# After a batch is used during the training process and another one is needed, we read the batch data from disk.\n","\n","TEST_BATCH_SIZE = 1 \n","\n","train_params = {\n","  'batch_size': config.TRAIN_BATCH_SIZE,\n","  'shuffle': True,\n","  'num_workers': 0\n","  }\n","\n","dev_params = {\n","  'batch_size': config.VALID_BATCH_SIZE,\n","  'shuffle': False,\n","  'num_workers': 0\n","  }\n","\n","test_params = {\n","  'batch_size': TEST_BATCH_SIZE,\n","  'shuffle': False,\n","  'num_workers': 0\n","  }\n","\n","training_loader = DataLoader(train_set, **train_params)\n","dev_loader = DataLoader(dev_set, **dev_params)\n","test_loader = DataLoader(test_set, **test_params)"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"kKxdX61LW6dY","executionInfo":{"status":"ok","timestamp":1606764777406,"user_tz":300,"elapsed":4778,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n","model = model.to(device)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"ePGtVuaUXqli","executionInfo":{"status":"ok","timestamp":1606764777406,"user_tz":300,"elapsed":4529,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["# optimizer \n","# https://pytorch.org/docs/stable/optim.html\n","optimizer = torch.optim.Adam(params = model.parameters(), lr=config.LEARNING_RATE)"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"whGS8TXqq5u7","executionInfo":{"status":"ok","timestamp":1606764777407,"user_tz":300,"elapsed":3722,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"fb99eb97-b885-46b2-dca4-23aa2b6feece"},"source":["optimizer"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    eps: 1e-08\n","    lr: 0.0001\n","    weight_decay: 0\n",")"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"DUD8KqP20gmT"},"source":["# CP_TEMP_NAME = 'epoch10'\n","# CP_PATH = \"/content/drive/My Drive/W266/checkpoints/MSFT_50EPOCH_Intransit_AMI512_NoNA/\" + CP_TEMP_NAME +\".pt\"\n","# checkpoint = torch.load(CP_PATH)\n","# model.load_state_dict(checkpoint['model_state_dict'])\n","# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GHmes1VwYbjX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606748592752,"user_tz":300,"elapsed":2719178,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"53d37de9-3cd7-4277-9bc6-c9e3a6d570ea"},"source":["training_time_log = []\n","MODEL_NAME = \"T5_1024_together_eax\"\n","start_train_time = time.time()\n","wandb.watch(model, log='all')\n","\n","\n","print(\"starting fine-tuning with training and validation\")\n","i = 0\n","for epoch in range(config.EPOCHS):\n","\n","  ## ================= Training =================== ##\n","  print(\"start training epoch\" + str(i))\n","  CP_TEMP_NAME = 'epoch' + str(i)\n","  CP_TEMP_PATH = \"/content/drive/My Drive/W266/checkpoints/Together_1024_smalllr/\"+ CP_TEMP_NAME +\".pt\"\n","  train(epoch, tokenizer, model, device, training_loader, optimizer)\n","  torch.save({\n","      'model_state_dict': model.state_dict(),\n","      'optimizer_state_dict': optimizer.state_dict(),\n","      'train_epoch': i\n","      }, CP_TEMP_PATH)\n","  training_time = time.time() - start_train_time\n","  print(\"done training epoch\" +str(i))\n","  wandb.log({'epoch_traingTime': training_time,\n","             'epoch': i})\n","  print(\"--- %s seconds ---\" % (training_time))\n","  training_time_log.append(training_time)\n","  i+=1\n","  ## ================= Validation =================== ##\n","  # print(\"strat validation epoch\" + str(i))\n","  # predictions, actuals = dev(epoch, tokenizer, model, device, dev_loader)\n","  # final_df = pd.DataFrame({'Generated_Abstractive_Summary':predictions,\n","  #                           'Golden_Abstractive_Text':actuals})\n","  # final_df.to_csv('/content/drive/My Drive/W266/results/'+MODEL_NAME + \"_epoch\" +str(i)+'.csv')\n","  # print(\"done validation epoch\" +str(i))\n","\n","  # rouge_results = compute_rouge_scores(final_df.Generated_Abstractive_Summary,\n","  #                                      final_df.Golden_Abstractive_Text)\n","  \n","  # wandb.log({'rouge1': rouge_results.get(\"rouge_1_f_score\"), \n","  #            'rougeL': rouge_results.get(\"rouge_l_f_score\"),  \n","  #            'rouge2': rouge_results.get(\"rouge_2_f_score\"),\n","  #            'epoch': i})\n","  # i+=1\n","\n","#run.finish()\n","  \n"],"execution_count":64,"outputs":[{"output_type":"stream","text":["starting fine-tuning with training and validation\n","start training epoch0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/modeling_t5.py:1156: FutureWarning: The `lm_labels` argument is deprecated and will be removed in a future version, use `labels` instead.\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0, Loss:  7.2827558517456055\n","done training epoch0\n","--- 51.51425337791443 seconds ---\n","start training epoch1\n","Epoch: 1, Loss:  3.394904851913452\n","done training epoch1\n","--- 103.9356038570404 seconds ---\n","start training epoch2\n","Epoch: 2, Loss:  3.084415912628174\n","done training epoch2\n","--- 159.5088062286377 seconds ---\n","start training epoch3\n","Epoch: 3, Loss:  3.3717005252838135\n","done training epoch3\n","--- 212.2182812690735 seconds ---\n","start training epoch4\n","Epoch: 4, Loss:  2.002228260040283\n","done training epoch4\n","--- 267.2146484851837 seconds ---\n","start training epoch5\n","Epoch: 5, Loss:  2.0860416889190674\n","done training epoch5\n","--- 319.87990856170654 seconds ---\n","start training epoch6\n","Epoch: 6, Loss:  2.123786449432373\n","done training epoch6\n","--- 372.7616710662842 seconds ---\n","start training epoch7\n","Epoch: 7, Loss:  2.5126595497131348\n","done training epoch7\n","--- 430.10999608039856 seconds ---\n","start training epoch8\n","Epoch: 8, Loss:  1.548439860343933\n","done training epoch8\n","--- 483.6095187664032 seconds ---\n","start training epoch9\n","Epoch: 9, Loss:  2.0562028884887695\n","done training epoch9\n","--- 540.1676061153412 seconds ---\n","start training epoch10\n","Epoch: 10, Loss:  0.7451457977294922\n","done training epoch10\n","--- 593.7314419746399 seconds ---\n","start training epoch11\n","Epoch: 11, Loss:  1.5642162561416626\n","done training epoch11\n","--- 649.8195600509644 seconds ---\n","start training epoch12\n","Epoch: 12, Loss:  1.588454246520996\n","done training epoch12\n","--- 705.3961503505707 seconds ---\n","start training epoch13\n","Epoch: 13, Loss:  0.28318095207214355\n","done training epoch13\n","--- 758.0387208461761 seconds ---\n","start training epoch14\n","Epoch: 14, Loss:  2.369330644607544\n","done training epoch14\n","--- 815.1446208953857 seconds ---\n","start training epoch15\n","Epoch: 15, Loss:  1.0157514810562134\n","done training epoch15\n","--- 869.0000176429749 seconds ---\n","start training epoch16\n","Epoch: 16, Loss:  1.6894270181655884\n","done training epoch16\n","--- 924.2711174488068 seconds ---\n","start training epoch17\n","Epoch: 17, Loss:  0.1254958063364029\n","done training epoch17\n","--- 977.8970715999603 seconds ---\n","start training epoch18\n","Epoch: 18, Loss:  0.8042092323303223\n","done training epoch18\n","--- 1032.071994304657 seconds ---\n","start training epoch19\n","Epoch: 19, Loss:  1.5338054895401\n","done training epoch19\n","--- 1087.0575840473175 seconds ---\n","start training epoch20\n","Epoch: 20, Loss:  1.4867537021636963\n","done training epoch20\n","--- 1138.8327515125275 seconds ---\n","start training epoch21\n","Epoch: 21, Loss:  1.445891261100769\n","done training epoch21\n","--- 1193.8645312786102 seconds ---\n","start training epoch22\n","Epoch: 22, Loss:  0.6660033464431763\n","done training epoch22\n","--- 1246.4614398479462 seconds ---\n","start training epoch23\n","Epoch: 23, Loss:  0.7109442353248596\n","done training epoch23\n","--- 1301.5785703659058 seconds ---\n","start training epoch24\n","Epoch: 24, Loss:  0.2529006898403168\n","done training epoch24\n","--- 1355.1479625701904 seconds ---\n","start training epoch25\n","Epoch: 25, Loss:  1.4295878410339355\n","done training epoch25\n","--- 1408.241786956787 seconds ---\n","start training epoch26\n","Epoch: 26, Loss:  0.0904991626739502\n","done training epoch26\n","--- 1465.713185787201 seconds ---\n","start training epoch27\n","Epoch: 27, Loss:  0.1293686181306839\n","done training epoch27\n","--- 1518.5953822135925 seconds ---\n","start training epoch28\n","Epoch: 28, Loss:  0.14477568864822388\n","done training epoch28\n","--- 1573.694893836975 seconds ---\n","start training epoch29\n","Epoch: 29, Loss:  0.259185254573822\n","done training epoch29\n","--- 1628.2333958148956 seconds ---\n","start training epoch30\n","Epoch: 30, Loss:  0.2060496211051941\n","done training epoch30\n","--- 1681.6271753311157 seconds ---\n","start training epoch31\n","Epoch: 31, Loss:  0.7731719613075256\n","done training epoch31\n","--- 1736.248972415924 seconds ---\n","start training epoch32\n","Epoch: 32, Loss:  0.5224964022636414\n","done training epoch32\n","--- 1788.569952249527 seconds ---\n","start training epoch33\n","Epoch: 33, Loss:  0.1610114574432373\n","done training epoch33\n","--- 1844.1795673370361 seconds ---\n","start training epoch34\n","Epoch: 34, Loss:  0.18363088369369507\n","done training epoch34\n","--- 1897.473682641983 seconds ---\n","start training epoch35\n","Epoch: 35, Loss:  0.25500527024269104\n","done training epoch35\n","--- 1952.8294703960419 seconds ---\n","start training epoch36\n","Epoch: 36, Loss:  0.8545915484428406\n","done training epoch36\n","--- 2007.8465621471405 seconds ---\n","start training epoch37\n","Epoch: 37, Loss:  0.9292997121810913\n","done training epoch37\n","--- 2060.6724429130554 seconds ---\n","start training epoch38\n","Epoch: 38, Loss:  0.5477363467216492\n","done training epoch38\n","--- 2119.2481303215027 seconds ---\n","start training epoch39\n","Epoch: 39, Loss:  0.4221063256263733\n","done training epoch39\n","--- 2171.7602956295013 seconds ---\n","start training epoch40\n","Epoch: 40, Loss:  0.2586943209171295\n","done training epoch40\n","--- 2225.783866405487 seconds ---\n","start training epoch41\n","Epoch: 41, Loss:  0.16111290454864502\n","done training epoch41\n","--- 2278.1116688251495 seconds ---\n","start training epoch42\n","Epoch: 42, Loss:  0.03120001219213009\n","done training epoch42\n","--- 2333.915836572647 seconds ---\n","start training epoch43\n","Epoch: 43, Loss:  0.19589819014072418\n","done training epoch43\n","--- 2387.777712583542 seconds ---\n","start training epoch44\n","Epoch: 44, Loss:  0.5212076306343079\n","done training epoch44\n","--- 2441.6069173812866 seconds ---\n","start training epoch45\n","Epoch: 45, Loss:  0.4936932921409607\n","done training epoch45\n","--- 2497.180312871933 seconds ---\n","start training epoch46\n","Epoch: 46, Loss:  0.4425869286060333\n","done training epoch46\n","--- 2550.792691707611 seconds ---\n","start training epoch47\n","Epoch: 47, Loss:  0.133999302983284\n","done training epoch47\n","--- 2606.018646001816 seconds ---\n","start training epoch48\n","Epoch: 48, Loss:  0.09449062496423721\n","done training epoch48\n","--- 2662.786605119705 seconds ---\n","start training epoch49\n","Epoch: 49, Loss:  0.09553766250610352\n","done training epoch49\n","--- 2717.823555469513 seconds ---\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["26795496a54a4322b3de446a439e5db8","8b5fa38084284294af3c9eaddecffaa4","1c5f46b827ae42b9b61dbb80a35c3ad8","bcd508bf905a48daaaf6c2e715e825d8","e9648c49d6474a5d951a257a274899e0","3c7d5b349eb042ceb05f5daa592ac688","4bf5bf69096f44ee9df44ba7c79a3799","a4856c9358184d6bbd815f6b22a8685b"]},"id":"2tVOuLscBjxq","executionInfo":{"status":"ok","timestamp":1606801378537,"user_tz":300,"elapsed":36419697,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"4603fe8d-e0d2-450d-adb8-08fd0f3686f1"},"source":["validation_time_log = []\n","MODEL_NAME = \"T5_1024_together_eax_AMI\"\n","start_validation_time = time.time()\n","\n","print(\"starting fine-tuning with training and validation\")\n","i = 0\n","for epoch in range(config.EPOCHS):\n","\n","  ## ================= Validation =================== ##\n","  print(\"strat validation epoch\" + str(i))\n","  model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n","  model = model.to(device)\n","  # optimizer \n","  # https://pytorch.org/docs/stable/optim.html\n","  optimizer = torch.optim.Adam(params = model.parameters(), lr=config.LEARNING_RATE)\n","\n","  CP_TEMP_NAME = 'epoch' + str(i)\n","  CP_PATH = \"/content/drive/My Drive/W266/checkpoints/Together_1024_smalllr/\" + CP_TEMP_NAME +\".pt\"\n","  checkpoint = torch.load(CP_PATH)\n","  model.load_state_dict(checkpoint['model_state_dict'])\n","  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","  wandb.watch(model, log='all')\n","\n","  predictions, actuals = dev(epoch, tokenizer, model, device, dev_loader)\n","  final_df = pd.DataFrame({'Generated_Abstractive_Summary':predictions,\n","                            'Golden_Abstractive_Text':actuals})\n","  final_df.to_csv('/content/drive/My Drive/W266/results/'+MODEL_NAME + \"_epoch\" +str(i)+'.csv')\n","\n","  rouge_results = compute_rouge_scores(final_df.Generated_Abstractive_Summary,\n","                                       final_df.Golden_Abstractive_Text)\n","  \n","  validation_time = time.time() - start_validation_time\n","  validation_time_log.append(validation_time)\n","\n","  # amigold = pd.read_csv(AMI_PATH)\n","  # icsigold = pd.read_csv(ICSI_PATH)\n","\n","  rouge_results_perdoc = rouge_per_document(final_df,amigold)\n","  wandb.log({'rouge1_ami': rouge_results.get(\"rouge_1_f_score\"), \n","            'rougeL_ami': rouge_results.get(\"rouge_l_f_score\"),  \n","            'rouge2_ami': rouge_results.get(\"rouge_2_f_score\"),\n","            'rouge1_doclevel_ami': rouge_results_perdoc.get(\"rouge_1_f_score\"), \n","            'rougeL_doclevel_ami': rouge_results_perdoc.get(\"rouge_l_f_score\"),  \n","            'rouge2_doclevel_ami': rouge_results_perdoc.get(\"rouge_2_f_score\"),\n","            'epoch_validationTime_ami': validation_time,\n","            'epoch': i})\n","  print(\"done validation epoch\" +str(i))\n","  i+=1\n","\n","\n","run.finish()\n","  \n"],"execution_count":40,"outputs":[{"output_type":"stream","text":["starting fine-tuning with training and validation\n","strat validation epoch0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Completed 0\n","Completed 100\n","done validation epoch0\n","strat validation epoch1\n","Completed 0\n","Completed 100\n","done validation epoch1\n","strat validation epoch2\n","Completed 0\n","Completed 100\n","done validation epoch2\n","strat validation epoch3\n","Completed 0\n","Completed 100\n","done validation epoch3\n","strat validation epoch4\n","Completed 0\n","Completed 100\n","done validation epoch4\n","strat validation epoch5\n","Completed 0\n","Completed 100\n","done validation epoch5\n","strat validation epoch6\n","Completed 0\n","Completed 100\n","done validation epoch6\n","strat validation epoch7\n","Completed 0\n","Completed 100\n","done validation epoch7\n","strat validation epoch8\n","Completed 0\n","Completed 100\n","done validation epoch8\n","strat validation epoch9\n","Completed 0\n","Completed 100\n","done validation epoch9\n","strat validation epoch10\n","Completed 0\n","Completed 100\n","done validation epoch10\n","strat validation epoch11\n","Completed 0\n","Completed 100\n","done validation epoch11\n","strat validation epoch12\n","Completed 0\n","Completed 100\n","done validation epoch12\n","strat validation epoch13\n","Completed 0\n","Completed 100\n","done validation epoch13\n","strat validation epoch14\n","Completed 0\n","Completed 100\n","done validation epoch14\n","strat validation epoch15\n","Completed 0\n","Completed 100\n","done validation epoch15\n","strat validation epoch16\n","Completed 0\n","Completed 100\n","done validation epoch16\n","strat validation epoch17\n","Completed 0\n","Completed 100\n","done validation epoch17\n","strat validation epoch18\n","Completed 0\n","Completed 100\n","done validation epoch18\n","strat validation epoch19\n","Completed 0\n","Completed 100\n","done validation epoch19\n","strat validation epoch20\n","Completed 0\n","Completed 100\n","done validation epoch20\n","strat validation epoch21\n","Completed 0\n","Completed 100\n","done validation epoch21\n","strat validation epoch22\n","Completed 0\n","Completed 100\n","done validation epoch22\n","strat validation epoch23\n","Completed 0\n","Completed 100\n","done validation epoch23\n","strat validation epoch24\n","Completed 0\n","Completed 100\n","done validation epoch24\n","strat validation epoch25\n","Completed 0\n","Completed 100\n","done validation epoch25\n","strat validation epoch26\n","Completed 0\n","Completed 100\n","done validation epoch26\n","strat validation epoch27\n","Completed 0\n","Completed 100\n","done validation epoch27\n","strat validation epoch28\n","Completed 0\n","Completed 100\n","done validation epoch28\n","strat validation epoch29\n","Completed 0\n","Completed 100\n","done validation epoch29\n","strat validation epoch30\n","Completed 0\n","Completed 100\n","done validation epoch30\n","strat validation epoch31\n","Completed 0\n","Completed 100\n","done validation epoch31\n","strat validation epoch32\n","Completed 0\n","Completed 100\n","done validation epoch32\n","strat validation epoch33\n","Completed 0\n","Completed 100\n","done validation epoch33\n","strat validation epoch34\n","Completed 0\n","Completed 100\n","done validation epoch34\n","strat validation epoch35\n","Completed 0\n","Completed 100\n","done validation epoch35\n","strat validation epoch36\n","Completed 0\n","Completed 100\n","done validation epoch36\n","strat validation epoch37\n","Completed 0\n","Completed 100\n","done validation epoch37\n","strat validation epoch38\n","Completed 0\n","Completed 100\n","done validation epoch38\n","strat validation epoch39\n","Completed 0\n","Completed 100\n","done validation epoch39\n","strat validation epoch40\n","Completed 0\n","Completed 100\n","done validation epoch40\n","strat validation epoch41\n","Completed 0\n","Completed 100\n","done validation epoch41\n","strat validation epoch42\n","Completed 0\n","Completed 100\n","done validation epoch42\n","strat validation epoch43\n","Completed 0\n","Completed 100\n","done validation epoch43\n","strat validation epoch44\n","Completed 0\n","Completed 100\n","done validation epoch44\n","strat validation epoch45\n","Completed 0\n","Completed 100\n","done validation epoch45\n","strat validation epoch46\n","Completed 0\n","Completed 100\n","done validation epoch46\n","strat validation epoch47\n","Completed 0\n","Completed 100\n","done validation epoch47\n","strat validation epoch48\n","Completed 0\n","Completed 100\n","done validation epoch48\n","strat validation epoch49\n","Completed 0\n","Completed 100\n","done validation epoch49\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 2681<br/>Program ended successfully."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"26795496a54a4322b3de446a439e5db8","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["Find user logs for this run at: <code>/content/wandb/run-20201130_193248-2cy97ztl/logs/debug.log</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["Find internal logs for this run at: <code>/content/wandb/run-20201130_193248-2cy97ztl/logs/debug-internal.log</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<h3>Run summary:</h3><br/><style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    </style><table class=\"wandb\">\n","<tr><td>_timestamp</td><td>1606801370</td></tr><tr><td>rouge1_doclevel_ami</td><td>0.39117</td></tr><tr><td>rougeL_doclevel_ami</td><td>0.31281</td></tr><tr><td>Training Loss</td><td>0.00959</td></tr><tr><td>rouge1_ami</td><td>0.29085</td></tr><tr><td>rouge2_ami</td><td>0.07175</td></tr><tr><td>rougeL_ami</td><td>0.24002</td></tr><tr><td>epoch_validationTime_ami</td><td>36410.03547</td></tr><tr><td>_runtime</td><td>53687</td></tr><tr><td>epoch_traingTime</td><td>2717.82356</td></tr><tr><td>_step</td><td>2249</td></tr><tr><td>rouge2_doclevel_ami</td><td>0.11821</td></tr><tr><td>epoch</td><td>49</td></tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<h3>Run history:</h3><br/><style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    </style><table class=\"wandb\">\n","<tr><td>rouge1_ami</td><td>â–â–‚â–ƒâ–ƒâ–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡</td></tr><tr><td>rougeL_ami</td><td>â–â–‚â–„â–„â–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡</td></tr><tr><td>rouge2_ami</td><td>â–â–‚â–ƒâ–ƒâ–„â–…â–†â–…â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–†â–‡â–†â–‡â–‡â–‡â–†â–‡â–‡â–†â–‡</td></tr><tr><td>rouge1_doclevel_ami</td><td>â–â–‚â–ƒâ–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–†â–†â–‡â–†â–‡â–‡â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–†â–†â–‡</td></tr><tr><td>rougeL_doclevel_ami</td><td>â–â–‚â–„â–„â–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–†â–ˆâ–†â–†â–‡â–‡â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–‡â–‡â–†â–‡</td></tr><tr><td>rouge2_doclevel_ami</td><td>â–â–‚â–ƒâ–„â–…â–†â–†â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–†â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>epoch_validationTime_ami</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>_runtime</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>_timestamp</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr></table><br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","                    <br/>Synced <strong style=\"color:#cdcd00\">confused-forest-1</strong>: <a href=\"https://wandb.ai/wuqq09/T5_1024_together/runs/2cy97ztl\" target=\"_blank\">https://wandb.ai/wuqq09/T5_1024_together/runs/2cy97ztl</a><br/>\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MzS-XNA3z9wg","executionInfo":{"status":"ok","timestamp":1606599845866,"user_tz":300,"elapsed":424,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"0de5425c-11a0-44d1-c366-558df8300b9a"},"source":["len(final_df)\n","\n","  "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["189"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3aOhtnmG0DRk","executionInfo":{"status":"ok","timestamp":1606599893919,"user_tz":300,"elapsed":432,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"56a0ee0a-4d98-42db-fdc5-e47a76de86ad"},"source":["final_df_exam = final_df.dropna(subset=['Generated_Abstractive_Summary'])\n","final_df_exam = final_df_exam.reset_index(drop=True)\n","len(final_df_exam)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["189"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"dyhLFo3N0SD0"},"source":["rouge_results = compute_rouge_scores(final_df.Generated_Abstractive_Summary,\n","                                     final_df.Golden_Abstractive_Text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b5lBVnro12G0"},"source":["rouge_results_perdoc = rouge_per_document(final_df,amigold)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uBu3Byul13bM","executionInfo":{"status":"ok","timestamp":1606600327994,"user_tz":300,"elapsed":468,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"d313fc37-41a5-4e8c-c7b9-fdb6b9ac41bc"},"source":["rouge_results_perdoc"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'rouge_1_f_score': 0.37213286129867573,\n"," 'rouge_2_f_score': 0.10793264420054217,\n"," 'rouge_l_f_score': 0.29351381850775093}"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QL3L1l4h15lA","executionInfo":{"status":"ok","timestamp":1606600337230,"user_tz":300,"elapsed":818,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"f44933a6-c6c4-48ae-c9ff-82642ecbbe14"},"source":["i"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ptlFcGar18hF","executionInfo":{"status":"ok","timestamp":1606600347470,"user_tz":300,"elapsed":540,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"eccc2ea4-d9aa-4439-facc-ec5c07366576"},"source":["validation_time"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2802.2264659404755"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"Iiml8KGSeSGB"},"source":["#### Checkpoint \n","\n","Remember to change the CP_NAME to a new model pt name.\n","\n","The model is then saved as checkpoints to Google Drive with the related tunable parameters."]},{"cell_type":"code","metadata":{"id":"nVgDGjccbZQY"},"source":["# https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\n","# Checkpoint Saving\n","CP_NAME = MODEL_NAME\n","\n","CP_TRAIN_EPOCHS = TRAIN_EPOCHS\n","CP_DEV_EPOCHS = DEV_EPOCHS\n","CP_LEARNING_RATE = LEARNING_RATE\n","CP_PATH = \"/content/drive/My Drive/W266/checkpoints/\"+ CP_NAME +\".pt\"\n","CP_MAX_LEN = MAX_LEN\n","CP_SUMMARY_LEN = SUMMARY_LEN\n","CP_TRAIN_BATCH_SIZE = TRAIN_BATCH_SIZE\n","CP_DEV_BATCH_SIZE = DEV_BATCH_SIZE\n","CP_MODEL = 'T5ForConditionalGeneration,t5-small'\n","CP_OPTIMIZER_OPTION = 'Adam'\n","CP_LOSSLIST = losslist\n","CP_TEST_OPTIONS = {\n","    \"num_beams\":          12,\n","    \"repetition_penalty\": 2.5, \n","    \"length_penalty\":     1.0, \n","    \"early_stopping\":     True\n","}\n","CT_TRAIN_TIME = training_time\n","#CT_EVALUATE_TIME = evaluating_time\n","\n","torch.save({\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'train_epoch': CP_TRAIN_EPOCHS,\n","            'dev_epoch': CP_DEV_EPOCHS,\n","            'learning_rate': CP_LEARNING_RATE,\n","            'max_source_length':CP_MAX_LEN,\n","            'max_target_length':CP_SUMMARY_LEN,\n","            'train_batch_size':CP_TRAIN_BATCH_SIZE,\n","            'dev_batch_size':CP_DEV_BATCH_SIZE,\n","            'model_option':CP_MODEL,\n","            'optimizer_option':CP_OPTIMIZER_OPTION,\n","            'losslist': CP_LOSSLIST,\n","            'training_time': CT_TRAIN_TIME,\n","            #'evaluating_time': CT_EVALUATE_TIME,\n","            'test_option': CP_TEST_OPTIONS\n","            }, CP_PATH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R-EORf2EbxV3","executionInfo":{"elapsed":2832,"status":"ok","timestamp":1605718971694,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"},"user_tz":300},"outputId":"7db9540d-f6a2-41a4-fd93-417f63e01b10"},"source":["MODEL_NAME = \"epoch61\"\n","CP_PATH = \"/content/drive/My Drive/W266/checkpoints/MSFT_50EPOCH_Intransit_AMI1024_NoNA/\" + MODEL_NAME +\".pt\"\n","print(CP_PATH)\n","checkpoint = torch.load(CP_PATH)\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","\n","# train_epoch = checkpoint['train_epoch']\n","# dev_epoch = checkpoint['dev_epoch']\n","# losslist = checkpoint['losslist']\n","# learning_rate = checkpoint['learning_rate']\n","# max_source_length = checkpoint['max_source_length']\n","# max_target_length = checkpoint['max_target_length']\n","# train_batch_size = checkpoint['train_batch_size']\n","# dev_batch_size = checkpoint['dev_batch_size']\n","# optimizer_option = checkpoint['optimizer_option']\n","# test_option = checkpoint['test_option']\n","# training_time = checkpoint['training_time']\n","\n","\n","# evaluating_time = checkpoint['evaluating_time']"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/W266/checkpoints/MSFT_50EPOCH_Intransit_AMI1024_NoNA/epoch61.pt\n"],"name":"stdout"}]}]}