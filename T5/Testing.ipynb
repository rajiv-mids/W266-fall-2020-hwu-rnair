{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Testing.ipynb","provenance":[{"file_id":"1QmLVy9BRlWkwzqGb3xeCLAcSerUVBLTi","timestamp":1607001018802},{"file_id":"1AZtUbaz75zZAztw1LI9uWV2PoH3BAKOu","timestamp":1605978559499},{"file_id":"1UF8WpYXCqNkWZi7JfeLBISki5zkxoR1T","timestamp":1605490905789}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6JMpA3Pi4rr9"},"source":["# T5 Baseline\n","\n","The initial exploration will use T5-small as the pre-training model along with ICSI dataset. When the model is ready, we will expand the dataset and also validation set for other hyperparameter tuning.\n","\n","1. Library Loading  \n","2. Dataset Loading\n","3.   Dataset Transformation\n","4.   Training and Test Splitting\n","5.   Fine Tuning\n","6.   Checkpoint saving\n","7.   Evaluation\n","\n"]},{"cell_type":"markdown","metadata":{"id":"lyAat9uX5rJn"},"source":["## Library Loading"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BODRVvgf5RGZ","executionInfo":{"status":"ok","timestamp":1607002612856,"user_tz":300,"elapsed":14095,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"55c3c998-b895-4251-f783-3364e73d6735"},"source":["!pip install 'transformers==3.3.1'\n","!pip install wandb -q\n","#!pip install datasets\n","!pip install nlp\n","#!pip install rouge_score\n","!pip install rouge\n","#!curl -q https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n","#!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev\n","#!pip install sentencepiece"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers==3.3.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 9.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (1.18.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (4.41.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (0.0.43)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (0.1.94)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (20.4)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (0.8)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (2.23.0)\n","Collecting tokenizers==0.8.1.rc2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 23.9MB/s \n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.3.1) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.3.1) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.3.1) (0.17.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.3.1) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.3.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.3.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.3.1) (2020.11.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.3.1) (1.24.3)\n","Installing collected packages: tokenizers, transformers\n","  Found existing installation: tokenizers 0.9.4\n","    Uninstalling tokenizers-0.9.4:\n","      Successfully uninstalled tokenizers-0.9.4\n","  Found existing installation: transformers 4.0.0\n","    Uninstalling transformers-4.0.0:\n","      Successfully uninstalled transformers-4.0.0\n","Successfully installed tokenizers-0.8.1rc2 transformers-3.3.1\n","Requirement already satisfied: nlp in /usr/local/lib/python3.6/dist-packages (0.4.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from nlp) (2.23.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.6/dist-packages (from nlp) (2.0.0)\n","Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from nlp) (2.0.0)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from nlp) (0.8)\n","Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from nlp) (0.3.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from nlp) (1.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from nlp) (1.18.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from nlp) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from nlp) (4.41.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2020.11.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (1.24.3)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->nlp) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->nlp) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->nlp) (1.15.0)\n","Requirement already satisfied: rouge in /usr/local/lib/python3.6/dist-packages (1.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rouge) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H_ywhvC-zx2k","executionInfo":{"status":"ok","timestamp":1607002616669,"user_tz":300,"elapsed":911,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"ea9fb7af-6b78-49fc-c6c6-50b5ee9fead1"},"source":["!pip list | grep transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["transformers                  3.3.1          \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eqwv6NyQ_Wjl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607002626780,"user_tz":300,"elapsed":3340,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"9a2c78bb-b438-48f9-acfe-d76c2e3760e0"},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","import time\n","\n","# Importing the T5 modules from huggingface/transformers\n","# T5ForConditionalGeneration is specific for sequence-to-sequence\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","\n","#from nlp import load_metric\n","import nlp\n","from rouge import Rouge\n","#import sentencepiece as spm\n","import wandb"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U8XNh-h8_g0_","executionInfo":{"status":"ok","timestamp":1607002628121,"user_tz":300,"elapsed":381,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"de10676b-3d61-46c5-d4a5-3e5bc43d7a27"},"source":["# Checking out the GPU we have access to. This is output is from the google colab version. \n","!nvidia-smi"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Thu Dec  3 13:37:07 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   49C    P0    29W / 250W |     10MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gtYB7VvI_jm4","executionInfo":{"status":"ok","timestamp":1607002628274,"user_tz":300,"elapsed":174,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["# # Setting up the device for GPU usage\n","from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xqq1uu8hA49j"},"source":["## Data Loading\n","\n","Loaded from GDrive the transformed dataset.\n","\n","This portion is using the dataset from extractive summary to abstractive summary"]},{"cell_type":"code","metadata":{"id":"XGXLrMD7GC4O","executionInfo":{"status":"ok","timestamp":1607002630944,"user_tz":300,"elapsed":323,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","train_size = 0.8"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cvq382j4A3MC","executionInfo":{"status":"ok","timestamp":1607002632689,"user_tz":300,"elapsed":1477,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"e3d34fab-1118-4943-cc18-46c8670f2bac"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","#/content/drive/My Drive/W266/data/ICSI_extrac_abstrac_512token.csv"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TZ4EXP96GZ8n"},"source":["## Dataset Transformation\n","\n","Tokenize the input and also perform the attention masking to make sure everything can be done in tensors. \n","\n","Tunable Hyprparam:\n","\n","*   MAX_LEN\n","*   SUMMARY_LEN\n","* TRAIN_BATCH_SIZE\n","* DEV_BATCH_SIZE\n","* TEST_BATCH_SIZE\n"]},{"cell_type":"code","metadata":{"id":"07SniX-oGTcj","executionInfo":{"status":"ok","timestamp":1607032977355,"user_tz":300,"elapsed":295,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["# most code from https://colab.research.google.com/drive/1ypT7oCjtBOTSMJv7J5_1vO7hDYSD_-oU?authuser=2#scrollTo=932p8NhxeNw4\n","\n","class CustomDataset(Dataset):\n","\n","    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.source_len = source_len\n","        self.summ_len = summ_len\n","        self.abstractive = self.data.abstractive\n","        self.extractive = self.data.extractive\n","\n","    def __len__(self):\n","        return len(self.abstractive)\n","\n","    def __getitem__(self, index):\n","        extractive = str(self.extractive[index])\n","        extractive = ' '.join(extractive.split())\n","\n","        abstractive = str(self.abstractive[index])\n","        abstractive = ' '.join(abstractive.split())\n","\n","        source = self.tokenizer.batch_encode_plus([extractive], max_length= self.source_len, truncation=True, pad_to_max_length=True,return_tensors='pt')\n","        target = self.tokenizer.batch_encode_plus([abstractive], max_length= self.summ_len, truncation=True, pad_to_max_length=True,return_tensors='pt')\n","        source_ids = source['input_ids'].squeeze()\n","        source_mask = source['attention_mask'].squeeze()\n","        target_ids = target['input_ids'].squeeze()\n","        target_mask = target['attention_mask'].squeeze()\n","\n","        return {\n","            'source_ids': source_ids.to(dtype=torch.long), \n","            'source_mask': source_mask.to(dtype=torch.long), \n","            'target_ids': target_ids.to(dtype=torch.long),\n","            'target_ids_y': target_ids.to(dtype=torch.long)\n","        }"],"execution_count":95,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WFx2e48uKnY3"},"source":["## Fine Tuning\n","\n","Here we directly use the pre-trained model t5-small and will save checkpoint every 500 steps. \n","\n","Tunable Parameter:\n","* T5ForConditionalGeneration or T5\n","* epoch - train, dev, test\n","* optimizer - LEARNING_RATE, Adam\n","* output: num_beams, length_penalty,early_stopping\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"P9MmjbqbYjHB"},"source":["### Training & Validation Functions\n","\n","The training part uses the t5-small pretrained model, didn't make any change to the model layer structures, and fine tune the parameters based on the dataset we have."]},{"cell_type":"code","metadata":{"id":"UJddO-eY3whv","executionInfo":{"status":"ok","timestamp":1607003784107,"user_tz":300,"elapsed":292,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["def compute_rouge_scores(cand_list, ref_list):\n","    \"\"\"\n","    :param cand_list: list of candidate summaries\n","    :param ref_list: list of reference summaries\n","    :return: rouge scores\n","    \"\"\"\n","    rouge = Rouge()\n","    rouge_1_f_score = 0.\n","    rouge_2_f_score = 0.\n","    rouge_L_f_score = 0.\n","\n","    rouge_1_r_score = 0.\n","    rouge_2_r_score = 0.\n","    rouge_L_r_score = 0.\n","\n","    rouge_1_p_score = 0.\n","    rouge_2_p_score = 0.\n","    rouge_L_p_score = 0.\n","\n","    doc_count = len(cand_list)\n","\n","    for cand, ref in zip(cand_list, ref_list):\n","        rouge_scores = rouge.get_scores(cand, ref)[0]\n","        rouge_1_f_score += rouge_scores['rouge-1']['f']\n","        rouge_2_f_score += rouge_scores['rouge-2']['f']\n","        rouge_L_f_score += rouge_scores['rouge-l']['f']\n","\n","        rouge_1_r_score += rouge_scores['rouge-1']['r']\n","        rouge_2_r_score += rouge_scores['rouge-2']['r']\n","        rouge_L_r_score += rouge_scores['rouge-l']['r']\n","\n","        rouge_1_p_score += rouge_scores['rouge-1']['p']\n","        rouge_2_p_score += rouge_scores['rouge-2']['p']\n","        rouge_L_p_score += rouge_scores['rouge-l']['p']\n","    rouge_1_f_score = rouge_1_f_score / doc_count\n","    rouge_2_f_score = rouge_2_f_score / doc_count\n","    rouge_L_f_score = rouge_L_f_score / doc_count\n","\n","    results_dict = {}\n","    results_dict['rouge_1_f_score'] = rouge_1_f_score\n","    results_dict['rouge_2_f_score'] = rouge_2_f_score\n","    results_dict['rouge_l_f_score'] = rouge_L_f_score\n","\n","    return results_dict"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iPFN2UlXn37l"},"source":["# Testing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FMPmQP1qn6Yv","executionInfo":{"status":"ok","timestamp":1607036741835,"user_tz":300,"elapsed":510,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"a06a864d-b24c-40d9-d1a1-eeeef85ca9f1"},"source":["test_dataset_icsi = pd.read_csv('/content/drive/My Drive/W266/data/512_tokens/ICSI_512_test.csv',encoding='latin-1')\n","test_dataset_ami = pd.read_csv('/content/drive/My Drive/W266/data/512_tokens/AMI_512_test.csv',encoding='latin-1')\n","\n","test_dataset_icsi = test_dataset_icsi.dropna(subset=['abstractive'])\n","test_dataset_icsi = test_dataset_icsi.reset_index(drop=True)\n","\n","test_dataset_ami = test_dataset_ami.dropna(subset=['abstractive'])\n","test_dataset_ami = test_dataset_ami.reset_index(drop=True)\n","\n","# use the pre-defined \"summarize\" for abstractive summary\n","test_dataset_icsi.extractive = 'summarize: ' + test_dataset_icsi.extractive\n","test_dataset_ami.extractive = 'summarize: ' + test_dataset_ami.extractive\n","print(len(test_dataset_icsi))\n","print(len(test_dataset_ami))\n"],"execution_count":125,"outputs":[{"output_type":"stream","text":["52\n","898\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":340},"id":"VKzbfeq32zRR","executionInfo":{"status":"ok","timestamp":1607036743000,"user_tz":300,"elapsed":308,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"79cc31e3-a821-4106-8333-b03fa432b9c2"},"source":["test_dataset_icsi.head(5)"],"execution_count":126,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>meeting</th>\n","      <th>original</th>\n","      <th>extractive</th>\n","      <th>abstractive</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Bed004.A</td>\n","      <td>Hey , you 're not supposed to be drinking in h...</td>\n","      <td>summarize: So , what I did for this this is uh...</td>\n","      <td>It is not a working net yet, but identifying c...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Bed004.A</td>\n","      <td>um , so we could sort of isolate them or whate...</td>\n","      <td>summarize: So basically all I did was I took t...</td>\n","      <td>It is not a working net yet, but identifying c...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Bed004.A</td>\n","      <td>Um , the Parse would be what verb they chose ,...</td>\n","      <td>summarize: Um , the Parse would be what verb t...</td>\n","      <td>It is not a working net yet, but identifying c...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Bed004.B</td>\n","      <td>Mm - hmm .  So , are are you trying to record ...</td>\n","      <td>summarize: S so if you just number them \" one ...</td>\n","      <td>The group decided to hire the \"wizard\" and con...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Bed004.B</td>\n","      <td>So , so if you if we made if we wanted to make...</td>\n","      <td>summarize: is , if we just do this , we could ...</td>\n","      <td>There are potential problems from a combinator...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    meeting  ...                                        abstractive\n","0  Bed004.A  ...  It is not a working net yet, but identifying c...\n","1  Bed004.A  ...  It is not a working net yet, but identifying c...\n","2  Bed004.A  ...  It is not a working net yet, but identifying c...\n","3  Bed004.B  ...  The group decided to hire the \"wizard\" and con...\n","4  Bed004.B  ...  There are potential problems from a combinator...\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":126}]},{"cell_type":"code","metadata":{"id":"P25aYtvxpdGl","executionInfo":{"status":"ok","timestamp":1607036748944,"user_tz":300,"elapsed":630,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["MAX_LEN = 512\n","SUMMARY_LEN= 150\n","\n","# note here only uses the t5-small model.\n","tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n","test_set_icsi  = CustomDataset(test_dataset_icsi, tokenizer, MAX_LEN, SUMMARY_LEN)\n","test_set_ami  = CustomDataset(test_dataset_ami, tokenizer, MAX_LEN, SUMMARY_LEN)\n"],"execution_count":128,"outputs":[]},{"cell_type":"code","metadata":{"id":"mNgYmRkLqTjT","executionInfo":{"status":"ok","timestamp":1607036749900,"user_tz":300,"elapsed":347,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["# https://deeplizard.com/learn/video/kWVgvsejXsE#:~:text=The%20num_workers%20attribute%20tells%20the,sequentially%20inside%20the%20main%20process\n","# num_workers to default 0\n","# This means that the training process will work sequentially inside the main process. \n","# After a batch is used during the training process and another one is needed, we read the batch data from disk.\n","\n","TEST_BATCH_SIZE = 1 \n","\n","test_params = {\n","  'batch_size': TEST_BATCH_SIZE,\n","  'shuffle': False,\n","  'num_workers': 0\n","  }\n","test_loader_icsi = DataLoader(test_set_icsi, **test_params)\n","test_loader_ami = DataLoader(test_set_ami, **test_params)"],"execution_count":129,"outputs":[]},{"cell_type":"code","metadata":{"id":"pMKUN-nCpwtp","executionInfo":{"status":"ok","timestamp":1607036752092,"user_tz":300,"elapsed":308,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["# https://towardsdatascience.com/fine-tuning-a-t5-transformer-for-any-summarization-task-82334c64c81\n","\n","def test(epoch, tokenizer, model, device, loader, beams):\n","  #https://stackoverflow.com/questions/60018578/what-does-model-eval-do-in-pytorch\n","  model.eval()\n","  predictions = []\n","  actuals = []\n","  #rouge_metric = load_metric('rouge') \n","  # https://datascience.stackexchange.com/questions/32651/what-is-the-use-of-torch-no-grad-in-pytorch\n","  with torch.no_grad():\n","\n","    for _, data in enumerate(loader, 0):\n","\n","      y = data['target_ids'].to(device, dtype = torch.long)\n","      ids = data['source_ids'].to(device, dtype = torch.long)\n","      mask = data['source_mask'].to(device, dtype = torch.long)\n","\n","      generated_ids = model.generate(\n","          input_ids = ids,\n","          attention_mask = mask, \n","          max_length=150, \n","          num_beams=beams,\n","          repetition_penalty=2.5, \n","          length_penalty=1.0, \n","          early_stopping=True\n","          )\n","      preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n","      target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n","      if _%100==0:\n","          print(f'Completed {_}')\n","      predictions.extend(preds)\n","      actuals.extend(target)\n","  return predictions, actuals"],"execution_count":130,"outputs":[]},{"cell_type":"code","metadata":{"id":"rs8ziDgiqCjk","executionInfo":{"status":"ok","timestamp":1607036754706,"user_tz":300,"elapsed":337,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["AMI_PATH = \"/content/drive/My Drive/W266/data/gold_abstractive_summary/goldsummary_AMI_as_test.csv\"\n","ICSI_PATH = \"/content/drive/My Drive/W266/data/gold_abstractive_summary/goldsummary_ICSI_as_test.csv\"\n","\n","amigold = pd.read_csv(AMI_PATH)\n","icsigold = pd.read_csv(ICSI_PATH)\n","\n","def rouge_per_document(final_df,gold, test_dataset):\n","  merged_df = pd.concat([test_dataset.meeting, final_df.Generated_Abstractive_Summary], axis=1)\n","  merged_df[\"meetinglevel\"] = merged_df.meeting.apply(lambda x: x.split(\".\")[0]) \n","\n","  gas_list =[]\n","  meeting_list = []\n","  generated_abstractive = \"\"\n","  for me in set(merged_df.meetinglevel):\n","    for gas in merged_df[merged_df.meetinglevel == me]['Generated_Abstractive_Summary']:\n","      generated_abstractive+= gas + \" \"\n","    gas_list.append(generated_abstractive)\n","    meeting_list.append(me)\n","    generated_abstractive = \" \"\n","  per_doc_summary = pd.DataFrame(\n","    {'Meeting': meeting_list,\n","     'Generated_Abstractive_Summary': gas_list\n","    })\n","  \n","  new_df = pd.merge(per_doc_summary, gold,  how='left', left_on='Meeting', right_on ='meeting')\n","  rouge_results_perdoc = compute_rouge_scores(new_df.Generated_Abstractive_Summary,\n","                                      new_df.abstractive)\n","  return rouge_results_perdoc\n","  "],"execution_count":131,"outputs":[]},{"cell_type":"code","metadata":{"id":"WxLGRjF8rHlq","executionInfo":{"status":"ok","timestamp":1607036756319,"user_tz":300,"elapsed":284,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["## ================= TESTING =================== ##\n","def testingprocess (modelsize, LEARNING_RATE,CP_TEMP_NAME, MODEL_NAME, folder,beams,gold,test_set,test_loader):\n","  print(\"strat testing\")\n","  model = T5ForConditionalGeneration.from_pretrained(modelsize)\n","  model = model.to(device)\n","  optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n","\n","  CP_PATH = \"/content/drive/My Drive/W266/checkpoints/\"+folder+ \"/\" + CP_TEMP_NAME +\".pt\"\n","  checkpoint = torch.load(CP_PATH)\n","  model.load_state_dict(checkpoint['model_state_dict'])\n","  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","  print(\"strat epoch\")\n","  predictions, actuals = test(1, tokenizer, model, device, test_loader,beams)\n","  final_df = pd.DataFrame({'Generated_Abstractive_Summary':predictions,\n","                            'Golden_Abstractive_Text':actuals})\n","  final_df.to_csv('/content/drive/My Drive/W266/final/'+MODEL_NAME +'_prediction.csv')\n","\n","  rouge_results = compute_rouge_scores(final_df.Generated_Abstractive_Summary,\n","                                        final_df.Golden_Abstractive_Text)\n","  print(\"done row level Rouge\")\n","  test_time = time.time() - start_test_time\n","\n","  # amigold = pd.read_csv(AMI_PATH)\n","  # icsigold = pd.read_csv(ICSI_PATH)\n","\n","  rouge_results_perdoc = rouge_per_document(final_df,gold,test_set)\n","  print(\"done document level Rouge\")\n","\n","  results = pd.DataFrame({\n","            'model': MODEL_NAME,\n","            'rouge1': rouge_results.get(\"rouge_1_f_score\"), \n","            'rougeL': rouge_results.get(\"rouge_l_f_score\"),  \n","            'rouge2': rouge_results.get(\"rouge_2_f_score\"),\n","            'rouge1_doclevel': rouge_results_perdoc.get(\"rouge_1_f_score\"), \n","            'rougeL_doclevel': rouge_results_perdoc.get(\"rouge_l_f_score\"),  \n","            'rouge2_doclevel': rouge_results_perdoc.get(\"rouge_2_f_score\"),\n","            'testTime': test_time\n","            },index=[0])\n","  results.to_csv('/content/drive/My Drive/W266/final/'+MODEL_NAME +'_rouge.csv')\n","  return rouge_results_perdoc,rouge_results"],"execution_count":132,"outputs":[]},{"cell_type":"code","metadata":{"id":"ukA0Qa1XuFYR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607036869451,"user_tz":300,"elapsed":107792,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"e24101ae-5984-40f0-e3a6-0516e304f280"},"source":["start_test_time = time.time()\n","LEARNING_RATE = 0.0005\n","MODEL_NAME = \"ICSI_512_9\"\n","CP_TEMP_NAME = 'epoch9' \n","folder = \"MSFT_50EPOCH_Intransit_ICSI512_NoNA\"\n","beams = 9\n","gold = icsigold\n","test_set = test_dataset_icsi\n","testingprocess (\"t5-small\",LEARNING_RATE,CP_TEMP_NAME, \n","                                  MODEL_NAME, folder,beams,gold,test_set,test_loader_icsi)\n"],"execution_count":133,"outputs":[{"output_type":"stream","text":["strat testing\n","strat epoch\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Completed 0\n","done row level Rouge\n","done document level Rouge\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["({'rouge_1_f_score': 0.24691853592978777,\n","  'rouge_2_f_score': 0.038219265353075904,\n","  'rouge_l_f_score': 0.20595295115555093},\n"," {'rouge_1_f_score': 0.15650915732937948,\n","  'rouge_2_f_score': 0.014400942429079331,\n","  'rouge_l_f_score': 0.11335229096312885})"]},"metadata":{"tags":[]},"execution_count":133}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DCHKnApL3iVv","executionInfo":{"status":"ok","timestamp":1607037979623,"user_tz":300,"elapsed":1109514,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"2c01c38a-8c70-4a0e-983f-991836b0c674"},"source":["start_test_time = time.time()\n","LEARNING_RATE = 0.0005\n","MODEL_NAME = \"AMI_512_15\"\n","CP_TEMP_NAME = 'epoch15' \n","folder = \"MSFT_50EPOCH_Intransit_AMI512_NoNA\"\n","beams = 12\n","gold = amigold\n","test_set = test_dataset_ami\n","test_loader = test_loader_ami\n","testingprocess (\"t5-small\",LEARNING_RATE,CP_TEMP_NAME, \n","                                  MODEL_NAME, folder,beams,gold,test_set,test_loader)\n","\n"],"execution_count":134,"outputs":[{"output_type":"stream","text":["strat testing\n","strat epoch\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Completed 0\n","Completed 100\n","Completed 200\n","Completed 300\n","Completed 400\n","Completed 500\n","Completed 600\n","Completed 700\n","Completed 800\n","done row level Rouge\n","done document level Rouge\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["({'rouge_1_f_score': 0.2407445478960022,\n","  'rouge_2_f_score': 0.06733138141661116,\n","  'rouge_l_f_score': 0.26106556609284315},\n"," {'rouge_1_f_score': 0.15896372952509064,\n","  'rouge_2_f_score': 0.022142911276734817,\n","  'rouge_l_f_score': 0.13194669919855792})"]},"metadata":{"tags":[]},"execution_count":134}]},{"cell_type":"code","metadata":{"id":"Ik5LTJ8_ePmS","executionInfo":{"status":"ok","timestamp":1607034093561,"user_tz":300,"elapsed":322,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["## ================= TESTING =================== ##\n","def testingprocess_BERT (modelsize, LEARNING_RATE,CP_TEMP_NAME, MODEL_NAME, folder,beams,gold,test_set,test_loader):\n","  print(\"strat testing\")\n","  model = T5ForConditionalGeneration.from_pretrained(modelsize)\n","  model = model.to(device)\n","  optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n","\n","  CP_PATH = \"/content/drive/My Drive/W266/checkpoints/\"+folder+ \"/\" + CP_TEMP_NAME +\".pt\"\n","  checkpoint = torch.load(CP_PATH)\n","  model.load_state_dict(checkpoint['model_state_dict'])\n","  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","  print(\"strat epoch\")\n","  predictions, actuals = test(1, tokenizer, model, device, test_loader,beams)\n","  final_df = pd.DataFrame({'Generated_Abstractive_Summary':predictions,\n","                            'Golden_Abstractive_Text':actuals})\n","  final_df.to_csv('/content/drive/My Drive/W266/final/'+MODEL_NAME +'_prediction.csv')\n","\n","  test_time = time.time() - start_test_time\n","\n","  # amigold = pd.read_csv(AMI_PATH)\n","  # icsigold = pd.read_csv(ICSI_PATH)\n","\n","  rouge_results_perdoc = rouge_per_document(final_df,gold,test_set)\n","  print(\"done document level Rouge\")\n","\n","  results = pd.DataFrame({\n","            'model': MODEL_NAME,\n","            'rouge1_doclevel': rouge_results_perdoc.get(\"rouge_1_f_score\"), \n","            'rougeL_doclevel': rouge_results_perdoc.get(\"rouge_l_f_score\"),  \n","            'rouge2_doclevel': rouge_results_perdoc.get(\"rouge_2_f_score\"),\n","            'testTime': test_time\n","            },index=[0])\n","  results.to_csv('/content/drive/My Drive/W266/final/'+MODEL_NAME +'_rouge.csv')\n","  return rouge_results_perdoc"],"execution_count":119,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XTCtMi7spIEy","executionInfo":{"status":"ok","timestamp":1607034652110,"user_tz":300,"elapsed":65613,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"53bfe4a3-af9c-45e7-a666-b18f56b97b80"},"source":["start_test_time = time.time()\n","LEARNING_RATE = 0.001\n","MODEL_NAME = \"ICSI_ex_largelr_34\"\n","CP_TEMP_NAME = 'epoch34' \n","folder = \"50EPOCH_Intransit_ICSI1024_eax_largelr\"\n","beams = 9\n","gold = icsigold\n","test_set = test_dataset_icsi\n","testingprocess_BERT(\"t5-small\",LEARNING_RATE,CP_TEMP_NAME, \n","                                  MODEL_NAME, folder,beams,gold,test_set,test_loader_icsi)\n"],"execution_count":123,"outputs":[{"output_type":"stream","text":["strat testing\n","strat epoch\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Completed 0\n","done document level Rouge\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'rouge_1_f_score': 0.24506177151011407,\n"," 'rouge_2_f_score': 0.019061940082116213,\n"," 'rouge_l_f_score': 0.19795215860618973}"]},"metadata":{"tags":[]},"execution_count":123}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h791tnrqrzOm","executionInfo":{"status":"ok","timestamp":1607034945898,"user_tz":300,"elapsed":293781,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"a3a4d4ac-9a19-4fa0-aef4-78a036e6e9d0"},"source":["start_test_time = time.time()\n","LEARNING_RATE = 0.001\n","MODEL_NAME = \"AMI_ex_largelr_15\"\n","CP_TEMP_NAME = 'epoch15' \n","folder = \"50EPOCH_Intransit_AMI1024_eax_largelr\"\n","beams = 12\n","gold = amigold\n","test_set = test_dataset_ami\n","test_loader = test_loader_ami\n","testingprocess_BERT(\"t5-small\",LEARNING_RATE,CP_TEMP_NAME, \n","                                  MODEL_NAME, folder,beams,gold,test_set,test_loader)\n","\n"],"execution_count":124,"outputs":[{"output_type":"stream","text":["strat testing\n","strat epoch\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Completed 0\n","done document level Rouge\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'rouge_1_f_score': 0.31107486599755413,\n"," 'rouge_2_f_score': 0.07397523049180393,\n"," 'rouge_l_f_score': 0.24337593412034625}"]},"metadata":{"tags":[]},"execution_count":124}]},{"cell_type":"code","metadata":{"id":"WL3hEYATqxs_","executionInfo":{"status":"ok","timestamp":1607033667599,"user_tz":300,"elapsed":371,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["final_df= pd.read_csv('/content/drive/My Drive/W266/final/'+MODEL_NAME +'_prediction.csv')"],"execution_count":107,"outputs":[]},{"cell_type":"code","metadata":{"id":"BCMJUfuZqidx","executionInfo":{"status":"ok","timestamp":1607033667757,"user_tz":300,"elapsed":188,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}}},"source":["merged_df = pd.concat([test_dataset_icsi.meeting, final_df.Generated_Abstractive_Summary], axis=1)\n","merged_df[\"meetinglevel\"] = merged_df.meeting.apply(lambda x: x.split(\".\")[0]) \n"],"execution_count":108,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":155},"id":"IXvaLyVHq8ze","executionInfo":{"status":"ok","timestamp":1607033750109,"user_tz":300,"elapsed":306,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"140b5975-afa4-4548-d6e1-42f696f04420"},"source":["merged_df.iloc[0]['Generated_Abstractive_Summary']"],"execution_count":112,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'results, if those prove appropriate, and how much responsibility rests on participants being available and checking their e-mail regularly. The group suggest sending reminder e-mails, although since many participants are local they can be contacted by other means if necessary. Checking of the NSA meetings has revealed that this non-native English meeting data contains transcription inaccuracies due to the use of foreign language terms and technical vocabulary. Additional topics covered more briefly in this meeting are disk space, the DARPA annual report,'"]},"metadata":{"tags":[]},"execution_count":112}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VpC2CW6CqvhG","executionInfo":{"status":"ok","timestamp":1607033806537,"user_tz":300,"elapsed":349,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"baf5d33d-52d8-4543-e2d5-df3053934b6f"},"source":["\n","gas_list =[]\n","meeting_list = []\n","generated_abstractive = \"\"\n","for me in set(merged_df.meetinglevel):\n","  for gas in merged_df[merged_df.meetinglevel == me]['Generated_Abstractive_Summary']:\n","    generated_abstractive+= gas + \" \"\n","  gas_list.append(generated_abstractive)\n","  meeting_list.append(me)\n","  generated_abstractive = \" \"\n","per_doc_summary = pd.DataFrame(\n","  {'Meeting': meeting_list,\n","    'Generated_Abstractive_Summary': gas_list\n","  })\n","\n","new_df = pd.merge(per_doc_summary, gold,  how='left', left_on='Meeting', right_on ='meeting')\n","print(new_df)\n","\n","rouge_results_perdoc = compute_rouge_scores(new_df.Generated_Abstractive_Summary,\n","                                    new_df.abstractive)\n"],"execution_count":113,"outputs":[{"output_type":"stream","text":["  Meeting  ...                                        abstractive\n","0  Bed016  ...  The meeting was taken up by discussion about a...\n","1  Bmr005  ...  Topics discussed by the Berkeley Meeting Recor...\n","2  Bro018  ...  The ICSI Meeting Recorder Group met once more ...\n","3  Bed009  ...  The Berkeley Even Deeper Understanding group d...\n","4  Bmr019  ...  The Berkeley Meeting Recorder group discussed ...\n","5  Bed004  ...  A test run of the data collection design was v...\n","\n","[6 rows x 4 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":310},"id":"SdHyaBuerFm6","executionInfo":{"status":"ok","timestamp":1607033835265,"user_tz":300,"elapsed":325,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"7b833369-80de-447c-acd0-3a65035ce205"},"source":["new_df.iloc[0]['abstractive']"],"execution_count":115,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'The meeting was taken up by discussion about a thesis proposal and a talk about to take place at EML. The latter will present the work that is currently being done at ICSI including examples of inference of user intentions and of the recordings of the on-going data collection. The talk will also outline the theoretical (X-schemas, image schemas, Bayes-nets) and neural background. The thesis proposal, on the other hand, presents the idea of \"construal\" and makes claims as to how inferences are drawn in a probabilistic relational model by using information from the ontology, situation, user and discourse models. It was advised that more emphasis should be put on the role of construal in the understanding of metaphor and metonymy. Base constructions deal with the norm, while further general domain mechanisms determine how the constructions are invoked depending on the context. Several potential examples of polysemy were discussed in detail: \"walk/run into\", \"on the bus\", \"out of film\", \"where is X?\". However, none of them was an example of lexical polysemy resolved by construal straightforward enough to include in the proposal; the tourist domain is not metaphor rich. '"]},"metadata":{"tags":[]},"execution_count":115}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":258},"id":"EKUg88Y9rh-c","executionInfo":{"status":"ok","timestamp":1607033844804,"user_tz":300,"elapsed":439,"user":{"displayName":"Qianqian Wu","photoUrl":"","userId":"07224477723120945833"}},"outputId":"603d521c-228b-49c2-f537-fcc8d35d3190"},"source":["new_df.iloc[0]['Generated_Abstractive_Summary']"],"execution_count":116,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"discussions were also made with regard to a visitor from research partner OGI These included making plans for upcoming experiments, clarifying definitions, and approaches which may or may not be against the rules of the Aurora project, alongside alternatives that would not be. Although the members of ICSI's Meeting Recorder Group at Berkeley had little progress to report, there were still a number of issues relating to their work to discuss. These included making plans for upcoming experiments, clarifying definitions, and approaches which may or may not be against the this includes reports on the progress of the groups main digit recogniser project, with interest on voice-activity detectors and voiced/unvoiced detection, work on acoustic feature detection, and research into dealing with reverberation. The group note that the annual report needs to be worked on for next week, and it is also suggested to hold recognition meetings separately, however these issues will be discussed in more detail at the next meeting. \""]},"metadata":{"tags":[]},"execution_count":116}]},{"cell_type":"code","metadata":{"id":"aPrNtWJUrnJj"},"source":[""],"execution_count":null,"outputs":[]}]}